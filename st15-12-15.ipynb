{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "df=pd.read_csv('C:/Users/yy2895/Desktop/update_stresult19-15-19.csv',header=None)\n",
    "d = df.values\n",
    "ntotal=len(df)\n",
    "\n",
    "# we do not renormalize it \n",
    "#d = normalize(d, axis=0, norm='l2')\n",
    "\n",
    "\n",
    "resultu = []\n",
    "np.random.rand(4)\n",
    "# Return 100 results (for instance)\n",
    "for i in range(ntotal):\n",
    "    \n",
    "    res = random.random()\n",
    "    if res < 0.1:\n",
    "        resultu.append(1)\n",
    "    elif res < 0.2 and res>=0.1:\n",
    "        resultu.append(2)\n",
    "    elif res < 0.3 and res>=0.2:\n",
    "        resultu.append(3)\n",
    "    elif res < 0.4 and res>=0.3:\n",
    "        resultu.append(4)\n",
    "    elif res < 0.5 and res>=0.4:\n",
    "        resultu.append(5)\n",
    "    elif res < 0.6 and res>=0.5:\n",
    "        resultu.append(6)\n",
    "    elif res < 0.7 and res>=0.6:\n",
    "        resultu.append(7)\n",
    "    elif res < 0.8 and res>=0.7:\n",
    "        resultu.append(8)\n",
    "    else:\n",
    "        resultu.append(9)\n",
    "resultu=np.array(resultu)\n",
    "trainset=[]\n",
    "for i in range(1,8):\n",
    "    toinsert=d[resultu==i].astype(np.float32)\n",
    "    trainset.append(toinsert)\n",
    "validationset=d[resultu==8].astype(np.float32)\n",
    "testset=d[resultu==9].astype(np.float32)\n",
    "\n",
    "\n",
    "#x = data\n",
    "\n",
    "# Following Hinton-Salakhutdinov Architecture\n",
    "\n",
    "# 3 hidden layers for encoder\n",
    "n_encoder_h_1 = 14\n",
    "n_encoder_h_2 = 9\n",
    "\n",
    "\n",
    "\n",
    "#n_encoder_h_5 = 10\n",
    "\n",
    "\n",
    "# 3 hidden layers for decoder\n",
    "#n_decoder_h_1 = 10\n",
    "n_decoder_h_1 = 14\n",
    "n_decoder_h_2 = 19\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.005\n",
    "\n",
    "#batch_size = 7\n",
    "display_step = 1\n",
    "\n",
    "total_batch=7\n",
    "training_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we begin\n",
      "Epoch: 0001 cost = 1.443781137\n",
      "Validation Loss: 1.946187\n",
      "Epoch: 0002 cost = 1.423898407\n",
      "Validation Loss: 1.6862603\n",
      "Epoch: 0003 cost = 1.404661826\n",
      "Validation Loss: 1.5295599\n",
      "Epoch: 0004 cost = 1.386461854\n",
      "Validation Loss: 1.4572841\n",
      "Epoch: 0005 cost = 1.368692483\n",
      "Validation Loss: 1.460228\n",
      "Epoch: 0006 cost = 1.349577427\n",
      "Validation Loss: 1.3358514\n",
      "Epoch: 0007 cost = 1.325785245\n",
      "Validation Loss: 1.4209105\n",
      "Epoch: 0008 cost = 1.294718266\n",
      "Validation Loss: 1.3363613\n",
      "Epoch: 0009 cost = 1.265867404\n",
      "Validation Loss: 1.370359\n",
      "Epoch: 0010 cost = 1.244474207\n",
      "Validation Loss: 1.4007187\n",
      "Epoch: 0011 cost = 1.225911209\n",
      "Validation Loss: 1.4136133\n",
      "Epoch: 0012 cost = 1.208220788\n",
      "Validation Loss: 1.4184484\n",
      "Epoch: 0013 cost = 1.191461495\n",
      "Validation Loss: 1.397293\n",
      "Epoch: 0014 cost = 1.176175475\n",
      "Validation Loss: 1.3464154\n",
      "Epoch: 0015 cost = 1.162802202\n",
      "Validation Loss: 1.2957115\n",
      "Epoch: 0016 cost = 1.151400396\n",
      "Validation Loss: 1.3906928\n",
      "Epoch: 0017 cost = 1.141514761\n",
      "Validation Loss: 1.2742362\n",
      "Epoch: 0018 cost = 1.132600273\n",
      "Validation Loss: 1.3247088\n",
      "Epoch: 0019 cost = 1.124279652\n",
      "Validation Loss: 1.2121774\n",
      "Epoch: 0020 cost = 1.116332855\n",
      "Validation Loss: 1.2756358\n",
      "Epoch: 0021 cost = 1.108639683\n",
      "Validation Loss: 1.1719093\n",
      "Epoch: 0022 cost = 1.101133653\n",
      "Validation Loss: 1.2505347\n",
      "Epoch: 0023 cost = 1.093772020\n",
      "Validation Loss: 1.1510438\n",
      "Epoch: 0024 cost = 1.086522256\n",
      "Validation Loss: 1.2350475\n",
      "Epoch: 0025 cost = 1.079357522\n",
      "Validation Loss: 1.1343737\n",
      "Epoch: 0026 cost = 1.072256446\n",
      "Validation Loss: 1.2240176\n",
      "Epoch: 0027 cost = 1.065200789\n",
      "Validation Loss: 1.1308681\n",
      "Epoch: 0028 cost = 1.058177505\n",
      "Validation Loss: 1.211246\n",
      "Epoch: 0029 cost = 1.051175577\n",
      "Validation Loss: 1.1104634\n",
      "Epoch: 0030 cost = 1.044184957\n",
      "Validation Loss: 1.1898488\n",
      "Epoch: 0031 cost = 1.037193997\n",
      "Validation Loss: 1.097942\n",
      "Epoch: 0032 cost = 1.030189105\n",
      "Validation Loss: 1.1731552\n",
      "Epoch: 0033 cost = 1.023155212\n",
      "Validation Loss: 1.0789405\n",
      "Epoch: 0034 cost = 1.016082406\n",
      "Validation Loss: 1.1464366\n",
      "Epoch: 0035 cost = 1.008976528\n",
      "Validation Loss: 1.0613451\n",
      "Epoch: 0036 cost = 1.001866000\n",
      "Validation Loss: 1.1430975\n",
      "Epoch: 0037 cost = 0.994798345\n",
      "Validation Loss: 1.0524378\n",
      "Epoch: 0038 cost = 0.987806584\n",
      "Validation Loss: 1.1134177\n",
      "Epoch: 0039 cost = 0.980873985\n",
      "Validation Loss: 1.0175736\n",
      "Epoch: 0040 cost = 0.973954976\n",
      "Validation Loss: 1.0840495\n",
      "Epoch: 0041 cost = 0.967020128\n",
      "Validation Loss: 0.9982138\n",
      "Epoch: 0042 cost = 0.960058093\n",
      "Validation Loss: 1.0690156\n",
      "Epoch: 0043 cost = 0.953066758\n",
      "Validation Loss: 0.9751848\n",
      "Epoch: 0044 cost = 0.946043628\n",
      "Validation Loss: 1.0459542\n",
      "Epoch: 0045 cost = 0.938986736\n",
      "Validation Loss: 0.96257573\n",
      "Epoch: 0046 cost = 0.931905942\n",
      "Validation Loss: 1.0141553\n",
      "Epoch: 0047 cost = 0.924828555\n",
      "Validation Loss: 0.9041399\n",
      "Epoch: 0048 cost = 0.917785857\n",
      "Validation Loss: 1.0063726\n",
      "Epoch: 0049 cost = 0.910804416\n",
      "Validation Loss: 0.930555\n",
      "Epoch: 0050 cost = 0.903905281\n",
      "Validation Loss: 0.8999368\n",
      "Epoch: 0051 cost = 0.897101649\n",
      "Validation Loss: 0.97521925\n",
      "Epoch: 0052 cost = 0.890396927\n",
      "Validation Loss: 0.8835709\n",
      "Epoch: 0053 cost = 0.883784073\n",
      "Validation Loss: 0.97530985\n",
      "Epoch: 0054 cost = 0.877252689\n",
      "Validation Loss: 0.9256281\n",
      "Epoch: 0055 cost = 0.870793709\n",
      "Validation Loss: 0.9234014\n",
      "Epoch: 0056 cost = 0.864399833\n",
      "Validation Loss: 0.91084886\n",
      "Epoch: 0057 cost = 0.858062966\n",
      "Validation Loss: 0.8743652\n",
      "Epoch: 0058 cost = 0.851773364\n",
      "Validation Loss: 0.98141\n",
      "Epoch: 0059 cost = 0.845521271\n",
      "Validation Loss: 0.92551196\n",
      "Epoch: 0060 cost = 0.839296980\n",
      "Validation Loss: 0.90911615\n",
      "Epoch: 0061 cost = 0.833092468\n",
      "Validation Loss: 0.9033895\n",
      "Epoch: 0062 cost = 0.826902645\n",
      "Validation Loss: 0.91443515\n",
      "Epoch: 0063 cost = 0.820724504\n",
      "Validation Loss: 0.8587168\n",
      "Epoch: 0064 cost = 0.814559741\n",
      "Validation Loss: 0.981434\n",
      "Epoch: 0065 cost = 0.808415217\n",
      "Validation Loss: 0.92137116\n",
      "Epoch: 0066 cost = 0.802305732\n",
      "Validation Loss: 0.87691534\n",
      "Epoch: 0067 cost = 0.796255452\n",
      "Validation Loss: 0.87729937\n",
      "Epoch: 0068 cost = 0.790292731\n",
      "Validation Loss: 0.90437734\n",
      "Epoch: 0069 cost = 0.784443208\n",
      "Validation Loss: 0.90618885\n",
      "Epoch: 0070 cost = 0.778718318\n",
      "Validation Loss: 0.91413677\n",
      "Epoch: 0071 cost = 0.773111020\n",
      "Validation Loss: 0.92212945\n",
      "Epoch: 0072 cost = 0.767603329\n",
      "Validation Loss: 0.9610544\n",
      "Epoch: 0073 cost = 0.762177919\n",
      "Validation Loss: 0.9351102\n",
      "Epoch: 0074 cost = 0.756823191\n",
      "Validation Loss: 0.92925924\n",
      "Epoch: 0075 cost = 0.751532384\n",
      "Validation Loss: 0.91862524\n",
      "Epoch: 0076 cost = 0.746299633\n",
      "Validation Loss: 0.886066\n",
      "Epoch: 0077 cost = 0.741120338\n",
      "Validation Loss: 0.8599076\n",
      "Epoch: 0078 cost = 0.735990516\n",
      "Validation Loss: 0.8334738\n",
      "Epoch: 0079 cost = 0.730907815\n",
      "Validation Loss: 0.8970177\n",
      "Epoch: 0080 cost = 0.725869766\n",
      "Validation Loss: 0.81196874\n",
      "Epoch: 0081 cost = 0.720874914\n",
      "Validation Loss: 0.8634658\n",
      "Epoch: 0082 cost = 0.715921657\n",
      "Validation Loss: 0.8273476\n",
      "Epoch: 0083 cost = 0.711008821\n",
      "Validation Loss: 0.7986659\n",
      "Epoch: 0084 cost = 0.706135256\n",
      "Validation Loss: 0.85064816\n",
      "Epoch: 0085 cost = 0.701300485\n",
      "Validation Loss: 0.7755803\n",
      "Epoch: 0086 cost = 0.696502992\n",
      "Validation Loss: 0.8409707\n",
      "Epoch: 0087 cost = 0.691742310\n",
      "Validation Loss: 0.7450982\n",
      "Epoch: 0088 cost = 0.687017356\n",
      "Validation Loss: 0.81973034\n",
      "Epoch: 0089 cost = 0.682327058\n",
      "Validation Loss: 0.7173895\n",
      "Epoch: 0090 cost = 0.677670709\n",
      "Validation Loss: 0.83001596\n",
      "Epoch: 0091 cost = 0.673046853\n",
      "Validation Loss: 0.7559044\n",
      "Epoch: 0092 cost = 0.668455218\n",
      "Validation Loss: 0.7117202\n",
      "Epoch: 0093 cost = 0.663893964\n",
      "Validation Loss: 0.8122668\n",
      "Epoch: 0094 cost = 0.659362674\n",
      "Validation Loss: 0.72604257\n",
      "Epoch: 0095 cost = 0.654860343\n",
      "Validation Loss: 0.6916693\n",
      "Epoch: 0096 cost = 0.650385865\n",
      "Validation Loss: 0.7894378\n",
      "Epoch: 0097 cost = 0.645938235\n",
      "Validation Loss: 0.7103224\n",
      "Epoch: 0098 cost = 0.641516668\n",
      "Validation Loss: 0.6704235\n",
      "Epoch: 0099 cost = 0.637120170\n",
      "Validation Loss: 0.7657226\n",
      "Epoch: 0100 cost = 0.632747812\n",
      "Validation Loss: 0.68497753\n",
      "Epoch: 0101 cost = 0.628398206\n",
      "Validation Loss: 0.6657809\n",
      "Epoch: 0102 cost = 0.624071317\n",
      "Validation Loss: 0.75473297\n",
      "Epoch: 0103 cost = 0.619766065\n",
      "Validation Loss: 0.6603027\n",
      "Epoch: 0104 cost = 0.615481487\n",
      "Validation Loss: 0.73639464\n",
      "Epoch: 0105 cost = 0.611216920\n",
      "Validation Loss: 0.6403961\n",
      "Epoch: 0106 cost = 0.606972013\n",
      "Validation Loss: 0.72643644\n",
      "Epoch: 0107 cost = 0.602746419\n",
      "Validation Loss: 0.6406369\n",
      "Epoch: 0108 cost = 0.598539455\n",
      "Validation Loss: 0.606346\n",
      "Epoch: 0109 cost = 0.594351249\n",
      "Validation Loss: 0.70439976\n",
      "Epoch: 0110 cost = 0.590181547\n",
      "Validation Loss: 0.58803463\n",
      "Epoch: 0111 cost = 0.586030560\n",
      "Validation Loss: 0.6415455\n",
      "Epoch: 0112 cost = 0.581897983\n",
      "Validation Loss: 0.5299697\n",
      "Epoch: 0113 cost = 0.577785194\n",
      "Validation Loss: 0.6519084\n",
      "Epoch: 0114 cost = 0.573691564\n",
      "Validation Loss: 0.5380066\n",
      "Epoch: 0115 cost = 0.569618319\n",
      "Validation Loss: 0.5116057\n",
      "Epoch: 0116 cost = 0.565565475\n",
      "Validation Loss: 0.64361304\n",
      "Epoch: 0117 cost = 0.561534158\n",
      "Validation Loss: 0.52421296\n",
      "Epoch: 0118 cost = 0.557524094\n",
      "Validation Loss: 0.49364036\n",
      "Epoch: 0119 cost = 0.553536092\n",
      "Validation Loss: 0.6096123\n",
      "Epoch: 0120 cost = 0.549570790\n",
      "Validation Loss: 0.5050929\n",
      "Epoch: 0121 cost = 0.545627773\n",
      "Validation Loss: 0.465923\n",
      "Epoch: 0122 cost = 0.541707729\n",
      "Validation Loss: 0.61761206\n",
      "Epoch: 0123 cost = 0.537810385\n",
      "Validation Loss: 0.5211494\n",
      "Epoch: 0124 cost = 0.533935777\n",
      "Validation Loss: 0.46742767\n",
      "Epoch: 0125 cost = 0.530083997\n",
      "Validation Loss: 0.47345188\n",
      "Epoch: 0126 cost = 0.526254799\n",
      "Validation Loss: 0.4656339\n",
      "Epoch: 0127 cost = 0.522449017\n",
      "Validation Loss: 0.58974487\n",
      "Epoch: 0128 cost = 0.518666157\n",
      "Validation Loss: 0.45632285\n",
      "Epoch: 0129 cost = 0.514906687\n",
      "Validation Loss: 0.5695355\n",
      "Epoch: 0130 cost = 0.511170668\n",
      "Validation Loss: 0.520669\n",
      "Epoch: 0131 cost = 0.507458861\n",
      "Validation Loss: 0.48758543\n",
      "Epoch: 0132 cost = 0.503771280\n",
      "Validation Loss: 0.4604497\n",
      "Epoch: 0133 cost = 0.500108480\n",
      "Validation Loss: 0.43540785\n",
      "Epoch: 0134 cost = 0.496470596\n",
      "Validation Loss: 0.5839008\n",
      "Epoch: 0135 cost = 0.492857703\n",
      "Validation Loss: 0.44842505\n",
      "Epoch: 0136 cost = 0.489270398\n",
      "Validation Loss: 0.3972861\n",
      "Epoch: 0137 cost = 0.485708309\n",
      "Validation Loss: 0.49708608\n",
      "Epoch: 0138 cost = 0.482171003\n",
      "Validation Loss: 0.4009406\n",
      "Epoch: 0139 cost = 0.478658642\n",
      "Validation Loss: 0.39840364\n",
      "Epoch: 0140 cost = 0.475170804\n",
      "Validation Loss: 0.40041018\n",
      "Epoch: 0141 cost = 0.471706829\n",
      "Validation Loss: 0.39924976\n",
      "Epoch: 0142 cost = 0.468266457\n",
      "Validation Loss: 0.38936785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0143 cost = 0.464848761\n",
      "Validation Loss: 0.51093715\n",
      "Epoch: 0144 cost = 0.461453706\n",
      "Validation Loss: 0.44614476\n",
      "Epoch: 0145 cost = 0.458080756\n",
      "Validation Loss: 0.43623766\n",
      "Epoch: 0146 cost = 0.454729732\n",
      "Validation Loss: 0.38421693\n",
      "Epoch: 0147 cost = 0.451400578\n",
      "Validation Loss: 0.4702245\n",
      "Epoch: 0148 cost = 0.448093606\n",
      "Validation Loss: 0.32868695\n",
      "Epoch: 0149 cost = 0.444808653\n",
      "Validation Loss: 0.41298303\n",
      "Epoch: 0150 cost = 0.441546547\n",
      "Validation Loss: 0.37387058\n",
      "Epoch: 0151 cost = 0.438307907\n",
      "Validation Loss: 0.33967718\n",
      "Epoch: 0152 cost = 0.435093654\n",
      "Validation Loss: 0.34887877\n",
      "Epoch: 0153 cost = 0.431905202\n",
      "Validation Loss: 0.3597652\n",
      "Epoch: 0154 cost = 0.428742984\n",
      "Validation Loss: 0.3349866\n",
      "Epoch: 0155 cost = 0.425608380\n",
      "Validation Loss: 0.36736074\n",
      "Epoch: 0156 cost = 0.422502420\n",
      "Validation Loss: 0.36983028\n",
      "Epoch: 0157 cost = 0.419425918\n",
      "Validation Loss: 0.32891366\n",
      "Epoch: 0158 cost = 0.416379141\n",
      "Validation Loss: 0.3387396\n",
      "Epoch: 0159 cost = 0.413362818\n",
      "Validation Loss: 0.34980032\n",
      "Epoch: 0160 cost = 0.410376847\n",
      "Validation Loss: 0.38152754\n",
      "Epoch: 0161 cost = 0.407421006\n",
      "Validation Loss: 0.36513153\n",
      "Epoch: 0162 cost = 0.404495516\n",
      "Validation Loss: 0.28822562\n",
      "Epoch: 0163 cost = 0.401599714\n",
      "Validation Loss: 0.42124736\n",
      "Epoch: 0164 cost = 0.398733667\n",
      "Validation Loss: 0.3423719\n",
      "Epoch: 0165 cost = 0.395896665\n",
      "Validation Loss: 0.32594487\n",
      "Epoch: 0166 cost = 0.393088366\n",
      "Validation Loss: 0.33469412\n",
      "Epoch: 0167 cost = 0.390309347\n",
      "Validation Loss: 0.35766912\n",
      "Epoch: 0168 cost = 0.387558358\n",
      "Validation Loss: 0.34406686\n",
      "Epoch: 0169 cost = 0.384836291\n",
      "Validation Loss: 0.3183569\n",
      "Epoch: 0170 cost = 0.382142263\n",
      "Validation Loss: 0.32106146\n",
      "Epoch: 0171 cost = 0.379476522\n",
      "Validation Loss: 0.34834337\n",
      "Epoch: 0172 cost = 0.376838624\n",
      "Validation Loss: 0.3298323\n",
      "Epoch: 0173 cost = 0.374228686\n",
      "Validation Loss: 0.4020602\n",
      "Epoch: 0174 cost = 0.371646111\n",
      "Validation Loss: 0.45202208\n",
      "Epoch: 0175 cost = 0.369091064\n",
      "Validation Loss: 0.42359152\n",
      "Epoch: 0176 cost = 0.366563137\n",
      "Validation Loss: 0.3769696\n",
      "Epoch: 0177 cost = 0.364062096\n",
      "Validation Loss: 0.46462873\n",
      "Epoch: 0178 cost = 0.361587967\n",
      "Validation Loss: 0.45413074\n",
      "Epoch: 0179 cost = 0.359139826\n",
      "Validation Loss: 0.4823051\n",
      "Epoch: 0180 cost = 0.356718025\n",
      "Validation Loss: 0.5603714\n",
      "Epoch: 0181 cost = 0.354322063\n",
      "Validation Loss: 0.65363073\n",
      "Epoch: 0182 cost = 0.351951944\n",
      "Validation Loss: 0.64274776\n",
      "Epoch: 0183 cost = 0.349606914\n",
      "Validation Loss: 0.5706396\n",
      "Epoch: 0184 cost = 0.347287204\n",
      "Validation Loss: 0.44399008\n",
      "Epoch: 0185 cost = 0.344992365\n",
      "Validation Loss: 0.27912647\n",
      "Epoch: 0186 cost = 0.342722003\n",
      "Validation Loss: 0.3898319\n",
      "Epoch: 0187 cost = 0.340476138\n",
      "Validation Loss: 0.42275506\n",
      "Epoch: 0188 cost = 0.338254098\n",
      "Validation Loss: 0.46538633\n",
      "Epoch: 0189 cost = 0.336056109\n",
      "Validation Loss: 0.44865003\n",
      "Epoch: 0190 cost = 0.333881195\n",
      "Validation Loss: 0.41675872\n",
      "Epoch: 0191 cost = 0.331729638\n",
      "Validation Loss: 0.3684013\n",
      "Epoch: 0192 cost = 0.329600743\n",
      "Validation Loss: 0.39482796\n",
      "Epoch: 0193 cost = 0.327494353\n",
      "Validation Loss: 0.3582367\n",
      "Epoch: 0194 cost = 0.325409736\n",
      "Validation Loss: 0.30949277\n",
      "Epoch: 0195 cost = 0.323347637\n",
      "Validation Loss: 0.3572159\n",
      "Epoch: 0196 cost = 0.321306493\n",
      "Validation Loss: 0.44850045\n",
      "Epoch: 0197 cost = 0.319286300\n",
      "Validation Loss: 0.4973302\n",
      "Epoch: 0198 cost = 0.317287049\n",
      "Validation Loss: 0.47242424\n",
      "Epoch: 0199 cost = 0.315308120\n",
      "Validation Loss: 0.3870107\n",
      "Epoch: 0200 cost = 0.313349175\n",
      "Validation Loss: 0.34011522\n",
      "Epoch: 0201 cost = 0.311410342\n",
      "Validation Loss: 0.33758286\n",
      "Epoch: 0202 cost = 0.309490268\n",
      "Validation Loss: 0.30187312\n",
      "Epoch: 0203 cost = 0.307589501\n",
      "Validation Loss: 0.3028374\n",
      "Epoch: 0204 cost = 0.305707561\n",
      "Validation Loss: 0.32100868\n",
      "Epoch: 0205 cost = 0.303843835\n",
      "Validation Loss: 0.39106593\n",
      "Epoch: 0206 cost = 0.301998598\n",
      "Validation Loss: 0.45961243\n",
      "Epoch: 0207 cost = 0.300170877\n",
      "Validation Loss: 0.4249798\n",
      "Epoch: 0208 cost = 0.298360888\n",
      "Validation Loss: 0.43520832\n",
      "Epoch: 0209 cost = 0.296567691\n",
      "Validation Loss: 0.4300609\n",
      "Epoch: 0210 cost = 0.294791809\n",
      "Validation Loss: 0.36462745\n",
      "Epoch: 0211 cost = 0.293032425\n",
      "Validation Loss: 0.30033404\n",
      "Epoch: 0212 cost = 0.291289513\n",
      "Validation Loss: 0.3224162\n",
      "Epoch: 0213 cost = 0.289562643\n",
      "Validation Loss: 0.29521963\n",
      "Epoch: 0214 cost = 0.287851700\n",
      "Validation Loss: 0.26206657\n",
      "Epoch: 0215 cost = 0.286156267\n",
      "Validation Loss: 0.3825489\n",
      "Epoch: 0216 cost = 0.284476059\n",
      "Validation Loss: 0.4021185\n",
      "Epoch: 0217 cost = 0.282811127\n",
      "Validation Loss: 0.398836\n",
      "Epoch: 0218 cost = 0.281160772\n",
      "Validation Loss: 0.38658705\n",
      "Epoch: 0219 cost = 0.279524973\n",
      "Validation Loss: 0.42201063\n",
      "Epoch: 0220 cost = 0.277903595\n",
      "Validation Loss: 0.40111405\n",
      "Epoch: 0221 cost = 0.276296415\n",
      "Validation Loss: 0.35103628\n",
      "Epoch: 0222 cost = 0.274703119\n",
      "Validation Loss: 0.33858374\n",
      "Epoch: 0223 cost = 0.273123362\n",
      "Validation Loss: 0.30543622\n",
      "Epoch: 0224 cost = 0.271556914\n",
      "Validation Loss: 0.26996684\n",
      "Epoch: 0225 cost = 0.270004111\n",
      "Validation Loss: 0.27166772\n",
      "Epoch: 0226 cost = 0.268464037\n",
      "Validation Loss: 0.3409808\n",
      "Epoch: 0227 cost = 0.266936681\n",
      "Validation Loss: 0.29754055\n",
      "Epoch: 0228 cost = 0.265421982\n",
      "Validation Loss: 0.3201634\n",
      "Epoch: 0229 cost = 0.263919773\n",
      "Validation Loss: 0.3723675\n",
      "Epoch: 0230 cost = 0.262429514\n",
      "Validation Loss: 0.36460957\n",
      "Epoch: 0231 cost = 0.260951600\n",
      "Validation Loss: 0.31993705\n",
      "Epoch: 0232 cost = 0.259485070\n",
      "Validation Loss: 0.27176946\n",
      "Epoch: 0233 cost = 0.258030530\n",
      "Validation Loss: 0.2361763\n",
      "Epoch: 0234 cost = 0.256587284\n",
      "Validation Loss: 0.27736738\n",
      "Epoch: 0235 cost = 0.255155319\n",
      "Validation Loss: 0.2516862\n",
      "Epoch: 0236 cost = 0.253734646\n",
      "Validation Loss: 0.3427514\n",
      "Epoch: 0237 cost = 0.252324611\n",
      "Validation Loss: 0.38504216\n",
      "Epoch: 0238 cost = 0.250925509\n",
      "Validation Loss: 0.39316761\n",
      "Epoch: 0239 cost = 0.249536753\n",
      "Validation Loss: 0.42873162\n",
      "Epoch: 0240 cost = 0.248158847\n",
      "Validation Loss: 0.35209763\n",
      "Epoch: 0241 cost = 0.246790877\n",
      "Validation Loss: 0.2842167\n",
      "Epoch: 0242 cost = 0.245433328\n",
      "Validation Loss: 0.24371675\n",
      "Epoch: 0243 cost = 0.244085478\n",
      "Validation Loss: 0.25299546\n",
      "Epoch: 0244 cost = 0.242747696\n",
      "Validation Loss: 0.29879287\n",
      "Epoch: 0245 cost = 0.241419320\n",
      "Validation Loss: 0.32758892\n",
      "Epoch: 0246 cost = 0.240100575\n",
      "Validation Loss: 0.29422426\n",
      "Epoch: 0247 cost = 0.238791319\n",
      "Validation Loss: 0.27965474\n",
      "Epoch: 0248 cost = 0.237490971\n",
      "Validation Loss: 0.30982885\n",
      "Epoch: 0249 cost = 0.236200079\n",
      "Validation Loss: 0.35437912\n",
      "Epoch: 0250 cost = 0.234918011\n",
      "Validation Loss: 0.30757874\n",
      "Epoch: 0251 cost = 0.233644511\n",
      "Validation Loss: 0.26380047\n",
      "Epoch: 0252 cost = 0.232380109\n",
      "Validation Loss: 0.2691199\n",
      "Epoch: 0253 cost = 0.231123984\n",
      "Validation Loss: 0.2633435\n",
      "Epoch: 0254 cost = 0.229876129\n",
      "Validation Loss: 0.27533963\n",
      "Epoch: 0255 cost = 0.228636608\n",
      "Validation Loss: 0.25840175\n",
      "Epoch: 0256 cost = 0.227405199\n",
      "Validation Loss: 0.20107728\n",
      "Epoch: 0257 cost = 0.226181801\n",
      "Validation Loss: 0.260639\n",
      "Epoch: 0258 cost = 0.224966173\n",
      "Validation Loss: 0.22907865\n",
      "Epoch: 0259 cost = 0.223758125\n",
      "Validation Loss: 0.2942295\n",
      "Epoch: 0260 cost = 0.222557515\n",
      "Validation Loss: 0.28946003\n",
      "Epoch: 0261 cost = 0.221364360\n",
      "Validation Loss: 0.32317796\n",
      "Epoch: 0262 cost = 0.220178393\n",
      "Validation Loss: 0.34708294\n",
      "Epoch: 0263 cost = 0.218999316\n",
      "Validation Loss: 0.26935145\n",
      "Epoch: 0264 cost = 0.217827254\n",
      "Validation Loss: 0.30158338\n",
      "Epoch: 0265 cost = 0.216661738\n",
      "Validation Loss: 0.2490012\n",
      "Epoch: 0266 cost = 0.215503007\n",
      "Validation Loss: 0.19580315\n",
      "Epoch: 0267 cost = 0.214350255\n",
      "Validation Loss: 0.3290172\n",
      "Epoch: 0268 cost = 0.213204084\n",
      "Validation Loss: 0.32914218\n",
      "Epoch: 0269 cost = 0.212063855\n",
      "Validation Loss: 0.31640363\n",
      "Epoch: 0270 cost = 0.210929194\n",
      "Validation Loss: 0.22823107\n",
      "Epoch: 0271 cost = 0.209800343\n",
      "Validation Loss: 0.19096226\n",
      "Epoch: 0272 cost = 0.208676677\n",
      "Validation Loss: 0.29590863\n",
      "Epoch: 0273 cost = 0.207558202\n",
      "Validation Loss: 0.304818\n",
      "Epoch: 0274 cost = 0.206445015\n",
      "Validation Loss: 0.27872607\n",
      "Epoch: 0275 cost = 0.205336422\n",
      "Validation Loss: 0.23931588\n",
      "Epoch: 0276 cost = 0.204232531\n",
      "Validation Loss: 0.2182958\n",
      "Epoch: 0277 cost = 0.203132812\n",
      "Validation Loss: 0.24449046\n",
      "Epoch: 0278 cost = 0.202037530\n",
      "Validation Loss: 0.24153124\n",
      "Epoch: 0279 cost = 0.200945920\n",
      "Validation Loss: 0.18758097\n",
      "Epoch: 0280 cost = 0.199858091\n",
      "Validation Loss: 0.23754814\n",
      "Epoch: 0281 cost = 0.198774106\n",
      "Validation Loss: 0.26226294\n",
      "Epoch: 0282 cost = 0.197693118\n",
      "Validation Loss: 0.37773\n",
      "Epoch: 0283 cost = 0.196615372\n",
      "Validation Loss: 0.40505937\n",
      "Epoch: 0284 cost = 0.195540394\n",
      "Validation Loss: 0.366595\n",
      "Epoch: 0285 cost = 0.194468649\n",
      "Validation Loss: 0.3145555\n",
      "Epoch: 0286 cost = 0.193399163\n",
      "Validation Loss: 0.20124486\n",
      "Epoch: 0287 cost = 0.192332598\n",
      "Validation Loss: 0.20937084\n",
      "Epoch: 0288 cost = 0.191268278\n",
      "Validation Loss: 0.21435364\n",
      "Epoch: 0289 cost = 0.190206777\n",
      "Validation Loss: 0.29888457\n",
      "Epoch: 0290 cost = 0.189147502\n",
      "Validation Loss: 0.33731747\n",
      "Epoch: 0291 cost = 0.188091033\n",
      "Validation Loss: 0.38117713\n",
      "Epoch: 0292 cost = 0.187037289\n",
      "Validation Loss: 0.34450972\n",
      "Epoch: 0293 cost = 0.185986427\n",
      "Validation Loss: 0.25430444\n",
      "Epoch: 0294 cost = 0.184938784\n",
      "Validation Loss: 0.2511555\n",
      "Epoch: 0295 cost = 0.183894515\n",
      "Validation Loss: 0.3173733\n",
      "Epoch: 0296 cost = 0.182854124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3701964\n",
      "Epoch: 0297 cost = 0.181817936\n",
      "Validation Loss: 0.42631727\n",
      "Epoch: 0298 cost = 0.180786139\n",
      "Validation Loss: 0.4135653\n",
      "Epoch: 0299 cost = 0.179759266\n",
      "Validation Loss: 0.31065807\n",
      "Epoch: 0300 cost = 0.178737713\n",
      "Validation Loss: 0.26357776\n",
      "Epoch: 0301 cost = 0.177721792\n",
      "Validation Loss: 0.29003426\n",
      "Epoch: 0302 cost = 0.176711532\n",
      "Validation Loss: 0.29055715\n",
      "Epoch: 0303 cost = 0.175707532\n",
      "Validation Loss: 0.18010844\n",
      "Epoch: 0304 cost = 0.174709908\n",
      "Validation Loss: 0.28922844\n",
      "Epoch: 0305 cost = 0.173718793\n",
      "Validation Loss: 0.2032914\n",
      "Epoch: 0306 cost = 0.172734916\n",
      "Validation Loss: 0.26143888\n",
      "Epoch: 0307 cost = 0.171757524\n",
      "Validation Loss: 0.23692271\n",
      "Epoch: 0308 cost = 0.170787394\n",
      "Validation Loss: 0.23941104\n",
      "Epoch: 0309 cost = 0.169824558\n",
      "Validation Loss: 0.33599737\n",
      "Epoch: 0310 cost = 0.168869244\n",
      "Validation Loss: 0.28907207\n",
      "Epoch: 0311 cost = 0.167921432\n",
      "Validation Loss: 0.29743528\n",
      "Epoch: 0312 cost = 0.166981188\n",
      "Validation Loss: 0.27973205\n",
      "Epoch: 0313 cost = 0.166048874\n",
      "Validation Loss: 0.25656185\n",
      "Epoch: 0314 cost = 0.165124346\n",
      "Validation Loss: 0.25667706\n",
      "Epoch: 0315 cost = 0.164207693\n",
      "Validation Loss: 0.22868638\n",
      "Epoch: 0316 cost = 0.163299324\n",
      "Validation Loss: 0.1866188\n",
      "Epoch: 0317 cost = 0.162399086\n",
      "Validation Loss: 0.20232993\n",
      "Epoch: 0318 cost = 0.161507300\n",
      "Validation Loss: 0.18004785\n",
      "Epoch: 0319 cost = 0.160623712\n",
      "Validation Loss: 0.19267397\n",
      "Epoch: 0320 cost = 0.159748865\n",
      "Validation Loss: 0.18526132\n",
      "Epoch: 0321 cost = 0.158882437\n",
      "Validation Loss: 0.17528814\n",
      "Epoch: 0322 cost = 0.158024722\n",
      "Validation Loss: 0.1777102\n",
      "Epoch: 0323 cost = 0.157175786\n",
      "Validation Loss: 0.14760816\n",
      "Epoch: 0324 cost = 0.156335554\n",
      "Validation Loss: 0.18433413\n",
      "Epoch: 0325 cost = 0.155504210\n",
      "Validation Loss: 0.20427987\n",
      "Epoch: 0326 cost = 0.154681734\n",
      "Validation Loss: 0.2431364\n",
      "Epoch: 0327 cost = 0.153868037\n",
      "Validation Loss: 0.27155212\n",
      "Epoch: 0328 cost = 0.153063110\n",
      "Validation Loss: 0.2911731\n",
      "Epoch: 0329 cost = 0.152266915\n",
      "Validation Loss: 0.16950795\n",
      "Epoch: 0330 cost = 0.151479349\n",
      "Validation Loss: 0.12809104\n",
      "Epoch: 0331 cost = 0.150700733\n",
      "Validation Loss: 0.24970673\n",
      "Epoch: 0332 cost = 0.149930765\n",
      "Validation Loss: 0.16173245\n",
      "Epoch: 0333 cost = 0.149169015\n",
      "Validation Loss: 0.17052558\n",
      "Epoch: 0334 cost = 0.148416055\n",
      "Validation Loss: 0.19228214\n",
      "Epoch: 0335 cost = 0.147671672\n",
      "Validation Loss: 0.25066927\n",
      "Epoch: 0336 cost = 0.146935414\n",
      "Validation Loss: 0.23839502\n",
      "Epoch: 0337 cost = 0.146207533\n",
      "Validation Loss: 0.25870308\n",
      "Epoch: 0338 cost = 0.145487930\n",
      "Validation Loss: 0.1997938\n",
      "Epoch: 0339 cost = 0.144776825\n",
      "Validation Loss: 0.14216678\n",
      "Epoch: 0340 cost = 0.144073567\n",
      "Validation Loss: 0.11706799\n",
      "Epoch: 0341 cost = 0.143378611\n",
      "Validation Loss: 0.17700544\n",
      "Epoch: 0342 cost = 0.142691702\n",
      "Validation Loss: 0.13732122\n",
      "Epoch: 0343 cost = 0.142012525\n",
      "Validation Loss: 0.14465685\n",
      "Epoch: 0344 cost = 0.141341514\n",
      "Validation Loss: 0.14876525\n",
      "Epoch: 0345 cost = 0.140678072\n",
      "Validation Loss: 0.1511205\n",
      "Epoch: 0346 cost = 0.140022618\n",
      "Validation Loss: 0.1272624\n",
      "Epoch: 0347 cost = 0.139374505\n",
      "Validation Loss: 0.13215171\n",
      "Epoch: 0348 cost = 0.138733979\n",
      "Validation Loss: 0.14054829\n",
      "Epoch: 0349 cost = 0.138100627\n",
      "Validation Loss: 0.12949218\n",
      "Epoch: 0350 cost = 0.137474654\n",
      "Validation Loss: 0.13193673\n",
      "Epoch: 0351 cost = 0.136855521\n",
      "Validation Loss: 0.15152976\n",
      "Epoch: 0352 cost = 0.136243573\n",
      "Validation Loss: 0.12703359\n",
      "Epoch: 0353 cost = 0.135637936\n",
      "Validation Loss: 0.1384302\n",
      "Epoch: 0354 cost = 0.135039058\n",
      "Validation Loss: 0.14590333\n",
      "Epoch: 0355 cost = 0.134446394\n",
      "Validation Loss: 0.11133406\n",
      "Epoch: 0356 cost = 0.133859922\n",
      "Validation Loss: 0.17554913\n",
      "Epoch: 0357 cost = 0.133279284\n",
      "Validation Loss: 0.1256606\n",
      "Epoch: 0358 cost = 0.132704571\n",
      "Validation Loss: 0.16973875\n",
      "Epoch: 0359 cost = 0.132135018\n",
      "Validation Loss: 0.18429452\n",
      "Epoch: 0360 cost = 0.131570702\n",
      "Validation Loss: 0.15739715\n",
      "Epoch: 0361 cost = 0.131012121\n",
      "Validation Loss: 0.12522705\n",
      "Epoch: 0362 cost = 0.130458042\n",
      "Validation Loss: 0.13131614\n",
      "Epoch: 0363 cost = 0.129909255\n",
      "Validation Loss: 0.13251743\n",
      "Epoch: 0364 cost = 0.129364541\n",
      "Validation Loss: 0.14714909\n",
      "Epoch: 0365 cost = 0.128824440\n",
      "Validation Loss: 0.1309002\n",
      "Epoch: 0366 cost = 0.128288692\n",
      "Validation Loss: 0.15035564\n",
      "Epoch: 0367 cost = 0.127757150\n",
      "Validation Loss: 0.13531294\n",
      "Epoch: 0368 cost = 0.127229530\n",
      "Validation Loss: 0.13012838\n",
      "Epoch: 0369 cost = 0.126705681\n",
      "Validation Loss: 0.22247279\n",
      "Epoch: 0370 cost = 0.126185652\n",
      "Validation Loss: 0.26460838\n",
      "Epoch: 0371 cost = 0.125669276\n",
      "Validation Loss: 0.1878932\n",
      "Epoch: 0372 cost = 0.125156239\n",
      "Validation Loss: 0.16048616\n",
      "Epoch: 0373 cost = 0.124646421\n",
      "Validation Loss: 0.15838894\n",
      "Epoch: 0374 cost = 0.124139689\n",
      "Validation Loss: 0.16614202\n",
      "Epoch: 0375 cost = 0.123635956\n",
      "Validation Loss: 0.18536915\n",
      "Epoch: 0376 cost = 0.123135126\n",
      "Validation Loss: 0.16635825\n",
      "Epoch: 0377 cost = 0.122637096\n",
      "Validation Loss: 0.17275201\n",
      "Epoch: 0378 cost = 0.122141245\n",
      "Validation Loss: 0.22778851\n",
      "Epoch: 0379 cost = 0.121647699\n",
      "Validation Loss: 0.14460103\n",
      "Epoch: 0380 cost = 0.121156504\n",
      "Validation Loss: 0.11986977\n",
      "Epoch: 0381 cost = 0.120667439\n",
      "Validation Loss: 0.15858382\n",
      "Epoch: 0382 cost = 0.120180088\n",
      "Validation Loss: 0.15829793\n",
      "Epoch: 0383 cost = 0.119694178\n",
      "Validation Loss: 0.10844207\n",
      "Epoch: 0384 cost = 0.119209900\n",
      "Validation Loss: 0.18850164\n",
      "Epoch: 0385 cost = 0.118726986\n",
      "Validation Loss: 0.12615703\n",
      "Epoch: 0386 cost = 0.118245109\n",
      "Validation Loss: 0.12581025\n",
      "Epoch: 0387 cost = 0.117764387\n",
      "Validation Loss: 0.10936354\n",
      "Epoch: 0388 cost = 0.117283887\n",
      "Validation Loss: 0.10936445\n",
      "Epoch: 0389 cost = 0.116804550\n",
      "Validation Loss: 0.096428424\n",
      "Epoch: 0390 cost = 0.116325054\n",
      "Validation Loss: 0.1687633\n",
      "Epoch: 0391 cost = 0.115846312\n",
      "Validation Loss: 0.10804292\n",
      "Epoch: 0392 cost = 0.115367651\n",
      "Validation Loss: 0.099397175\n",
      "Epoch: 0393 cost = 0.114888735\n",
      "Validation Loss: 0.12062061\n",
      "Epoch: 0394 cost = 0.114409602\n",
      "Validation Loss: 0.11618548\n",
      "Epoch: 0395 cost = 0.113930218\n",
      "Validation Loss: 0.13333863\n",
      "Epoch: 0396 cost = 0.113450691\n",
      "Validation Loss: 0.12759243\n",
      "Epoch: 0397 cost = 0.112970532\n",
      "Validation Loss: 0.1261371\n",
      "Epoch: 0398 cost = 0.112489732\n",
      "Validation Loss: 0.1268891\n",
      "Epoch: 0399 cost = 0.112008506\n",
      "Validation Loss: 0.13995247\n",
      "Epoch: 0400 cost = 0.111526603\n",
      "Validation Loss: 0.15944123\n",
      "Epoch: 0401 cost = 0.111044138\n",
      "Validation Loss: 0.10644017\n",
      "Epoch: 0402 cost = 0.110561264\n",
      "Validation Loss: 0.110156305\n",
      "Epoch: 0403 cost = 0.110077431\n",
      "Validation Loss: 0.106803454\n",
      "Epoch: 0404 cost = 0.109593295\n",
      "Validation Loss: 0.1125293\n",
      "Epoch: 0405 cost = 0.109108508\n",
      "Validation Loss: 0.11310498\n",
      "Epoch: 0406 cost = 0.108623356\n",
      "Validation Loss: 0.11134329\n",
      "Epoch: 0407 cost = 0.108137607\n",
      "Validation Loss: 0.112131774\n",
      "Epoch: 0408 cost = 0.107651553\n",
      "Validation Loss: 0.11267723\n",
      "Epoch: 0409 cost = 0.107164920\n",
      "Validation Loss: 0.09332461\n",
      "Epoch: 0410 cost = 0.106678079\n",
      "Validation Loss: 0.15454055\n",
      "Epoch: 0411 cost = 0.106190491\n",
      "Validation Loss: 0.10368113\n",
      "Epoch: 0412 cost = 0.105702229\n",
      "Validation Loss: 0.095855184\n",
      "Epoch: 0413 cost = 0.105212816\n",
      "Validation Loss: 0.08587601\n",
      "Epoch: 0414 cost = 0.104721661\n",
      "Validation Loss: 0.14333762\n",
      "Epoch: 0415 cost = 0.104228283\n",
      "Validation Loss: 0.112896055\n",
      "Epoch: 0416 cost = 0.103731711\n",
      "Validation Loss: 0.09653843\n",
      "Epoch: 0417 cost = 0.103230655\n",
      "Validation Loss: 0.10394527\n",
      "Epoch: 0418 cost = 0.102724241\n",
      "Validation Loss: 0.09831286\n",
      "Epoch: 0419 cost = 0.102211255\n",
      "Validation Loss: 0.111815415\n",
      "Epoch: 0420 cost = 0.101690660\n",
      "Validation Loss: 0.11379987\n",
      "Epoch: 0421 cost = 0.101162633\n",
      "Validation Loss: 0.12365305\n",
      "Epoch: 0422 cost = 0.100628042\n",
      "Validation Loss: 0.15256217\n",
      "Epoch: 0423 cost = 0.100088256\n",
      "Validation Loss: 0.16203077\n",
      "Epoch: 0424 cost = 0.099545431\n",
      "Validation Loss: 0.13180603\n",
      "Epoch: 0425 cost = 0.099002720\n",
      "Validation Loss: 0.13322057\n",
      "Epoch: 0426 cost = 0.098461947\n",
      "Validation Loss: 0.13403153\n",
      "Epoch: 0427 cost = 0.097926820\n",
      "Validation Loss: 0.10685829\n",
      "Epoch: 0428 cost = 0.097399966\n",
      "Validation Loss: 0.12500277\n",
      "Epoch: 0429 cost = 0.096884821\n",
      "Validation Loss: 0.1288919\n",
      "Epoch: 0430 cost = 0.096384794\n",
      "Validation Loss: 0.10285066\n",
      "Epoch: 0431 cost = 0.095902794\n",
      "Validation Loss: 0.09550409\n",
      "Epoch: 0432 cost = 0.095442199\n",
      "Validation Loss: 0.08785813\n",
      "Epoch: 0433 cost = 0.095006438\n",
      "Validation Loss: 0.09230103\n",
      "Epoch: 0434 cost = 0.094598395\n",
      "Validation Loss: 0.10453077\n",
      "Epoch: 0435 cost = 0.094220310\n",
      "Validation Loss: 0.1403691\n",
      "Epoch: 0436 cost = 0.093873261\n",
      "Validation Loss: 0.11661547\n",
      "Epoch: 0437 cost = 0.093553457\n",
      "Validation Loss: 0.099377386\n",
      "Epoch: 0438 cost = 0.093249410\n",
      "Validation Loss: 0.10132999\n",
      "Epoch: 0439 cost = 0.092943044\n",
      "Validation Loss: 0.123234265\n",
      "Epoch: 0440 cost = 0.092616739\n",
      "Validation Loss: 0.13201725\n",
      "Epoch: 0441 cost = 0.092258682\n",
      "Validation Loss: 0.19227073\n",
      "Epoch: 0442 cost = 0.091868966\n",
      "Validation Loss: 0.22901745\n",
      "Epoch: 0443 cost = 0.091455237\n",
      "Validation Loss: 0.29835078\n",
      "Epoch: 0444 cost = 0.091026623\n",
      "Validation Loss: 0.2904567\n",
      "Epoch: 0445 cost = 0.090590985\n",
      "Validation Loss: 0.19695362\n",
      "Epoch: 0446 cost = 0.090153427\n",
      "Validation Loss: 0.1734493\n",
      "Epoch: 0447 cost = 0.089717860\n",
      "Validation Loss: 0.16777605\n",
      "Epoch: 0448 cost = 0.089288191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.16474444\n",
      "Epoch: 0449 cost = 0.088869389\n",
      "Validation Loss: 0.11458719\n",
      "Epoch: 0450 cost = 0.088464921\n",
      "Validation Loss: 0.11288174\n",
      "Epoch: 0451 cost = 0.088075907\n",
      "Validation Loss: 0.115612976\n",
      "Epoch: 0452 cost = 0.087701637\n",
      "Validation Loss: 0.117705904\n",
      "Epoch: 0453 cost = 0.087339665\n",
      "Validation Loss: 0.09359282\n",
      "Epoch: 0454 cost = 0.086986216\n",
      "Validation Loss: 0.110585526\n",
      "Epoch: 0455 cost = 0.086638001\n",
      "Validation Loss: 0.11428457\n",
      "Epoch: 0456 cost = 0.086292568\n",
      "Validation Loss: 0.12347729\n",
      "Epoch: 0457 cost = 0.085948820\n",
      "Validation Loss: 0.1126035\n",
      "Epoch: 0458 cost = 0.085606298\n",
      "Validation Loss: 0.07634462\n",
      "Epoch: 0459 cost = 0.085264120\n",
      "Validation Loss: 0.13648961\n",
      "Epoch: 0460 cost = 0.084920957\n",
      "Validation Loss: 0.09145202\n",
      "Epoch: 0461 cost = 0.084575409\n",
      "Validation Loss: 0.081381105\n",
      "Epoch: 0462 cost = 0.084225550\n",
      "Validation Loss: 0.07485068\n",
      "Epoch: 0463 cost = 0.083871612\n",
      "Validation Loss: 0.1330285\n",
      "Epoch: 0464 cost = 0.083515796\n",
      "Validation Loss: 0.0807082\n",
      "Epoch: 0465 cost = 0.083161582\n",
      "Validation Loss: 0.09573051\n",
      "Epoch: 0466 cost = 0.082813627\n",
      "Validation Loss: 0.08636923\n",
      "Epoch: 0467 cost = 0.082475156\n",
      "Validation Loss: 0.076302305\n",
      "Epoch: 0468 cost = 0.082147166\n",
      "Validation Loss: 0.076188296\n",
      "Epoch: 0469 cost = 0.081829521\n",
      "Validation Loss: 0.1036444\n",
      "Epoch: 0470 cost = 0.081519197\n",
      "Validation Loss: 0.16128904\n",
      "Epoch: 0471 cost = 0.081213938\n",
      "Validation Loss: 0.23898263\n",
      "Epoch: 0472 cost = 0.080910759\n",
      "Validation Loss: 0.26324993\n",
      "Epoch: 0473 cost = 0.080606808\n",
      "Validation Loss: 0.20715784\n",
      "Epoch: 0474 cost = 0.080300807\n",
      "Validation Loss: 0.114687055\n",
      "Epoch: 0475 cost = 0.079992379\n",
      "Validation Loss: 0.10947875\n",
      "Epoch: 0476 cost = 0.079682900\n",
      "Validation Loss: 0.11292061\n",
      "Epoch: 0477 cost = 0.079374232\n",
      "Validation Loss: 0.11180489\n",
      "Epoch: 0478 cost = 0.079068785\n",
      "Validation Loss: 0.14067562\n",
      "Epoch: 0479 cost = 0.078767491\n",
      "Validation Loss: 0.08767535\n",
      "Epoch: 0480 cost = 0.078471544\n",
      "Validation Loss: 0.095894344\n",
      "Epoch: 0481 cost = 0.078179948\n",
      "Validation Loss: 0.091158085\n",
      "Epoch: 0482 cost = 0.077892151\n",
      "Validation Loss: 0.10902667\n",
      "Epoch: 0483 cost = 0.077606604\n",
      "Validation Loss: 0.08439918\n",
      "Epoch: 0484 cost = 0.077322432\n",
      "Validation Loss: 0.064738415\n",
      "Epoch: 0485 cost = 0.077038967\n",
      "Validation Loss: 0.121235326\n",
      "Epoch: 0486 cost = 0.076755632\n",
      "Validation Loss: 0.08180004\n",
      "Epoch: 0487 cost = 0.076473085\n",
      "Validation Loss: 0.119068265\n",
      "Epoch: 0488 cost = 0.076191888\n",
      "Validation Loss: 0.10323454\n",
      "Epoch: 0489 cost = 0.075912597\n",
      "Validation Loss: 0.10755298\n",
      "Epoch: 0490 cost = 0.075636059\n",
      "Validation Loss: 0.08856883\n",
      "Epoch: 0491 cost = 0.075362656\n",
      "Validation Loss: 0.0793315\n",
      "Epoch: 0492 cost = 0.075091723\n",
      "Validation Loss: 0.11070163\n",
      "Epoch: 0493 cost = 0.074823440\n",
      "Validation Loss: 0.11653386\n",
      "Epoch: 0494 cost = 0.074556727\n",
      "Validation Loss: 0.07907606\n",
      "Epoch: 0495 cost = 0.074291616\n",
      "Validation Loss: 0.06458866\n",
      "Epoch: 0496 cost = 0.074027519\n",
      "Validation Loss: 0.13697343\n",
      "Epoch: 0497 cost = 0.073765075\n",
      "Validation Loss: 0.10002134\n",
      "Epoch: 0498 cost = 0.073503894\n",
      "Validation Loss: 0.08901367\n",
      "Epoch: 0499 cost = 0.073244771\n",
      "Validation Loss: 0.09344225\n",
      "Epoch: 0500 cost = 0.072987062\n",
      "Validation Loss: 0.08018364\n",
      "Epoch: 0501 cost = 0.072731283\n",
      "Validation Loss: 0.0714962\n",
      "Epoch: 0502 cost = 0.072477893\n",
      "Validation Loss: 0.08153397\n",
      "Epoch: 0503 cost = 0.072226443\n",
      "Validation Loss: 0.0924793\n",
      "Epoch: 0504 cost = 0.071976508\n",
      "Validation Loss: 0.10945086\n",
      "Epoch: 0505 cost = 0.071728521\n",
      "Validation Loss: 0.13060033\n",
      "Epoch: 0506 cost = 0.071482028\n",
      "Validation Loss: 0.1501314\n",
      "Epoch: 0507 cost = 0.071237070\n",
      "Validation Loss: 0.16143008\n",
      "Epoch: 0508 cost = 0.070993756\n",
      "Validation Loss: 0.08640384\n",
      "Epoch: 0509 cost = 0.070751803\n",
      "Validation Loss: 0.07138787\n",
      "Epoch: 0510 cost = 0.070511486\n",
      "Validation Loss: 0.07506046\n",
      "Epoch: 0511 cost = 0.070272662\n",
      "Validation Loss: 0.064750366\n",
      "Epoch: 0512 cost = 0.070035325\n",
      "Validation Loss: 0.0803453\n",
      "Epoch: 0513 cost = 0.069799615\n",
      "Validation Loss: 0.096736684\n",
      "Epoch: 0514 cost = 0.069565514\n",
      "Validation Loss: 0.06602117\n",
      "Epoch: 0515 cost = 0.069332839\n",
      "Validation Loss: 0.062907666\n",
      "Epoch: 0516 cost = 0.069101357\n",
      "Validation Loss: 0.13851625\n",
      "Epoch: 0517 cost = 0.068871286\n",
      "Validation Loss: 0.100803964\n",
      "Epoch: 0518 cost = 0.068642564\n",
      "Validation Loss: 0.081297025\n",
      "Epoch: 0519 cost = 0.068414735\n",
      "Validation Loss: 0.087529704\n",
      "Epoch: 0520 cost = 0.068187782\n",
      "Validation Loss: 0.17885326\n",
      "Epoch: 0521 cost = 0.067961593\n",
      "Validation Loss: 0.22845818\n",
      "Epoch: 0522 cost = 0.067736421\n",
      "Validation Loss: 0.20751612\n",
      "Epoch: 0523 cost = 0.067511877\n",
      "Validation Loss: 0.15050274\n",
      "Epoch: 0524 cost = 0.067288086\n",
      "Validation Loss: 0.12277705\n",
      "Epoch: 0525 cost = 0.067064905\n",
      "Validation Loss: 0.09654574\n",
      "Epoch: 0526 cost = 0.066842007\n",
      "Validation Loss: 0.08346316\n",
      "Epoch: 0527 cost = 0.066619248\n",
      "Validation Loss: 0.12877263\n",
      "Epoch: 0528 cost = 0.066396484\n",
      "Validation Loss: 0.14147937\n",
      "Epoch: 0529 cost = 0.066173311\n",
      "Validation Loss: 0.15767968\n",
      "Epoch: 0530 cost = 0.065949576\n",
      "Validation Loss: 0.16745923\n",
      "Epoch: 0531 cost = 0.065724790\n",
      "Validation Loss: 0.22388792\n",
      "Epoch: 0532 cost = 0.065498442\n",
      "Validation Loss: 0.24018456\n",
      "Epoch: 0533 cost = 0.065270408\n",
      "Validation Loss: 0.23063152\n",
      "Epoch: 0534 cost = 0.065039614\n",
      "Validation Loss: 0.14283703\n",
      "Epoch: 0535 cost = 0.064805901\n",
      "Validation Loss: 0.10859461\n",
      "Epoch: 0536 cost = 0.064568401\n",
      "Validation Loss: 0.11363045\n",
      "Epoch: 0537 cost = 0.064325706\n",
      "Validation Loss: 0.11447947\n",
      "Epoch: 0538 cost = 0.064077089\n",
      "Validation Loss: 0.08557283\n",
      "Epoch: 0539 cost = 0.063820482\n",
      "Validation Loss: 0.072888024\n",
      "Epoch: 0540 cost = 0.063554248\n",
      "Validation Loss: 0.06883474\n",
      "Epoch: 0541 cost = 0.063276707\n",
      "Validation Loss: 0.0700726\n",
      "Epoch: 0542 cost = 0.062986057\n",
      "Validation Loss: 0.07672598\n",
      "Epoch: 0543 cost = 0.062681008\n",
      "Validation Loss: 0.15001327\n",
      "Epoch: 0544 cost = 0.062361157\n",
      "Validation Loss: 0.29823893\n",
      "Epoch: 0545 cost = 0.062028482\n",
      "Validation Loss: 0.24413767\n",
      "Epoch: 0546 cost = 0.061685428\n",
      "Validation Loss: 0.2090742\n",
      "Epoch: 0547 cost = 0.061335819\n",
      "Validation Loss: 0.16628353\n",
      "Epoch: 0548 cost = 0.060983099\n",
      "Validation Loss: 0.20070034\n",
      "Epoch: 0549 cost = 0.060630403\n",
      "Validation Loss: 0.26657048\n",
      "Epoch: 0550 cost = 0.060279714\n",
      "Validation Loss: 0.17643549\n",
      "Epoch: 0551 cost = 0.059933456\n",
      "Validation Loss: 0.083209775\n",
      "Epoch: 0552 cost = 0.059592419\n",
      "Validation Loss: 0.07671385\n",
      "Epoch: 0553 cost = 0.059257801\n",
      "Validation Loss: 0.067936376\n",
      "Epoch: 0554 cost = 0.058929907\n",
      "Validation Loss: 0.057393946\n",
      "Epoch: 0555 cost = 0.058607693\n",
      "Validation Loss: 0.23663034\n",
      "Epoch: 0556 cost = 0.058290526\n",
      "Validation Loss: 0.17723204\n",
      "Epoch: 0557 cost = 0.057976707\n",
      "Validation Loss: 0.07832796\n",
      "Epoch: 0558 cost = 0.057664570\n",
      "Validation Loss: 0.07216918\n",
      "Epoch: 0559 cost = 0.057352003\n",
      "Validation Loss: 0.079651214\n",
      "Epoch: 0560 cost = 0.057036788\n",
      "Validation Loss: 0.07702161\n",
      "Epoch: 0561 cost = 0.056717731\n",
      "Validation Loss: 0.09334529\n",
      "Epoch: 0562 cost = 0.056393435\n",
      "Validation Loss: 0.07899337\n",
      "Epoch: 0563 cost = 0.056063984\n",
      "Validation Loss: 0.08127054\n",
      "Epoch: 0564 cost = 0.055729549\n",
      "Validation Loss: 0.08493961\n",
      "Epoch: 0565 cost = 0.055391554\n",
      "Validation Loss: 0.10181456\n",
      "Epoch: 0566 cost = 0.055051658\n",
      "Validation Loss: 0.08840149\n",
      "Epoch: 0567 cost = 0.054712841\n",
      "Validation Loss: 0.10763882\n",
      "Epoch: 0568 cost = 0.054378929\n",
      "Validation Loss: 0.16035321\n",
      "Epoch: 0569 cost = 0.054055701\n",
      "Validation Loss: 0.17235498\n",
      "Epoch: 0570 cost = 0.053751270\n",
      "Validation Loss: 0.17414466\n",
      "Epoch: 0571 cost = 0.053475246\n",
      "Validation Loss: 0.14804108\n",
      "Epoch: 0572 cost = 0.053238892\n",
      "Validation Loss: 0.12434752\n",
      "Epoch: 0573 cost = 0.053054762\n",
      "Validation Loss: 0.07213362\n",
      "Epoch: 0574 cost = 0.052937747\n",
      "Validation Loss: 0.07681526\n",
      "Epoch: 0575 cost = 0.052889847\n",
      "Validation Loss: 0.08891698\n",
      "Epoch: 0576 cost = 0.052861825\n",
      "Validation Loss: 0.08294676\n",
      "Epoch: 0577 cost = 0.052696769\n",
      "Validation Loss: 0.080537885\n",
      "Epoch: 0578 cost = 0.052238429\n",
      "Validation Loss: 0.07653841\n",
      "Epoch: 0579 cost = 0.051573967\n",
      "Validation Loss: 0.12668265\n",
      "Epoch: 0580 cost = 0.050919477\n",
      "Validation Loss: 0.18272139\n",
      "Epoch: 0581 cost = 0.050398005\n",
      "Validation Loss: 0.25844613\n",
      "Epoch: 0582 cost = 0.050006320\n",
      "Validation Loss: 0.2544427\n",
      "Epoch: 0583 cost = 0.049695777\n",
      "Validation Loss: 0.17816073\n",
      "Epoch: 0584 cost = 0.049431929\n",
      "Validation Loss: 0.13487895\n",
      "Epoch: 0585 cost = 0.049196785\n",
      "Validation Loss: 0.16399404\n",
      "Epoch: 0586 cost = 0.048974657\n",
      "Validation Loss: 0.1934698\n",
      "Epoch: 0587 cost = 0.048755697\n",
      "Validation Loss: 0.17188945\n",
      "Epoch: 0588 cost = 0.048535115\n",
      "Validation Loss: 0.17332721\n",
      "Epoch: 0589 cost = 0.048310755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.09269849\n",
      "Epoch: 0590 cost = 0.048081930\n",
      "Validation Loss: 0.06846194\n",
      "Epoch: 0591 cost = 0.047849770\n",
      "Validation Loss: 0.056269594\n",
      "Epoch: 0592 cost = 0.047615914\n",
      "Validation Loss: 0.12929656\n",
      "Epoch: 0593 cost = 0.047380514\n",
      "Validation Loss: 0.08418613\n",
      "Epoch: 0594 cost = 0.047143668\n",
      "Validation Loss: 0.07349908\n",
      "Epoch: 0595 cost = 0.046905288\n",
      "Validation Loss: 0.071986936\n",
      "Epoch: 0596 cost = 0.046667220\n",
      "Validation Loss: 0.062352322\n",
      "Epoch: 0597 cost = 0.046432502\n",
      "Validation Loss: 0.065334275\n",
      "Epoch: 0598 cost = 0.046203515\n",
      "Validation Loss: 0.06170659\n",
      "Epoch: 0599 cost = 0.045980177\n",
      "Validation Loss: 0.070148595\n",
      "Epoch: 0600 cost = 0.045760887\n",
      "Validation Loss: 0.08659053\n",
      "Epoch: 0601 cost = 0.045543223\n",
      "Validation Loss: 0.057232823\n",
      "Epoch: 0602 cost = 0.045325593\n",
      "Validation Loss: 0.053762145\n",
      "Epoch: 0603 cost = 0.045108367\n",
      "Validation Loss: 0.10616895\n",
      "Epoch: 0604 cost = 0.044894002\n",
      "Validation Loss: 0.060881414\n",
      "Epoch: 0605 cost = 0.044690482\n",
      "Validation Loss: 0.05549785\n",
      "Epoch: 0606 cost = 0.044506245\n",
      "Validation Loss: 0.05392582\n",
      "Epoch: 0607 cost = 0.044337322\n",
      "Validation Loss: 0.081140526\n",
      "Epoch: 0608 cost = 0.044165613\n",
      "Validation Loss: 0.11490772\n",
      "Epoch: 0609 cost = 0.043977256\n",
      "Validation Loss: 0.1896629\n",
      "Epoch: 0610 cost = 0.043772440\n",
      "Validation Loss: 0.15013671\n",
      "Epoch: 0611 cost = 0.043560088\n",
      "Validation Loss: 0.10931534\n",
      "Epoch: 0612 cost = 0.043348772\n",
      "Validation Loss: 0.07803966\n",
      "Epoch: 0613 cost = 0.043140674\n",
      "Validation Loss: 0.082679704\n",
      "Epoch: 0614 cost = 0.042930163\n",
      "Validation Loss: 0.14344354\n",
      "Epoch: 0615 cost = 0.042702323\n",
      "Validation Loss: 0.17705241\n",
      "Epoch: 0616 cost = 0.042435519\n",
      "Validation Loss: 0.1937638\n",
      "Epoch: 0617 cost = 0.042137657\n",
      "Validation Loss: 0.19168317\n",
      "Epoch: 0618 cost = 0.041861719\n",
      "Validation Loss: 0.14865705\n",
      "Epoch: 0619 cost = 0.041600604\n",
      "Validation Loss: 0.07706392\n",
      "Epoch: 0620 cost = 0.041337635\n",
      "Validation Loss: 0.080370694\n",
      "Epoch: 0621 cost = 0.041101125\n",
      "Validation Loss: 0.09259594\n",
      "Epoch: 0622 cost = 0.040907938\n",
      "Validation Loss: 0.06781467\n",
      "Epoch: 0623 cost = 0.040756084\n",
      "Validation Loss: 0.067619585\n",
      "Epoch: 0624 cost = 0.040634855\n",
      "Validation Loss: 0.062735625\n",
      "Epoch: 0625 cost = 0.040533120\n",
      "Validation Loss: 0.05395267\n",
      "Epoch: 0626 cost = 0.040437648\n",
      "Validation Loss: 0.05492417\n",
      "Epoch: 0627 cost = 0.040335409\n",
      "Validation Loss: 0.057076477\n",
      "Epoch: 0628 cost = 0.040217832\n",
      "Validation Loss: 0.05362426\n",
      "Epoch: 0629 cost = 0.040085677\n",
      "Validation Loss: 0.10943605\n",
      "Epoch: 0630 cost = 0.039947673\n",
      "Validation Loss: 0.07845635\n",
      "Epoch: 0631 cost = 0.039814495\n",
      "Validation Loss: 0.059939172\n",
      "Epoch: 0632 cost = 0.039692304\n",
      "Validation Loss: 0.05484989\n",
      "Epoch: 0633 cost = 0.039582833\n",
      "Validation Loss: 0.049562227\n",
      "Epoch: 0634 cost = 0.039482817\n",
      "Validation Loss: 0.11459082\n",
      "Epoch: 0635 cost = 0.039387401\n",
      "Validation Loss: 0.07119508\n",
      "Epoch: 0636 cost = 0.039290907\n",
      "Validation Loss: 0.061268777\n",
      "Epoch: 0637 cost = 0.039190086\n",
      "Validation Loss: 0.0699419\n",
      "Epoch: 0638 cost = 0.039084589\n",
      "Validation Loss: 0.05765901\n",
      "Epoch: 0639 cost = 0.038976915\n",
      "Validation Loss: 0.045912705\n",
      "Epoch: 0640 cost = 0.038870487\n",
      "Validation Loss: 0.10410692\n",
      "Epoch: 0641 cost = 0.038767618\n",
      "Validation Loss: 0.06738779\n",
      "Epoch: 0642 cost = 0.038669529\n",
      "Validation Loss: 0.05280574\n",
      "Epoch: 0643 cost = 0.038575034\n",
      "Validation Loss: 0.057324752\n",
      "Epoch: 0644 cost = 0.038483419\n",
      "Validation Loss: 0.05964024\n",
      "Epoch: 0645 cost = 0.038392378\n",
      "Validation Loss: 0.053539757\n",
      "Epoch: 0646 cost = 0.038301390\n",
      "Validation Loss: 0.054852746\n",
      "Epoch: 0647 cost = 0.038209831\n",
      "Validation Loss: 0.05956171\n",
      "Epoch: 0648 cost = 0.038118243\n",
      "Validation Loss: 0.06254443\n",
      "Epoch: 0649 cost = 0.038027765\n",
      "Validation Loss: 0.06452283\n",
      "Epoch: 0650 cost = 0.037938736\n",
      "Validation Loss: 0.0739516\n",
      "Epoch: 0651 cost = 0.037851687\n",
      "Validation Loss: 0.08089116\n",
      "Epoch: 0652 cost = 0.037767105\n",
      "Validation Loss: 0.10360985\n",
      "Epoch: 0653 cost = 0.037684398\n",
      "Validation Loss: 0.09588407\n",
      "Epoch: 0654 cost = 0.037603458\n",
      "Validation Loss: 0.1376051\n",
      "Epoch: 0655 cost = 0.037523738\n",
      "Validation Loss: 0.08087361\n",
      "Epoch: 0656 cost = 0.037445449\n",
      "Validation Loss: 0.05287983\n",
      "Epoch: 0657 cost = 0.037367987\n",
      "Validation Loss: 0.07385716\n",
      "Epoch: 0658 cost = 0.037291569\n",
      "Validation Loss: 0.08542484\n",
      "Epoch: 0659 cost = 0.037216548\n",
      "Validation Loss: 0.059116967\n",
      "Epoch: 0660 cost = 0.037142685\n",
      "Validation Loss: 0.05032939\n",
      "Epoch: 0661 cost = 0.037070192\n",
      "Validation Loss: 0.053418748\n",
      "Epoch: 0662 cost = 0.036999081\n",
      "Validation Loss: 0.052699003\n",
      "Epoch: 0663 cost = 0.036929514\n",
      "Validation Loss: 0.05387645\n",
      "Epoch: 0664 cost = 0.036861152\n",
      "Validation Loss: 0.0496797\n",
      "Epoch: 0665 cost = 0.036793873\n",
      "Validation Loss: 0.057152152\n",
      "Epoch: 0666 cost = 0.036727662\n",
      "Validation Loss: 0.059237037\n",
      "Epoch: 0667 cost = 0.036662242\n",
      "Validation Loss: 0.06640451\n",
      "Epoch: 0668 cost = 0.036597869\n",
      "Validation Loss: 0.056869227\n",
      "Epoch: 0669 cost = 0.036534206\n",
      "Validation Loss: 0.048502315\n",
      "Epoch: 0670 cost = 0.036471422\n",
      "Validation Loss: 0.050078817\n",
      "Epoch: 0671 cost = 0.036409504\n",
      "Validation Loss: 0.061664682\n",
      "Epoch: 0672 cost = 0.036348613\n",
      "Validation Loss: 0.05479947\n",
      "Epoch: 0673 cost = 0.036288372\n",
      "Validation Loss: 0.05448355\n",
      "Epoch: 0674 cost = 0.036228990\n",
      "Validation Loss: 0.053414874\n",
      "Epoch: 0675 cost = 0.036170438\n",
      "Validation Loss: 0.052170597\n",
      "Epoch: 0676 cost = 0.036112552\n",
      "Validation Loss: 0.05687901\n",
      "Epoch: 0677 cost = 0.036055122\n",
      "Validation Loss: 0.057689555\n",
      "Epoch: 0678 cost = 0.035998467\n",
      "Validation Loss: 0.067010485\n",
      "Epoch: 0679 cost = 0.035942379\n",
      "Validation Loss: 0.07242302\n",
      "Epoch: 0680 cost = 0.035886926\n",
      "Validation Loss: 0.06937831\n",
      "Epoch: 0681 cost = 0.035832052\n",
      "Validation Loss: 0.05836733\n",
      "Epoch: 0682 cost = 0.035777669\n",
      "Validation Loss: 0.056959424\n",
      "Epoch: 0683 cost = 0.035723743\n",
      "Validation Loss: 0.047563996\n",
      "Epoch: 0684 cost = 0.035670604\n",
      "Validation Loss: 0.044538982\n",
      "Epoch: 0685 cost = 0.035617700\n",
      "Validation Loss: 0.11224067\n",
      "Epoch: 0686 cost = 0.035565294\n",
      "Validation Loss: 0.0804501\n",
      "Epoch: 0687 cost = 0.035513537\n",
      "Validation Loss: 0.078261994\n",
      "Epoch: 0688 cost = 0.035461875\n",
      "Validation Loss: 0.07587716\n",
      "Epoch: 0689 cost = 0.035410824\n",
      "Validation Loss: 0.07391759\n",
      "Epoch: 0690 cost = 0.035360231\n",
      "Validation Loss: 0.08390107\n",
      "Epoch: 0691 cost = 0.035309976\n",
      "Validation Loss: 0.090222664\n",
      "Epoch: 0692 cost = 0.035260003\n",
      "Validation Loss: 0.07559082\n",
      "Epoch: 0693 cost = 0.035210477\n",
      "Validation Loss: 0.06157185\n",
      "Epoch: 0694 cost = 0.035161274\n",
      "Validation Loss: 0.059718523\n",
      "Epoch: 0695 cost = 0.035112488\n",
      "Validation Loss: 0.06418958\n",
      "Epoch: 0696 cost = 0.035063963\n",
      "Validation Loss: 0.06289923\n",
      "Epoch: 0697 cost = 0.035015877\n",
      "Validation Loss: 0.054798406\n",
      "Epoch: 0698 cost = 0.034968100\n",
      "Validation Loss: 0.05179639\n",
      "Epoch: 0699 cost = 0.034920667\n",
      "Validation Loss: 0.05320803\n",
      "Epoch: 0700 cost = 0.034873473\n",
      "Validation Loss: 0.051642876\n",
      "Epoch: 0701 cost = 0.034826653\n",
      "Validation Loss: 0.04911271\n",
      "Epoch: 0702 cost = 0.034780246\n",
      "Validation Loss: 0.05612186\n",
      "Epoch: 0703 cost = 0.034734146\n",
      "Validation Loss: 0.07407034\n",
      "Epoch: 0704 cost = 0.034688417\n",
      "Validation Loss: 0.08682576\n",
      "Epoch: 0705 cost = 0.034642917\n",
      "Validation Loss: 0.08480747\n",
      "Epoch: 0706 cost = 0.034597828\n",
      "Validation Loss: 0.05483158\n",
      "Epoch: 0707 cost = 0.034553327\n",
      "Validation Loss: 0.051552482\n",
      "Epoch: 0708 cost = 0.034509127\n",
      "Validation Loss: 0.05058236\n",
      "Epoch: 0709 cost = 0.034465479\n",
      "Validation Loss: 0.054924604\n",
      "Epoch: 0710 cost = 0.034422229\n",
      "Validation Loss: 0.077024125\n",
      "Epoch: 0711 cost = 0.034379349\n",
      "Validation Loss: 0.05965026\n",
      "Epoch: 0712 cost = 0.034337095\n",
      "Validation Loss: 0.051274545\n",
      "Epoch: 0713 cost = 0.034295247\n",
      "Validation Loss: 0.049615648\n",
      "Epoch: 0714 cost = 0.034253868\n",
      "Validation Loss: 0.045869637\n",
      "Epoch: 0715 cost = 0.034212936\n",
      "Validation Loss: 0.047873657\n",
      "Epoch: 0716 cost = 0.034172579\n",
      "Validation Loss: 0.051197335\n",
      "Epoch: 0717 cost = 0.034132548\n",
      "Validation Loss: 0.06958872\n",
      "Epoch: 0718 cost = 0.034093053\n",
      "Validation Loss: 0.07872914\n",
      "Epoch: 0719 cost = 0.034054037\n",
      "Validation Loss: 0.0643488\n",
      "Epoch: 0720 cost = 0.034015464\n",
      "Validation Loss: 0.06985517\n",
      "Epoch: 0721 cost = 0.033977275\n",
      "Validation Loss: 0.07574757\n",
      "Epoch: 0722 cost = 0.033939574\n",
      "Validation Loss: 0.056089297\n",
      "Epoch: 0723 cost = 0.033902311\n",
      "Validation Loss: 0.04366257\n",
      "Epoch: 0724 cost = 0.033865414\n",
      "Validation Loss: 0.10103954\n",
      "Epoch: 0725 cost = 0.033828889\n",
      "Validation Loss: 0.054226413\n",
      "Epoch: 0726 cost = 0.033792829\n",
      "Validation Loss: 0.039412733\n",
      "Epoch: 0727 cost = 0.033757047\n",
      "Validation Loss: 0.07859686\n",
      "Epoch: 0728 cost = 0.033721754\n",
      "Validation Loss: 0.04738789\n",
      "Epoch: 0729 cost = 0.033686811\n",
      "Validation Loss: 0.052873686\n",
      "Epoch: 0730 cost = 0.033652118\n",
      "Validation Loss: 0.09115567\n",
      "Epoch: 0731 cost = 0.033617741\n",
      "Validation Loss: 0.10255944\n",
      "Epoch: 0732 cost = 0.033583671\n",
      "Validation Loss: 0.07771835\n",
      "Epoch: 0733 cost = 0.033549977\n",
      "Validation Loss: 0.040413566\n",
      "Epoch: 0734 cost = 0.033516616\n",
      "Validation Loss: 0.045569643\n",
      "Epoch: 0735 cost = 0.033483387\n",
      "Validation Loss: 0.054547086\n",
      "Epoch: 0736 cost = 0.033450572\n",
      "Validation Loss: 0.046812326\n",
      "Epoch: 0737 cost = 0.033417972\n",
      "Validation Loss: 0.053883124\n",
      "Epoch: 0738 cost = 0.033385501\n",
      "Validation Loss: 0.057750586\n",
      "Epoch: 0739 cost = 0.033353469\n",
      "Validation Loss: 0.06845846\n",
      "Epoch: 0740 cost = 0.033321637\n",
      "Validation Loss: 0.049675744\n",
      "Epoch: 0741 cost = 0.033289934\n",
      "Validation Loss: 0.049467586\n",
      "Epoch: 0742 cost = 0.033258525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.048900254\n",
      "Epoch: 0743 cost = 0.033227399\n",
      "Validation Loss: 0.04920881\n",
      "Epoch: 0744 cost = 0.033196422\n",
      "Validation Loss: 0.042794153\n",
      "Epoch: 0745 cost = 0.033165563\n",
      "Validation Loss: 0.038090955\n",
      "Epoch: 0746 cost = 0.033135161\n",
      "Validation Loss: 0.09786937\n",
      "Epoch: 0747 cost = 0.033104814\n",
      "Validation Loss: 0.059516203\n",
      "Epoch: 0748 cost = 0.033074596\n",
      "Validation Loss: 0.043480612\n",
      "Epoch: 0749 cost = 0.033044644\n",
      "Validation Loss: 0.04300414\n",
      "Epoch: 0750 cost = 0.033014963\n",
      "Validation Loss: 0.04429065\n",
      "Epoch: 0751 cost = 0.032985274\n",
      "Validation Loss: 0.053084314\n",
      "Epoch: 0752 cost = 0.032955856\n",
      "Validation Loss: 0.054236285\n",
      "Epoch: 0753 cost = 0.032926698\n",
      "Validation Loss: 0.055907812\n",
      "Epoch: 0754 cost = 0.032897545\n",
      "Validation Loss: 0.060867254\n",
      "Epoch: 0755 cost = 0.032868708\n",
      "Validation Loss: 0.05799159\n",
      "Epoch: 0756 cost = 0.032839906\n",
      "Validation Loss: 0.07133869\n",
      "Epoch: 0757 cost = 0.032811334\n",
      "Validation Loss: 0.05094441\n",
      "Epoch: 0758 cost = 0.032782939\n",
      "Validation Loss: 0.044802878\n",
      "Epoch: 0759 cost = 0.032754553\n",
      "Validation Loss: 0.049095083\n",
      "Epoch: 0760 cost = 0.032726581\n",
      "Validation Loss: 0.061064906\n",
      "Epoch: 0761 cost = 0.032698629\n",
      "Validation Loss: 0.05269171\n",
      "Epoch: 0762 cost = 0.032670770\n",
      "Validation Loss: 0.044472694\n",
      "Epoch: 0763 cost = 0.032643164\n",
      "Validation Loss: 0.039949328\n",
      "Epoch: 0764 cost = 0.032615560\n",
      "Validation Loss: 0.040556435\n",
      "Epoch: 0765 cost = 0.032588071\n",
      "Validation Loss: 0.045731988\n",
      "Epoch: 0766 cost = 0.032560881\n",
      "Validation Loss: 0.06698337\n",
      "Epoch: 0767 cost = 0.032533711\n",
      "Validation Loss: 0.07501306\n",
      "Epoch: 0768 cost = 0.032506631\n",
      "Validation Loss: 0.06353525\n",
      "Epoch: 0769 cost = 0.032479713\n",
      "Validation Loss: 0.063321464\n",
      "Epoch: 0770 cost = 0.032452805\n",
      "Validation Loss: 0.04827085\n",
      "Epoch: 0771 cost = 0.032426233\n",
      "Validation Loss: 0.050089426\n",
      "Epoch: 0772 cost = 0.032399646\n",
      "Validation Loss: 0.054660037\n",
      "Epoch: 0773 cost = 0.032373235\n",
      "Validation Loss: 0.051169306\n",
      "Epoch: 0774 cost = 0.032346910\n",
      "Validation Loss: 0.041651744\n",
      "Epoch: 0775 cost = 0.032320611\n",
      "Validation Loss: 0.03575452\n",
      "Epoch: 0776 cost = 0.032294410\n",
      "Validation Loss: 0.08045213\n",
      "Epoch: 0777 cost = 0.032268490\n",
      "Validation Loss: 0.04158536\n",
      "Epoch: 0778 cost = 0.032242541\n",
      "Validation Loss: 0.03847152\n",
      "Epoch: 0779 cost = 0.032216736\n",
      "Validation Loss: 0.046971515\n",
      "Epoch: 0780 cost = 0.032190971\n",
      "Validation Loss: 0.04562394\n",
      "Epoch: 0781 cost = 0.032165423\n",
      "Validation Loss: 0.043322746\n",
      "Epoch: 0782 cost = 0.032139782\n",
      "Validation Loss: 0.038150758\n",
      "Epoch: 0783 cost = 0.032114363\n",
      "Validation Loss: 0.03641306\n",
      "Epoch: 0784 cost = 0.032089002\n",
      "Validation Loss: 0.03558901\n",
      "Epoch: 0785 cost = 0.032063639\n",
      "Validation Loss: 0.08845532\n",
      "Epoch: 0786 cost = 0.032038501\n",
      "Validation Loss: 0.05249641\n",
      "Epoch: 0787 cost = 0.032013505\n",
      "Validation Loss: 0.042950302\n",
      "Epoch: 0788 cost = 0.031988515\n",
      "Validation Loss: 0.044039145\n",
      "Epoch: 0789 cost = 0.031963446\n",
      "Validation Loss: 0.04817932\n",
      "Epoch: 0790 cost = 0.031938491\n",
      "Validation Loss: 0.053557694\n",
      "Epoch: 0791 cost = 0.031913837\n",
      "Validation Loss: 0.07747387\n",
      "Epoch: 0792 cost = 0.031889079\n",
      "Validation Loss: 0.0729325\n",
      "Epoch: 0793 cost = 0.031864418\n",
      "Validation Loss: 0.058613364\n",
      "Epoch: 0794 cost = 0.031839893\n",
      "Validation Loss: 0.05799761\n",
      "Epoch: 0795 cost = 0.031815325\n",
      "Validation Loss: 0.044758935\n",
      "Epoch: 0796 cost = 0.031790835\n",
      "Validation Loss: 0.045409974\n",
      "Epoch: 0797 cost = 0.031766512\n",
      "Validation Loss: 0.04338191\n",
      "Epoch: 0798 cost = 0.031742243\n",
      "Validation Loss: 0.04188701\n",
      "Epoch: 0799 cost = 0.031718048\n",
      "Validation Loss: 0.041640718\n",
      "Epoch: 0800 cost = 0.031693787\n",
      "Validation Loss: 0.046273753\n",
      "Epoch: 0801 cost = 0.031669664\n",
      "Validation Loss: 0.047611743\n",
      "Epoch: 0802 cost = 0.031645702\n",
      "Validation Loss: 0.04088829\n",
      "Epoch: 0803 cost = 0.031621709\n",
      "Validation Loss: 0.039740127\n",
      "Epoch: 0804 cost = 0.031597754\n",
      "Validation Loss: 0.04256156\n",
      "Epoch: 0805 cost = 0.031573818\n",
      "Validation Loss: 0.042624954\n",
      "Epoch: 0806 cost = 0.031550159\n",
      "Validation Loss: 0.043305814\n",
      "Epoch: 0807 cost = 0.031526344\n",
      "Validation Loss: 0.04748194\n",
      "Epoch: 0808 cost = 0.031502654\n",
      "Validation Loss: 0.061591204\n",
      "Epoch: 0809 cost = 0.031479004\n",
      "Validation Loss: 0.06897772\n",
      "Epoch: 0810 cost = 0.031455316\n",
      "Validation Loss: 0.063070744\n",
      "Epoch: 0811 cost = 0.031431811\n",
      "Validation Loss: 0.07221877\n",
      "Epoch: 0812 cost = 0.031408289\n",
      "Validation Loss: 0.08205626\n",
      "Epoch: 0813 cost = 0.031384736\n",
      "Validation Loss: 0.072543465\n",
      "Epoch: 0814 cost = 0.031361516\n",
      "Validation Loss: 0.066904545\n",
      "Epoch: 0815 cost = 0.031338129\n",
      "Validation Loss: 0.051745325\n",
      "Epoch: 0816 cost = 0.031314878\n",
      "Validation Loss: 0.0408161\n",
      "Epoch: 0817 cost = 0.031291524\n",
      "Validation Loss: 0.039530367\n",
      "Epoch: 0818 cost = 0.031268401\n",
      "Validation Loss: 0.039690733\n",
      "Epoch: 0819 cost = 0.031245177\n",
      "Validation Loss: 0.045750774\n",
      "Epoch: 0820 cost = 0.031222009\n",
      "Validation Loss: 0.045562476\n",
      "Epoch: 0821 cost = 0.031198973\n",
      "Validation Loss: 0.050510343\n",
      "Epoch: 0822 cost = 0.031175804\n",
      "Validation Loss: 0.0711317\n",
      "Epoch: 0823 cost = 0.031152880\n",
      "Validation Loss: 0.09127128\n",
      "Epoch: 0824 cost = 0.031129884\n",
      "Validation Loss: 0.0713637\n",
      "Epoch: 0825 cost = 0.031106896\n",
      "Validation Loss: 0.046800923\n",
      "Epoch: 0826 cost = 0.031084098\n",
      "Validation Loss: 0.03909579\n",
      "Epoch: 0827 cost = 0.031061242\n",
      "Validation Loss: 0.051900342\n",
      "Epoch: 0828 cost = 0.031038559\n",
      "Validation Loss: 0.06879649\n",
      "Epoch: 0829 cost = 0.031015570\n",
      "Validation Loss: 0.06521375\n",
      "Epoch: 0830 cost = 0.030992954\n",
      "Validation Loss: 0.07109296\n",
      "Epoch: 0831 cost = 0.030970119\n",
      "Validation Loss: 0.06661788\n",
      "Epoch: 0832 cost = 0.030947568\n",
      "Validation Loss: 0.05730885\n",
      "Epoch: 0833 cost = 0.030924975\n",
      "Validation Loss: 0.05094526\n",
      "Epoch: 0834 cost = 0.030902336\n",
      "Validation Loss: 0.04022922\n",
      "Epoch: 0835 cost = 0.030879805\n",
      "Validation Loss: 0.043459717\n",
      "Epoch: 0836 cost = 0.030857145\n",
      "Validation Loss: 0.066273466\n",
      "Epoch: 0837 cost = 0.030834632\n",
      "Validation Loss: 0.054110877\n",
      "Epoch: 0838 cost = 0.030812316\n",
      "Validation Loss: 0.057955466\n",
      "Epoch: 0839 cost = 0.030789810\n",
      "Validation Loss: 0.06028889\n",
      "Epoch: 0840 cost = 0.030767489\n",
      "Validation Loss: 0.047825795\n",
      "Epoch: 0841 cost = 0.030744997\n",
      "Validation Loss: 0.04892191\n",
      "Epoch: 0842 cost = 0.030722821\n",
      "Validation Loss: 0.05784379\n",
      "Epoch: 0843 cost = 0.030700410\n",
      "Validation Loss: 0.04766311\n",
      "Epoch: 0844 cost = 0.030678077\n",
      "Validation Loss: 0.042098645\n",
      "Epoch: 0845 cost = 0.030655741\n",
      "Validation Loss: 0.047059365\n",
      "Epoch: 0846 cost = 0.030633665\n",
      "Validation Loss: 0.053292524\n",
      "Epoch: 0847 cost = 0.030611270\n",
      "Validation Loss: 0.050725594\n",
      "Epoch: 0848 cost = 0.030589262\n",
      "Validation Loss: 0.04787619\n",
      "Epoch: 0849 cost = 0.030567148\n",
      "Validation Loss: 0.044878066\n",
      "Epoch: 0850 cost = 0.030545040\n",
      "Validation Loss: 0.039032217\n",
      "Epoch: 0851 cost = 0.030522862\n",
      "Validation Loss: 0.048026472\n",
      "Epoch: 0852 cost = 0.030500811\n",
      "Validation Loss: 0.049270622\n",
      "Epoch: 0853 cost = 0.030478894\n",
      "Validation Loss: 0.04943227\n",
      "Epoch: 0854 cost = 0.030456792\n",
      "Validation Loss: 0.052287437\n",
      "Epoch: 0855 cost = 0.030434890\n",
      "Validation Loss: 0.04996572\n",
      "Epoch: 0856 cost = 0.030412846\n",
      "Validation Loss: 0.052264206\n",
      "Epoch: 0857 cost = 0.030390905\n",
      "Validation Loss: 0.044688083\n",
      "Epoch: 0858 cost = 0.030368950\n",
      "Validation Loss: 0.03376708\n",
      "Epoch: 0859 cost = 0.030347098\n",
      "Validation Loss: 0.09268472\n",
      "Epoch: 0860 cost = 0.030325265\n",
      "Validation Loss: 0.06742827\n",
      "Epoch: 0861 cost = 0.030303427\n",
      "Validation Loss: 0.051465966\n",
      "Epoch: 0862 cost = 0.030281662\n",
      "Validation Loss: 0.043036398\n",
      "Epoch: 0863 cost = 0.030259857\n",
      "Validation Loss: 0.047576007\n",
      "Epoch: 0864 cost = 0.030238102\n",
      "Validation Loss: 0.04722982\n",
      "Epoch: 0865 cost = 0.030216503\n",
      "Validation Loss: 0.04565884\n",
      "Epoch: 0866 cost = 0.030194658\n",
      "Validation Loss: 0.047648434\n",
      "Epoch: 0867 cost = 0.030173212\n",
      "Validation Loss: 0.05681834\n",
      "Epoch: 0868 cost = 0.030151437\n",
      "Validation Loss: 0.06385375\n",
      "Epoch: 0869 cost = 0.030129861\n",
      "Validation Loss: 0.05319759\n",
      "Epoch: 0870 cost = 0.030108216\n",
      "Validation Loss: 0.059389833\n",
      "Epoch: 0871 cost = 0.030086606\n",
      "Validation Loss: 0.06392324\n",
      "Epoch: 0872 cost = 0.030065073\n",
      "Validation Loss: 0.058105603\n",
      "Epoch: 0873 cost = 0.030043634\n",
      "Validation Loss: 0.06347787\n",
      "Epoch: 0874 cost = 0.030022122\n",
      "Validation Loss: 0.06968644\n",
      "Epoch: 0875 cost = 0.030000696\n",
      "Validation Loss: 0.061776932\n",
      "Epoch: 0876 cost = 0.029979166\n",
      "Validation Loss: 0.046511184\n",
      "Epoch: 0877 cost = 0.029957865\n",
      "Validation Loss: 0.04303649\n",
      "Epoch: 0878 cost = 0.029936485\n",
      "Validation Loss: 0.055407044\n",
      "Epoch: 0879 cost = 0.029915138\n",
      "Validation Loss: 0.054387312\n",
      "Epoch: 0880 cost = 0.029893748\n",
      "Validation Loss: 0.049988147\n",
      "Epoch: 0881 cost = 0.029872404\n",
      "Validation Loss: 0.057217952\n",
      "Epoch: 0882 cost = 0.029851095\n",
      "Validation Loss: 0.060395725\n",
      "Epoch: 0883 cost = 0.029829912\n",
      "Validation Loss: 0.054703623\n",
      "Epoch: 0884 cost = 0.029808690\n",
      "Validation Loss: 0.04045116\n",
      "Epoch: 0885 cost = 0.029787471\n",
      "Validation Loss: 0.039043233\n",
      "Epoch: 0886 cost = 0.029766280\n",
      "Validation Loss: 0.038970433\n",
      "Epoch: 0887 cost = 0.029745239\n",
      "Validation Loss: 0.045584336\n",
      "Epoch: 0888 cost = 0.029723945\n",
      "Validation Loss: 0.037185173\n",
      "Epoch: 0889 cost = 0.029702939\n",
      "Validation Loss: 0.036120303\n",
      "Epoch: 0890 cost = 0.029681905\n",
      "Validation Loss: 0.0461152\n",
      "Epoch: 0891 cost = 0.029660968\n",
      "Validation Loss: 0.05028575\n",
      "Epoch: 0892 cost = 0.029639835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.052533563\n",
      "Epoch: 0893 cost = 0.029618823\n",
      "Validation Loss: 0.043372404\n",
      "Epoch: 0894 cost = 0.029598063\n",
      "Validation Loss: 0.035346586\n",
      "Epoch: 0895 cost = 0.029577150\n",
      "Validation Loss: 0.040454477\n",
      "Epoch: 0896 cost = 0.029556218\n",
      "Validation Loss: 0.043223567\n",
      "Epoch: 0897 cost = 0.029535272\n",
      "Validation Loss: 0.054096967\n",
      "Epoch: 0898 cost = 0.029514723\n",
      "Validation Loss: 0.06412573\n",
      "Epoch: 0899 cost = 0.029493729\n",
      "Validation Loss: 0.04435653\n",
      "Epoch: 0900 cost = 0.029473134\n",
      "Validation Loss: 0.03864736\n",
      "Epoch: 0901 cost = 0.029452333\n",
      "Validation Loss: 0.041277975\n",
      "Epoch: 0902 cost = 0.029431828\n",
      "Validation Loss: 0.054383297\n",
      "Epoch: 0903 cost = 0.029411143\n",
      "Validation Loss: 0.07236799\n",
      "Epoch: 0904 cost = 0.029390333\n",
      "Validation Loss: 0.059360404\n",
      "Epoch: 0905 cost = 0.029369833\n",
      "Validation Loss: 0.04719974\n",
      "Epoch: 0906 cost = 0.029349375\n",
      "Validation Loss: 0.03621577\n",
      "Epoch: 0907 cost = 0.029328889\n",
      "Validation Loss: 0.050624475\n",
      "Epoch: 0908 cost = 0.029308340\n",
      "Validation Loss: 0.058167923\n",
      "Epoch: 0909 cost = 0.029287889\n",
      "Validation Loss: 0.045915086\n",
      "Epoch: 0910 cost = 0.029267453\n",
      "Validation Loss: 0.052939747\n",
      "Epoch: 0911 cost = 0.029247123\n",
      "Validation Loss: 0.059840072\n",
      "Epoch: 0912 cost = 0.029226745\n",
      "Validation Loss: 0.062144235\n",
      "Epoch: 0913 cost = 0.029206365\n",
      "Validation Loss: 0.06549422\n",
      "Epoch: 0914 cost = 0.029186222\n",
      "Validation Loss: 0.03652322\n",
      "Epoch: 0915 cost = 0.029166019\n",
      "Validation Loss: 0.04007152\n",
      "Epoch: 0916 cost = 0.029145855\n",
      "Validation Loss: 0.048825584\n",
      "Epoch: 0917 cost = 0.029125659\n",
      "Validation Loss: 0.043054536\n",
      "Epoch: 0918 cost = 0.029105435\n",
      "Validation Loss: 0.038821783\n",
      "Epoch: 0919 cost = 0.029085429\n",
      "Validation Loss: 0.04473935\n",
      "Epoch: 0920 cost = 0.029065384\n",
      "Validation Loss: 0.051621348\n",
      "Epoch: 0921 cost = 0.029045546\n",
      "Validation Loss: 0.0538214\n",
      "Epoch: 0922 cost = 0.029025494\n",
      "Validation Loss: 0.050313864\n",
      "Epoch: 0923 cost = 0.029005476\n",
      "Validation Loss: 0.04448537\n",
      "Epoch: 0924 cost = 0.028985716\n",
      "Validation Loss: 0.03191035\n",
      "Epoch: 0925 cost = 0.028965851\n",
      "Validation Loss: 0.09255582\n",
      "Epoch: 0926 cost = 0.028946109\n",
      "Validation Loss: 0.072078586\n",
      "Epoch: 0927 cost = 0.028926171\n",
      "Validation Loss: 0.07009103\n",
      "Epoch: 0928 cost = 0.028906583\n",
      "Validation Loss: 0.08589901\n",
      "Epoch: 0929 cost = 0.028886973\n",
      "Validation Loss: 0.06874616\n",
      "Epoch: 0930 cost = 0.028867220\n",
      "Validation Loss: 0.045555826\n",
      "Epoch: 0931 cost = 0.028847467\n",
      "Validation Loss: 0.03806968\n",
      "Epoch: 0932 cost = 0.028828024\n",
      "Validation Loss: 0.04295203\n",
      "Epoch: 0933 cost = 0.028808417\n",
      "Validation Loss: 0.063760385\n",
      "Epoch: 0934 cost = 0.028789013\n",
      "Validation Loss: 0.05750463\n",
      "Epoch: 0935 cost = 0.028769334\n",
      "Validation Loss: 0.040508103\n",
      "Epoch: 0936 cost = 0.028750080\n",
      "Validation Loss: 0.034024723\n",
      "Epoch: 0937 cost = 0.028730613\n",
      "Validation Loss: 0.042759538\n",
      "Epoch: 0938 cost = 0.028711377\n",
      "Validation Loss: 0.046251755\n",
      "Epoch: 0939 cost = 0.028691966\n",
      "Validation Loss: 0.07074666\n",
      "Epoch: 0940 cost = 0.028672712\n",
      "Validation Loss: 0.07364093\n",
      "Epoch: 0941 cost = 0.028653462\n",
      "Validation Loss: 0.064606614\n",
      "Epoch: 0942 cost = 0.028634228\n",
      "Validation Loss: 0.06059459\n",
      "Epoch: 0943 cost = 0.028615178\n",
      "Validation Loss: 0.06847378\n",
      "Epoch: 0944 cost = 0.028596003\n",
      "Validation Loss: 0.06920128\n",
      "Epoch: 0945 cost = 0.028576830\n",
      "Validation Loss: 0.051039852\n",
      "Epoch: 0946 cost = 0.028557665\n",
      "Validation Loss: 0.04399276\n",
      "Epoch: 0947 cost = 0.028538833\n",
      "Validation Loss: 0.03840591\n",
      "Epoch: 0948 cost = 0.028519802\n",
      "Validation Loss: 0.0402056\n",
      "Epoch: 0949 cost = 0.028500792\n",
      "Validation Loss: 0.044373784\n",
      "Epoch: 0950 cost = 0.028481843\n",
      "Validation Loss: 0.033977732\n",
      "Epoch: 0951 cost = 0.028463097\n",
      "Validation Loss: 0.035528876\n",
      "Epoch: 0952 cost = 0.028444071\n",
      "Validation Loss: 0.040987454\n",
      "Epoch: 0953 cost = 0.028425444\n",
      "Validation Loss: 0.04115137\n",
      "Epoch: 0954 cost = 0.028406580\n",
      "Validation Loss: 0.04662173\n",
      "Epoch: 0955 cost = 0.028387754\n",
      "Validation Loss: 0.051802464\n",
      "Epoch: 0956 cost = 0.028368939\n",
      "Validation Loss: 0.042755812\n",
      "Epoch: 0957 cost = 0.028350489\n",
      "Validation Loss: 0.039971486\n",
      "Epoch: 0958 cost = 0.028331874\n",
      "Validation Loss: 0.044239227\n",
      "Epoch: 0959 cost = 0.028313156\n",
      "Validation Loss: 0.04647513\n",
      "Epoch: 0960 cost = 0.028294602\n",
      "Validation Loss: 0.050466962\n",
      "Epoch: 0961 cost = 0.028275893\n",
      "Validation Loss: 0.03998633\n",
      "Epoch: 0962 cost = 0.028257498\n",
      "Validation Loss: 0.0400174\n",
      "Epoch: 0963 cost = 0.028239081\n",
      "Validation Loss: 0.04634481\n",
      "Epoch: 0964 cost = 0.028220605\n",
      "Validation Loss: 0.057369236\n",
      "Epoch: 0965 cost = 0.028202211\n",
      "Validation Loss: 0.049988415\n",
      "Epoch: 0966 cost = 0.028183902\n",
      "Validation Loss: 0.053136\n",
      "Epoch: 0967 cost = 0.028165615\n",
      "Validation Loss: 0.03966514\n",
      "Epoch: 0968 cost = 0.028147169\n",
      "Validation Loss: 0.038903803\n",
      "Epoch: 0969 cost = 0.028128912\n",
      "Validation Loss: 0.05338658\n",
      "Epoch: 0970 cost = 0.028110738\n",
      "Validation Loss: 0.046089232\n",
      "Epoch: 0971 cost = 0.028092513\n",
      "Validation Loss: 0.033013966\n",
      "Epoch: 0972 cost = 0.028074278\n",
      "Validation Loss: 0.031465244\n",
      "Epoch: 0973 cost = 0.028056319\n",
      "Validation Loss: 0.07496752\n",
      "Epoch: 0974 cost = 0.028038245\n",
      "Validation Loss: 0.044854455\n",
      "Epoch: 0975 cost = 0.028020132\n",
      "Validation Loss: 0.04189341\n",
      "Epoch: 0976 cost = 0.028002142\n",
      "Validation Loss: 0.047069833\n",
      "Epoch: 0977 cost = 0.027984109\n",
      "Validation Loss: 0.045532364\n",
      "Epoch: 0978 cost = 0.027966102\n",
      "Validation Loss: 0.035124525\n",
      "Epoch: 0979 cost = 0.027948270\n",
      "Validation Loss: 0.035303053\n",
      "Epoch: 0980 cost = 0.027930305\n",
      "Validation Loss: 0.042149212\n",
      "Epoch: 0981 cost = 0.027912558\n",
      "Validation Loss: 0.038549334\n",
      "Epoch: 0982 cost = 0.027894733\n",
      "Validation Loss: 0.036105845\n",
      "Epoch: 0983 cost = 0.027876986\n",
      "Validation Loss: 0.048590366\n",
      "Epoch: 0984 cost = 0.027859260\n",
      "Validation Loss: 0.060233105\n",
      "Epoch: 0985 cost = 0.027841474\n",
      "Validation Loss: 0.049140416\n",
      "Epoch: 0986 cost = 0.027823908\n",
      "Validation Loss: 0.046692364\n",
      "Epoch: 0987 cost = 0.027806139\n",
      "Validation Loss: 0.05925931\n",
      "Epoch: 0988 cost = 0.027788520\n",
      "Validation Loss: 0.06409486\n",
      "Epoch: 0989 cost = 0.027770851\n",
      "Validation Loss: 0.051167946\n",
      "Epoch: 0990 cost = 0.027753299\n",
      "Validation Loss: 0.07272266\n",
      "Epoch: 0991 cost = 0.027735837\n",
      "Validation Loss: 0.07287253\n",
      "Epoch: 0992 cost = 0.027718318\n",
      "Validation Loss: 0.071872264\n",
      "Epoch: 0993 cost = 0.027701020\n",
      "Validation Loss: 0.062793665\n",
      "Epoch: 0994 cost = 0.027683595\n",
      "Validation Loss: 0.05046213\n",
      "Epoch: 0995 cost = 0.027666190\n",
      "Validation Loss: 0.04011925\n",
      "Epoch: 0996 cost = 0.027648815\n",
      "Validation Loss: 0.04356735\n",
      "Epoch: 0997 cost = 0.027631546\n",
      "Validation Loss: 0.053834286\n",
      "Epoch: 0998 cost = 0.027614308\n",
      "Validation Loss: 0.04878034\n",
      "Epoch: 0999 cost = 0.027597125\n",
      "Validation Loss: 0.04335036\n",
      "Epoch: 1000 cost = 0.027579872\n",
      "Validation Loss: 0.037440725\n",
      "Epoch: 1001 cost = 0.027562725\n",
      "Validation Loss: 0.040906\n",
      "Epoch: 1002 cost = 0.027545586\n",
      "Validation Loss: 0.03955595\n",
      "Epoch: 1003 cost = 0.027528550\n",
      "Validation Loss: 0.034400593\n",
      "Epoch: 1004 cost = 0.027511499\n",
      "Validation Loss: 0.035639662\n",
      "Epoch: 1005 cost = 0.027494372\n",
      "Validation Loss: 0.048414387\n",
      "Epoch: 1006 cost = 0.027477430\n",
      "Validation Loss: 0.058753144\n",
      "Epoch: 1007 cost = 0.027460622\n",
      "Validation Loss: 0.059146088\n",
      "Epoch: 1008 cost = 0.027443552\n",
      "Validation Loss: 0.05032161\n",
      "Epoch: 1009 cost = 0.027426678\n",
      "Validation Loss: 0.06022148\n",
      "Epoch: 1010 cost = 0.027409939\n",
      "Validation Loss: 0.0671932\n",
      "Epoch: 1011 cost = 0.027392991\n",
      "Validation Loss: 0.05029068\n",
      "Epoch: 1012 cost = 0.027376230\n",
      "Validation Loss: 0.047117073\n",
      "Epoch: 1013 cost = 0.027359471\n",
      "Validation Loss: 0.04470906\n",
      "Epoch: 1014 cost = 0.027342838\n",
      "Validation Loss: 0.040552884\n",
      "Epoch: 1015 cost = 0.027326223\n",
      "Validation Loss: 0.036899038\n",
      "Epoch: 1016 cost = 0.027309491\n",
      "Validation Loss: 0.0417927\n",
      "Epoch: 1017 cost = 0.027292900\n",
      "Validation Loss: 0.04279581\n",
      "Epoch: 1018 cost = 0.027276432\n",
      "Validation Loss: 0.034188524\n",
      "Epoch: 1019 cost = 0.027259690\n",
      "Validation Loss: 0.030307438\n",
      "Epoch: 1020 cost = 0.027243333\n",
      "Validation Loss: 0.06559357\n",
      "Epoch: 1021 cost = 0.027226812\n",
      "Validation Loss: 0.03993131\n",
      "Epoch: 1022 cost = 0.027210354\n",
      "Validation Loss: 0.03602576\n",
      "Epoch: 1023 cost = 0.027194060\n",
      "Validation Loss: 0.03018477\n",
      "Epoch: 1024 cost = 0.027177684\n",
      "Validation Loss: 0.07750529\n",
      "Epoch: 1025 cost = 0.027161280\n",
      "Validation Loss: 0.04732053\n",
      "Epoch: 1026 cost = 0.027145051\n",
      "Validation Loss: 0.048496857\n",
      "Epoch: 1027 cost = 0.027128716\n",
      "Validation Loss: 0.032928716\n",
      "Epoch: 1028 cost = 0.027112671\n",
      "Validation Loss: 0.027320467\n",
      "Epoch: 1029 cost = 0.027096375\n",
      "Validation Loss: 0.06514435\n",
      "Epoch: 1030 cost = 0.027080303\n",
      "Validation Loss: 0.038862444\n",
      "Epoch: 1031 cost = 0.027064086\n",
      "Validation Loss: 0.047098428\n",
      "Epoch: 1032 cost = 0.027048027\n",
      "Validation Loss: 0.05005611\n",
      "Epoch: 1033 cost = 0.027032053\n",
      "Validation Loss: 0.06510805\n",
      "Epoch: 1034 cost = 0.027015877\n",
      "Validation Loss: 0.047326773\n",
      "Epoch: 1035 cost = 0.026999853\n",
      "Validation Loss: 0.032439455\n",
      "Epoch: 1036 cost = 0.026984098\n",
      "Validation Loss: 0.031670887\n",
      "Epoch: 1037 cost = 0.026968155\n",
      "Validation Loss: 0.050370626\n",
      "Epoch: 1038 cost = 0.026952212\n",
      "Validation Loss: 0.052384295\n",
      "Epoch: 1039 cost = 0.026936449\n",
      "Validation Loss: 0.038977176\n",
      "Epoch: 1040 cost = 0.026920661\n",
      "Validation Loss: 0.03694069\n",
      "Epoch: 1041 cost = 0.026904882\n",
      "Validation Loss: 0.040401615\n",
      "Epoch: 1042 cost = 0.026889263\n",
      "Validation Loss: 0.03275745\n",
      "Epoch: 1043 cost = 0.026873286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.036749393\n",
      "Epoch: 1044 cost = 0.026857758\n",
      "Validation Loss: 0.043404363\n",
      "Epoch: 1045 cost = 0.026842032\n",
      "Validation Loss: 0.035154637\n",
      "Epoch: 1046 cost = 0.026826489\n",
      "Validation Loss: 0.028396226\n",
      "Epoch: 1047 cost = 0.026810998\n",
      "Validation Loss: 0.033638142\n",
      "Epoch: 1048 cost = 0.026795489\n",
      "Validation Loss: 0.03473075\n",
      "Epoch: 1049 cost = 0.026779890\n",
      "Validation Loss: 0.03645066\n",
      "Epoch: 1050 cost = 0.026764450\n",
      "Validation Loss: 0.043290686\n",
      "Epoch: 1051 cost = 0.026749057\n",
      "Validation Loss: 0.053968918\n",
      "Epoch: 1052 cost = 0.026733560\n",
      "Validation Loss: 0.049985826\n",
      "Epoch: 1053 cost = 0.026718441\n",
      "Validation Loss: 0.044869803\n",
      "Epoch: 1054 cost = 0.026703034\n",
      "Validation Loss: 0.047981564\n",
      "Epoch: 1055 cost = 0.026687852\n",
      "Validation Loss: 0.04930731\n",
      "Epoch: 1056 cost = 0.026672441\n",
      "Validation Loss: 0.052219342\n",
      "Epoch: 1057 cost = 0.026657125\n",
      "Validation Loss: 0.05329457\n",
      "Epoch: 1058 cost = 0.026642102\n",
      "Validation Loss: 0.058059745\n",
      "Epoch: 1059 cost = 0.026627088\n",
      "Validation Loss: 0.060025714\n",
      "Epoch: 1060 cost = 0.026611849\n",
      "Validation Loss: 0.045574486\n",
      "Epoch: 1061 cost = 0.026596894\n",
      "Validation Loss: 0.041157372\n",
      "Epoch: 1062 cost = 0.026581931\n",
      "Validation Loss: 0.033802148\n",
      "Epoch: 1063 cost = 0.026567025\n",
      "Validation Loss: 0.034746114\n",
      "Epoch: 1064 cost = 0.026551865\n",
      "Validation Loss: 0.03985386\n",
      "Epoch: 1065 cost = 0.026537160\n",
      "Validation Loss: 0.04520541\n",
      "Epoch: 1066 cost = 0.026522229\n",
      "Validation Loss: 0.038073186\n",
      "Epoch: 1067 cost = 0.026507354\n",
      "Validation Loss: 0.03123088\n",
      "Epoch: 1068 cost = 0.026492674\n",
      "Validation Loss: 0.03267977\n",
      "Epoch: 1069 cost = 0.026477689\n",
      "Validation Loss: 0.034346543\n",
      "Epoch: 1070 cost = 0.026463044\n",
      "Validation Loss: 0.04615571\n",
      "Epoch: 1071 cost = 0.026448329\n",
      "Validation Loss: 0.04856657\n",
      "Epoch: 1072 cost = 0.026433696\n",
      "Validation Loss: 0.042816155\n",
      "Epoch: 1073 cost = 0.026419164\n",
      "Validation Loss: 0.035233315\n",
      "Epoch: 1074 cost = 0.026404544\n",
      "Validation Loss: 0.030088985\n",
      "Epoch: 1075 cost = 0.026389911\n",
      "Validation Loss: 0.027762547\n",
      "Epoch: 1076 cost = 0.026375368\n",
      "Validation Loss: 0.031064527\n",
      "Epoch: 1077 cost = 0.026361079\n",
      "Validation Loss: 0.04225591\n",
      "Epoch: 1078 cost = 0.026346508\n",
      "Validation Loss: 0.036510233\n",
      "Epoch: 1079 cost = 0.026332073\n",
      "Validation Loss: 0.02763499\n",
      "Epoch: 1080 cost = 0.026317649\n",
      "Validation Loss: 0.038031\n",
      "Epoch: 1081 cost = 0.026303316\n",
      "Validation Loss: 0.036379598\n",
      "Epoch: 1082 cost = 0.026289102\n",
      "Validation Loss: 0.037763387\n",
      "Epoch: 1083 cost = 0.026274779\n",
      "Validation Loss: 0.0360989\n",
      "Epoch: 1084 cost = 0.026260397\n",
      "Validation Loss: 0.037557703\n",
      "Epoch: 1085 cost = 0.026246245\n",
      "Validation Loss: 0.032713704\n",
      "Epoch: 1086 cost = 0.026232214\n",
      "Validation Loss: 0.033321403\n",
      "Epoch: 1087 cost = 0.026217936\n",
      "Validation Loss: 0.03547365\n",
      "Epoch: 1088 cost = 0.026204002\n",
      "Validation Loss: 0.043476097\n",
      "Epoch: 1089 cost = 0.026189933\n",
      "Validation Loss: 0.05100023\n",
      "Epoch: 1090 cost = 0.026175969\n",
      "Validation Loss: 0.037242774\n",
      "Epoch: 1091 cost = 0.026161884\n",
      "Validation Loss: 0.041520853\n",
      "Epoch: 1092 cost = 0.026147876\n",
      "Validation Loss: 0.040756095\n",
      "Epoch: 1093 cost = 0.026134004\n",
      "Validation Loss: 0.032314777\n",
      "Epoch: 1094 cost = 0.026120168\n",
      "Validation Loss: 0.030197438\n",
      "Epoch: 1095 cost = 0.026106181\n",
      "Validation Loss: 0.036246136\n",
      "Epoch: 1096 cost = 0.026092386\n",
      "Validation Loss: 0.03565291\n",
      "Epoch: 1097 cost = 0.026078481\n",
      "Validation Loss: 0.031560343\n",
      "Epoch: 1098 cost = 0.026064918\n",
      "Validation Loss: 0.031465996\n",
      "Epoch: 1099 cost = 0.026051281\n",
      "Validation Loss: 0.033330534\n",
      "Epoch: 1100 cost = 0.026037680\n",
      "Validation Loss: 0.035832934\n",
      "Epoch: 1101 cost = 0.026023989\n",
      "Validation Loss: 0.03873709\n",
      "Epoch: 1102 cost = 0.026010347\n",
      "Validation Loss: 0.04636664\n",
      "Epoch: 1103 cost = 0.025996849\n",
      "Validation Loss: 0.04236578\n",
      "Epoch: 1104 cost = 0.025983230\n",
      "Validation Loss: 0.05682975\n",
      "Epoch: 1105 cost = 0.025969448\n",
      "Validation Loss: 0.056124486\n",
      "Epoch: 1106 cost = 0.025956179\n",
      "Validation Loss: 0.05047056\n",
      "Epoch: 1107 cost = 0.025942612\n",
      "Validation Loss: 0.05225095\n",
      "Epoch: 1108 cost = 0.025929136\n",
      "Validation Loss: 0.045589633\n",
      "Epoch: 1109 cost = 0.025915988\n",
      "Validation Loss: 0.048132796\n",
      "Epoch: 1110 cost = 0.025902700\n",
      "Validation Loss: 0.045488216\n",
      "Epoch: 1111 cost = 0.025889377\n",
      "Validation Loss: 0.044281956\n",
      "Epoch: 1112 cost = 0.025876024\n",
      "Validation Loss: 0.054667223\n",
      "Epoch: 1113 cost = 0.025862935\n",
      "Validation Loss: 0.055259272\n",
      "Epoch: 1114 cost = 0.025849514\n",
      "Validation Loss: 0.050122265\n",
      "Epoch: 1115 cost = 0.025836463\n",
      "Validation Loss: 0.06421445\n",
      "Epoch: 1116 cost = 0.025823180\n",
      "Validation Loss: 0.05417843\n",
      "Epoch: 1117 cost = 0.025810165\n",
      "Validation Loss: 0.047562853\n",
      "Epoch: 1118 cost = 0.025797129\n",
      "Validation Loss: 0.036727678\n",
      "Epoch: 1119 cost = 0.025783983\n",
      "Validation Loss: 0.037599698\n",
      "Epoch: 1120 cost = 0.025770902\n",
      "Validation Loss: 0.03535406\n",
      "Epoch: 1121 cost = 0.025757884\n",
      "Validation Loss: 0.048799187\n",
      "Epoch: 1122 cost = 0.025745103\n",
      "Validation Loss: 0.06946296\n",
      "Epoch: 1123 cost = 0.025732030\n",
      "Validation Loss: 0.048438236\n",
      "Epoch: 1124 cost = 0.025719054\n",
      "Validation Loss: 0.038008653\n",
      "Epoch: 1125 cost = 0.025706313\n",
      "Validation Loss: 0.034353368\n",
      "Epoch: 1126 cost = 0.025693478\n",
      "Validation Loss: 0.04250938\n",
      "Epoch: 1127 cost = 0.025680698\n",
      "Validation Loss: 0.05082849\n",
      "Epoch: 1128 cost = 0.025667877\n",
      "Validation Loss: 0.04672404\n",
      "Epoch: 1129 cost = 0.025655209\n",
      "Validation Loss: 0.03788743\n",
      "Epoch: 1130 cost = 0.025642363\n",
      "Validation Loss: 0.03993637\n",
      "Epoch: 1131 cost = 0.025629858\n",
      "Validation Loss: 0.038762305\n",
      "Epoch: 1132 cost = 0.025617340\n",
      "Validation Loss: 0.035546605\n",
      "Epoch: 1133 cost = 0.025604627\n",
      "Validation Loss: 0.040736884\n",
      "Epoch: 1134 cost = 0.025591828\n",
      "Validation Loss: 0.035988323\n",
      "Epoch: 1135 cost = 0.025579325\n",
      "Validation Loss: 0.04471455\n",
      "Epoch: 1136 cost = 0.025567004\n",
      "Validation Loss: 0.054800663\n",
      "Epoch: 1137 cost = 0.025554447\n",
      "Validation Loss: 0.06410428\n",
      "Epoch: 1138 cost = 0.025542036\n",
      "Validation Loss: 0.05054699\n",
      "Epoch: 1139 cost = 0.025529397\n",
      "Validation Loss: 0.047813777\n",
      "Epoch: 1140 cost = 0.025516931\n",
      "Validation Loss: 0.038361814\n",
      "Epoch: 1141 cost = 0.025504689\n",
      "Validation Loss: 0.043528013\n",
      "Epoch: 1142 cost = 0.025492267\n",
      "Validation Loss: 0.032536253\n",
      "Epoch: 1143 cost = 0.025479940\n",
      "Validation Loss: 0.03403189\n",
      "Epoch: 1144 cost = 0.025467694\n",
      "Validation Loss: 0.032248832\n",
      "Epoch: 1145 cost = 0.025455503\n",
      "Validation Loss: 0.040068183\n",
      "Epoch: 1146 cost = 0.025443136\n",
      "Validation Loss: 0.036217246\n",
      "Epoch: 1147 cost = 0.025431179\n",
      "Validation Loss: 0.035542835\n",
      "Epoch: 1148 cost = 0.025418754\n",
      "Validation Loss: 0.03505366\n",
      "Epoch: 1149 cost = 0.025406682\n",
      "Validation Loss: 0.037403215\n",
      "Epoch: 1150 cost = 0.025394462\n",
      "Validation Loss: 0.032166176\n",
      "Epoch: 1151 cost = 0.025382323\n",
      "Validation Loss: 0.037058663\n",
      "Epoch: 1152 cost = 0.025370463\n",
      "Validation Loss: 0.038698643\n",
      "Epoch: 1153 cost = 0.025358516\n",
      "Validation Loss: 0.031864684\n",
      "Epoch: 1154 cost = 0.025346475\n",
      "Validation Loss: 0.032137584\n",
      "Epoch: 1155 cost = 0.025334525\n",
      "Validation Loss: 0.028648987\n",
      "Epoch: 1156 cost = 0.025322354\n",
      "Validation Loss: 0.0417383\n",
      "Epoch: 1157 cost = 0.025310534\n",
      "Validation Loss: 0.044431336\n",
      "Epoch: 1158 cost = 0.025298580\n",
      "Validation Loss: 0.02878445\n",
      "Epoch: 1159 cost = 0.025286665\n",
      "Validation Loss: 0.027315237\n",
      "Epoch: 1160 cost = 0.025274704\n",
      "Validation Loss: 0.07444595\n",
      "Epoch: 1161 cost = 0.025263084\n",
      "Validation Loss: 0.032919705\n",
      "Epoch: 1162 cost = 0.025251250\n",
      "Validation Loss: 0.031953618\n",
      "Epoch: 1163 cost = 0.025239589\n",
      "Validation Loss: 0.036612995\n",
      "Epoch: 1164 cost = 0.025227740\n",
      "Validation Loss: 0.04509848\n",
      "Epoch: 1165 cost = 0.025216028\n",
      "Validation Loss: 0.04551698\n",
      "Epoch: 1166 cost = 0.025204294\n",
      "Validation Loss: 0.040978406\n",
      "Epoch: 1167 cost = 0.025192721\n",
      "Validation Loss: 0.04085627\n",
      "Epoch: 1168 cost = 0.025181045\n",
      "Validation Loss: 0.03772365\n",
      "Epoch: 1169 cost = 0.025169464\n",
      "Validation Loss: 0.033790078\n",
      "Epoch: 1170 cost = 0.025157939\n",
      "Validation Loss: 0.037087034\n",
      "Epoch: 1171 cost = 0.025146262\n",
      "Validation Loss: 0.04041789\n",
      "Epoch: 1172 cost = 0.025134680\n",
      "Validation Loss: 0.042980324\n",
      "Epoch: 1173 cost = 0.025123231\n",
      "Validation Loss: 0.048799023\n",
      "Epoch: 1174 cost = 0.025111817\n",
      "Validation Loss: 0.046710633\n",
      "Epoch: 1175 cost = 0.025100359\n",
      "Validation Loss: 0.050930656\n",
      "Epoch: 1176 cost = 0.025088782\n",
      "Validation Loss: 0.044573404\n",
      "Epoch: 1177 cost = 0.025077420\n",
      "Validation Loss: 0.039604686\n",
      "Epoch: 1178 cost = 0.025066112\n",
      "Validation Loss: 0.040448703\n",
      "Epoch: 1179 cost = 0.025054804\n",
      "Validation Loss: 0.046287343\n",
      "Epoch: 1180 cost = 0.025043365\n",
      "Validation Loss: 0.038613133\n",
      "Epoch: 1181 cost = 0.025032054\n",
      "Validation Loss: 0.030422045\n",
      "Epoch: 1182 cost = 0.025020797\n",
      "Validation Loss: 0.029446423\n",
      "Epoch: 1183 cost = 0.025009534\n",
      "Validation Loss: 0.02949546\n",
      "Epoch: 1184 cost = 0.024998502\n",
      "Validation Loss: 0.034278523\n",
      "Epoch: 1185 cost = 0.024986999\n",
      "Validation Loss: 0.044808395\n",
      "Epoch: 1186 cost = 0.024975938\n",
      "Validation Loss: 0.03687061\n",
      "Epoch: 1187 cost = 0.024964745\n",
      "Validation Loss: 0.03503002\n",
      "Epoch: 1188 cost = 0.024953402\n",
      "Validation Loss: 0.04179176\n",
      "Epoch: 1189 cost = 0.024942519\n",
      "Validation Loss: 0.06492189\n",
      "Epoch: 1190 cost = 0.024931133\n",
      "Validation Loss: 0.058896612\n",
      "Epoch: 1191 cost = 0.024920246\n",
      "Validation Loss: 0.073365234\n",
      "Epoch: 1192 cost = 0.024909241\n",
      "Validation Loss: 0.07543531\n",
      "Epoch: 1193 cost = 0.024898299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.050838154\n",
      "Epoch: 1194 cost = 0.024887108\n",
      "Validation Loss: 0.047727313\n",
      "Epoch: 1195 cost = 0.024876087\n",
      "Validation Loss: 0.044641692\n",
      "Epoch: 1196 cost = 0.024865261\n",
      "Validation Loss: 0.05275309\n",
      "Epoch: 1197 cost = 0.024854417\n",
      "Validation Loss: 0.06013615\n",
      "Epoch: 1198 cost = 0.024843413\n",
      "Validation Loss: 0.048616305\n",
      "Epoch: 1199 cost = 0.024832618\n",
      "Validation Loss: 0.039225273\n",
      "Epoch: 1200 cost = 0.024821767\n",
      "Validation Loss: 0.03550901\n",
      "Epoch: 1201 cost = 0.024810775\n",
      "Validation Loss: 0.036418714\n",
      "Epoch: 1202 cost = 0.024799925\n",
      "Validation Loss: 0.03171898\n",
      "Epoch: 1203 cost = 0.024789186\n",
      "Validation Loss: 0.031865276\n",
      "Epoch: 1204 cost = 0.024778486\n",
      "Validation Loss: 0.04307001\n",
      "Epoch: 1205 cost = 0.024767645\n",
      "Validation Loss: 0.055978455\n",
      "Epoch: 1206 cost = 0.024756745\n",
      "Validation Loss: 0.048607215\n",
      "Epoch: 1207 cost = 0.024746196\n",
      "Validation Loss: 0.048457235\n",
      "Epoch: 1208 cost = 0.024735461\n",
      "Validation Loss: 0.03912539\n",
      "Epoch: 1209 cost = 0.024724800\n",
      "Validation Loss: 0.047310594\n",
      "Epoch: 1210 cost = 0.024714109\n",
      "Validation Loss: 0.049783606\n",
      "Epoch: 1211 cost = 0.024703671\n",
      "Validation Loss: 0.049658168\n",
      "Epoch: 1212 cost = 0.024692976\n",
      "Validation Loss: 0.043176997\n",
      "Epoch: 1213 cost = 0.024682309\n",
      "Validation Loss: 0.039910372\n",
      "Epoch: 1214 cost = 0.024671920\n",
      "Validation Loss: 0.03859482\n",
      "Epoch: 1215 cost = 0.024661100\n",
      "Validation Loss: 0.039282467\n",
      "Epoch: 1216 cost = 0.024650592\n",
      "Validation Loss: 0.04173173\n",
      "Epoch: 1217 cost = 0.024640109\n",
      "Validation Loss: 0.045513432\n",
      "Epoch: 1218 cost = 0.024629733\n",
      "Validation Loss: 0.04059828\n",
      "Epoch: 1219 cost = 0.024619257\n",
      "Validation Loss: 0.025415612\n",
      "Epoch: 1220 cost = 0.024609024\n",
      "Validation Loss: 0.07225169\n",
      "Epoch: 1221 cost = 0.024598524\n",
      "Validation Loss: 0.042439226\n",
      "Epoch: 1222 cost = 0.024588026\n",
      "Validation Loss: 0.048880424\n",
      "Epoch: 1223 cost = 0.024577587\n",
      "Validation Loss: 0.05332928\n",
      "Epoch: 1224 cost = 0.024567184\n",
      "Validation Loss: 0.04396676\n",
      "Epoch: 1225 cost = 0.024556985\n",
      "Validation Loss: 0.071206234\n",
      "Epoch: 1226 cost = 0.024546702\n",
      "Validation Loss: 0.065966405\n",
      "Epoch: 1227 cost = 0.024536408\n",
      "Validation Loss: 0.059681255\n",
      "Epoch: 1228 cost = 0.024526190\n",
      "Validation Loss: 0.04789528\n",
      "Epoch: 1229 cost = 0.024515951\n",
      "Validation Loss: 0.02580742\n",
      "Epoch: 1230 cost = 0.024505520\n",
      "Validation Loss: 0.0416142\n",
      "Epoch: 1231 cost = 0.024495457\n",
      "Validation Loss: 0.052729666\n",
      "Epoch: 1232 cost = 0.024485096\n",
      "Validation Loss: 0.036045108\n",
      "Epoch: 1233 cost = 0.024475153\n",
      "Validation Loss: 0.036748588\n",
      "Epoch: 1234 cost = 0.024465076\n",
      "Validation Loss: 0.044284333\n",
      "Epoch: 1235 cost = 0.024454707\n",
      "Validation Loss: 0.0334123\n",
      "Epoch: 1236 cost = 0.024444777\n",
      "Validation Loss: 0.040937062\n",
      "Epoch: 1237 cost = 0.024434581\n",
      "Validation Loss: 0.035326447\n",
      "Epoch: 1238 cost = 0.024424686\n",
      "Validation Loss: 0.04164999\n",
      "Epoch: 1239 cost = 0.024414354\n",
      "Validation Loss: 0.04099949\n",
      "Epoch: 1240 cost = 0.024404592\n",
      "Validation Loss: 0.03707872\n",
      "Epoch: 1241 cost = 0.024394604\n",
      "Validation Loss: 0.044350978\n",
      "Epoch: 1242 cost = 0.024384434\n",
      "Validation Loss: 0.046349604\n",
      "Epoch: 1243 cost = 0.024374598\n",
      "Validation Loss: 0.033306427\n",
      "Epoch: 1244 cost = 0.024364589\n",
      "Validation Loss: 0.038582765\n",
      "Epoch: 1245 cost = 0.024354483\n",
      "Validation Loss: 0.046184503\n",
      "Epoch: 1246 cost = 0.024344777\n",
      "Validation Loss: 0.049277678\n",
      "Epoch: 1247 cost = 0.024334823\n",
      "Validation Loss: 0.038551576\n",
      "Epoch: 1248 cost = 0.024325021\n",
      "Validation Loss: 0.04461858\n",
      "Epoch: 1249 cost = 0.024315273\n",
      "Validation Loss: 0.05073499\n",
      "Epoch: 1250 cost = 0.024305372\n",
      "Validation Loss: 0.047136307\n",
      "Epoch: 1251 cost = 0.024295469\n",
      "Validation Loss: 0.043860156\n",
      "Epoch: 1252 cost = 0.024285723\n",
      "Validation Loss: 0.043200433\n",
      "Epoch: 1253 cost = 0.024276039\n",
      "Validation Loss: 0.040218253\n",
      "Epoch: 1254 cost = 0.024266223\n",
      "Validation Loss: 0.049957242\n",
      "Epoch: 1255 cost = 0.024256617\n",
      "Validation Loss: 0.035553474\n",
      "Epoch: 1256 cost = 0.024246980\n",
      "Validation Loss: 0.035258226\n",
      "Epoch: 1257 cost = 0.024237282\n",
      "Validation Loss: 0.033012144\n",
      "Epoch: 1258 cost = 0.024227574\n",
      "Validation Loss: 0.032954823\n",
      "Epoch: 1259 cost = 0.024217787\n",
      "Validation Loss: 0.03759001\n",
      "Epoch: 1260 cost = 0.024208276\n",
      "Validation Loss: 0.046332244\n",
      "Epoch: 1261 cost = 0.024198611\n",
      "Validation Loss: 0.059851274\n",
      "Epoch: 1262 cost = 0.024189064\n",
      "Validation Loss: 0.053515222\n",
      "Epoch: 1263 cost = 0.024179528\n",
      "Validation Loss: 0.049373064\n",
      "Epoch: 1264 cost = 0.024170163\n",
      "Validation Loss: 0.041072503\n",
      "Epoch: 1265 cost = 0.024160565\n",
      "Validation Loss: 0.040002976\n",
      "Epoch: 1266 cost = 0.024151091\n",
      "Validation Loss: 0.048550658\n",
      "Epoch: 1267 cost = 0.024141418\n",
      "Validation Loss: 0.04369529\n",
      "Epoch: 1268 cost = 0.024132120\n",
      "Validation Loss: 0.0484042\n",
      "Epoch: 1269 cost = 0.024122510\n",
      "Validation Loss: 0.039184675\n",
      "Epoch: 1270 cost = 0.024113240\n",
      "Validation Loss: 0.04813426\n",
      "Epoch: 1271 cost = 0.024103744\n",
      "Validation Loss: 0.048330586\n",
      "Epoch: 1272 cost = 0.024094429\n",
      "Validation Loss: 0.03927597\n",
      "Epoch: 1273 cost = 0.024084915\n",
      "Validation Loss: 0.03961971\n",
      "Epoch: 1274 cost = 0.024075597\n",
      "Validation Loss: 0.054615136\n",
      "Epoch: 1275 cost = 0.024066379\n",
      "Validation Loss: 0.044892337\n",
      "Epoch: 1276 cost = 0.024057049\n",
      "Validation Loss: 0.035731845\n",
      "Epoch: 1277 cost = 0.024047714\n",
      "Validation Loss: 0.028159209\n",
      "Epoch: 1278 cost = 0.024038470\n",
      "Validation Loss: 0.031942222\n",
      "Epoch: 1279 cost = 0.024029077\n",
      "Validation Loss: 0.037976723\n",
      "Epoch: 1280 cost = 0.024020124\n",
      "Validation Loss: 0.057020105\n",
      "Epoch: 1281 cost = 0.024010718\n",
      "Validation Loss: 0.06732442\n",
      "Epoch: 1282 cost = 0.024001650\n",
      "Validation Loss: 0.06324524\n",
      "Epoch: 1283 cost = 0.023992547\n",
      "Validation Loss: 0.049532782\n",
      "Epoch: 1284 cost = 0.023983277\n",
      "Validation Loss: 0.05043066\n",
      "Epoch: 1285 cost = 0.023974091\n",
      "Validation Loss: 0.03868293\n",
      "Epoch: 1286 cost = 0.023965131\n",
      "Validation Loss: 0.03364317\n",
      "Epoch: 1287 cost = 0.023956046\n",
      "Validation Loss: 0.045052793\n",
      "Epoch: 1288 cost = 0.023947032\n",
      "Validation Loss: 0.057502486\n",
      "Epoch: 1289 cost = 0.023937920\n",
      "Validation Loss: 0.049098905\n",
      "Epoch: 1290 cost = 0.023928620\n",
      "Validation Loss: 0.044631906\n",
      "Epoch: 1291 cost = 0.023919981\n",
      "Validation Loss: 0.043985564\n",
      "Epoch: 1292 cost = 0.023910786\n",
      "Validation Loss: 0.044482995\n",
      "Epoch: 1293 cost = 0.023901589\n",
      "Validation Loss: 0.053705156\n",
      "Epoch: 1294 cost = 0.023892913\n",
      "Validation Loss: 0.054758564\n",
      "Epoch: 1295 cost = 0.023883986\n",
      "Validation Loss: 0.035177607\n",
      "Epoch: 1296 cost = 0.023874902\n",
      "Validation Loss: 0.050056055\n",
      "Epoch: 1297 cost = 0.023866252\n",
      "Validation Loss: 0.06244002\n",
      "Epoch: 1298 cost = 0.023857225\n",
      "Validation Loss: 0.054949973\n",
      "Epoch: 1299 cost = 0.023848456\n",
      "Validation Loss: 0.0488662\n",
      "Epoch: 1300 cost = 0.023839600\n",
      "Validation Loss: 0.064458594\n",
      "Epoch: 1301 cost = 0.023830756\n",
      "Validation Loss: 0.056433253\n",
      "Epoch: 1302 cost = 0.023822067\n",
      "Validation Loss: 0.06068186\n",
      "Epoch: 1303 cost = 0.023813272\n",
      "Validation Loss: 0.066867724\n",
      "Epoch: 1304 cost = 0.023804497\n",
      "Validation Loss: 0.06351013\n",
      "Epoch: 1305 cost = 0.023795547\n",
      "Validation Loss: 0.06411749\n",
      "Epoch: 1306 cost = 0.023787075\n",
      "Validation Loss: 0.057464372\n",
      "Epoch: 1307 cost = 0.023778228\n",
      "Validation Loss: 0.048017852\n",
      "Epoch: 1308 cost = 0.023769613\n",
      "Validation Loss: 0.04069508\n",
      "Epoch: 1309 cost = 0.023760980\n",
      "Validation Loss: 0.034965385\n",
      "Epoch: 1310 cost = 0.023752153\n",
      "Validation Loss: 0.029159378\n",
      "Epoch: 1311 cost = 0.023743547\n",
      "Validation Loss: 0.0370675\n",
      "Epoch: 1312 cost = 0.023735091\n",
      "Validation Loss: 0.036193375\n",
      "Epoch: 1313 cost = 0.023726636\n",
      "Validation Loss: 0.036210224\n",
      "Epoch: 1314 cost = 0.023717842\n",
      "Validation Loss: 0.030320382\n",
      "Epoch: 1315 cost = 0.023709336\n",
      "Validation Loss: 0.047447514\n",
      "Epoch: 1316 cost = 0.023701056\n",
      "Validation Loss: 0.043852016\n",
      "Epoch: 1317 cost = 0.023692582\n",
      "Validation Loss: 0.03518739\n",
      "Epoch: 1318 cost = 0.023684017\n",
      "Validation Loss: 0.034062896\n",
      "Epoch: 1319 cost = 0.023675483\n",
      "Validation Loss: 0.035588928\n",
      "Epoch: 1320 cost = 0.023666870\n",
      "Validation Loss: 0.031692795\n",
      "Epoch: 1321 cost = 0.023658600\n",
      "Validation Loss: 0.04168548\n",
      "Epoch: 1322 cost = 0.023650070\n",
      "Validation Loss: 0.03461431\n",
      "Epoch: 1323 cost = 0.023641818\n",
      "Validation Loss: 0.04264482\n",
      "Epoch: 1324 cost = 0.023633409\n",
      "Validation Loss: 0.044407908\n",
      "Epoch: 1325 cost = 0.023625070\n",
      "Validation Loss: 0.033515964\n",
      "Epoch: 1326 cost = 0.023616748\n",
      "Validation Loss: 0.030592287\n",
      "Epoch: 1327 cost = 0.023608341\n",
      "Validation Loss: 0.03311087\n",
      "Epoch: 1328 cost = 0.023600018\n",
      "Validation Loss: 0.040391292\n",
      "Epoch: 1329 cost = 0.023591749\n",
      "Validation Loss: 0.036830634\n",
      "Epoch: 1330 cost = 0.023583642\n",
      "Validation Loss: 0.03733776\n",
      "Epoch: 1331 cost = 0.023575183\n",
      "Validation Loss: 0.041640744\n",
      "Epoch: 1332 cost = 0.023567058\n",
      "Validation Loss: 0.031048587\n",
      "Epoch: 1333 cost = 0.023558966\n",
      "Validation Loss: 0.028124178\n",
      "Epoch: 1334 cost = 0.023550691\n",
      "Validation Loss: 0.031650975\n",
      "Epoch: 1335 cost = 0.023542405\n",
      "Validation Loss: 0.0412607\n",
      "Epoch: 1336 cost = 0.023534421\n",
      "Validation Loss: 0.041899692\n",
      "Epoch: 1337 cost = 0.023526447\n",
      "Validation Loss: 0.04558089\n",
      "Epoch: 1338 cost = 0.023517990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.031243654\n",
      "Epoch: 1339 cost = 0.023510162\n",
      "Validation Loss: 0.04064421\n",
      "Epoch: 1340 cost = 0.023501764\n",
      "Validation Loss: 0.045547012\n",
      "Epoch: 1341 cost = 0.023494049\n",
      "Validation Loss: 0.028494395\n",
      "Epoch: 1342 cost = 0.023485762\n",
      "Validation Loss: 0.03996324\n",
      "Epoch: 1343 cost = 0.023477802\n",
      "Validation Loss: 0.07150022\n",
      "Epoch: 1344 cost = 0.023469867\n",
      "Validation Loss: 0.043160338\n",
      "Epoch: 1345 cost = 0.023461860\n",
      "Validation Loss: 0.044156298\n",
      "Epoch: 1346 cost = 0.023453877\n",
      "Validation Loss: 0.031866696\n",
      "Epoch: 1347 cost = 0.023445701\n",
      "Validation Loss: 0.032760486\n",
      "Epoch: 1348 cost = 0.023437941\n",
      "Validation Loss: 0.033735767\n",
      "Epoch: 1349 cost = 0.023430058\n",
      "Validation Loss: 0.034556482\n",
      "Epoch: 1350 cost = 0.023422185\n",
      "Validation Loss: 0.037719365\n",
      "Epoch: 1351 cost = 0.023414273\n",
      "Validation Loss: 0.045330327\n",
      "Epoch: 1352 cost = 0.023406518\n",
      "Validation Loss: 0.06341461\n",
      "Epoch: 1353 cost = 0.023398535\n",
      "Validation Loss: 0.07034405\n",
      "Epoch: 1354 cost = 0.023390728\n",
      "Validation Loss: 0.04332246\n",
      "Epoch: 1355 cost = 0.023382924\n",
      "Validation Loss: 0.028669434\n",
      "Epoch: 1356 cost = 0.023375226\n",
      "Validation Loss: 0.024564022\n",
      "Epoch: 1357 cost = 0.023367475\n",
      "Validation Loss: 0.06523878\n",
      "Epoch: 1358 cost = 0.023359758\n",
      "Validation Loss: 0.04120461\n",
      "Epoch: 1359 cost = 0.023351968\n",
      "Validation Loss: 0.037481725\n",
      "Epoch: 1360 cost = 0.023344044\n",
      "Validation Loss: 0.0368698\n",
      "Epoch: 1361 cost = 0.023336557\n",
      "Validation Loss: 0.029849827\n",
      "Epoch: 1362 cost = 0.023328637\n",
      "Validation Loss: 0.030694207\n",
      "Epoch: 1363 cost = 0.023321180\n",
      "Validation Loss: 0.030902347\n",
      "Epoch: 1364 cost = 0.023313473\n",
      "Validation Loss: 0.03881092\n",
      "Epoch: 1365 cost = 0.023305701\n",
      "Validation Loss: 0.029092658\n",
      "Epoch: 1366 cost = 0.023298172\n",
      "Validation Loss: 0.03133761\n",
      "Epoch: 1367 cost = 0.023290607\n",
      "Validation Loss: 0.0337177\n",
      "Epoch: 1368 cost = 0.023282906\n",
      "Validation Loss: 0.039778646\n",
      "Epoch: 1369 cost = 0.023275414\n",
      "Validation Loss: 0.043136954\n",
      "Epoch: 1370 cost = 0.023268017\n",
      "Validation Loss: 0.04641216\n",
      "Epoch: 1371 cost = 0.023260501\n",
      "Validation Loss: 0.05856632\n",
      "Epoch: 1372 cost = 0.023252870\n",
      "Validation Loss: 0.04610828\n",
      "Epoch: 1373 cost = 0.023245237\n",
      "Validation Loss: 0.037139304\n",
      "Epoch: 1374 cost = 0.023237840\n",
      "Validation Loss: 0.028043592\n",
      "Epoch: 1375 cost = 0.023230342\n",
      "Validation Loss: 0.034233794\n",
      "Epoch: 1376 cost = 0.023223097\n",
      "Validation Loss: 0.03673763\n",
      "Epoch: 1377 cost = 0.023215527\n",
      "Validation Loss: 0.045200996\n",
      "Epoch: 1378 cost = 0.023208196\n",
      "Validation Loss: 0.040955614\n",
      "Epoch: 1379 cost = 0.023200602\n",
      "Validation Loss: 0.029332964\n",
      "Epoch: 1380 cost = 0.023193176\n",
      "Validation Loss: 0.022802597\n",
      "Epoch: 1381 cost = 0.023185997\n",
      "Validation Loss: 0.072312705\n",
      "Epoch: 1382 cost = 0.023178590\n",
      "Validation Loss: 0.046841685\n",
      "Epoch: 1383 cost = 0.023171167\n",
      "Validation Loss: 0.04201922\n",
      "Epoch: 1384 cost = 0.023163769\n",
      "Validation Loss: 0.031640593\n",
      "Epoch: 1385 cost = 0.023156574\n",
      "Validation Loss: 0.040743668\n",
      "Epoch: 1386 cost = 0.023149422\n",
      "Validation Loss: 0.050546393\n",
      "Epoch: 1387 cost = 0.023142016\n",
      "Validation Loss: 0.035097376\n",
      "Epoch: 1388 cost = 0.023134873\n",
      "Validation Loss: 0.029393349\n",
      "Epoch: 1389 cost = 0.023127426\n",
      "Validation Loss: 0.026950764\n",
      "Epoch: 1390 cost = 0.023120373\n",
      "Validation Loss: 0.03080573\n",
      "Epoch: 1391 cost = 0.023112833\n",
      "Validation Loss: 0.05005809\n",
      "Epoch: 1392 cost = 0.023105933\n",
      "Validation Loss: 0.036153816\n",
      "Epoch: 1393 cost = 0.023098543\n",
      "Validation Loss: 0.033091486\n",
      "Epoch: 1394 cost = 0.023091390\n",
      "Validation Loss: 0.028463135\n",
      "Epoch: 1395 cost = 0.023084344\n",
      "Validation Loss: 0.044604626\n",
      "Epoch: 1396 cost = 0.023077215\n",
      "Validation Loss: 0.044573665\n",
      "Epoch: 1397 cost = 0.023069993\n",
      "Validation Loss: 0.03807453\n",
      "Epoch: 1398 cost = 0.023063014\n",
      "Validation Loss: 0.028303338\n",
      "Epoch: 1399 cost = 0.023055932\n",
      "Validation Loss: 0.024832435\n",
      "Epoch: 1400 cost = 0.023048764\n",
      "Validation Loss: 0.025440017\n",
      "Epoch: 1401 cost = 0.023041638\n",
      "Validation Loss: 0.03443287\n",
      "Epoch: 1402 cost = 0.023034522\n",
      "Validation Loss: 0.040102232\n",
      "Epoch: 1403 cost = 0.023027454\n",
      "Validation Loss: 0.053975675\n",
      "Epoch: 1404 cost = 0.023020724\n",
      "Validation Loss: 0.04305829\n",
      "Epoch: 1405 cost = 0.023013508\n",
      "Validation Loss: 0.041007064\n",
      "Epoch: 1406 cost = 0.023006653\n",
      "Validation Loss: 0.03857401\n",
      "Epoch: 1407 cost = 0.022999484\n",
      "Validation Loss: 0.048551667\n",
      "Epoch: 1408 cost = 0.022992506\n",
      "Validation Loss: 0.04427978\n",
      "Epoch: 1409 cost = 0.022985738\n",
      "Validation Loss: 0.038151916\n",
      "Epoch: 1410 cost = 0.022978773\n",
      "Validation Loss: 0.029993625\n",
      "Epoch: 1411 cost = 0.022971828\n",
      "Validation Loss: 0.041364066\n",
      "Epoch: 1412 cost = 0.022965006\n",
      "Validation Loss: 0.056641813\n",
      "Epoch: 1413 cost = 0.022958222\n",
      "Validation Loss: 0.06396553\n",
      "Epoch: 1414 cost = 0.022951311\n",
      "Validation Loss: 0.06836939\n",
      "Epoch: 1415 cost = 0.022944178\n",
      "Validation Loss: 0.059373904\n",
      "Epoch: 1416 cost = 0.022937354\n",
      "Validation Loss: 0.03258984\n",
      "Epoch: 1417 cost = 0.022930732\n",
      "Validation Loss: 0.02468316\n",
      "Epoch: 1418 cost = 0.022923801\n",
      "Validation Loss: 0.030637518\n",
      "Epoch: 1419 cost = 0.022917008\n",
      "Validation Loss: 0.033072453\n",
      "Epoch: 1420 cost = 0.022910160\n",
      "Validation Loss: 0.031282894\n",
      "Epoch: 1421 cost = 0.022903219\n",
      "Validation Loss: 0.028481737\n",
      "Epoch: 1422 cost = 0.022896601\n",
      "Validation Loss: 0.036437113\n",
      "Epoch: 1423 cost = 0.022889895\n",
      "Validation Loss: 0.056419335\n",
      "Epoch: 1424 cost = 0.022883111\n",
      "Validation Loss: 0.055819277\n",
      "Epoch: 1425 cost = 0.022876353\n",
      "Validation Loss: 0.058772083\n",
      "Epoch: 1426 cost = 0.022869626\n",
      "Validation Loss: 0.065684795\n",
      "Epoch: 1427 cost = 0.022863122\n",
      "Validation Loss: 0.059466094\n",
      "Epoch: 1428 cost = 0.022856421\n",
      "Validation Loss: 0.049507443\n",
      "Epoch: 1429 cost = 0.022849642\n",
      "Validation Loss: 0.04041923\n",
      "Epoch: 1430 cost = 0.022843013\n",
      "Validation Loss: 0.025845855\n",
      "Epoch: 1431 cost = 0.022836331\n",
      "Validation Loss: 0.04509657\n",
      "Epoch: 1432 cost = 0.022829811\n",
      "Validation Loss: 0.063033596\n",
      "Epoch: 1433 cost = 0.022823249\n",
      "Validation Loss: 0.054510657\n",
      "Epoch: 1434 cost = 0.022816389\n",
      "Validation Loss: 0.034319445\n",
      "Epoch: 1435 cost = 0.022809815\n",
      "Validation Loss: 0.024220852\n",
      "Epoch: 1436 cost = 0.022803352\n",
      "Validation Loss: 0.035149626\n",
      "Epoch: 1437 cost = 0.022796723\n",
      "Validation Loss: 0.03838774\n",
      "Epoch: 1438 cost = 0.022790397\n",
      "Validation Loss: 0.033134308\n",
      "Epoch: 1439 cost = 0.022783639\n",
      "Validation Loss: 0.032496214\n",
      "Epoch: 1440 cost = 0.022777047\n",
      "Validation Loss: 0.028847355\n",
      "Epoch: 1441 cost = 0.022770616\n",
      "Validation Loss: 0.028644951\n",
      "Epoch: 1442 cost = 0.022764109\n",
      "Validation Loss: 0.02630776\n",
      "Epoch: 1443 cost = 0.022757685\n",
      "Validation Loss: 0.0328785\n",
      "Epoch: 1444 cost = 0.022751150\n",
      "Validation Loss: 0.03527307\n",
      "Epoch: 1445 cost = 0.022744875\n",
      "Validation Loss: 0.036472745\n",
      "Epoch: 1446 cost = 0.022738150\n",
      "Validation Loss: 0.030601598\n",
      "Epoch: 1447 cost = 0.022731878\n",
      "Validation Loss: 0.023546431\n",
      "Epoch: 1448 cost = 0.022725428\n",
      "Validation Loss: 0.026152758\n",
      "Epoch: 1449 cost = 0.022719000\n",
      "Validation Loss: 0.03164866\n",
      "Epoch: 1450 cost = 0.022712838\n",
      "Validation Loss: 0.030191246\n",
      "Epoch: 1451 cost = 0.022706204\n",
      "Validation Loss: 0.038798634\n",
      "Epoch: 1452 cost = 0.022699794\n",
      "Validation Loss: 0.055279132\n",
      "Epoch: 1453 cost = 0.022693553\n",
      "Validation Loss: 0.062444296\n",
      "Epoch: 1454 cost = 0.022687384\n",
      "Validation Loss: 0.028206294\n",
      "Epoch: 1455 cost = 0.022680784\n",
      "Validation Loss: 0.034958612\n",
      "Epoch: 1456 cost = 0.022674428\n",
      "Validation Loss: 0.03476384\n",
      "Epoch: 1457 cost = 0.022668129\n",
      "Validation Loss: 0.030172521\n",
      "Epoch: 1458 cost = 0.022661687\n",
      "Validation Loss: 0.050397456\n",
      "Epoch: 1459 cost = 0.022655521\n",
      "Validation Loss: 0.034307282\n",
      "Epoch: 1460 cost = 0.022649355\n",
      "Validation Loss: 0.03208864\n",
      "Epoch: 1461 cost = 0.022642990\n",
      "Validation Loss: 0.047657214\n",
      "Epoch: 1462 cost = 0.022636845\n",
      "Validation Loss: 0.0640483\n",
      "Epoch: 1463 cost = 0.022630457\n",
      "Validation Loss: 0.060578678\n",
      "Epoch: 1464 cost = 0.022624534\n",
      "Validation Loss: 0.063418105\n",
      "Epoch: 1465 cost = 0.022618028\n",
      "Validation Loss: 0.050533276\n",
      "Epoch: 1466 cost = 0.022611832\n",
      "Validation Loss: 0.041137397\n",
      "Epoch: 1467 cost = 0.022605703\n",
      "Validation Loss: 0.020671494\n",
      "Epoch: 1468 cost = 0.022599525\n",
      "Validation Loss: 0.07423756\n",
      "Epoch: 1469 cost = 0.022593329\n",
      "Validation Loss: 0.03303274\n",
      "Epoch: 1470 cost = 0.022587101\n",
      "Validation Loss: 0.02741894\n",
      "Epoch: 1471 cost = 0.022581106\n",
      "Validation Loss: 0.03212519\n",
      "Epoch: 1472 cost = 0.022574929\n",
      "Validation Loss: 0.038031686\n",
      "Epoch: 1473 cost = 0.022568786\n",
      "Validation Loss: 0.035044607\n",
      "Epoch: 1474 cost = 0.022562462\n",
      "Validation Loss: 0.03331647\n",
      "Epoch: 1475 cost = 0.022556483\n",
      "Validation Loss: 0.032661065\n",
      "Epoch: 1476 cost = 0.022550457\n",
      "Validation Loss: 0.025058812\n",
      "Epoch: 1477 cost = 0.022544094\n",
      "Validation Loss: 0.027337516\n",
      "Epoch: 1478 cost = 0.022538367\n",
      "Validation Loss: 0.029213868\n",
      "Epoch: 1479 cost = 0.022532262\n",
      "Validation Loss: 0.04248494\n",
      "Epoch: 1480 cost = 0.022526051\n",
      "Validation Loss: 0.040020585\n",
      "Epoch: 1481 cost = 0.022520094\n",
      "Validation Loss: 0.043198016\n",
      "Epoch: 1482 cost = 0.022514086\n",
      "Validation Loss: 0.04797867\n",
      "Epoch: 1483 cost = 0.022507951\n",
      "Validation Loss: 0.033097528\n",
      "Epoch: 1484 cost = 0.022502188\n",
      "Validation Loss: 0.03570104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1485 cost = 0.022496171\n",
      "Validation Loss: 0.033091597\n",
      "Epoch: 1486 cost = 0.022490070\n",
      "Validation Loss: 0.036996078\n",
      "Epoch: 1487 cost = 0.022484047\n",
      "Validation Loss: 0.048561625\n",
      "Epoch: 1488 cost = 0.022478204\n",
      "Validation Loss: 0.058011316\n",
      "Epoch: 1489 cost = 0.022472333\n",
      "Validation Loss: 0.0587846\n",
      "Epoch: 1490 cost = 0.022466523\n",
      "Validation Loss: 0.0429042\n",
      "Epoch: 1491 cost = 0.022460543\n",
      "Validation Loss: 0.03137398\n",
      "Epoch: 1492 cost = 0.022454646\n",
      "Validation Loss: 0.03543616\n",
      "Epoch: 1493 cost = 0.022448491\n",
      "Validation Loss: 0.036322027\n",
      "Epoch: 1494 cost = 0.022442482\n",
      "Validation Loss: 0.026867338\n",
      "Epoch: 1495 cost = 0.022436757\n",
      "Validation Loss: 0.03091865\n",
      "Epoch: 1496 cost = 0.022430824\n",
      "Validation Loss: 0.048819672\n",
      "Epoch: 1497 cost = 0.022424977\n",
      "Validation Loss: 0.04474003\n",
      "Epoch: 1498 cost = 0.022419266\n",
      "Validation Loss: 0.031378917\n",
      "Epoch: 1499 cost = 0.022413293\n",
      "Validation Loss: 0.028484276\n",
      "Epoch: 1500 cost = 0.022407480\n",
      "Validation Loss: 0.027526774\n",
      "Epoch: 1501 cost = 0.022401499\n",
      "Validation Loss: 0.036980648\n",
      "Epoch: 1502 cost = 0.022395933\n",
      "Validation Loss: 0.03489142\n",
      "Epoch: 1503 cost = 0.022390140\n",
      "Validation Loss: 0.0315236\n",
      "Epoch: 1504 cost = 0.022384289\n",
      "Validation Loss: 0.03998604\n",
      "Epoch: 1505 cost = 0.022378561\n",
      "Validation Loss: 0.043011397\n",
      "Epoch: 1506 cost = 0.022372472\n",
      "Validation Loss: 0.05068107\n",
      "Epoch: 1507 cost = 0.022366802\n",
      "Validation Loss: 0.058679912\n",
      "Epoch: 1508 cost = 0.022361093\n",
      "Validation Loss: 0.05253787\n",
      "Epoch: 1509 cost = 0.022355320\n",
      "Validation Loss: 0.040263437\n",
      "Epoch: 1510 cost = 0.022349497\n",
      "Validation Loss: 0.041356355\n",
      "Epoch: 1511 cost = 0.022343780\n",
      "Validation Loss: 0.021761877\n",
      "Epoch: 1512 cost = 0.022338215\n",
      "Validation Loss: 0.028312406\n",
      "Epoch: 1513 cost = 0.022332600\n",
      "Validation Loss: 0.038315162\n",
      "Epoch: 1514 cost = 0.022326854\n",
      "Validation Loss: 0.029498916\n",
      "Epoch: 1515 cost = 0.022321193\n",
      "Validation Loss: 0.023388071\n",
      "Epoch: 1516 cost = 0.022315630\n",
      "Validation Loss: 0.02667964\n",
      "Epoch: 1517 cost = 0.022309994\n",
      "Validation Loss: 0.028019072\n",
      "Epoch: 1518 cost = 0.022304336\n",
      "Validation Loss: 0.04068726\n",
      "Epoch: 1519 cost = 0.022298526\n",
      "Validation Loss: 0.03298226\n",
      "Epoch: 1520 cost = 0.022292964\n",
      "Validation Loss: 0.05163634\n",
      "Epoch: 1521 cost = 0.022287161\n",
      "Validation Loss: 0.056588907\n",
      "Epoch: 1522 cost = 0.022281703\n",
      "Validation Loss: 0.050792787\n",
      "Epoch: 1523 cost = 0.022276122\n",
      "Validation Loss: 0.057204492\n",
      "Epoch: 1524 cost = 0.022270468\n",
      "Validation Loss: 0.032710228\n",
      "Epoch: 1525 cost = 0.022264844\n",
      "Validation Loss: 0.025910495\n",
      "Epoch: 1526 cost = 0.022259213\n",
      "Validation Loss: 0.042520244\n",
      "Epoch: 1527 cost = 0.022253838\n",
      "Validation Loss: 0.035740875\n",
      "Epoch: 1528 cost = 0.022248329\n",
      "Validation Loss: 0.02875594\n",
      "Epoch: 1529 cost = 0.022242573\n",
      "Validation Loss: 0.056008115\n",
      "Epoch: 1530 cost = 0.022237124\n",
      "Validation Loss: 0.04219643\n",
      "Epoch: 1531 cost = 0.022231633\n",
      "Validation Loss: 0.03649112\n",
      "Epoch: 1532 cost = 0.022226008\n",
      "Validation Loss: 0.02506071\n",
      "Epoch: 1533 cost = 0.022220649\n",
      "Validation Loss: 0.024971532\n",
      "Epoch: 1534 cost = 0.022215329\n",
      "Validation Loss: 0.04353707\n",
      "Epoch: 1535 cost = 0.022209639\n",
      "Validation Loss: 0.024985183\n",
      "Epoch: 1536 cost = 0.022204217\n",
      "Validation Loss: 0.033735298\n",
      "Epoch: 1537 cost = 0.022198505\n",
      "Validation Loss: 0.036009472\n",
      "Epoch: 1538 cost = 0.022193172\n",
      "Validation Loss: 0.033015814\n",
      "Epoch: 1539 cost = 0.022187577\n",
      "Validation Loss: 0.02671638\n",
      "Epoch: 1540 cost = 0.022182119\n",
      "Validation Loss: 0.029575888\n",
      "Epoch: 1541 cost = 0.022176763\n",
      "Validation Loss: 0.026364727\n",
      "Epoch: 1542 cost = 0.022171509\n",
      "Validation Loss: 0.033785395\n",
      "Epoch: 1543 cost = 0.022165856\n",
      "Validation Loss: 0.027553985\n",
      "Epoch: 1544 cost = 0.022160574\n",
      "Validation Loss: 0.021119181\n",
      "Epoch: 1545 cost = 0.022155094\n",
      "Validation Loss: 0.03924692\n",
      "Epoch: 1546 cost = 0.022149766\n",
      "Validation Loss: 0.03926629\n",
      "Epoch: 1547 cost = 0.022144302\n",
      "Validation Loss: 0.05042632\n",
      "Epoch: 1548 cost = 0.022139030\n",
      "Validation Loss: 0.05909677\n",
      "Epoch: 1549 cost = 0.022133637\n",
      "Validation Loss: 0.05134825\n",
      "Epoch: 1550 cost = 0.022128122\n",
      "Validation Loss: 0.035233058\n",
      "Epoch: 1551 cost = 0.022123024\n",
      "Validation Loss: 0.028874855\n",
      "Epoch: 1552 cost = 0.022117671\n",
      "Validation Loss: 0.03082874\n",
      "Epoch: 1553 cost = 0.022112041\n",
      "Validation Loss: 0.030190814\n",
      "Epoch: 1554 cost = 0.022107029\n",
      "Validation Loss: 0.025467275\n",
      "Epoch: 1555 cost = 0.022101611\n",
      "Validation Loss: 0.0378839\n",
      "Epoch: 1556 cost = 0.022096425\n",
      "Validation Loss: 0.059671618\n",
      "Epoch: 1557 cost = 0.022090913\n",
      "Validation Loss: 0.06725825\n",
      "Epoch: 1558 cost = 0.022085857\n",
      "Validation Loss: 0.046980165\n",
      "Epoch: 1559 cost = 0.022080431\n",
      "Validation Loss: 0.047098387\n",
      "Epoch: 1560 cost = 0.022075306\n",
      "Validation Loss: 0.032643933\n",
      "Epoch: 1561 cost = 0.022070053\n",
      "Validation Loss: 0.032225\n",
      "Epoch: 1562 cost = 0.022064773\n",
      "Validation Loss: 0.030974936\n",
      "Epoch: 1563 cost = 0.022059398\n",
      "Validation Loss: 0.029590528\n",
      "Epoch: 1564 cost = 0.022054224\n",
      "Validation Loss: 0.03448726\n",
      "Epoch: 1565 cost = 0.022048887\n",
      "Validation Loss: 0.032255456\n",
      "Epoch: 1566 cost = 0.022043825\n",
      "Validation Loss: 0.026165817\n",
      "Epoch: 1567 cost = 0.022038416\n",
      "Validation Loss: 0.03913596\n",
      "Epoch: 1568 cost = 0.022033297\n",
      "Validation Loss: 0.03223588\n",
      "Epoch: 1569 cost = 0.022028167\n",
      "Validation Loss: 0.028129406\n",
      "Epoch: 1570 cost = 0.022022832\n",
      "Validation Loss: 0.03388925\n",
      "Epoch: 1571 cost = 0.022017793\n",
      "Validation Loss: 0.045065343\n",
      "Epoch: 1572 cost = 0.022012390\n",
      "Validation Loss: 0.042667925\n",
      "Epoch: 1573 cost = 0.022007456\n",
      "Validation Loss: 0.044400122\n",
      "Epoch: 1574 cost = 0.022002197\n",
      "Validation Loss: 0.058636237\n",
      "Epoch: 1575 cost = 0.021997028\n",
      "Validation Loss: 0.053481624\n",
      "Epoch: 1576 cost = 0.021992063\n",
      "Validation Loss: 0.041180454\n",
      "Epoch: 1577 cost = 0.021986827\n",
      "Validation Loss: 0.055269763\n",
      "Epoch: 1578 cost = 0.021981742\n",
      "Validation Loss: 0.05926584\n",
      "Epoch: 1579 cost = 0.021976577\n",
      "Validation Loss: 0.051795542\n",
      "Epoch: 1580 cost = 0.021971475\n",
      "Validation Loss: 0.04205435\n",
      "Epoch: 1581 cost = 0.021966510\n",
      "Validation Loss: 0.05317318\n",
      "Epoch: 1582 cost = 0.021961137\n",
      "Validation Loss: 0.048921302\n",
      "Epoch: 1583 cost = 0.021956060\n",
      "Validation Loss: 0.03438138\n",
      "Epoch: 1584 cost = 0.021951265\n",
      "Validation Loss: 0.039652053\n",
      "Epoch: 1585 cost = 0.021945937\n",
      "Validation Loss: 0.03591672\n",
      "Epoch: 1586 cost = 0.021940961\n",
      "Validation Loss: 0.038041066\n",
      "Epoch: 1587 cost = 0.021935980\n",
      "Validation Loss: 0.041916635\n",
      "Epoch: 1588 cost = 0.021931047\n",
      "Validation Loss: 0.04356581\n",
      "Epoch: 1589 cost = 0.021926016\n",
      "Validation Loss: 0.042276897\n",
      "Epoch: 1590 cost = 0.021920808\n",
      "Validation Loss: 0.047501706\n",
      "Epoch: 1591 cost = 0.021915812\n",
      "Validation Loss: 0.05189096\n",
      "Epoch: 1592 cost = 0.021910904\n",
      "Validation Loss: 0.043016277\n",
      "Epoch: 1593 cost = 0.021905907\n",
      "Validation Loss: 0.042829115\n",
      "Epoch: 1594 cost = 0.021900951\n",
      "Validation Loss: 0.042446606\n",
      "Epoch: 1595 cost = 0.021895798\n",
      "Validation Loss: 0.03863358\n",
      "Epoch: 1596 cost = 0.021890927\n",
      "Validation Loss: 0.029661749\n",
      "Epoch: 1597 cost = 0.021886004\n",
      "Validation Loss: 0.021615967\n",
      "Epoch: 1598 cost = 0.021880781\n",
      "Validation Loss: 0.033832625\n",
      "Epoch: 1599 cost = 0.021876007\n",
      "Validation Loss: 0.022935903\n",
      "Epoch: 1600 cost = 0.021870924\n",
      "Validation Loss: 0.028040104\n",
      "Epoch: 1601 cost = 0.021866137\n",
      "Validation Loss: 0.04473759\n",
      "Epoch: 1602 cost = 0.021860992\n",
      "Validation Loss: 0.04675138\n",
      "Epoch: 1603 cost = 0.021856316\n",
      "Validation Loss: 0.029552516\n",
      "Epoch: 1604 cost = 0.021851327\n",
      "Validation Loss: 0.031511273\n",
      "Epoch: 1605 cost = 0.021846527\n",
      "Validation Loss: 0.03380162\n",
      "Epoch: 1606 cost = 0.021841393\n",
      "Validation Loss: 0.043401137\n",
      "Epoch: 1607 cost = 0.021836576\n",
      "Validation Loss: 0.032539915\n",
      "Epoch: 1608 cost = 0.021831621\n",
      "Validation Loss: 0.032249607\n",
      "Epoch: 1609 cost = 0.021826684\n",
      "Validation Loss: 0.046457045\n",
      "Epoch: 1610 cost = 0.021821820\n",
      "Validation Loss: 0.041520033\n",
      "Epoch: 1611 cost = 0.021816911\n",
      "Validation Loss: 0.038341798\n",
      "Epoch: 1612 cost = 0.021812362\n",
      "Validation Loss: 0.05297061\n",
      "Epoch: 1613 cost = 0.021807499\n",
      "Validation Loss: 0.064090736\n",
      "Epoch: 1614 cost = 0.021802450\n",
      "Validation Loss: 0.056950003\n",
      "Epoch: 1615 cost = 0.021797749\n",
      "Validation Loss: 0.054148678\n",
      "Epoch: 1616 cost = 0.021792651\n",
      "Validation Loss: 0.050226394\n",
      "Epoch: 1617 cost = 0.021787937\n",
      "Validation Loss: 0.04744923\n",
      "Epoch: 1618 cost = 0.021783088\n",
      "Validation Loss: 0.054484043\n",
      "Epoch: 1619 cost = 0.021778446\n",
      "Validation Loss: 0.055482134\n",
      "Epoch: 1620 cost = 0.021773480\n",
      "Validation Loss: 0.04852778\n",
      "Epoch: 1621 cost = 0.021768806\n",
      "Validation Loss: 0.03584128\n",
      "Epoch: 1622 cost = 0.021764145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.033007916\n",
      "Epoch: 1623 cost = 0.021759269\n",
      "Validation Loss: 0.04377558\n",
      "Epoch: 1624 cost = 0.021754233\n",
      "Validation Loss: 0.03861947\n",
      "Epoch: 1625 cost = 0.021749706\n",
      "Validation Loss: 0.03648449\n",
      "Epoch: 1626 cost = 0.021744928\n",
      "Validation Loss: 0.036885325\n",
      "Epoch: 1627 cost = 0.021740245\n",
      "Validation Loss: 0.03493225\n",
      "Epoch: 1628 cost = 0.021735456\n",
      "Validation Loss: 0.048924547\n",
      "Epoch: 1629 cost = 0.021730628\n",
      "Validation Loss: 0.035519596\n",
      "Epoch: 1630 cost = 0.021725848\n",
      "Validation Loss: 0.042523444\n",
      "Epoch: 1631 cost = 0.021721007\n",
      "Validation Loss: 0.045923367\n",
      "Epoch: 1632 cost = 0.021716413\n",
      "Validation Loss: 0.04175393\n",
      "Epoch: 1633 cost = 0.021711479\n",
      "Validation Loss: 0.038007326\n",
      "Epoch: 1634 cost = 0.021706862\n",
      "Validation Loss: 0.045263205\n",
      "Epoch: 1635 cost = 0.021702528\n",
      "Validation Loss: 0.03780904\n",
      "Epoch: 1636 cost = 0.021697587\n",
      "Validation Loss: 0.036104728\n",
      "Epoch: 1637 cost = 0.021692657\n",
      "Validation Loss: 0.049128324\n",
      "Epoch: 1638 cost = 0.021688202\n",
      "Validation Loss: 0.03985566\n",
      "Epoch: 1639 cost = 0.021683762\n",
      "Validation Loss: 0.042256977\n",
      "Epoch: 1640 cost = 0.021678910\n",
      "Validation Loss: 0.05957408\n",
      "Epoch: 1641 cost = 0.021674062\n",
      "Validation Loss: 0.060900472\n",
      "Epoch: 1642 cost = 0.021669745\n",
      "Validation Loss: 0.03905347\n",
      "Epoch: 1643 cost = 0.021664855\n",
      "Validation Loss: 0.029127633\n",
      "Epoch: 1644 cost = 0.021660337\n",
      "Validation Loss: 0.03606573\n",
      "Epoch: 1645 cost = 0.021655568\n",
      "Validation Loss: 0.037054405\n",
      "Epoch: 1646 cost = 0.021651201\n",
      "Validation Loss: 0.037584867\n",
      "Epoch: 1647 cost = 0.021646309\n",
      "Validation Loss: 0.038995273\n",
      "Epoch: 1648 cost = 0.021641856\n",
      "Validation Loss: 0.051102523\n",
      "Epoch: 1649 cost = 0.021637142\n",
      "Validation Loss: 0.044045225\n",
      "Epoch: 1650 cost = 0.021632694\n",
      "Validation Loss: 0.03483477\n",
      "Epoch: 1651 cost = 0.021628004\n",
      "Validation Loss: 0.031952444\n",
      "Epoch: 1652 cost = 0.021623190\n",
      "Validation Loss: 0.038819596\n",
      "Epoch: 1653 cost = 0.021618654\n",
      "Validation Loss: 0.0464156\n",
      "Epoch: 1654 cost = 0.021614089\n",
      "Validation Loss: 0.044460736\n",
      "Epoch: 1655 cost = 0.021609610\n",
      "Validation Loss: 0.03983384\n",
      "Epoch: 1656 cost = 0.021605054\n",
      "Validation Loss: 0.036176324\n",
      "Epoch: 1657 cost = 0.021600737\n",
      "Validation Loss: 0.0278571\n",
      "Epoch: 1658 cost = 0.021595922\n",
      "Validation Loss: 0.035281323\n",
      "Epoch: 1659 cost = 0.021591664\n",
      "Validation Loss: 0.054960497\n",
      "Epoch: 1660 cost = 0.021586824\n",
      "Validation Loss: 0.089449495\n",
      "Epoch: 1661 cost = 0.021582234\n",
      "Validation Loss: 0.053195544\n",
      "Epoch: 1662 cost = 0.021577734\n",
      "Validation Loss: 0.03284288\n",
      "Epoch: 1663 cost = 0.021573293\n",
      "Validation Loss: 0.032075897\n",
      "Epoch: 1664 cost = 0.021568651\n",
      "Validation Loss: 0.031397022\n",
      "Epoch: 1665 cost = 0.021564323\n",
      "Validation Loss: 0.033787675\n",
      "Epoch: 1666 cost = 0.021559950\n",
      "Validation Loss: 0.031544648\n",
      "Epoch: 1667 cost = 0.021555245\n",
      "Validation Loss: 0.038836937\n",
      "Epoch: 1668 cost = 0.021550861\n",
      "Validation Loss: 0.026338754\n",
      "Epoch: 1669 cost = 0.021546202\n",
      "Validation Loss: 0.02741912\n",
      "Epoch: 1670 cost = 0.021541914\n",
      "Validation Loss: 0.030476876\n",
      "Epoch: 1671 cost = 0.021537504\n",
      "Validation Loss: 0.038078643\n",
      "Epoch: 1672 cost = 0.021532877\n",
      "Validation Loss: 0.031126153\n",
      "Epoch: 1673 cost = 0.021528640\n",
      "Validation Loss: 0.02165724\n",
      "Epoch: 1674 cost = 0.021524009\n",
      "Validation Loss: 0.028434271\n",
      "Epoch: 1675 cost = 0.021519759\n",
      "Validation Loss: 0.037529245\n",
      "Epoch: 1676 cost = 0.021515223\n",
      "Validation Loss: 0.037610292\n",
      "Epoch: 1677 cost = 0.021510629\n",
      "Validation Loss: 0.03985751\n",
      "Epoch: 1678 cost = 0.021506295\n",
      "Validation Loss: 0.038291015\n",
      "Epoch: 1679 cost = 0.021501727\n",
      "Validation Loss: 0.036522876\n",
      "Epoch: 1680 cost = 0.021497349\n",
      "Validation Loss: 0.042609863\n",
      "Epoch: 1681 cost = 0.021493004\n",
      "Validation Loss: 0.033074822\n",
      "Epoch: 1682 cost = 0.021488460\n",
      "Validation Loss: 0.03015175\n",
      "Epoch: 1683 cost = 0.021484270\n",
      "Validation Loss: 0.037402526\n",
      "Epoch: 1684 cost = 0.021480028\n",
      "Validation Loss: 0.03425018\n",
      "Epoch: 1685 cost = 0.021475426\n",
      "Validation Loss: 0.05728789\n",
      "Epoch: 1686 cost = 0.021470916\n",
      "Validation Loss: 0.057144634\n",
      "Epoch: 1687 cost = 0.021466732\n",
      "Validation Loss: 0.043030992\n",
      "Epoch: 1688 cost = 0.021462237\n",
      "Validation Loss: 0.052339524\n",
      "Epoch: 1689 cost = 0.021457949\n",
      "Validation Loss: 0.04107697\n",
      "Epoch: 1690 cost = 0.021453454\n",
      "Validation Loss: 0.039168067\n",
      "Epoch: 1691 cost = 0.021449347\n",
      "Validation Loss: 0.037594933\n",
      "Epoch: 1692 cost = 0.021444948\n",
      "Validation Loss: 0.034078345\n",
      "Epoch: 1693 cost = 0.021440774\n",
      "Validation Loss: 0.041847017\n",
      "Epoch: 1694 cost = 0.021436335\n",
      "Validation Loss: 0.04144622\n",
      "Epoch: 1695 cost = 0.021431844\n",
      "Validation Loss: 0.039297316\n",
      "Epoch: 1696 cost = 0.021427748\n",
      "Validation Loss: 0.03274019\n",
      "Epoch: 1697 cost = 0.021423207\n",
      "Validation Loss: 0.03328465\n",
      "Epoch: 1698 cost = 0.021418896\n",
      "Validation Loss: 0.036920547\n",
      "Epoch: 1699 cost = 0.021414460\n",
      "Validation Loss: 0.034352\n",
      "Epoch: 1700 cost = 0.021410523\n",
      "Validation Loss: 0.034200408\n",
      "Epoch: 1701 cost = 0.021406000\n",
      "Validation Loss: 0.023247967\n",
      "Epoch: 1702 cost = 0.021401736\n",
      "Validation Loss: 0.030094482\n",
      "Epoch: 1703 cost = 0.021397312\n",
      "Validation Loss: 0.029991299\n",
      "Epoch: 1704 cost = 0.021393142\n",
      "Validation Loss: 0.051852476\n",
      "Epoch: 1705 cost = 0.021389008\n",
      "Validation Loss: 0.072526745\n",
      "Epoch: 1706 cost = 0.021384644\n",
      "Validation Loss: 0.055333413\n",
      "Epoch: 1707 cost = 0.021380569\n",
      "Validation Loss: 0.038973983\n",
      "Epoch: 1708 cost = 0.021376167\n",
      "Validation Loss: 0.03780931\n",
      "Epoch: 1709 cost = 0.021371894\n",
      "Validation Loss: 0.037963107\n",
      "Epoch: 1710 cost = 0.021367731\n",
      "Validation Loss: 0.05112526\n",
      "Epoch: 1711 cost = 0.021363449\n",
      "Validation Loss: 0.046068624\n",
      "Epoch: 1712 cost = 0.021359103\n",
      "Validation Loss: 0.0398758\n",
      "Epoch: 1713 cost = 0.021354983\n",
      "Validation Loss: 0.02233365\n",
      "Epoch: 1714 cost = 0.021350808\n",
      "Validation Loss: 0.019554725\n",
      "Epoch: 1715 cost = 0.021346536\n",
      "Validation Loss: 0.08389229\n",
      "Epoch: 1716 cost = 0.021342306\n",
      "Validation Loss: 0.0640413\n",
      "Epoch: 1717 cost = 0.021338045\n",
      "Validation Loss: 0.05542475\n",
      "Epoch: 1718 cost = 0.021333953\n",
      "Validation Loss: 0.042933654\n",
      "Epoch: 1719 cost = 0.021329822\n",
      "Validation Loss: 0.037370034\n",
      "Epoch: 1720 cost = 0.021325461\n",
      "Validation Loss: 0.050528858\n",
      "Epoch: 1721 cost = 0.021321398\n",
      "Validation Loss: 0.0612443\n",
      "Epoch: 1722 cost = 0.021316868\n",
      "Validation Loss: 0.04181883\n",
      "Epoch: 1723 cost = 0.021312953\n",
      "Validation Loss: 0.03355294\n",
      "Epoch: 1724 cost = 0.021308915\n",
      "Validation Loss: 0.031733602\n",
      "Epoch: 1725 cost = 0.021304500\n",
      "Validation Loss: 0.035278622\n",
      "Epoch: 1726 cost = 0.021300426\n",
      "Validation Loss: 0.057228804\n",
      "Epoch: 1727 cost = 0.021296309\n",
      "Validation Loss: 0.060161773\n",
      "Epoch: 1728 cost = 0.021292155\n",
      "Validation Loss: 0.04872173\n",
      "Epoch: 1729 cost = 0.021288060\n",
      "Validation Loss: 0.03813165\n",
      "Epoch: 1730 cost = 0.021284132\n",
      "Validation Loss: 0.033889234\n",
      "Epoch: 1731 cost = 0.021280019\n",
      "Validation Loss: 0.032572497\n",
      "Epoch: 1732 cost = 0.021275638\n",
      "Validation Loss: 0.029782537\n",
      "Epoch: 1733 cost = 0.021271569\n",
      "Validation Loss: 0.032039333\n",
      "Epoch: 1734 cost = 0.021267312\n",
      "Validation Loss: 0.0317605\n",
      "Epoch: 1735 cost = 0.021263317\n",
      "Validation Loss: 0.042383675\n",
      "Epoch: 1736 cost = 0.021259113\n",
      "Validation Loss: 0.043075927\n",
      "Epoch: 1737 cost = 0.021255196\n",
      "Validation Loss: 0.051244576\n",
      "Epoch: 1738 cost = 0.021251353\n",
      "Validation Loss: 0.053561464\n",
      "Epoch: 1739 cost = 0.021246823\n",
      "Validation Loss: 0.056065384\n",
      "Epoch: 1740 cost = 0.021242788\n",
      "Validation Loss: 0.037487525\n",
      "Epoch: 1741 cost = 0.021238666\n",
      "Validation Loss: 0.027041491\n",
      "Epoch: 1742 cost = 0.021234821\n",
      "Validation Loss: 0.026253382\n",
      "Epoch: 1743 cost = 0.021230716\n",
      "Validation Loss: 0.039353125\n",
      "Epoch: 1744 cost = 0.021226502\n",
      "Validation Loss: 0.03577822\n",
      "Epoch: 1745 cost = 0.021222668\n",
      "Validation Loss: 0.025665354\n",
      "Epoch: 1746 cost = 0.021218649\n",
      "Validation Loss: 0.024358332\n",
      "Epoch: 1747 cost = 0.021214436\n",
      "Validation Loss: 0.02761389\n",
      "Epoch: 1748 cost = 0.021210502\n",
      "Validation Loss: 0.025679458\n",
      "Epoch: 1749 cost = 0.021206280\n",
      "Validation Loss: 0.032397877\n",
      "Epoch: 1750 cost = 0.021202212\n",
      "Validation Loss: 0.024946176\n",
      "Epoch: 1751 cost = 0.021198156\n",
      "Validation Loss: 0.028493319\n",
      "Epoch: 1752 cost = 0.021194371\n",
      "Validation Loss: 0.033607148\n",
      "Epoch: 1753 cost = 0.021190222\n",
      "Validation Loss: 0.044702105\n",
      "Epoch: 1754 cost = 0.021186144\n",
      "Validation Loss: 0.05739963\n",
      "Epoch: 1755 cost = 0.021182260\n",
      "Validation Loss: 0.04645487\n",
      "Epoch: 1756 cost = 0.021178135\n",
      "Validation Loss: 0.04743854\n",
      "Epoch: 1757 cost = 0.021174200\n",
      "Validation Loss: 0.026919592\n",
      "Epoch: 1758 cost = 0.021170217\n",
      "Validation Loss: 0.024182525\n",
      "Epoch: 1759 cost = 0.021166351\n",
      "Validation Loss: 0.024536245\n",
      "Epoch: 1760 cost = 0.021162331\n",
      "Validation Loss: 0.028845942\n",
      "Epoch: 1761 cost = 0.021158277\n",
      "Validation Loss: 0.045204144\n",
      "Epoch: 1762 cost = 0.021154295\n",
      "Validation Loss: 0.049072046\n",
      "Epoch: 1763 cost = 0.021150355\n",
      "Validation Loss: 0.041421372\n",
      "Epoch: 1764 cost = 0.021146436\n",
      "Validation Loss: 0.03482518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1765 cost = 0.021142285\n",
      "Validation Loss: 0.028682193\n",
      "Epoch: 1766 cost = 0.021138207\n",
      "Validation Loss: 0.034350388\n",
      "Epoch: 1767 cost = 0.021134434\n",
      "Validation Loss: 0.056199566\n",
      "Epoch: 1768 cost = 0.021130658\n",
      "Validation Loss: 0.0627467\n",
      "Epoch: 1769 cost = 0.021126489\n",
      "Validation Loss: 0.060305133\n",
      "Epoch: 1770 cost = 0.021122831\n",
      "Validation Loss: 0.04446876\n",
      "Epoch: 1771 cost = 0.021118651\n",
      "Validation Loss: 0.039384436\n",
      "Epoch: 1772 cost = 0.021114677\n",
      "Validation Loss: 0.05722705\n",
      "Epoch: 1773 cost = 0.021111059\n",
      "Validation Loss: 0.03890665\n",
      "Epoch: 1774 cost = 0.021106934\n",
      "Validation Loss: 0.025860772\n",
      "Epoch: 1775 cost = 0.021102941\n",
      "Validation Loss: 0.02515415\n",
      "Epoch: 1776 cost = 0.021099127\n",
      "Validation Loss: 0.027958494\n",
      "Epoch: 1777 cost = 0.021095135\n",
      "Validation Loss: 0.030001832\n",
      "Epoch: 1778 cost = 0.021091234\n",
      "Validation Loss: 0.025247103\n",
      "Epoch: 1779 cost = 0.021087522\n",
      "Validation Loss: 0.029595187\n",
      "Epoch: 1780 cost = 0.021083460\n",
      "Validation Loss: 0.029197667\n",
      "Epoch: 1781 cost = 0.021079764\n",
      "Validation Loss: 0.033041086\n",
      "Epoch: 1782 cost = 0.021075667\n",
      "Validation Loss: 0.030325985\n",
      "Epoch: 1783 cost = 0.021071875\n",
      "Validation Loss: 0.029795453\n",
      "Epoch: 1784 cost = 0.021068018\n",
      "Validation Loss: 0.031433016\n",
      "Epoch: 1785 cost = 0.021063959\n",
      "Validation Loss: 0.033925995\n",
      "Epoch: 1786 cost = 0.021060145\n",
      "Validation Loss: 0.041232035\n",
      "Epoch: 1787 cost = 0.021056248\n",
      "Validation Loss: 0.042587496\n",
      "Epoch: 1788 cost = 0.021052541\n",
      "Validation Loss: 0.0469283\n",
      "Epoch: 1789 cost = 0.021048447\n",
      "Validation Loss: 0.047279976\n",
      "Epoch: 1790 cost = 0.021044791\n",
      "Validation Loss: 0.05129269\n",
      "Epoch: 1791 cost = 0.021041255\n",
      "Validation Loss: 0.03600833\n",
      "Epoch: 1792 cost = 0.021037280\n",
      "Validation Loss: 0.030882701\n",
      "Epoch: 1793 cost = 0.021033321\n",
      "Validation Loss: 0.054069687\n",
      "Epoch: 1794 cost = 0.021029360\n",
      "Validation Loss: 0.057016946\n",
      "Epoch: 1795 cost = 0.021025656\n",
      "Validation Loss: 0.042621087\n",
      "Epoch: 1796 cost = 0.021021854\n",
      "Validation Loss: 0.03352523\n",
      "Epoch: 1797 cost = 0.021018311\n",
      "Validation Loss: 0.03921757\n",
      "Epoch: 1798 cost = 0.021014319\n",
      "Validation Loss: 0.045757238\n",
      "Epoch: 1799 cost = 0.021010286\n",
      "Validation Loss: 0.04258779\n",
      "Epoch: 1800 cost = 0.021006694\n",
      "Validation Loss: 0.04549884\n",
      "Epoch: 1801 cost = 0.021002745\n",
      "Validation Loss: 0.03250378\n",
      "Epoch: 1802 cost = 0.020999128\n",
      "Validation Loss: 0.044394515\n",
      "Epoch: 1803 cost = 0.020995079\n",
      "Validation Loss: 0.048897944\n",
      "Epoch: 1804 cost = 0.020991479\n",
      "Validation Loss: 0.039801486\n",
      "Epoch: 1805 cost = 0.020987859\n",
      "Validation Loss: 0.038264144\n",
      "Epoch: 1806 cost = 0.020983937\n",
      "Validation Loss: 0.04454786\n",
      "Epoch: 1807 cost = 0.020980180\n",
      "Validation Loss: 0.039784506\n",
      "Epoch: 1808 cost = 0.020976594\n",
      "Validation Loss: 0.042331535\n",
      "Epoch: 1809 cost = 0.020972569\n",
      "Validation Loss: 0.03779106\n",
      "Epoch: 1810 cost = 0.020969003\n",
      "Validation Loss: 0.03559041\n",
      "Epoch: 1811 cost = 0.020965260\n",
      "Validation Loss: 0.03392498\n",
      "Epoch: 1812 cost = 0.020961411\n",
      "Validation Loss: 0.044252127\n",
      "Epoch: 1813 cost = 0.020957651\n",
      "Validation Loss: 0.03660027\n",
      "Epoch: 1814 cost = 0.020953849\n",
      "Validation Loss: 0.03061601\n",
      "Epoch: 1815 cost = 0.020950065\n",
      "Validation Loss: 0.029076591\n",
      "Epoch: 1816 cost = 0.020946485\n",
      "Validation Loss: 0.03463059\n",
      "Epoch: 1817 cost = 0.020942872\n",
      "Validation Loss: 0.030362563\n",
      "Epoch: 1818 cost = 0.020939077\n",
      "Validation Loss: 0.042039733\n",
      "Epoch: 1819 cost = 0.020935277\n",
      "Validation Loss: 0.02558834\n",
      "Epoch: 1820 cost = 0.020931825\n",
      "Validation Loss: 0.034024857\n",
      "Epoch: 1821 cost = 0.020927727\n",
      "Validation Loss: 0.038622037\n",
      "Epoch: 1822 cost = 0.020924175\n",
      "Validation Loss: 0.039014947\n",
      "Epoch: 1823 cost = 0.020920335\n",
      "Validation Loss: 0.03572554\n",
      "Epoch: 1824 cost = 0.020916970\n",
      "Validation Loss: 0.031353906\n",
      "Epoch: 1825 cost = 0.020913175\n",
      "Validation Loss: 0.039179984\n",
      "Epoch: 1826 cost = 0.020909119\n",
      "Validation Loss: 0.035261255\n",
      "Epoch: 1827 cost = 0.020905559\n",
      "Validation Loss: 0.03131476\n",
      "Epoch: 1828 cost = 0.020902075\n",
      "Validation Loss: 0.026428431\n",
      "Epoch: 1829 cost = 0.020898357\n",
      "Validation Loss: 0.043944042\n",
      "Epoch: 1830 cost = 0.020894569\n",
      "Validation Loss: 0.038651276\n",
      "Epoch: 1831 cost = 0.020890762\n",
      "Validation Loss: 0.034325626\n",
      "Epoch: 1832 cost = 0.020887335\n",
      "Validation Loss: 0.03569132\n",
      "Epoch: 1833 cost = 0.020883499\n",
      "Validation Loss: 0.042605776\n",
      "Epoch: 1834 cost = 0.020880028\n",
      "Validation Loss: 0.042712886\n",
      "Epoch: 1835 cost = 0.020876288\n",
      "Validation Loss: 0.032872275\n",
      "Epoch: 1836 cost = 0.020872729\n",
      "Validation Loss: 0.038225632\n",
      "Epoch: 1837 cost = 0.020869158\n",
      "Validation Loss: 0.04877387\n",
      "Epoch: 1838 cost = 0.020865414\n",
      "Validation Loss: 0.062192783\n",
      "Epoch: 1839 cost = 0.020861885\n",
      "Validation Loss: 0.06264256\n",
      "Epoch: 1840 cost = 0.020858189\n",
      "Validation Loss: 0.05119773\n",
      "Epoch: 1841 cost = 0.020854630\n",
      "Validation Loss: 0.044525746\n",
      "Epoch: 1842 cost = 0.020851012\n",
      "Validation Loss: 0.029508578\n",
      "Epoch: 1843 cost = 0.020847459\n",
      "Validation Loss: 0.030643273\n",
      "Epoch: 1844 cost = 0.020843435\n",
      "Validation Loss: 0.034205113\n",
      "Epoch: 1845 cost = 0.020840267\n",
      "Validation Loss: 0.030867668\n",
      "Epoch: 1846 cost = 0.020836489\n",
      "Validation Loss: 0.037323344\n",
      "Epoch: 1847 cost = 0.020832809\n",
      "Validation Loss: 0.04152037\n",
      "Epoch: 1848 cost = 0.020829207\n",
      "Validation Loss: 0.033856574\n",
      "Epoch: 1849 cost = 0.020825676\n",
      "Validation Loss: 0.033170246\n",
      "Epoch: 1850 cost = 0.020821941\n",
      "Validation Loss: 0.030819222\n",
      "Epoch: 1851 cost = 0.020818590\n",
      "Validation Loss: 0.024575748\n",
      "Epoch: 1852 cost = 0.020814953\n",
      "Validation Loss: 0.03585021\n",
      "Epoch: 1853 cost = 0.020811277\n",
      "Validation Loss: 0.043435007\n",
      "Epoch: 1854 cost = 0.020807566\n",
      "Validation Loss: 0.05777191\n",
      "Epoch: 1855 cost = 0.020804045\n",
      "Validation Loss: 0.051808495\n",
      "Epoch: 1856 cost = 0.020800722\n",
      "Validation Loss: 0.03644201\n",
      "Epoch: 1857 cost = 0.020797101\n",
      "Validation Loss: 0.043377068\n",
      "Epoch: 1858 cost = 0.020793642\n",
      "Validation Loss: 0.064734094\n",
      "Epoch: 1859 cost = 0.020789779\n",
      "Validation Loss: 0.04841888\n",
      "Epoch: 1860 cost = 0.020786323\n",
      "Validation Loss: 0.0303296\n",
      "Epoch: 1861 cost = 0.020782870\n",
      "Validation Loss: 0.03675656\n",
      "Epoch: 1862 cost = 0.020779179\n",
      "Validation Loss: 0.05761269\n",
      "Epoch: 1863 cost = 0.020775800\n",
      "Validation Loss: 0.057527177\n",
      "Epoch: 1864 cost = 0.020772245\n",
      "Validation Loss: 0.05323784\n",
      "Epoch: 1865 cost = 0.020768852\n",
      "Validation Loss: 0.032998804\n",
      "Epoch: 1866 cost = 0.020765092\n",
      "Validation Loss: 0.03320086\n",
      "Epoch: 1867 cost = 0.020761593\n",
      "Validation Loss: 0.04104748\n",
      "Epoch: 1868 cost = 0.020758437\n",
      "Validation Loss: 0.03721198\n",
      "Epoch: 1869 cost = 0.020754665\n",
      "Validation Loss: 0.030660842\n",
      "Epoch: 1870 cost = 0.020751163\n",
      "Validation Loss: 0.04852345\n",
      "Epoch: 1871 cost = 0.020747535\n",
      "Validation Loss: 0.059902802\n",
      "Epoch: 1872 cost = 0.020744100\n",
      "Validation Loss: 0.06665149\n",
      "Epoch: 1873 cost = 0.020740564\n",
      "Validation Loss: 0.05560864\n",
      "Epoch: 1874 cost = 0.020737277\n",
      "Validation Loss: 0.03864743\n",
      "Epoch: 1875 cost = 0.020733585\n",
      "Validation Loss: 0.026225494\n",
      "Epoch: 1876 cost = 0.020729903\n",
      "Validation Loss: 0.03386115\n",
      "Epoch: 1877 cost = 0.020726454\n",
      "Validation Loss: 0.03777463\n",
      "Epoch: 1878 cost = 0.020723288\n",
      "Validation Loss: 0.04278995\n",
      "Epoch: 1879 cost = 0.020719721\n",
      "Validation Loss: 0.058577172\n",
      "Epoch: 1880 cost = 0.020716388\n",
      "Validation Loss: 0.061628986\n",
      "Epoch: 1881 cost = 0.020712823\n",
      "Validation Loss: 0.057159893\n",
      "Epoch: 1882 cost = 0.020709200\n",
      "Validation Loss: 0.043945484\n",
      "Epoch: 1883 cost = 0.020705842\n",
      "Validation Loss: 0.028762992\n",
      "Epoch: 1884 cost = 0.020702399\n",
      "Validation Loss: 0.0410294\n",
      "Epoch: 1885 cost = 0.020698921\n",
      "Validation Loss: 0.043219168\n",
      "Epoch: 1886 cost = 0.020695527\n",
      "Validation Loss: 0.043698102\n",
      "Epoch: 1887 cost = 0.020691900\n",
      "Validation Loss: 0.04776265\n",
      "Epoch: 1888 cost = 0.020688365\n",
      "Validation Loss: 0.033389\n",
      "Epoch: 1889 cost = 0.020684983\n",
      "Validation Loss: 0.047226906\n",
      "Epoch: 1890 cost = 0.020681511\n",
      "Validation Loss: 0.04204147\n",
      "Epoch: 1891 cost = 0.020678274\n",
      "Validation Loss: 0.036956042\n",
      "Epoch: 1892 cost = 0.020674696\n",
      "Validation Loss: 0.041630425\n",
      "Epoch: 1893 cost = 0.020671479\n",
      "Validation Loss: 0.055452406\n",
      "Epoch: 1894 cost = 0.020667914\n",
      "Validation Loss: 0.06693551\n",
      "Epoch: 1895 cost = 0.020664758\n",
      "Validation Loss: 0.056712456\n",
      "Epoch: 1896 cost = 0.020661174\n",
      "Validation Loss: 0.045837075\n",
      "Epoch: 1897 cost = 0.020657636\n",
      "Validation Loss: 0.04091947\n",
      "Epoch: 1898 cost = 0.020654248\n",
      "Validation Loss: 0.035671826\n",
      "Epoch: 1899 cost = 0.020651032\n",
      "Validation Loss: 0.034169137\n",
      "Epoch: 1900 cost = 0.020647302\n",
      "Validation Loss: 0.039042767\n",
      "Epoch: 1901 cost = 0.020644130\n",
      "Validation Loss: 0.04477384\n",
      "Epoch: 1902 cost = 0.020640868\n",
      "Validation Loss: 0.04363776\n",
      "Epoch: 1903 cost = 0.020637343\n",
      "Validation Loss: 0.03384202\n",
      "Epoch: 1904 cost = 0.020633872\n",
      "Validation Loss: 0.027422907\n",
      "Epoch: 1905 cost = 0.020630446\n",
      "Validation Loss: 0.025996586\n",
      "Epoch: 1906 cost = 0.020627250\n",
      "Validation Loss: 0.024113275\n",
      "Epoch: 1907 cost = 0.020623812\n",
      "Validation Loss: 0.035435997\n",
      "Epoch: 1908 cost = 0.020620393\n",
      "Validation Loss: 0.04465616\n",
      "Epoch: 1909 cost = 0.020616941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.053033367\n",
      "Epoch: 1910 cost = 0.020613641\n",
      "Validation Loss: 0.03570097\n",
      "Epoch: 1911 cost = 0.020610228\n",
      "Validation Loss: 0.031139975\n",
      "Epoch: 1912 cost = 0.020606999\n",
      "Validation Loss: 0.028091757\n",
      "Epoch: 1913 cost = 0.020603505\n",
      "Validation Loss: 0.039639276\n",
      "Epoch: 1914 cost = 0.020600330\n",
      "Validation Loss: 0.034010094\n",
      "Epoch: 1915 cost = 0.020596929\n",
      "Validation Loss: 0.037394937\n",
      "Epoch: 1916 cost = 0.020593589\n",
      "Validation Loss: 0.02692937\n",
      "Epoch: 1917 cost = 0.020590150\n",
      "Validation Loss: 0.03799406\n",
      "Epoch: 1918 cost = 0.020586865\n",
      "Validation Loss: 0.043284643\n",
      "Epoch: 1919 cost = 0.020583681\n",
      "Validation Loss: 0.05319156\n",
      "Epoch: 1920 cost = 0.020580134\n",
      "Validation Loss: 0.052238073\n",
      "Epoch: 1921 cost = 0.020577013\n",
      "Validation Loss: 0.04172938\n",
      "Epoch: 1922 cost = 0.020573382\n",
      "Validation Loss: 0.064044096\n",
      "Epoch: 1923 cost = 0.020570364\n",
      "Validation Loss: 0.05767509\n",
      "Epoch: 1924 cost = 0.020566941\n",
      "Validation Loss: 0.035828512\n",
      "Epoch: 1925 cost = 0.020563589\n",
      "Validation Loss: 0.034758072\n",
      "Epoch: 1926 cost = 0.020560391\n",
      "Validation Loss: 0.024695003\n",
      "Epoch: 1927 cost = 0.020556874\n",
      "Validation Loss: 0.023519266\n",
      "Epoch: 1928 cost = 0.020553579\n",
      "Validation Loss: 0.037650358\n",
      "Epoch: 1929 cost = 0.020550487\n",
      "Validation Loss: 0.056887526\n",
      "Epoch: 1930 cost = 0.020547180\n",
      "Validation Loss: 0.047130853\n",
      "Epoch: 1931 cost = 0.020543715\n",
      "Validation Loss: 0.032226827\n",
      "Epoch: 1932 cost = 0.020540546\n",
      "Validation Loss: 0.024011655\n",
      "Epoch: 1933 cost = 0.020537231\n",
      "Validation Loss: 0.043590847\n",
      "Epoch: 1934 cost = 0.020534004\n",
      "Validation Loss: 0.035695538\n",
      "Epoch: 1935 cost = 0.020530514\n",
      "Validation Loss: 0.045809805\n",
      "Epoch: 1936 cost = 0.020527584\n",
      "Validation Loss: 0.037927303\n",
      "Epoch: 1937 cost = 0.020524152\n",
      "Validation Loss: 0.039300207\n",
      "Epoch: 1938 cost = 0.020520799\n",
      "Validation Loss: 0.03721771\n",
      "Epoch: 1939 cost = 0.020517652\n",
      "Validation Loss: 0.036736015\n",
      "Epoch: 1940 cost = 0.020514724\n",
      "Validation Loss: 0.04062249\n",
      "Epoch: 1941 cost = 0.020510901\n",
      "Validation Loss: 0.038929958\n",
      "Epoch: 1942 cost = 0.020507943\n",
      "Validation Loss: 0.034356415\n",
      "Epoch: 1943 cost = 0.020504718\n",
      "Validation Loss: 0.035860255\n",
      "Epoch: 1944 cost = 0.020501255\n",
      "Validation Loss: 0.02895389\n",
      "Epoch: 1945 cost = 0.020498257\n",
      "Validation Loss: 0.038225822\n",
      "Epoch: 1946 cost = 0.020494754\n",
      "Validation Loss: 0.04119472\n",
      "Epoch: 1947 cost = 0.020491737\n",
      "Validation Loss: 0.037121776\n",
      "Epoch: 1948 cost = 0.020488524\n",
      "Validation Loss: 0.03687179\n",
      "Epoch: 1949 cost = 0.020485082\n",
      "Validation Loss: 0.04185202\n",
      "Epoch: 1950 cost = 0.020482130\n",
      "Validation Loss: 0.07129098\n",
      "Epoch: 1951 cost = 0.020478683\n",
      "Validation Loss: 0.06576373\n",
      "Epoch: 1952 cost = 0.020475560\n",
      "Validation Loss: 0.03279673\n",
      "Epoch: 1953 cost = 0.020472089\n",
      "Validation Loss: 0.033804398\n",
      "Epoch: 1954 cost = 0.020469093\n",
      "Validation Loss: 0.039955296\n",
      "Epoch: 1955 cost = 0.020465816\n",
      "Validation Loss: 0.032493804\n",
      "Epoch: 1956 cost = 0.020462743\n",
      "Validation Loss: 0.039571553\n",
      "Epoch: 1957 cost = 0.020459513\n",
      "Validation Loss: 0.043479186\n",
      "Epoch: 1958 cost = 0.020456192\n",
      "Validation Loss: 0.044591922\n",
      "Epoch: 1959 cost = 0.020453020\n",
      "Validation Loss: 0.045488197\n",
      "Epoch: 1960 cost = 0.020449943\n",
      "Validation Loss: 0.03556537\n",
      "Epoch: 1961 cost = 0.020446535\n",
      "Validation Loss: 0.029390195\n",
      "Epoch: 1962 cost = 0.020443674\n",
      "Validation Loss: 0.046555363\n",
      "Epoch: 1963 cost = 0.020440123\n",
      "Validation Loss: 0.051943906\n",
      "Epoch: 1964 cost = 0.020437264\n",
      "Validation Loss: 0.052361466\n",
      "Epoch: 1965 cost = 0.020434030\n",
      "Validation Loss: 0.04532005\n",
      "Epoch: 1966 cost = 0.020430575\n",
      "Validation Loss: 0.05105569\n",
      "Epoch: 1967 cost = 0.020427628\n",
      "Validation Loss: 0.04347414\n",
      "Epoch: 1968 cost = 0.020424598\n",
      "Validation Loss: 0.028724717\n",
      "Epoch: 1969 cost = 0.020421161\n",
      "Validation Loss: 0.036902085\n",
      "Epoch: 1970 cost = 0.020418085\n",
      "Validation Loss: 0.049458303\n",
      "Epoch: 1971 cost = 0.020415027\n",
      "Validation Loss: 0.06177437\n",
      "Epoch: 1972 cost = 0.020411827\n",
      "Validation Loss: 0.04547557\n",
      "Epoch: 1973 cost = 0.020408778\n",
      "Validation Loss: 0.033727776\n",
      "Epoch: 1974 cost = 0.020405296\n",
      "Validation Loss: 0.025333054\n",
      "Epoch: 1975 cost = 0.020402518\n",
      "Validation Loss: 0.033166837\n",
      "Epoch: 1976 cost = 0.020399210\n",
      "Validation Loss: 0.025022326\n",
      "Epoch: 1977 cost = 0.020395877\n",
      "Validation Loss: 0.028447831\n",
      "Epoch: 1978 cost = 0.020393033\n",
      "Validation Loss: 0.032060992\n",
      "Epoch: 1979 cost = 0.020389653\n",
      "Validation Loss: 0.039865702\n",
      "Epoch: 1980 cost = 0.020386847\n",
      "Validation Loss: 0.03970505\n",
      "Epoch: 1981 cost = 0.020383431\n",
      "Validation Loss: 0.04633644\n",
      "Epoch: 1982 cost = 0.020380301\n",
      "Validation Loss: 0.059190426\n",
      "Epoch: 1983 cost = 0.020377047\n",
      "Validation Loss: 0.04751819\n",
      "Epoch: 1984 cost = 0.020373955\n",
      "Validation Loss: 0.03415196\n",
      "Epoch: 1985 cost = 0.020370881\n",
      "Validation Loss: 0.045420494\n",
      "Epoch: 1986 cost = 0.020368071\n",
      "Validation Loss: 0.05773516\n",
      "Epoch: 1987 cost = 0.020365009\n",
      "Validation Loss: 0.042221494\n",
      "Epoch: 1988 cost = 0.020361793\n",
      "Validation Loss: 0.03573576\n",
      "Epoch: 1989 cost = 0.020358781\n",
      "Validation Loss: 0.04236208\n",
      "Epoch: 1990 cost = 0.020355572\n",
      "Validation Loss: 0.04038509\n",
      "Epoch: 1991 cost = 0.020352347\n",
      "Validation Loss: 0.049531993\n",
      "Epoch: 1992 cost = 0.020349331\n",
      "Validation Loss: 0.05651693\n",
      "Epoch: 1993 cost = 0.020346250\n",
      "Validation Loss: 0.05198414\n",
      "Epoch: 1994 cost = 0.020343042\n",
      "Validation Loss: 0.044008147\n",
      "Epoch: 1995 cost = 0.020340200\n",
      "Validation Loss: 0.026847318\n",
      "Epoch: 1996 cost = 0.020337023\n",
      "Validation Loss: 0.034797467\n",
      "Epoch: 1997 cost = 0.020333856\n",
      "Validation Loss: 0.034644574\n",
      "Epoch: 1998 cost = 0.020330957\n",
      "Validation Loss: 0.025597569\n",
      "Epoch: 1999 cost = 0.020327692\n",
      "Validation Loss: 0.025440896\n",
      "Epoch: 2000 cost = 0.020324705\n",
      "Validation Loss: 0.028953122\n",
      "Epoch: 2001 cost = 0.020321907\n",
      "Validation Loss: 0.03835365\n",
      "Epoch: 2002 cost = 0.020318815\n",
      "Validation Loss: 0.033944078\n",
      "Epoch: 2003 cost = 0.020315707\n",
      "Validation Loss: 0.040291004\n",
      "Epoch: 2004 cost = 0.020312392\n",
      "Validation Loss: 0.046648145\n",
      "Epoch: 2005 cost = 0.020309480\n",
      "Validation Loss: 0.04945901\n",
      "Epoch: 2006 cost = 0.020306312\n",
      "Validation Loss: 0.029101767\n",
      "Epoch: 2007 cost = 0.020303187\n",
      "Validation Loss: 0.035383616\n",
      "Epoch: 2008 cost = 0.020300257\n",
      "Validation Loss: 0.04710526\n",
      "Epoch: 2009 cost = 0.020297084\n",
      "Validation Loss: 0.04390187\n",
      "Epoch: 2010 cost = 0.020294447\n",
      "Validation Loss: 0.047569115\n",
      "Epoch: 2011 cost = 0.020291002\n",
      "Validation Loss: 0.0285435\n",
      "Epoch: 2012 cost = 0.020287964\n",
      "Validation Loss: 0.02780438\n",
      "Epoch: 2013 cost = 0.020285086\n",
      "Validation Loss: 0.025718622\n",
      "Epoch: 2014 cost = 0.020282271\n",
      "Validation Loss: 0.029296031\n",
      "Epoch: 2015 cost = 0.020278909\n",
      "Validation Loss: 0.03643541\n",
      "Epoch: 2016 cost = 0.020276076\n",
      "Validation Loss: 0.03402004\n",
      "Epoch: 2017 cost = 0.020272955\n",
      "Validation Loss: 0.0328632\n",
      "Epoch: 2018 cost = 0.020270019\n",
      "Validation Loss: 0.04951323\n",
      "Epoch: 2019 cost = 0.020267108\n",
      "Validation Loss: 0.05822228\n",
      "Epoch: 2020 cost = 0.020263917\n",
      "Validation Loss: 0.051024936\n",
      "Epoch: 2021 cost = 0.020260988\n",
      "Validation Loss: 0.042863693\n",
      "Epoch: 2022 cost = 0.020257927\n",
      "Validation Loss: 0.04270093\n",
      "Epoch: 2023 cost = 0.020254704\n",
      "Validation Loss: 0.053179014\n",
      "Epoch: 2024 cost = 0.020252017\n",
      "Validation Loss: 0.0475674\n",
      "Epoch: 2025 cost = 0.020248819\n",
      "Validation Loss: 0.032493733\n",
      "Epoch: 2026 cost = 0.020245924\n",
      "Validation Loss: 0.033334192\n",
      "Epoch: 2027 cost = 0.020242753\n",
      "Validation Loss: 0.031668518\n",
      "Epoch: 2028 cost = 0.020240106\n",
      "Validation Loss: 0.030122604\n",
      "Epoch: 2029 cost = 0.020236884\n",
      "Validation Loss: 0.037974264\n",
      "Epoch: 2030 cost = 0.020233737\n",
      "Validation Loss: 0.034599125\n",
      "Epoch: 2031 cost = 0.020230880\n",
      "Validation Loss: 0.03391103\n",
      "Epoch: 2032 cost = 0.020228267\n",
      "Validation Loss: 0.042157765\n",
      "Epoch: 2033 cost = 0.020225009\n",
      "Validation Loss: 0.043666814\n",
      "Epoch: 2034 cost = 0.020221953\n",
      "Validation Loss: 0.038802493\n",
      "Epoch: 2035 cost = 0.020219182\n",
      "Validation Loss: 0.037623733\n",
      "Epoch: 2036 cost = 0.020216176\n",
      "Validation Loss: 0.034967955\n",
      "Epoch: 2037 cost = 0.020213106\n",
      "Validation Loss: 0.034530867\n",
      "Epoch: 2038 cost = 0.020210354\n",
      "Validation Loss: 0.04677489\n",
      "Epoch: 2039 cost = 0.020207250\n",
      "Validation Loss: 0.035619106\n",
      "Epoch: 2040 cost = 0.020204308\n",
      "Validation Loss: 0.052205108\n",
      "Epoch: 2041 cost = 0.020201498\n",
      "Validation Loss: 0.06245159\n",
      "Epoch: 2042 cost = 0.020198285\n",
      "Validation Loss: 0.069420524\n",
      "Epoch: 2043 cost = 0.020195572\n",
      "Validation Loss: 0.06597773\n",
      "Epoch: 2044 cost = 0.020192767\n",
      "Validation Loss: 0.04083765\n",
      "Epoch: 2045 cost = 0.020189607\n",
      "Validation Loss: 0.037839625\n",
      "Epoch: 2046 cost = 0.020186985\n",
      "Validation Loss: 0.061800264\n",
      "Epoch: 2047 cost = 0.020183908\n",
      "Validation Loss: 0.08737723\n",
      "Epoch: 2048 cost = 0.020180764\n",
      "Validation Loss: 0.07848712\n",
      "Epoch: 2049 cost = 0.020178180\n",
      "Validation Loss: 0.05747369\n",
      "Epoch: 2050 cost = 0.020175094\n",
      "Validation Loss: 0.044311807\n",
      "Epoch: 2051 cost = 0.020172240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.034482215\n",
      "Epoch: 2052 cost = 0.020169168\n",
      "Validation Loss: 0.031723734\n",
      "Epoch: 2053 cost = 0.020166459\n",
      "Validation Loss: 0.03602782\n",
      "Epoch: 2054 cost = 0.020163514\n",
      "Validation Loss: 0.025231734\n",
      "Epoch: 2055 cost = 0.020160765\n",
      "Validation Loss: 0.052766837\n",
      "Epoch: 2056 cost = 0.020157790\n",
      "Validation Loss: 0.05963844\n",
      "Epoch: 2057 cost = 0.020154556\n",
      "Validation Loss: 0.036998376\n",
      "Epoch: 2058 cost = 0.020151769\n",
      "Validation Loss: 0.03783207\n",
      "Epoch: 2059 cost = 0.020148664\n",
      "Validation Loss: 0.046206567\n",
      "Epoch: 2060 cost = 0.020146046\n",
      "Validation Loss: 0.045431282\n",
      "Epoch: 2061 cost = 0.020143171\n",
      "Validation Loss: 0.044203192\n",
      "Epoch: 2062 cost = 0.020140244\n",
      "Validation Loss: 0.035609487\n",
      "Epoch: 2063 cost = 0.020137355\n",
      "Validation Loss: 0.038644195\n",
      "Epoch: 2064 cost = 0.020134685\n",
      "Validation Loss: 0.041593842\n",
      "Epoch: 2065 cost = 0.020131397\n",
      "Validation Loss: 0.040172253\n",
      "Epoch: 2066 cost = 0.020128729\n",
      "Validation Loss: 0.031692952\n",
      "Epoch: 2067 cost = 0.020125857\n",
      "Validation Loss: 0.03127536\n",
      "Epoch: 2068 cost = 0.020122687\n",
      "Validation Loss: 0.03418561\n",
      "Epoch: 2069 cost = 0.020119929\n",
      "Validation Loss: 0.03619189\n",
      "Epoch: 2070 cost = 0.020117293\n",
      "Validation Loss: 0.047026407\n",
      "Epoch: 2071 cost = 0.020114236\n",
      "Validation Loss: 0.046700936\n",
      "Epoch: 2072 cost = 0.020111513\n",
      "Validation Loss: 0.04254421\n",
      "Epoch: 2073 cost = 0.020108725\n",
      "Validation Loss: 0.03976699\n",
      "Epoch: 2074 cost = 0.020105810\n",
      "Validation Loss: 0.053909298\n",
      "Epoch: 2075 cost = 0.020103115\n",
      "Validation Loss: 0.058196526\n",
      "Epoch: 2076 cost = 0.020100108\n",
      "Validation Loss: 0.06991827\n",
      "Epoch: 2077 cost = 0.020097486\n",
      "Validation Loss: 0.056722045\n",
      "Epoch: 2078 cost = 0.020094363\n",
      "Validation Loss: 0.045487512\n",
      "Epoch: 2079 cost = 0.020091568\n",
      "Validation Loss: 0.045652527\n",
      "Epoch: 2080 cost = 0.020088727\n",
      "Validation Loss: 0.052079506\n",
      "Epoch: 2081 cost = 0.020085869\n",
      "Validation Loss: 0.03869476\n",
      "Epoch: 2082 cost = 0.020082971\n",
      "Validation Loss: 0.037923243\n",
      "Epoch: 2083 cost = 0.020080416\n",
      "Validation Loss: 0.036672432\n",
      "Epoch: 2084 cost = 0.020077389\n",
      "Validation Loss: 0.025793469\n",
      "Epoch: 2085 cost = 0.020074777\n",
      "Validation Loss: 0.022594685\n",
      "Epoch: 2086 cost = 0.020071837\n",
      "Validation Loss: 0.028052164\n",
      "Epoch: 2087 cost = 0.020068917\n",
      "Validation Loss: 0.02603028\n",
      "Epoch: 2088 cost = 0.020066226\n",
      "Validation Loss: 0.032001212\n",
      "Epoch: 2089 cost = 0.020063184\n",
      "Validation Loss: 0.024263749\n",
      "Epoch: 2090 cost = 0.020060562\n",
      "Validation Loss: 0.03218653\n",
      "Epoch: 2091 cost = 0.020057740\n",
      "Validation Loss: 0.043421015\n",
      "Epoch: 2092 cost = 0.020054796\n",
      "Validation Loss: 0.05289691\n",
      "Epoch: 2093 cost = 0.020052163\n",
      "Validation Loss: 0.04753873\n",
      "Epoch: 2094 cost = 0.020049347\n",
      "Validation Loss: 0.038317926\n",
      "Epoch: 2095 cost = 0.020046594\n",
      "Validation Loss: 0.038955685\n",
      "Epoch: 2096 cost = 0.020043781\n",
      "Validation Loss: 0.04125532\n",
      "Epoch: 2097 cost = 0.020040697\n",
      "Validation Loss: 0.04840718\n",
      "Epoch: 2098 cost = 0.020038006\n",
      "Validation Loss: 0.056005586\n",
      "Epoch: 2099 cost = 0.020035472\n",
      "Validation Loss: 0.05198261\n",
      "Epoch: 2100 cost = 0.020032473\n",
      "Validation Loss: 0.037798647\n",
      "Epoch: 2101 cost = 0.020029857\n",
      "Validation Loss: 0.04107369\n",
      "Epoch: 2102 cost = 0.020026819\n",
      "Validation Loss: 0.050637346\n",
      "Epoch: 2103 cost = 0.020024141\n",
      "Validation Loss: 0.053848326\n",
      "Epoch: 2104 cost = 0.020021519\n",
      "Validation Loss: 0.0756448\n",
      "Epoch: 2105 cost = 0.020018715\n",
      "Validation Loss: 0.08271806\n",
      "Epoch: 2106 cost = 0.020016097\n",
      "Validation Loss: 0.055865783\n",
      "Epoch: 2107 cost = 0.020013255\n",
      "Validation Loss: 0.046687365\n",
      "Epoch: 2108 cost = 0.020010259\n",
      "Validation Loss: 0.051192153\n",
      "Epoch: 2109 cost = 0.020007393\n",
      "Validation Loss: 0.05907517\n",
      "Epoch: 2110 cost = 0.020004835\n",
      "Validation Loss: 0.051535964\n",
      "Epoch: 2111 cost = 0.020002160\n",
      "Validation Loss: 0.03823013\n",
      "Epoch: 2112 cost = 0.019999453\n",
      "Validation Loss: 0.029739954\n",
      "Epoch: 2113 cost = 0.019996477\n",
      "Validation Loss: 0.03303678\n",
      "Epoch: 2114 cost = 0.019993831\n",
      "Validation Loss: 0.046900824\n",
      "Epoch: 2115 cost = 0.019991093\n",
      "Validation Loss: 0.03123003\n",
      "Epoch: 2116 cost = 0.019988396\n",
      "Validation Loss: 0.03839172\n",
      "Epoch: 2117 cost = 0.019985908\n",
      "Validation Loss: 0.038767945\n",
      "Epoch: 2118 cost = 0.019983049\n",
      "Validation Loss: 0.03719243\n",
      "Epoch: 2119 cost = 0.019980224\n",
      "Validation Loss: 0.036259793\n",
      "Epoch: 2120 cost = 0.019977483\n",
      "Validation Loss: 0.04529593\n",
      "Epoch: 2121 cost = 0.019974807\n",
      "Validation Loss: 0.050828144\n",
      "Epoch: 2122 cost = 0.019971962\n",
      "Validation Loss: 0.038161643\n",
      "Epoch: 2123 cost = 0.019969176\n",
      "Validation Loss: 0.02521821\n",
      "Epoch: 2124 cost = 0.019966561\n",
      "Validation Loss: 0.03159216\n",
      "Epoch: 2125 cost = 0.019963626\n",
      "Validation Loss: 0.037513565\n",
      "Epoch: 2126 cost = 0.019961315\n",
      "Validation Loss: 0.048064373\n",
      "Epoch: 2127 cost = 0.019958458\n",
      "Validation Loss: 0.04142611\n",
      "Epoch: 2128 cost = 0.019955728\n",
      "Validation Loss: 0.046193913\n",
      "Epoch: 2129 cost = 0.019953012\n",
      "Validation Loss: 0.046869874\n",
      "Epoch: 2130 cost = 0.019950410\n",
      "Validation Loss: 0.031516787\n",
      "Epoch: 2131 cost = 0.019947458\n",
      "Validation Loss: 0.046979517\n",
      "Epoch: 2132 cost = 0.019944937\n",
      "Validation Loss: 0.052016962\n",
      "Epoch: 2133 cost = 0.019942420\n",
      "Validation Loss: 0.056506675\n",
      "Epoch: 2134 cost = 0.019939538\n",
      "Validation Loss: 0.049861845\n",
      "Epoch: 2135 cost = 0.019936909\n",
      "Validation Loss: 0.04036753\n",
      "Epoch: 2136 cost = 0.019934230\n",
      "Validation Loss: 0.037441503\n",
      "Epoch: 2137 cost = 0.019931420\n",
      "Validation Loss: 0.04538741\n",
      "Epoch: 2138 cost = 0.019928661\n",
      "Validation Loss: 0.048336394\n",
      "Epoch: 2139 cost = 0.019926213\n",
      "Validation Loss: 0.04314403\n",
      "Epoch: 2140 cost = 0.019923295\n",
      "Validation Loss: 0.041430566\n",
      "Epoch: 2141 cost = 0.019920651\n",
      "Validation Loss: 0.03684314\n",
      "Epoch: 2142 cost = 0.019917902\n",
      "Validation Loss: 0.03487705\n",
      "Epoch: 2143 cost = 0.019915559\n",
      "Validation Loss: 0.029952286\n",
      "Epoch: 2144 cost = 0.019912614\n",
      "Validation Loss: 0.031715486\n",
      "Epoch: 2145 cost = 0.019909915\n",
      "Validation Loss: 0.037300844\n",
      "Epoch: 2146 cost = 0.019907545\n",
      "Validation Loss: 0.038208682\n",
      "Epoch: 2147 cost = 0.019904785\n",
      "Validation Loss: 0.035621047\n",
      "Epoch: 2148 cost = 0.019902136\n",
      "Validation Loss: 0.025926264\n",
      "Epoch: 2149 cost = 0.019899523\n",
      "Validation Loss: 0.03787954\n",
      "Epoch: 2150 cost = 0.019896761\n",
      "Validation Loss: 0.04987752\n",
      "Epoch: 2151 cost = 0.019894217\n",
      "Validation Loss: 0.05256972\n",
      "Epoch: 2152 cost = 0.019891491\n",
      "Validation Loss: 0.056769747\n",
      "Epoch: 2153 cost = 0.019889014\n",
      "Validation Loss: 0.06866887\n",
      "Epoch: 2154 cost = 0.019886421\n",
      "Validation Loss: 0.064172395\n",
      "Epoch: 2155 cost = 0.019883435\n",
      "Validation Loss: 0.06216926\n",
      "Epoch: 2156 cost = 0.019880804\n",
      "Validation Loss: 0.04920065\n",
      "Epoch: 2157 cost = 0.019878250\n",
      "Validation Loss: 0.040235735\n",
      "Epoch: 2158 cost = 0.019875753\n",
      "Validation Loss: 0.04483675\n",
      "Epoch: 2159 cost = 0.019873097\n",
      "Validation Loss: 0.03346116\n",
      "Epoch: 2160 cost = 0.019870367\n",
      "Validation Loss: 0.029640425\n",
      "Epoch: 2161 cost = 0.019867661\n",
      "Validation Loss: 0.023963211\n",
      "Epoch: 2162 cost = 0.019864962\n",
      "Validation Loss: 0.03615725\n",
      "Epoch: 2163 cost = 0.019862510\n",
      "Validation Loss: 0.046883218\n",
      "Epoch: 2164 cost = 0.019860146\n",
      "Validation Loss: 0.062111605\n",
      "Epoch: 2165 cost = 0.019857282\n",
      "Validation Loss: 0.04626296\n",
      "Epoch: 2166 cost = 0.019854739\n",
      "Validation Loss: 0.031861294\n",
      "Epoch: 2167 cost = 0.019851972\n",
      "Validation Loss: 0.029191809\n",
      "Epoch: 2168 cost = 0.019849608\n",
      "Validation Loss: 0.035162307\n",
      "Epoch: 2169 cost = 0.019846847\n",
      "Validation Loss: 0.034805577\n",
      "Epoch: 2170 cost = 0.019844276\n",
      "Validation Loss: 0.03473966\n",
      "Epoch: 2171 cost = 0.019841929\n",
      "Validation Loss: 0.033364348\n",
      "Epoch: 2172 cost = 0.019839280\n",
      "Validation Loss: 0.02925254\n",
      "Epoch: 2173 cost = 0.019836344\n",
      "Validation Loss: 0.029082121\n",
      "Epoch: 2174 cost = 0.019833700\n",
      "Validation Loss: 0.0453233\n",
      "Epoch: 2175 cost = 0.019831183\n",
      "Validation Loss: 0.04198568\n",
      "Epoch: 2176 cost = 0.019829073\n",
      "Validation Loss: 0.03562475\n",
      "Epoch: 2177 cost = 0.019826123\n",
      "Validation Loss: 0.040356528\n",
      "Epoch: 2178 cost = 0.019823515\n",
      "Validation Loss: 0.06309801\n",
      "Epoch: 2179 cost = 0.019821264\n",
      "Validation Loss: 0.05844921\n",
      "Epoch: 2180 cost = 0.019818402\n",
      "Validation Loss: 0.047781445\n",
      "Epoch: 2181 cost = 0.019815804\n",
      "Validation Loss: 0.041378215\n",
      "Epoch: 2182 cost = 0.019813365\n",
      "Validation Loss: 0.042841293\n",
      "Epoch: 2183 cost = 0.019810760\n",
      "Validation Loss: 0.0345695\n",
      "Epoch: 2184 cost = 0.019808172\n",
      "Validation Loss: 0.03168736\n",
      "Epoch: 2185 cost = 0.019805624\n",
      "Validation Loss: 0.029554205\n",
      "Epoch: 2186 cost = 0.019803086\n",
      "Validation Loss: 0.025636403\n",
      "Epoch: 2187 cost = 0.019800461\n",
      "Validation Loss: 0.02741162\n",
      "Epoch: 2188 cost = 0.019797828\n",
      "Validation Loss: 0.02755559\n",
      "Epoch: 2189 cost = 0.019795591\n",
      "Validation Loss: 0.034611348\n",
      "Epoch: 2190 cost = 0.019792762\n",
      "Validation Loss: 0.050169762\n",
      "Epoch: 2191 cost = 0.019790347\n",
      "Validation Loss: 0.054453496\n",
      "Epoch: 2192 cost = 0.019787494\n",
      "Validation Loss: 0.047900937\n",
      "Epoch: 2193 cost = 0.019785269\n",
      "Validation Loss: 0.041092075\n",
      "Epoch: 2194 cost = 0.019782630\n",
      "Validation Loss: 0.03840394\n",
      "Epoch: 2195 cost = 0.019780082\n",
      "Validation Loss: 0.03241474\n",
      "Epoch: 2196 cost = 0.019777712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.031195803\n",
      "Epoch: 2197 cost = 0.019774850\n",
      "Validation Loss: 0.03008819\n",
      "Epoch: 2198 cost = 0.019772429\n",
      "Validation Loss: 0.026917148\n",
      "Epoch: 2199 cost = 0.019769922\n",
      "Validation Loss: 0.030061819\n",
      "Epoch: 2200 cost = 0.019767478\n",
      "Validation Loss: 0.02685777\n",
      "Epoch: 2201 cost = 0.019764984\n",
      "Validation Loss: 0.035327934\n",
      "Epoch: 2202 cost = 0.019762460\n",
      "Validation Loss: 0.033775214\n",
      "Epoch: 2203 cost = 0.019759865\n",
      "Validation Loss: 0.039390806\n",
      "Epoch: 2204 cost = 0.019757382\n",
      "Validation Loss: 0.040281165\n",
      "Epoch: 2205 cost = 0.019754976\n",
      "Validation Loss: 0.06965217\n",
      "Epoch: 2206 cost = 0.019752451\n",
      "Validation Loss: 0.076327555\n",
      "Epoch: 2207 cost = 0.019749686\n",
      "Validation Loss: 0.07502393\n",
      "Epoch: 2208 cost = 0.019747241\n",
      "Validation Loss: 0.06011104\n",
      "Epoch: 2209 cost = 0.019744868\n",
      "Validation Loss: 0.094403766\n",
      "Epoch: 2210 cost = 0.019742180\n",
      "Validation Loss: 0.110198855\n",
      "Epoch: 2211 cost = 0.019739843\n",
      "Validation Loss: 0.081882104\n",
      "Epoch: 2212 cost = 0.019737579\n",
      "Validation Loss: 0.056056976\n",
      "Epoch: 2213 cost = 0.019734986\n",
      "Validation Loss: 0.044691794\n",
      "Epoch: 2214 cost = 0.019732086\n",
      "Validation Loss: 0.028980741\n",
      "Epoch: 2215 cost = 0.019729859\n",
      "Validation Loss: 0.047563165\n",
      "Epoch: 2216 cost = 0.019727347\n",
      "Validation Loss: 0.058169257\n",
      "Epoch: 2217 cost = 0.019724714\n",
      "Validation Loss: 0.03711676\n",
      "Epoch: 2218 cost = 0.019722396\n",
      "Validation Loss: 0.029063487\n",
      "Epoch: 2219 cost = 0.019719944\n",
      "Validation Loss: 0.037550554\n",
      "Epoch: 2220 cost = 0.019717593\n",
      "Validation Loss: 0.03554249\n",
      "Epoch: 2221 cost = 0.019715089\n",
      "Validation Loss: 0.026441965\n",
      "Epoch: 2222 cost = 0.019712627\n",
      "Validation Loss: 0.038443178\n",
      "Epoch: 2223 cost = 0.019710217\n",
      "Validation Loss: 0.034795213\n",
      "Epoch: 2224 cost = 0.019707480\n",
      "Validation Loss: 0.028494705\n",
      "Epoch: 2225 cost = 0.019705035\n",
      "Validation Loss: 0.033090208\n",
      "Epoch: 2226 cost = 0.019702925\n",
      "Validation Loss: 0.04024767\n",
      "Epoch: 2227 cost = 0.019700345\n",
      "Validation Loss: 0.04306774\n",
      "Epoch: 2228 cost = 0.019697736\n",
      "Validation Loss: 0.038748145\n",
      "Epoch: 2229 cost = 0.019695420\n",
      "Validation Loss: 0.039380882\n",
      "Epoch: 2230 cost = 0.019692744\n",
      "Validation Loss: 0.03259178\n",
      "Epoch: 2231 cost = 0.019690184\n",
      "Validation Loss: 0.043057732\n",
      "Epoch: 2232 cost = 0.019687742\n",
      "Validation Loss: 0.06105624\n",
      "Epoch: 2233 cost = 0.019685660\n",
      "Validation Loss: 0.060215626\n",
      "Epoch: 2234 cost = 0.019683064\n",
      "Validation Loss: 0.048750937\n",
      "Epoch: 2235 cost = 0.019680773\n",
      "Validation Loss: 0.057288513\n",
      "Epoch: 2236 cost = 0.019678024\n",
      "Validation Loss: 0.060429808\n",
      "Epoch: 2237 cost = 0.019675691\n",
      "Validation Loss: 0.0427732\n",
      "Epoch: 2238 cost = 0.019673258\n",
      "Validation Loss: 0.039072584\n",
      "Epoch: 2239 cost = 0.019671152\n",
      "Validation Loss: 0.032671142\n",
      "Epoch: 2240 cost = 0.019668362\n",
      "Validation Loss: 0.036983088\n",
      "Epoch: 2241 cost = 0.019666132\n",
      "Validation Loss: 0.02762172\n",
      "Epoch: 2242 cost = 0.019663411\n",
      "Validation Loss: 0.03721971\n",
      "Epoch: 2243 cost = 0.019661299\n",
      "Validation Loss: 0.049428657\n",
      "Epoch: 2244 cost = 0.019658920\n",
      "Validation Loss: 0.05639358\n",
      "Epoch: 2245 cost = 0.019656178\n",
      "Validation Loss: 0.055444445\n",
      "Epoch: 2246 cost = 0.019654061\n",
      "Validation Loss: 0.04055493\n",
      "Epoch: 2247 cost = 0.019651586\n",
      "Validation Loss: 0.029631754\n",
      "Epoch: 2248 cost = 0.019649167\n",
      "Validation Loss: 0.04089772\n",
      "Epoch: 2249 cost = 0.019646863\n",
      "Validation Loss: 0.046633672\n",
      "Epoch: 2250 cost = 0.019644347\n",
      "Validation Loss: 0.034544177\n",
      "Epoch: 2251 cost = 0.019642054\n",
      "Validation Loss: 0.032741953\n",
      "Epoch: 2252 cost = 0.019639455\n",
      "Validation Loss: 0.043159947\n",
      "Epoch: 2253 cost = 0.019637327\n",
      "Validation Loss: 0.062590234\n",
      "Epoch: 2254 cost = 0.019634861\n",
      "Validation Loss: 0.035643004\n",
      "Epoch: 2255 cost = 0.019632413\n",
      "Validation Loss: 0.029189833\n",
      "Epoch: 2256 cost = 0.019629955\n",
      "Validation Loss: 0.050295487\n",
      "Epoch: 2257 cost = 0.019627508\n",
      "Validation Loss: 0.068693794\n",
      "Epoch: 2258 cost = 0.019625162\n",
      "Validation Loss: 0.065473\n",
      "Epoch: 2259 cost = 0.019622741\n",
      "Validation Loss: 0.056292918\n",
      "Epoch: 2260 cost = 0.019620506\n",
      "Validation Loss: 0.0356934\n",
      "Epoch: 2261 cost = 0.019618112\n",
      "Validation Loss: 0.03310229\n",
      "Epoch: 2262 cost = 0.019616012\n",
      "Validation Loss: 0.044971395\n",
      "Epoch: 2263 cost = 0.019613348\n",
      "Validation Loss: 0.048329327\n",
      "Epoch: 2264 cost = 0.019610952\n",
      "Validation Loss: 0.03646748\n",
      "Epoch: 2265 cost = 0.019608612\n",
      "Validation Loss: 0.045196757\n",
      "Epoch: 2266 cost = 0.019606411\n",
      "Validation Loss: 0.05384246\n",
      "Epoch: 2267 cost = 0.019603832\n",
      "Validation Loss: 0.06440005\n",
      "Epoch: 2268 cost = 0.019601453\n",
      "Validation Loss: 0.03925253\n",
      "Epoch: 2269 cost = 0.019599344\n",
      "Validation Loss: 0.03770908\n",
      "Epoch: 2270 cost = 0.019596540\n",
      "Validation Loss: 0.049240515\n",
      "Epoch: 2271 cost = 0.019594163\n",
      "Validation Loss: 0.03661194\n",
      "Epoch: 2272 cost = 0.019592358\n",
      "Validation Loss: 0.040007778\n",
      "Epoch: 2273 cost = 0.019589759\n",
      "Validation Loss: 0.03698171\n",
      "Epoch: 2274 cost = 0.019587423\n",
      "Validation Loss: 0.027455725\n",
      "Epoch: 2275 cost = 0.019585243\n",
      "Validation Loss: 0.035607453\n",
      "Epoch: 2276 cost = 0.019582720\n",
      "Validation Loss: 0.03918584\n",
      "Epoch: 2277 cost = 0.019580295\n",
      "Validation Loss: 0.026697423\n",
      "Epoch: 2278 cost = 0.019578252\n",
      "Validation Loss: 0.041619662\n",
      "Epoch: 2279 cost = 0.019575862\n",
      "Validation Loss: 0.036054417\n",
      "Epoch: 2280 cost = 0.019573274\n",
      "Validation Loss: 0.029283533\n",
      "Epoch: 2281 cost = 0.019571074\n",
      "Validation Loss: 0.034833338\n",
      "Epoch: 2282 cost = 0.019568888\n",
      "Validation Loss: 0.045668624\n",
      "Epoch: 2283 cost = 0.019566534\n",
      "Validation Loss: 0.064803556\n",
      "Epoch: 2284 cost = 0.019563990\n",
      "Validation Loss: 0.07510457\n",
      "Epoch: 2285 cost = 0.019561838\n",
      "Validation Loss: 0.03492812\n",
      "Epoch: 2286 cost = 0.019559470\n",
      "Validation Loss: 0.056818463\n",
      "Epoch: 2287 cost = 0.019557217\n",
      "Validation Loss: 0.0577452\n",
      "Epoch: 2288 cost = 0.019554951\n",
      "Validation Loss: 0.036491606\n",
      "Epoch: 2289 cost = 0.019552552\n",
      "Validation Loss: 0.034392256\n",
      "Epoch: 2290 cost = 0.019549959\n",
      "Validation Loss: 0.046299137\n",
      "Epoch: 2291 cost = 0.019547976\n",
      "Validation Loss: 0.05095953\n",
      "Epoch: 2292 cost = 0.019545784\n",
      "Validation Loss: 0.052224983\n",
      "Epoch: 2293 cost = 0.019543335\n",
      "Validation Loss: 0.064641416\n",
      "Epoch: 2294 cost = 0.019541112\n",
      "Validation Loss: 0.07179342\n",
      "Epoch: 2295 cost = 0.019538858\n",
      "Validation Loss: 0.059113875\n",
      "Epoch: 2296 cost = 0.019536352\n",
      "Validation Loss: 0.043928698\n",
      "Epoch: 2297 cost = 0.019534043\n",
      "Validation Loss: 0.048187576\n",
      "Epoch: 2298 cost = 0.019532009\n",
      "Validation Loss: 0.04169976\n",
      "Epoch: 2299 cost = 0.019529592\n",
      "Validation Loss: 0.035665855\n",
      "Epoch: 2300 cost = 0.019527305\n",
      "Validation Loss: 0.035363793\n",
      "Epoch: 2301 cost = 0.019524926\n",
      "Validation Loss: 0.033827957\n",
      "Epoch: 2302 cost = 0.019522674\n",
      "Validation Loss: 0.034367014\n",
      "Epoch: 2303 cost = 0.019520561\n",
      "Validation Loss: 0.07351388\n",
      "Epoch: 2304 cost = 0.019518449\n",
      "Validation Loss: 0.07459368\n",
      "Epoch: 2305 cost = 0.019515871\n",
      "Validation Loss: 0.061406225\n",
      "Epoch: 2306 cost = 0.019513735\n",
      "Validation Loss: 0.04666066\n",
      "Epoch: 2307 cost = 0.019511634\n",
      "Validation Loss: 0.043626804\n",
      "Epoch: 2308 cost = 0.019509121\n",
      "Validation Loss: 0.041383434\n",
      "Epoch: 2309 cost = 0.019506837\n",
      "Validation Loss: 0.0389038\n",
      "Epoch: 2310 cost = 0.019504629\n",
      "Validation Loss: 0.03346662\n",
      "Epoch: 2311 cost = 0.019502464\n",
      "Validation Loss: 0.040534247\n",
      "Epoch: 2312 cost = 0.019500186\n",
      "Validation Loss: 0.038485117\n",
      "Epoch: 2313 cost = 0.019497936\n",
      "Validation Loss: 0.033618893\n",
      "Epoch: 2314 cost = 0.019495327\n",
      "Validation Loss: 0.02895005\n",
      "Epoch: 2315 cost = 0.019493188\n",
      "Validation Loss: 0.032060266\n",
      "Epoch: 2316 cost = 0.019491281\n",
      "Validation Loss: 0.036289047\n",
      "Epoch: 2317 cost = 0.019489022\n",
      "Validation Loss: 0.048089575\n",
      "Epoch: 2318 cost = 0.019486438\n",
      "Validation Loss: 0.048326716\n",
      "Epoch: 2319 cost = 0.019484683\n",
      "Validation Loss: 0.04224304\n",
      "Epoch: 2320 cost = 0.019482370\n",
      "Validation Loss: 0.03280854\n",
      "Epoch: 2321 cost = 0.019480076\n",
      "Validation Loss: 0.045560464\n",
      "Epoch: 2322 cost = 0.019477927\n",
      "Validation Loss: 0.050943468\n",
      "Epoch: 2323 cost = 0.019475551\n",
      "Validation Loss: 0.05706522\n",
      "Epoch: 2324 cost = 0.019473130\n",
      "Validation Loss: 0.042829297\n",
      "Epoch: 2325 cost = 0.019471045\n",
      "Validation Loss: 0.03286396\n",
      "Epoch: 2326 cost = 0.019468897\n",
      "Validation Loss: 0.039607696\n",
      "Epoch: 2327 cost = 0.019466445\n",
      "Validation Loss: 0.04600081\n",
      "Epoch: 2328 cost = 0.019464307\n",
      "Validation Loss: 0.053414255\n",
      "Epoch: 2329 cost = 0.019462357\n",
      "Validation Loss: 0.050096914\n",
      "Epoch: 2330 cost = 0.019460154\n",
      "Validation Loss: 0.058730643\n",
      "Epoch: 2331 cost = 0.019457649\n",
      "Validation Loss: 0.056046903\n",
      "Epoch: 2332 cost = 0.019455731\n",
      "Validation Loss: 0.048302073\n",
      "Epoch: 2333 cost = 0.019453449\n",
      "Validation Loss: 0.034604803\n",
      "Epoch: 2334 cost = 0.019451036\n",
      "Validation Loss: 0.028030878\n",
      "Epoch: 2335 cost = 0.019448747\n",
      "Validation Loss: 0.023253953\n",
      "Epoch: 2336 cost = 0.019446395\n",
      "Validation Loss: 0.02874967\n",
      "Epoch: 2337 cost = 0.019444470\n",
      "Validation Loss: 0.03436224\n",
      "Epoch: 2338 cost = 0.019442569\n",
      "Validation Loss: 0.041363306\n",
      "Epoch: 2339 cost = 0.019440076\n",
      "Validation Loss: 0.03162307\n",
      "Epoch: 2340 cost = 0.019437845\n",
      "Validation Loss: 0.026237637\n",
      "Epoch: 2341 cost = 0.019435961\n",
      "Validation Loss: 0.02760809\n",
      "Epoch: 2342 cost = 0.019433462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.039577577\n",
      "Epoch: 2343 cost = 0.019431566\n",
      "Validation Loss: 0.041208588\n",
      "Epoch: 2344 cost = 0.019429207\n",
      "Validation Loss: 0.03366039\n",
      "Epoch: 2345 cost = 0.019427096\n",
      "Validation Loss: 0.03365224\n",
      "Epoch: 2346 cost = 0.019424862\n",
      "Validation Loss: 0.035461307\n",
      "Epoch: 2347 cost = 0.019422603\n",
      "Validation Loss: 0.03673924\n",
      "Epoch: 2348 cost = 0.019420553\n",
      "Validation Loss: 0.033770368\n",
      "Epoch: 2349 cost = 0.019418303\n",
      "Validation Loss: 0.03574243\n",
      "Epoch: 2350 cost = 0.019416491\n",
      "Validation Loss: 0.043911986\n",
      "Epoch: 2351 cost = 0.019414092\n",
      "Validation Loss: 0.03751379\n",
      "Epoch: 2352 cost = 0.019411889\n",
      "Validation Loss: 0.041927267\n",
      "Epoch: 2353 cost = 0.019409457\n",
      "Validation Loss: 0.044752415\n",
      "Epoch: 2354 cost = 0.019407795\n",
      "Validation Loss: 0.035172686\n",
      "Epoch: 2355 cost = 0.019405393\n",
      "Validation Loss: 0.029519852\n",
      "Epoch: 2356 cost = 0.019403389\n",
      "Validation Loss: 0.037308432\n",
      "Epoch: 2357 cost = 0.019401077\n",
      "Validation Loss: 0.04319412\n",
      "Epoch: 2358 cost = 0.019398913\n",
      "Validation Loss: 0.044137713\n",
      "Epoch: 2359 cost = 0.019396751\n",
      "Validation Loss: 0.05877437\n",
      "Epoch: 2360 cost = 0.019394556\n",
      "Validation Loss: 0.05033353\n",
      "Epoch: 2361 cost = 0.019392626\n",
      "Validation Loss: 0.05445617\n",
      "Epoch: 2362 cost = 0.019390255\n",
      "Validation Loss: 0.05790256\n",
      "Epoch: 2363 cost = 0.019387975\n",
      "Validation Loss: 0.032159567\n",
      "Epoch: 2364 cost = 0.019385889\n",
      "Validation Loss: 0.030602593\n",
      "Epoch: 2365 cost = 0.019383971\n",
      "Validation Loss: 0.037566576\n",
      "Epoch: 2366 cost = 0.019381709\n",
      "Validation Loss: 0.04337777\n",
      "Epoch: 2367 cost = 0.019379485\n",
      "Validation Loss: 0.050197694\n",
      "Epoch: 2368 cost = 0.019377599\n",
      "Validation Loss: 0.03730968\n",
      "Epoch: 2369 cost = 0.019375375\n",
      "Validation Loss: 0.033296917\n",
      "Epoch: 2370 cost = 0.019373493\n",
      "Validation Loss: 0.039546713\n",
      "Epoch: 2371 cost = 0.019371315\n",
      "Validation Loss: 0.04372879\n",
      "Epoch: 2372 cost = 0.019369288\n",
      "Validation Loss: 0.03861745\n",
      "Epoch: 2373 cost = 0.019366944\n",
      "Validation Loss: 0.047190677\n",
      "Epoch: 2374 cost = 0.019365001\n",
      "Validation Loss: 0.04231112\n",
      "Epoch: 2375 cost = 0.019362720\n",
      "Validation Loss: 0.03272983\n",
      "Epoch: 2376 cost = 0.019360857\n",
      "Validation Loss: 0.027145162\n",
      "Epoch: 2377 cost = 0.019358447\n",
      "Validation Loss: 0.03653393\n",
      "Epoch: 2378 cost = 0.019356130\n",
      "Validation Loss: 0.062693715\n",
      "Epoch: 2379 cost = 0.019354210\n",
      "Validation Loss: 0.058444224\n",
      "Epoch: 2380 cost = 0.019352311\n",
      "Validation Loss: 0.03919446\n",
      "Epoch: 2381 cost = 0.019350239\n",
      "Validation Loss: 0.03072433\n",
      "Epoch: 2382 cost = 0.019348018\n",
      "Validation Loss: 0.03360343\n",
      "Epoch: 2383 cost = 0.019345985\n",
      "Validation Loss: 0.042540964\n",
      "Epoch: 2384 cost = 0.019343934\n",
      "Validation Loss: 0.04994163\n",
      "Epoch: 2385 cost = 0.019341722\n",
      "Validation Loss: 0.06438341\n",
      "Epoch: 2386 cost = 0.019339666\n",
      "Validation Loss: 0.05669804\n",
      "Epoch: 2387 cost = 0.019337582\n",
      "Validation Loss: 0.042469606\n",
      "Epoch: 2388 cost = 0.019335679\n",
      "Validation Loss: 0.029413266\n",
      "Epoch: 2389 cost = 0.019333640\n",
      "Validation Loss: 0.029164521\n",
      "Epoch: 2390 cost = 0.019331315\n",
      "Validation Loss: 0.024220195\n",
      "Epoch: 2391 cost = 0.019329060\n",
      "Validation Loss: 0.02488789\n",
      "Epoch: 2392 cost = 0.019327284\n",
      "Validation Loss: 0.02184823\n",
      "Epoch: 2393 cost = 0.019325006\n",
      "Validation Loss: 0.035144195\n",
      "Epoch: 2394 cost = 0.019323159\n",
      "Validation Loss: 0.058074504\n",
      "Epoch: 2395 cost = 0.019321211\n",
      "Validation Loss: 0.04000056\n",
      "Epoch: 2396 cost = 0.019318877\n",
      "Validation Loss: 0.03009855\n",
      "Epoch: 2397 cost = 0.019317219\n",
      "Validation Loss: 0.041738547\n",
      "Epoch: 2398 cost = 0.019314782\n",
      "Validation Loss: 0.039034035\n",
      "Epoch: 2399 cost = 0.019312816\n",
      "Validation Loss: 0.038420603\n",
      "Epoch: 2400 cost = 0.019310731\n",
      "Validation Loss: 0.043835413\n",
      "Epoch: 2401 cost = 0.019308698\n",
      "Validation Loss: 0.035745375\n",
      "Epoch: 2402 cost = 0.019306632\n",
      "Validation Loss: 0.050332434\n",
      "Epoch: 2403 cost = 0.019304485\n",
      "Validation Loss: 0.046033975\n",
      "Epoch: 2404 cost = 0.019302646\n",
      "Validation Loss: 0.034983225\n",
      "Epoch: 2405 cost = 0.019300411\n",
      "Validation Loss: 0.029866919\n",
      "Epoch: 2406 cost = 0.019298432\n",
      "Validation Loss: 0.031168893\n",
      "Epoch: 2407 cost = 0.019296305\n",
      "Validation Loss: 0.03013449\n",
      "Epoch: 2408 cost = 0.019294327\n",
      "Validation Loss: 0.038166117\n",
      "Epoch: 2409 cost = 0.019292156\n",
      "Validation Loss: 0.037799492\n",
      "Epoch: 2410 cost = 0.019290091\n",
      "Validation Loss: 0.041664094\n",
      "Epoch: 2411 cost = 0.019288083\n",
      "Validation Loss: 0.04837203\n",
      "Epoch: 2412 cost = 0.019285832\n",
      "Validation Loss: 0.03994943\n",
      "Epoch: 2413 cost = 0.019284091\n",
      "Validation Loss: 0.05453894\n",
      "Epoch: 2414 cost = 0.019282126\n",
      "Validation Loss: 0.045785166\n",
      "Epoch: 2415 cost = 0.019280465\n",
      "Validation Loss: 0.02808728\n",
      "Epoch: 2416 cost = 0.019277976\n",
      "Validation Loss: 0.029246219\n",
      "Epoch: 2417 cost = 0.019275944\n",
      "Validation Loss: 0.0230308\n",
      "Epoch: 2418 cost = 0.019273969\n",
      "Validation Loss: 0.033764847\n",
      "Epoch: 2419 cost = 0.019271832\n",
      "Validation Loss: 0.04750073\n",
      "Epoch: 2420 cost = 0.019269624\n",
      "Validation Loss: 0.037051495\n",
      "Epoch: 2421 cost = 0.019268170\n",
      "Validation Loss: 0.04007044\n",
      "Epoch: 2422 cost = 0.019265838\n",
      "Validation Loss: 0.031627033\n",
      "Epoch: 2423 cost = 0.019263975\n",
      "Validation Loss: 0.043581646\n",
      "Epoch: 2424 cost = 0.019261724\n",
      "Validation Loss: 0.0626354\n",
      "Epoch: 2425 cost = 0.019260030\n",
      "Validation Loss: 0.07303169\n",
      "Epoch: 2426 cost = 0.019257775\n",
      "Validation Loss: 0.05884037\n",
      "Epoch: 2427 cost = 0.019255736\n",
      "Validation Loss: 0.041970327\n",
      "Epoch: 2428 cost = 0.019253895\n",
      "Validation Loss: 0.030504415\n",
      "Epoch: 2429 cost = 0.019251946\n",
      "Validation Loss: 0.04411559\n",
      "Epoch: 2430 cost = 0.019250149\n",
      "Validation Loss: 0.03909401\n",
      "Epoch: 2431 cost = 0.019247783\n",
      "Validation Loss: 0.027864087\n",
      "Epoch: 2432 cost = 0.019245749\n",
      "Validation Loss: 0.043380376\n",
      "Epoch: 2433 cost = 0.019243870\n",
      "Validation Loss: 0.029370904\n",
      "Epoch: 2434 cost = 0.019242163\n",
      "Validation Loss: 0.024548104\n",
      "Epoch: 2435 cost = 0.019240009\n",
      "Validation Loss: 0.044099443\n",
      "Epoch: 2436 cost = 0.019237858\n",
      "Validation Loss: 0.05175248\n",
      "Epoch: 2437 cost = 0.019236282\n",
      "Validation Loss: 0.044932265\n",
      "Epoch: 2438 cost = 0.019233768\n",
      "Validation Loss: 0.04630668\n",
      "Epoch: 2439 cost = 0.019232004\n",
      "Validation Loss: 0.03253725\n",
      "Epoch: 2440 cost = 0.019229991\n",
      "Validation Loss: 0.04253215\n",
      "Epoch: 2441 cost = 0.019227742\n",
      "Validation Loss: 0.05982944\n",
      "Epoch: 2442 cost = 0.019226113\n",
      "Validation Loss: 0.07320492\n",
      "Epoch: 2443 cost = 0.019224319\n",
      "Validation Loss: 0.061186135\n",
      "Epoch: 2444 cost = 0.019222092\n",
      "Validation Loss: 0.049680673\n",
      "Epoch: 2445 cost = 0.019220231\n",
      "Validation Loss: 0.058068186\n",
      "Epoch: 2446 cost = 0.019218247\n",
      "Validation Loss: 0.048425227\n",
      "Epoch: 2447 cost = 0.019216251\n",
      "Validation Loss: 0.04769979\n",
      "Epoch: 2448 cost = 0.019214535\n",
      "Validation Loss: 0.032358926\n",
      "Epoch: 2449 cost = 0.019212271\n",
      "Validation Loss: 0.029517533\n",
      "Epoch: 2450 cost = 0.019210448\n",
      "Validation Loss: 0.03498277\n",
      "Epoch: 2451 cost = 0.019208507\n",
      "Validation Loss: 0.03242316\n",
      "Epoch: 2452 cost = 0.019206431\n",
      "Validation Loss: 0.02953687\n",
      "Epoch: 2453 cost = 0.019204578\n",
      "Validation Loss: 0.048939116\n",
      "Epoch: 2454 cost = 0.019202413\n",
      "Validation Loss: 0.038583517\n",
      "Epoch: 2455 cost = 0.019200345\n",
      "Validation Loss: 0.045063064\n",
      "Epoch: 2456 cost = 0.019198676\n",
      "Validation Loss: 0.05866422\n",
      "Epoch: 2457 cost = 0.019196861\n",
      "Validation Loss: 0.04218223\n",
      "Epoch: 2458 cost = 0.019194836\n",
      "Validation Loss: 0.044405725\n",
      "Epoch: 2459 cost = 0.019192789\n",
      "Validation Loss: 0.052705\n",
      "Epoch: 2460 cost = 0.019191164\n",
      "Validation Loss: 0.08143817\n",
      "Epoch: 2461 cost = 0.019188824\n",
      "Validation Loss: 0.055424966\n",
      "Epoch: 2462 cost = 0.019187132\n",
      "Validation Loss: 0.051023364\n",
      "Epoch: 2463 cost = 0.019185183\n",
      "Validation Loss: 0.0429457\n",
      "Epoch: 2464 cost = 0.019183191\n",
      "Validation Loss: 0.045794804\n",
      "Epoch: 2465 cost = 0.019181440\n",
      "Validation Loss: 0.047391396\n",
      "Epoch: 2466 cost = 0.019179276\n",
      "Validation Loss: 0.050596736\n",
      "Epoch: 2467 cost = 0.019177443\n",
      "Validation Loss: 0.04474192\n",
      "Epoch: 2468 cost = 0.019175529\n",
      "Validation Loss: 0.035045564\n",
      "Epoch: 2469 cost = 0.019173534\n",
      "Validation Loss: 0.033773873\n",
      "Epoch: 2470 cost = 0.019171601\n",
      "Validation Loss: 0.025507627\n",
      "Epoch: 2471 cost = 0.019169545\n",
      "Validation Loss: 0.023702502\n",
      "Epoch: 2472 cost = 0.019167843\n",
      "Validation Loss: 0.037669457\n",
      "Epoch: 2473 cost = 0.019166070\n",
      "Validation Loss: 0.057718474\n",
      "Epoch: 2474 cost = 0.019164065\n",
      "Validation Loss: 0.050722472\n",
      "Epoch: 2475 cost = 0.019161861\n",
      "Validation Loss: 0.046666913\n",
      "Epoch: 2476 cost = 0.019160265\n",
      "Validation Loss: 0.04349943\n",
      "Epoch: 2477 cost = 0.019158508\n",
      "Validation Loss: 0.027755642\n",
      "Epoch: 2478 cost = 0.019156189\n",
      "Validation Loss: 0.0414142\n",
      "Epoch: 2479 cost = 0.019154286\n",
      "Validation Loss: 0.06932698\n",
      "Epoch: 2480 cost = 0.019152422\n",
      "Validation Loss: 0.061068274\n",
      "Epoch: 2481 cost = 0.019150445\n",
      "Validation Loss: 0.03822214\n",
      "Epoch: 2482 cost = 0.019148642\n",
      "Validation Loss: 0.035168204\n",
      "Epoch: 2483 cost = 0.019146725\n",
      "Validation Loss: 0.03489168\n",
      "Epoch: 2484 cost = 0.019144869\n",
      "Validation Loss: 0.04428413\n",
      "Epoch: 2485 cost = 0.019143097\n",
      "Validation Loss: 0.04611721\n",
      "Epoch: 2486 cost = 0.019141434\n",
      "Validation Loss: 0.043761864\n",
      "Epoch: 2487 cost = 0.019139424\n",
      "Validation Loss: 0.04937449\n",
      "Epoch: 2488 cost = 0.019137454\n",
      "Validation Loss: 0.05687783\n",
      "Epoch: 2489 cost = 0.019135415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.06407467\n",
      "Epoch: 2490 cost = 0.019133319\n",
      "Validation Loss: 0.06731611\n",
      "Epoch: 2491 cost = 0.019131742\n",
      "Validation Loss: 0.039894953\n",
      "Epoch: 2492 cost = 0.019129892\n",
      "Validation Loss: 0.044125754\n",
      "Epoch: 2493 cost = 0.019127885\n",
      "Validation Loss: 0.04480762\n",
      "Epoch: 2494 cost = 0.019126144\n",
      "Validation Loss: 0.048575025\n",
      "Epoch: 2495 cost = 0.019124345\n",
      "Validation Loss: 0.03908256\n",
      "Epoch: 2496 cost = 0.019122533\n",
      "Validation Loss: 0.041528746\n",
      "Epoch: 2497 cost = 0.019120546\n",
      "Validation Loss: 0.0572581\n",
      "Epoch: 2498 cost = 0.019118559\n",
      "Validation Loss: 0.05759544\n",
      "Epoch: 2499 cost = 0.019116649\n",
      "Validation Loss: 0.038955286\n",
      "Epoch: 2500 cost = 0.019114931\n",
      "Validation Loss: 0.028638408\n",
      "Epoch: 2501 cost = 0.019113337\n",
      "Validation Loss: 0.022150062\n",
      "Epoch: 2502 cost = 0.019111328\n",
      "Validation Loss: 0.035420902\n",
      "Epoch: 2503 cost = 0.019109479\n",
      "Validation Loss: 0.049885772\n",
      "Epoch: 2504 cost = 0.019107540\n",
      "Validation Loss: 0.03749473\n",
      "Epoch: 2505 cost = 0.019105627\n",
      "Validation Loss: 0.029460793\n",
      "Epoch: 2506 cost = 0.019103676\n",
      "Validation Loss: 0.048169933\n",
      "Epoch: 2507 cost = 0.019102014\n",
      "Validation Loss: 0.037265636\n",
      "Epoch: 2508 cost = 0.019100396\n",
      "Validation Loss: 0.028613102\n",
      "Epoch: 2509 cost = 0.019098268\n",
      "Validation Loss: 0.029323539\n",
      "Epoch: 2510 cost = 0.019096360\n",
      "Validation Loss: 0.033594724\n",
      "Epoch: 2511 cost = 0.019094661\n",
      "Validation Loss: 0.02626519\n",
      "Epoch: 2512 cost = 0.019092618\n",
      "Validation Loss: 0.029064182\n",
      "Epoch: 2513 cost = 0.019090663\n",
      "Validation Loss: 0.04402691\n",
      "Epoch: 2514 cost = 0.019089168\n",
      "Validation Loss: 0.037323054\n",
      "Epoch: 2515 cost = 0.019087136\n",
      "Validation Loss: 0.044368934\n",
      "Epoch: 2516 cost = 0.019085277\n",
      "Validation Loss: 0.04058389\n",
      "Epoch: 2517 cost = 0.019083577\n",
      "Validation Loss: 0.031050093\n",
      "Epoch: 2518 cost = 0.019081692\n",
      "Validation Loss: 0.024094522\n",
      "Epoch: 2519 cost = 0.019079729\n",
      "Validation Loss: 0.048832446\n",
      "Epoch: 2520 cost = 0.019078177\n",
      "Validation Loss: 0.044030048\n",
      "Epoch: 2521 cost = 0.019076340\n",
      "Validation Loss: 0.037139505\n",
      "Epoch: 2522 cost = 0.019074563\n",
      "Validation Loss: 0.027680438\n",
      "Epoch: 2523 cost = 0.019072473\n",
      "Validation Loss: 0.029151835\n",
      "Epoch: 2524 cost = 0.019070500\n",
      "Validation Loss: 0.041742787\n",
      "Epoch: 2525 cost = 0.019068978\n",
      "Validation Loss: 0.038891014\n",
      "Epoch: 2526 cost = 0.019067083\n",
      "Validation Loss: 0.023855137\n",
      "Epoch: 2527 cost = 0.019065263\n",
      "Validation Loss: 0.02560951\n",
      "Epoch: 2528 cost = 0.019063463\n",
      "Validation Loss: 0.024625596\n",
      "Epoch: 2529 cost = 0.019061781\n",
      "Validation Loss: 0.028392024\n",
      "Epoch: 2530 cost = 0.019059886\n",
      "Validation Loss: 0.021941917\n",
      "Epoch: 2531 cost = 0.019057872\n",
      "Validation Loss: 0.044908274\n",
      "Epoch: 2532 cost = 0.019056324\n",
      "Validation Loss: 0.05990344\n",
      "Epoch: 2533 cost = 0.019054532\n",
      "Validation Loss: 0.042181972\n",
      "Epoch: 2534 cost = 0.019052566\n",
      "Validation Loss: 0.0299404\n",
      "Epoch: 2535 cost = 0.019050810\n",
      "Validation Loss: 0.032274626\n",
      "Epoch: 2536 cost = 0.019049022\n",
      "Validation Loss: 0.03525275\n",
      "Epoch: 2537 cost = 0.019047370\n",
      "Validation Loss: 0.03299692\n",
      "Epoch: 2538 cost = 0.019045593\n",
      "Validation Loss: 0.033326704\n",
      "Epoch: 2539 cost = 0.019043873\n",
      "Validation Loss: 0.030083375\n",
      "Epoch: 2540 cost = 0.019042036\n",
      "Validation Loss: 0.038478855\n",
      "Epoch: 2541 cost = 0.019039960\n",
      "Validation Loss: 0.027987087\n",
      "Epoch: 2542 cost = 0.019038137\n",
      "Validation Loss: 0.03931358\n",
      "Epoch: 2543 cost = 0.019036598\n",
      "Validation Loss: 0.045740515\n",
      "Epoch: 2544 cost = 0.019034755\n",
      "Validation Loss: 0.024698513\n",
      "Epoch: 2545 cost = 0.019032809\n",
      "Validation Loss: 0.03562633\n",
      "Epoch: 2546 cost = 0.019031051\n",
      "Validation Loss: 0.033575132\n",
      "Epoch: 2547 cost = 0.019029355\n",
      "Validation Loss: 0.032790884\n",
      "Epoch: 2548 cost = 0.019027302\n",
      "Validation Loss: 0.045477323\n",
      "Epoch: 2549 cost = 0.019025722\n",
      "Validation Loss: 0.04474659\n",
      "Epoch: 2550 cost = 0.019024094\n",
      "Validation Loss: 0.049458936\n",
      "Epoch: 2551 cost = 0.019022127\n",
      "Validation Loss: 0.04085782\n",
      "Epoch: 2552 cost = 0.019020461\n",
      "Validation Loss: 0.044353973\n",
      "Epoch: 2553 cost = 0.019018574\n",
      "Validation Loss: 0.045981266\n",
      "Epoch: 2554 cost = 0.019016937\n",
      "Validation Loss: 0.047750644\n",
      "Epoch: 2555 cost = 0.019015133\n",
      "Validation Loss: 0.042434603\n",
      "Epoch: 2556 cost = 0.019013603\n",
      "Validation Loss: 0.029481238\n",
      "Epoch: 2557 cost = 0.019011584\n",
      "Validation Loss: 0.030729445\n",
      "Epoch: 2558 cost = 0.019009837\n",
      "Validation Loss: 0.039874878\n",
      "Epoch: 2559 cost = 0.019008236\n",
      "Validation Loss: 0.06828834\n",
      "Epoch: 2560 cost = 0.019006203\n",
      "Validation Loss: 0.08374231\n",
      "Epoch: 2561 cost = 0.019004343\n",
      "Validation Loss: 0.0794342\n",
      "Epoch: 2562 cost = 0.019002782\n",
      "Validation Loss: 0.050204396\n",
      "Epoch: 2563 cost = 0.019001188\n",
      "Validation Loss: 0.057956085\n",
      "Epoch: 2564 cost = 0.018999221\n",
      "Validation Loss: 0.047404207\n",
      "Epoch: 2565 cost = 0.018997484\n",
      "Validation Loss: 0.04793377\n",
      "Epoch: 2566 cost = 0.018995797\n",
      "Validation Loss: 0.038720068\n",
      "Epoch: 2567 cost = 0.018994101\n",
      "Validation Loss: 0.053012226\n",
      "Epoch: 2568 cost = 0.018992223\n",
      "Validation Loss: 0.050756887\n",
      "Epoch: 2569 cost = 0.018990670\n",
      "Validation Loss: 0.054357566\n",
      "Epoch: 2570 cost = 0.018988969\n",
      "Validation Loss: 0.045122232\n",
      "Epoch: 2571 cost = 0.018987179\n",
      "Validation Loss: 0.030518992\n",
      "Epoch: 2572 cost = 0.018985366\n",
      "Validation Loss: 0.035450924\n",
      "Epoch: 2573 cost = 0.018983928\n",
      "Validation Loss: 0.05497285\n",
      "Epoch: 2574 cost = 0.018981948\n",
      "Validation Loss: 0.046124\n",
      "Epoch: 2575 cost = 0.018980222\n",
      "Validation Loss: 0.051261682\n",
      "Epoch: 2576 cost = 0.018978584\n",
      "Validation Loss: 0.051599044\n",
      "Epoch: 2577 cost = 0.018976813\n",
      "Validation Loss: 0.050111003\n",
      "Epoch: 2578 cost = 0.018974926\n",
      "Validation Loss: 0.03406163\n",
      "Epoch: 2579 cost = 0.018973224\n",
      "Validation Loss: 0.03204986\n",
      "Epoch: 2580 cost = 0.018971514\n",
      "Validation Loss: 0.025975378\n",
      "Epoch: 2581 cost = 0.018969538\n",
      "Validation Loss: 0.037058044\n",
      "Epoch: 2582 cost = 0.018968406\n",
      "Validation Loss: 0.039829474\n",
      "Epoch: 2583 cost = 0.018966226\n",
      "Validation Loss: 0.036471833\n",
      "Epoch: 2584 cost = 0.018964540\n",
      "Validation Loss: 0.0317836\n",
      "Epoch: 2585 cost = 0.018962714\n",
      "Validation Loss: 0.032114763\n",
      "Epoch: 2586 cost = 0.018961199\n",
      "Validation Loss: 0.038762506\n",
      "Epoch: 2587 cost = 0.018959356\n",
      "Validation Loss: 0.039283887\n",
      "Epoch: 2588 cost = 0.018957406\n",
      "Validation Loss: 0.045037508\n",
      "Epoch: 2589 cost = 0.018955744\n",
      "Validation Loss: 0.033430737\n",
      "Epoch: 2590 cost = 0.018954254\n",
      "Validation Loss: 0.031906754\n",
      "Epoch: 2591 cost = 0.018952094\n",
      "Validation Loss: 0.03766477\n",
      "Epoch: 2592 cost = 0.018950874\n",
      "Validation Loss: 0.040163364\n",
      "Epoch: 2593 cost = 0.018949097\n",
      "Validation Loss: 0.042390846\n",
      "Epoch: 2594 cost = 0.018947259\n",
      "Validation Loss: 0.036909916\n",
      "Epoch: 2595 cost = 0.018945879\n",
      "Validation Loss: 0.0379242\n",
      "Epoch: 2596 cost = 0.018944106\n",
      "Validation Loss: 0.022301007\n",
      "Epoch: 2597 cost = 0.018942355\n",
      "Validation Loss: 0.03724202\n",
      "Epoch: 2598 cost = 0.018940479\n",
      "Validation Loss: 0.056587975\n",
      "Epoch: 2599 cost = 0.018938878\n",
      "Validation Loss: 0.04907943\n",
      "Epoch: 2600 cost = 0.018937316\n",
      "Validation Loss: 0.045048825\n",
      "Epoch: 2601 cost = 0.018935454\n",
      "Validation Loss: 0.046805162\n",
      "Epoch: 2602 cost = 0.018933560\n",
      "Validation Loss: 0.04658486\n",
      "Epoch: 2603 cost = 0.018932353\n",
      "Validation Loss: 0.036743358\n",
      "Epoch: 2604 cost = 0.018930303\n",
      "Validation Loss: 0.036217563\n",
      "Epoch: 2605 cost = 0.018928424\n",
      "Validation Loss: 0.042574093\n",
      "Epoch: 2606 cost = 0.018927011\n",
      "Validation Loss: 0.051025044\n",
      "Epoch: 2607 cost = 0.018925080\n",
      "Validation Loss: 0.04526563\n",
      "Epoch: 2608 cost = 0.018923340\n",
      "Validation Loss: 0.039488804\n",
      "Epoch: 2609 cost = 0.018922231\n",
      "Validation Loss: 0.03519981\n",
      "Epoch: 2610 cost = 0.018920254\n",
      "Validation Loss: 0.032661945\n",
      "Epoch: 2611 cost = 0.018918392\n",
      "Validation Loss: 0.04070984\n",
      "Epoch: 2612 cost = 0.018916903\n",
      "Validation Loss: 0.047818694\n",
      "Epoch: 2613 cost = 0.018915076\n",
      "Validation Loss: 0.06306728\n",
      "Epoch: 2614 cost = 0.018913475\n",
      "Validation Loss: 0.059489056\n",
      "Epoch: 2615 cost = 0.018911702\n",
      "Validation Loss: 0.04759061\n",
      "Epoch: 2616 cost = 0.018910421\n",
      "Validation Loss: 0.0375594\n",
      "Epoch: 2617 cost = 0.018908905\n",
      "Validation Loss: 0.030276451\n",
      "Epoch: 2618 cost = 0.018907066\n",
      "Validation Loss: 0.028190035\n",
      "Epoch: 2619 cost = 0.018905218\n",
      "Validation Loss: 0.03184838\n",
      "Epoch: 2620 cost = 0.018903359\n",
      "Validation Loss: 0.037625987\n",
      "Epoch: 2621 cost = 0.018901667\n",
      "Validation Loss: 0.029772019\n",
      "Epoch: 2622 cost = 0.018900201\n",
      "Validation Loss: 0.044381898\n",
      "Epoch: 2623 cost = 0.018898737\n",
      "Validation Loss: 0.0257419\n",
      "Epoch: 2624 cost = 0.018896796\n",
      "Validation Loss: 0.022619778\n",
      "Epoch: 2625 cost = 0.018895227\n",
      "Validation Loss: 0.032854784\n",
      "Epoch: 2626 cost = 0.018893806\n",
      "Validation Loss: 0.048262592\n",
      "Epoch: 2627 cost = 0.018891883\n",
      "Validation Loss: 0.04640754\n",
      "Epoch: 2628 cost = 0.018890200\n",
      "Validation Loss: 0.055510547\n",
      "Epoch: 2629 cost = 0.018888594\n",
      "Validation Loss: 0.06953508\n",
      "Epoch: 2630 cost = 0.018886810\n",
      "Validation Loss: 0.08505048\n",
      "Epoch: 2631 cost = 0.018885260\n",
      "Validation Loss: 0.0706587\n",
      "Epoch: 2632 cost = 0.018883937\n",
      "Validation Loss: 0.0600211\n",
      "Epoch: 2633 cost = 0.018882188\n",
      "Validation Loss: 0.07698783\n",
      "Epoch: 2634 cost = 0.018880368\n",
      "Validation Loss: 0.08179202\n",
      "Epoch: 2635 cost = 0.018878677\n",
      "Validation Loss: 0.060165312\n",
      "Epoch: 2636 cost = 0.018877081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.040311735\n",
      "Epoch: 2637 cost = 0.018875500\n",
      "Validation Loss: 0.036055338\n",
      "Epoch: 2638 cost = 0.018874165\n",
      "Validation Loss: 0.033865795\n",
      "Epoch: 2639 cost = 0.018872034\n",
      "Validation Loss: 0.041198317\n",
      "Epoch: 2640 cost = 0.018870322\n",
      "Validation Loss: 0.063034676\n",
      "Epoch: 2641 cost = 0.018868865\n",
      "Validation Loss: 0.08251643\n",
      "Epoch: 2642 cost = 0.018867121\n",
      "Validation Loss: 0.09217117\n",
      "Epoch: 2643 cost = 0.018865654\n",
      "Validation Loss: 0.085291296\n",
      "Epoch: 2644 cost = 0.018864018\n",
      "Validation Loss: 0.0620922\n",
      "Epoch: 2645 cost = 0.018862320\n",
      "Validation Loss: 0.05125337\n",
      "Epoch: 2646 cost = 0.018860864\n",
      "Validation Loss: 0.034962784\n",
      "Epoch: 2647 cost = 0.018858949\n",
      "Validation Loss: 0.02850945\n",
      "Epoch: 2648 cost = 0.018857152\n",
      "Validation Loss: 0.034408715\n",
      "Epoch: 2649 cost = 0.018855823\n",
      "Validation Loss: 0.03259736\n",
      "Epoch: 2650 cost = 0.018854120\n",
      "Validation Loss: 0.04933214\n",
      "Epoch: 2651 cost = 0.018852409\n",
      "Validation Loss: 0.05381856\n",
      "Epoch: 2652 cost = 0.018850652\n",
      "Validation Loss: 0.04358672\n",
      "Epoch: 2653 cost = 0.018849302\n",
      "Validation Loss: 0.051954266\n",
      "Epoch: 2654 cost = 0.018847507\n",
      "Validation Loss: 0.057519894\n",
      "Epoch: 2655 cost = 0.018845929\n",
      "Validation Loss: 0.063177444\n",
      "Epoch: 2656 cost = 0.018844265\n",
      "Validation Loss: 0.044418663\n",
      "Epoch: 2657 cost = 0.018842942\n",
      "Validation Loss: 0.034610495\n",
      "Epoch: 2658 cost = 0.018841230\n",
      "Validation Loss: 0.056113157\n",
      "Epoch: 2659 cost = 0.018839503\n",
      "Validation Loss: 0.05498172\n",
      "Epoch: 2660 cost = 0.018837716\n",
      "Validation Loss: 0.047384374\n",
      "Epoch: 2661 cost = 0.018836215\n",
      "Validation Loss: 0.05034482\n",
      "Epoch: 2662 cost = 0.018834801\n",
      "Validation Loss: 0.035322297\n",
      "Epoch: 2663 cost = 0.018833292\n",
      "Validation Loss: 0.02930461\n",
      "Epoch: 2664 cost = 0.018831514\n",
      "Validation Loss: 0.04309246\n",
      "Epoch: 2665 cost = 0.018829772\n",
      "Validation Loss: 0.04939901\n",
      "Epoch: 2666 cost = 0.018828414\n",
      "Validation Loss: 0.044145226\n",
      "Epoch: 2667 cost = 0.018826696\n",
      "Validation Loss: 0.04465856\n",
      "Epoch: 2668 cost = 0.018825429\n",
      "Validation Loss: 0.067327976\n",
      "Epoch: 2669 cost = 0.018823349\n",
      "Validation Loss: 0.06399001\n",
      "Epoch: 2670 cost = 0.018821842\n",
      "Validation Loss: 0.06699701\n",
      "Epoch: 2671 cost = 0.018820480\n",
      "Validation Loss: 0.06659098\n",
      "Epoch: 2672 cost = 0.018818575\n",
      "Validation Loss: 0.04437632\n",
      "Epoch: 2673 cost = 0.018817097\n",
      "Validation Loss: 0.035999708\n",
      "Epoch: 2674 cost = 0.018815643\n",
      "Validation Loss: 0.033170186\n",
      "Epoch: 2675 cost = 0.018814007\n",
      "Validation Loss: 0.040904175\n",
      "Epoch: 2676 cost = 0.018812484\n",
      "Validation Loss: 0.032105852\n",
      "Epoch: 2677 cost = 0.018810472\n",
      "Validation Loss: 0.03524093\n",
      "Epoch: 2678 cost = 0.018809078\n",
      "Validation Loss: 0.04350683\n",
      "Epoch: 2679 cost = 0.018807767\n",
      "Validation Loss: 0.050723966\n",
      "Epoch: 2680 cost = 0.018806178\n",
      "Validation Loss: 0.042535324\n",
      "Epoch: 2681 cost = 0.018804441\n",
      "Validation Loss: 0.037289158\n",
      "Epoch: 2682 cost = 0.018802864\n",
      "Validation Loss: 0.045615166\n",
      "Epoch: 2683 cost = 0.018800960\n",
      "Validation Loss: 0.04914082\n",
      "Epoch: 2684 cost = 0.018799498\n",
      "Validation Loss: 0.033026073\n",
      "Epoch: 2685 cost = 0.018798104\n",
      "Validation Loss: 0.02286526\n",
      "Epoch: 2686 cost = 0.018796340\n",
      "Validation Loss: 0.036779974\n",
      "Epoch: 2687 cost = 0.018794734\n",
      "Validation Loss: 0.037374984\n",
      "Epoch: 2688 cost = 0.018793160\n",
      "Validation Loss: 0.026655208\n",
      "Epoch: 2689 cost = 0.018791629\n",
      "Validation Loss: 0.024708807\n",
      "Epoch: 2690 cost = 0.018790332\n",
      "Validation Loss: 0.03820562\n",
      "Epoch: 2691 cost = 0.018788733\n",
      "Validation Loss: 0.037214752\n",
      "Epoch: 2692 cost = 0.018787204\n",
      "Validation Loss: 0.04078295\n",
      "Epoch: 2693 cost = 0.018785374\n",
      "Validation Loss: 0.03210916\n",
      "Epoch: 2694 cost = 0.018783893\n",
      "Validation Loss: 0.029184876\n",
      "Epoch: 2695 cost = 0.018782326\n",
      "Validation Loss: 0.037398957\n",
      "Epoch: 2696 cost = 0.018780862\n",
      "Validation Loss: 0.055106428\n",
      "Epoch: 2697 cost = 0.018779495\n",
      "Validation Loss: 0.060540777\n",
      "Epoch: 2698 cost = 0.018777777\n",
      "Validation Loss: 0.029516703\n",
      "Epoch: 2699 cost = 0.018776201\n",
      "Validation Loss: 0.024505094\n",
      "Epoch: 2700 cost = 0.018774712\n",
      "Validation Loss: 0.03547995\n",
      "Epoch: 2701 cost = 0.018773090\n",
      "Validation Loss: 0.043205287\n",
      "Epoch: 2702 cost = 0.018771352\n",
      "Validation Loss: 0.033659592\n",
      "Epoch: 2703 cost = 0.018769879\n",
      "Validation Loss: 0.025109062\n",
      "Epoch: 2704 cost = 0.018768226\n",
      "Validation Loss: 0.021611096\n",
      "Epoch: 2705 cost = 0.018766800\n",
      "Validation Loss: 0.031569727\n",
      "Epoch: 2706 cost = 0.018765328\n",
      "Validation Loss: 0.04287798\n",
      "Epoch: 2707 cost = 0.018763539\n",
      "Validation Loss: 0.044053584\n",
      "Epoch: 2708 cost = 0.018761984\n",
      "Validation Loss: 0.040175896\n",
      "Epoch: 2709 cost = 0.018760504\n",
      "Validation Loss: 0.046422992\n",
      "Epoch: 2710 cost = 0.018758741\n",
      "Validation Loss: 0.043960225\n",
      "Epoch: 2711 cost = 0.018757282\n",
      "Validation Loss: 0.03421525\n",
      "Epoch: 2712 cost = 0.018755716\n",
      "Validation Loss: 0.026768189\n",
      "Epoch: 2713 cost = 0.018754382\n",
      "Validation Loss: 0.02739153\n",
      "Epoch: 2714 cost = 0.018752634\n",
      "Validation Loss: 0.035959516\n",
      "Epoch: 2715 cost = 0.018751241\n",
      "Validation Loss: 0.036514625\n",
      "Epoch: 2716 cost = 0.018749709\n",
      "Validation Loss: 0.035595782\n",
      "Epoch: 2717 cost = 0.018748412\n",
      "Validation Loss: 0.052412905\n",
      "Epoch: 2718 cost = 0.018746883\n",
      "Validation Loss: 0.057483118\n",
      "Epoch: 2719 cost = 0.018745196\n",
      "Validation Loss: 0.055613726\n",
      "Epoch: 2720 cost = 0.018743543\n",
      "Validation Loss: 0.05862237\n",
      "Epoch: 2721 cost = 0.018742114\n",
      "Validation Loss: 0.059869155\n",
      "Epoch: 2722 cost = 0.018740610\n",
      "Validation Loss: 0.04565234\n",
      "Epoch: 2723 cost = 0.018738871\n",
      "Validation Loss: 0.033417884\n",
      "Epoch: 2724 cost = 0.018737631\n",
      "Validation Loss: 0.040546335\n",
      "Epoch: 2725 cost = 0.018736187\n",
      "Validation Loss: 0.052968975\n",
      "Epoch: 2726 cost = 0.018734533\n",
      "Validation Loss: 0.055180456\n",
      "Epoch: 2727 cost = 0.018732869\n",
      "Validation Loss: 0.030231288\n",
      "Epoch: 2728 cost = 0.018731186\n",
      "Validation Loss: 0.046675406\n",
      "Epoch: 2729 cost = 0.018729750\n",
      "Validation Loss: 0.05686398\n",
      "Epoch: 2730 cost = 0.018728583\n",
      "Validation Loss: 0.051173627\n",
      "Epoch: 2731 cost = 0.018726741\n",
      "Validation Loss: 0.039341386\n",
      "Epoch: 2732 cost = 0.018725333\n",
      "Validation Loss: 0.04436744\n",
      "Epoch: 2733 cost = 0.018723971\n",
      "Validation Loss: 0.039158184\n",
      "Epoch: 2734 cost = 0.018722153\n",
      "Validation Loss: 0.03035759\n",
      "Epoch: 2735 cost = 0.018720838\n",
      "Validation Loss: 0.03272169\n",
      "Epoch: 2736 cost = 0.018719365\n",
      "Validation Loss: 0.027062658\n",
      "Epoch: 2737 cost = 0.018717531\n",
      "Validation Loss: 0.041243754\n",
      "Epoch: 2738 cost = 0.018716233\n",
      "Validation Loss: 0.052885715\n",
      "Epoch: 2739 cost = 0.018714715\n",
      "Validation Loss: 0.0601392\n",
      "Epoch: 2740 cost = 0.018713220\n",
      "Validation Loss: 0.054169245\n",
      "Epoch: 2741 cost = 0.018711457\n",
      "Validation Loss: 0.048619077\n",
      "Epoch: 2742 cost = 0.018710327\n",
      "Validation Loss: 0.046428632\n",
      "Epoch: 2743 cost = 0.018708403\n",
      "Validation Loss: 0.04973964\n",
      "Epoch: 2744 cost = 0.018706965\n",
      "Validation Loss: 0.04746952\n",
      "Epoch: 2745 cost = 0.018705700\n",
      "Validation Loss: 0.04564879\n",
      "Epoch: 2746 cost = 0.018704395\n",
      "Validation Loss: 0.05026099\n",
      "Epoch: 2747 cost = 0.018702704\n",
      "Validation Loss: 0.052144673\n",
      "Epoch: 2748 cost = 0.018701125\n",
      "Validation Loss: 0.04086075\n",
      "Epoch: 2749 cost = 0.018699549\n",
      "Validation Loss: 0.041590914\n",
      "Epoch: 2750 cost = 0.018698109\n",
      "Validation Loss: 0.044037864\n",
      "Epoch: 2751 cost = 0.018696594\n",
      "Validation Loss: 0.055824544\n",
      "Epoch: 2752 cost = 0.018695234\n",
      "Validation Loss: 0.039367434\n",
      "Epoch: 2753 cost = 0.018693451\n",
      "Validation Loss: 0.027571552\n",
      "Epoch: 2754 cost = 0.018692253\n",
      "Validation Loss: 0.026084658\n",
      "Epoch: 2755 cost = 0.018690737\n",
      "Validation Loss: 0.022923175\n",
      "Epoch: 2756 cost = 0.018689038\n",
      "Validation Loss: 0.028759196\n",
      "Epoch: 2757 cost = 0.018687662\n",
      "Validation Loss: 0.028728869\n",
      "Epoch: 2758 cost = 0.018685968\n",
      "Validation Loss: 0.03518585\n",
      "Epoch: 2759 cost = 0.018684846\n",
      "Validation Loss: 0.022685783\n",
      "Epoch: 2760 cost = 0.018683295\n",
      "Validation Loss: 0.025072085\n",
      "Epoch: 2761 cost = 0.018681910\n",
      "Validation Loss: 0.038328934\n",
      "Epoch: 2762 cost = 0.018680279\n",
      "Validation Loss: 0.044591278\n",
      "Epoch: 2763 cost = 0.018678810\n",
      "Validation Loss: 0.045418087\n",
      "Epoch: 2764 cost = 0.018677413\n",
      "Validation Loss: 0.030975012\n",
      "Epoch: 2765 cost = 0.018675705\n",
      "Validation Loss: 0.06398557\n",
      "Epoch: 2766 cost = 0.018674397\n",
      "Validation Loss: 0.061319776\n",
      "Epoch: 2767 cost = 0.018673006\n",
      "Validation Loss: 0.06477117\n",
      "Epoch: 2768 cost = 0.018671318\n",
      "Validation Loss: 0.050721124\n",
      "Epoch: 2769 cost = 0.018670058\n",
      "Validation Loss: 0.04475218\n",
      "Epoch: 2770 cost = 0.018668565\n",
      "Validation Loss: 0.038235154\n",
      "Epoch: 2771 cost = 0.018666844\n",
      "Validation Loss: 0.03338507\n",
      "Epoch: 2772 cost = 0.018665368\n",
      "Validation Loss: 0.029108131\n",
      "Epoch: 2773 cost = 0.018664148\n",
      "Validation Loss: 0.04278103\n",
      "Epoch: 2774 cost = 0.018662377\n",
      "Validation Loss: 0.037508234\n",
      "Epoch: 2775 cost = 0.018661283\n",
      "Validation Loss: 0.04853562\n",
      "Epoch: 2776 cost = 0.018659556\n",
      "Validation Loss: 0.06984988\n",
      "Epoch: 2777 cost = 0.018658018\n",
      "Validation Loss: 0.08050215\n",
      "Epoch: 2778 cost = 0.018656664\n",
      "Validation Loss: 0.067756005\n",
      "Epoch: 2779 cost = 0.018655357\n",
      "Validation Loss: 0.059864476\n",
      "Epoch: 2780 cost = 0.018654006\n",
      "Validation Loss: 0.041369706\n",
      "Epoch: 2781 cost = 0.018652115\n",
      "Validation Loss: 0.042187247\n",
      "Epoch: 2782 cost = 0.018650580\n",
      "Validation Loss: 0.055755273\n",
      "Epoch: 2783 cost = 0.018649001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.035993822\n",
      "Epoch: 2784 cost = 0.018648052\n",
      "Validation Loss: 0.034887593\n",
      "Epoch: 2785 cost = 0.018646268\n",
      "Validation Loss: 0.04026851\n",
      "Epoch: 2786 cost = 0.018645029\n",
      "Validation Loss: 0.046046097\n",
      "Epoch: 2787 cost = 0.018643430\n",
      "Validation Loss: 0.044996183\n",
      "Epoch: 2788 cost = 0.018641901\n",
      "Validation Loss: 0.046087913\n",
      "Epoch: 2789 cost = 0.018640694\n",
      "Validation Loss: 0.06377\n",
      "Epoch: 2790 cost = 0.018639080\n",
      "Validation Loss: 0.0627866\n",
      "Epoch: 2791 cost = 0.018637671\n",
      "Validation Loss: 0.05131716\n",
      "Epoch: 2792 cost = 0.018636223\n",
      "Validation Loss: 0.0445641\n",
      "Epoch: 2793 cost = 0.018634745\n",
      "Validation Loss: 0.0569253\n",
      "Epoch: 2794 cost = 0.018633189\n",
      "Validation Loss: 0.06665864\n",
      "Epoch: 2795 cost = 0.018631981\n",
      "Validation Loss: 0.06774416\n",
      "Epoch: 2796 cost = 0.018630317\n",
      "Validation Loss: 0.07681245\n",
      "Epoch: 2797 cost = 0.018628873\n",
      "Validation Loss: 0.04364942\n",
      "Epoch: 2798 cost = 0.018627590\n",
      "Validation Loss: 0.030369513\n",
      "Epoch: 2799 cost = 0.018626107\n",
      "Validation Loss: 0.033901267\n",
      "Epoch: 2800 cost = 0.018624683\n",
      "Validation Loss: 0.036928058\n",
      "Epoch: 2801 cost = 0.018623106\n",
      "Validation Loss: 0.050234113\n",
      "Epoch: 2802 cost = 0.018621997\n",
      "Validation Loss: 0.057933748\n",
      "Epoch: 2803 cost = 0.018620146\n",
      "Validation Loss: 0.060617343\n",
      "Epoch: 2804 cost = 0.018618839\n",
      "Validation Loss: 0.03690844\n",
      "Epoch: 2805 cost = 0.018617404\n",
      "Validation Loss: 0.030725025\n",
      "Epoch: 2806 cost = 0.018616068\n",
      "Validation Loss: 0.030057067\n",
      "Epoch: 2807 cost = 0.018614589\n",
      "Validation Loss: 0.046182416\n",
      "Epoch: 2808 cost = 0.018613160\n",
      "Validation Loss: 0.04804852\n",
      "Epoch: 2809 cost = 0.018611838\n",
      "Validation Loss: 0.04592344\n",
      "Epoch: 2810 cost = 0.018610241\n",
      "Validation Loss: 0.04332112\n",
      "Epoch: 2811 cost = 0.018609014\n",
      "Validation Loss: 0.037826095\n",
      "Epoch: 2812 cost = 0.018607485\n",
      "Validation Loss: 0.042260714\n",
      "Epoch: 2813 cost = 0.018605937\n",
      "Validation Loss: 0.056484614\n",
      "Epoch: 2814 cost = 0.018604513\n",
      "Validation Loss: 0.055811793\n",
      "Epoch: 2815 cost = 0.018603195\n",
      "Validation Loss: 0.04072031\n",
      "Epoch: 2816 cost = 0.018601942\n",
      "Validation Loss: 0.024611143\n",
      "Epoch: 2817 cost = 0.018600334\n",
      "Validation Loss: 0.033863038\n",
      "Epoch: 2818 cost = 0.018599176\n",
      "Validation Loss: 0.042724397\n",
      "Epoch: 2819 cost = 0.018597148\n",
      "Validation Loss: 0.031436406\n",
      "Epoch: 2820 cost = 0.018596339\n",
      "Validation Loss: 0.04080874\n",
      "Epoch: 2821 cost = 0.018594395\n",
      "Validation Loss: 0.04754078\n",
      "Epoch: 2822 cost = 0.018593460\n",
      "Validation Loss: 0.039274696\n",
      "Epoch: 2823 cost = 0.018591950\n",
      "Validation Loss: 0.037942782\n",
      "Epoch: 2824 cost = 0.018590700\n",
      "Validation Loss: 0.031794406\n",
      "Epoch: 2825 cost = 0.018588974\n",
      "Validation Loss: 0.04795537\n",
      "Epoch: 2826 cost = 0.018587792\n",
      "Validation Loss: 0.037498493\n",
      "Epoch: 2827 cost = 0.018586144\n",
      "Validation Loss: 0.037206516\n",
      "Epoch: 2828 cost = 0.018584829\n",
      "Validation Loss: 0.025374204\n",
      "Epoch: 2829 cost = 0.018583584\n",
      "Validation Loss: 0.023261156\n",
      "Epoch: 2830 cost = 0.018582132\n",
      "Validation Loss: 0.033768676\n",
      "Epoch: 2831 cost = 0.018580353\n",
      "Validation Loss: 0.03444957\n",
      "Epoch: 2832 cost = 0.018579248\n",
      "Validation Loss: 0.023777189\n",
      "Epoch: 2833 cost = 0.018577619\n",
      "Validation Loss: 0.02768483\n",
      "Epoch: 2834 cost = 0.018576240\n",
      "Validation Loss: 0.040164873\n",
      "Epoch: 2835 cost = 0.018574782\n",
      "Validation Loss: 0.04647335\n",
      "Epoch: 2836 cost = 0.018573459\n",
      "Validation Loss: 0.050242223\n",
      "Epoch: 2837 cost = 0.018572171\n",
      "Validation Loss: 0.042168736\n",
      "Epoch: 2838 cost = 0.018570530\n",
      "Validation Loss: 0.03950093\n",
      "Epoch: 2839 cost = 0.018569354\n",
      "Validation Loss: 0.03260331\n",
      "Epoch: 2840 cost = 0.018568112\n",
      "Validation Loss: 0.040574107\n",
      "Epoch: 2841 cost = 0.018566479\n",
      "Validation Loss: 0.045809418\n",
      "Epoch: 2842 cost = 0.018564933\n",
      "Validation Loss: 0.036084898\n",
      "Epoch: 2843 cost = 0.018563727\n",
      "Validation Loss: 0.042665657\n",
      "Epoch: 2844 cost = 0.018562297\n",
      "Validation Loss: 0.06291788\n",
      "Epoch: 2845 cost = 0.018561033\n",
      "Validation Loss: 0.07476666\n",
      "Epoch: 2846 cost = 0.018559532\n",
      "Validation Loss: 0.0646702\n",
      "Epoch: 2847 cost = 0.018558253\n",
      "Validation Loss: 0.055839915\n",
      "Epoch: 2848 cost = 0.018556760\n",
      "Validation Loss: 0.034895718\n",
      "Epoch: 2849 cost = 0.018555577\n",
      "Validation Loss: 0.04055291\n",
      "Epoch: 2850 cost = 0.018554363\n",
      "Validation Loss: 0.071081206\n",
      "Epoch: 2851 cost = 0.018552468\n",
      "Validation Loss: 0.061729077\n",
      "Epoch: 2852 cost = 0.018551274\n",
      "Validation Loss: 0.03228281\n",
      "Epoch: 2853 cost = 0.018549707\n",
      "Validation Loss: 0.031292982\n",
      "Epoch: 2854 cost = 0.018548461\n",
      "Validation Loss: 0.024463536\n",
      "Epoch: 2855 cost = 0.018547036\n",
      "Validation Loss: 0.047754806\n",
      "Epoch: 2856 cost = 0.018545742\n",
      "Validation Loss: 0.05616395\n",
      "Epoch: 2857 cost = 0.018544297\n",
      "Validation Loss: 0.052355994\n",
      "Epoch: 2858 cost = 0.018542531\n",
      "Validation Loss: 0.047161672\n",
      "Epoch: 2859 cost = 0.018541206\n",
      "Validation Loss: 0.054458044\n",
      "Epoch: 2860 cost = 0.018539724\n",
      "Validation Loss: 0.047055464\n",
      "Epoch: 2861 cost = 0.018538511\n",
      "Validation Loss: 0.06309788\n",
      "Epoch: 2862 cost = 0.018537555\n",
      "Validation Loss: 0.05722891\n",
      "Epoch: 2863 cost = 0.018535865\n",
      "Validation Loss: 0.06074198\n",
      "Epoch: 2864 cost = 0.018534534\n",
      "Validation Loss: 0.06337928\n",
      "Epoch: 2865 cost = 0.018533180\n",
      "Validation Loss: 0.073885314\n",
      "Epoch: 2866 cost = 0.018531825\n",
      "Validation Loss: 0.054874398\n",
      "Epoch: 2867 cost = 0.018530793\n",
      "Validation Loss: 0.037626624\n",
      "Epoch: 2868 cost = 0.018529310\n",
      "Validation Loss: 0.026060965\n",
      "Epoch: 2869 cost = 0.018527935\n",
      "Validation Loss: 0.044186424\n",
      "Epoch: 2870 cost = 0.018526142\n",
      "Validation Loss: 0.050950464\n",
      "Epoch: 2871 cost = 0.018525050\n",
      "Validation Loss: 0.04023394\n",
      "Epoch: 2872 cost = 0.018523846\n",
      "Validation Loss: 0.03810861\n",
      "Epoch: 2873 cost = 0.018522292\n",
      "Validation Loss: 0.042427387\n",
      "Epoch: 2874 cost = 0.018521187\n",
      "Validation Loss: 0.044231106\n",
      "Epoch: 2875 cost = 0.018519377\n",
      "Validation Loss: 0.026084278\n",
      "Epoch: 2876 cost = 0.018518203\n",
      "Validation Loss: 0.027319623\n",
      "Epoch: 2877 cost = 0.018517060\n",
      "Validation Loss: 0.027588543\n",
      "Epoch: 2878 cost = 0.018515262\n",
      "Validation Loss: 0.034757927\n",
      "Epoch: 2879 cost = 0.018514137\n",
      "Validation Loss: 0.03370227\n",
      "Epoch: 2880 cost = 0.018512828\n",
      "Validation Loss: 0.039069638\n",
      "Epoch: 2881 cost = 0.018511410\n",
      "Validation Loss: 0.051372353\n",
      "Epoch: 2882 cost = 0.018510046\n",
      "Validation Loss: 0.036323138\n",
      "Epoch: 2883 cost = 0.018508727\n",
      "Validation Loss: 0.02947215\n",
      "Epoch: 2884 cost = 0.018507522\n",
      "Validation Loss: 0.035964385\n",
      "Epoch: 2885 cost = 0.018506073\n",
      "Validation Loss: 0.05453131\n",
      "Epoch: 2886 cost = 0.018504576\n",
      "Validation Loss: 0.041088574\n",
      "Epoch: 2887 cost = 0.018503344\n",
      "Validation Loss: 0.031192785\n",
      "Epoch: 2888 cost = 0.018502001\n",
      "Validation Loss: 0.039645378\n",
      "Epoch: 2889 cost = 0.018500754\n",
      "Validation Loss: 0.03593695\n",
      "Epoch: 2890 cost = 0.018499080\n",
      "Validation Loss: 0.028654898\n",
      "Epoch: 2891 cost = 0.018498078\n",
      "Validation Loss: 0.03446125\n",
      "Epoch: 2892 cost = 0.018496403\n",
      "Validation Loss: 0.046468753\n",
      "Epoch: 2893 cost = 0.018494884\n",
      "Validation Loss: 0.061629273\n",
      "Epoch: 2894 cost = 0.018493836\n",
      "Validation Loss: 0.08518332\n",
      "Epoch: 2895 cost = 0.018492386\n",
      "Validation Loss: 0.066281274\n",
      "Epoch: 2896 cost = 0.018491186\n",
      "Validation Loss: 0.047259156\n",
      "Epoch: 2897 cost = 0.018489921\n",
      "Validation Loss: 0.038355865\n",
      "Epoch: 2898 cost = 0.018488317\n",
      "Validation Loss: 0.047776192\n",
      "Epoch: 2899 cost = 0.018487031\n",
      "Validation Loss: 0.058830313\n",
      "Epoch: 2900 cost = 0.018485796\n",
      "Validation Loss: 0.062295623\n",
      "Epoch: 2901 cost = 0.018484499\n",
      "Validation Loss: 0.045015275\n",
      "Epoch: 2902 cost = 0.018483280\n",
      "Validation Loss: 0.046807844\n",
      "Epoch: 2903 cost = 0.018481530\n",
      "Validation Loss: 0.044737432\n",
      "Epoch: 2904 cost = 0.018480423\n",
      "Validation Loss: 0.0423291\n",
      "Epoch: 2905 cost = 0.018479212\n",
      "Validation Loss: 0.05124418\n",
      "Epoch: 2906 cost = 0.018477520\n",
      "Validation Loss: 0.05012814\n",
      "Epoch: 2907 cost = 0.018476282\n",
      "Validation Loss: 0.044461217\n",
      "Epoch: 2908 cost = 0.018474952\n",
      "Validation Loss: 0.041854486\n",
      "Epoch: 2909 cost = 0.018474123\n",
      "Validation Loss: 0.038396597\n",
      "Epoch: 2910 cost = 0.018472401\n",
      "Validation Loss: 0.045002393\n",
      "Epoch: 2911 cost = 0.018471380\n",
      "Validation Loss: 0.03592709\n",
      "Epoch: 2912 cost = 0.018469703\n",
      "Validation Loss: 0.047447376\n",
      "Epoch: 2913 cost = 0.018468143\n",
      "Validation Loss: 0.07334381\n",
      "Epoch: 2914 cost = 0.018467352\n",
      "Validation Loss: 0.083151124\n",
      "Epoch: 2915 cost = 0.018465923\n",
      "Validation Loss: 0.059347935\n",
      "Epoch: 2916 cost = 0.018464426\n",
      "Validation Loss: 0.047571465\n",
      "Epoch: 2917 cost = 0.018463304\n",
      "Validation Loss: 0.049107816\n",
      "Epoch: 2918 cost = 0.018461782\n",
      "Validation Loss: 0.037289813\n",
      "Epoch: 2919 cost = 0.018460617\n",
      "Validation Loss: 0.056978732\n",
      "Epoch: 2920 cost = 0.018459364\n",
      "Validation Loss: 0.076936245\n",
      "Epoch: 2921 cost = 0.018457884\n",
      "Validation Loss: 0.06928871\n",
      "Epoch: 2922 cost = 0.018456761\n",
      "Validation Loss: 0.067914784\n",
      "Epoch: 2923 cost = 0.018455418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.06737236\n",
      "Epoch: 2924 cost = 0.018454182\n",
      "Validation Loss: 0.053500187\n",
      "Epoch: 2925 cost = 0.018452578\n",
      "Validation Loss: 0.051393382\n",
      "Epoch: 2926 cost = 0.018451324\n",
      "Validation Loss: 0.053422157\n",
      "Epoch: 2927 cost = 0.018450079\n",
      "Validation Loss: 0.06039773\n",
      "Epoch: 2928 cost = 0.018448717\n",
      "Validation Loss: 0.06274167\n",
      "Epoch: 2929 cost = 0.018447325\n",
      "Validation Loss: 0.032119457\n",
      "Epoch: 2930 cost = 0.018446067\n",
      "Validation Loss: 0.034682594\n",
      "Epoch: 2931 cost = 0.018445036\n",
      "Validation Loss: 0.053060986\n",
      "Epoch: 2932 cost = 0.018443468\n",
      "Validation Loss: 0.0584576\n",
      "Epoch: 2933 cost = 0.018441882\n",
      "Validation Loss: 0.045594316\n",
      "Epoch: 2934 cost = 0.018440994\n",
      "Validation Loss: 0.042992838\n",
      "Epoch: 2935 cost = 0.018439652\n",
      "Validation Loss: 0.054385684\n",
      "Epoch: 2936 cost = 0.018438171\n",
      "Validation Loss: 0.03624776\n",
      "Epoch: 2937 cost = 0.018436798\n",
      "Validation Loss: 0.04256712\n",
      "Epoch: 2938 cost = 0.018435459\n",
      "Validation Loss: 0.044484712\n",
      "Epoch: 2939 cost = 0.018434107\n",
      "Validation Loss: 0.04238798\n",
      "Epoch: 2940 cost = 0.018433065\n",
      "Validation Loss: 0.05543755\n",
      "Epoch: 2941 cost = 0.018431700\n",
      "Validation Loss: 0.055877212\n",
      "Epoch: 2942 cost = 0.018430433\n",
      "Validation Loss: 0.051375106\n",
      "Epoch: 2943 cost = 0.018429020\n",
      "Validation Loss: 0.030382574\n",
      "Epoch: 2944 cost = 0.018427961\n",
      "Validation Loss: 0.030517729\n",
      "Epoch: 2945 cost = 0.018426622\n",
      "Validation Loss: 0.036540966\n",
      "Epoch: 2946 cost = 0.018425165\n",
      "Validation Loss: 0.039732628\n",
      "Epoch: 2947 cost = 0.018423800\n",
      "Validation Loss: 0.054057576\n",
      "Epoch: 2948 cost = 0.018422722\n",
      "Validation Loss: 0.04986169\n",
      "Epoch: 2949 cost = 0.018421435\n",
      "Validation Loss: 0.037140656\n",
      "Epoch: 2950 cost = 0.018420125\n",
      "Validation Loss: 0.028929533\n",
      "Epoch: 2951 cost = 0.018418531\n",
      "Validation Loss: 0.020848596\n",
      "Epoch: 2952 cost = 0.018417458\n",
      "Validation Loss: 0.025171353\n",
      "Epoch: 2953 cost = 0.018416343\n",
      "Validation Loss: 0.031425864\n",
      "Epoch: 2954 cost = 0.018415203\n",
      "Validation Loss: 0.029698279\n",
      "Epoch: 2955 cost = 0.018413707\n",
      "Validation Loss: 0.028332528\n",
      "Epoch: 2956 cost = 0.018412110\n",
      "Validation Loss: 0.03635571\n",
      "Epoch: 2957 cost = 0.018411253\n",
      "Validation Loss: 0.052458126\n",
      "Epoch: 2958 cost = 0.018409768\n",
      "Validation Loss: 0.040664326\n",
      "Epoch: 2959 cost = 0.018408816\n",
      "Validation Loss: 0.030437833\n",
      "Epoch: 2960 cost = 0.018406894\n",
      "Validation Loss: 0.023560748\n",
      "Epoch: 2961 cost = 0.018406329\n",
      "Validation Loss: 0.041253306\n",
      "Epoch: 2962 cost = 0.018404812\n",
      "Validation Loss: 0.059123714\n",
      "Epoch: 2963 cost = 0.018403470\n",
      "Validation Loss: 0.07328651\n",
      "Epoch: 2964 cost = 0.018401977\n",
      "Validation Loss: 0.054808415\n",
      "Epoch: 2965 cost = 0.018400831\n",
      "Validation Loss: 0.04194812\n",
      "Epoch: 2966 cost = 0.018399639\n",
      "Validation Loss: 0.030757984\n",
      "Epoch: 2967 cost = 0.018398380\n",
      "Validation Loss: 0.040569883\n",
      "Epoch: 2968 cost = 0.018396911\n",
      "Validation Loss: 0.054178085\n",
      "Epoch: 2969 cost = 0.018395712\n",
      "Validation Loss: 0.070670456\n",
      "Epoch: 2970 cost = 0.018394306\n",
      "Validation Loss: 0.059231326\n",
      "Epoch: 2971 cost = 0.018393171\n",
      "Validation Loss: 0.041299254\n",
      "Epoch: 2972 cost = 0.018391972\n",
      "Validation Loss: 0.05707569\n",
      "Epoch: 2973 cost = 0.018390501\n",
      "Validation Loss: 0.04200265\n",
      "Epoch: 2974 cost = 0.018389102\n",
      "Validation Loss: 0.032026894\n",
      "Epoch: 2975 cost = 0.018388047\n",
      "Validation Loss: 0.047875997\n",
      "Epoch: 2976 cost = 0.018386894\n",
      "Validation Loss: 0.05728754\n",
      "Epoch: 2977 cost = 0.018385275\n",
      "Validation Loss: 0.061409824\n",
      "Epoch: 2978 cost = 0.018384239\n",
      "Validation Loss: 0.06850642\n",
      "Epoch: 2979 cost = 0.018382872\n",
      "Validation Loss: 0.070338815\n",
      "Epoch: 2980 cost = 0.018381683\n",
      "Validation Loss: 0.054184876\n",
      "Epoch: 2981 cost = 0.018380253\n",
      "Validation Loss: 0.047883287\n",
      "Epoch: 2982 cost = 0.018379221\n",
      "Validation Loss: 0.03831938\n",
      "Epoch: 2983 cost = 0.018377677\n",
      "Validation Loss: 0.03791614\n",
      "Epoch: 2984 cost = 0.018376888\n",
      "Validation Loss: 0.04486883\n",
      "Epoch: 2985 cost = 0.018375067\n",
      "Validation Loss: 0.051361002\n",
      "Epoch: 2986 cost = 0.018373965\n",
      "Validation Loss: 0.037654016\n",
      "Epoch: 2987 cost = 0.018372827\n",
      "Validation Loss: 0.030798858\n",
      "Epoch: 2988 cost = 0.018371819\n",
      "Validation Loss: 0.031029707\n",
      "Epoch: 2989 cost = 0.018370496\n",
      "Validation Loss: 0.03763093\n",
      "Epoch: 2990 cost = 0.018369122\n",
      "Validation Loss: 0.043287978\n",
      "Epoch: 2991 cost = 0.018368007\n",
      "Validation Loss: 0.025183434\n",
      "Epoch: 2992 cost = 0.018366484\n",
      "Validation Loss: 0.031356532\n",
      "Epoch: 2993 cost = 0.018365264\n",
      "Validation Loss: 0.04861292\n",
      "Epoch: 2994 cost = 0.018364095\n",
      "Validation Loss: 0.02969488\n",
      "Epoch: 2995 cost = 0.018362706\n",
      "Validation Loss: 0.03336211\n",
      "Epoch: 2996 cost = 0.018361685\n",
      "Validation Loss: 0.038766008\n",
      "Epoch: 2997 cost = 0.018359909\n",
      "Validation Loss: 0.032902904\n",
      "Epoch: 2998 cost = 0.018358873\n",
      "Validation Loss: 0.04328611\n",
      "Epoch: 2999 cost = 0.018358153\n",
      "Validation Loss: 0.045983117\n",
      "Epoch: 3000 cost = 0.018356918\n",
      "Validation Loss: 0.03430374\n",
      "Epoch: 3001 cost = 0.018355357\n",
      "Validation Loss: 0.029962571\n",
      "Epoch: 3002 cost = 0.018354338\n",
      "Validation Loss: 0.028363597\n",
      "Epoch: 3003 cost = 0.018353064\n",
      "Validation Loss: 0.03164803\n",
      "Epoch: 3004 cost = 0.018351750\n",
      "Validation Loss: 0.025439225\n",
      "Epoch: 3005 cost = 0.018350242\n",
      "Validation Loss: 0.04274276\n",
      "Epoch: 3006 cost = 0.018349193\n",
      "Validation Loss: 0.046439487\n",
      "Epoch: 3007 cost = 0.018347950\n",
      "Validation Loss: 0.035135347\n",
      "Epoch: 3008 cost = 0.018346602\n",
      "Validation Loss: 0.045162346\n",
      "Epoch: 3009 cost = 0.018345675\n",
      "Validation Loss: 0.040114045\n",
      "Epoch: 3010 cost = 0.018344241\n",
      "Validation Loss: 0.036924146\n",
      "Epoch: 3011 cost = 0.018342962\n",
      "Validation Loss: 0.05628843\n",
      "Epoch: 3012 cost = 0.018341716\n",
      "Validation Loss: 0.037519455\n",
      "Epoch: 3013 cost = 0.018340346\n",
      "Validation Loss: 0.034947664\n",
      "Epoch: 3014 cost = 0.018339199\n",
      "Validation Loss: 0.065979876\n",
      "Epoch: 3015 cost = 0.018337855\n",
      "Validation Loss: 0.07276106\n",
      "Epoch: 3016 cost = 0.018336826\n",
      "Validation Loss: 0.07755689\n",
      "Epoch: 3017 cost = 0.018335581\n",
      "Validation Loss: 0.05853462\n",
      "Epoch: 3018 cost = 0.018334584\n",
      "Validation Loss: 0.030080574\n",
      "Epoch: 3019 cost = 0.018333315\n",
      "Validation Loss: 0.042767517\n",
      "Epoch: 3020 cost = 0.018331571\n",
      "Validation Loss: 0.08490742\n",
      "Epoch: 3021 cost = 0.018330785\n",
      "Validation Loss: 0.0769293\n",
      "Epoch: 3022 cost = 0.018329523\n",
      "Validation Loss: 0.07582175\n",
      "Epoch: 3023 cost = 0.018328076\n",
      "Validation Loss: 0.04958501\n",
      "Epoch: 3024 cost = 0.018326768\n",
      "Validation Loss: 0.020890001\n",
      "Epoch: 3025 cost = 0.018325680\n",
      "Validation Loss: 0.05094042\n",
      "Epoch: 3026 cost = 0.018324736\n",
      "Validation Loss: 0.06979894\n",
      "Epoch: 3027 cost = 0.018323271\n",
      "Validation Loss: 0.0850185\n",
      "Epoch: 3028 cost = 0.018322143\n",
      "Validation Loss: 0.06779544\n",
      "Epoch: 3029 cost = 0.018320790\n",
      "Validation Loss: 0.037465822\n",
      "Epoch: 3030 cost = 0.018319534\n",
      "Validation Loss: 0.028078444\n",
      "Epoch: 3031 cost = 0.018318222\n",
      "Validation Loss: 0.03323158\n",
      "Epoch: 3032 cost = 0.018317183\n",
      "Validation Loss: 0.04244026\n",
      "Epoch: 3033 cost = 0.018315732\n",
      "Validation Loss: 0.047773823\n",
      "Epoch: 3034 cost = 0.018314395\n",
      "Validation Loss: 0.056167115\n",
      "Epoch: 3035 cost = 0.018313871\n",
      "Validation Loss: 0.04757479\n",
      "Epoch: 3036 cost = 0.018312292\n",
      "Validation Loss: 0.036907695\n",
      "Epoch: 3037 cost = 0.018311458\n",
      "Validation Loss: 0.026748465\n",
      "Epoch: 3038 cost = 0.018309661\n",
      "Validation Loss: 0.02874149\n",
      "Epoch: 3039 cost = 0.018308859\n",
      "Validation Loss: 0.035168342\n",
      "Epoch: 3040 cost = 0.018307038\n",
      "Validation Loss: 0.03539284\n",
      "Epoch: 3041 cost = 0.018306226\n",
      "Validation Loss: 0.048182424\n",
      "Epoch: 3042 cost = 0.018305291\n",
      "Validation Loss: 0.053084366\n",
      "Epoch: 3043 cost = 0.018303871\n",
      "Validation Loss: 0.04908289\n",
      "Epoch: 3044 cost = 0.018302820\n",
      "Validation Loss: 0.065743215\n",
      "Epoch: 3045 cost = 0.018301312\n",
      "Validation Loss: 0.07157698\n",
      "Epoch: 3046 cost = 0.018300407\n",
      "Validation Loss: 0.06846636\n",
      "Epoch: 3047 cost = 0.018299149\n",
      "Validation Loss: 0.06745009\n",
      "Epoch: 3048 cost = 0.018297696\n",
      "Validation Loss: 0.05116491\n",
      "Epoch: 3049 cost = 0.018296804\n",
      "Validation Loss: 0.056442227\n",
      "Epoch: 3050 cost = 0.018295238\n",
      "Validation Loss: 0.044846307\n",
      "Epoch: 3051 cost = 0.018294519\n",
      "Validation Loss: 0.036137626\n",
      "Epoch: 3052 cost = 0.018292694\n",
      "Validation Loss: 0.035961755\n",
      "Epoch: 3053 cost = 0.018291811\n",
      "Validation Loss: 0.03779793\n",
      "Epoch: 3054 cost = 0.018290685\n",
      "Validation Loss: 0.04835354\n",
      "Epoch: 3055 cost = 0.018289069\n",
      "Validation Loss: 0.056769866\n",
      "Epoch: 3056 cost = 0.018288511\n",
      "Validation Loss: 0.04091883\n",
      "Epoch: 3057 cost = 0.018287307\n",
      "Validation Loss: 0.023069046\n",
      "Epoch: 3058 cost = 0.018285393\n",
      "Validation Loss: 0.02671704\n",
      "Epoch: 3059 cost = 0.018284321\n",
      "Validation Loss: 0.026937673\n",
      "Epoch: 3060 cost = 0.018283341\n",
      "Validation Loss: 0.033677682\n",
      "Epoch: 3061 cost = 0.018282155\n",
      "Validation Loss: 0.044515256\n",
      "Epoch: 3062 cost = 0.018281128\n",
      "Validation Loss: 0.029503083\n",
      "Epoch: 3063 cost = 0.018279380\n",
      "Validation Loss: 0.039451554\n",
      "Epoch: 3064 cost = 0.018278279\n",
      "Validation Loss: 0.03554706\n",
      "Epoch: 3065 cost = 0.018277864\n",
      "Validation Loss: 0.026674403\n",
      "Epoch: 3066 cost = 0.018276253\n",
      "Validation Loss: 0.030021012\n",
      "Epoch: 3067 cost = 0.018274938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.043595947\n",
      "Epoch: 3068 cost = 0.018273990\n",
      "Validation Loss: 0.04174955\n",
      "Epoch: 3069 cost = 0.018272779\n",
      "Validation Loss: 0.048581105\n",
      "Epoch: 3070 cost = 0.018271532\n",
      "Validation Loss: 0.044786647\n",
      "Epoch: 3071 cost = 0.018270418\n",
      "Validation Loss: 0.037845127\n",
      "Epoch: 3072 cost = 0.018269262\n",
      "Validation Loss: 0.032375496\n",
      "Epoch: 3073 cost = 0.018267720\n",
      "Validation Loss: 0.02688155\n",
      "Epoch: 3074 cost = 0.018266601\n",
      "Validation Loss: 0.033949126\n",
      "Epoch: 3075 cost = 0.018265660\n",
      "Validation Loss: 0.04812126\n",
      "Epoch: 3076 cost = 0.018264557\n",
      "Validation Loss: 0.032298107\n",
      "Epoch: 3077 cost = 0.018263267\n",
      "Validation Loss: 0.024153432\n",
      "Epoch: 3078 cost = 0.018261767\n",
      "Validation Loss: 0.032697372\n",
      "Epoch: 3079 cost = 0.018260638\n",
      "Validation Loss: 0.039633114\n",
      "Epoch: 3080 cost = 0.018259789\n",
      "Validation Loss: 0.050095726\n",
      "Epoch: 3081 cost = 0.018258676\n",
      "Validation Loss: 0.059099168\n",
      "Epoch: 3082 cost = 0.018257502\n",
      "Validation Loss: 0.07028731\n",
      "Epoch: 3083 cost = 0.018255857\n",
      "Validation Loss: 0.080591425\n",
      "Epoch: 3084 cost = 0.018255239\n",
      "Validation Loss: 0.07134406\n",
      "Epoch: 3085 cost = 0.018253829\n",
      "Validation Loss: 0.058938537\n",
      "Epoch: 3086 cost = 0.018252730\n",
      "Validation Loss: 0.04707053\n",
      "Epoch: 3087 cost = 0.018251573\n",
      "Validation Loss: 0.03074402\n",
      "Epoch: 3088 cost = 0.018250211\n",
      "Validation Loss: 0.028518187\n",
      "Epoch: 3089 cost = 0.018249259\n",
      "Validation Loss: 0.033665676\n",
      "Epoch: 3090 cost = 0.018247923\n",
      "Validation Loss: 0.03516474\n",
      "Epoch: 3091 cost = 0.018246467\n",
      "Validation Loss: 0.049131498\n",
      "Epoch: 3092 cost = 0.018245344\n",
      "Validation Loss: 0.074020885\n",
      "Epoch: 3093 cost = 0.018244571\n",
      "Validation Loss: 0.06534861\n",
      "Epoch: 3094 cost = 0.018243333\n",
      "Validation Loss: 0.07289872\n",
      "Epoch: 3095 cost = 0.018242058\n",
      "Validation Loss: 0.060361646\n",
      "Epoch: 3096 cost = 0.018240911\n",
      "Validation Loss: 0.047256928\n",
      "Epoch: 3097 cost = 0.018239745\n",
      "Validation Loss: 0.06511644\n",
      "Epoch: 3098 cost = 0.018238249\n",
      "Validation Loss: 0.08719046\n",
      "Epoch: 3099 cost = 0.018237653\n",
      "Validation Loss: 0.09462019\n",
      "Epoch: 3100 cost = 0.018236284\n",
      "Validation Loss: 0.07591123\n",
      "Epoch: 3101 cost = 0.018235345\n",
      "Validation Loss: 0.064459756\n",
      "Epoch: 3102 cost = 0.018234042\n",
      "Validation Loss: 0.06041254\n",
      "Epoch: 3103 cost = 0.018232802\n",
      "Validation Loss: 0.06265786\n",
      "Epoch: 3104 cost = 0.018231713\n",
      "Validation Loss: 0.055282105\n",
      "Epoch: 3105 cost = 0.018230249\n",
      "Validation Loss: 0.047228865\n",
      "Epoch: 3106 cost = 0.018229394\n",
      "Validation Loss: 0.041217305\n",
      "Epoch: 3107 cost = 0.018228211\n",
      "Validation Loss: 0.041169498\n",
      "Epoch: 3108 cost = 0.018226906\n",
      "Validation Loss: 0.03979752\n",
      "Epoch: 3109 cost = 0.018225732\n",
      "Validation Loss: 0.0415714\n",
      "Epoch: 3110 cost = 0.018224332\n",
      "Validation Loss: 0.044388216\n",
      "Epoch: 3111 cost = 0.018223413\n",
      "Validation Loss: 0.057017952\n",
      "Epoch: 3112 cost = 0.018222401\n",
      "Validation Loss: 0.050689183\n",
      "Epoch: 3113 cost = 0.018221355\n",
      "Validation Loss: 0.057736572\n",
      "Epoch: 3114 cost = 0.018219784\n",
      "Validation Loss: 0.038348835\n",
      "Epoch: 3115 cost = 0.018218725\n",
      "Validation Loss: 0.034364585\n",
      "Epoch: 3116 cost = 0.018217625\n",
      "Validation Loss: 0.034065817\n",
      "Epoch: 3117 cost = 0.018216826\n",
      "Validation Loss: 0.04025773\n",
      "Epoch: 3118 cost = 0.018214716\n",
      "Validation Loss: 0.036528062\n",
      "Epoch: 3119 cost = 0.018214064\n",
      "Validation Loss: 0.0325224\n",
      "Epoch: 3120 cost = 0.018213148\n",
      "Validation Loss: 0.03114536\n",
      "Epoch: 3121 cost = 0.018212272\n",
      "Validation Loss: 0.02570675\n",
      "Epoch: 3122 cost = 0.018210743\n",
      "Validation Loss: 0.038334467\n",
      "Epoch: 3123 cost = 0.018209404\n",
      "Validation Loss: 0.039337955\n",
      "Epoch: 3124 cost = 0.018208379\n",
      "Validation Loss: 0.05017852\n",
      "Epoch: 3125 cost = 0.018207528\n",
      "Validation Loss: 0.04893676\n",
      "Epoch: 3126 cost = 0.018206072\n",
      "Validation Loss: 0.047156535\n",
      "Epoch: 3127 cost = 0.018204758\n",
      "Validation Loss: 0.04049481\n",
      "Epoch: 3128 cost = 0.018204119\n",
      "Validation Loss: 0.032164894\n",
      "Epoch: 3129 cost = 0.018202949\n",
      "Validation Loss: 0.05157151\n",
      "Epoch: 3130 cost = 0.018201966\n",
      "Validation Loss: 0.06996167\n",
      "Epoch: 3131 cost = 0.018200871\n",
      "Validation Loss: 0.058788672\n",
      "Epoch: 3132 cost = 0.018199140\n",
      "Validation Loss: 0.04340484\n",
      "Epoch: 3133 cost = 0.018198418\n",
      "Validation Loss: 0.03400479\n",
      "Epoch: 3134 cost = 0.018197396\n",
      "Validation Loss: 0.053367425\n",
      "Epoch: 3135 cost = 0.018195744\n",
      "Validation Loss: 0.07148837\n",
      "Epoch: 3136 cost = 0.018194824\n",
      "Validation Loss: 0.05589749\n",
      "Epoch: 3137 cost = 0.018193943\n",
      "Validation Loss: 0.038704753\n",
      "Epoch: 3138 cost = 0.018192870\n",
      "Validation Loss: 0.025105696\n",
      "Epoch: 3139 cost = 0.018191363\n",
      "Validation Loss: 0.030724023\n",
      "Epoch: 3140 cost = 0.018190238\n",
      "Validation Loss: 0.030732019\n",
      "Epoch: 3141 cost = 0.018189111\n",
      "Validation Loss: 0.04025781\n",
      "Epoch: 3142 cost = 0.018188071\n",
      "Validation Loss: 0.05642428\n",
      "Epoch: 3143 cost = 0.018187057\n",
      "Validation Loss: 0.06868738\n",
      "Epoch: 3144 cost = 0.018185601\n",
      "Validation Loss: 0.062101226\n",
      "Epoch: 3145 cost = 0.018184586\n",
      "Validation Loss: 0.056604173\n",
      "Epoch: 3146 cost = 0.018183342\n",
      "Validation Loss: 0.046763908\n",
      "Epoch: 3147 cost = 0.018182273\n",
      "Validation Loss: 0.05342048\n",
      "Epoch: 3148 cost = 0.018181360\n",
      "Validation Loss: 0.03232634\n",
      "Epoch: 3149 cost = 0.018179847\n",
      "Validation Loss: 0.025615875\n",
      "Epoch: 3150 cost = 0.018179709\n",
      "Validation Loss: 0.023363953\n",
      "Epoch: 3151 cost = 0.018178393\n",
      "Validation Loss: 0.041146208\n",
      "Epoch: 3152 cost = 0.018176643\n",
      "Validation Loss: 0.045460053\n",
      "Epoch: 3153 cost = 0.018175609\n",
      "Validation Loss: 0.04042595\n",
      "Epoch: 3154 cost = 0.018174562\n",
      "Validation Loss: 0.04509384\n",
      "Epoch: 3155 cost = 0.018173364\n",
      "Validation Loss: 0.052436635\n",
      "Epoch: 3156 cost = 0.018172266\n",
      "Validation Loss: 0.041910913\n",
      "Epoch: 3157 cost = 0.018171353\n",
      "Validation Loss: 0.038391087\n",
      "Epoch: 3158 cost = 0.018169893\n",
      "Validation Loss: 0.026022948\n",
      "Epoch: 3159 cost = 0.018169047\n",
      "Validation Loss: 0.0345738\n",
      "Epoch: 3160 cost = 0.018168410\n",
      "Validation Loss: 0.042997763\n",
      "Epoch: 3161 cost = 0.018166926\n",
      "Validation Loss: 0.0374137\n",
      "Epoch: 3162 cost = 0.018165738\n",
      "Validation Loss: 0.041015334\n",
      "Epoch: 3163 cost = 0.018164453\n",
      "Validation Loss: 0.053446442\n",
      "Epoch: 3164 cost = 0.018163173\n",
      "Validation Loss: 0.07135005\n",
      "Epoch: 3165 cost = 0.018162286\n",
      "Validation Loss: 0.0740977\n",
      "Epoch: 3166 cost = 0.018161233\n",
      "Validation Loss: 0.06660528\n",
      "Epoch: 3167 cost = 0.018159976\n",
      "Validation Loss: 0.04143007\n",
      "Epoch: 3168 cost = 0.018158855\n",
      "Validation Loss: 0.02948697\n",
      "Epoch: 3169 cost = 0.018157991\n",
      "Validation Loss: 0.04283898\n",
      "Epoch: 3170 cost = 0.018156810\n",
      "Validation Loss: 0.054720778\n",
      "Epoch: 3171 cost = 0.018155811\n",
      "Validation Loss: 0.048915137\n",
      "Epoch: 3172 cost = 0.018154593\n",
      "Validation Loss: 0.038944185\n",
      "Epoch: 3173 cost = 0.018153426\n",
      "Validation Loss: 0.064054854\n",
      "Epoch: 3174 cost = 0.018152284\n",
      "Validation Loss: 0.088223964\n",
      "Epoch: 3175 cost = 0.018151087\n",
      "Validation Loss: 0.08558843\n",
      "Epoch: 3176 cost = 0.018150300\n",
      "Validation Loss: 0.044677813\n",
      "Epoch: 3177 cost = 0.018149008\n",
      "Validation Loss: 0.036763582\n",
      "Epoch: 3178 cost = 0.018147874\n",
      "Validation Loss: 0.03843802\n",
      "Epoch: 3179 cost = 0.018147180\n",
      "Validation Loss: 0.045832112\n",
      "Epoch: 3180 cost = 0.018145816\n",
      "Validation Loss: 0.051359907\n",
      "Epoch: 3181 cost = 0.018144430\n",
      "Validation Loss: 0.06776682\n",
      "Epoch: 3182 cost = 0.018143238\n",
      "Validation Loss: 0.05798653\n",
      "Epoch: 3183 cost = 0.018142379\n",
      "Validation Loss: 0.050855327\n",
      "Epoch: 3184 cost = 0.018141533\n",
      "Validation Loss: 0.028960913\n",
      "Epoch: 3185 cost = 0.018140284\n",
      "Validation Loss: 0.022155242\n",
      "Epoch: 3186 cost = 0.018139351\n",
      "Validation Loss: 0.030229418\n",
      "Epoch: 3187 cost = 0.018138115\n",
      "Validation Loss: 0.03154036\n",
      "Epoch: 3188 cost = 0.018136934\n",
      "Validation Loss: 0.03041188\n",
      "Epoch: 3189 cost = 0.018135598\n",
      "Validation Loss: 0.038910627\n",
      "Epoch: 3190 cost = 0.018134691\n",
      "Validation Loss: 0.027013674\n",
      "Epoch: 3191 cost = 0.018133719\n",
      "Validation Loss: 0.024098821\n",
      "Epoch: 3192 cost = 0.018132564\n",
      "Validation Loss: 0.018267224\n",
      "Epoch: 3193 cost = 0.018131058\n",
      "Validation Loss: 0.099839896\n",
      "Epoch: 3194 cost = 0.018130297\n",
      "Validation Loss: 0.08486956\n",
      "Epoch: 3195 cost = 0.018129109\n",
      "Validation Loss: 0.067331254\n",
      "Epoch: 3196 cost = 0.018128336\n",
      "Validation Loss: 0.032651953\n",
      "Epoch: 3197 cost = 0.018127352\n",
      "Validation Loss: 0.022432704\n",
      "Epoch: 3198 cost = 0.018126317\n",
      "Validation Loss: 0.028369702\n",
      "Epoch: 3199 cost = 0.018125090\n",
      "Validation Loss: 0.035718367\n",
      "Epoch: 3200 cost = 0.018123802\n",
      "Validation Loss: 0.047729272\n",
      "Epoch: 3201 cost = 0.018122824\n",
      "Validation Loss: 0.043544736\n",
      "Epoch: 3202 cost = 0.018121734\n",
      "Validation Loss: 0.036244698\n",
      "Epoch: 3203 cost = 0.018120860\n",
      "Validation Loss: 0.03987742\n",
      "Epoch: 3204 cost = 0.018119322\n",
      "Validation Loss: 0.03763243\n",
      "Epoch: 3205 cost = 0.018118435\n",
      "Validation Loss: 0.049448904\n",
      "Epoch: 3206 cost = 0.018117311\n",
      "Validation Loss: 0.06745255\n",
      "Epoch: 3207 cost = 0.018116178\n",
      "Validation Loss: 0.052057855\n",
      "Epoch: 3208 cost = 0.018115583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.047772028\n",
      "Epoch: 3209 cost = 0.018114568\n",
      "Validation Loss: 0.034599505\n",
      "Epoch: 3210 cost = 0.018112912\n",
      "Validation Loss: 0.029098587\n",
      "Epoch: 3211 cost = 0.018111925\n",
      "Validation Loss: 0.035409413\n",
      "Epoch: 3212 cost = 0.018111345\n",
      "Validation Loss: 0.040643148\n",
      "Epoch: 3213 cost = 0.018110025\n",
      "Validation Loss: 0.03633797\n",
      "Epoch: 3214 cost = 0.018108972\n",
      "Validation Loss: 0.03901188\n",
      "Epoch: 3215 cost = 0.018107810\n",
      "Validation Loss: 0.043771684\n",
      "Epoch: 3216 cost = 0.018106436\n",
      "Validation Loss: 0.027302267\n",
      "Epoch: 3217 cost = 0.018105336\n",
      "Validation Loss: 0.030227043\n",
      "Epoch: 3218 cost = 0.018104534\n",
      "Validation Loss: 0.027698146\n",
      "Epoch: 3219 cost = 0.018103803\n",
      "Validation Loss: 0.034082897\n",
      "Epoch: 3220 cost = 0.018102586\n",
      "Validation Loss: 0.043242913\n",
      "Epoch: 3221 cost = 0.018101118\n",
      "Validation Loss: 0.042689845\n",
      "Epoch: 3222 cost = 0.018099862\n",
      "Validation Loss: 0.048863236\n",
      "Epoch: 3223 cost = 0.018099410\n",
      "Validation Loss: 0.054168526\n",
      "Epoch: 3224 cost = 0.018098037\n",
      "Validation Loss: 0.051432956\n",
      "Epoch: 3225 cost = 0.018097075\n",
      "Validation Loss: 0.03949566\n",
      "Epoch: 3226 cost = 0.018095590\n",
      "Validation Loss: 0.042987235\n",
      "Epoch: 3227 cost = 0.018095218\n",
      "Validation Loss: 0.059574842\n",
      "Epoch: 3228 cost = 0.018093708\n",
      "Validation Loss: 0.06033295\n",
      "Epoch: 3229 cost = 0.018093079\n",
      "Validation Loss: 0.03574671\n",
      "Epoch: 3230 cost = 0.018091456\n",
      "Validation Loss: 0.038846448\n",
      "Epoch: 3231 cost = 0.018090644\n",
      "Validation Loss: 0.05156705\n",
      "Epoch: 3232 cost = 0.018089208\n",
      "Validation Loss: 0.05001097\n",
      "Epoch: 3233 cost = 0.018088762\n",
      "Validation Loss: 0.05201413\n",
      "Epoch: 3234 cost = 0.018087649\n",
      "Validation Loss: 0.047694944\n",
      "Epoch: 3235 cost = 0.018086437\n",
      "Validation Loss: 0.050680086\n",
      "Epoch: 3236 cost = 0.018085471\n",
      "Validation Loss: 0.04131953\n",
      "Epoch: 3237 cost = 0.018084020\n",
      "Validation Loss: 0.036693465\n",
      "Epoch: 3238 cost = 0.018083174\n",
      "Validation Loss: 0.04305978\n",
      "Epoch: 3239 cost = 0.018082432\n",
      "Validation Loss: 0.04870394\n",
      "Epoch: 3240 cost = 0.018080966\n",
      "Validation Loss: 0.03860579\n",
      "Epoch: 3241 cost = 0.018079826\n",
      "Validation Loss: 0.035729032\n",
      "Epoch: 3242 cost = 0.018078711\n",
      "Validation Loss: 0.052471783\n",
      "Epoch: 3243 cost = 0.018077940\n",
      "Validation Loss: 0.050452106\n",
      "Epoch: 3244 cost = 0.018076777\n",
      "Validation Loss: 0.030420957\n",
      "Epoch: 3245 cost = 0.018075782\n",
      "Validation Loss: 0.03048801\n",
      "Epoch: 3246 cost = 0.018075034\n",
      "Validation Loss: 0.02830251\n",
      "Epoch: 3247 cost = 0.018073616\n",
      "Validation Loss: 0.033811383\n",
      "Epoch: 3248 cost = 0.018072921\n",
      "Validation Loss: 0.035581376\n",
      "Epoch: 3249 cost = 0.018071713\n",
      "Validation Loss: 0.03849305\n",
      "Epoch: 3250 cost = 0.018070868\n",
      "Validation Loss: 0.04438749\n",
      "Epoch: 3251 cost = 0.018069614\n",
      "Validation Loss: 0.044503067\n",
      "Epoch: 3252 cost = 0.018067938\n",
      "Validation Loss: 0.04682857\n",
      "Epoch: 3253 cost = 0.018067204\n",
      "Validation Loss: 0.04148248\n",
      "Epoch: 3254 cost = 0.018066312\n",
      "Validation Loss: 0.043596353\n",
      "Epoch: 3255 cost = 0.018065317\n",
      "Validation Loss: 0.053941146\n",
      "Epoch: 3256 cost = 0.018064549\n",
      "Validation Loss: 0.05188457\n",
      "Epoch: 3257 cost = 0.018063374\n",
      "Validation Loss: 0.05353442\n",
      "Epoch: 3258 cost = 0.018062359\n",
      "Validation Loss: 0.045988064\n",
      "Epoch: 3259 cost = 0.018061025\n",
      "Validation Loss: 0.04416558\n",
      "Epoch: 3260 cost = 0.018060261\n",
      "Validation Loss: 0.0459752\n",
      "Epoch: 3261 cost = 0.018059152\n",
      "Validation Loss: 0.039848432\n",
      "Epoch: 3262 cost = 0.018058065\n",
      "Validation Loss: 0.048542965\n",
      "Epoch: 3263 cost = 0.018057223\n",
      "Validation Loss: 0.04443289\n",
      "Epoch: 3264 cost = 0.018056076\n",
      "Validation Loss: 0.040474106\n",
      "Epoch: 3265 cost = 0.018055183\n",
      "Validation Loss: 0.035685074\n",
      "Epoch: 3266 cost = 0.018053851\n",
      "Validation Loss: 0.0417231\n",
      "Epoch: 3267 cost = 0.018053043\n",
      "Validation Loss: 0.060121063\n",
      "Epoch: 3268 cost = 0.018051781\n",
      "Validation Loss: 0.04231341\n",
      "Epoch: 3269 cost = 0.018050911\n",
      "Validation Loss: 0.04338445\n",
      "Epoch: 3270 cost = 0.018049908\n",
      "Validation Loss: 0.058306422\n",
      "Epoch: 3271 cost = 0.018049005\n",
      "Validation Loss: 0.048700333\n",
      "Epoch: 3272 cost = 0.018047735\n",
      "Validation Loss: 0.04346027\n",
      "Epoch: 3273 cost = 0.018046748\n",
      "Validation Loss: 0.022549983\n",
      "Epoch: 3274 cost = 0.018046051\n",
      "Validation Loss: 0.031300668\n",
      "Epoch: 3275 cost = 0.018044626\n",
      "Validation Loss: 0.059341878\n",
      "Epoch: 3276 cost = 0.018043502\n",
      "Validation Loss: 0.072762065\n",
      "Epoch: 3277 cost = 0.018042804\n",
      "Validation Loss: 0.076700486\n",
      "Epoch: 3278 cost = 0.018041968\n",
      "Validation Loss: 0.06134369\n",
      "Epoch: 3279 cost = 0.018040586\n",
      "Validation Loss: 0.043909553\n",
      "Epoch: 3280 cost = 0.018039588\n",
      "Validation Loss: 0.045046255\n",
      "Epoch: 3281 cost = 0.018038755\n",
      "Validation Loss: 0.04106884\n",
      "Epoch: 3282 cost = 0.018037528\n",
      "Validation Loss: 0.03574038\n",
      "Epoch: 3283 cost = 0.018036511\n",
      "Validation Loss: 0.041340493\n",
      "Epoch: 3284 cost = 0.018035292\n",
      "Validation Loss: 0.066160105\n",
      "Epoch: 3285 cost = 0.018034618\n",
      "Validation Loss: 0.07450066\n",
      "Epoch: 3286 cost = 0.018033183\n",
      "Validation Loss: 0.07409309\n",
      "Epoch: 3287 cost = 0.018032471\n",
      "Validation Loss: 0.06823213\n",
      "Epoch: 3288 cost = 0.018031862\n",
      "Validation Loss: 0.04545646\n",
      "Epoch: 3289 cost = 0.018030098\n",
      "Validation Loss: 0.03975991\n",
      "Epoch: 3290 cost = 0.018029571\n",
      "Validation Loss: 0.04524373\n",
      "Epoch: 3291 cost = 0.018028391\n",
      "Validation Loss: 0.038544293\n",
      "Epoch: 3292 cost = 0.018027445\n",
      "Validation Loss: 0.045726977\n",
      "Epoch: 3293 cost = 0.018026217\n",
      "Validation Loss: 0.06765199\n",
      "Epoch: 3294 cost = 0.018025230\n",
      "Validation Loss: 0.071718395\n",
      "Epoch: 3295 cost = 0.018024315\n",
      "Validation Loss: 0.05542884\n",
      "Epoch: 3296 cost = 0.018023241\n",
      "Validation Loss: 0.04411057\n",
      "Epoch: 3297 cost = 0.018022125\n",
      "Validation Loss: 0.033753138\n",
      "Epoch: 3298 cost = 0.018021478\n",
      "Validation Loss: 0.026730446\n",
      "Epoch: 3299 cost = 0.018020421\n",
      "Validation Loss: 0.035281446\n",
      "Epoch: 3300 cost = 0.018019355\n",
      "Validation Loss: 0.047711547\n",
      "Epoch: 3301 cost = 0.018018218\n",
      "Validation Loss: 0.05473284\n",
      "Epoch: 3302 cost = 0.018017149\n",
      "Validation Loss: 0.060098324\n",
      "Epoch: 3303 cost = 0.018016389\n",
      "Validation Loss: 0.06274096\n",
      "Epoch: 3304 cost = 0.018015120\n",
      "Validation Loss: 0.03418777\n",
      "Epoch: 3305 cost = 0.018014325\n",
      "Validation Loss: 0.036252588\n",
      "Epoch: 3306 cost = 0.018013078\n",
      "Validation Loss: 0.029573204\n",
      "Epoch: 3307 cost = 0.018012103\n",
      "Validation Loss: 0.032642696\n",
      "Epoch: 3308 cost = 0.018010945\n",
      "Validation Loss: 0.059065334\n",
      "Epoch: 3309 cost = 0.018009959\n",
      "Validation Loss: 0.07728527\n",
      "Epoch: 3310 cost = 0.018009244\n",
      "Validation Loss: 0.07568447\n",
      "Epoch: 3311 cost = 0.018008520\n",
      "Validation Loss: 0.049057804\n",
      "Epoch: 3312 cost = 0.018007232\n",
      "Validation Loss: 0.053441536\n",
      "Epoch: 3313 cost = 0.018005942\n",
      "Validation Loss: 0.03754801\n",
      "Epoch: 3314 cost = 0.018004849\n",
      "Validation Loss: 0.05054389\n",
      "Epoch: 3315 cost = 0.018003678\n",
      "Validation Loss: 0.0652776\n",
      "Epoch: 3316 cost = 0.018003397\n",
      "Validation Loss: 0.05913459\n",
      "Epoch: 3317 cost = 0.018001857\n",
      "Validation Loss: 0.03936694\n",
      "Epoch: 3318 cost = 0.018001082\n",
      "Validation Loss: 0.038988132\n",
      "Epoch: 3319 cost = 0.018000171\n",
      "Validation Loss: 0.04285328\n",
      "Epoch: 3320 cost = 0.017999078\n",
      "Validation Loss: 0.03639549\n",
      "Epoch: 3321 cost = 0.017998282\n",
      "Validation Loss: 0.040373698\n",
      "Epoch: 3322 cost = 0.017997392\n",
      "Validation Loss: 0.042804517\n",
      "Epoch: 3323 cost = 0.017996075\n",
      "Validation Loss: 0.049707\n",
      "Epoch: 3324 cost = 0.017995110\n",
      "Validation Loss: 0.047833968\n",
      "Epoch: 3325 cost = 0.017993884\n",
      "Validation Loss: 0.057118937\n",
      "Epoch: 3326 cost = 0.017993375\n",
      "Validation Loss: 0.059078235\n",
      "Epoch: 3327 cost = 0.017992360\n",
      "Validation Loss: 0.039110526\n",
      "Epoch: 3328 cost = 0.017991109\n",
      "Validation Loss: 0.042616773\n",
      "Epoch: 3329 cost = 0.017990609\n",
      "Validation Loss: 0.04369385\n",
      "Epoch: 3330 cost = 0.017989337\n",
      "Validation Loss: 0.03565774\n",
      "Epoch: 3331 cost = 0.017988274\n",
      "Validation Loss: 0.029139737\n",
      "Epoch: 3332 cost = 0.017987705\n",
      "Validation Loss: 0.039240286\n",
      "Epoch: 3333 cost = 0.017986207\n",
      "Validation Loss: 0.047534663\n",
      "Epoch: 3334 cost = 0.017985180\n",
      "Validation Loss: 0.033209756\n",
      "Epoch: 3335 cost = 0.017984255\n",
      "Validation Loss: 0.028852848\n",
      "Epoch: 3336 cost = 0.017982981\n",
      "Validation Loss: 0.050124545\n",
      "Epoch: 3337 cost = 0.017981995\n",
      "Validation Loss: 0.061294455\n",
      "Epoch: 3338 cost = 0.017981348\n",
      "Validation Loss: 0.056371324\n",
      "Epoch: 3339 cost = 0.017980425\n",
      "Validation Loss: 0.065570794\n",
      "Epoch: 3340 cost = 0.017979334\n",
      "Validation Loss: 0.08615299\n",
      "Epoch: 3341 cost = 0.017978391\n",
      "Validation Loss: 0.060578212\n",
      "Epoch: 3342 cost = 0.017977745\n",
      "Validation Loss: 0.030968335\n",
      "Epoch: 3343 cost = 0.017976589\n",
      "Validation Loss: 0.038767498\n",
      "Epoch: 3344 cost = 0.017975390\n",
      "Validation Loss: 0.036635913\n",
      "Epoch: 3345 cost = 0.017974888\n",
      "Validation Loss: 0.03990762\n",
      "Epoch: 3346 cost = 0.017973607\n",
      "Validation Loss: 0.047938522\n",
      "Epoch: 3347 cost = 0.017972408\n",
      "Validation Loss: 0.057267986\n",
      "Epoch: 3348 cost = 0.017971522\n",
      "Validation Loss: 0.05513406\n",
      "Epoch: 3349 cost = 0.017970609\n",
      "Validation Loss: 0.04012688\n",
      "Epoch: 3350 cost = 0.017969935\n",
      "Validation Loss: 0.033820484\n",
      "Epoch: 3351 cost = 0.017968781\n",
      "Validation Loss: 0.029201595\n",
      "Epoch: 3352 cost = 0.017967928\n",
      "Validation Loss: 0.025324635\n",
      "Epoch: 3353 cost = 0.017966775\n",
      "Validation Loss: 0.046921372\n",
      "Epoch: 3354 cost = 0.017965458\n",
      "Validation Loss: 0.058005095\n",
      "Epoch: 3355 cost = 0.017964899\n",
      "Validation Loss: 0.052232575\n",
      "Epoch: 3356 cost = 0.017963876\n",
      "Validation Loss: 0.040164396\n",
      "Epoch: 3357 cost = 0.017962840\n",
      "Validation Loss: 0.037197832\n",
      "Epoch: 3358 cost = 0.017962044\n",
      "Validation Loss: 0.05404957\n",
      "Epoch: 3359 cost = 0.017961199\n",
      "Validation Loss: 0.06640743\n",
      "Epoch: 3360 cost = 0.017959514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.050104253\n",
      "Epoch: 3361 cost = 0.017958588\n",
      "Validation Loss: 0.03973\n",
      "Epoch: 3362 cost = 0.017957587\n",
      "Validation Loss: 0.05517005\n",
      "Epoch: 3363 cost = 0.017956295\n",
      "Validation Loss: 0.07166998\n",
      "Epoch: 3364 cost = 0.017956098\n",
      "Validation Loss: 0.075642556\n",
      "Epoch: 3365 cost = 0.017955264\n",
      "Validation Loss: 0.080673754\n",
      "Epoch: 3366 cost = 0.017954409\n",
      "Validation Loss: 0.07826386\n",
      "Epoch: 3367 cost = 0.017953044\n",
      "Validation Loss: 0.035040867\n",
      "Epoch: 3368 cost = 0.017952089\n",
      "Validation Loss: 0.035406996\n",
      "Epoch: 3369 cost = 0.017951280\n",
      "Validation Loss: 0.036436144\n",
      "Epoch: 3370 cost = 0.017950269\n",
      "Validation Loss: 0.037025757\n",
      "Epoch: 3371 cost = 0.017949566\n",
      "Validation Loss: 0.049270965\n",
      "Epoch: 3372 cost = 0.017948484\n",
      "Validation Loss: 0.06106843\n",
      "Epoch: 3373 cost = 0.017947359\n",
      "Validation Loss: 0.047573972\n",
      "Epoch: 3374 cost = 0.017946459\n",
      "Validation Loss: 0.027937708\n",
      "Epoch: 3375 cost = 0.017945515\n",
      "Validation Loss: 0.032411933\n",
      "Epoch: 3376 cost = 0.017944730\n",
      "Validation Loss: 0.034972385\n",
      "Epoch: 3377 cost = 0.017943448\n",
      "Validation Loss: 0.034049463\n",
      "Epoch: 3378 cost = 0.017942646\n",
      "Validation Loss: 0.038841225\n",
      "Epoch: 3379 cost = 0.017941519\n",
      "Validation Loss: 0.045585595\n",
      "Epoch: 3380 cost = 0.017940664\n",
      "Validation Loss: 0.040467486\n",
      "Epoch: 3381 cost = 0.017939856\n",
      "Validation Loss: 0.032171775\n",
      "Epoch: 3382 cost = 0.017938674\n",
      "Validation Loss: 0.022115977\n",
      "Epoch: 3383 cost = 0.017937699\n",
      "Validation Loss: 0.038516928\n",
      "Epoch: 3384 cost = 0.017937234\n",
      "Validation Loss: 0.043266755\n",
      "Epoch: 3385 cost = 0.017935471\n",
      "Validation Loss: 0.038319133\n",
      "Epoch: 3386 cost = 0.017934988\n",
      "Validation Loss: 0.049014818\n",
      "Epoch: 3387 cost = 0.017933963\n",
      "Validation Loss: 0.05335704\n",
      "Epoch: 3388 cost = 0.017932882\n",
      "Validation Loss: 0.06613123\n",
      "Epoch: 3389 cost = 0.017932079\n",
      "Validation Loss: 0.05729962\n",
      "Epoch: 3390 cost = 0.017931077\n",
      "Validation Loss: 0.044600617\n",
      "Epoch: 3391 cost = 0.017929862\n",
      "Validation Loss: 0.03902716\n",
      "Epoch: 3392 cost = 0.017929699\n",
      "Validation Loss: 0.059954997\n",
      "Epoch: 3393 cost = 0.017927656\n",
      "Validation Loss: 0.068912484\n",
      "Epoch: 3394 cost = 0.017927299\n",
      "Validation Loss: 0.08434619\n",
      "Epoch: 3395 cost = 0.017926345\n",
      "Validation Loss: 0.0739364\n",
      "Epoch: 3396 cost = 0.017925497\n",
      "Validation Loss: 0.05172629\n",
      "Epoch: 3397 cost = 0.017924328\n",
      "Validation Loss: 0.047636002\n",
      "Epoch: 3398 cost = 0.017923571\n",
      "Validation Loss: 0.060474984\n",
      "Epoch: 3399 cost = 0.017922666\n",
      "Validation Loss: 0.049617246\n",
      "Epoch: 3400 cost = 0.017921626\n",
      "Validation Loss: 0.056623984\n",
      "Epoch: 3401 cost = 0.017920569\n",
      "Validation Loss: 0.08920043\n",
      "Epoch: 3402 cost = 0.017920071\n",
      "Validation Loss: 0.10698167\n",
      "Epoch: 3403 cost = 0.017918767\n",
      "Validation Loss: 0.092042066\n",
      "Epoch: 3404 cost = 0.017917536\n",
      "Validation Loss: 0.072068796\n",
      "Epoch: 3405 cost = 0.017916790\n",
      "Validation Loss: 0.08302493\n",
      "Epoch: 3406 cost = 0.017916135\n",
      "Validation Loss: 0.07139266\n",
      "Epoch: 3407 cost = 0.017915039\n",
      "Validation Loss: 0.06834963\n",
      "Epoch: 3408 cost = 0.017914291\n",
      "Validation Loss: 0.046592247\n",
      "Epoch: 3409 cost = 0.017913367\n",
      "Validation Loss: 0.01979389\n",
      "Epoch: 3410 cost = 0.017912006\n",
      "Validation Loss: 0.03300715\n",
      "Epoch: 3411 cost = 0.017911598\n",
      "Validation Loss: 0.044355966\n",
      "Epoch: 3412 cost = 0.017910232\n",
      "Validation Loss: 0.04541926\n",
      "Epoch: 3413 cost = 0.017909189\n",
      "Validation Loss: 0.061235674\n",
      "Epoch: 3414 cost = 0.017908394\n",
      "Validation Loss: 0.047013175\n",
      "Epoch: 3415 cost = 0.017907384\n",
      "Validation Loss: 0.03210156\n",
      "Epoch: 3416 cost = 0.017906713\n",
      "Validation Loss: 0.026232012\n",
      "Epoch: 3417 cost = 0.017905927\n",
      "Validation Loss: 0.02614491\n",
      "Epoch: 3418 cost = 0.017904604\n",
      "Validation Loss: 0.025394397\n",
      "Epoch: 3419 cost = 0.017903850\n",
      "Validation Loss: 0.029265579\n",
      "Epoch: 3420 cost = 0.017903129\n",
      "Validation Loss: 0.030125579\n",
      "Epoch: 3421 cost = 0.017902129\n",
      "Validation Loss: 0.038010504\n",
      "Epoch: 3422 cost = 0.017901313\n",
      "Validation Loss: 0.032409843\n",
      "Epoch: 3423 cost = 0.017900046\n",
      "Validation Loss: 0.03113151\n",
      "Epoch: 3424 cost = 0.017899206\n",
      "Validation Loss: 0.023690982\n",
      "Epoch: 3425 cost = 0.017898057\n",
      "Validation Loss: 0.03380347\n",
      "Epoch: 3426 cost = 0.017897562\n",
      "Validation Loss: 0.039127234\n",
      "Epoch: 3427 cost = 0.017896349\n",
      "Validation Loss: 0.040383656\n",
      "Epoch: 3428 cost = 0.017895941\n",
      "Validation Loss: 0.030043155\n",
      "Epoch: 3429 cost = 0.017894665\n",
      "Validation Loss: 0.03578263\n",
      "Epoch: 3430 cost = 0.017894046\n",
      "Validation Loss: 0.034965534\n",
      "Epoch: 3431 cost = 0.017893152\n",
      "Validation Loss: 0.04884908\n",
      "Epoch: 3432 cost = 0.017892169\n",
      "Validation Loss: 0.034337297\n",
      "Epoch: 3433 cost = 0.017890800\n",
      "Validation Loss: 0.024053454\n",
      "Epoch: 3434 cost = 0.017890080\n",
      "Validation Loss: 0.04682521\n",
      "Epoch: 3435 cost = 0.017889400\n",
      "Validation Loss: 0.043474976\n",
      "Epoch: 3436 cost = 0.017888166\n",
      "Validation Loss: 0.04938136\n",
      "Epoch: 3437 cost = 0.017887521\n",
      "Validation Loss: 0.058722872\n",
      "Epoch: 3438 cost = 0.017886506\n",
      "Validation Loss: 0.048928842\n",
      "Epoch: 3439 cost = 0.017885211\n",
      "Validation Loss: 0.048940193\n",
      "Epoch: 3440 cost = 0.017884321\n",
      "Validation Loss: 0.032726504\n",
      "Epoch: 3441 cost = 0.017883760\n",
      "Validation Loss: 0.034728277\n",
      "Epoch: 3442 cost = 0.017882978\n",
      "Validation Loss: 0.034018226\n",
      "Epoch: 3443 cost = 0.017881810\n",
      "Validation Loss: 0.023989564\n",
      "Epoch: 3444 cost = 0.017880812\n",
      "Validation Loss: 0.03903507\n",
      "Epoch: 3445 cost = 0.017880167\n",
      "Validation Loss: 0.040592402\n",
      "Epoch: 3446 cost = 0.017879091\n",
      "Validation Loss: 0.041479196\n",
      "Epoch: 3447 cost = 0.017878130\n",
      "Validation Loss: 0.044409446\n",
      "Epoch: 3448 cost = 0.017877251\n",
      "Validation Loss: 0.05129318\n",
      "Epoch: 3449 cost = 0.017876461\n",
      "Validation Loss: 0.047517825\n",
      "Epoch: 3450 cost = 0.017875385\n",
      "Validation Loss: 0.041505203\n",
      "Epoch: 3451 cost = 0.017874435\n",
      "Validation Loss: 0.030657882\n",
      "Epoch: 3452 cost = 0.017873715\n",
      "Validation Loss: 0.03611921\n",
      "Epoch: 3453 cost = 0.017872530\n",
      "Validation Loss: 0.039011046\n",
      "Epoch: 3454 cost = 0.017871819\n",
      "Validation Loss: 0.034327284\n",
      "Epoch: 3455 cost = 0.017870950\n",
      "Validation Loss: 0.030633194\n",
      "Epoch: 3456 cost = 0.017869732\n",
      "Validation Loss: 0.060456395\n",
      "Epoch: 3457 cost = 0.017869143\n",
      "Validation Loss: 0.079294786\n",
      "Epoch: 3458 cost = 0.017867981\n",
      "Validation Loss: 0.06364341\n",
      "Epoch: 3459 cost = 0.017867637\n",
      "Validation Loss: 0.045351904\n",
      "Epoch: 3460 cost = 0.017866163\n",
      "Validation Loss: 0.055452734\n",
      "Epoch: 3461 cost = 0.017865443\n",
      "Validation Loss: 0.08221201\n",
      "Epoch: 3462 cost = 0.017864556\n",
      "Validation Loss: 0.07185851\n",
      "Epoch: 3463 cost = 0.017863736\n",
      "Validation Loss: 0.044892482\n",
      "Epoch: 3464 cost = 0.017862717\n",
      "Validation Loss: 0.02871202\n",
      "Epoch: 3465 cost = 0.017862149\n",
      "Validation Loss: 0.033207733\n",
      "Epoch: 3466 cost = 0.017861129\n",
      "Validation Loss: 0.04587981\n",
      "Epoch: 3467 cost = 0.017859919\n",
      "Validation Loss: 0.034059092\n",
      "Epoch: 3468 cost = 0.017859384\n",
      "Validation Loss: 0.024417566\n",
      "Epoch: 3469 cost = 0.017858549\n",
      "Validation Loss: 0.03675022\n",
      "Epoch: 3470 cost = 0.017857310\n",
      "Validation Loss: 0.058665633\n",
      "Epoch: 3471 cost = 0.017856287\n",
      "Validation Loss: 0.06383354\n",
      "Epoch: 3472 cost = 0.017855391\n",
      "Validation Loss: 0.054047197\n",
      "Epoch: 3473 cost = 0.017854709\n",
      "Validation Loss: 0.054447036\n",
      "Epoch: 3474 cost = 0.017853842\n",
      "Validation Loss: 0.06554002\n",
      "Epoch: 3475 cost = 0.017852872\n",
      "Validation Loss: 0.05994642\n",
      "Epoch: 3476 cost = 0.017851802\n",
      "Validation Loss: 0.043275762\n",
      "Epoch: 3477 cost = 0.017851001\n",
      "Validation Loss: 0.025479639\n",
      "Epoch: 3478 cost = 0.017850321\n",
      "Validation Loss: 0.034281496\n",
      "Epoch: 3479 cost = 0.017849084\n",
      "Validation Loss: 0.025009101\n",
      "Epoch: 3480 cost = 0.017848558\n",
      "Validation Loss: 0.041569255\n",
      "Epoch: 3481 cost = 0.017847529\n",
      "Validation Loss: 0.046108156\n",
      "Epoch: 3482 cost = 0.017846204\n",
      "Validation Loss: 0.049960274\n",
      "Epoch: 3483 cost = 0.017845764\n",
      "Validation Loss: 0.05719895\n",
      "Epoch: 3484 cost = 0.017845253\n",
      "Validation Loss: 0.058555253\n",
      "Epoch: 3485 cost = 0.017844200\n",
      "Validation Loss: 0.045682203\n",
      "Epoch: 3486 cost = 0.017843502\n",
      "Validation Loss: 0.069956034\n",
      "Epoch: 3487 cost = 0.017842445\n",
      "Validation Loss: 0.061090004\n",
      "Epoch: 3488 cost = 0.017841650\n",
      "Validation Loss: 0.06104766\n",
      "Epoch: 3489 cost = 0.017840311\n",
      "Validation Loss: 0.045877762\n",
      "Epoch: 3490 cost = 0.017839747\n",
      "Validation Loss: 0.033002455\n",
      "Epoch: 3491 cost = 0.017838516\n",
      "Validation Loss: 0.035635095\n",
      "Epoch: 3492 cost = 0.017838141\n",
      "Validation Loss: 0.04156935\n",
      "Epoch: 3493 cost = 0.017837093\n",
      "Validation Loss: 0.035697035\n",
      "Epoch: 3494 cost = 0.017836232\n",
      "Validation Loss: 0.028646987\n",
      "Epoch: 3495 cost = 0.017835296\n",
      "Validation Loss: 0.024346134\n",
      "Epoch: 3496 cost = 0.017834426\n",
      "Validation Loss: 0.049284194\n",
      "Epoch: 3497 cost = 0.017833451\n",
      "Validation Loss: 0.06908304\n",
      "Epoch: 3498 cost = 0.017832579\n",
      "Validation Loss: 0.07725442\n",
      "Epoch: 3499 cost = 0.017831924\n",
      "Validation Loss: 0.067769736\n",
      "Epoch: 3500 cost = 0.017830667\n",
      "Validation Loss: 0.0457997\n",
      "Epoch: 3501 cost = 0.017829751\n",
      "Validation Loss: 0.03179651\n",
      "Epoch: 3502 cost = 0.017828902\n",
      "Validation Loss: 0.02369863\n",
      "Epoch: 3503 cost = 0.017828252\n",
      "Validation Loss: 0.043467674\n",
      "Epoch: 3504 cost = 0.017827458\n",
      "Validation Loss: 0.04592673\n",
      "Epoch: 3505 cost = 0.017826928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0494314\n",
      "Epoch: 3506 cost = 0.017825932\n",
      "Validation Loss: 0.054629553\n",
      "Epoch: 3507 cost = 0.017825029\n",
      "Validation Loss: 0.060857162\n",
      "Epoch: 3508 cost = 0.017824000\n",
      "Validation Loss: 0.043721635\n",
      "Epoch: 3509 cost = 0.017822662\n",
      "Validation Loss: 0.042295385\n",
      "Epoch: 3510 cost = 0.017821994\n",
      "Validation Loss: 0.04013211\n",
      "Epoch: 3511 cost = 0.017821528\n",
      "Validation Loss: 0.02774724\n",
      "Epoch: 3512 cost = 0.017820336\n",
      "Validation Loss: 0.034499835\n",
      "Epoch: 3513 cost = 0.017819517\n",
      "Validation Loss: 0.047662567\n",
      "Epoch: 3514 cost = 0.017818694\n",
      "Validation Loss: 0.03961574\n",
      "Epoch: 3515 cost = 0.017817564\n",
      "Validation Loss: 0.04191269\n",
      "Epoch: 3516 cost = 0.017817302\n",
      "Validation Loss: 0.057427183\n",
      "Epoch: 3517 cost = 0.017816055\n",
      "Validation Loss: 0.06536544\n",
      "Epoch: 3518 cost = 0.017815429\n",
      "Validation Loss: 0.06351709\n",
      "Epoch: 3519 cost = 0.017814276\n",
      "Validation Loss: 0.048093732\n",
      "Epoch: 3520 cost = 0.017813311\n",
      "Validation Loss: 0.039163258\n",
      "Epoch: 3521 cost = 0.017812980\n",
      "Validation Loss: 0.041304473\n",
      "Epoch: 3522 cost = 0.017811634\n",
      "Validation Loss: 0.042081296\n",
      "Epoch: 3523 cost = 0.017810976\n",
      "Validation Loss: 0.03234351\n",
      "Epoch: 3524 cost = 0.017809914\n",
      "Validation Loss: 0.040675275\n",
      "Epoch: 3525 cost = 0.017808983\n",
      "Validation Loss: 0.038304854\n",
      "Epoch: 3526 cost = 0.017808367\n",
      "Validation Loss: 0.049965568\n",
      "Epoch: 3527 cost = 0.017807170\n",
      "Validation Loss: 0.06911771\n",
      "Epoch: 3528 cost = 0.017806623\n",
      "Validation Loss: 0.09330009\n",
      "Epoch: 3529 cost = 0.017806026\n",
      "Validation Loss: 0.08618372\n",
      "Epoch: 3530 cost = 0.017805097\n",
      "Validation Loss: 0.08246434\n",
      "Epoch: 3531 cost = 0.017803905\n",
      "Validation Loss: 0.07516054\n",
      "Epoch: 3532 cost = 0.017803479\n",
      "Validation Loss: 0.06345172\n",
      "Epoch: 3533 cost = 0.017802143\n",
      "Validation Loss: 0.037811697\n",
      "Epoch: 3534 cost = 0.017801707\n",
      "Validation Loss: 0.03355725\n",
      "Epoch: 3535 cost = 0.017800285\n",
      "Validation Loss: 0.037689626\n",
      "Epoch: 3536 cost = 0.017799626\n",
      "Validation Loss: 0.032423463\n",
      "Epoch: 3537 cost = 0.017798913\n",
      "Validation Loss: 0.040952742\n",
      "Epoch: 3538 cost = 0.017798150\n",
      "Validation Loss: 0.03379811\n",
      "Epoch: 3539 cost = 0.017796876\n",
      "Validation Loss: 0.049221985\n",
      "Epoch: 3540 cost = 0.017796301\n",
      "Validation Loss: 0.054556\n",
      "Epoch: 3541 cost = 0.017795696\n",
      "Validation Loss: 0.046855934\n",
      "Epoch: 3542 cost = 0.017794498\n",
      "Validation Loss: 0.042580027\n",
      "Epoch: 3543 cost = 0.017793741\n",
      "Validation Loss: 0.042476572\n",
      "Epoch: 3544 cost = 0.017792914\n",
      "Validation Loss: 0.039673977\n",
      "Epoch: 3545 cost = 0.017791932\n",
      "Validation Loss: 0.04064288\n",
      "Epoch: 3546 cost = 0.017790869\n",
      "Validation Loss: 0.03197064\n",
      "Epoch: 3547 cost = 0.017790499\n",
      "Validation Loss: 0.03539583\n",
      "Epoch: 3548 cost = 0.017789490\n",
      "Validation Loss: 0.038836673\n",
      "Epoch: 3549 cost = 0.017788817\n",
      "Validation Loss: 0.03668117\n",
      "Epoch: 3550 cost = 0.017787771\n",
      "Validation Loss: 0.025850631\n",
      "Epoch: 3551 cost = 0.017786931\n",
      "Validation Loss: 0.025818964\n",
      "Epoch: 3552 cost = 0.017786111\n",
      "Validation Loss: 0.035801917\n",
      "Epoch: 3553 cost = 0.017784857\n",
      "Validation Loss: 0.045525275\n",
      "Epoch: 3554 cost = 0.017784052\n",
      "Validation Loss: 0.049431644\n",
      "Epoch: 3555 cost = 0.017783529\n",
      "Validation Loss: 0.04123912\n",
      "Epoch: 3556 cost = 0.017782812\n",
      "Validation Loss: 0.0420619\n",
      "Epoch: 3557 cost = 0.017782115\n",
      "Validation Loss: 0.039231785\n",
      "Epoch: 3558 cost = 0.017780876\n",
      "Validation Loss: 0.04848619\n",
      "Epoch: 3559 cost = 0.017780237\n",
      "Validation Loss: 0.057930775\n",
      "Epoch: 3560 cost = 0.017779375\n",
      "Validation Loss: 0.05524333\n",
      "Epoch: 3561 cost = 0.017778290\n",
      "Validation Loss: 0.057514407\n",
      "Epoch: 3562 cost = 0.017777816\n",
      "Validation Loss: 0.05443982\n",
      "Epoch: 3563 cost = 0.017776875\n",
      "Validation Loss: 0.046670195\n",
      "Epoch: 3564 cost = 0.017775782\n",
      "Validation Loss: 0.04036527\n",
      "Epoch: 3565 cost = 0.017775746\n",
      "Validation Loss: 0.024546552\n",
      "Epoch: 3566 cost = 0.017774688\n",
      "Validation Loss: 0.02479418\n",
      "Epoch: 3567 cost = 0.017773575\n",
      "Validation Loss: 0.031606406\n",
      "Epoch: 3568 cost = 0.017772959\n",
      "Validation Loss: 0.035466485\n",
      "Epoch: 3569 cost = 0.017771420\n",
      "Validation Loss: 0.02748762\n",
      "Epoch: 3570 cost = 0.017770919\n",
      "Validation Loss: 0.03256924\n",
      "Epoch: 3571 cost = 0.017770267\n",
      "Validation Loss: 0.03949626\n",
      "Epoch: 3572 cost = 0.017769474\n",
      "Validation Loss: 0.0367915\n",
      "Epoch: 3573 cost = 0.017768193\n",
      "Validation Loss: 0.048962165\n",
      "Epoch: 3574 cost = 0.017767547\n",
      "Validation Loss: 0.063612215\n",
      "Epoch: 3575 cost = 0.017767212\n",
      "Validation Loss: 0.049145624\n",
      "Epoch: 3576 cost = 0.017766330\n",
      "Validation Loss: 0.039837558\n",
      "Epoch: 3577 cost = 0.017765154\n",
      "Validation Loss: 0.034170784\n",
      "Epoch: 3578 cost = 0.017764108\n",
      "Validation Loss: 0.049456492\n",
      "Epoch: 3579 cost = 0.017763754\n",
      "Validation Loss: 0.048789196\n",
      "Epoch: 3580 cost = 0.017762901\n",
      "Validation Loss: 0.048004128\n",
      "Epoch: 3581 cost = 0.017761930\n",
      "Validation Loss: 0.05399592\n",
      "Epoch: 3582 cost = 0.017760859\n",
      "Validation Loss: 0.0509134\n",
      "Epoch: 3583 cost = 0.017760406\n",
      "Validation Loss: 0.04450359\n",
      "Epoch: 3584 cost = 0.017759561\n",
      "Validation Loss: 0.05974427\n",
      "Epoch: 3585 cost = 0.017758893\n",
      "Validation Loss: 0.040677417\n",
      "Epoch: 3586 cost = 0.017757596\n",
      "Validation Loss: 0.029971031\n",
      "Epoch: 3587 cost = 0.017757025\n",
      "Validation Loss: 0.041805375\n",
      "Epoch: 3588 cost = 0.017756477\n",
      "Validation Loss: 0.04955159\n",
      "Epoch: 3589 cost = 0.017755250\n",
      "Validation Loss: 0.07278405\n",
      "Epoch: 3590 cost = 0.017754645\n",
      "Validation Loss: 0.067210555\n",
      "Epoch: 3591 cost = 0.017753591\n",
      "Validation Loss: 0.05702965\n",
      "Epoch: 3592 cost = 0.017752753\n",
      "Validation Loss: 0.058634866\n",
      "Epoch: 3593 cost = 0.017752257\n",
      "Validation Loss: 0.04515863\n",
      "Epoch: 3594 cost = 0.017751213\n",
      "Validation Loss: 0.039997887\n",
      "Epoch: 3595 cost = 0.017750390\n",
      "Validation Loss: 0.04961384\n",
      "Epoch: 3596 cost = 0.017749641\n",
      "Validation Loss: 0.047315788\n",
      "Epoch: 3597 cost = 0.017748688\n",
      "Validation Loss: 0.03794747\n",
      "Epoch: 3598 cost = 0.017747762\n",
      "Validation Loss: 0.040712148\n",
      "Epoch: 3599 cost = 0.017747193\n",
      "Validation Loss: 0.03752904\n",
      "Epoch: 3600 cost = 0.017746402\n",
      "Validation Loss: 0.039398693\n",
      "Epoch: 3601 cost = 0.017745412\n",
      "Validation Loss: 0.041102238\n",
      "Epoch: 3602 cost = 0.017744645\n",
      "Validation Loss: 0.04092648\n",
      "Epoch: 3603 cost = 0.017743889\n",
      "Validation Loss: 0.044277582\n",
      "Epoch: 3604 cost = 0.017742869\n",
      "Validation Loss: 0.037148576\n",
      "Epoch: 3605 cost = 0.017742268\n",
      "Validation Loss: 0.038601883\n",
      "Epoch: 3606 cost = 0.017741125\n",
      "Validation Loss: 0.03432712\n",
      "Epoch: 3607 cost = 0.017740544\n",
      "Validation Loss: 0.04117295\n",
      "Epoch: 3608 cost = 0.017739980\n",
      "Validation Loss: 0.03818387\n",
      "Epoch: 3609 cost = 0.017738869\n",
      "Validation Loss: 0.039546166\n",
      "Epoch: 3610 cost = 0.017738320\n",
      "Validation Loss: 0.039665986\n",
      "Epoch: 3611 cost = 0.017737412\n",
      "Validation Loss: 0.039490536\n",
      "Epoch: 3612 cost = 0.017736395\n",
      "Validation Loss: 0.038992155\n",
      "Epoch: 3613 cost = 0.017735609\n",
      "Validation Loss: 0.031705335\n",
      "Epoch: 3614 cost = 0.017734662\n",
      "Validation Loss: 0.040416095\n",
      "Epoch: 3615 cost = 0.017733651\n",
      "Validation Loss: 0.02916117\n",
      "Epoch: 3616 cost = 0.017733240\n",
      "Validation Loss: 0.062151656\n",
      "Epoch: 3617 cost = 0.017732415\n",
      "Validation Loss: 0.055521335\n",
      "Epoch: 3618 cost = 0.017731923\n",
      "Validation Loss: 0.04931682\n",
      "Epoch: 3619 cost = 0.017730639\n",
      "Validation Loss: 0.045573305\n",
      "Epoch: 3620 cost = 0.017730170\n",
      "Validation Loss: 0.049043756\n",
      "Epoch: 3621 cost = 0.017729137\n",
      "Validation Loss: 0.05361018\n",
      "Epoch: 3622 cost = 0.017728293\n",
      "Validation Loss: 0.054979343\n",
      "Epoch: 3623 cost = 0.017727045\n",
      "Validation Loss: 0.05893265\n",
      "Epoch: 3624 cost = 0.017726277\n",
      "Validation Loss: 0.063729525\n",
      "Epoch: 3625 cost = 0.017725899\n",
      "Validation Loss: 0.0557126\n",
      "Epoch: 3626 cost = 0.017725040\n",
      "Validation Loss: 0.044862524\n",
      "Epoch: 3627 cost = 0.017724755\n",
      "Validation Loss: 0.039567642\n",
      "Epoch: 3628 cost = 0.017724039\n",
      "Validation Loss: 0.035341777\n",
      "Epoch: 3629 cost = 0.017722767\n",
      "Validation Loss: 0.033355948\n",
      "Epoch: 3630 cost = 0.017722176\n",
      "Validation Loss: 0.0534948\n",
      "Epoch: 3631 cost = 0.017721429\n",
      "Validation Loss: 0.03498302\n",
      "Epoch: 3632 cost = 0.017720520\n",
      "Validation Loss: 0.03612698\n",
      "Epoch: 3633 cost = 0.017719660\n",
      "Validation Loss: 0.037251383\n",
      "Epoch: 3634 cost = 0.017718919\n",
      "Validation Loss: 0.04278256\n",
      "Epoch: 3635 cost = 0.017718182\n",
      "Validation Loss: 0.051621202\n",
      "Epoch: 3636 cost = 0.017716768\n",
      "Validation Loss: 0.05387655\n",
      "Epoch: 3637 cost = 0.017716765\n",
      "Validation Loss: 0.040614583\n",
      "Epoch: 3638 cost = 0.017715560\n",
      "Validation Loss: 0.029008884\n",
      "Epoch: 3639 cost = 0.017714360\n",
      "Validation Loss: 0.029978452\n",
      "Epoch: 3640 cost = 0.017714004\n",
      "Validation Loss: 0.032426275\n",
      "Epoch: 3641 cost = 0.017713433\n",
      "Validation Loss: 0.02470877\n",
      "Epoch: 3642 cost = 0.017712610\n",
      "Validation Loss: 0.042112585\n",
      "Epoch: 3643 cost = 0.017711516\n",
      "Validation Loss: 0.060521923\n",
      "Epoch: 3644 cost = 0.017710595\n",
      "Validation Loss: 0.070236094\n",
      "Epoch: 3645 cost = 0.017710383\n",
      "Validation Loss: 0.072267346\n",
      "Epoch: 3646 cost = 0.017709499\n",
      "Validation Loss: 0.06478117\n",
      "Epoch: 3647 cost = 0.017708394\n",
      "Validation Loss: 0.049730055\n",
      "Epoch: 3648 cost = 0.017707798\n",
      "Validation Loss: 0.029472226\n",
      "Epoch: 3649 cost = 0.017707106\n",
      "Validation Loss: 0.041222576\n",
      "Epoch: 3650 cost = 0.017706288\n",
      "Validation Loss: 0.05128948\n",
      "Epoch: 3651 cost = 0.017705502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.041668814\n",
      "Epoch: 3652 cost = 0.017704094\n",
      "Validation Loss: 0.03206318\n",
      "Epoch: 3653 cost = 0.017703559\n",
      "Validation Loss: 0.034409016\n",
      "Epoch: 3654 cost = 0.017702838\n",
      "Validation Loss: 0.02945395\n",
      "Epoch: 3655 cost = 0.017701752\n",
      "Validation Loss: 0.033570036\n",
      "Epoch: 3656 cost = 0.017701557\n",
      "Validation Loss: 0.056464065\n",
      "Epoch: 3657 cost = 0.017700843\n",
      "Validation Loss: 0.056479666\n",
      "Epoch: 3658 cost = 0.017699827\n",
      "Validation Loss: 0.042516652\n",
      "Epoch: 3659 cost = 0.017699153\n",
      "Validation Loss: 0.032845072\n",
      "Epoch: 3660 cost = 0.017698629\n",
      "Validation Loss: 0.028023157\n",
      "Epoch: 3661 cost = 0.017697111\n",
      "Validation Loss: 0.028943451\n",
      "Epoch: 3662 cost = 0.017696684\n",
      "Validation Loss: 0.024124457\n",
      "Epoch: 3663 cost = 0.017695917\n",
      "Validation Loss: 0.029855207\n",
      "Epoch: 3664 cost = 0.017695274\n",
      "Validation Loss: 0.03240616\n",
      "Epoch: 3665 cost = 0.017694249\n",
      "Validation Loss: 0.04567478\n",
      "Epoch: 3666 cost = 0.017693610\n",
      "Validation Loss: 0.048344556\n",
      "Epoch: 3667 cost = 0.017693102\n",
      "Validation Loss: 0.023430923\n",
      "Epoch: 3668 cost = 0.017691843\n",
      "Validation Loss: 0.029135823\n",
      "Epoch: 3669 cost = 0.017691394\n",
      "Validation Loss: 0.027634729\n",
      "Epoch: 3670 cost = 0.017690351\n",
      "Validation Loss: 0.029799063\n",
      "Epoch: 3671 cost = 0.017689162\n",
      "Validation Loss: 0.04802715\n",
      "Epoch: 3672 cost = 0.017688800\n",
      "Validation Loss: 0.070390455\n",
      "Epoch: 3673 cost = 0.017687771\n",
      "Validation Loss: 0.0743983\n",
      "Epoch: 3674 cost = 0.017687144\n",
      "Validation Loss: 0.06768275\n",
      "Epoch: 3675 cost = 0.017686440\n",
      "Validation Loss: 0.06770085\n",
      "Epoch: 3676 cost = 0.017685589\n",
      "Validation Loss: 0.061355513\n",
      "Epoch: 3677 cost = 0.017685064\n",
      "Validation Loss: 0.05573414\n",
      "Epoch: 3678 cost = 0.017684415\n",
      "Validation Loss: 0.044899378\n",
      "Epoch: 3679 cost = 0.017683008\n",
      "Validation Loss: 0.057829782\n",
      "Epoch: 3680 cost = 0.017682470\n",
      "Validation Loss: 0.05240033\n",
      "Epoch: 3681 cost = 0.017681945\n",
      "Validation Loss: 0.043641236\n",
      "Epoch: 3682 cost = 0.017681277\n",
      "Validation Loss: 0.04370768\n",
      "Epoch: 3683 cost = 0.017680128\n",
      "Validation Loss: 0.05565257\n",
      "Epoch: 3684 cost = 0.017679668\n",
      "Validation Loss: 0.058005843\n",
      "Epoch: 3685 cost = 0.017678665\n",
      "Validation Loss: 0.044518977\n",
      "Epoch: 3686 cost = 0.017677912\n",
      "Validation Loss: 0.045858704\n",
      "Epoch: 3687 cost = 0.017677140\n",
      "Validation Loss: 0.053514674\n",
      "Epoch: 3688 cost = 0.017676407\n",
      "Validation Loss: 0.04797779\n",
      "Epoch: 3689 cost = 0.017675605\n",
      "Validation Loss: 0.050565097\n",
      "Epoch: 3690 cost = 0.017674607\n",
      "Validation Loss: 0.0465396\n",
      "Epoch: 3691 cost = 0.017673997\n",
      "Validation Loss: 0.04520402\n",
      "Epoch: 3692 cost = 0.017673264\n",
      "Validation Loss: 0.055035226\n",
      "Epoch: 3693 cost = 0.017672496\n",
      "Validation Loss: 0.044468552\n",
      "Epoch: 3694 cost = 0.017672014\n",
      "Validation Loss: 0.039490964\n",
      "Epoch: 3695 cost = 0.017671337\n",
      "Validation Loss: 0.03534899\n",
      "Epoch: 3696 cost = 0.017669942\n",
      "Validation Loss: 0.027214367\n",
      "Epoch: 3697 cost = 0.017669692\n",
      "Validation Loss: 0.025438948\n",
      "Epoch: 3698 cost = 0.017669145\n",
      "Validation Loss: 0.036117487\n",
      "Epoch: 3699 cost = 0.017668198\n",
      "Validation Loss: 0.036128838\n",
      "Epoch: 3700 cost = 0.017667334\n",
      "Validation Loss: 0.0335429\n",
      "Epoch: 3701 cost = 0.017666670\n",
      "Validation Loss: 0.035802383\n",
      "Epoch: 3702 cost = 0.017665883\n",
      "Validation Loss: 0.032462824\n",
      "Epoch: 3703 cost = 0.017664705\n",
      "Validation Loss: 0.035433922\n",
      "Epoch: 3704 cost = 0.017664045\n",
      "Validation Loss: 0.046105906\n",
      "Epoch: 3705 cost = 0.017663624\n",
      "Validation Loss: 0.0610306\n",
      "Epoch: 3706 cost = 0.017662364\n",
      "Validation Loss: 0.056502312\n",
      "Epoch: 3707 cost = 0.017662027\n",
      "Validation Loss: 0.048708223\n",
      "Epoch: 3708 cost = 0.017661118\n",
      "Validation Loss: 0.043850146\n",
      "Epoch: 3709 cost = 0.017660333\n",
      "Validation Loss: 0.051185913\n",
      "Epoch: 3710 cost = 0.017659811\n",
      "Validation Loss: 0.037148703\n",
      "Epoch: 3711 cost = 0.017659439\n",
      "Validation Loss: 0.034139447\n",
      "Epoch: 3712 cost = 0.017658487\n",
      "Validation Loss: 0.04288402\n",
      "Epoch: 3713 cost = 0.017657528\n",
      "Validation Loss: 0.042019263\n",
      "Epoch: 3714 cost = 0.017656456\n",
      "Validation Loss: 0.030921565\n",
      "Epoch: 3715 cost = 0.017655737\n",
      "Validation Loss: 0.0349534\n",
      "Epoch: 3716 cost = 0.017654906\n",
      "Validation Loss: 0.044140298\n",
      "Epoch: 3717 cost = 0.017654048\n",
      "Validation Loss: 0.03591236\n",
      "Epoch: 3718 cost = 0.017653522\n",
      "Validation Loss: 0.051510654\n",
      "Epoch: 3719 cost = 0.017653182\n",
      "Validation Loss: 0.05923465\n",
      "Epoch: 3720 cost = 0.017651920\n",
      "Validation Loss: 0.048710667\n",
      "Epoch: 3721 cost = 0.017651893\n",
      "Validation Loss: 0.0394684\n",
      "Epoch: 3722 cost = 0.017650835\n",
      "Validation Loss: 0.03832302\n",
      "Epoch: 3723 cost = 0.017649786\n",
      "Validation Loss: 0.046141326\n",
      "Epoch: 3724 cost = 0.017649240\n",
      "Validation Loss: 0.044237312\n",
      "Epoch: 3725 cost = 0.017648269\n",
      "Validation Loss: 0.05186781\n",
      "Epoch: 3726 cost = 0.017647730\n",
      "Validation Loss: 0.04154357\n",
      "Epoch: 3727 cost = 0.017646794\n",
      "Validation Loss: 0.02604912\n",
      "Epoch: 3728 cost = 0.017646161\n",
      "Validation Loss: 0.031659745\n",
      "Epoch: 3729 cost = 0.017645440\n",
      "Validation Loss: 0.036396727\n",
      "Epoch: 3730 cost = 0.017644576\n",
      "Validation Loss: 0.045308225\n",
      "Epoch: 3731 cost = 0.017644158\n",
      "Validation Loss: 0.040806502\n",
      "Epoch: 3732 cost = 0.017643419\n",
      "Validation Loss: 0.033701736\n",
      "Epoch: 3733 cost = 0.017642549\n",
      "Validation Loss: 0.030004138\n",
      "Epoch: 3734 cost = 0.017641886\n",
      "Validation Loss: 0.028622052\n",
      "Epoch: 3735 cost = 0.017641030\n",
      "Validation Loss: 0.032170653\n",
      "Epoch: 3736 cost = 0.017640262\n",
      "Validation Loss: 0.05261277\n",
      "Epoch: 3737 cost = 0.017639069\n",
      "Validation Loss: 0.04135269\n",
      "Epoch: 3738 cost = 0.017638796\n",
      "Validation Loss: 0.04254868\n",
      "Epoch: 3739 cost = 0.017638257\n",
      "Validation Loss: 0.04111892\n",
      "Epoch: 3740 cost = 0.017637501\n",
      "Validation Loss: 0.025221996\n",
      "Epoch: 3741 cost = 0.017636189\n",
      "Validation Loss: 0.026655419\n",
      "Epoch: 3742 cost = 0.017635721\n",
      "Validation Loss: 0.04566651\n",
      "Epoch: 3743 cost = 0.017634682\n",
      "Validation Loss: 0.0554448\n",
      "Epoch: 3744 cost = 0.017634193\n",
      "Validation Loss: 0.057128944\n",
      "Epoch: 3745 cost = 0.017633664\n",
      "Validation Loss: 0.061260354\n",
      "Epoch: 3746 cost = 0.017632652\n",
      "Validation Loss: 0.053554267\n",
      "Epoch: 3747 cost = 0.017631842\n",
      "Validation Loss: 0.033730723\n",
      "Epoch: 3748 cost = 0.017631663\n",
      "Validation Loss: 0.029017743\n",
      "Epoch: 3749 cost = 0.017630729\n",
      "Validation Loss: 0.031067966\n",
      "Epoch: 3750 cost = 0.017630042\n",
      "Validation Loss: 0.043156244\n",
      "Epoch: 3751 cost = 0.017629241\n",
      "Validation Loss: 0.042490724\n",
      "Epoch: 3752 cost = 0.017628564\n",
      "Validation Loss: 0.04587584\n",
      "Epoch: 3753 cost = 0.017627368\n",
      "Validation Loss: 0.04331941\n",
      "Epoch: 3754 cost = 0.017626444\n",
      "Validation Loss: 0.039875273\n",
      "Epoch: 3755 cost = 0.017626106\n",
      "Validation Loss: 0.020703498\n",
      "Epoch: 3756 cost = 0.017625399\n",
      "Validation Loss: 0.028126638\n",
      "Epoch: 3757 cost = 0.017624725\n",
      "Validation Loss: 0.029787147\n",
      "Epoch: 3758 cost = 0.017624001\n",
      "Validation Loss: 0.033497293\n",
      "Epoch: 3759 cost = 0.017623214\n",
      "Validation Loss: 0.033429217\n",
      "Epoch: 3760 cost = 0.017622598\n",
      "Validation Loss: 0.036294535\n",
      "Epoch: 3761 cost = 0.017621495\n",
      "Validation Loss: 0.038945317\n",
      "Epoch: 3762 cost = 0.017621130\n",
      "Validation Loss: 0.03527127\n",
      "Epoch: 3763 cost = 0.017620198\n",
      "Validation Loss: 0.04029138\n",
      "Epoch: 3764 cost = 0.017619401\n",
      "Validation Loss: 0.040926017\n",
      "Epoch: 3765 cost = 0.017618742\n",
      "Validation Loss: 0.033405762\n",
      "Epoch: 3766 cost = 0.017618536\n",
      "Validation Loss: 0.028184803\n",
      "Epoch: 3767 cost = 0.017617260\n",
      "Validation Loss: 0.028641405\n",
      "Epoch: 3768 cost = 0.017616753\n",
      "Validation Loss: 0.042510103\n",
      "Epoch: 3769 cost = 0.017616285\n",
      "Validation Loss: 0.06572081\n",
      "Epoch: 3770 cost = 0.017615021\n",
      "Validation Loss: 0.058967486\n",
      "Epoch: 3771 cost = 0.017614616\n",
      "Validation Loss: 0.031840943\n",
      "Epoch: 3772 cost = 0.017613795\n",
      "Validation Loss: 0.028430004\n",
      "Epoch: 3773 cost = 0.017612844\n",
      "Validation Loss: 0.037075642\n",
      "Epoch: 3774 cost = 0.017611778\n",
      "Validation Loss: 0.03579975\n",
      "Epoch: 3775 cost = 0.017611674\n",
      "Validation Loss: 0.028241182\n",
      "Epoch: 3776 cost = 0.017610747\n",
      "Validation Loss: 0.02326234\n",
      "Epoch: 3777 cost = 0.017609908\n",
      "Validation Loss: 0.04377875\n",
      "Epoch: 3778 cost = 0.017609098\n",
      "Validation Loss: 0.048326775\n",
      "Epoch: 3779 cost = 0.017608935\n",
      "Validation Loss: 0.047983207\n",
      "Epoch: 3780 cost = 0.017607681\n",
      "Validation Loss: 0.054233093\n",
      "Epoch: 3781 cost = 0.017607515\n",
      "Validation Loss: 0.047415152\n",
      "Epoch: 3782 cost = 0.017606656\n",
      "Validation Loss: 0.030897336\n",
      "Epoch: 3783 cost = 0.017606025\n",
      "Validation Loss: 0.021109685\n",
      "Epoch: 3784 cost = 0.017604800\n",
      "Validation Loss: 0.04144315\n",
      "Epoch: 3785 cost = 0.017604283\n",
      "Validation Loss: 0.036681358\n",
      "Epoch: 3786 cost = 0.017604201\n",
      "Validation Loss: 0.052866332\n",
      "Epoch: 3787 cost = 0.017602906\n",
      "Validation Loss: 0.04192502\n",
      "Epoch: 3788 cost = 0.017602038\n",
      "Validation Loss: 0.0328651\n",
      "Epoch: 3789 cost = 0.017601249\n",
      "Validation Loss: 0.026664626\n",
      "Epoch: 3790 cost = 0.017600927\n",
      "Validation Loss: 0.037832346\n",
      "Epoch: 3791 cost = 0.017600281\n",
      "Validation Loss: 0.045311455\n",
      "Epoch: 3792 cost = 0.017599163\n",
      "Validation Loss: 0.038233694\n",
      "Epoch: 3793 cost = 0.017598485\n",
      "Validation Loss: 0.039387457\n",
      "Epoch: 3794 cost = 0.017597644\n",
      "Validation Loss: 0.03555852\n",
      "Epoch: 3795 cost = 0.017596606\n",
      "Validation Loss: 0.034708176\n",
      "Epoch: 3796 cost = 0.017596037\n",
      "Validation Loss: 0.03828707\n",
      "Epoch: 3797 cost = 0.017595740\n",
      "Validation Loss: 0.03664935\n",
      "Epoch: 3798 cost = 0.017595105\n",
      "Validation Loss: 0.04186064\n",
      "Epoch: 3799 cost = 0.017594558\n",
      "Validation Loss: 0.03679922\n",
      "Epoch: 3800 cost = 0.017593155\n",
      "Validation Loss: 0.03065282\n",
      "Epoch: 3801 cost = 0.017592769\n",
      "Validation Loss: 0.027695617\n",
      "Epoch: 3802 cost = 0.017592118\n",
      "Validation Loss: 0.03426077\n",
      "Epoch: 3803 cost = 0.017591333\n",
      "Validation Loss: 0.027265768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3804 cost = 0.017590708\n",
      "Validation Loss: 0.057804063\n",
      "Epoch: 3805 cost = 0.017590135\n",
      "Validation Loss: 0.056171436\n",
      "Epoch: 3806 cost = 0.017589313\n",
      "Validation Loss: 0.0533518\n",
      "Epoch: 3807 cost = 0.017588929\n",
      "Validation Loss: 0.042025004\n",
      "Epoch: 3808 cost = 0.017587875\n",
      "Validation Loss: 0.03598434\n",
      "Epoch: 3809 cost = 0.017587294\n",
      "Validation Loss: 0.037852068\n",
      "Epoch: 3810 cost = 0.017587028\n",
      "Validation Loss: 0.052970193\n",
      "Epoch: 3811 cost = 0.017585427\n",
      "Validation Loss: 0.046766255\n",
      "Epoch: 3812 cost = 0.017585314\n",
      "Validation Loss: 0.030866817\n",
      "Epoch: 3813 cost = 0.017584228\n",
      "Validation Loss: 0.028550737\n",
      "Epoch: 3814 cost = 0.017583500\n",
      "Validation Loss: 0.043198686\n",
      "Epoch: 3815 cost = 0.017583096\n",
      "Validation Loss: 0.07474114\n",
      "Epoch: 3816 cost = 0.017581996\n",
      "Validation Loss: 0.07852995\n",
      "Epoch: 3817 cost = 0.017581270\n",
      "Validation Loss: 0.07719956\n",
      "Epoch: 3818 cost = 0.017580912\n",
      "Validation Loss: 0.07541068\n",
      "Epoch: 3819 cost = 0.017580215\n",
      "Validation Loss: 0.06893765\n",
      "Epoch: 3820 cost = 0.017579602\n",
      "Validation Loss: 0.06698135\n",
      "Epoch: 3821 cost = 0.017578353\n",
      "Validation Loss: 0.05787365\n",
      "Epoch: 3822 cost = 0.017577882\n",
      "Validation Loss: 0.048273206\n",
      "Epoch: 3823 cost = 0.017577086\n",
      "Validation Loss: 0.04229401\n",
      "Epoch: 3824 cost = 0.017576381\n",
      "Validation Loss: 0.045701824\n",
      "Epoch: 3825 cost = 0.017575408\n",
      "Validation Loss: 0.047505233\n",
      "Epoch: 3826 cost = 0.017575347\n",
      "Validation Loss: 0.045687784\n",
      "Epoch: 3827 cost = 0.017574245\n",
      "Validation Loss: 0.03203523\n",
      "Epoch: 3828 cost = 0.017573787\n",
      "Validation Loss: 0.056032963\n",
      "Epoch: 3829 cost = 0.017573072\n",
      "Validation Loss: 0.060560573\n",
      "Epoch: 3830 cost = 0.017572948\n",
      "Validation Loss: 0.05228975\n",
      "Epoch: 3831 cost = 0.017571949\n",
      "Validation Loss: 0.056167882\n",
      "Epoch: 3832 cost = 0.017570926\n",
      "Validation Loss: 0.0654602\n",
      "Epoch: 3833 cost = 0.017570107\n",
      "Validation Loss: 0.061940975\n",
      "Epoch: 3834 cost = 0.017569182\n",
      "Validation Loss: 0.04033032\n",
      "Epoch: 3835 cost = 0.017568517\n",
      "Validation Loss: 0.054263152\n",
      "Epoch: 3836 cost = 0.017568351\n",
      "Validation Loss: 0.0638419\n",
      "Epoch: 3837 cost = 0.017567274\n",
      "Validation Loss: 0.05744114\n",
      "Epoch: 3838 cost = 0.017566547\n",
      "Validation Loss: 0.056444257\n",
      "Epoch: 3839 cost = 0.017566549\n",
      "Validation Loss: 0.05477933\n",
      "Epoch: 3840 cost = 0.017565068\n",
      "Validation Loss: 0.056193862\n",
      "Epoch: 3841 cost = 0.017565016\n",
      "Validation Loss: 0.04842515\n",
      "Epoch: 3842 cost = 0.017563690\n",
      "Validation Loss: 0.03196994\n",
      "Epoch: 3843 cost = 0.017563201\n",
      "Validation Loss: 0.048891693\n",
      "Epoch: 3844 cost = 0.017562545\n",
      "Validation Loss: 0.04492748\n",
      "Epoch: 3845 cost = 0.017561801\n",
      "Validation Loss: 0.05096488\n",
      "Epoch: 3846 cost = 0.017561139\n",
      "Validation Loss: 0.049294043\n",
      "Epoch: 3847 cost = 0.017560338\n",
      "Validation Loss: 0.05532861\n",
      "Epoch: 3848 cost = 0.017559776\n",
      "Validation Loss: 0.04722289\n",
      "Epoch: 3849 cost = 0.017559063\n",
      "Validation Loss: 0.05453154\n",
      "Epoch: 3850 cost = 0.017558468\n",
      "Validation Loss: 0.062486615\n",
      "Epoch: 3851 cost = 0.017557586\n",
      "Validation Loss: 0.07208687\n",
      "Epoch: 3852 cost = 0.017557150\n",
      "Validation Loss: 0.0752775\n",
      "Epoch: 3853 cost = 0.017555973\n",
      "Validation Loss: 0.082440175\n",
      "Epoch: 3854 cost = 0.017555672\n",
      "Validation Loss: 0.09251795\n",
      "Epoch: 3855 cost = 0.017555309\n",
      "Validation Loss: 0.09601687\n",
      "Epoch: 3856 cost = 0.017554810\n",
      "Validation Loss: 0.07753469\n",
      "Epoch: 3857 cost = 0.017553881\n",
      "Validation Loss: 0.06462548\n",
      "Epoch: 3858 cost = 0.017553181\n",
      "Validation Loss: 0.061336085\n",
      "Epoch: 3859 cost = 0.017552225\n",
      "Validation Loss: 0.060358264\n",
      "Epoch: 3860 cost = 0.017551321\n",
      "Validation Loss: 0.06503699\n",
      "Epoch: 3861 cost = 0.017550960\n",
      "Validation Loss: 0.06604412\n",
      "Epoch: 3862 cost = 0.017550122\n",
      "Validation Loss: 0.08452047\n",
      "Epoch: 3863 cost = 0.017549537\n",
      "Validation Loss: 0.068677485\n",
      "Epoch: 3864 cost = 0.017549086\n",
      "Validation Loss: 0.040384166\n",
      "Epoch: 3865 cost = 0.017548262\n",
      "Validation Loss: 0.0345732\n",
      "Epoch: 3866 cost = 0.017547588\n",
      "Validation Loss: 0.02729019\n",
      "Epoch: 3867 cost = 0.017546788\n",
      "Validation Loss: 0.034024533\n",
      "Epoch: 3868 cost = 0.017545993\n",
      "Validation Loss: 0.04219853\n",
      "Epoch: 3869 cost = 0.017545187\n",
      "Validation Loss: 0.0314842\n",
      "Epoch: 3870 cost = 0.017544482\n",
      "Validation Loss: 0.049464274\n",
      "Epoch: 3871 cost = 0.017543678\n",
      "Validation Loss: 0.04335448\n",
      "Epoch: 3872 cost = 0.017543293\n",
      "Validation Loss: 0.02927602\n",
      "Epoch: 3873 cost = 0.017542794\n",
      "Validation Loss: 0.038981255\n",
      "Epoch: 3874 cost = 0.017541816\n",
      "Validation Loss: 0.048074905\n",
      "Epoch: 3875 cost = 0.017541794\n",
      "Validation Loss: 0.0574561\n",
      "Epoch: 3876 cost = 0.017540722\n",
      "Validation Loss: 0.053772677\n",
      "Epoch: 3877 cost = 0.017539942\n",
      "Validation Loss: 0.05704582\n",
      "Epoch: 3878 cost = 0.017539327\n",
      "Validation Loss: 0.036274143\n",
      "Epoch: 3879 cost = 0.017538674\n",
      "Validation Loss: 0.03688154\n",
      "Epoch: 3880 cost = 0.017538187\n",
      "Validation Loss: 0.038671445\n",
      "Epoch: 3881 cost = 0.017537629\n",
      "Validation Loss: 0.040433273\n",
      "Epoch: 3882 cost = 0.017536614\n",
      "Validation Loss: 0.048754472\n",
      "Epoch: 3883 cost = 0.017535673\n",
      "Validation Loss: 0.043088265\n",
      "Epoch: 3884 cost = 0.017535421\n",
      "Validation Loss: 0.027946202\n",
      "Epoch: 3885 cost = 0.017534691\n",
      "Validation Loss: 0.026811438\n",
      "Epoch: 3886 cost = 0.017533910\n",
      "Validation Loss: 0.0277625\n",
      "Epoch: 3887 cost = 0.017533048\n",
      "Validation Loss: 0.02694947\n",
      "Epoch: 3888 cost = 0.017532318\n",
      "Validation Loss: 0.028772559\n",
      "Epoch: 3889 cost = 0.017531888\n",
      "Validation Loss: 0.043037042\n",
      "Epoch: 3890 cost = 0.017530830\n",
      "Validation Loss: 0.034777742\n",
      "Epoch: 3891 cost = 0.017530122\n",
      "Validation Loss: 0.02568351\n",
      "Epoch: 3892 cost = 0.017529530\n",
      "Validation Loss: 0.027510395\n",
      "Epoch: 3893 cost = 0.017528857\n",
      "Validation Loss: 0.052298084\n",
      "Epoch: 3894 cost = 0.017528128\n",
      "Validation Loss: 0.06741533\n",
      "Epoch: 3895 cost = 0.017527525\n",
      "Validation Loss: 0.055694584\n",
      "Epoch: 3896 cost = 0.017526880\n",
      "Validation Loss: 0.048768476\n",
      "Epoch: 3897 cost = 0.017526277\n",
      "Validation Loss: 0.045630682\n",
      "Epoch: 3898 cost = 0.017525611\n",
      "Validation Loss: 0.036802724\n",
      "Epoch: 3899 cost = 0.017524983\n",
      "Validation Loss: 0.032866277\n",
      "Epoch: 3900 cost = 0.017524315\n",
      "Validation Loss: 0.035456218\n",
      "Epoch: 3901 cost = 0.017523595\n",
      "Validation Loss: 0.039902847\n",
      "Epoch: 3902 cost = 0.017522922\n",
      "Validation Loss: 0.04955696\n",
      "Epoch: 3903 cost = 0.017522422\n",
      "Validation Loss: 0.057645362\n",
      "Epoch: 3904 cost = 0.017521669\n",
      "Validation Loss: 0.061564352\n",
      "Epoch: 3905 cost = 0.017521389\n",
      "Validation Loss: 0.050182886\n",
      "Epoch: 3906 cost = 0.017519950\n",
      "Validation Loss: 0.048824135\n",
      "Epoch: 3907 cost = 0.017519396\n",
      "Validation Loss: 0.043376982\n",
      "Epoch: 3908 cost = 0.017519292\n",
      "Validation Loss: 0.039763432\n",
      "Epoch: 3909 cost = 0.017518665\n",
      "Validation Loss: 0.040436354\n",
      "Epoch: 3910 cost = 0.017517385\n",
      "Validation Loss: 0.03597014\n",
      "Epoch: 3911 cost = 0.017517285\n",
      "Validation Loss: 0.036653213\n",
      "Epoch: 3912 cost = 0.017516428\n",
      "Validation Loss: 0.038661458\n",
      "Epoch: 3913 cost = 0.017515845\n",
      "Validation Loss: 0.045993634\n",
      "Epoch: 3914 cost = 0.017514752\n",
      "Validation Loss: 0.047679503\n",
      "Epoch: 3915 cost = 0.017514166\n",
      "Validation Loss: 0.06002439\n",
      "Epoch: 3916 cost = 0.017514024\n",
      "Validation Loss: 0.07202325\n",
      "Epoch: 3917 cost = 0.017512929\n",
      "Validation Loss: 0.060925703\n",
      "Epoch: 3918 cost = 0.017512941\n",
      "Validation Loss: 0.039869096\n",
      "Epoch: 3919 cost = 0.017512130\n",
      "Validation Loss: 0.03236277\n",
      "Epoch: 3920 cost = 0.017510914\n",
      "Validation Loss: 0.041998677\n",
      "Epoch: 3921 cost = 0.017510091\n",
      "Validation Loss: 0.04501444\n",
      "Epoch: 3922 cost = 0.017509437\n",
      "Validation Loss: 0.046953075\n",
      "Epoch: 3923 cost = 0.017508977\n",
      "Validation Loss: 0.056487847\n",
      "Epoch: 3924 cost = 0.017508497\n",
      "Validation Loss: 0.05204348\n",
      "Epoch: 3925 cost = 0.017507424\n",
      "Validation Loss: 0.048367042\n",
      "Epoch: 3926 cost = 0.017507540\n",
      "Validation Loss: 0.05496493\n",
      "Epoch: 3927 cost = 0.017506792\n",
      "Validation Loss: 0.04051619\n",
      "Epoch: 3928 cost = 0.017506056\n",
      "Validation Loss: 0.04092078\n",
      "Epoch: 3929 cost = 0.017505274\n",
      "Validation Loss: 0.048384886\n",
      "Epoch: 3930 cost = 0.017504494\n",
      "Validation Loss: 0.041190837\n",
      "Epoch: 3931 cost = 0.017503626\n",
      "Validation Loss: 0.03523829\n",
      "Epoch: 3932 cost = 0.017502789\n",
      "Validation Loss: 0.037881024\n",
      "Epoch: 3933 cost = 0.017502311\n",
      "Validation Loss: 0.036884196\n",
      "Epoch: 3934 cost = 0.017501627\n",
      "Validation Loss: 0.032835186\n",
      "Epoch: 3935 cost = 0.017501614\n",
      "Validation Loss: 0.042799667\n",
      "Epoch: 3936 cost = 0.017500516\n",
      "Validation Loss: 0.055053625\n",
      "Epoch: 3937 cost = 0.017499968\n",
      "Validation Loss: 0.063314185\n",
      "Epoch: 3938 cost = 0.017499114\n",
      "Validation Loss: 0.061351784\n",
      "Epoch: 3939 cost = 0.017498637\n",
      "Validation Loss: 0.04928782\n",
      "Epoch: 3940 cost = 0.017498005\n",
      "Validation Loss: 0.04564331\n",
      "Epoch: 3941 cost = 0.017497151\n",
      "Validation Loss: 0.052941356\n",
      "Epoch: 3942 cost = 0.017496549\n",
      "Validation Loss: 0.05404862\n",
      "Epoch: 3943 cost = 0.017495980\n",
      "Validation Loss: 0.05264844\n",
      "Epoch: 3944 cost = 0.017495500\n",
      "Validation Loss: 0.034977682\n",
      "Epoch: 3945 cost = 0.017494545\n",
      "Validation Loss: 0.045510154\n",
      "Epoch: 3946 cost = 0.017494317\n",
      "Validation Loss: 0.04335168\n",
      "Epoch: 3947 cost = 0.017493761\n",
      "Validation Loss: 0.032908637\n",
      "Epoch: 3948 cost = 0.017492501\n",
      "Validation Loss: 0.028043425\n",
      "Epoch: 3949 cost = 0.017491768\n",
      "Validation Loss: 0.032964397\n",
      "Epoch: 3950 cost = 0.017491350\n",
      "Validation Loss: 0.04366968\n",
      "Epoch: 3951 cost = 0.017490721\n",
      "Validation Loss: 0.037918143\n",
      "Epoch: 3952 cost = 0.017489709\n",
      "Validation Loss: 0.055687908\n",
      "Epoch: 3953 cost = 0.017489331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.07236772\n",
      "Epoch: 3954 cost = 0.017488646\n",
      "Validation Loss: 0.05611872\n",
      "Epoch: 3955 cost = 0.017487881\n",
      "Validation Loss: 0.053343553\n",
      "Epoch: 3956 cost = 0.017487354\n",
      "Validation Loss: 0.03002889\n",
      "Epoch: 3957 cost = 0.017486602\n",
      "Validation Loss: 0.0372024\n",
      "Epoch: 3958 cost = 0.017486018\n",
      "Validation Loss: 0.049392518\n",
      "Epoch: 3959 cost = 0.017485270\n",
      "Validation Loss: 0.068774305\n",
      "Epoch: 3960 cost = 0.017484922\n",
      "Validation Loss: 0.057217915\n",
      "Epoch: 3961 cost = 0.017484368\n",
      "Validation Loss: 0.050928343\n",
      "Epoch: 3962 cost = 0.017483751\n",
      "Validation Loss: 0.055319127\n",
      "Epoch: 3963 cost = 0.017483370\n",
      "Validation Loss: 0.044557467\n",
      "Epoch: 3964 cost = 0.017482433\n",
      "Validation Loss: 0.034214877\n",
      "Epoch: 3965 cost = 0.017481907\n",
      "Validation Loss: 0.033706173\n",
      "Epoch: 3966 cost = 0.017480528\n",
      "Validation Loss: 0.055694673\n",
      "Epoch: 3967 cost = 0.017480187\n",
      "Validation Loss: 0.058056194\n",
      "Epoch: 3968 cost = 0.017479973\n",
      "Validation Loss: 0.055808127\n",
      "Epoch: 3969 cost = 0.017478711\n",
      "Validation Loss: 0.051047698\n",
      "Epoch: 3970 cost = 0.017478559\n",
      "Validation Loss: 0.053581774\n",
      "Epoch: 3971 cost = 0.017477616\n",
      "Validation Loss: 0.043123797\n",
      "Epoch: 3972 cost = 0.017477416\n",
      "Validation Loss: 0.038908772\n",
      "Epoch: 3973 cost = 0.017476709\n",
      "Validation Loss: 0.028306875\n",
      "Epoch: 3974 cost = 0.017476118\n",
      "Validation Loss: 0.053366262\n",
      "Epoch: 3975 cost = 0.017475218\n",
      "Validation Loss: 0.05555836\n",
      "Epoch: 3976 cost = 0.017474577\n",
      "Validation Loss: 0.037516158\n",
      "Epoch: 3977 cost = 0.017473901\n",
      "Validation Loss: 0.054937176\n",
      "Epoch: 3978 cost = 0.017473746\n",
      "Validation Loss: 0.07794557\n",
      "Epoch: 3979 cost = 0.017472807\n",
      "Validation Loss: 0.074850835\n",
      "Epoch: 3980 cost = 0.017472048\n",
      "Validation Loss: 0.050494414\n",
      "Epoch: 3981 cost = 0.017471180\n",
      "Validation Loss: 0.042544123\n",
      "Epoch: 3982 cost = 0.017471110\n",
      "Validation Loss: 0.036399007\n",
      "Epoch: 3983 cost = 0.017469967\n",
      "Validation Loss: 0.048819575\n",
      "Epoch: 3984 cost = 0.017469899\n",
      "Validation Loss: 0.05886497\n",
      "Epoch: 3985 cost = 0.017469000\n",
      "Validation Loss: 0.050154272\n",
      "Epoch: 3986 cost = 0.017468369\n",
      "Validation Loss: 0.047824126\n",
      "Epoch: 3987 cost = 0.017468119\n",
      "Validation Loss: 0.037729096\n",
      "Epoch: 3988 cost = 0.017466803\n",
      "Validation Loss: 0.03870593\n",
      "Epoch: 3989 cost = 0.017466202\n",
      "Validation Loss: 0.040056285\n",
      "Epoch: 3990 cost = 0.017465802\n",
      "Validation Loss: 0.04720835\n",
      "Epoch: 3991 cost = 0.017465194\n",
      "Validation Loss: 0.0473126\n",
      "Epoch: 3992 cost = 0.017464628\n",
      "Validation Loss: 0.040639337\n",
      "Epoch: 3993 cost = 0.017464008\n",
      "Validation Loss: 0.05124059\n",
      "Epoch: 3994 cost = 0.017463405\n",
      "Validation Loss: 0.061467063\n",
      "Epoch: 3995 cost = 0.017462917\n",
      "Validation Loss: 0.049708907\n",
      "Epoch: 3996 cost = 0.017461844\n",
      "Validation Loss: 0.039482754\n",
      "Epoch: 3997 cost = 0.017461347\n",
      "Validation Loss: 0.052692313\n",
      "Epoch: 3998 cost = 0.017460805\n",
      "Validation Loss: 0.040103856\n",
      "Epoch: 3999 cost = 0.017460103\n",
      "Validation Loss: 0.038636573\n",
      "Epoch: 4000 cost = 0.017459370\n",
      "Validation Loss: 0.044476513\n",
      "Epoch: 4001 cost = 0.017458906\n",
      "Validation Loss: 0.052805636\n",
      "Epoch: 4002 cost = 0.017457950\n",
      "Validation Loss: 0.04148785\n",
      "Epoch: 4003 cost = 0.017457472\n",
      "Validation Loss: 0.045573566\n",
      "Epoch: 4004 cost = 0.017456711\n",
      "Validation Loss: 0.041828733\n",
      "Epoch: 4005 cost = 0.017455878\n",
      "Validation Loss: 0.034462534\n",
      "Epoch: 4006 cost = 0.017456106\n",
      "Validation Loss: 0.03186639\n",
      "Epoch: 4007 cost = 0.017455129\n",
      "Validation Loss: 0.02930884\n",
      "Epoch: 4008 cost = 0.017454121\n",
      "Validation Loss: 0.038362402\n",
      "Epoch: 4009 cost = 0.017454039\n",
      "Validation Loss: 0.057778448\n",
      "Epoch: 4010 cost = 0.017453467\n",
      "Validation Loss: 0.06068877\n",
      "Epoch: 4011 cost = 0.017453084\n",
      "Validation Loss: 0.06389483\n",
      "Epoch: 4012 cost = 0.017452037\n",
      "Validation Loss: 0.041363876\n",
      "Epoch: 4013 cost = 0.017451404\n",
      "Validation Loss: 0.034794737\n",
      "Epoch: 4014 cost = 0.017450741\n",
      "Validation Loss: 0.029220618\n",
      "Epoch: 4015 cost = 0.017450138\n",
      "Validation Loss: 0.039723046\n",
      "Epoch: 4016 cost = 0.017449548\n",
      "Validation Loss: 0.032117765\n",
      "Epoch: 4017 cost = 0.017448992\n",
      "Validation Loss: 0.046976276\n",
      "Epoch: 4018 cost = 0.017448152\n",
      "Validation Loss: 0.039403994\n",
      "Epoch: 4019 cost = 0.017447382\n",
      "Validation Loss: 0.046454277\n",
      "Epoch: 4020 cost = 0.017446942\n",
      "Validation Loss: 0.051949576\n",
      "Epoch: 4021 cost = 0.017446157\n",
      "Validation Loss: 0.038839467\n",
      "Epoch: 4022 cost = 0.017445332\n",
      "Validation Loss: 0.033413183\n",
      "Epoch: 4023 cost = 0.017445156\n",
      "Validation Loss: 0.046673033\n",
      "Epoch: 4024 cost = 0.017444390\n",
      "Validation Loss: 0.053714354\n",
      "Epoch: 4025 cost = 0.017443651\n",
      "Validation Loss: 0.055555027\n",
      "Epoch: 4026 cost = 0.017443039\n",
      "Validation Loss: 0.04841564\n",
      "Epoch: 4027 cost = 0.017442526\n",
      "Validation Loss: 0.050997265\n",
      "Epoch: 4028 cost = 0.017441823\n",
      "Validation Loss: 0.05002472\n",
      "Epoch: 4029 cost = 0.017441326\n",
      "Validation Loss: 0.06389511\n",
      "Epoch: 4030 cost = 0.017440726\n",
      "Validation Loss: 0.066803366\n",
      "Epoch: 4031 cost = 0.017439936\n",
      "Validation Loss: 0.052015636\n",
      "Epoch: 4032 cost = 0.017439639\n",
      "Validation Loss: 0.031106962\n",
      "Epoch: 4033 cost = 0.017439046\n",
      "Validation Loss: 0.030329224\n",
      "Epoch: 4034 cost = 0.017438353\n",
      "Validation Loss: 0.02856744\n",
      "Epoch: 4035 cost = 0.017437483\n",
      "Validation Loss: 0.023396654\n",
      "Epoch: 4036 cost = 0.017437170\n",
      "Validation Loss: 0.02681811\n",
      "Epoch: 4037 cost = 0.017436125\n",
      "Validation Loss: 0.058733933\n",
      "Epoch: 4038 cost = 0.017435360\n",
      "Validation Loss: 0.0492817\n",
      "Epoch: 4039 cost = 0.017434753\n",
      "Validation Loss: 0.023657762\n",
      "Epoch: 4040 cost = 0.017434594\n",
      "Validation Loss: 0.049892344\n",
      "Epoch: 4041 cost = 0.017434151\n",
      "Validation Loss: 0.054625344\n",
      "Epoch: 4042 cost = 0.017433417\n",
      "Validation Loss: 0.057450324\n",
      "Epoch: 4043 cost = 0.017432662\n",
      "Validation Loss: 0.06187418\n",
      "Epoch: 4044 cost = 0.017432024\n",
      "Validation Loss: 0.080857836\n",
      "Epoch: 4045 cost = 0.017431302\n",
      "Validation Loss: 0.06893168\n",
      "Epoch: 4046 cost = 0.017430599\n",
      "Validation Loss: 0.049980473\n",
      "Epoch: 4047 cost = 0.017430306\n",
      "Validation Loss: 0.040255647\n",
      "Epoch: 4048 cost = 0.017429424\n",
      "Validation Loss: 0.038197037\n",
      "Epoch: 4049 cost = 0.017429284\n",
      "Validation Loss: 0.045784723\n",
      "Epoch: 4050 cost = 0.017428754\n",
      "Validation Loss: 0.040808376\n",
      "Epoch: 4051 cost = 0.017428081\n",
      "Validation Loss: 0.033305313\n",
      "Epoch: 4052 cost = 0.017427191\n",
      "Validation Loss: 0.048848633\n",
      "Epoch: 4053 cost = 0.017426541\n",
      "Validation Loss: 0.055966128\n",
      "Epoch: 4054 cost = 0.017426166\n",
      "Validation Loss: 0.07168321\n",
      "Epoch: 4055 cost = 0.017425343\n",
      "Validation Loss: 0.07959059\n",
      "Epoch: 4056 cost = 0.017424861\n",
      "Validation Loss: 0.077782445\n",
      "Epoch: 4057 cost = 0.017423874\n",
      "Validation Loss: 0.0308672\n",
      "Epoch: 4058 cost = 0.017423596\n",
      "Validation Loss: 0.048404284\n",
      "Epoch: 4059 cost = 0.017423201\n",
      "Validation Loss: 0.07079461\n",
      "Epoch: 4060 cost = 0.017422844\n",
      "Validation Loss: 0.060551025\n",
      "Epoch: 4061 cost = 0.017421888\n",
      "Validation Loss: 0.04886067\n",
      "Epoch: 4062 cost = 0.017421082\n",
      "Validation Loss: 0.041194506\n",
      "Epoch: 4063 cost = 0.017420646\n",
      "Validation Loss: 0.048593584\n",
      "Epoch: 4064 cost = 0.017419676\n",
      "Validation Loss: 0.04912331\n",
      "Epoch: 4065 cost = 0.017419167\n",
      "Validation Loss: 0.07367482\n",
      "Epoch: 4066 cost = 0.017418850\n",
      "Validation Loss: 0.08913515\n",
      "Epoch: 4067 cost = 0.017418595\n",
      "Validation Loss: 0.07000771\n",
      "Epoch: 4068 cost = 0.017417377\n",
      "Validation Loss: 0.057688557\n",
      "Epoch: 4069 cost = 0.017416340\n",
      "Validation Loss: 0.046482813\n",
      "Epoch: 4070 cost = 0.017416109\n",
      "Validation Loss: 0.04461562\n",
      "Epoch: 4071 cost = 0.017415749\n",
      "Validation Loss: 0.041289352\n",
      "Epoch: 4072 cost = 0.017414987\n",
      "Validation Loss: 0.059255626\n",
      "Epoch: 4073 cost = 0.017414185\n",
      "Validation Loss: 0.07509208\n",
      "Epoch: 4074 cost = 0.017413966\n",
      "Validation Loss: 0.07036779\n",
      "Epoch: 4075 cost = 0.017413312\n",
      "Validation Loss: 0.039646838\n",
      "Epoch: 4076 cost = 0.017412696\n",
      "Validation Loss: 0.0363353\n",
      "Epoch: 4077 cost = 0.017412037\n",
      "Validation Loss: 0.034587514\n",
      "Epoch: 4078 cost = 0.017411717\n",
      "Validation Loss: 0.054043066\n",
      "Epoch: 4079 cost = 0.017410708\n",
      "Validation Loss: 0.049467925\n",
      "Epoch: 4080 cost = 0.017410094\n",
      "Validation Loss: 0.05170858\n",
      "Epoch: 4081 cost = 0.017409675\n",
      "Validation Loss: 0.057316706\n",
      "Epoch: 4082 cost = 0.017408907\n",
      "Validation Loss: 0.049745418\n",
      "Epoch: 4083 cost = 0.017408388\n",
      "Validation Loss: 0.040243227\n",
      "Epoch: 4084 cost = 0.017407619\n",
      "Validation Loss: 0.0417514\n",
      "Epoch: 4085 cost = 0.017407232\n",
      "Validation Loss: 0.04850994\n",
      "Epoch: 4086 cost = 0.017406902\n",
      "Validation Loss: 0.06800339\n",
      "Epoch: 4087 cost = 0.017406103\n",
      "Validation Loss: 0.057928205\n",
      "Epoch: 4088 cost = 0.017405400\n",
      "Validation Loss: 0.060388178\n",
      "Epoch: 4089 cost = 0.017405307\n",
      "Validation Loss: 0.06450647\n",
      "Epoch: 4090 cost = 0.017404379\n",
      "Validation Loss: 0.036465842\n",
      "Epoch: 4091 cost = 0.017403321\n",
      "Validation Loss: 0.03186236\n",
      "Epoch: 4092 cost = 0.017402661\n",
      "Validation Loss: 0.047697444\n",
      "Epoch: 4093 cost = 0.017401997\n",
      "Validation Loss: 0.048862863\n",
      "Epoch: 4094 cost = 0.017401690\n",
      "Validation Loss: 0.045846634\n",
      "Epoch: 4095 cost = 0.017401053\n",
      "Validation Loss: 0.036513433\n",
      "Epoch: 4096 cost = 0.017400651\n",
      "Validation Loss: 0.034753248\n",
      "Epoch: 4097 cost = 0.017400509\n",
      "Validation Loss: 0.042043764\n",
      "Epoch: 4098 cost = 0.017399536\n",
      "Validation Loss: 0.05700718\n",
      "Epoch: 4099 cost = 0.017398745\n",
      "Validation Loss: 0.061629657\n",
      "Epoch: 4100 cost = 0.017398136\n",
      "Validation Loss: 0.06360879\n",
      "Epoch: 4101 cost = 0.017397360\n",
      "Validation Loss: 0.055494413\n",
      "Epoch: 4102 cost = 0.017397243\n",
      "Validation Loss: 0.05218923\n",
      "Epoch: 4103 cost = 0.017396015\n",
      "Validation Loss: 0.053798616\n",
      "Epoch: 4104 cost = 0.017395696\n",
      "Validation Loss: 0.04475798\n",
      "Epoch: 4105 cost = 0.017395108\n",
      "Validation Loss: 0.049731027\n",
      "Epoch: 4106 cost = 0.017394958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04161023\n",
      "Epoch: 4107 cost = 0.017393562\n",
      "Validation Loss: 0.03645183\n",
      "Epoch: 4108 cost = 0.017393526\n",
      "Validation Loss: 0.051129974\n",
      "Epoch: 4109 cost = 0.017392646\n",
      "Validation Loss: 0.05912542\n",
      "Epoch: 4110 cost = 0.017392273\n",
      "Validation Loss: 0.037862502\n",
      "Epoch: 4111 cost = 0.017391914\n",
      "Validation Loss: 0.030206751\n",
      "Epoch: 4112 cost = 0.017391362\n",
      "Validation Loss: 0.035568547\n",
      "Epoch: 4113 cost = 0.017390149\n",
      "Validation Loss: 0.049854614\n",
      "Epoch: 4114 cost = 0.017389968\n",
      "Validation Loss: 0.051207326\n",
      "Epoch: 4115 cost = 0.017388878\n",
      "Validation Loss: 0.06922476\n",
      "Epoch: 4116 cost = 0.017388606\n",
      "Validation Loss: 0.060105506\n",
      "Epoch: 4117 cost = 0.017388458\n",
      "Validation Loss: 0.0466298\n",
      "Epoch: 4118 cost = 0.017387589\n",
      "Validation Loss: 0.038837437\n",
      "Epoch: 4119 cost = 0.017386887\n",
      "Validation Loss: 0.05017186\n",
      "Epoch: 4120 cost = 0.017385792\n",
      "Validation Loss: 0.036620185\n",
      "Epoch: 4121 cost = 0.017385679\n",
      "Validation Loss: 0.03492967\n",
      "Epoch: 4122 cost = 0.017385081\n",
      "Validation Loss: 0.03407519\n",
      "Epoch: 4123 cost = 0.017384566\n",
      "Validation Loss: 0.024894008\n",
      "Epoch: 4124 cost = 0.017384035\n",
      "Validation Loss: 0.045489475\n",
      "Epoch: 4125 cost = 0.017383137\n",
      "Validation Loss: 0.047920696\n",
      "Epoch: 4126 cost = 0.017382455\n",
      "Validation Loss: 0.047746852\n",
      "Epoch: 4127 cost = 0.017382236\n",
      "Validation Loss: 0.0455387\n",
      "Epoch: 4128 cost = 0.017381643\n",
      "Validation Loss: 0.05313037\n",
      "Epoch: 4129 cost = 0.017381188\n",
      "Validation Loss: 0.043483373\n",
      "Epoch: 4130 cost = 0.017380722\n",
      "Validation Loss: 0.04917667\n",
      "Epoch: 4131 cost = 0.017380126\n",
      "Validation Loss: 0.04335944\n",
      "Epoch: 4132 cost = 0.017379615\n",
      "Validation Loss: 0.053896826\n",
      "Epoch: 4133 cost = 0.017378902\n",
      "Validation Loss: 0.05649407\n",
      "Epoch: 4134 cost = 0.017378050\n",
      "Validation Loss: 0.044011574\n",
      "Epoch: 4135 cost = 0.017377356\n",
      "Validation Loss: 0.03480459\n",
      "Epoch: 4136 cost = 0.017376674\n",
      "Validation Loss: 0.04412911\n",
      "Epoch: 4137 cost = 0.017376656\n",
      "Validation Loss: 0.054667674\n",
      "Epoch: 4138 cost = 0.017375569\n",
      "Validation Loss: 0.03824608\n",
      "Epoch: 4139 cost = 0.017375117\n",
      "Validation Loss: 0.03158187\n",
      "Epoch: 4140 cost = 0.017374279\n",
      "Validation Loss: 0.057307318\n",
      "Epoch: 4141 cost = 0.017374083\n",
      "Validation Loss: 0.06604169\n",
      "Epoch: 4142 cost = 0.017373619\n",
      "Validation Loss: 0.03568939\n",
      "Epoch: 4143 cost = 0.017372977\n",
      "Validation Loss: 0.039243884\n",
      "Epoch: 4144 cost = 0.017372000\n",
      "Validation Loss: 0.03901066\n",
      "Epoch: 4145 cost = 0.017371724\n",
      "Validation Loss: 0.0454828\n",
      "Epoch: 4146 cost = 0.017370911\n",
      "Validation Loss: 0.043932363\n",
      "Epoch: 4147 cost = 0.017370530\n",
      "Validation Loss: 0.039818574\n",
      "Epoch: 4148 cost = 0.017370018\n",
      "Validation Loss: 0.040318795\n",
      "Epoch: 4149 cost = 0.017368941\n",
      "Validation Loss: 0.042568076\n",
      "Epoch: 4150 cost = 0.017369092\n",
      "Validation Loss: 0.045906045\n",
      "Epoch: 4151 cost = 0.017368719\n",
      "Validation Loss: 0.05117182\n",
      "Epoch: 4152 cost = 0.017367716\n",
      "Validation Loss: 0.041477267\n",
      "Epoch: 4153 cost = 0.017367229\n",
      "Validation Loss: 0.025066612\n",
      "Epoch: 4154 cost = 0.017366956\n",
      "Validation Loss: 0.03561582\n",
      "Epoch: 4155 cost = 0.017366067\n",
      "Validation Loss: 0.052738525\n",
      "Epoch: 4156 cost = 0.017365199\n",
      "Validation Loss: 0.06471981\n",
      "Epoch: 4157 cost = 0.017364846\n",
      "Validation Loss: 0.06280563\n",
      "Epoch: 4158 cost = 0.017364291\n",
      "Validation Loss: 0.052962903\n",
      "Epoch: 4159 cost = 0.017363384\n",
      "Validation Loss: 0.056475315\n",
      "Epoch: 4160 cost = 0.017363562\n",
      "Validation Loss: 0.0742036\n",
      "Epoch: 4161 cost = 0.017362524\n",
      "Validation Loss: 0.07876838\n",
      "Epoch: 4162 cost = 0.017361435\n",
      "Validation Loss: 0.05777988\n",
      "Epoch: 4163 cost = 0.017361352\n",
      "Validation Loss: 0.037801925\n",
      "Epoch: 4164 cost = 0.017360979\n",
      "Validation Loss: 0.045552094\n",
      "Epoch: 4165 cost = 0.017360046\n",
      "Validation Loss: 0.044181965\n",
      "Epoch: 4166 cost = 0.017359277\n",
      "Validation Loss: 0.047524896\n",
      "Epoch: 4167 cost = 0.017359018\n",
      "Validation Loss: 0.038579922\n",
      "Epoch: 4168 cost = 0.017358271\n",
      "Validation Loss: 0.034297418\n",
      "Epoch: 4169 cost = 0.017358112\n",
      "Validation Loss: 0.04092537\n",
      "Epoch: 4170 cost = 0.017357540\n",
      "Validation Loss: 0.030370865\n",
      "Epoch: 4171 cost = 0.017356872\n",
      "Validation Loss: 0.03589111\n",
      "Epoch: 4172 cost = 0.017355815\n",
      "Validation Loss: 0.039482325\n",
      "Epoch: 4173 cost = 0.017355293\n",
      "Validation Loss: 0.05140133\n",
      "Epoch: 4174 cost = 0.017355025\n",
      "Validation Loss: 0.059777744\n",
      "Epoch: 4175 cost = 0.017354609\n",
      "Validation Loss: 0.043854468\n",
      "Epoch: 4176 cost = 0.017353482\n",
      "Validation Loss: 0.024587331\n",
      "Epoch: 4177 cost = 0.017352999\n",
      "Validation Loss: 0.043905403\n",
      "Epoch: 4178 cost = 0.017353114\n",
      "Validation Loss: 0.05307936\n",
      "Epoch: 4179 cost = 0.017352153\n",
      "Validation Loss: 0.07712199\n",
      "Epoch: 4180 cost = 0.017351761\n",
      "Validation Loss: 0.06236422\n",
      "Epoch: 4181 cost = 0.017351042\n",
      "Validation Loss: 0.03427073\n",
      "Epoch: 4182 cost = 0.017350300\n",
      "Validation Loss: 0.046258166\n",
      "Epoch: 4183 cost = 0.017349990\n",
      "Validation Loss: 0.04956974\n",
      "Epoch: 4184 cost = 0.017349394\n",
      "Validation Loss: 0.04293617\n",
      "Epoch: 4185 cost = 0.017348654\n",
      "Validation Loss: 0.028894791\n",
      "Epoch: 4186 cost = 0.017348136\n",
      "Validation Loss: 0.03080421\n",
      "Epoch: 4187 cost = 0.017347226\n",
      "Validation Loss: 0.034437552\n",
      "Epoch: 4188 cost = 0.017346511\n",
      "Validation Loss: 0.06397918\n",
      "Epoch: 4189 cost = 0.017346448\n",
      "Validation Loss: 0.059996583\n",
      "Epoch: 4190 cost = 0.017346350\n",
      "Validation Loss: 0.047761537\n",
      "Epoch: 4191 cost = 0.017345076\n",
      "Validation Loss: 0.052535582\n",
      "Epoch: 4192 cost = 0.017345015\n",
      "Validation Loss: 0.056136776\n",
      "Epoch: 4193 cost = 0.017344263\n",
      "Validation Loss: 0.06077117\n",
      "Epoch: 4194 cost = 0.017343540\n",
      "Validation Loss: 0.047559064\n",
      "Epoch: 4195 cost = 0.017343572\n",
      "Validation Loss: 0.043664448\n",
      "Epoch: 4196 cost = 0.017342434\n",
      "Validation Loss: 0.04759126\n",
      "Epoch: 4197 cost = 0.017341501\n",
      "Validation Loss: 0.056962173\n",
      "Epoch: 4198 cost = 0.017341390\n",
      "Validation Loss: 0.07245862\n",
      "Epoch: 4199 cost = 0.017340755\n",
      "Validation Loss: 0.058723595\n",
      "Epoch: 4200 cost = 0.017339851\n",
      "Validation Loss: 0.04562738\n",
      "Epoch: 4201 cost = 0.017339386\n",
      "Validation Loss: 0.04500108\n",
      "Epoch: 4202 cost = 0.017339229\n",
      "Validation Loss: 0.0461856\n",
      "Epoch: 4203 cost = 0.017338384\n",
      "Validation Loss: 0.04222131\n",
      "Epoch: 4204 cost = 0.017337527\n",
      "Validation Loss: 0.036773227\n",
      "Epoch: 4205 cost = 0.017337198\n",
      "Validation Loss: 0.046194866\n",
      "Epoch: 4206 cost = 0.017336947\n",
      "Validation Loss: 0.05165236\n",
      "Epoch: 4207 cost = 0.017336469\n",
      "Validation Loss: 0.034991298\n",
      "Epoch: 4208 cost = 0.017335383\n",
      "Validation Loss: 0.03112113\n",
      "Epoch: 4209 cost = 0.017334862\n",
      "Validation Loss: 0.03057677\n",
      "Epoch: 4210 cost = 0.017334212\n",
      "Validation Loss: 0.031164538\n",
      "Epoch: 4211 cost = 0.017333691\n",
      "Validation Loss: 0.037670735\n",
      "Epoch: 4212 cost = 0.017333389\n",
      "Validation Loss: 0.04818044\n",
      "Epoch: 4213 cost = 0.017332954\n",
      "Validation Loss: 0.032591667\n",
      "Epoch: 4214 cost = 0.017332261\n",
      "Validation Loss: 0.03381499\n",
      "Epoch: 4215 cost = 0.017331722\n",
      "Validation Loss: 0.026446233\n",
      "Epoch: 4216 cost = 0.017331259\n",
      "Validation Loss: 0.025501404\n",
      "Epoch: 4217 cost = 0.017330530\n",
      "Validation Loss: 0.043524105\n",
      "Epoch: 4218 cost = 0.017330382\n",
      "Validation Loss: 0.047960944\n",
      "Epoch: 4219 cost = 0.017329477\n",
      "Validation Loss: 0.043414313\n",
      "Epoch: 4220 cost = 0.017328798\n",
      "Validation Loss: 0.048098866\n",
      "Epoch: 4221 cost = 0.017328176\n",
      "Validation Loss: 0.041070744\n",
      "Epoch: 4222 cost = 0.017327874\n",
      "Validation Loss: 0.040889867\n",
      "Epoch: 4223 cost = 0.017327165\n",
      "Validation Loss: 0.041885223\n",
      "Epoch: 4224 cost = 0.017326720\n",
      "Validation Loss: 0.038571075\n",
      "Epoch: 4225 cost = 0.017326593\n",
      "Validation Loss: 0.030230828\n",
      "Epoch: 4226 cost = 0.017325875\n",
      "Validation Loss: 0.041522823\n",
      "Epoch: 4227 cost = 0.017325050\n",
      "Validation Loss: 0.041579388\n",
      "Epoch: 4228 cost = 0.017325105\n",
      "Validation Loss: 0.034159463\n",
      "Epoch: 4229 cost = 0.017323980\n",
      "Validation Loss: 0.06496291\n",
      "Epoch: 4230 cost = 0.017323834\n",
      "Validation Loss: 0.0606539\n",
      "Epoch: 4231 cost = 0.017323282\n",
      "Validation Loss: 0.041067947\n",
      "Epoch: 4232 cost = 0.017322177\n",
      "Validation Loss: 0.04149205\n",
      "Epoch: 4233 cost = 0.017321755\n",
      "Validation Loss: 0.031334028\n",
      "Epoch: 4234 cost = 0.017320877\n",
      "Validation Loss: 0.043548454\n",
      "Epoch: 4235 cost = 0.017320821\n",
      "Validation Loss: 0.04045708\n",
      "Epoch: 4236 cost = 0.017320381\n",
      "Validation Loss: 0.041247837\n",
      "Epoch: 4237 cost = 0.017319418\n",
      "Validation Loss: 0.063954525\n",
      "Epoch: 4238 cost = 0.017318989\n",
      "Validation Loss: 0.07423891\n",
      "Epoch: 4239 cost = 0.017317795\n",
      "Validation Loss: 0.06630423\n",
      "Epoch: 4240 cost = 0.017317923\n",
      "Validation Loss: 0.04693704\n",
      "Epoch: 4241 cost = 0.017317386\n",
      "Validation Loss: 0.049800705\n",
      "Epoch: 4242 cost = 0.017316761\n",
      "Validation Loss: 0.041989572\n",
      "Epoch: 4243 cost = 0.017316039\n",
      "Validation Loss: 0.03897411\n",
      "Epoch: 4244 cost = 0.017315514\n",
      "Validation Loss: 0.051003624\n",
      "Epoch: 4245 cost = 0.017314912\n",
      "Validation Loss: 0.05741398\n",
      "Epoch: 4246 cost = 0.017314254\n",
      "Validation Loss: 0.054590218\n",
      "Epoch: 4247 cost = 0.017313653\n",
      "Validation Loss: 0.043891326\n",
      "Epoch: 4248 cost = 0.017313073\n",
      "Validation Loss: 0.046065334\n",
      "Epoch: 4249 cost = 0.017312390\n",
      "Validation Loss: 0.039905157\n",
      "Epoch: 4250 cost = 0.017312524\n",
      "Validation Loss: 0.03378009\n",
      "Epoch: 4251 cost = 0.017311749\n",
      "Validation Loss: 0.046396818\n",
      "Epoch: 4252 cost = 0.017311007\n",
      "Validation Loss: 0.048797313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4253 cost = 0.017310556\n",
      "Validation Loss: 0.03848446\n",
      "Epoch: 4254 cost = 0.017310067\n",
      "Validation Loss: 0.030281654\n",
      "Epoch: 4255 cost = 0.017309943\n",
      "Validation Loss: 0.04116467\n",
      "Epoch: 4256 cost = 0.017308907\n",
      "Validation Loss: 0.054642055\n",
      "Epoch: 4257 cost = 0.017308511\n",
      "Validation Loss: 0.056981977\n",
      "Epoch: 4258 cost = 0.017308183\n",
      "Validation Loss: 0.049020767\n",
      "Epoch: 4259 cost = 0.017307205\n",
      "Validation Loss: 0.05139976\n",
      "Epoch: 4260 cost = 0.017306967\n",
      "Validation Loss: 0.048234127\n",
      "Epoch: 4261 cost = 0.017306187\n",
      "Validation Loss: 0.0505979\n",
      "Epoch: 4262 cost = 0.017305596\n",
      "Validation Loss: 0.069822066\n",
      "Epoch: 4263 cost = 0.017305978\n",
      "Validation Loss: 0.073903486\n",
      "Epoch: 4264 cost = 0.017304432\n",
      "Validation Loss: 0.039382413\n",
      "Epoch: 4265 cost = 0.017304123\n",
      "Validation Loss: 0.036651034\n",
      "Epoch: 4266 cost = 0.017303366\n",
      "Validation Loss: 0.025528971\n",
      "Epoch: 4267 cost = 0.017302713\n",
      "Validation Loss: 0.030425875\n",
      "Epoch: 4268 cost = 0.017302914\n",
      "Validation Loss: 0.023179263\n",
      "Epoch: 4269 cost = 0.017301383\n",
      "Validation Loss: 0.027016416\n",
      "Epoch: 4270 cost = 0.017301108\n",
      "Validation Loss: 0.032403585\n",
      "Epoch: 4271 cost = 0.017300562\n",
      "Validation Loss: 0.024835523\n",
      "Epoch: 4272 cost = 0.017299893\n",
      "Validation Loss: 0.033065207\n",
      "Epoch: 4273 cost = 0.017299918\n",
      "Validation Loss: 0.034283325\n",
      "Epoch: 4274 cost = 0.017298907\n",
      "Validation Loss: 0.041304674\n",
      "Epoch: 4275 cost = 0.017298999\n",
      "Validation Loss: 0.042309463\n",
      "Epoch: 4276 cost = 0.017298126\n",
      "Validation Loss: 0.040855754\n",
      "Epoch: 4277 cost = 0.017297350\n",
      "Validation Loss: 0.02687164\n",
      "Epoch: 4278 cost = 0.017296979\n",
      "Validation Loss: 0.03938682\n",
      "Epoch: 4279 cost = 0.017296313\n",
      "Validation Loss: 0.04686253\n",
      "Epoch: 4280 cost = 0.017295529\n",
      "Validation Loss: 0.06608979\n",
      "Epoch: 4281 cost = 0.017295615\n",
      "Validation Loss: 0.06044752\n",
      "Epoch: 4282 cost = 0.017294786\n",
      "Validation Loss: 0.05056906\n",
      "Epoch: 4283 cost = 0.017294191\n",
      "Validation Loss: 0.055687055\n",
      "Epoch: 4284 cost = 0.017293221\n",
      "Validation Loss: 0.0690946\n",
      "Epoch: 4285 cost = 0.017293297\n",
      "Validation Loss: 0.08000039\n",
      "Epoch: 4286 cost = 0.017292804\n",
      "Validation Loss: 0.07677661\n",
      "Epoch: 4287 cost = 0.017291788\n",
      "Validation Loss: 0.046486236\n",
      "Epoch: 4288 cost = 0.017291649\n",
      "Validation Loss: 0.041939862\n",
      "Epoch: 4289 cost = 0.017290876\n",
      "Validation Loss: 0.04562328\n",
      "Epoch: 4290 cost = 0.017290212\n",
      "Validation Loss: 0.04949384\n",
      "Epoch: 4291 cost = 0.017289606\n",
      "Validation Loss: 0.038625848\n",
      "Epoch: 4292 cost = 0.017288740\n",
      "Validation Loss: 0.029405078\n",
      "Epoch: 4293 cost = 0.017288908\n",
      "Validation Loss: 0.022531308\n",
      "Epoch: 4294 cost = 0.017288426\n",
      "Validation Loss: 0.03819668\n",
      "Epoch: 4295 cost = 0.017287492\n",
      "Validation Loss: 0.033350375\n",
      "Epoch: 4296 cost = 0.017286202\n",
      "Validation Loss: 0.033529393\n",
      "Epoch: 4297 cost = 0.017286264\n",
      "Validation Loss: 0.040155582\n",
      "Epoch: 4298 cost = 0.017285845\n",
      "Validation Loss: 0.0277607\n",
      "Epoch: 4299 cost = 0.017285338\n",
      "Validation Loss: 0.026234206\n",
      "Epoch: 4300 cost = 0.017285020\n",
      "Validation Loss: 0.030416913\n",
      "Epoch: 4301 cost = 0.017284577\n",
      "Validation Loss: 0.03175844\n",
      "Epoch: 4302 cost = 0.017283835\n",
      "Validation Loss: 0.02802643\n",
      "Epoch: 4303 cost = 0.017282993\n",
      "Validation Loss: 0.039599415\n",
      "Epoch: 4304 cost = 0.017282798\n",
      "Validation Loss: 0.053013496\n",
      "Epoch: 4305 cost = 0.017282124\n",
      "Validation Loss: 0.050565567\n",
      "Epoch: 4306 cost = 0.017281398\n",
      "Validation Loss: 0.062009692\n",
      "Epoch: 4307 cost = 0.017281166\n",
      "Validation Loss: 0.045637492\n",
      "Epoch: 4308 cost = 0.017280683\n",
      "Validation Loss: 0.037545558\n",
      "Epoch: 4309 cost = 0.017280479\n",
      "Validation Loss: 0.037386302\n",
      "Epoch: 4310 cost = 0.017279980\n",
      "Validation Loss: 0.038447563\n",
      "Epoch: 4311 cost = 0.017278855\n",
      "Validation Loss: 0.04285129\n",
      "Epoch: 4312 cost = 0.017278496\n",
      "Validation Loss: 0.048850898\n",
      "Epoch: 4313 cost = 0.017277734\n",
      "Validation Loss: 0.08436333\n",
      "Epoch: 4314 cost = 0.017277474\n",
      "Validation Loss: 0.079381116\n",
      "Epoch: 4315 cost = 0.017277277\n",
      "Validation Loss: 0.060736515\n",
      "Epoch: 4316 cost = 0.017275962\n",
      "Validation Loss: 0.04717024\n",
      "Epoch: 4317 cost = 0.017276004\n",
      "Validation Loss: 0.057031285\n",
      "Epoch: 4318 cost = 0.017275366\n",
      "Validation Loss: 0.075202435\n",
      "Epoch: 4319 cost = 0.017274491\n",
      "Validation Loss: 0.06679828\n",
      "Epoch: 4320 cost = 0.017274157\n",
      "Validation Loss: 0.05157165\n",
      "Epoch: 4321 cost = 0.017273556\n",
      "Validation Loss: 0.047220144\n",
      "Epoch: 4322 cost = 0.017273077\n",
      "Validation Loss: 0.04656123\n",
      "Epoch: 4323 cost = 0.017272793\n",
      "Validation Loss: 0.027997369\n",
      "Epoch: 4324 cost = 0.017272019\n",
      "Validation Loss: 0.02858184\n",
      "Epoch: 4325 cost = 0.017271880\n",
      "Validation Loss: 0.032929767\n",
      "Epoch: 4326 cost = 0.017270923\n",
      "Validation Loss: 0.04307365\n",
      "Epoch: 4327 cost = 0.017270648\n",
      "Validation Loss: 0.047383558\n",
      "Epoch: 4328 cost = 0.017270735\n",
      "Validation Loss: 0.056180637\n",
      "Epoch: 4329 cost = 0.017269292\n",
      "Validation Loss: 0.05285078\n",
      "Epoch: 4330 cost = 0.017268868\n",
      "Validation Loss: 0.028440302\n",
      "Epoch: 4331 cost = 0.017268987\n",
      "Validation Loss: 0.023895552\n",
      "Epoch: 4332 cost = 0.017268029\n",
      "Validation Loss: 0.037315976\n",
      "Epoch: 4333 cost = 0.017267583\n",
      "Validation Loss: 0.039776444\n",
      "Epoch: 4334 cost = 0.017266860\n",
      "Validation Loss: 0.034432106\n",
      "Epoch: 4335 cost = 0.017266315\n",
      "Validation Loss: 0.035481624\n",
      "Epoch: 4336 cost = 0.017265892\n",
      "Validation Loss: 0.05871639\n",
      "Epoch: 4337 cost = 0.017265291\n",
      "Validation Loss: 0.054726526\n",
      "Epoch: 4338 cost = 0.017264480\n",
      "Validation Loss: 0.051745143\n",
      "Epoch: 4339 cost = 0.017264149\n",
      "Validation Loss: 0.068544574\n",
      "Epoch: 4340 cost = 0.017263112\n",
      "Validation Loss: 0.08797197\n",
      "Epoch: 4341 cost = 0.017262877\n",
      "Validation Loss: 0.10809311\n",
      "Epoch: 4342 cost = 0.017262461\n",
      "Validation Loss: 0.06824338\n",
      "Epoch: 4343 cost = 0.017261872\n",
      "Validation Loss: 0.046240207\n",
      "Epoch: 4344 cost = 0.017261482\n",
      "Validation Loss: 0.049560677\n",
      "Epoch: 4345 cost = 0.017260792\n",
      "Validation Loss: 0.049889356\n",
      "Epoch: 4346 cost = 0.017260943\n",
      "Validation Loss: 0.050767496\n",
      "Epoch: 4347 cost = 0.017260171\n",
      "Validation Loss: 0.039448082\n",
      "Epoch: 4348 cost = 0.017259705\n",
      "Validation Loss: 0.04779226\n",
      "Epoch: 4349 cost = 0.017258657\n",
      "Validation Loss: 0.05789727\n",
      "Epoch: 4350 cost = 0.017258273\n",
      "Validation Loss: 0.03778254\n",
      "Epoch: 4351 cost = 0.017257949\n",
      "Validation Loss: 0.029627586\n",
      "Epoch: 4352 cost = 0.017257311\n",
      "Validation Loss: 0.028469492\n",
      "Epoch: 4353 cost = 0.017256627\n",
      "Validation Loss: 0.033245575\n",
      "Epoch: 4354 cost = 0.017256348\n",
      "Validation Loss: 0.031382058\n",
      "Epoch: 4355 cost = 0.017255729\n",
      "Validation Loss: 0.054579455\n",
      "Epoch: 4356 cost = 0.017255261\n",
      "Validation Loss: 0.07981413\n",
      "Epoch: 4357 cost = 0.017254184\n",
      "Validation Loss: 0.067850105\n",
      "Epoch: 4358 cost = 0.017253874\n",
      "Validation Loss: 0.06962397\n",
      "Epoch: 4359 cost = 0.017253814\n",
      "Validation Loss: 0.057589583\n",
      "Epoch: 4360 cost = 0.017253187\n",
      "Validation Loss: 0.0340557\n",
      "Epoch: 4361 cost = 0.017252524\n",
      "Validation Loss: 0.032069854\n",
      "Epoch: 4362 cost = 0.017251721\n",
      "Validation Loss: 0.04819235\n",
      "Epoch: 4363 cost = 0.017251330\n",
      "Validation Loss: 0.04283276\n",
      "Epoch: 4364 cost = 0.017250729\n",
      "Validation Loss: 0.03983615\n",
      "Epoch: 4365 cost = 0.017250385\n",
      "Validation Loss: 0.053136844\n",
      "Epoch: 4366 cost = 0.017250625\n",
      "Validation Loss: 0.049963333\n",
      "Epoch: 4367 cost = 0.017249400\n",
      "Validation Loss: 0.039615132\n",
      "Epoch: 4368 cost = 0.017249089\n",
      "Validation Loss: 0.032067433\n",
      "Epoch: 4369 cost = 0.017248514\n",
      "Validation Loss: 0.03138057\n",
      "Epoch: 4370 cost = 0.017247775\n",
      "Validation Loss: 0.04261488\n",
      "Epoch: 4371 cost = 0.017247017\n",
      "Validation Loss: 0.041143082\n",
      "Epoch: 4372 cost = 0.017246452\n",
      "Validation Loss: 0.042160224\n",
      "Epoch: 4373 cost = 0.017246081\n",
      "Validation Loss: 0.048184637\n",
      "Epoch: 4374 cost = 0.017245909\n",
      "Validation Loss: 0.043647047\n",
      "Epoch: 4375 cost = 0.017245321\n",
      "Validation Loss: 0.039271824\n",
      "Epoch: 4376 cost = 0.017244418\n",
      "Validation Loss: 0.04526383\n",
      "Epoch: 4377 cost = 0.017244312\n",
      "Validation Loss: 0.05955033\n",
      "Epoch: 4378 cost = 0.017243640\n",
      "Validation Loss: 0.052071486\n",
      "Epoch: 4379 cost = 0.017243035\n",
      "Validation Loss: 0.05612915\n",
      "Epoch: 4380 cost = 0.017242383\n",
      "Validation Loss: 0.07283692\n",
      "Epoch: 4381 cost = 0.017242052\n",
      "Validation Loss: 0.05713746\n",
      "Epoch: 4382 cost = 0.017241408\n",
      "Validation Loss: 0.033219714\n",
      "Epoch: 4383 cost = 0.017240914\n",
      "Validation Loss: 0.034955412\n",
      "Epoch: 4384 cost = 0.017239540\n",
      "Validation Loss: 0.052605305\n",
      "Epoch: 4385 cost = 0.017239884\n",
      "Validation Loss: 0.06375243\n",
      "Epoch: 4386 cost = 0.017239067\n",
      "Validation Loss: 0.04349913\n",
      "Epoch: 4387 cost = 0.017238643\n",
      "Validation Loss: 0.039781958\n",
      "Epoch: 4388 cost = 0.017238187\n",
      "Validation Loss: 0.044702593\n",
      "Epoch: 4389 cost = 0.017238179\n",
      "Validation Loss: 0.03348083\n",
      "Epoch: 4390 cost = 0.017237334\n",
      "Validation Loss: 0.04039825\n",
      "Epoch: 4391 cost = 0.017236802\n",
      "Validation Loss: 0.045755118\n",
      "Epoch: 4392 cost = 0.017236334\n",
      "Validation Loss: 0.047896266\n",
      "Epoch: 4393 cost = 0.017235964\n",
      "Validation Loss: 0.044250224\n",
      "Epoch: 4394 cost = 0.017235549\n",
      "Validation Loss: 0.04236151\n",
      "Epoch: 4395 cost = 0.017234876\n",
      "Validation Loss: 0.04383548\n",
      "Epoch: 4396 cost = 0.017234464\n",
      "Validation Loss: 0.046240944\n",
      "Epoch: 4397 cost = 0.017233977\n",
      "Validation Loss: 0.042418912\n",
      "Epoch: 4398 cost = 0.017233302\n",
      "Validation Loss: 0.034707196\n",
      "Epoch: 4399 cost = 0.017233222\n",
      "Validation Loss: 0.040440843\n",
      "Epoch: 4400 cost = 0.017232801\n",
      "Validation Loss: 0.04124673\n",
      "Epoch: 4401 cost = 0.017232817\n",
      "Validation Loss: 0.043324262\n",
      "Epoch: 4402 cost = 0.017231824\n",
      "Validation Loss: 0.040519524\n",
      "Epoch: 4403 cost = 0.017231052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.035414997\n",
      "Epoch: 4404 cost = 0.017230354\n",
      "Validation Loss: 0.024015918\n",
      "Epoch: 4405 cost = 0.017229545\n",
      "Validation Loss: 0.022715868\n",
      "Epoch: 4406 cost = 0.017228887\n",
      "Validation Loss: 0.028696582\n",
      "Epoch: 4407 cost = 0.017228519\n",
      "Validation Loss: 0.047990035\n",
      "Epoch: 4408 cost = 0.017227695\n",
      "Validation Loss: 0.04507647\n",
      "Epoch: 4409 cost = 0.017227427\n",
      "Validation Loss: 0.04127007\n",
      "Epoch: 4410 cost = 0.017226857\n",
      "Validation Loss: 0.037938055\n",
      "Epoch: 4411 cost = 0.017226110\n",
      "Validation Loss: 0.06200159\n",
      "Epoch: 4412 cost = 0.017225984\n",
      "Validation Loss: 0.08700636\n",
      "Epoch: 4413 cost = 0.017225267\n",
      "Validation Loss: 0.08848346\n",
      "Epoch: 4414 cost = 0.017224813\n",
      "Validation Loss: 0.08236118\n",
      "Epoch: 4415 cost = 0.017224205\n",
      "Validation Loss: 0.04947316\n",
      "Epoch: 4416 cost = 0.017224043\n",
      "Validation Loss: 0.028670523\n",
      "Epoch: 4417 cost = 0.017223049\n",
      "Validation Loss: 0.03433495\n",
      "Epoch: 4418 cost = 0.017222860\n",
      "Validation Loss: 0.025429605\n",
      "Epoch: 4419 cost = 0.017222590\n",
      "Validation Loss: 0.040067352\n",
      "Epoch: 4420 cost = 0.017221860\n",
      "Validation Loss: 0.036898702\n",
      "Epoch: 4421 cost = 0.017221129\n",
      "Validation Loss: 0.029026765\n",
      "Epoch: 4422 cost = 0.017220917\n",
      "Validation Loss: 0.028050518\n",
      "Epoch: 4423 cost = 0.017220718\n",
      "Validation Loss: 0.03858404\n",
      "Epoch: 4424 cost = 0.017219914\n",
      "Validation Loss: 0.044553082\n",
      "Epoch: 4425 cost = 0.017219619\n",
      "Validation Loss: 0.030415371\n",
      "Epoch: 4426 cost = 0.017218479\n",
      "Validation Loss: 0.031498607\n",
      "Epoch: 4427 cost = 0.017218271\n",
      "Validation Loss: 0.028080754\n",
      "Epoch: 4428 cost = 0.017217728\n",
      "Validation Loss: 0.040527325\n",
      "Epoch: 4429 cost = 0.017216955\n",
      "Validation Loss: 0.06039199\n",
      "Epoch: 4430 cost = 0.017217213\n",
      "Validation Loss: 0.06435714\n",
      "Epoch: 4431 cost = 0.017216384\n",
      "Validation Loss: 0.036972146\n",
      "Epoch: 4432 cost = 0.017216183\n",
      "Validation Loss: 0.026935618\n",
      "Epoch: 4433 cost = 0.017215870\n",
      "Validation Loss: 0.047889933\n",
      "Epoch: 4434 cost = 0.017215520\n",
      "Validation Loss: 0.058983758\n",
      "Epoch: 4435 cost = 0.017214959\n",
      "Validation Loss: 0.04070683\n",
      "Epoch: 4436 cost = 0.017213836\n",
      "Validation Loss: 0.03704283\n",
      "Epoch: 4437 cost = 0.017213010\n",
      "Validation Loss: 0.060373288\n",
      "Epoch: 4438 cost = 0.017212858\n",
      "Validation Loss: 0.04497493\n",
      "Epoch: 4439 cost = 0.017212074\n",
      "Validation Loss: 0.041839864\n",
      "Epoch: 4440 cost = 0.017211560\n",
      "Validation Loss: 0.05765169\n",
      "Epoch: 4441 cost = 0.017211050\n",
      "Validation Loss: 0.04464936\n",
      "Epoch: 4442 cost = 0.017210682\n",
      "Validation Loss: 0.032438826\n",
      "Epoch: 4443 cost = 0.017209989\n",
      "Validation Loss: 0.034932688\n",
      "Epoch: 4444 cost = 0.017209742\n",
      "Validation Loss: 0.027831858\n",
      "Epoch: 4445 cost = 0.017209499\n",
      "Validation Loss: 0.03510108\n",
      "Epoch: 4446 cost = 0.017208580\n",
      "Validation Loss: 0.035463084\n",
      "Epoch: 4447 cost = 0.017208010\n",
      "Validation Loss: 0.033769477\n",
      "Epoch: 4448 cost = 0.017207800\n",
      "Validation Loss: 0.0343453\n",
      "Epoch: 4449 cost = 0.017207031\n",
      "Validation Loss: 0.040453687\n",
      "Epoch: 4450 cost = 0.017206663\n",
      "Validation Loss: 0.030941732\n",
      "Epoch: 4451 cost = 0.017206309\n",
      "Validation Loss: 0.033761628\n",
      "Epoch: 4452 cost = 0.017205748\n",
      "Validation Loss: 0.035099912\n",
      "Epoch: 4453 cost = 0.017205283\n",
      "Validation Loss: 0.03317624\n",
      "Epoch: 4454 cost = 0.017204390\n",
      "Validation Loss: 0.06523568\n",
      "Epoch: 4455 cost = 0.017204000\n",
      "Validation Loss: 0.0664906\n",
      "Epoch: 4456 cost = 0.017203247\n",
      "Validation Loss: 0.043349564\n",
      "Epoch: 4457 cost = 0.017203081\n",
      "Validation Loss: 0.033289295\n",
      "Epoch: 4458 cost = 0.017202672\n",
      "Validation Loss: 0.034823418\n",
      "Epoch: 4459 cost = 0.017202540\n",
      "Validation Loss: 0.031157823\n",
      "Epoch: 4460 cost = 0.017202051\n",
      "Validation Loss: 0.053918146\n",
      "Epoch: 4461 cost = 0.017200956\n",
      "Validation Loss: 0.044072814\n",
      "Epoch: 4462 cost = 0.017201099\n",
      "Validation Loss: 0.029882053\n",
      "Epoch: 4463 cost = 0.017200018\n",
      "Validation Loss: 0.023466688\n",
      "Epoch: 4464 cost = 0.017200078\n",
      "Validation Loss: 0.029814322\n",
      "Epoch: 4465 cost = 0.017199171\n",
      "Validation Loss: 0.044920083\n",
      "Epoch: 4466 cost = 0.017198713\n",
      "Validation Loss: 0.044514872\n",
      "Epoch: 4467 cost = 0.017198200\n",
      "Validation Loss: 0.030739238\n",
      "Epoch: 4468 cost = 0.017197167\n",
      "Validation Loss: 0.066150405\n",
      "Epoch: 4469 cost = 0.017197183\n",
      "Validation Loss: 0.07772093\n",
      "Epoch: 4470 cost = 0.017197057\n",
      "Validation Loss: 0.061647497\n",
      "Epoch: 4471 cost = 0.017196336\n",
      "Validation Loss: 0.05318502\n",
      "Epoch: 4472 cost = 0.017195554\n",
      "Validation Loss: 0.037929837\n",
      "Epoch: 4473 cost = 0.017195366\n",
      "Validation Loss: 0.059473228\n",
      "Epoch: 4474 cost = 0.017194469\n",
      "Validation Loss: 0.051769014\n",
      "Epoch: 4475 cost = 0.017194062\n",
      "Validation Loss: 0.03732982\n",
      "Epoch: 4476 cost = 0.017193597\n",
      "Validation Loss: 0.046433356\n",
      "Epoch: 4477 cost = 0.017193190\n",
      "Validation Loss: 0.045386504\n",
      "Epoch: 4478 cost = 0.017192800\n",
      "Validation Loss: 0.042514354\n",
      "Epoch: 4479 cost = 0.017192526\n",
      "Validation Loss: 0.04297376\n",
      "Epoch: 4480 cost = 0.017191985\n",
      "Validation Loss: 0.052960332\n",
      "Epoch: 4481 cost = 0.017191193\n",
      "Validation Loss: 0.047203545\n",
      "Epoch: 4482 cost = 0.017190520\n",
      "Validation Loss: 0.037967265\n",
      "Epoch: 4483 cost = 0.017189579\n",
      "Validation Loss: 0.051625933\n",
      "Epoch: 4484 cost = 0.017189294\n",
      "Validation Loss: 0.070182286\n",
      "Epoch: 4485 cost = 0.017189242\n",
      "Validation Loss: 0.09455706\n",
      "Epoch: 4486 cost = 0.017188263\n",
      "Validation Loss: 0.10664325\n",
      "Epoch: 4487 cost = 0.017187686\n",
      "Validation Loss: 0.09530795\n",
      "Epoch: 4488 cost = 0.017187597\n",
      "Validation Loss: 0.06626098\n",
      "Epoch: 4489 cost = 0.017186678\n",
      "Validation Loss: 0.04461086\n",
      "Epoch: 4490 cost = 0.017186617\n",
      "Validation Loss: 0.041534096\n",
      "Epoch: 4491 cost = 0.017185862\n",
      "Validation Loss: 0.03993326\n",
      "Epoch: 4492 cost = 0.017185418\n",
      "Validation Loss: 0.05275431\n",
      "Epoch: 4493 cost = 0.017184832\n",
      "Validation Loss: 0.051504288\n",
      "Epoch: 4494 cost = 0.017184839\n",
      "Validation Loss: 0.046250198\n",
      "Epoch: 4495 cost = 0.017184017\n",
      "Validation Loss: 0.044386372\n",
      "Epoch: 4496 cost = 0.017183508\n",
      "Validation Loss: 0.031812686\n",
      "Epoch: 4497 cost = 0.017183594\n",
      "Validation Loss: 0.03274\n",
      "Epoch: 4498 cost = 0.017182558\n",
      "Validation Loss: 0.037111927\n",
      "Epoch: 4499 cost = 0.017182158\n",
      "Validation Loss: 0.032874912\n",
      "Epoch: 4500 cost = 0.017181506\n",
      "Validation Loss: 0.04954556\n",
      "Epoch: 4501 cost = 0.017181658\n",
      "Validation Loss: 0.058179658\n",
      "Epoch: 4502 cost = 0.017181005\n",
      "Validation Loss: 0.06674676\n",
      "Epoch: 4503 cost = 0.017180495\n",
      "Validation Loss: 0.05649186\n",
      "Epoch: 4504 cost = 0.017179884\n",
      "Validation Loss: 0.047481786\n",
      "Epoch: 4505 cost = 0.017179189\n",
      "Validation Loss: 0.04686602\n",
      "Epoch: 4506 cost = 0.017179116\n",
      "Validation Loss: 0.059958313\n",
      "Epoch: 4507 cost = 0.017178551\n",
      "Validation Loss: 0.06075848\n",
      "Epoch: 4508 cost = 0.017177500\n",
      "Validation Loss: 0.050061796\n",
      "Epoch: 4509 cost = 0.017177722\n",
      "Validation Loss: 0.04235006\n",
      "Epoch: 4510 cost = 0.017177083\n",
      "Validation Loss: 0.034412086\n",
      "Epoch: 4511 cost = 0.017175860\n",
      "Validation Loss: 0.029029125\n",
      "Epoch: 4512 cost = 0.017175932\n",
      "Validation Loss: 0.0445657\n",
      "Epoch: 4513 cost = 0.017175572\n",
      "Validation Loss: 0.040289868\n",
      "Epoch: 4514 cost = 0.017174777\n",
      "Validation Loss: 0.037425555\n",
      "Epoch: 4515 cost = 0.017174394\n",
      "Validation Loss: 0.048590437\n",
      "Epoch: 4516 cost = 0.017173904\n",
      "Validation Loss: 0.08103884\n",
      "Epoch: 4517 cost = 0.017173758\n",
      "Validation Loss: 0.12478181\n",
      "Epoch: 4518 cost = 0.017172131\n",
      "Validation Loss: 0.11314732\n",
      "Epoch: 4519 cost = 0.017172109\n",
      "Validation Loss: 0.037506014\n",
      "Epoch: 4520 cost = 0.017172023\n",
      "Validation Loss: 0.025058115\n",
      "Epoch: 4521 cost = 0.017171388\n",
      "Validation Loss: 0.036637634\n",
      "Epoch: 4522 cost = 0.017170627\n",
      "Validation Loss: 0.06592517\n",
      "Epoch: 4523 cost = 0.017169711\n",
      "Validation Loss: 0.076262005\n",
      "Epoch: 4524 cost = 0.017169771\n",
      "Validation Loss: 0.07058391\n",
      "Epoch: 4525 cost = 0.017169138\n",
      "Validation Loss: 0.053242024\n",
      "Epoch: 4526 cost = 0.017168335\n",
      "Validation Loss: 0.054472376\n",
      "Epoch: 4527 cost = 0.017168203\n",
      "Validation Loss: 0.038756598\n",
      "Epoch: 4528 cost = 0.017167660\n",
      "Validation Loss: 0.032700468\n",
      "Epoch: 4529 cost = 0.017166950\n",
      "Validation Loss: 0.03310662\n",
      "Epoch: 4530 cost = 0.017166658\n",
      "Validation Loss: 0.032781035\n",
      "Epoch: 4531 cost = 0.017166354\n",
      "Validation Loss: 0.028460449\n",
      "Epoch: 4532 cost = 0.017165873\n",
      "Validation Loss: 0.051331624\n",
      "Epoch: 4533 cost = 0.017165423\n",
      "Validation Loss: 0.045984436\n",
      "Epoch: 4534 cost = 0.017164984\n",
      "Validation Loss: 0.04866486\n",
      "Epoch: 4535 cost = 0.017163826\n",
      "Validation Loss: 0.044259097\n",
      "Epoch: 4536 cost = 0.017163603\n",
      "Validation Loss: 0.055098604\n",
      "Epoch: 4537 cost = 0.017163373\n",
      "Validation Loss: 0.085501745\n",
      "Epoch: 4538 cost = 0.017163192\n",
      "Validation Loss: 0.114283524\n",
      "Epoch: 4539 cost = 0.017162472\n",
      "Validation Loss: 0.10390433\n",
      "Epoch: 4540 cost = 0.017162261\n",
      "Validation Loss: 0.09240394\n",
      "Epoch: 4541 cost = 0.017161397\n",
      "Validation Loss: 0.08820784\n",
      "Epoch: 4542 cost = 0.017161290\n",
      "Validation Loss: 0.06646587\n",
      "Epoch: 4543 cost = 0.017160846\n",
      "Validation Loss: 0.042610776\n",
      "Epoch: 4544 cost = 0.017160377\n",
      "Validation Loss: 0.033714864\n",
      "Epoch: 4545 cost = 0.017159899\n",
      "Validation Loss: 0.026043162\n",
      "Epoch: 4546 cost = 0.017159480\n",
      "Validation Loss: 0.043144573\n",
      "Epoch: 4547 cost = 0.017159231\n",
      "Validation Loss: 0.052562684\n",
      "Epoch: 4548 cost = 0.017158295\n",
      "Validation Loss: 0.048121564\n",
      "Epoch: 4549 cost = 0.017157819\n",
      "Validation Loss: 0.043603055\n",
      "Epoch: 4550 cost = 0.017157193\n",
      "Validation Loss: 0.039762907\n",
      "Epoch: 4551 cost = 0.017156805\n",
      "Validation Loss: 0.042469084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4552 cost = 0.017155877\n",
      "Validation Loss: 0.034749657\n",
      "Epoch: 4553 cost = 0.017155672\n",
      "Validation Loss: 0.026659524\n",
      "Epoch: 4554 cost = 0.017155170\n",
      "Validation Loss: 0.016860964\n",
      "Epoch: 4555 cost = 0.017154849\n",
      "Validation Loss: 0.06614633\n",
      "Epoch: 4556 cost = 0.017153928\n",
      "Validation Loss: 0.058523633\n",
      "Epoch: 4557 cost = 0.017153584\n",
      "Validation Loss: 0.045580257\n",
      "Epoch: 4558 cost = 0.017153068\n",
      "Validation Loss: 0.045733184\n",
      "Epoch: 4559 cost = 0.017152381\n",
      "Validation Loss: 0.039136183\n",
      "Epoch: 4560 cost = 0.017151945\n",
      "Validation Loss: 0.04104745\n",
      "Epoch: 4561 cost = 0.017151353\n",
      "Validation Loss: 0.043806348\n",
      "Epoch: 4562 cost = 0.017151405\n",
      "Validation Loss: 0.059882022\n",
      "Epoch: 4563 cost = 0.017151015\n",
      "Validation Loss: 0.074386194\n",
      "Epoch: 4564 cost = 0.017150187\n",
      "Validation Loss: 0.048342686\n",
      "Epoch: 4565 cost = 0.017149580\n",
      "Validation Loss: 0.03892628\n",
      "Epoch: 4566 cost = 0.017148871\n",
      "Validation Loss: 0.04160676\n",
      "Epoch: 4567 cost = 0.017148928\n",
      "Validation Loss: 0.077997744\n",
      "Epoch: 4568 cost = 0.017148028\n",
      "Validation Loss: 0.047387797\n",
      "Epoch: 4569 cost = 0.017147554\n",
      "Validation Loss: 0.042348295\n",
      "Epoch: 4570 cost = 0.017147413\n",
      "Validation Loss: 0.034716576\n",
      "Epoch: 4571 cost = 0.017147217\n",
      "Validation Loss: 0.039912514\n",
      "Epoch: 4572 cost = 0.017146419\n",
      "Validation Loss: 0.040088534\n",
      "Epoch: 4573 cost = 0.017145912\n",
      "Validation Loss: 0.04166801\n",
      "Epoch: 4574 cost = 0.017145196\n",
      "Validation Loss: 0.038399015\n",
      "Epoch: 4575 cost = 0.017144978\n",
      "Validation Loss: 0.027161555\n",
      "Epoch: 4576 cost = 0.017144130\n",
      "Validation Loss: 0.038028236\n",
      "Epoch: 4577 cost = 0.017143912\n",
      "Validation Loss: 0.05887792\n",
      "Epoch: 4578 cost = 0.017143120\n",
      "Validation Loss: 0.0764421\n",
      "Epoch: 4579 cost = 0.017143009\n",
      "Validation Loss: 0.0780598\n",
      "Epoch: 4580 cost = 0.017143218\n",
      "Validation Loss: 0.053956088\n",
      "Epoch: 4581 cost = 0.017142130\n",
      "Validation Loss: 0.043180242\n",
      "Epoch: 4582 cost = 0.017141186\n",
      "Validation Loss: 0.04593344\n",
      "Epoch: 4583 cost = 0.017141205\n",
      "Validation Loss: 0.05903255\n",
      "Epoch: 4584 cost = 0.017140690\n",
      "Validation Loss: 0.051341537\n",
      "Epoch: 4585 cost = 0.017140647\n",
      "Validation Loss: 0.03938669\n",
      "Epoch: 4586 cost = 0.017139603\n",
      "Validation Loss: 0.031118816\n",
      "Epoch: 4587 cost = 0.017139452\n",
      "Validation Loss: 0.045511074\n",
      "Epoch: 4588 cost = 0.017138820\n",
      "Validation Loss: 0.04217374\n",
      "Epoch: 4589 cost = 0.017138381\n",
      "Validation Loss: 0.031531602\n",
      "Epoch: 4590 cost = 0.017137709\n",
      "Validation Loss: 0.033232816\n",
      "Epoch: 4591 cost = 0.017137490\n",
      "Validation Loss: 0.028493116\n",
      "Epoch: 4592 cost = 0.017137067\n",
      "Validation Loss: 0.043290947\n",
      "Epoch: 4593 cost = 0.017135787\n",
      "Validation Loss: 0.06149692\n",
      "Epoch: 4594 cost = 0.017136133\n",
      "Validation Loss: 0.053603712\n",
      "Epoch: 4595 cost = 0.017135136\n",
      "Validation Loss: 0.04318076\n",
      "Epoch: 4596 cost = 0.017134642\n",
      "Validation Loss: 0.04072323\n",
      "Epoch: 4597 cost = 0.017133841\n",
      "Validation Loss: 0.035635106\n",
      "Epoch: 4598 cost = 0.017133876\n",
      "Validation Loss: 0.026013386\n",
      "Epoch: 4599 cost = 0.017132776\n",
      "Validation Loss: 0.028690265\n",
      "Epoch: 4600 cost = 0.017132612\n",
      "Validation Loss: 0.0398259\n",
      "Epoch: 4601 cost = 0.017131952\n",
      "Validation Loss: 0.044153508\n",
      "Epoch: 4602 cost = 0.017132073\n",
      "Validation Loss: 0.04705943\n",
      "Epoch: 4603 cost = 0.017131692\n",
      "Validation Loss: 0.04237911\n",
      "Epoch: 4604 cost = 0.017130668\n",
      "Validation Loss: 0.04651544\n",
      "Epoch: 4605 cost = 0.017130509\n",
      "Validation Loss: 0.052929357\n",
      "Epoch: 4606 cost = 0.017129604\n",
      "Validation Loss: 0.042695317\n",
      "Epoch: 4607 cost = 0.017129774\n",
      "Validation Loss: 0.048597727\n",
      "Epoch: 4608 cost = 0.017129368\n",
      "Validation Loss: 0.058062587\n",
      "Epoch: 4609 cost = 0.017128992\n",
      "Validation Loss: 0.052535184\n",
      "Epoch: 4610 cost = 0.017128083\n",
      "Validation Loss: 0.08014924\n",
      "Epoch: 4611 cost = 0.017128038\n",
      "Validation Loss: 0.06687555\n",
      "Epoch: 4612 cost = 0.017127636\n",
      "Validation Loss: 0.05550094\n",
      "Epoch: 4613 cost = 0.017126834\n",
      "Validation Loss: 0.075319976\n",
      "Epoch: 4614 cost = 0.017126819\n",
      "Validation Loss: 0.06976209\n",
      "Epoch: 4615 cost = 0.017125630\n",
      "Validation Loss: 0.053034484\n",
      "Epoch: 4616 cost = 0.017125084\n",
      "Validation Loss: 0.045051448\n",
      "Epoch: 4617 cost = 0.017125282\n",
      "Validation Loss: 0.04309568\n",
      "Epoch: 4618 cost = 0.017124685\n",
      "Validation Loss: 0.06375629\n",
      "Epoch: 4619 cost = 0.017123882\n",
      "Validation Loss: 0.06213712\n",
      "Epoch: 4620 cost = 0.017123845\n",
      "Validation Loss: 0.056779537\n",
      "Epoch: 4621 cost = 0.017123201\n",
      "Validation Loss: 0.049510155\n",
      "Epoch: 4622 cost = 0.017122398\n",
      "Validation Loss: 0.050661888\n",
      "Epoch: 4623 cost = 0.017122150\n",
      "Validation Loss: 0.04003411\n",
      "Epoch: 4624 cost = 0.017121471\n",
      "Validation Loss: 0.041635025\n",
      "Epoch: 4625 cost = 0.017120784\n",
      "Validation Loss: 0.04339422\n",
      "Epoch: 4626 cost = 0.017120439\n",
      "Validation Loss: 0.04497754\n",
      "Epoch: 4627 cost = 0.017119632\n",
      "Validation Loss: 0.026291892\n",
      "Epoch: 4628 cost = 0.017119368\n",
      "Validation Loss: 0.03373858\n",
      "Epoch: 4629 cost = 0.017118846\n",
      "Validation Loss: 0.039651964\n",
      "Epoch: 4630 cost = 0.017118298\n",
      "Validation Loss: 0.050522167\n",
      "Epoch: 4631 cost = 0.017118151\n",
      "Validation Loss: 0.052904356\n",
      "Epoch: 4632 cost = 0.017117436\n",
      "Validation Loss: 0.057199806\n",
      "Epoch: 4633 cost = 0.017117228\n",
      "Validation Loss: 0.05018825\n",
      "Epoch: 4634 cost = 0.017117285\n",
      "Validation Loss: 0.04500461\n",
      "Epoch: 4635 cost = 0.017116220\n",
      "Validation Loss: 0.036488216\n",
      "Epoch: 4636 cost = 0.017116141\n",
      "Validation Loss: 0.04599928\n",
      "Epoch: 4637 cost = 0.017115659\n",
      "Validation Loss: 0.06946146\n",
      "Epoch: 4638 cost = 0.017115287\n",
      "Validation Loss: 0.06889617\n",
      "Epoch: 4639 cost = 0.017114827\n",
      "Validation Loss: 0.060813203\n",
      "Epoch: 4640 cost = 0.017113400\n",
      "Validation Loss: 0.051747568\n",
      "Epoch: 4641 cost = 0.017113501\n",
      "Validation Loss: 0.052170023\n",
      "Epoch: 4642 cost = 0.017112423\n",
      "Validation Loss: 0.058440123\n",
      "Epoch: 4643 cost = 0.017112940\n",
      "Validation Loss: 0.06696395\n",
      "Epoch: 4644 cost = 0.017112096\n",
      "Validation Loss: 0.053162538\n",
      "Epoch: 4645 cost = 0.017112246\n",
      "Validation Loss: 0.03917002\n",
      "Epoch: 4646 cost = 0.017111247\n",
      "Validation Loss: 0.03060782\n",
      "Epoch: 4647 cost = 0.017110978\n",
      "Validation Loss: 0.034127537\n",
      "Epoch: 4648 cost = 0.017109661\n",
      "Validation Loss: 0.05758763\n",
      "Epoch: 4649 cost = 0.017109146\n",
      "Validation Loss: 0.0644524\n",
      "Epoch: 4650 cost = 0.017109279\n",
      "Validation Loss: 0.059601013\n",
      "Epoch: 4651 cost = 0.017109082\n",
      "Validation Loss: 0.04768072\n",
      "Epoch: 4652 cost = 0.017107718\n",
      "Validation Loss: 0.04178375\n",
      "Epoch: 4653 cost = 0.017107668\n",
      "Validation Loss: 0.038837697\n",
      "Epoch: 4654 cost = 0.017107336\n",
      "Validation Loss: 0.05216573\n",
      "Epoch: 4655 cost = 0.017107062\n",
      "Validation Loss: 0.0473954\n",
      "Epoch: 4656 cost = 0.017106174\n",
      "Validation Loss: 0.04414844\n",
      "Epoch: 4657 cost = 0.017105570\n",
      "Validation Loss: 0.055923752\n",
      "Epoch: 4658 cost = 0.017105281\n",
      "Validation Loss: 0.057885148\n",
      "Epoch: 4659 cost = 0.017105142\n",
      "Validation Loss: 0.06649651\n",
      "Epoch: 4660 cost = 0.017104282\n",
      "Validation Loss: 0.05028743\n",
      "Epoch: 4661 cost = 0.017103693\n",
      "Validation Loss: 0.052833777\n",
      "Epoch: 4662 cost = 0.017103862\n",
      "Validation Loss: 0.057457577\n",
      "Epoch: 4663 cost = 0.017103371\n",
      "Validation Loss: 0.042645637\n",
      "Epoch: 4664 cost = 0.017102732\n",
      "Validation Loss: 0.03347216\n",
      "Epoch: 4665 cost = 0.017102803\n",
      "Validation Loss: 0.033891223\n",
      "Epoch: 4666 cost = 0.017101822\n",
      "Validation Loss: 0.028197557\n",
      "Epoch: 4667 cost = 0.017100927\n",
      "Validation Loss: 0.032670766\n",
      "Epoch: 4668 cost = 0.017100345\n",
      "Validation Loss: 0.04484109\n",
      "Epoch: 4669 cost = 0.017100284\n",
      "Validation Loss: 0.057952818\n",
      "Epoch: 4670 cost = 0.017100129\n",
      "Validation Loss: 0.050882284\n",
      "Epoch: 4671 cost = 0.017099611\n",
      "Validation Loss: 0.02843191\n",
      "Epoch: 4672 cost = 0.017099095\n",
      "Validation Loss: 0.030259091\n",
      "Epoch: 4673 cost = 0.017098652\n",
      "Validation Loss: 0.038599476\n",
      "Epoch: 4674 cost = 0.017098144\n",
      "Validation Loss: 0.03616556\n",
      "Epoch: 4675 cost = 0.017097696\n",
      "Validation Loss: 0.030864563\n",
      "Epoch: 4676 cost = 0.017097614\n",
      "Validation Loss: 0.026014982\n",
      "Epoch: 4677 cost = 0.017096476\n",
      "Validation Loss: 0.034444127\n",
      "Epoch: 4678 cost = 0.017096839\n",
      "Validation Loss: 0.040769555\n",
      "Epoch: 4679 cost = 0.017095223\n",
      "Validation Loss: 0.032519642\n",
      "Epoch: 4680 cost = 0.017095223\n",
      "Validation Loss: 0.029168528\n",
      "Epoch: 4681 cost = 0.017094779\n",
      "Validation Loss: 0.035151195\n",
      "Epoch: 4682 cost = 0.017094904\n",
      "Validation Loss: 0.042133838\n",
      "Epoch: 4683 cost = 0.017093841\n",
      "Validation Loss: 0.050572693\n",
      "Epoch: 4684 cost = 0.017093306\n",
      "Validation Loss: 0.049416225\n",
      "Epoch: 4685 cost = 0.017093053\n",
      "Validation Loss: 0.038791046\n",
      "Epoch: 4686 cost = 0.017092410\n",
      "Validation Loss: 0.031134445\n",
      "Epoch: 4687 cost = 0.017091456\n",
      "Validation Loss: 0.038586274\n",
      "Epoch: 4688 cost = 0.017091785\n",
      "Validation Loss: 0.041289065\n",
      "Epoch: 4689 cost = 0.017090602\n",
      "Validation Loss: 0.05085334\n",
      "Epoch: 4690 cost = 0.017090446\n",
      "Validation Loss: 0.034667604\n",
      "Epoch: 4691 cost = 0.017089876\n",
      "Validation Loss: 0.04715637\n",
      "Epoch: 4692 cost = 0.017089470\n",
      "Validation Loss: 0.05163595\n",
      "Epoch: 4693 cost = 0.017088995\n",
      "Validation Loss: 0.0540334\n",
      "Epoch: 4694 cost = 0.017088739\n",
      "Validation Loss: 0.047964267\n",
      "Epoch: 4695 cost = 0.017088482\n",
      "Validation Loss: 0.05201554\n",
      "Epoch: 4696 cost = 0.017087814\n",
      "Validation Loss: 0.04193102\n",
      "Epoch: 4697 cost = 0.017086877\n",
      "Validation Loss: 0.037470784\n",
      "Epoch: 4698 cost = 0.017086922\n",
      "Validation Loss: 0.03302756\n",
      "Epoch: 4699 cost = 0.017086200\n",
      "Validation Loss: 0.029218277\n",
      "Epoch: 4700 cost = 0.017085937\n",
      "Validation Loss: 0.04070901\n",
      "Epoch: 4701 cost = 0.017085533\n",
      "Validation Loss: 0.057916068\n",
      "Epoch: 4702 cost = 0.017085752\n",
      "Validation Loss: 0.056083813\n",
      "Epoch: 4703 cost = 0.017084671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.054820843\n",
      "Epoch: 4704 cost = 0.017084303\n",
      "Validation Loss: 0.033345733\n",
      "Epoch: 4705 cost = 0.017084101\n",
      "Validation Loss: 0.034372255\n",
      "Epoch: 4706 cost = 0.017083292\n",
      "Validation Loss: 0.038018286\n",
      "Epoch: 4707 cost = 0.017083091\n",
      "Validation Loss: 0.064770654\n",
      "Epoch: 4708 cost = 0.017082450\n",
      "Validation Loss: 0.09540022\n",
      "Epoch: 4709 cost = 0.017081953\n",
      "Validation Loss: 0.10869691\n",
      "Epoch: 4710 cost = 0.017081502\n",
      "Validation Loss: 0.079177216\n",
      "Epoch: 4711 cost = 0.017080489\n",
      "Validation Loss: 0.032293953\n",
      "Epoch: 4712 cost = 0.017080033\n",
      "Validation Loss: 0.027645856\n",
      "Epoch: 4713 cost = 0.017079822\n",
      "Validation Loss: 0.052716102\n",
      "Epoch: 4714 cost = 0.017079188\n",
      "Validation Loss: 0.07680865\n",
      "Epoch: 4715 cost = 0.017079094\n",
      "Validation Loss: 0.04948392\n",
      "Epoch: 4716 cost = 0.017078554\n",
      "Validation Loss: 0.044803865\n",
      "Epoch: 4717 cost = 0.017078106\n",
      "Validation Loss: 0.06430885\n",
      "Epoch: 4718 cost = 0.017077844\n",
      "Validation Loss: 0.042828567\n",
      "Epoch: 4719 cost = 0.017076672\n",
      "Validation Loss: 0.03616513\n",
      "Epoch: 4720 cost = 0.017076588\n",
      "Validation Loss: 0.03942317\n",
      "Epoch: 4721 cost = 0.017075916\n",
      "Validation Loss: 0.041362103\n",
      "Epoch: 4722 cost = 0.017075291\n",
      "Validation Loss: 0.04492752\n",
      "Epoch: 4723 cost = 0.017075029\n",
      "Validation Loss: 0.04221284\n",
      "Epoch: 4724 cost = 0.017074556\n",
      "Validation Loss: 0.044565137\n",
      "Epoch: 4725 cost = 0.017074875\n",
      "Validation Loss: 0.050276645\n",
      "Epoch: 4726 cost = 0.017073823\n",
      "Validation Loss: 0.03995424\n",
      "Epoch: 4727 cost = 0.017073415\n",
      "Validation Loss: 0.03952309\n",
      "Epoch: 4728 cost = 0.017073347\n",
      "Validation Loss: 0.025246283\n",
      "Epoch: 4729 cost = 0.017072553\n",
      "Validation Loss: 0.03574813\n",
      "Epoch: 4730 cost = 0.017072126\n",
      "Validation Loss: 0.044267446\n",
      "Epoch: 4731 cost = 0.017071648\n",
      "Validation Loss: 0.048436854\n",
      "Epoch: 4732 cost = 0.017071698\n",
      "Validation Loss: 0.042092383\n",
      "Epoch: 4733 cost = 0.017071335\n",
      "Validation Loss: 0.04923105\n",
      "Epoch: 4734 cost = 0.017070363\n",
      "Validation Loss: 0.05394774\n",
      "Epoch: 4735 cost = 0.017070113\n",
      "Validation Loss: 0.047785107\n",
      "Epoch: 4736 cost = 0.017069173\n",
      "Validation Loss: 0.04468766\n",
      "Epoch: 4737 cost = 0.017068854\n",
      "Validation Loss: 0.043377716\n",
      "Epoch: 4738 cost = 0.017068850\n",
      "Validation Loss: 0.048679627\n",
      "Epoch: 4739 cost = 0.017068473\n",
      "Validation Loss: 0.038314406\n",
      "Epoch: 4740 cost = 0.017067517\n",
      "Validation Loss: 0.041001298\n",
      "Epoch: 4741 cost = 0.017066970\n",
      "Validation Loss: 0.043894995\n",
      "Epoch: 4742 cost = 0.017066741\n",
      "Validation Loss: 0.045585867\n",
      "Epoch: 4743 cost = 0.017066745\n",
      "Validation Loss: 0.048819117\n",
      "Epoch: 4744 cost = 0.017065389\n",
      "Validation Loss: 0.043031577\n",
      "Epoch: 4745 cost = 0.017065589\n",
      "Validation Loss: 0.027698215\n",
      "Epoch: 4746 cost = 0.017064474\n",
      "Validation Loss: 0.020084072\n",
      "Epoch: 4747 cost = 0.017064442\n",
      "Validation Loss: 0.028451635\n",
      "Epoch: 4748 cost = 0.017063677\n",
      "Validation Loss: 0.037259586\n",
      "Epoch: 4749 cost = 0.017063313\n",
      "Validation Loss: 0.04388045\n",
      "Epoch: 4750 cost = 0.017062939\n",
      "Validation Loss: 0.034494694\n",
      "Epoch: 4751 cost = 0.017062342\n",
      "Validation Loss: 0.041608702\n",
      "Epoch: 4752 cost = 0.017061924\n",
      "Validation Loss: 0.048723202\n",
      "Epoch: 4753 cost = 0.017061324\n",
      "Validation Loss: 0.03812846\n",
      "Epoch: 4754 cost = 0.017061013\n",
      "Validation Loss: 0.054500412\n",
      "Epoch: 4755 cost = 0.017060811\n",
      "Validation Loss: 0.07501668\n",
      "Epoch: 4756 cost = 0.017059987\n",
      "Validation Loss: 0.05684154\n",
      "Epoch: 4757 cost = 0.017059771\n",
      "Validation Loss: 0.07313209\n",
      "Epoch: 4758 cost = 0.017059085\n",
      "Validation Loss: 0.07770883\n",
      "Epoch: 4759 cost = 0.017058834\n",
      "Validation Loss: 0.059701458\n",
      "Epoch: 4760 cost = 0.017058244\n",
      "Validation Loss: 0.046981912\n",
      "Epoch: 4761 cost = 0.017057690\n",
      "Validation Loss: 0.06153384\n",
      "Epoch: 4762 cost = 0.017057405\n",
      "Validation Loss: 0.05687415\n",
      "Epoch: 4763 cost = 0.017056686\n",
      "Validation Loss: 0.037507173\n",
      "Epoch: 4764 cost = 0.017056078\n",
      "Validation Loss: 0.025416115\n",
      "Epoch: 4765 cost = 0.017056439\n",
      "Validation Loss: 0.041097257\n",
      "Epoch: 4766 cost = 0.017055516\n",
      "Validation Loss: 0.044491615\n",
      "Epoch: 4767 cost = 0.017054792\n",
      "Validation Loss: 0.052932978\n",
      "Epoch: 4768 cost = 0.017054852\n",
      "Validation Loss: 0.049665026\n",
      "Epoch: 4769 cost = 0.017054789\n",
      "Validation Loss: 0.051505923\n",
      "Epoch: 4770 cost = 0.017054138\n",
      "Validation Loss: 0.04005242\n",
      "Epoch: 4771 cost = 0.017053567\n",
      "Validation Loss: 0.033154223\n",
      "Epoch: 4772 cost = 0.017053067\n",
      "Validation Loss: 0.055625327\n",
      "Epoch: 4773 cost = 0.017052461\n",
      "Validation Loss: 0.038066354\n",
      "Epoch: 4774 cost = 0.017051739\n",
      "Validation Loss: 0.03842122\n",
      "Epoch: 4775 cost = 0.017051416\n",
      "Validation Loss: 0.05433124\n",
      "Epoch: 4776 cost = 0.017051787\n",
      "Validation Loss: 0.038039263\n",
      "Epoch: 4777 cost = 0.017050983\n",
      "Validation Loss: 0.045150045\n",
      "Epoch: 4778 cost = 0.017050241\n",
      "Validation Loss: 0.044712394\n",
      "Epoch: 4779 cost = 0.017049711\n",
      "Validation Loss: 0.03978754\n",
      "Epoch: 4780 cost = 0.017049454\n",
      "Validation Loss: 0.04561821\n",
      "Epoch: 4781 cost = 0.017049361\n",
      "Validation Loss: 0.05233457\n",
      "Epoch: 4782 cost = 0.017048542\n",
      "Validation Loss: 0.056567647\n",
      "Epoch: 4783 cost = 0.017047837\n",
      "Validation Loss: 0.055507857\n",
      "Epoch: 4784 cost = 0.017047947\n",
      "Validation Loss: 0.0503795\n",
      "Epoch: 4785 cost = 0.017047361\n",
      "Validation Loss: 0.055781957\n",
      "Epoch: 4786 cost = 0.017046351\n",
      "Validation Loss: 0.060900796\n",
      "Epoch: 4787 cost = 0.017045938\n",
      "Validation Loss: 0.048406802\n",
      "Epoch: 4788 cost = 0.017045311\n",
      "Validation Loss: 0.03360193\n",
      "Epoch: 4789 cost = 0.017045131\n",
      "Validation Loss: 0.039585713\n",
      "Epoch: 4790 cost = 0.017044664\n",
      "Validation Loss: 0.053589385\n",
      "Epoch: 4791 cost = 0.017044815\n",
      "Validation Loss: 0.050308365\n",
      "Epoch: 4792 cost = 0.017043593\n",
      "Validation Loss: 0.040908273\n",
      "Epoch: 4793 cost = 0.017043259\n",
      "Validation Loss: 0.04639296\n",
      "Epoch: 4794 cost = 0.017043293\n",
      "Validation Loss: 0.038321685\n",
      "Epoch: 4795 cost = 0.017042242\n",
      "Validation Loss: 0.038955573\n",
      "Epoch: 4796 cost = 0.017041774\n",
      "Validation Loss: 0.052605446\n",
      "Epoch: 4797 cost = 0.017041012\n",
      "Validation Loss: 0.04406917\n",
      "Epoch: 4798 cost = 0.017041255\n",
      "Validation Loss: 0.03987097\n",
      "Epoch: 4799 cost = 0.017040344\n",
      "Validation Loss: 0.04558882\n",
      "Epoch: 4800 cost = 0.017040038\n",
      "Validation Loss: 0.067503154\n",
      "Epoch: 4801 cost = 0.017039601\n",
      "Validation Loss: 0.06470674\n",
      "Epoch: 4802 cost = 0.017038867\n",
      "Validation Loss: 0.048685364\n",
      "Epoch: 4803 cost = 0.017038727\n",
      "Validation Loss: 0.03764036\n",
      "Epoch: 4804 cost = 0.017038093\n",
      "Validation Loss: 0.055866167\n",
      "Epoch: 4805 cost = 0.017037866\n",
      "Validation Loss: 0.051503617\n",
      "Epoch: 4806 cost = 0.017037578\n",
      "Validation Loss: 0.047983542\n",
      "Epoch: 4807 cost = 0.017037035\n",
      "Validation Loss: 0.053224944\n",
      "Epoch: 4808 cost = 0.017036977\n",
      "Validation Loss: 0.07419505\n",
      "Epoch: 4809 cost = 0.017036289\n",
      "Validation Loss: 0.08275365\n",
      "Epoch: 4810 cost = 0.017035653\n",
      "Validation Loss: 0.06211273\n",
      "Epoch: 4811 cost = 0.017035483\n",
      "Validation Loss: 0.06371466\n",
      "Epoch: 4812 cost = 0.017035233\n",
      "Validation Loss: 0.05808239\n",
      "Epoch: 4813 cost = 0.017034511\n",
      "Validation Loss: 0.056795757\n",
      "Epoch: 4814 cost = 0.017034534\n",
      "Validation Loss: 0.05812516\n",
      "Epoch: 4815 cost = 0.017033733\n",
      "Validation Loss: 0.04205845\n",
      "Epoch: 4816 cost = 0.017033029\n",
      "Validation Loss: 0.045372687\n",
      "Epoch: 4817 cost = 0.017033196\n",
      "Validation Loss: 0.05740252\n",
      "Epoch: 4818 cost = 0.017032285\n",
      "Validation Loss: 0.054369595\n",
      "Epoch: 4819 cost = 0.017031919\n",
      "Validation Loss: 0.052367438\n",
      "Epoch: 4820 cost = 0.017031621\n",
      "Validation Loss: 0.053378396\n",
      "Epoch: 4821 cost = 0.017031373\n",
      "Validation Loss: 0.063627034\n",
      "Epoch: 4822 cost = 0.017030590\n",
      "Validation Loss: 0.03794623\n",
      "Epoch: 4823 cost = 0.017030920\n",
      "Validation Loss: 0.03500186\n",
      "Epoch: 4824 cost = 0.017029394\n",
      "Validation Loss: 0.05029434\n",
      "Epoch: 4825 cost = 0.017029299\n",
      "Validation Loss: 0.062118962\n",
      "Epoch: 4826 cost = 0.017029176\n",
      "Validation Loss: 0.055951368\n",
      "Epoch: 4827 cost = 0.017028864\n",
      "Validation Loss: 0.052692488\n",
      "Epoch: 4828 cost = 0.017028304\n",
      "Validation Loss: 0.029929632\n",
      "Epoch: 4829 cost = 0.017027549\n",
      "Validation Loss: 0.040879566\n",
      "Epoch: 4830 cost = 0.017026843\n",
      "Validation Loss: 0.055315048\n",
      "Epoch: 4831 cost = 0.017026070\n",
      "Validation Loss: 0.0606602\n",
      "Epoch: 4832 cost = 0.017025497\n",
      "Validation Loss: 0.045438368\n",
      "Epoch: 4833 cost = 0.017025009\n",
      "Validation Loss: 0.048677474\n",
      "Epoch: 4834 cost = 0.017024558\n",
      "Validation Loss: 0.039043125\n",
      "Epoch: 4835 cost = 0.017024447\n",
      "Validation Loss: 0.040389795\n",
      "Epoch: 4836 cost = 0.017023972\n",
      "Validation Loss: 0.057341896\n",
      "Epoch: 4837 cost = 0.017023106\n",
      "Validation Loss: 0.070542835\n",
      "Epoch: 4838 cost = 0.017022845\n",
      "Validation Loss: 0.074053235\n",
      "Epoch: 4839 cost = 0.017022225\n",
      "Validation Loss: 0.08658122\n",
      "Epoch: 4840 cost = 0.017021598\n",
      "Validation Loss: 0.077946484\n",
      "Epoch: 4841 cost = 0.017021220\n",
      "Validation Loss: 0.045715068\n",
      "Epoch: 4842 cost = 0.017020226\n",
      "Validation Loss: 0.050794955\n",
      "Epoch: 4843 cost = 0.017020050\n",
      "Validation Loss: 0.044812266\n",
      "Epoch: 4844 cost = 0.017020201\n",
      "Validation Loss: 0.036394455\n",
      "Epoch: 4845 cost = 0.017019643\n",
      "Validation Loss: 0.04212138\n",
      "Epoch: 4846 cost = 0.017018978\n",
      "Validation Loss: 0.05585785\n",
      "Epoch: 4847 cost = 0.017018218\n",
      "Validation Loss: 0.07554851\n",
      "Epoch: 4848 cost = 0.017018156\n",
      "Validation Loss: 0.06903471\n",
      "Epoch: 4849 cost = 0.017018000\n",
      "Validation Loss: 0.07141361\n",
      "Epoch: 4850 cost = 0.017017296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0889287\n",
      "Epoch: 4851 cost = 0.017017830\n",
      "Validation Loss: 0.10221798\n",
      "Epoch: 4852 cost = 0.017017400\n",
      "Validation Loss: 0.06581681\n",
      "Epoch: 4853 cost = 0.017017435\n",
      "Validation Loss: 0.046667945\n",
      "Epoch: 4854 cost = 0.017016777\n",
      "Validation Loss: 0.04237946\n",
      "Epoch: 4855 cost = 0.017016823\n",
      "Validation Loss: 0.032572456\n",
      "Epoch: 4856 cost = 0.017016489\n",
      "Validation Loss: 0.02775594\n",
      "Epoch: 4857 cost = 0.017015836\n",
      "Validation Loss: 0.030605055\n",
      "Epoch: 4858 cost = 0.017015909\n",
      "Validation Loss: 0.03399375\n",
      "Epoch: 4859 cost = 0.017015529\n",
      "Validation Loss: 0.038357336\n",
      "Epoch: 4860 cost = 0.017014655\n",
      "Validation Loss: 0.051539022\n",
      "Epoch: 4861 cost = 0.017014153\n",
      "Validation Loss: 0.04771665\n",
      "Epoch: 4862 cost = 0.017014182\n",
      "Validation Loss: 0.036098294\n",
      "Epoch: 4863 cost = 0.017013265\n",
      "Validation Loss: 0.057340004\n",
      "Epoch: 4864 cost = 0.017013581\n",
      "Validation Loss: 0.067552425\n",
      "Epoch: 4865 cost = 0.017012273\n",
      "Validation Loss: 0.054881167\n",
      "Epoch: 4866 cost = 0.017011975\n",
      "Validation Loss: 0.05808888\n",
      "Epoch: 4867 cost = 0.017010858\n",
      "Validation Loss: 0.06103842\n",
      "Epoch: 4868 cost = 0.017010285\n",
      "Validation Loss: 0.07486038\n",
      "Epoch: 4869 cost = 0.017009815\n",
      "Validation Loss: 0.0657196\n",
      "Epoch: 4870 cost = 0.017009043\n",
      "Validation Loss: 0.066449806\n",
      "Epoch: 4871 cost = 0.017007743\n",
      "Validation Loss: 0.07085908\n",
      "Epoch: 4872 cost = 0.017007805\n",
      "Validation Loss: 0.05617318\n",
      "Epoch: 4873 cost = 0.017006721\n",
      "Validation Loss: 0.041544124\n",
      "Epoch: 4874 cost = 0.017005940\n",
      "Validation Loss: 0.040849995\n",
      "Epoch: 4875 cost = 0.017005487\n",
      "Validation Loss: 0.048811786\n",
      "Epoch: 4876 cost = 0.017004354\n",
      "Validation Loss: 0.048764803\n",
      "Epoch: 4877 cost = 0.017004469\n",
      "Validation Loss: 0.05615303\n",
      "Epoch: 4878 cost = 0.017003899\n",
      "Validation Loss: 0.067370325\n",
      "Epoch: 4879 cost = 0.017003293\n",
      "Validation Loss: 0.08010841\n",
      "Epoch: 4880 cost = 0.017002419\n",
      "Validation Loss: 0.07428599\n",
      "Epoch: 4881 cost = 0.017002155\n",
      "Validation Loss: 0.0657326\n",
      "Epoch: 4882 cost = 0.017001237\n",
      "Validation Loss: 0.03616501\n",
      "Epoch: 4883 cost = 0.017001336\n",
      "Validation Loss: 0.060021322\n",
      "Epoch: 4884 cost = 0.017000892\n",
      "Validation Loss: 0.063874386\n",
      "Epoch: 4885 cost = 0.017001162\n",
      "Validation Loss: 0.037321262\n",
      "Epoch: 4886 cost = 0.017000774\n",
      "Validation Loss: 0.02826985\n",
      "Epoch: 4887 cost = 0.017000706\n",
      "Validation Loss: 0.033818226\n",
      "Epoch: 4888 cost = 0.016999621\n",
      "Validation Loss: 0.05702731\n",
      "Epoch: 4889 cost = 0.016999463\n",
      "Validation Loss: 0.09210497\n",
      "Epoch: 4890 cost = 0.017000417\n",
      "Validation Loss: 0.10342167\n",
      "Epoch: 4891 cost = 0.017000121\n",
      "Validation Loss: 0.08590071\n",
      "Epoch: 4892 cost = 0.017000348\n",
      "Validation Loss: 0.081258\n",
      "Epoch: 4893 cost = 0.016999993\n",
      "Validation Loss: 0.088207304\n",
      "Epoch: 4894 cost = 0.017000244\n",
      "Validation Loss: 0.07026956\n",
      "Epoch: 4895 cost = 0.017000047\n",
      "Validation Loss: 0.038631845\n",
      "Epoch: 4896 cost = 0.017000200\n",
      "Validation Loss: 0.038086966\n",
      "Epoch: 4897 cost = 0.016999834\n",
      "Validation Loss: 0.07409847\n",
      "Epoch: 4898 cost = 0.016999996\n",
      "Validation Loss: 0.09394602\n",
      "Epoch: 4899 cost = 0.017000214\n",
      "Validation Loss: 0.077105336\n",
      "Epoch: 4900 cost = 0.016999789\n",
      "Validation Loss: 0.044851366\n",
      "Epoch: 4901 cost = 0.016999633\n",
      "Validation Loss: 0.048523612\n",
      "Epoch: 4902 cost = 0.016998736\n",
      "Validation Loss: 0.050711896\n",
      "Epoch: 4903 cost = 0.016998263\n",
      "Validation Loss: 0.04682764\n",
      "Epoch: 4904 cost = 0.016997185\n",
      "Validation Loss: 0.045510598\n",
      "Epoch: 4905 cost = 0.016997052\n",
      "Validation Loss: 0.054882955\n",
      "Epoch: 4906 cost = 0.016995693\n",
      "Validation Loss: 0.05831267\n",
      "Epoch: 4907 cost = 0.016995115\n",
      "Validation Loss: 0.060705584\n",
      "Epoch: 4908 cost = 0.016994192\n",
      "Validation Loss: 0.032045487\n",
      "Epoch: 4909 cost = 0.016992648\n",
      "Validation Loss: 0.033446845\n",
      "Epoch: 4910 cost = 0.016991988\n",
      "Validation Loss: 0.056477703\n",
      "Epoch: 4911 cost = 0.016990934\n",
      "Validation Loss: 0.05064372\n",
      "Epoch: 4912 cost = 0.016989172\n",
      "Validation Loss: 0.044498917\n",
      "Epoch: 4913 cost = 0.016988798\n",
      "Validation Loss: 0.04543317\n",
      "Epoch: 4914 cost = 0.016987569\n",
      "Validation Loss: 0.036295783\n",
      "Epoch: 4915 cost = 0.016986637\n",
      "Validation Loss: 0.044253904\n",
      "Epoch: 4916 cost = 0.016985468\n",
      "Validation Loss: 0.049808748\n",
      "Epoch: 4917 cost = 0.016984459\n",
      "Validation Loss: 0.054163177\n",
      "Epoch: 4918 cost = 0.016983275\n",
      "Validation Loss: 0.05304705\n",
      "Epoch: 4919 cost = 0.016981996\n",
      "Validation Loss: 0.054899286\n",
      "Epoch: 4920 cost = 0.016981216\n",
      "Validation Loss: 0.039180674\n",
      "Epoch: 4921 cost = 0.016981097\n",
      "Validation Loss: 0.04007301\n",
      "Epoch: 4922 cost = 0.016980414\n",
      "Validation Loss: 0.04612236\n",
      "Epoch: 4923 cost = 0.016979621\n",
      "Validation Loss: 0.053880252\n",
      "Epoch: 4924 cost = 0.016979751\n",
      "Validation Loss: 0.057902332\n",
      "Epoch: 4925 cost = 0.016979055\n",
      "Validation Loss: 0.054375462\n",
      "Epoch: 4926 cost = 0.016979584\n",
      "Validation Loss: 0.055510875\n",
      "Epoch: 4927 cost = 0.016979484\n",
      "Validation Loss: 0.071798205\n",
      "Epoch: 4928 cost = 0.016979691\n",
      "Validation Loss: 0.082474306\n",
      "Epoch: 4929 cost = 0.016980159\n",
      "Validation Loss: 0.08207963\n",
      "Epoch: 4930 cost = 0.016980835\n",
      "Validation Loss: 0.066461936\n",
      "Epoch: 4931 cost = 0.016981606\n",
      "Validation Loss: 0.05359903\n",
      "Epoch: 4932 cost = 0.016982144\n",
      "Validation Loss: 0.052312713\n",
      "Epoch: 4933 cost = 0.016983355\n",
      "Validation Loss: 0.05280233\n",
      "Epoch: 4934 cost = 0.016983854\n",
      "Validation Loss: 0.057314653\n",
      "Epoch: 4935 cost = 0.016985224\n",
      "Validation Loss: 0.044964153\n",
      "Epoch: 4936 cost = 0.016986453\n",
      "Validation Loss: 0.031400636\n",
      "Epoch: 4937 cost = 0.016987618\n",
      "Validation Loss: 0.038570978\n",
      "Epoch: 4938 cost = 0.016987273\n",
      "Validation Loss: 0.05935445\n",
      "Epoch: 4939 cost = 0.016988290\n",
      "Validation Loss: 0.065584406\n",
      "Epoch: 4940 cost = 0.016989013\n",
      "Validation Loss: 0.06563846\n",
      "Epoch: 4941 cost = 0.016989933\n",
      "Validation Loss: 0.052642815\n",
      "Epoch: 4942 cost = 0.016989860\n",
      "Validation Loss: 0.056574322\n",
      "Epoch: 4943 cost = 0.016989430\n",
      "Validation Loss: 0.07536192\n",
      "Epoch: 4944 cost = 0.016989206\n",
      "Validation Loss: 0.06355703\n",
      "Epoch: 4945 cost = 0.016988094\n",
      "Validation Loss: 0.045109168\n",
      "Epoch: 4946 cost = 0.016986576\n",
      "Validation Loss: 0.038102232\n",
      "Epoch: 4947 cost = 0.016985532\n",
      "Validation Loss: 0.037318263\n",
      "Epoch: 4948 cost = 0.016982800\n",
      "Validation Loss: 0.047615994\n",
      "Epoch: 4949 cost = 0.016981051\n",
      "Validation Loss: 0.06251025\n",
      "Epoch: 4950 cost = 0.016979086\n",
      "Validation Loss: 0.08324138\n",
      "Epoch: 4951 cost = 0.016976787\n",
      "Validation Loss: 0.10337106\n",
      "Epoch: 4952 cost = 0.016973956\n",
      "Validation Loss: 0.09480153\n",
      "Epoch: 4953 cost = 0.016971167\n",
      "Validation Loss: 0.059973504\n",
      "Epoch: 4954 cost = 0.016968983\n",
      "Validation Loss: 0.04345629\n",
      "Epoch: 4955 cost = 0.016966026\n",
      "Validation Loss: 0.029259292\n",
      "Epoch: 4956 cost = 0.016964333\n",
      "Validation Loss: 0.030172357\n",
      "Epoch: 4957 cost = 0.016961325\n",
      "Validation Loss: 0.039215583\n",
      "Epoch: 4958 cost = 0.016959271\n",
      "Validation Loss: 0.040015828\n",
      "Epoch: 4959 cost = 0.016957092\n",
      "Validation Loss: 0.040920313\n",
      "Epoch: 4960 cost = 0.016955426\n",
      "Validation Loss: 0.05211761\n",
      "Epoch: 4961 cost = 0.016953535\n",
      "Validation Loss: 0.08201064\n",
      "Epoch: 4962 cost = 0.016952183\n",
      "Validation Loss: 0.06927281\n",
      "Epoch: 4963 cost = 0.016951177\n",
      "Validation Loss: 0.069248565\n",
      "Epoch: 4964 cost = 0.016950329\n",
      "Validation Loss: 0.038598053\n",
      "Epoch: 4965 cost = 0.016949485\n",
      "Validation Loss: 0.029521061\n",
      "Epoch: 4966 cost = 0.016949208\n",
      "Validation Loss: 0.039896715\n",
      "Epoch: 4967 cost = 0.016949103\n",
      "Validation Loss: 0.03531316\n",
      "Epoch: 4968 cost = 0.016949593\n",
      "Validation Loss: 0.038039945\n",
      "Epoch: 4969 cost = 0.016949896\n",
      "Validation Loss: 0.03450143\n",
      "Epoch: 4970 cost = 0.016951289\n",
      "Validation Loss: 0.051669564\n",
      "Epoch: 4971 cost = 0.016952792\n",
      "Validation Loss: 0.06152802\n",
      "Epoch: 4972 cost = 0.016955021\n",
      "Validation Loss: 0.054023392\n",
      "Epoch: 4973 cost = 0.016957552\n",
      "Validation Loss: 0.052297622\n",
      "Epoch: 4974 cost = 0.016961024\n",
      "Validation Loss: 0.03629674\n",
      "Epoch: 4975 cost = 0.016965575\n",
      "Validation Loss: 0.05013087\n",
      "Epoch: 4976 cost = 0.016970219\n",
      "Validation Loss: 0.050012514\n",
      "Epoch: 4977 cost = 0.016975465\n",
      "Validation Loss: 0.036687486\n",
      "Epoch: 4978 cost = 0.016981159\n",
      "Validation Loss: 0.048807845\n",
      "Epoch: 4979 cost = 0.016987272\n",
      "Validation Loss: 0.058007073\n",
      "Epoch: 4980 cost = 0.016992991\n",
      "Validation Loss: 0.049471594\n",
      "Epoch: 4981 cost = 0.016998446\n",
      "Validation Loss: 0.046518218\n",
      "Epoch: 4982 cost = 0.017002917\n",
      "Validation Loss: 0.05677398\n",
      "Epoch: 4983 cost = 0.017006193\n",
      "Validation Loss: 0.072907716\n",
      "Epoch: 4984 cost = 0.017008220\n",
      "Validation Loss: 0.07502781\n",
      "Epoch: 4985 cost = 0.017008367\n",
      "Validation Loss: 0.075932406\n",
      "Epoch: 4986 cost = 0.017006533\n",
      "Validation Loss: 0.053600915\n",
      "Epoch: 4987 cost = 0.017003368\n",
      "Validation Loss: 0.05207745\n",
      "Epoch: 4988 cost = 0.016998369\n",
      "Validation Loss: 0.04877926\n",
      "Epoch: 4989 cost = 0.016992007\n",
      "Validation Loss: 0.042655826\n",
      "Epoch: 4990 cost = 0.016984797\n",
      "Validation Loss: 0.044369746\n",
      "Epoch: 4991 cost = 0.016978061\n",
      "Validation Loss: 0.052528255\n",
      "Epoch: 4992 cost = 0.016969947\n",
      "Validation Loss: 0.056697987\n",
      "Epoch: 4993 cost = 0.016962821\n",
      "Validation Loss: 0.06448451\n",
      "Epoch: 4994 cost = 0.016955163\n",
      "Validation Loss: 0.042618338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4995 cost = 0.016948580\n",
      "Validation Loss: 0.03447316\n",
      "Epoch: 4996 cost = 0.016942941\n",
      "Validation Loss: 0.03203214\n",
      "Epoch: 4997 cost = 0.016937794\n",
      "Validation Loss: 0.04298062\n",
      "Epoch: 4998 cost = 0.016934123\n",
      "Validation Loss: 0.0467359\n",
      "Epoch: 4999 cost = 0.016930196\n",
      "Validation Loss: 0.053728245\n",
      "Epoch: 5000 cost = 0.016927041\n",
      "Validation Loss: 0.04203015\n",
      "Optimization Finished!\n",
      "Test Loss: 0.039048117\n"
     ]
    }
   ],
   "source": [
    "#we store the variables here\n",
    "log_files_path = 'C:/Users/yy2895/Desktop/st15-12-15/tmp/model.ckpt'\n",
    "def layer_batch_normalization(x, n_out, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - n_out: integer, depth of input maps - number of sample in the batch \n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - batch-normalized maps   \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    beta_init = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_init)\n",
    "    \n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_init)\n",
    "\n",
    "    #tf.nn.moment: https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "    #calculate mean and variance of x\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "    \n",
    "    #tf.train.ExponentialMovingAverage:\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
    "    #Maintains moving averages of variables by employing an exponential decay.\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    \n",
    "    def mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "        \n",
    "    #tf.cond: https://www.tensorflow.org/api_docs/python/tf/cond\n",
    "    #Return true_fn() if the predicate pred is true else false_fn()\n",
    "    mean, var = tf.cond(phase_train, mean_var_with_update, lambda: (ema_mean, ema_var))\n",
    "    \n",
    "    \n",
    "    #Here, we changesd the shape of x into [[[x1]],[[x2] ],....]\n",
    "\n",
    "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var, beta, gamma, 1e-3, True)\n",
    "    \n",
    "    return tf.reshape(normed, [-1, n_out])\n",
    "\n",
    "def layer(x, weight_shape, bias_shape, phase_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape the the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize weights\n",
    "    weight_init = tf.random_normal_initializer(stddev=(1.0/weight_shape[0])**0.5)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    \n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "\n",
    "    logits = tf.matmul(x, W) + b\n",
    "    \n",
    "    #apply the non-linear function after the batch normalization\n",
    "    return tf.nn.sigmoid(layer_batch_normalization(logits, weight_shape[1], phase_train))\n",
    "def encoder(x, n_code, phase_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the network encoder part\n",
    "    input:\n",
    "        - x: input vector of the encoder\n",
    "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder)\n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector: reduced dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope(\"code\"):\n",
    "            output = layer(x, [15, n_code], [n_code], phase_train)\n",
    "\n",
    "\n",
    "    return output\n",
    "\n",
    "def decoder(x, n_code, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network encoder part\n",
    "    input:\n",
    "        - x: input vector of the decoder - reduced dimension vector\n",
    "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder) \n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector: reconstructed dimension of the initial vector\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        \n",
    "   \n",
    "        with tf.variable_scope(\"output\"):\n",
    "            output = layer(x, [ n_code, 15], [15], phase_train)\n",
    "\n",
    "    return output\n",
    "def loss(output, x):\n",
    "    \"\"\"\n",
    "    Compute the loss of the auto-encoder\n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the decoder\n",
    "        - x: true value of the sample batch - this is the input of the encoder\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"training\"):\n",
    "        \n",
    "        l2 = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x)), 1))\n",
    "        train_loss = tf.reduce_mean(l2)\n",
    "        train_summary_op = tf.summary.scalar(\"train_cost\", train_loss)\n",
    "        return train_loss, train_summary_op\n",
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op\n",
    "def evaluate(output, x):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        -output: prediction vector of the network for the validation set\n",
    "        -x: true value for the validation set\n",
    "    output:\n",
    "        - val_loss: loss of the autoencoder\n",
    "        - in_image_op: input image \n",
    "        - out_image_op:reconstructed image \n",
    "        - val_summary_op: summary of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"validation\"):\n",
    "        \n",
    "        #in_image_op = image_summary(\"input_image\", x)\n",
    "        \n",
    "        #out_image_op = image_summary(\"output_image\", output)\n",
    "        \n",
    "        l2_norm = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x, name=\"val_diff\")), 1))\n",
    "        \n",
    "        val_loss = tf.reduce_mean(l2_norm)\n",
    "        \n",
    "        val_summary_op = tf.summary.scalar(\"val_cost\", val_loss)\n",
    "        \n",
    "        #return val_loss, in_image_op, out_image_op, val_summary_op\n",
    "        return val_loss,  val_summary_op\n",
    "\"\"\"\n",
    "def image_summary(label, tensor):\n",
    "    #tf.summary.image: https://www.tensorflow.org/api_docs/python/tf/summary/image\n",
    "    #Outputs a Summary protocol buffer with images.\n",
    "\n",
    "    tensor_reshaped = tf.reshape(tensor, [-1, 19, 1, 1])\n",
    "    return tf.summary.image(label, tensor_reshaped)\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    print('we begin')\n",
    "\n",
    "    #if a python file, please use the 4 lines bellow and comment the \"n_code = '2'\"\n",
    "    #parser = argparse.ArgumentParser(description='Autoencoder')\n",
    "    #parser.add_argument('n_code', nargs=1, type=str)\n",
    "    #args = parser.parse_args(['--help'])\n",
    "    #n_code = args.n_code[0]\n",
    "    \n",
    "    #if a jupyter file, please comment the 4 above and use the one bellow\n",
    "    n_code = '12'\n",
    "    \n",
    "    #feel free to change with your own \n",
    "    #log_files_path = r'C:\\Users\\yy2895\\Desktop\\pys'\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.variable_scope(\"autoencoder_model\"):\n",
    "\n",
    "            #the input variables are first define as placeholder \n",
    "            # a placeholder is a variable/data which will be assigned later \n",
    "            # image vector & label, phase_train is a boolean \n",
    "            x = tf.placeholder(\"float\", [None, 15]) # MNIST data image of shape 28*28=784\n",
    "            \n",
    "            phase_train = tf.placeholder(tf.bool)\n",
    "            \n",
    "            #define the encoder \n",
    "            code = encoder(x, int(n_code), phase_train)\n",
    "            \n",
    "            #define the decoder\n",
    "            output = decoder(code, int(n_code), phase_train)\n",
    "            \n",
    "            #compute the loss \n",
    "            cost, train_summary_op = loss(output, x)\n",
    "\n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "            train_op = training(cost, global_step)\n",
    "\n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            #eval_op, in_image_op, out_image_op, val_summary_op = evaluate(output, x)\n",
    "            eval_op, val_summary_op = evaluate(output, x)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "\n",
    "            #save and restore variables to and from checkpoints.\n",
    "            #saver = tf.train.Saver(max_to_keep=200)\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "\n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            #train_writer = tf.summary.FileWriter(log_files_path+'mnist_autoencoder_hidden_' + n_code + '_logs/', graph=sess.graph)\n",
    "\n",
    "            #val_writer   = tf.summary.FileWriter(log_files_path+'mnist_autoencoder_hidden_' + n_code + '_logs/', graph=sess.graph)\n",
    "\n",
    "            #initialization of the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "\n",
    "            sess.run(init_op)\n",
    "            currentmin=10000000000\n",
    "            currentmin_index=-1\n",
    "            error_path=[]\n",
    "            togive100=[]\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                #total_batch = int(numberofsamples/batch_size)\n",
    "                \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "                    \n",
    "                    minibatch_x= trainset[i]\n",
    "                    \n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    _, new_cost, train_summary = sess.run([train_op, cost, train_summary_op], feed_dict={x: minibatch_x, phase_train: True})\n",
    "                    \n",
    "                    #train_writer.add_summary(train_summary, sess.run(global_step))\n",
    "                    \n",
    "                    # Compute average loss\n",
    "                    avg_cost += new_cost/total_batch\n",
    "                    \n",
    "                \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:0.9f}\".format(avg_cost))\n",
    "\n",
    "                    #the accuracy is evaluated using the validation dataset\n",
    "                    #train_writer.add_summary(train_summary, sess.run(global_step))\n",
    "\n",
    "                    #validation_loss, in_image, out_image, val_summary = sess.run([eval_op, in_image_op, out_image_op, val_summary_op], feed_dict={x: validationset, phase_train: False})\n",
    "                    validation_loss,  val_summary = sess.run([eval_op, val_summary_op], feed_dict={x: validationset, phase_train: False})\n",
    "                    #val_writer.add_summary(in_image, sess.run(global_step))\n",
    "                    #val_writer.add_summary(out_image, sess.run(global_step))\n",
    "                    #val_writer.add_summary(val_summary, sess.run(global_step))\n",
    "                    print(\"Validation Loss:\", validation_loss)\n",
    "                    error_path.append(validation_loss)\n",
    "                    \n",
    "                    if validation_loss<currentmin:\n",
    "                        currentmin=validation_loss\n",
    "                        currentmin_index=epoch\n",
    "                        saver.save(sess, 'C:/Users/yy2895/Desktop/st15-12-15/tmp/model.ckpt')\n",
    "                        togive4=[]\n",
    "                        for i in range(len(d)):\n",
    "                            any_image = d[i].reshape(-1,15)\n",
    "                            output_any_image = sess.run(code,feed_dict={x:any_image,phase_train: False})\n",
    "                            togive4.append(output_any_image)\n",
    "                            \n",
    "                        togive100=togive4\n",
    "                    #save to use later\n",
    "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "                    #saver.save(sess, 'C:/Users/yy2895/Desktop/st19-14-19/tmp/model.ckpt')\n",
    "                    \n",
    "\n",
    "            print(\"Optimization Finished!\")\n",
    "\n",
    "            test_loss = sess.run(eval_op, feed_dict={x: testset, phase_train: False})\n",
    "            #nps_loss = sess.run(eval_op, feed_dict={x: mnist.validation.images, phase_train: False})\n",
    "            print(\"Test Loss:\", test_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016860964"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('C:/Users/yy2895/Desktop/update_stresult15-12-15.csv', 'w',newline='') as myfile:\n",
    "     wr = csv.writer(myfile)\n",
    "     for i in range(len(togive100)):\n",
    "        wr.writerow(list(togive100[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.23245826, 0.17940712, 0.14006864, 0.5881337 , 0.19452874,\n",
       "         0.8957805 , 0.17331076, 0.89777666, 0.8822948 , 0.8448451 ,\n",
       "         0.2797415 , 0.9086028 ]], dtype=float32),\n",
       " array([[0.23581468, 0.1842496 , 0.15721422, 0.58996737, 0.19807823,\n",
       "         0.88539183, 0.17599826, 0.8926599 , 0.86924213, 0.839592  ,\n",
       "         0.26024953, 0.9032815 ]], dtype=float32),\n",
       " array([[0.28703323, 0.18859379, 0.1761419 , 0.63856745, 0.20452034,\n",
       "         0.86446506, 0.25961348, 0.85537606, 0.84788156, 0.7850526 ,\n",
       "         0.26088893, 0.8684034 ]], dtype=float32),\n",
       " array([[0.36432374, 0.20287919, 0.19722061, 0.5997979 , 0.22918402,\n",
       "         0.8440207 , 0.39524326, 0.8101399 , 0.8236773 , 0.7233658 ,\n",
       "         0.29931876, 0.8277678 ]], dtype=float32),\n",
       " array([[0.4522251 , 0.20713754, 0.20780112, 0.6194414 , 0.24215764,\n",
       "         0.82837296, 0.5666883 , 0.7346474 , 0.8076063 , 0.63859695,\n",
       "         0.3375831 , 0.75922585]], dtype=float32),\n",
       " array([[0.35054812, 0.1977856 , 0.21370697, 0.63403136, 0.22988585,\n",
       "         0.83110523, 0.39118037, 0.78714544, 0.80937785, 0.72518086,\n",
       "         0.27692926, 0.80625355]], dtype=float32),\n",
       " array([[0.46676952, 0.21393344, 0.21585712, 0.6356981 , 0.23976433,\n",
       "         0.80949557, 0.5834271 , 0.7369177 , 0.78798324, 0.61464787,\n",
       "         0.3195538 , 0.7596439 ]], dtype=float32),\n",
       " array([[0.41072178, 0.19317731, 0.22495669, 0.63749444, 0.24282278,\n",
       "         0.8140515 , 0.5057645 , 0.73638856, 0.783804  , 0.6620035 ,\n",
       "         0.29195142, 0.756428  ]], dtype=float32),\n",
       " array([[0.37628716, 0.19229601, 0.22247367, 0.6655344 , 0.2307208 ,\n",
       "         0.8217394 , 0.42913288, 0.7656042 , 0.80356777, 0.7013945 ,\n",
       "         0.2819148 , 0.7806714 ]], dtype=float32),\n",
       " array([[0.34355205, 0.19509713, 0.21578804, 0.6386563 , 0.23823416,\n",
       "         0.82481056, 0.4022068 , 0.762879  , 0.7968218 , 0.7129609 ,\n",
       "         0.2579784 , 0.784138  ]], dtype=float32),\n",
       " array([[0.5009829 , 0.199234  , 0.2717146 , 0.6811643 , 0.26168102,\n",
       "         0.7591279 , 0.7116373 , 0.6029057 , 0.7285919 , 0.563168  ,\n",
       "         0.30898625, 0.63499945]], dtype=float32),\n",
       " array([[0.60155505, 0.21305232, 0.31583208, 0.6987785 , 0.2728022 ,\n",
       "         0.69337666, 0.8391429 , 0.53686124, 0.6780961 , 0.4849939 ,\n",
       "         0.36994195, 0.5764379 ]], dtype=float32),\n",
       " array([[0.614789  , 0.22328347, 0.34315774, 0.7364123 , 0.2610251 ,\n",
       "         0.6507357 , 0.8336729 , 0.5501879 , 0.6625918 , 0.49799097,\n",
       "         0.37396044, 0.57700354]], dtype=float32),\n",
       " array([[0.6007485 , 0.22834672, 0.36139724, 0.7250249 , 0.26839828,\n",
       "         0.64061016, 0.8230171 , 0.56656784, 0.6540327 , 0.51318294,\n",
       "         0.36047632, 0.5952429 ]], dtype=float32),\n",
       " array([[0.6338375 , 0.22178678, 0.3751953 , 0.7170709 , 0.28869227,\n",
       "         0.6415445 , 0.8725604 , 0.48692107, 0.6459448 , 0.4964845 ,\n",
       "         0.3784056 , 0.52056485]], dtype=float32),\n",
       " array([[0.639037  , 0.22509867, 0.42332286, 0.7534748 , 0.2832447 ,\n",
       "         0.56863713, 0.8797482 , 0.47143936, 0.6054201 , 0.5324416 ,\n",
       "         0.40620634, 0.49655202]], dtype=float32),\n",
       " array([[0.49813652, 0.19520248, 0.3186458 , 0.6981259 , 0.25877652,\n",
       "         0.72732383, 0.64079195, 0.65337354, 0.71096444, 0.6246862 ,\n",
       "         0.3193162 , 0.67255574]], dtype=float32),\n",
       " array([[0.46477887, 0.195033  , 0.3558322 , 0.76412964, 0.24803767,\n",
       "         0.6588753 , 0.60963243, 0.65013266, 0.68168366, 0.66645503,\n",
       "         0.3202548 , 0.6565171 ]], dtype=float32),\n",
       " array([[0.31687808, 0.16690347, 0.26078984, 0.72317684, 0.23103423,\n",
       "         0.80178386, 0.29959702, 0.75522006, 0.77992004, 0.73977   ,\n",
       "         0.22482388, 0.7564463 ]], dtype=float32),\n",
       " array([[0.4882199 , 0.20163648, 0.33963078, 0.70256114, 0.2720656 ,\n",
       "         0.6976761 , 0.702072  , 0.6187331 , 0.68987733, 0.61324674,\n",
       "         0.31581765, 0.6473735 ]], dtype=float32),\n",
       " array([[0.55257094, 0.2203208 , 0.42939502, 0.7396592 , 0.27795658,\n",
       "         0.567964  , 0.8079375 , 0.54465526, 0.60183126, 0.621372  ,\n",
       "         0.36248145, 0.56640655]], dtype=float32),\n",
       " array([[0.46090332, 0.20445159, 0.38617128, 0.7407733 , 0.26121312,\n",
       "         0.6300772 , 0.6424344 , 0.6242595 , 0.6518973 , 0.6862514 ,\n",
       "         0.3216894 , 0.639052  ]], dtype=float32),\n",
       " array([[0.43313712, 0.19356841, 0.3202979 , 0.7004822 , 0.25706357,\n",
       "         0.7194887 , 0.56588614, 0.7079673 , 0.71026266, 0.6398    ,\n",
       "         0.29395986, 0.726365  ]], dtype=float32),\n",
       " array([[0.2690745 , 0.17125456, 0.25335357, 0.6828968 , 0.2328009 ,\n",
       "         0.804513  , 0.1853425 , 0.82565266, 0.7796198 , 0.75548786,\n",
       "         0.21261607, 0.8274785 ]], dtype=float32),\n",
       " array([[0.5931767 , 0.22599912, 0.3874345 , 0.69011974, 0.28832692,\n",
       "         0.6720873 , 0.86043   , 0.59809273, 0.68112254, 0.5031154 ,\n",
       "         0.34010828, 0.6332858 ]], dtype=float32),\n",
       " array([[0.54182255, 0.20783626, 0.37672472, 0.72132665, 0.2655    ,\n",
       "         0.6291554 , 0.7856001 , 0.59793395, 0.6348119 , 0.59395385,\n",
       "         0.3509267 , 0.62370294]], dtype=float32),\n",
       " array([[0.31413424, 0.17009619, 0.24599542, 0.6808647 , 0.23072492,\n",
       "         0.8109484 , 0.23831642, 0.7803627 , 0.77673835, 0.7478771 ,\n",
       "         0.2330562 , 0.7823341 ]], dtype=float32),\n",
       " array([[0.536478  , 0.2015323 , 0.323354  , 0.6744064 , 0.27413744,\n",
       "         0.72254235, 0.7778585 , 0.61699057, 0.6988284 , 0.56903476,\n",
       "         0.3329815 , 0.65079266]], dtype=float32),\n",
       " array([[0.56873024, 0.22454938, 0.37163863, 0.70227927, 0.2741125 ,\n",
       "         0.6294154 , 0.84413505, 0.578701  , 0.6378421 , 0.5708434 ,\n",
       "         0.35398334, 0.613828  ]], dtype=float32),\n",
       " array([[0.48835558, 0.20822772, 0.325698  , 0.6782791 , 0.26662362,\n",
       "         0.7014755 , 0.7057234 , 0.6750895 , 0.68804514, 0.5901502 ,\n",
       "         0.31313223, 0.7049248 ]], dtype=float32),\n",
       " array([[0.3635655 , 0.19409521, 0.26725036, 0.6930635 , 0.24018063,\n",
       "         0.7639811 , 0.3872761 , 0.73532325, 0.745627  , 0.7087582 ,\n",
       "         0.25198746, 0.7473798 ]], dtype=float32),\n",
       " array([[0.3856781 , 0.18746951, 0.27209026, 0.694051  , 0.23937052,\n",
       "         0.776018  , 0.39722827, 0.7465471 , 0.76084465, 0.70314837,\n",
       "         0.27450678, 0.7531194 ]], dtype=float32),\n",
       " array([[0.46268976, 0.19508936, 0.2938378 , 0.6939874 , 0.24626756,\n",
       "         0.73483056, 0.6029131 , 0.72428745, 0.72413343, 0.6205585 ,\n",
       "         0.31570536, 0.73691636]], dtype=float32),\n",
       " array([[0.21969044, 0.16309144, 0.22297966, 0.68130034, 0.22310792,\n",
       "         0.84729946, 0.09101693, 0.8250975 , 0.8169951 , 0.8038241 ,\n",
       "         0.18344308, 0.82122606]], dtype=float32),\n",
       " array([[0.10680277, 0.14861476, 0.15083407, 0.6745624 , 0.19040976,\n",
       "         0.9054434 , 0.00910819, 0.90873116, 0.87808216, 0.89420325,\n",
       "         0.12256581, 0.89673   ]], dtype=float32),\n",
       " array([[0.27060917, 0.1821009 , 0.1799134 , 0.65004176, 0.22063783,\n",
       "         0.86084646, 0.15955192, 0.82026196, 0.8271989 , 0.74123496,\n",
       "         0.19832158, 0.8238635 ]], dtype=float32),\n",
       " array([[0.3179334 , 0.18863826, 0.22048904, 0.63407856, 0.2331473 ,\n",
       "         0.82733077, 0.22405495, 0.82096505, 0.7957748 , 0.72111243,\n",
       "         0.23455001, 0.82348025]], dtype=float32),\n",
       " array([[0.43690476, 0.20387234, 0.27529022, 0.64868766, 0.2491798 ,\n",
       "         0.76154476, 0.55417645, 0.7428019 , 0.73562205, 0.6287928 ,\n",
       "         0.2918706 , 0.7609653 ]], dtype=float32),\n",
       " array([[0.2234836 , 0.1762489 , 0.17485467, 0.6387046 , 0.21636689,\n",
       "         0.88367236, 0.07470673, 0.8498817 , 0.85275537, 0.7988151 ,\n",
       "         0.17707446, 0.8456432 ]], dtype=float32),\n",
       " array([[0.3237151 , 0.1888115 , 0.21177073, 0.6271588 , 0.23189247,\n",
       "         0.8286001 , 0.22396791, 0.83175015, 0.7932251 , 0.70374477,\n",
       "         0.22759147, 0.8290367 ]], dtype=float32),\n",
       " array([[0.49891922, 0.20539713, 0.28541574, 0.63192284, 0.2634621 ,\n",
       "         0.7493282 , 0.7179981 , 0.722716  , 0.7206631 , 0.5593775 ,\n",
       "         0.32626387, 0.7452934 ]], dtype=float32),\n",
       " array([[0.606597  , 0.22514023, 0.3265538 , 0.655068  , 0.27626187,\n",
       "         0.6874327 , 0.9182245 , 0.57627743, 0.6646566 , 0.47658846,\n",
       "         0.36814523, 0.63241607]], dtype=float32),\n",
       " array([[0.51038134, 0.20815021, 0.30290768, 0.6638999 , 0.25954297,\n",
       "         0.7253843 , 0.7709252 , 0.65828425, 0.7002201 , 0.5676616 ,\n",
       "         0.32051343, 0.68972963]], dtype=float32),\n",
       " array([[0.49887937, 0.20800045, 0.25431815, 0.61560297, 0.26094332,\n",
       "         0.7822463 , 0.71980774, 0.68770397, 0.7380219 , 0.5744822 ,\n",
       "         0.3082908 , 0.7187833 ]], dtype=float32),\n",
       " array([[0.3658624 , 0.19828784, 0.19827025, 0.6306138 , 0.2312443 ,\n",
       "         0.83582544, 0.33033428, 0.7964051 , 0.80648226, 0.6856578 ,\n",
       "         0.2570139 , 0.80323124]], dtype=float32),\n",
       " array([[0.10951474, 0.15245852, 0.13097262, 0.61355746, 0.2036144 ,\n",
       "         0.92874223, 0.00678174, 0.9078906 , 0.9010535 , 0.902752  ,\n",
       "         0.1296275 , 0.8943183 ]], dtype=float32),\n",
       " array([[0.10430577, 0.15148799, 0.15062901, 0.6442546 , 0.2037119 ,\n",
       "         0.90760624, 0.00766652, 0.8974543 , 0.87740165, 0.9002323 ,\n",
       "         0.12758431, 0.8851102 ]], dtype=float32),\n",
       " array([[0.51177496, 0.20163888, 0.25936168, 0.6243598 , 0.27003005,\n",
       "         0.7627594 , 0.8395284 , 0.5927681 , 0.70367825, 0.52999395,\n",
       "         0.31691992, 0.65039444]], dtype=float32),\n",
       " array([[0.20648108, 0.16771622, 0.17301327, 0.6213989 , 0.21610768,\n",
       "         0.88185483, 0.05187599, 0.8424043 , 0.84006184, 0.83085114,\n",
       "         0.18152434, 0.8346804 ]], dtype=float32),\n",
       " array([[0.26529312, 0.18181558, 0.18719834, 0.64988554, 0.21345162,\n",
       "         0.86001015, 0.12046348, 0.8341654 , 0.8376298 , 0.7823399 ,\n",
       "         0.23006454, 0.831462  ]], dtype=float32),\n",
       " array([[0.50693035, 0.21261394, 0.27912945, 0.62188345, 0.2757586 ,\n",
       "         0.7505033 , 0.83509684, 0.6178822 , 0.7060782 , 0.53680927,\n",
       "         0.31927982, 0.6746331 ]], dtype=float32),\n",
       " array([[0.6458746 , 0.23464102, 0.31042632, 0.636241  , 0.2795304 ,\n",
       "         0.68375343, 0.95331436, 0.58811694, 0.65953267, 0.4091666 ,\n",
       "         0.3968608 , 0.650911  ]], dtype=float32),\n",
       " array([[0.24873029, 0.18104072, 0.18147527, 0.59900284, 0.21909565,\n",
       "         0.8852843 , 0.0590928 , 0.87427217, 0.865757  , 0.8411952 ,\n",
       "         0.25410134, 0.8643465 ]], dtype=float32),\n",
       " array([[0.39915648, 0.19040477, 0.24341837, 0.6104029 , 0.25530005,\n",
       "         0.79220545, 0.47740117, 0.7338587 , 0.74223965, 0.66531026,\n",
       "         0.2794725 , 0.7481101 ]], dtype=float32),\n",
       " array([[0.09841909, 0.14524907, 0.14359924, 0.6346581 , 0.17616701,\n",
       "         0.9241594 , 0.00177235, 0.9417463 , 0.91059965, 0.94932276,\n",
       "         0.17713888, 0.9199177 ]], dtype=float32),\n",
       " array([[0.65073806, 0.22954343, 0.26236224, 0.5751104 , 0.2991284 ,\n",
       "         0.7512344 , 0.96769774, 0.5140701 , 0.6817311 , 0.3748411 ,\n",
       "         0.36450028, 0.59804076]], dtype=float32),\n",
       " array([[0.67633885, 0.24200472, 0.39472404, 0.6439674 , 0.31966412,\n",
       "         0.55242604, 0.98396677, 0.40419197, 0.49703076, 0.34697983,\n",
       "         0.3381115 , 0.49014282]], dtype=float32),\n",
       " array([[0.6026007 , 0.2307142 , 0.43233877, 0.69812226, 0.28650215,\n",
       "         0.5293275 , 0.94289124, 0.501728  , 0.50335056, 0.45566764,\n",
       "         0.30003768, 0.5483398 ]], dtype=float32),\n",
       " array([[0.41706142, 0.2005894 , 0.3137241 , 0.7279507 , 0.23731707,\n",
       "         0.6920226 , 0.6273352 , 0.65935004, 0.67591804, 0.6149472 ,\n",
       "         0.23826112, 0.6750157 ]], dtype=float32),\n",
       " array([[0.5311637 , 0.22559714, 0.36739093, 0.7016386 , 0.26077417,\n",
       "         0.5888538 , 0.8573492 , 0.6482394 , 0.58531564, 0.49322623,\n",
       "         0.29409814, 0.67304456]], dtype=float32),\n",
       " array([[0.6657995 , 0.24754024, 0.3863381 , 0.6484161 , 0.31660244,\n",
       "         0.5654117 , 0.9797807 , 0.48818165, 0.531982  , 0.3360297 ,\n",
       "         0.33937514, 0.5658105 ]], dtype=float32),\n",
       " array([[0.6302114 , 0.24204285, 0.379552  , 0.69472635, 0.2837907 ,\n",
       "         0.5671852 , 0.95965695, 0.51653504, 0.56052613, 0.4188039 ,\n",
       "         0.33269745, 0.57053256]], dtype=float32),\n",
       " array([[0.141414  , 0.14971216, 0.14861856, 0.63391435, 0.20053257,\n",
       "         0.92446876, 0.00947004, 0.8850573 , 0.8979678 , 0.90234417,\n",
       "         0.1589894 , 0.8693523 ]], dtype=float32),\n",
       " array([[0.48454103, 0.19271073, 0.18731894, 0.68123925, 0.22378477,\n",
       "         0.87259924, 0.63915825, 0.7291463 , 0.86667037, 0.6118065 ,\n",
       "         0.3413064 , 0.74449927]], dtype=float32),\n",
       " array([[0.47518837, 0.22297403, 0.31045914, 0.68502235, 0.25369158,\n",
       "         0.64390045, 0.7883608 , 0.6450135 , 0.6088918 , 0.5376417 ,\n",
       "         0.25999   , 0.6786908 ]], dtype=float32),\n",
       " array([[0.21336597, 0.19047236, 0.26629934, 0.65225375, 0.23139137,\n",
       "         0.7535759 , 0.06979945, 0.80670387, 0.69489485, 0.82250506,\n",
       "         0.14863081, 0.7934367 ]], dtype=float32),\n",
       " array([[0.24220069, 0.18299146, 0.21471171, 0.6600782 , 0.22211301,\n",
       "         0.8243326 , 0.11574591, 0.78215253, 0.7741954 , 0.78942865,\n",
       "         0.17368805, 0.78266263]], dtype=float32),\n",
       " array([[7.1124278e-02, 1.4248075e-01, 1.5582816e-01, 6.3333011e-01,\n",
       "         1.7426388e-01, 9.2736501e-01, 6.3273602e-04, 9.4766068e-01,\n",
       "         9.1475672e-01, 9.6691698e-01, 1.6017403e-01, 9.2865342e-01]],\n",
       "       dtype=float32),\n",
       " array([[8.6765431e-02, 1.3795584e-01, 1.4813526e-01, 6.2316728e-01,\n",
       "         1.5053257e-01, 9.3704420e-01, 2.2810396e-04, 9.8184949e-01,\n",
       "         9.4492364e-01, 9.7787631e-01, 2.7773997e-01, 9.6488690e-01]],\n",
       "       dtype=float32),\n",
       " array([[0.09144143, 0.1490737 , 0.20351298, 0.63001364, 0.18057127,\n",
       "         0.8696339 , 0.00121616, 0.95666045, 0.8599214 , 0.95623493,\n",
       "         0.20198034, 0.9362724 ]], dtype=float32),\n",
       " array([[0.10880552, 0.16979216, 0.3067053 , 0.60508645, 0.21875237,\n",
       "         0.7666016 , 0.00359423, 0.9170302 , 0.72177356, 0.9450691 ,\n",
       "         0.15865146, 0.89145315]], dtype=float32),\n",
       " array([[0.12574205, 0.17553836, 0.21479627, 0.6116545 , 0.20357226,\n",
       "         0.7969061 , 0.01298896, 0.8372551 , 0.7050166 , 0.90992427,\n",
       "         0.12050936, 0.8113664 ]], dtype=float32),\n",
       " array([[0.64215624, 0.21986726, 0.29238334, 0.6379353 , 0.29273444,\n",
       "         0.70102817, 0.9809951 , 0.38326937, 0.6092605 , 0.33557352,\n",
       "         0.29788515, 0.47430396]], dtype=float32),\n",
       " array([[0.83437896, 0.26332188, 0.34188038, 0.60125935, 0.33424205,\n",
       "         0.6130547 , 0.9986638 , 0.36741295, 0.56089234, 0.1558464 ,\n",
       "         0.47805598, 0.4848848 ]], dtype=float32),\n",
       " array([[0.7852735 , 0.2729484 , 0.3733686 , 0.5769901 , 0.3406254 ,\n",
       "         0.5758603 , 0.99584407, 0.4406899 , 0.5129598 , 0.22363634,\n",
       "         0.41738105, 0.54066455]], dtype=float32),\n",
       " array([[0.7596854 , 0.2549998 , 0.3029309 , 0.6122621 , 0.31659567,\n",
       "         0.66977817, 0.9941943 , 0.44945863, 0.628208  , 0.23675855,\n",
       "         0.41588658, 0.547916  ]], dtype=float32),\n",
       " array([[0.76862943, 0.24653377, 0.3446582 , 0.6590319 , 0.3224314 ,\n",
       "         0.6263688 , 0.9958182 , 0.4099761 , 0.6050282 , 0.21236393,\n",
       "         0.41750395, 0.51398486]], dtype=float32),\n",
       " array([[0.7190123 , 0.25255024, 0.33859947, 0.6954253 , 0.30961773,\n",
       "         0.6011331 , 0.9931444 , 0.43194485, 0.5943345 , 0.23575315,\n",
       "         0.36510003, 0.53374785]], dtype=float32),\n",
       " array([[0.67646855, 0.22741811, 0.38118687, 0.75510865, 0.26329276,\n",
       "         0.5274874 , 0.9793006 , 0.47922   , 0.53305304, 0.3301592 ,\n",
       "         0.36399555, 0.5454997 ]], dtype=float32),\n",
       " array([[0.5984738 , 0.21893193, 0.2400433 , 0.69817597, 0.24897015,\n",
       "         0.79094744, 0.9152316 , 0.55669117, 0.78071594, 0.48372176,\n",
       "         0.3408836 , 0.60847384]], dtype=float32),\n",
       " array([[0.7176006 , 0.27198523, 0.22349511, 0.65979683, 0.2793762 ,\n",
       "         0.7689354 , 0.98618966, 0.5180826 , 0.77625   , 0.31495315,\n",
       "         0.40374282, 0.60335475]], dtype=float32),\n",
       " array([[0.52447844, 0.23646668, 0.24266294, 0.6845726 , 0.24984299,\n",
       "         0.7804011 , 0.85113734, 0.6566533 , 0.78927565, 0.5236673 ,\n",
       "         0.3371641 , 0.7124325 ]], dtype=float32),\n",
       " array([[0.46353635, 0.23135321, 0.25144416, 0.7170674 , 0.23962982,\n",
       "         0.7692961 , 0.7693667 , 0.66169417, 0.7887851 , 0.5848759 ,\n",
       "         0.3066051 , 0.71190333]], dtype=float32),\n",
       " array([[0.71901506, 0.2751119 , 0.4352229 , 0.71571827, 0.32069147,\n",
       "         0.5204497 , 0.98996943, 0.38880733, 0.61113507, 0.50912184,\n",
       "         0.44981813, 0.4343301 ]], dtype=float32),\n",
       " array([[0.61706597, 0.23127049, 0.35051396, 0.7238106 , 0.26137775,\n",
       "         0.61065435, 0.92535615, 0.56436527, 0.6225239 , 0.47872445,\n",
       "         0.3529062 , 0.6085887 ]], dtype=float32),\n",
       " array([[0.6189602 , 0.23279276, 0.34346315, 0.7334826 , 0.26519653,\n",
       "         0.62915623, 0.93233514, 0.58060235, 0.6624413 , 0.46755207,\n",
       "         0.3674407 , 0.626219  ]], dtype=float32),\n",
       " array([[0.6898657 , 0.26764783, 0.5874649 , 0.80053484, 0.30225876,\n",
       "         0.33252332, 0.9892246 , 0.39918506, 0.48780313, 0.5671562 ,\n",
       "         0.46586147, 0.43695274]], dtype=float32),\n",
       " array([[0.6519559 , 0.25204593, 0.46933183, 0.80134803, 0.2598049 ,\n",
       "         0.44616732, 0.96106577, 0.5342366 , 0.57278657, 0.52415043,\n",
       "         0.42080948, 0.5646715 ]], dtype=float32),\n",
       " array([[0.6529931 , 0.25026965, 0.5162013 , 0.77521586, 0.29340443,\n",
       "         0.4510389 , 0.9559217 , 0.4985296 , 0.5834006 , 0.63185364,\n",
       "         0.44818804, 0.5171317 ]], dtype=float32),\n",
       " array([[0.49189085, 0.1872435 , 0.36105824, 0.7406432 , 0.25028187,\n",
       "         0.69453055, 0.5290343 , 0.67930627, 0.70902604, 0.7025259 ,\n",
       "         0.3476964 , 0.68026805]], dtype=float32),\n",
       " array([[0.3349085 , 0.15989149, 0.22212042, 0.7172013 , 0.21589358,\n",
       "         0.84421694, 0.13962604, 0.7910405 , 0.82295537, 0.7645028 ,\n",
       "         0.2574716 , 0.7830983 ]], dtype=float32),\n",
       " array([[0.47666293, 0.20335582, 0.3809573 , 0.8070255 , 0.22776145,\n",
       "         0.5817322 , 0.6376013 , 0.6417637 , 0.66519386, 0.74404776,\n",
       "         0.36469105, 0.63231295]], dtype=float32),\n",
       " array([[0.2941027 , 0.17044732, 0.28822973, 0.75606585, 0.22203828,\n",
       "         0.7876825 , 0.14544386, 0.7645437 , 0.7996601 , 0.81583214,\n",
       "         0.264738  , 0.7604185 ]], dtype=float32),\n",
       " array([[0.20252523, 0.15708165, 0.19890684, 0.74130654, 0.19981633,\n",
       "         0.8670568 , 0.04294624, 0.82501465, 0.85917705, 0.8453236 ,\n",
       "         0.20524432, 0.8204035 ]], dtype=float32),\n",
       " array([[3.3748463e-02, 1.2123690e-01, 1.6402711e-01, 7.2519821e-01,\n",
       "         1.7311051e-01, 9.2762220e-01, 1.7775767e-04, 9.3346435e-01,\n",
       "         9.1295654e-01, 9.7350401e-01, 9.2401333e-02, 9.2310327e-01]],\n",
       "       dtype=float32),\n",
       " array([[0.39933005, 0.16674899, 0.20561773, 0.5727039 , 0.27506316,\n",
       "         0.8873792 , 0.4146127 , 0.7441965 , 0.84046316, 0.6428655 ,\n",
       "         0.3019193 , 0.78086865]], dtype=float32),\n",
       " array([[0.3101338 , 0.17691368, 0.2430514 , 0.61764306, 0.23964302,\n",
       "         0.8337219 , 0.1227578 , 0.86465466, 0.80764896, 0.74661595,\n",
       "         0.2774424 , 0.8649136 ]], dtype=float32),\n",
       " array([[8.0342621e-02, 1.3826618e-01, 2.0277369e-01, 6.5735829e-01,\n",
       "         1.8540166e-01, 8.8561201e-01, 7.3370466e-04, 9.6262205e-01,\n",
       "         8.7269282e-01, 9.4429982e-01, 1.5688471e-01, 9.4801337e-01]],\n",
       "       dtype=float32),\n",
       " array([[0.20916036, 0.14477913, 0.19210221, 0.64373356, 0.20866983,\n",
       "         0.88170135, 0.02308748, 0.9044065 , 0.854457  , 0.8402554 ,\n",
       "         0.23354577, 0.88847786]], dtype=float32),\n",
       " array([[0.14763294, 0.13492386, 0.16579929, 0.61068636, 0.19408785,\n",
       "         0.9143658 , 0.00390707, 0.93744045, 0.88387346, 0.9095827 ,\n",
       "         0.18966448, 0.91441786]], dtype=float32),\n",
       " array([[0.11365318, 0.13751408, 0.19875264, 0.53880197, 0.20720471,\n",
       "         0.8919712 , 0.0009865 , 0.9650033 , 0.85818017, 0.95016265,\n",
       "         0.20791087, 0.9448151 ]], dtype=float32),\n",
       " array([[0.17462151, 0.15528464, 0.13337155, 0.6048884 , 0.196487  ,\n",
       "         0.92228943, 0.01835006, 0.8884189 , 0.8891331 , 0.8599357 ,\n",
       "         0.19039732, 0.8794044 ]], dtype=float32),\n",
       " array([[0.7508072 , 0.23842192, 0.24349801, 0.63207793, 0.2907592 ,\n",
       "         0.7803832 , 0.99224937, 0.42506438, 0.7469356 , 0.2721407 ,\n",
       "         0.44728667, 0.5388332 ]], dtype=float32),\n",
       " array([[0.75523525, 0.2303181 , 0.28762257, 0.7101127 , 0.26518273,\n",
       "         0.6898835 , 0.99015766, 0.46454814, 0.6869533 , 0.28471214,\n",
       "         0.46573058, 0.54788744]], dtype=float32),\n",
       " array([[0.7487127 , 0.24747927, 0.35398674, 0.7123995 , 0.28826645,\n",
       "         0.6439987 , 0.9905239 , 0.43207273, 0.67008173, 0.33733496,\n",
       "         0.46037146, 0.5157266 ]], dtype=float32),\n",
       " array([[0.8376641 , 0.31183124, 0.54677224, 0.83063126, 0.28193057,\n",
       "         0.335245  , 0.9989391 , 0.31997728, 0.53934777, 0.3340211 ,\n",
       "         0.5719236 , 0.38029066]], dtype=float32),\n",
       " array([[0.6089398 , 0.20547141, 0.28990775, 0.60909444, 0.30030203,\n",
       "         0.7746418 , 0.9191997 , 0.5676484 , 0.71139383, 0.43691927,\n",
       "         0.3445456 , 0.6391352 ]], dtype=float32),\n",
       " array([[0.5668312 , 0.20710921, 0.26697078, 0.7208354 , 0.23782109,\n",
       "         0.7438775 , 0.82419926, 0.64448375, 0.74915576, 0.5476403 ,\n",
       "         0.3774173 , 0.67486817]], dtype=float32),\n",
       " array([[0.64912146, 0.23631427, 0.3932295 , 0.7367276 , 0.27420652,\n",
       "         0.5765138 , 0.9487623 , 0.48819548, 0.6243461 , 0.5635565 ,\n",
       "         0.418689  , 0.52278394]], dtype=float32),\n",
       " array([[0.520366  , 0.20852652, 0.32174444, 0.7379448 , 0.23981714,\n",
       "         0.6542193 , 0.7415414 , 0.5888479 , 0.64819795, 0.6424092 ,\n",
       "         0.3068521 , 0.59734446]], dtype=float32),\n",
       " array([[0.6487796 , 0.2501968 , 0.4042735 , 0.72073984, 0.28054073,\n",
       "         0.5799625 , 0.9417    , 0.49510935, 0.64332956, 0.61570656,\n",
       "         0.41400224, 0.5190579 ]], dtype=float32),\n",
       " array([[0.7642079 , 0.30440938, 0.7240143 , 0.8607326 , 0.29416597,\n",
       "         0.14795473, 0.9978078 , 0.27472866, 0.3290864 , 0.74828774,\n",
       "         0.57461196, 0.29130688]], dtype=float32),\n",
       " array([[0.68082094, 0.28306323, 0.47922614, 0.72374725, 0.29767764,\n",
       "         0.4247002 , 0.9808318 , 0.4786707 , 0.503218  , 0.5020728 ,\n",
       "         0.4050865 , 0.52604795]], dtype=float32),\n",
       " array([[0.5423772 , 0.22664158, 0.3531053 , 0.69935685, 0.26839414,\n",
       "         0.61697346, 0.8443947 , 0.6296453 , 0.6140972 , 0.53270835,\n",
       "         0.33200568, 0.66981953]], dtype=float32),\n",
       " array([[0.33888766, 0.17870837, 0.24078621, 0.6544137 , 0.23796089,\n",
       "         0.8239581 , 0.19626777, 0.80814177, 0.78599274, 0.6874838 ,\n",
       "         0.25237325, 0.8188992 ]], dtype=float32),\n",
       " array([[0.44731283, 0.18175024, 0.2053271 , 0.63823766, 0.24105911,\n",
       "         0.8323233 , 0.44580895, 0.77663875, 0.778283  , 0.5567449 ,\n",
       "         0.27459085, 0.7903355 ]], dtype=float32),\n",
       " array([[0.23557423, 0.1522186 , 0.16697702, 0.6755214 , 0.19679905,\n",
       "         0.89108914, 0.03248392, 0.89132416, 0.86033297, 0.783091  ,\n",
       "         0.2030929 , 0.8779685 ]], dtype=float32),\n",
       " array([[0.44080815, 0.1852387 , 0.27511203, 0.6731269 , 0.24989913,\n",
       "         0.7879905 , 0.4465093 , 0.7182915 , 0.759682  , 0.67356336,\n",
       "         0.3093423 , 0.7315172 ]], dtype=float32),\n",
       " array([[0.5448616 , 0.22889298, 0.42173272, 0.75816476, 0.2607319 ,\n",
       "         0.5295188 , 0.84674954, 0.5796308 , 0.60034364, 0.6830559 ,\n",
       "         0.39135322, 0.59411645]], dtype=float32),\n",
       " array([[0.29656363, 0.17826284, 0.21389435, 0.6654052 , 0.22581334,\n",
       "         0.8449975 , 0.13500361, 0.80895746, 0.8153504 , 0.7485973 ,\n",
       "         0.23036893, 0.8130977 ]], dtype=float32),\n",
       " array([[0.31099537, 0.18011212, 0.22793327, 0.6282927 , 0.24032743,\n",
       "         0.8282236 , 0.18368083, 0.8273332 , 0.78854775, 0.69384164,\n",
       "         0.25295436, 0.8410727 ]], dtype=float32),\n",
       " array([[0.21163964, 0.16392705, 0.17876773, 0.64976615, 0.22127528,\n",
       "         0.89165527, 0.05382028, 0.8587722 , 0.8628057 , 0.7771488 ,\n",
       "         0.18814452, 0.86039156]], dtype=float32),\n",
       " array([[0.17116925, 0.15712795, 0.17693645, 0.63598293, 0.20937513,\n",
       "         0.89265144, 0.01832692, 0.91312754, 0.86414224, 0.8175323 ,\n",
       "         0.17545734, 0.9044074 ]], dtype=float32),\n",
       " array([[0.1245473 , 0.13446318, 0.15435337, 0.7201907 , 0.17149034,\n",
       "         0.9076093 , 0.00497034, 0.9337264 , 0.8905674 , 0.87255824,\n",
       "         0.1459496 , 0.9126464 ]], dtype=float32),\n",
       " array([[0.26890138, 0.16386697, 0.20843425, 0.6941389 , 0.21304618,\n",
       "         0.8489207 , 0.12309813, 0.8540808 , 0.82589424, 0.70859855,\n",
       "         0.21669477, 0.8471373 ]], dtype=float32),\n",
       " array([[0.27847207, 0.16514483, 0.16549663, 0.64997125, 0.21418364,\n",
       "         0.8951849 , 0.1224158 , 0.8376616 , 0.86681455, 0.72619325,\n",
       "         0.22106859, 0.8366856 ]], dtype=float32),\n",
       " array([[0.54108864, 0.22122195, 0.27060455, 0.6104596 , 0.27354842,\n",
       "         0.769352  , 0.84578604, 0.6555302 , 0.729921  , 0.49527228,\n",
       "         0.33089915, 0.7105709 ]], dtype=float32),\n",
       " array([[0.63017446, 0.23126067, 0.28922266, 0.6404156 , 0.27338666,\n",
       "         0.73953855, 0.9381057 , 0.56566507, 0.7178356 , 0.45777884,\n",
       "         0.38824502, 0.6328793 ]], dtype=float32),\n",
       " array([[0.6717799 , 0.24744435, 0.3347947 , 0.6498614 , 0.2917356 ,\n",
       "         0.6869764 , 0.9653598 , 0.48398232, 0.6826797 , 0.47569025,\n",
       "         0.39915526, 0.5496204 ]], dtype=float32),\n",
       " array([[0.58511394, 0.21398051, 0.2489857 , 0.6290038 , 0.25704235,\n",
       "         0.7750767 , 0.86211574, 0.6378461 , 0.73052454, 0.49005303,\n",
       "         0.35477617, 0.68658984]], dtype=float32),\n",
       " array([[0.5890646 , 0.21379584, 0.28791553, 0.66501004, 0.26469103,\n",
       "         0.7284741 , 0.8865662 , 0.593204  , 0.70206   , 0.51460063,\n",
       "         0.36921358, 0.64170945]], dtype=float32),\n",
       " array([[0.4836942 , 0.20434402, 0.2175366 , 0.6107614 , 0.25313425,\n",
       "         0.8309711 , 0.6290036 , 0.716325  , 0.7892764 , 0.58955413,\n",
       "         0.29835358, 0.74408853]], dtype=float32),\n",
       " array([[0.45018312, 0.20469567, 0.20496482, 0.62663394, 0.23917332,\n",
       "         0.82161164, 0.5434132 , 0.75781757, 0.784222  , 0.5961333 ,\n",
       "         0.2876233 , 0.77766955]], dtype=float32),\n",
       " array([[0.25927603, 0.17675872, 0.16609487, 0.63540167, 0.21594177,\n",
       "         0.8873085 , 0.10094941, 0.82490057, 0.8518965 , 0.7668122 ,\n",
       "         0.19889231, 0.827668  ]], dtype=float32),\n",
       " array([[0.12016463, 0.1562483 , 0.11454581, 0.6308797 , 0.1856377 ,\n",
       "         0.9369394 , 0.00683297, 0.90449697, 0.9088332 , 0.8830532 ,\n",
       "         0.12473574, 0.8940984 ]], dtype=float32),\n",
       " array([[0.10807633, 0.16226657, 0.12936464, 0.6398813 , 0.18341278,\n",
       "         0.92041993, 0.0051898 , 0.91362494, 0.8924632 , 0.8971516 ,\n",
       "         0.12417816, 0.9031282 ]], dtype=float32),\n",
       " array([[6.3328005e-02, 1.5301985e-01, 1.4898628e-01, 5.8637691e-01,\n",
       "         1.9238177e-01, 9.2268062e-01, 7.7585370e-04, 9.4644284e-01,\n",
       "         8.9293861e-01, 9.4981700e-01, 1.0901515e-01, 9.3348271e-01]],\n",
       "       dtype=float32),\n",
       " array([[0.09718365, 0.16761866, 0.15060547, 0.5504962 , 0.21416937,\n",
       "         0.91129744, 0.0043165 , 0.921639  , 0.8728425 , 0.91275686,\n",
       "         0.13520515, 0.9146735 ]], dtype=float32),\n",
       " array([[0.186979  , 0.17000696, 0.17203194, 0.60616064, 0.21838574,\n",
       "         0.89041513, 0.04181746, 0.86133635, 0.85598636, 0.8283627 ,\n",
       "         0.18923254, 0.86136246]], dtype=float32),\n",
       " array([[0.14008252, 0.16745803, 0.21227199, 0.53905386, 0.23008479,\n",
       "         0.8698946 , 0.00729802, 0.9299632 , 0.8280981 , 0.90414125,\n",
       "         0.18096314, 0.9142988 ]], dtype=float32),\n",
       " array([[0.41895744, 0.18463235, 0.22973347, 0.5760222 , 0.25491938,\n",
       "         0.8277279 , 0.45839417, 0.7869665 , 0.778467  , 0.64128184,\n",
       "         0.30729398, 0.7929471 ]], dtype=float32),\n",
       " array([[0.5098643 , 0.21399514, 0.27327213, 0.56362987, 0.26710063,\n",
       "         0.758504  , 0.67967534, 0.7814318 , 0.7120243 , 0.56771886,\n",
       "         0.34221828, 0.7901661 ]], dtype=float32),\n",
       " array([[0.5916585 , 0.21524723, 0.24996367, 0.5963358 , 0.26548082,\n",
       "         0.7845809 , 0.8867668 , 0.68033046, 0.74480313, 0.46084106,\n",
       "         0.3693584 , 0.7153811 ]], dtype=float32),\n",
       " array([[0.6394087 , 0.21733192, 0.26436526, 0.6321791 , 0.26802897,\n",
       "         0.7473895 , 0.952958  , 0.57902235, 0.70107746, 0.38600847,\n",
       "         0.3739887 , 0.64011115]], dtype=float32),\n",
       " array([[0.6540026 , 0.21997021, 0.28121567, 0.6655878 , 0.2643144 ,\n",
       "         0.7184468 , 0.96347934, 0.55819494, 0.68794906, 0.36888945,\n",
       "         0.38457093, 0.622991  ]], dtype=float32),\n",
       " array([[0.6883227 , 0.22406779, 0.3099771 , 0.677483  , 0.28709716,\n",
       "         0.6952449 , 0.9831162 , 0.42331567, 0.66463846, 0.3585469 ,\n",
       "         0.39497727, 0.51150906]], dtype=float32),\n",
       " array([[0.6361221 , 0.21714082, 0.30959213, 0.67743945, 0.27290776,\n",
       "         0.70448154, 0.95590085, 0.5153461 , 0.6724693 , 0.42001036,\n",
       "         0.36575618, 0.58253974]], dtype=float32),\n",
       " array([[0.4714355 , 0.19838743, 0.25095198, 0.65799886, 0.25000954,\n",
       "         0.7859626 , 0.6960947 , 0.6814196 , 0.7493035 , 0.5804361 ,\n",
       "         0.29300407, 0.710703  ]], dtype=float32),\n",
       " array([[0.4382833 , 0.18895727, 0.2068443 , 0.6846152 , 0.23184638,\n",
       "         0.80901426, 0.63787097, 0.68174064, 0.7650978 , 0.5775348 ,\n",
       "         0.25789046, 0.7056414 ]], dtype=float32),\n",
       " array([[0.55131423, 0.21412265, 0.28403646, 0.6828607 , 0.26127833,\n",
       "         0.7236393 , 0.8916593 , 0.5774904 , 0.6995715 , 0.504624  ,\n",
       "         0.33479553, 0.6339754 ]], dtype=float32),\n",
       " array([[0.63400984, 0.23097315, 0.2716486 , 0.65601   , 0.27063057,\n",
       "         0.7386623 , 0.95239633, 0.5549279 , 0.71870977, 0.42344406,\n",
       "         0.37759537, 0.6235967 ]], dtype=float32),\n",
       " array([[0.60011524, 0.23323846, 0.29783577, 0.662835  , 0.27916056,\n",
       "         0.700817  , 0.94017583, 0.52356917, 0.67587274, 0.47625732,\n",
       "         0.34535685, 0.5914744 ]], dtype=float32),\n",
       " array([[0.676711  , 0.25014886, 0.36449534, 0.72283816, 0.27123296,\n",
       "         0.6212533 , 0.9703077 , 0.45908004, 0.67041546, 0.5103063 ,\n",
       "         0.43301648, 0.5144388 ]], dtype=float32),\n",
       " array([[0.630822  , 0.2435514 , 0.384688  , 0.73824286, 0.2630769 ,\n",
       "         0.58626866, 0.94464743, 0.5199485 , 0.6427412 , 0.5495542 ,\n",
       "         0.40780765, 0.5613046 ]], dtype=float32),\n",
       " array([[0.3968088 , 0.2034018 , 0.24746595, 0.6242168 , 0.25905144,\n",
       "         0.8133789 , 0.46440625, 0.739516  , 0.7849275 , 0.66927326,\n",
       "         0.2770762 , 0.7669848 ]], dtype=float32),\n",
       " array([[0.32201278, 0.18226318, 0.21777487, 0.6922575 , 0.22655137,\n",
       "         0.8259214 , 0.2568582 , 0.78174686, 0.8104808 , 0.7169254 ,\n",
       "         0.24700727, 0.78879756]], dtype=float32),\n",
       " array([[0.3957262 , 0.1909899 , 0.19897227, 0.6812662 , 0.23422886,\n",
       "         0.8508992 , 0.46924424, 0.7324054 , 0.84221053, 0.66649175,\n",
       "         0.28589794, 0.7500046 ]], dtype=float32),\n",
       " array([[0.27235785, 0.16487487, 0.19749402, 0.71677226, 0.20267816,\n",
       "         0.8585517 , 0.10758398, 0.8288938 , 0.8497283 , 0.7802198 ,\n",
       "         0.23356889, 0.8170686 ]], dtype=float32),\n",
       " array([[0.07826225, 0.13683334, 0.15744208, 0.67274314, 0.19104545,\n",
       "         0.9205009 , 0.00181096, 0.9206842 , 0.90057874, 0.93709624,\n",
       "         0.12145451, 0.9028437 ]], dtype=float32),\n",
       " array([[0.15256841, 0.16071707, 0.17262265, 0.6653949 , 0.2080198 ,\n",
       "         0.8845182 , 0.02082498, 0.8844609 , 0.86145604, 0.8527256 ,\n",
       "         0.16310994, 0.8744523 ]], dtype=float32),\n",
       " array([[0.15709612, 0.16117465, 0.21206565, 0.6603895 , 0.21656731,\n",
       "         0.8549324 , 0.02281305, 0.8708884 , 0.8250761 , 0.8622952 ,\n",
       "         0.1686036 , 0.86092234]], dtype=float32),\n",
       " array([[0.15499848, 0.16718993, 0.21642418, 0.63049924, 0.22238691,\n",
       "         0.8479404 , 0.02042477, 0.87302023, 0.8153994 , 0.8781035 ,\n",
       "         0.17970748, 0.86482716]], dtype=float32),\n",
       " array([[0.14637844, 0.17188483, 0.24585547, 0.6139669 , 0.223824  ,\n",
       "         0.83088607, 0.01241778, 0.89447725, 0.79384613, 0.897453  ,\n",
       "         0.16843309, 0.880018  ]], dtype=float32),\n",
       " array([[0.45806563, 0.18380338, 0.26830718, 0.64316887, 0.2553028 ,\n",
       "         0.7754705 , 0.6590808 , 0.680664  , 0.72484887, 0.60460085,\n",
       "         0.3037436 , 0.7034705 ]], dtype=float32),\n",
       " array([[0.58330053, 0.21373631, 0.30594087, 0.6086057 , 0.27194333,\n",
       "         0.7154135 , 0.8573548 , 0.68538356, 0.6775023 , 0.5125035 ,\n",
       "         0.38036   , 0.7121501 ]], dtype=float32),\n",
       " array([[0.5096271 , 0.20938024, 0.27792028, 0.63143426, 0.2558812 ,\n",
       "         0.76156515, 0.7401889 , 0.7074789 , 0.74102986, 0.58645433,\n",
       "         0.35477203, 0.7328552 ]], dtype=float32),\n",
       " array([[0.41192272, 0.21608843, 0.24637295, 0.6116516 , 0.24470815,\n",
       "         0.7668394 , 0.47774097, 0.770971  , 0.7278073 , 0.6564629 ,\n",
       "         0.27987492, 0.7840394 ]], dtype=float32),\n",
       " array([[0.2908002 , 0.1932575 , 0.19894016, 0.609297  , 0.22046693,\n",
       "         0.84641457, 0.10318168, 0.85705954, 0.80945665, 0.78726375,\n",
       "         0.21819568, 0.8414643 ]], dtype=float32),\n",
       " array([[0.4220284 , 0.224102  , 0.23157582, 0.6030306 , 0.23620184,\n",
       "         0.7859287 , 0.4054469 , 0.82412845, 0.75725913, 0.6640106 ,\n",
       "         0.27764213, 0.8189331 ]], dtype=float32),\n",
       " array([[0.5012509 , 0.2257542 , 0.21925439, 0.6320504 , 0.23716474,\n",
       "         0.7993142 , 0.71467453, 0.71787417, 0.76468635, 0.56672823,\n",
       "         0.28641477, 0.73697704]], dtype=float32),\n",
       " array([[0.37972602, 0.21061376, 0.2082988 , 0.6434273 , 0.23022331,\n",
       "         0.8278718 , 0.42588902, 0.7455138 , 0.7946087 , 0.6718457 ,\n",
       "         0.23655507, 0.76043665]], dtype=float32),\n",
       " array([[0.50858325, 0.21259472, 0.23585705, 0.6545032 , 0.24624397,\n",
       "         0.7898296 , 0.7894598 , 0.65539473, 0.7557835 , 0.54596156,\n",
       "         0.29749686, 0.6889985 ]], dtype=float32),\n",
       " array([[0.51438123, 0.22683181, 0.28067598, 0.64878064, 0.2580808 ,\n",
       "         0.73286414, 0.8140233 , 0.6656619 , 0.7106612 , 0.5440807 ,\n",
       "         0.31773886, 0.7061792 ]], dtype=float32),\n",
       " array([[0.7120194 , 0.24427146, 0.27421916, 0.64098424, 0.29818138,\n",
       "         0.734332  , 0.988027  , 0.4431455 , 0.7089177 , 0.31865224,\n",
       "         0.4041962 , 0.5418078 ]], dtype=float32),\n",
       " array([[0.7360578 , 0.25542247, 0.33696216, 0.7120028 , 0.2855627 ,\n",
       "         0.6285479 , 0.9910773 , 0.4179556 , 0.6553781 , 0.33203644,\n",
       "         0.4349033 , 0.502948  ]], dtype=float32),\n",
       " array([[0.7184515 , 0.24261607, 0.368215  , 0.7138159 , 0.29336637,\n",
       "         0.6247647 , 0.98447704, 0.41387883, 0.6519185 , 0.41340616,\n",
       "         0.43217352, 0.48346624]], dtype=float32),\n",
       " array([[0.70675546, 0.25430256, 0.3963071 , 0.74444216, 0.27582687,\n",
       "         0.55083156, 0.9768763 , 0.46344155, 0.61737984, 0.4629918 ,\n",
       "         0.4322655 , 0.50954413]], dtype=float32),\n",
       " array([[0.71222943, 0.25580958, 0.39372393, 0.73918253, 0.2755578 ,\n",
       "         0.5575774 , 0.9724363 , 0.46722546, 0.6253674 , 0.50128293,\n",
       "         0.44610503, 0.5077076 ]], dtype=float32),\n",
       " array([[0.7087161 , 0.25949422, 0.5363121 , 0.7827729 , 0.29706267,\n",
       "         0.41527513, 0.98126775, 0.41233838, 0.5576389 , 0.5994137 ,\n",
       "         0.48660383, 0.43772444]], dtype=float32),\n",
       " array([[0.74962145, 0.2773945 , 0.68464375, 0.8315317 , 0.31154567,\n",
       "         0.2052511 , 0.9927978 , 0.29676247, 0.3829098 , 0.75331724,\n",
       "         0.56912446, 0.3011303 ]], dtype=float32),\n",
       " array([[0.680929  , 0.26025617, 0.53721756, 0.79604095, 0.27686533,\n",
       "         0.35521728, 0.9624821 , 0.4528857 , 0.5015924 , 0.70709795,\n",
       "         0.4869001 , 0.45452213]], dtype=float32),\n",
       " array([[0.55490077, 0.22243372, 0.36372128, 0.7477645 , 0.24599573,\n",
       "         0.6142365 , 0.70868695, 0.6397099 , 0.6666617 , 0.69273615,\n",
       "         0.37423655, 0.6331332 ]], dtype=float32),\n",
       " array([[0.6667109 , 0.25360358, 0.59964913, 0.80093896, 0.30377954,\n",
       "         0.34280998, 0.972646  , 0.42596227, 0.5122439 , 0.7611178 ,\n",
       "         0.49417675, 0.42881423]], dtype=float32),\n",
       " array([[0.6340356 , 0.24867292, 0.5551202 , 0.820576  , 0.26532227,\n",
       "         0.3520434 , 0.94327056, 0.50806284, 0.51301676, 0.7240423 ,\n",
       "         0.46619025, 0.5075808 ]], dtype=float32),\n",
       " array([[0.5658477 , 0.22831024, 0.48733735, 0.77816707, 0.27563068,\n",
       "         0.490499  , 0.8667426 , 0.5496319 , 0.6024471 , 0.74632376,\n",
       "         0.42618197, 0.5561471 ]], dtype=float32),\n",
       " array([[0.49073568, 0.20212053, 0.43484682, 0.776871  , 0.2571304 ,\n",
       "         0.5590505 , 0.7074683 , 0.62962866, 0.62171286, 0.7132847 ,\n",
       "         0.3764099 , 0.6372665 ]], dtype=float32),\n",
       " array([[0.409114  , 0.1839564 , 0.34662035, 0.7476597 , 0.24389987,\n",
       "         0.7021738 , 0.39665502, 0.73145115, 0.71747917, 0.6968253 ,\n",
       "         0.31336415, 0.73422223]], dtype=float32),\n",
       " array([[0.19568321, 0.14563805, 0.1702607 , 0.6092372 , 0.22243112,\n",
       "         0.91553754, 0.02214544, 0.89927036, 0.8711809 , 0.7595724 ,\n",
       "         0.17667909, 0.8998057 ]], dtype=float32),\n",
       " array([[0.09167908, 0.12483728, 0.14213756, 0.68315697, 0.1820052 ,\n",
       "         0.93073   , 0.00207711, 0.92620957, 0.89746827, 0.8876338 ,\n",
       "         0.12150011, 0.9174384 ]], dtype=float32),\n",
       " array([[0.26875505, 0.15519887, 0.19668782, 0.6575049 , 0.22921951,\n",
       "         0.8805605 , 0.10759103, 0.825543  , 0.8382272 , 0.703168  ,\n",
       "         0.21552299, 0.83465254]], dtype=float32),\n",
       " array([[0.42897382, 0.1674125 , 0.27651843, 0.67290395, 0.2572305 ,\n",
       "         0.7955632 , 0.5164492 , 0.70143175, 0.74586076, 0.60611385,\n",
       "         0.30520904, 0.7284717 ]], dtype=float32),\n",
       " array([[0.3395777 , 0.16848955, 0.33292386, 0.7254646 , 0.24203461,\n",
       "         0.72932535, 0.29111782, 0.775845  , 0.71320295, 0.68843263,\n",
       "         0.2828849 , 0.78290635]], dtype=float32),\n",
       " array([[0.3124671 , 0.16333596, 0.26898378, 0.6981008 , 0.2373124 ,\n",
       "         0.7989731 , 0.21840683, 0.7885    , 0.76548284, 0.7003102 ,\n",
       "         0.25222537, 0.79469603]], dtype=float32),\n",
       " array([[0.22425406, 0.15800852, 0.21257314, 0.65533453, 0.22637856,\n",
       "         0.8638766 , 0.06526449, 0.8575841 , 0.8241502 , 0.7472452 ,\n",
       "         0.1956797 , 0.85944545]], dtype=float32),\n",
       " array([[0.35325477, 0.17736867, 0.24581817, 0.6484385 , 0.2463435 ,\n",
       "         0.8261163 , 0.30970752, 0.81873304, 0.80558205, 0.64320767,\n",
       "         0.29137522, 0.83067113]], dtype=float32),\n",
       " array([[0.50976753, 0.18496943, 0.26867348, 0.62600476, 0.27878284,\n",
       "         0.79438055, 0.8100693 , 0.64467895, 0.731493  , 0.48057148,\n",
       "         0.31702864, 0.6987323 ]], dtype=float32),\n",
       " array([[0.46968395, 0.18306026, 0.29464397, 0.7012056 , 0.2481523 ,\n",
       "         0.7436779 , 0.66353947, 0.6753488 , 0.7136504 , 0.5941621 ,\n",
       "         0.3178458 , 0.69635326]], dtype=float32),\n",
       " array([[0.24475639, 0.1500133 , 0.15723945, 0.634402  , 0.20496488,\n",
       "         0.89569813, 0.05394017, 0.86316174, 0.8469964 , 0.76150507,\n",
       "         0.2004843 , 0.8562997 ]], dtype=float32),\n",
       " array([[0.43016922, 0.19137911, 0.22410262, 0.63262624, 0.24710305,\n",
       "         0.82100475, 0.53815705, 0.7531459 , 0.7805006 , 0.5766861 ,\n",
       "         0.2824593 , 0.7769471 ]], dtype=float32),\n",
       " array([[0.4925379 , 0.21558426, 0.24570698, 0.63071954, 0.26235357,\n",
       "         0.7902921 , 0.76122975, 0.6658046 , 0.7582684 , 0.5464659 ,\n",
       "         0.30686527, 0.7142407 ]], dtype=float32),\n",
       " array([[0.37761545, 0.19635719, 0.22402816, 0.652619  , 0.23694152,\n",
       "         0.80888957, 0.4235195 , 0.7316757 , 0.7724369 , 0.65823317,\n",
       "         0.2607975 , 0.7594945 ]], dtype=float32),\n",
       " array([[0.13241474, 0.14923537, 0.13258532, 0.6017519 , 0.20140012,\n",
       "         0.93160623, 0.00887589, 0.8986382 , 0.8945303 , 0.8643399 ,\n",
       "         0.13458253, 0.8917171 ]], dtype=float32),\n",
       " array([[0.21595608, 0.1567577 , 0.13070816, 0.61349094, 0.20370568,\n",
       "         0.91784734, 0.04408314, 0.87206364, 0.8769567 , 0.77397805,\n",
       "         0.17447057, 0.8658352 ]], dtype=float32),\n",
       " array([[0.30316466, 0.18083999, 0.1756631 , 0.5953717 , 0.22321564,\n",
       "         0.87160915, 0.14155783, 0.8480507 , 0.8253932 , 0.7123041 ,\n",
       "         0.22028486, 0.8474198 ]], dtype=float32),\n",
       " array([[0.27251795, 0.18307488, 0.19107853, 0.62833744, 0.22737116,\n",
       "         0.8633273 , 0.15017956, 0.82803047, 0.8325521 , 0.7270023 ,\n",
       "         0.22004883, 0.83726203]], dtype=float32),\n",
       " array([[0.4479729 , 0.20023847, 0.28083947, 0.65878826, 0.2578014 ,\n",
       "         0.7544999 , 0.7012961 , 0.6608829 , 0.7191832 , 0.59190744,\n",
       "         0.29839262, 0.7033145 ]], dtype=float32),\n",
       " array([[0.35636166, 0.18679346, 0.22740749, 0.6546255 , 0.22947697,\n",
       "         0.8124589 , 0.3286763 , 0.7761865 , 0.77029186, 0.664854  ,\n",
       "         0.23854786, 0.7853301 ]], dtype=float32),\n",
       " array([[0.43294936, 0.19438106, 0.24768981, 0.6079535 , 0.25746447,\n",
       "         0.80121714, 0.54600775, 0.7726338 , 0.7623123 , 0.59087306,\n",
       "         0.29684988, 0.7885514 ]], dtype=float32),\n",
       " array([[0.5258734 , 0.20860235, 0.2799028 , 0.63476974, 0.2651756 ,\n",
       "         0.7660103 , 0.81385875, 0.6575716 , 0.7322297 , 0.5312279 ,\n",
       "         0.33128408, 0.69981486]], dtype=float32),\n",
       " array([[0.5282557 , 0.22140138, 0.25540504, 0.6276355 , 0.2581602 ,\n",
       "         0.7703928 , 0.81465346, 0.66453934, 0.7373399 , 0.5283471 ,\n",
       "         0.3256129 , 0.7101382 ]], dtype=float32),\n",
       " array([[0.54770315, 0.21350457, 0.25487486, 0.66843235, 0.25044525,\n",
       "         0.7694863 , 0.84128445, 0.6599045 , 0.752905  , 0.5083222 ,\n",
       "         0.3379556 , 0.6945428 ]], dtype=float32),\n",
       " array([[0.59238225, 0.215015  , 0.3001401 , 0.67035717, 0.27555886,\n",
       "         0.7346733 , 0.922952  , 0.54008096, 0.7182634 , 0.5081804 ,\n",
       "         0.37317273, 0.5991312 ]], dtype=float32),\n",
       " array([[0.5262708 , 0.20709263, 0.279119  , 0.6865901 , 0.24847855,\n",
       "         0.7279741 , 0.80280477, 0.645227  , 0.7094787 , 0.5580998 ,\n",
       "         0.338123  , 0.6773888 ]], dtype=float32),\n",
       " array([[0.5475893 , 0.21663222, 0.28832138, 0.6560704 , 0.27683204,\n",
       "         0.70888853, 0.8886684 , 0.573508  , 0.6714667 , 0.51628566,\n",
       "         0.33162794, 0.63127834]], dtype=float32),\n",
       " array([[0.49540082, 0.21535078, 0.22294657, 0.61953306, 0.2619881 ,\n",
       "         0.81033444, 0.752233  , 0.6663259 , 0.77940094, 0.5742269 ,\n",
       "         0.31568313, 0.71099114]], dtype=float32),\n",
       " array([[0.50497454, 0.21566226, 0.26714274, 0.66095865, 0.26317757,\n",
       "         0.7508776 , 0.7799827 , 0.6447555 , 0.73146725, 0.58304244,\n",
       "         0.31753817, 0.6807385 ]], dtype=float32),\n",
       " array([[0.4079892 , 0.20315827, 0.23228236, 0.66737384, 0.23796082,\n",
       "         0.8083049 , 0.45968905, 0.7533829 , 0.79293543, 0.6569246 ,\n",
       "         0.26919612, 0.7639771 ]], dtype=float32),\n",
       " array([[0.21910948, 0.1676372 , 0.18525004, 0.6869158 , 0.20818496,\n",
       "         0.87073654, 0.06039552, 0.83550256, 0.8493473 , 0.8150773 ,\n",
       "         0.1912087 , 0.8278343 ]], dtype=float32),\n",
       " array([[0.13457116, 0.15791358, 0.15420172, 0.6461646 , 0.19703199,\n",
       "         0.9045363 , 0.00940546, 0.89944506, 0.87418014, 0.88219863,\n",
       "         0.13951322, 0.884797  ]], dtype=float32),\n",
       " array([[0.16306065, 0.16997746, 0.15309098, 0.66693735, 0.19325249,\n",
       "         0.89602333, 0.02056375, 0.8824512 , 0.8711129 , 0.84989536,\n",
       "         0.14944585, 0.8708683 ]], dtype=float32),\n",
       " array([[0.1568574 , 0.17849353, 0.17800392, 0.6395738 , 0.20431165,\n",
       "         0.88283974, 0.01660742, 0.9018655 , 0.8632502 , 0.86500067,\n",
       "         0.1602989 , 0.89070994]], dtype=float32),\n",
       " array([[0.32445604, 0.18657245, 0.22302403, 0.6558453 , 0.23446536,\n",
       "         0.83299196, 0.2838341 , 0.7645516 , 0.80198604, 0.7117799 ,\n",
       "         0.23151462, 0.7757399 ]], dtype=float32),\n",
       " array([[0.4021061 , 0.2105054 , 0.2566478 , 0.63616306, 0.24420993,\n",
       "         0.76772046, 0.4928474 , 0.7585041 , 0.7389507 , 0.6448036 ,\n",
       "         0.276927  , 0.7783753 ]], dtype=float32),\n",
       " array([[0.38266855, 0.19763716, 0.23326096, 0.5955043 , 0.2428194 ,\n",
       "         0.8039214 , 0.32653353, 0.79821914, 0.7555958 , 0.6916718 ,\n",
       "         0.26741546, 0.80155015]], dtype=float32),\n",
       " array([[0.24505709, 0.19281405, 0.2201375 , 0.5839888 , 0.24124753,\n",
       "         0.837354  , 0.06479244, 0.89007366, 0.8095235 , 0.8016676 ,\n",
       "         0.21446264, 0.8790537 ]], dtype=float32),\n",
       " array([[0.24180712, 0.17145863, 0.2178571 , 0.6426298 , 0.22237335,\n",
       "         0.8386404 , 0.05985724, 0.8829805 , 0.8152594 , 0.8027548 ,\n",
       "         0.21681464, 0.8649672 ]], dtype=float32),\n",
       " array([[0.5136142 , 0.21012162, 0.26196173, 0.6211334 , 0.2621909 ,\n",
       "         0.7736901 , 0.7697575 , 0.68405944, 0.7298346 , 0.54753494,\n",
       "         0.30728248, 0.71329653]], dtype=float32),\n",
       " array([[0.40413538, 0.1901121 , 0.21012469, 0.65336406, 0.22420213,\n",
       "         0.8348154 , 0.3944449 , 0.7757808 , 0.8071295 , 0.66877514,\n",
       "         0.2721007 , 0.775428  ]], dtype=float32),\n",
       " array([[0.5375867 , 0.21647225, 0.2543473 , 0.6454375 , 0.25360665,\n",
       "         0.76798654, 0.82957125, 0.65736365, 0.7362559 , 0.52227026,\n",
       "         0.32182333, 0.69417536]], dtype=float32),\n",
       " array([[0.6527686 , 0.23500806, 0.30181438, 0.66984415, 0.2601728 ,\n",
       "         0.68746156, 0.952641  , 0.54856133, 0.66739684, 0.43725038,\n",
       "         0.38335428, 0.60697633]], dtype=float32),\n",
       " array([[0.6924931 , 0.2443188 , 0.3778753 , 0.688657  , 0.28649127,\n",
       "         0.60915023, 0.9798656 , 0.4218803 , 0.6083034 , 0.438409  ,\n",
       "         0.41419905, 0.4983914 ]], dtype=float32),\n",
       " array([[0.6820758 , 0.24579763, 0.35685402, 0.71288675, 0.27220508,\n",
       "         0.61538786, 0.9743026 , 0.48102537, 0.6451249 , 0.44231278,\n",
       "         0.42710173, 0.5459493 ]], dtype=float32),\n",
       " array([[0.61136246, 0.2348258 , 0.2958313 , 0.6594624 , 0.2723956 ,\n",
       "         0.71484965, 0.9276666 , 0.5930874 , 0.70311624, 0.46645534,\n",
       "         0.36281738, 0.6480869 ]], dtype=float32),\n",
       " array([[0.5897125 , 0.2219994 , 0.28938246, 0.68959266, 0.26011974,\n",
       "         0.7241917 , 0.9027466 , 0.607057  , 0.7280519 , 0.504192  ,\n",
       "         0.37424415, 0.6505837 ]], dtype=float32),\n",
       " array([[0.51194084, 0.20889363, 0.27379546, 0.6749387 , 0.25124994,\n",
       "         0.75152653, 0.7622375 , 0.6677212 , 0.7331372 , 0.575519  ,\n",
       "         0.3234185 , 0.6962513 ]], dtype=float32),\n",
       " array([[0.5253037 , 0.22284093, 0.26831135, 0.64531577, 0.26112333,\n",
       "         0.76089925, 0.79279125, 0.691423  , 0.7424142 , 0.5412687 ,\n",
       "         0.32111385, 0.72419226]], dtype=float32),\n",
       " array([[0.37054354, 0.19550502, 0.23533288, 0.70616925, 0.22275946,\n",
       "         0.7891574 , 0.37760746, 0.736558  , 0.77254295, 0.6978319 ,\n",
       "         0.24717182, 0.7434018 ]], dtype=float32),\n",
       " array([[0.35114545, 0.2025941 , 0.2016721 , 0.6615905 , 0.22625473,\n",
       "         0.8364616 , 0.3129812 , 0.7607859 , 0.81217986, 0.71171176,\n",
       "         0.23433495, 0.7716688 ]], dtype=float32),\n",
       " array([[0.4281758 , 0.20623894, 0.24770834, 0.6645199 , 0.24314715,\n",
       "         0.78853565, 0.5557908 , 0.720549  , 0.7735678 , 0.6522029 ,\n",
       "         0.29465568, 0.74235827]], dtype=float32),\n",
       " array([[0.36558917, 0.21240772, 0.2408427 , 0.66792357, 0.23432887,\n",
       "         0.78949296, 0.37922707, 0.76616555, 0.7773757 , 0.6935279 ,\n",
       "         0.25405255, 0.78057104]], dtype=float32),\n",
       " array([[0.18237002, 0.16804765, 0.19753578, 0.6446261 , 0.22014548,\n",
       "         0.873756  , 0.03175571, 0.865831  , 0.8468082 , 0.85009056,\n",
       "         0.1793429 , 0.8577725 ]], dtype=float32),\n",
       " array([[0.11748581, 0.15547   , 0.15469363, 0.65452975, 0.19691263,\n",
       "         0.9073975 , 0.00624466, 0.9165475 , 0.8893688 , 0.90149826,\n",
       "         0.1493349 , 0.9007137 ]], dtype=float32),\n",
       " array([[0.09921624, 0.14059593, 0.18549709, 0.63947886, 0.2070059 ,\n",
       "         0.88574606, 0.00287463, 0.9347664 , 0.860813  , 0.9248641 ,\n",
       "         0.1529986 , 0.9140875 ]], dtype=float32),\n",
       " array([[0.21578906, 0.16336355, 0.20508175, 0.6536269 , 0.22106573,\n",
       "         0.85619134, 0.05141098, 0.86510986, 0.8299061 , 0.8218663 ,\n",
       "         0.20637156, 0.8512683 ]], dtype=float32),\n",
       " array([[0.2874807 , 0.17167948, 0.22099817, 0.6648094 , 0.229305  ,\n",
       "         0.8289297 , 0.1913619 , 0.78734756, 0.79628706, 0.74916846,\n",
       "         0.23725581, 0.7914959 ]], dtype=float32),\n",
       " array([[0.17215034, 0.16451414, 0.2024016 , 0.63355285, 0.2178806 ,\n",
       "         0.8676268 , 0.02039075, 0.8857615 , 0.83868366, 0.8731676 ,\n",
       "         0.18055026, 0.868512  ]], dtype=float32),\n",
       " array([[0.27378276, 0.18047808, 0.2239048 , 0.6432363 , 0.22972196,\n",
       "         0.82286817, 0.127226  , 0.8371953 , 0.79506254, 0.7739191 ,\n",
       "         0.23213254, 0.8299843 ]], dtype=float32),\n",
       " array([[0.49287271, 0.20860189, 0.29188168, 0.634473  , 0.2656496 ,\n",
       "         0.7395734 , 0.7539701 , 0.69040656, 0.7092477 , 0.57193625,\n",
       "         0.32568222, 0.7204962 ]], dtype=float32),\n",
       " array([[0.6391664 , 0.220313  , 0.32730892, 0.64011973, 0.29097256,\n",
       "         0.69531703, 0.9597468 , 0.53336495, 0.66287404, 0.41858366,\n",
       "         0.39160064, 0.6042213 ]], dtype=float32),\n",
       " array([[0.6180738 , 0.21320087, 0.30825707, 0.6696073 , 0.2687415 ,\n",
       "         0.6879384 , 0.9444937 , 0.54462445, 0.6559085 , 0.44370636,\n",
       "         0.38185686, 0.6066848 ]], dtype=float32),\n",
       " array([[0.66405773, 0.22386685, 0.3340155 , 0.68888754, 0.26945108,\n",
       "         0.66440105, 0.9645616 , 0.516448  , 0.6497545 , 0.41479006,\n",
       "         0.39526445, 0.5776589 ]], dtype=float32),\n",
       " array([[0.63597685, 0.21804433, 0.31657043, 0.66656655, 0.2748606 ,\n",
       "         0.70256233, 0.94671524, 0.55747354, 0.6822781 , 0.44400886,\n",
       "         0.39042532, 0.614862  ]], dtype=float32),\n",
       " array([[0.63640904, 0.23047906, 0.3278181 , 0.6862725 , 0.27038723,\n",
       "         0.6766963 , 0.95160764, 0.538248  , 0.6718256 , 0.4514224 ,\n",
       "         0.38298404, 0.59949774]], dtype=float32),\n",
       " array([[0.45376867, 0.21296106, 0.25178918, 0.64013296, 0.25706628,\n",
       "         0.7906566 , 0.6533887 , 0.69926906, 0.76380086, 0.61195135,\n",
       "         0.2845062 , 0.72810143]], dtype=float32),\n",
       " array([[0.32476634, 0.18850423, 0.17579222, 0.66986465, 0.217666  ,\n",
       "         0.8567037 , 0.25431505, 0.7805122 , 0.82771635, 0.7090832 ,\n",
       "         0.2188485 , 0.7834618 ]], dtype=float32),\n",
       " array([[0.22677857, 0.17610307, 0.16697025, 0.6655505 , 0.20430858,\n",
       "         0.88040954, 0.06015094, 0.84390914, 0.8537989 , 0.815409  ,\n",
       "         0.18287905, 0.83209366]], dtype=float32),\n",
       " array([[0.2614495 , 0.18263784, 0.17075889, 0.6589177 , 0.21385293,\n",
       "         0.87442225, 0.12618963, 0.8091896 , 0.85047007, 0.7784978 ,\n",
       "         0.2093231 , 0.8093376 ]], dtype=float32),\n",
       " array([[0.35764998, 0.208495  , 0.23203923, 0.6685021 , 0.23159145,\n",
       "         0.79557264, 0.38829634, 0.74909747, 0.77391547, 0.690885  ,\n",
       "         0.24219725, 0.7657604 ]], dtype=float32),\n",
       " array([[0.48061842, 0.22063324, 0.2818258 , 0.6493939 , 0.25926006,\n",
       "         0.7376608 , 0.73651534, 0.69205093, 0.7174994 , 0.5823325 ,\n",
       "         0.30681074, 0.72395873]], dtype=float32),\n",
       " array([[0.63791364, 0.23376843, 0.3325328 , 0.63563776, 0.29258958,\n",
       "         0.67765594, 0.95566374, 0.53873944, 0.64765066, 0.43735036,\n",
       "         0.3781711 , 0.6084062 ]], dtype=float32),\n",
       " array([[0.62936777, 0.22705945, 0.3376387 , 0.68236166, 0.26878703,\n",
       "         0.6603397 , 0.9402341 , 0.5665441 , 0.6554257 , 0.4679315 ,\n",
       "         0.3913973 , 0.62030363]], dtype=float32),\n",
       " array([[0.66952646, 0.22633103, 0.3523965 , 0.67888147, 0.29219234,\n",
       "         0.6635968 , 0.97099113, 0.4600075 , 0.65368444, 0.44195053,\n",
       "         0.41063175, 0.535409  ]], dtype=float32),\n",
       " array([[0.6694507 , 0.22828263, 0.37502947, 0.7192465 , 0.27727294,\n",
       "         0.62061936, 0.9644755 , 0.47502452, 0.64466584, 0.4849758 ,\n",
       "         0.42797726, 0.53211945]], dtype=float32),\n",
       " array([[0.63113713, 0.22328694, 0.35499692, 0.7155731 , 0.26766303,\n",
       "         0.6313164 , 0.935668  , 0.5403159 , 0.64669174, 0.51024604,\n",
       "         0.40491736, 0.5876025 ]], dtype=float32),\n",
       " array([[0.6265659 , 0.22464353, 0.39109853, 0.7405073 , 0.2720625 ,\n",
       "         0.60269   , 0.9347087 , 0.5163528 , 0.6539311 , 0.5689199 ,\n",
       "         0.42578244, 0.55340064]], dtype=float32),\n",
       " array([[0.5917676 , 0.22003233, 0.41315785, 0.7399537 , 0.2774199 ,\n",
       "         0.57207644, 0.9112147 , 0.5206605 , 0.6171651 , 0.61099285,\n",
       "         0.40658984, 0.5533859 ]], dtype=float32),\n",
       " array([[0.5760591 , 0.21652113, 0.40568483, 0.74223   , 0.27182505,\n",
       "         0.58803254, 0.8823794 , 0.55530035, 0.6319372 , 0.61784637,\n",
       "         0.3963691 , 0.58227605]], dtype=float32),\n",
       " array([[0.59239185, 0.22644217, 0.44303653, 0.73997915, 0.28782606,\n",
       "         0.5434369 , 0.90990907, 0.4995693 , 0.6063242 , 0.670351  ,\n",
       "         0.4184936 , 0.52445555]], dtype=float32),\n",
       " array([[0.56619287, 0.22738215, 0.451865  , 0.7616884 , 0.27213702,\n",
       "         0.5231525 , 0.8734022 , 0.5536281 , 0.6048775 , 0.68217814,\n",
       "         0.4057688 , 0.56786275]], dtype=float32),\n",
       " array([[0.53106046, 0.21560462, 0.43149802, 0.7604772 , 0.26875204,\n",
       "         0.556268  , 0.8276116 , 0.5842597 , 0.6232901 , 0.68330187,\n",
       "         0.39152712, 0.5999367 ]], dtype=float32),\n",
       " array([[0.44247344, 0.20117298, 0.3464066 , 0.72314876, 0.2588511 ,\n",
       "         0.6771166 , 0.61134076, 0.6599978 , 0.69618905, 0.7080888 ,\n",
       "         0.33445895, 0.6787654 ]], dtype=float32),\n",
       " array([[0.35564268, 0.18424404, 0.2678513 , 0.6934654 , 0.23829685,\n",
       "         0.7808124 , 0.3015986 , 0.76049584, 0.76653653, 0.7259563 ,\n",
       "         0.27641445, 0.76973265]], dtype=float32),\n",
       " array([[0.42491698, 0.19224201, 0.26533294, 0.6627647 , 0.2530716 ,\n",
       "         0.7850666 , 0.500442  , 0.7172109 , 0.75943536, 0.66782373,\n",
       "         0.3006496 , 0.7395809 ]], dtype=float32),\n",
       " array([[0.31385434, 0.17515671, 0.24505101, 0.6878905 , 0.22451615,\n",
       "         0.80832845, 0.1664596 , 0.80614185, 0.7860219 , 0.75593185,\n",
       "         0.25179356, 0.8044007 ]], dtype=float32),\n",
       " array([[0.39545283, 0.18538028, 0.2669572 , 0.67368186, 0.24168372,\n",
       "         0.783193  , 0.37349996, 0.7548987 , 0.7583115 , 0.694904  ,\n",
       "         0.28851986, 0.7642525 ]], dtype=float32),\n",
       " array([[0.39481026, 0.1850753 , 0.2778461 , 0.68919104, 0.24065357,\n",
       "         0.764105  , 0.39863   , 0.7458862 , 0.7448464 , 0.69416785,\n",
       "         0.29262018, 0.75504905]], dtype=float32),\n",
       " array([[0.33198196, 0.17835726, 0.23759794, 0.64501595, 0.23849216,\n",
       "         0.81312674, 0.22446889, 0.79622096, 0.77566344, 0.7252911 ,\n",
       "         0.26210034, 0.8048392 ]], dtype=float32),\n",
       " array([[0.3261292 , 0.17895137, 0.23645732, 0.64206874, 0.23929839,\n",
       "         0.8216242 , 0.2182828 , 0.80294746, 0.78725004, 0.72431225,\n",
       "         0.25498226, 0.8093652 ]], dtype=float32),\n",
       " array([[0.39145547, 0.18841852, 0.24789546, 0.6467494 , 0.24784215,\n",
       "         0.80616385, 0.42693186, 0.744977  , 0.7724357 , 0.66989607,\n",
       "         0.27792355, 0.7637855 ]], dtype=float32),\n",
       " array([[0.32664475, 0.17484778, 0.24422011, 0.67267615, 0.22965339,\n",
       "         0.8141212 , 0.21139711, 0.8149453 , 0.78998137, 0.7198758 ,\n",
       "         0.25470352, 0.8124182 ]], dtype=float32),\n",
       " array([[0.17817216, 0.15074027, 0.17475235, 0.66587627, 0.20231858,\n",
       "         0.89172965, 0.02210378, 0.8840993 , 0.86308885, 0.84464   ,\n",
       "         0.17458811, 0.8688556 ]], dtype=float32),\n",
       " array([[0.29564118, 0.17345546, 0.22049108, 0.654605  , 0.22927946,\n",
       "         0.8445592 , 0.16537501, 0.8109665 , 0.8130557 , 0.74275935,\n",
       "         0.2290186 , 0.81074923]], dtype=float32),\n",
       " array([[0.38302964, 0.189011  , 0.25247538, 0.6663276 , 0.23977321,\n",
       "         0.79532826, 0.4166849 , 0.75868636, 0.76956165, 0.6642698 ,\n",
       "         0.26986346, 0.7700793 ]], dtype=float32),\n",
       " array([[0.33286995, 0.1916005 , 0.22853234, 0.6361307 , 0.23889907,\n",
       "         0.8277578 , 0.26504847, 0.79899555, 0.7984311 , 0.7031194 ,\n",
       "         0.24122414, 0.80683166]], dtype=float32),\n",
       " array([[0.11486237, 0.1553132 , 0.15867966, 0.63257325, 0.20132673,\n",
       "         0.9112201 , 0.00492371, 0.92536664, 0.88877755, 0.90174556,\n",
       "         0.13774663, 0.9086766 ]], dtype=float32),\n",
       " array([[0.15530251, 0.16668746, 0.15043709, 0.6373765 , 0.20126884,\n",
       "         0.90260804, 0.01551938, 0.9093839 , 0.878801  , 0.8509587 ,\n",
       "         0.1543027 , 0.89582574]], dtype=float32),\n",
       " array([[0.3523311 , 0.19427636, 0.20285402, 0.6171574 , 0.23534368,\n",
       "         0.84463793, 0.27571362, 0.81850713, 0.81255317, 0.68561757,\n",
       "         0.24447203, 0.81905556]], dtype=float32),\n",
       " array([[0.48240644, 0.21122895, 0.2592596 , 0.6363631 , 0.246882  ,\n",
       "         0.7669765 , 0.68934363, 0.71698123, 0.73351574, 0.57833225,\n",
       "         0.30789244, 0.7427305 ]], dtype=float32),\n",
       " array([[0.60736495, 0.22657692, 0.29781935, 0.65287775, 0.2613638 ,\n",
       "         0.7122284 , 0.91968906, 0.56927687, 0.6801987 , 0.48874763,\n",
       "         0.3622816 , 0.6266678 ]], dtype=float32),\n",
       " array([[0.60010195, 0.22718751, 0.28776336, 0.6591547 , 0.25698653,\n",
       "         0.7126063 , 0.9105109 , 0.58611983, 0.6846142 , 0.49268967,\n",
       "         0.358875  , 0.63870984]], dtype=float32),\n",
       " array([[0.6112577 , 0.22715163, 0.28214127, 0.6440347 , 0.26538473,\n",
       "         0.727272  , 0.9218187 , 0.6106002 , 0.69877267, 0.45262644,\n",
       "         0.36324862, 0.66382027]], dtype=float32),\n",
       " array([[0.5456106 , 0.22544722, 0.2673253 , 0.64318705, 0.25777283,\n",
       "         0.74836814, 0.8298055 , 0.6783169 , 0.7257061 , 0.51963466,\n",
       "         0.33020097, 0.71406037]], dtype=float32),\n",
       " array([[0.5371343 , 0.22649878, 0.2479425 , 0.6326506 , 0.26074713,\n",
       "         0.7691241 , 0.8287981 , 0.66380453, 0.7401444 , 0.5240367 ,\n",
       "         0.31825048, 0.7043959 ]], dtype=float32),\n",
       " array([[0.48481452, 0.21238329, 0.23393406, 0.6470082 , 0.24436934,\n",
       "         0.7896153 , 0.68109363, 0.7065538 , 0.75971824, 0.5882083 ,\n",
       "         0.29590005, 0.7288246 ]], dtype=float32),\n",
       " array([[0.29903844, 0.18386489, 0.18594465, 0.6669064 , 0.21330534,\n",
       "         0.8579679 , 0.15488887, 0.81778806, 0.83237904, 0.7492151 ,\n",
       "         0.21611862, 0.81181175]], dtype=float32),\n",
       " array([[0.19126953, 0.168706  , 0.15578796, 0.6342857 , 0.2096142 ,\n",
       "         0.8992404 , 0.03509405, 0.858515  , 0.8675982 , 0.8398782 ,\n",
       "         0.17021328, 0.84905016]], dtype=float32),\n",
       " array([[0.15974192, 0.1759673 , 0.15411821, 0.66328716, 0.19907008,\n",
       "         0.88983697, 0.02375584, 0.87875247, 0.86789995, 0.8509256 ,\n",
       "         0.15419638, 0.86991626]], dtype=float32),\n",
       " array([[0.23322381, 0.18635459, 0.19495445, 0.6628547 , 0.21867928,\n",
       "         0.85411054, 0.09711435, 0.8329884 , 0.83303297, 0.78464276,\n",
       "         0.19277841, 0.8325879 ]], dtype=float32),\n",
       " array([[0.4140804 , 0.21098527, 0.24396239, 0.6556364 , 0.24341092,\n",
       "         0.7924884 , 0.5499598 , 0.7353829 , 0.77226216, 0.63363606,\n",
       "         0.26903594, 0.7553801 ]], dtype=float32),\n",
       " array([[0.53113306, 0.21923605, 0.2973088 , 0.64499176, 0.26376414,\n",
       "         0.7115669 , 0.82186574, 0.66894364, 0.6839466 , 0.5375362 ,\n",
       "         0.33314294, 0.704239  ]], dtype=float32),\n",
       " array([[0.61741036, 0.2216251 , 0.32011724, 0.6517632 , 0.27775776,\n",
       "         0.6952065 , 0.93188965, 0.5989394 , 0.6775655 , 0.4590406 ,\n",
       "         0.38873574, 0.65089905]], dtype=float32),\n",
       " array([[0.6238347 , 0.21680494, 0.33783448, 0.67150486, 0.28302735,\n",
       "         0.68445003, 0.9453245 , 0.55032355, 0.67244387, 0.4598352 ,\n",
       "         0.39527047, 0.61023504]], dtype=float32),\n",
       " array([[0.5890397 , 0.21748444, 0.3279418 , 0.6798713 , 0.2674639 ,\n",
       "         0.684811  , 0.8999762 , 0.6062432 , 0.6781047 , 0.5096772 ,\n",
       "         0.37602   , 0.6493163 ]], dtype=float32),\n",
       " array([[0.5460332 , 0.20815876, 0.3183958 , 0.6847394 , 0.26519445,\n",
       "         0.70659477, 0.8457094 , 0.61738914, 0.69694513, 0.5594515 ,\n",
       "         0.35573426, 0.65410894]], dtype=float32),\n",
       " array([[0.54962426, 0.20089968, 0.31502956, 0.6947984 , 0.26429346,\n",
       "         0.70403415, 0.85690475, 0.591781  , 0.6923209 , 0.5633289 ,\n",
       "         0.367259  , 0.6308868 ]], dtype=float32),\n",
       " array([[0.5642087 , 0.20674759, 0.32726744, 0.7009562 , 0.27034235,\n",
       "         0.6871041 , 0.88503313, 0.5540272 , 0.6838143 , 0.570211  ,\n",
       "         0.37716344, 0.5983823 ]], dtype=float32),\n",
       " array([[0.52578366, 0.20970753, 0.30879748, 0.70220625, 0.25948423,\n",
       "         0.7064862 , 0.81262726, 0.6054025 , 0.71040255, 0.61186564,\n",
       "         0.35749832, 0.63884234]], dtype=float32),\n",
       " array([[0.4774696 , 0.20815179, 0.32666406, 0.718279  , 0.25675094,\n",
       "         0.6842337 , 0.7395772 , 0.6345466 , 0.69702214, 0.64322627,\n",
       "         0.3305537 , 0.66018844]], dtype=float32),\n",
       " array([[0.43790555, 0.20066045, 0.32208312, 0.71208656, 0.25842792,\n",
       "         0.7105424 , 0.653295  , 0.66730905, 0.7154238 , 0.6538428 ,\n",
       "         0.30512258, 0.6893679 ]], dtype=float32),\n",
       " array([[0.4278403 , 0.19783747, 0.30785874, 0.6996189 , 0.2553239 ,\n",
       "         0.7221483 , 0.60431045, 0.6835662 , 0.71555525, 0.65980065,\n",
       "         0.30031678, 0.7048633 ]], dtype=float32),\n",
       " array([[0.3421232 , 0.18644188, 0.2509913 , 0.6659827 , 0.24223316,\n",
       "         0.8077318 , 0.296367  , 0.75898623, 0.78500134, 0.72881067,\n",
       "         0.25686777, 0.7689771 ]], dtype=float32),\n",
       " array([[0.18584786, 0.1629801 , 0.17449573, 0.66565675, 0.20624101,\n",
       "         0.88817185, 0.02972985, 0.8621929 , 0.8625033 , 0.8482362 ,\n",
       "         0.17290907, 0.8506002 ]], dtype=float32),\n",
       " array([[0.17635949, 0.1694239 , 0.17012644, 0.6594628 , 0.20104215,\n",
       "         0.8865308 , 0.02165855, 0.89113665, 0.8648638 , 0.8524561 ,\n",
       "         0.1667211 , 0.8763272 ]], dtype=float32),\n",
       " array([[0.35536426, 0.19323277, 0.23249939, 0.65248275, 0.23512508,\n",
       "         0.8238762 , 0.29442215, 0.7904759 , 0.800827  , 0.70546657,\n",
       "         0.24831934, 0.7927751 ]], dtype=float32),\n",
       " array([[0.35641465, 0.19931972, 0.24367082, 0.64599776, 0.23620497,\n",
       "         0.7962205 , 0.30982947, 0.788938  , 0.77050406, 0.705578  ,\n",
       "         0.25673354, 0.79559016]], dtype=float32),\n",
       " array([[0.257692  , 0.181134  , 0.19538794, 0.634256  , 0.22423759,\n",
       "         0.8534055 , 0.099492  , 0.83595634, 0.8202467 , 0.7841215 ,\n",
       "         0.2075774 , 0.8313003 ]], dtype=float32),\n",
       " array([[0.12394978, 0.16292551, 0.16294102, 0.6188437 , 0.20722422,\n",
       "         0.899986  , 0.00612765, 0.9205714 , 0.87555104, 0.90478563,\n",
       "         0.148376  , 0.9031007 ]], dtype=float32),\n",
       " array([[0.10477619, 0.15924035, 0.15957835, 0.6284524 , 0.1965594 ,\n",
       "         0.89752865, 0.0029263 , 0.9438819 , 0.88061434, 0.9213657 ,\n",
       "         0.14844579, 0.92495453]], dtype=float32),\n",
       " array([[0.27688792, 0.18018919, 0.20436512, 0.6562337 , 0.2233984 ,\n",
       "         0.85353875, 0.1398333 , 0.8244334 , 0.8314015 , 0.7634529 ,\n",
       "         0.22276741, 0.8205759 ]], dtype=float32),\n",
       " array([[0.5420405 , 0.20602748, 0.28805512, 0.6611941 , 0.2604374 ,\n",
       "         0.7461744 , 0.8500723 , 0.6250352 , 0.7206062 , 0.5331568 ,\n",
       "         0.34694225, 0.6671953 ]], dtype=float32),\n",
       " array([[0.5511733 , 0.20787105, 0.3051306 , 0.69238305, 0.2534971 ,\n",
       "         0.71152097, 0.8623227 , 0.6228982 , 0.70033294, 0.52717054,\n",
       "         0.35363778, 0.66070366]], dtype=float32),\n",
       " array([[0.6362851 , 0.21996999, 0.33051068, 0.68541056, 0.26505688,\n",
       "         0.6751475 , 0.94456214, 0.54317945, 0.66308916, 0.46740228,\n",
       "         0.39722347, 0.5983706 ]], dtype=float32),\n",
       " array([[0.6522764 , 0.23158774, 0.3573105 , 0.69211304, 0.27215928,\n",
       "         0.6376974 , 0.95790535, 0.5397409 , 0.63969666, 0.44179457,\n",
       "         0.39969894, 0.5983301 ]], dtype=float32),\n",
       " array([[0.65099055, 0.23408183, 0.3521175 , 0.6820481 , 0.2742648 ,\n",
       "         0.6373333 , 0.95513743, 0.54425687, 0.62948513, 0.44206977,\n",
       "         0.3872304 , 0.60254335]], dtype=float32),\n",
       " array([[0.6194089 , 0.23227325, 0.31530562, 0.6596844 , 0.2723525 ,\n",
       "         0.68153614, 0.92943835, 0.5893265 , 0.6620571 , 0.46616462,\n",
       "         0.36657614, 0.64185387]], dtype=float32),\n",
       " array([[0.63048464, 0.22866063, 0.30960205, 0.6657676 , 0.27051038,\n",
       "         0.6946677 , 0.93197364, 0.54874057, 0.67432445, 0.49338543,\n",
       "         0.375478  , 0.6017611 ]], dtype=float32),\n",
       " array([[0.6095061 , 0.22286642, 0.3189086 , 0.68921393, 0.2662176 ,\n",
       "         0.6762146 , 0.917745  , 0.5652919 , 0.66990787, 0.5128734 ,\n",
       "         0.37844697, 0.61165863]], dtype=float32),\n",
       " array([[0.5583847 , 0.22123177, 0.2873961 , 0.6569406 , 0.2635926 ,\n",
       "         0.7280281 , 0.83914936, 0.6485457 , 0.7074026 , 0.53976417,\n",
       "         0.33994457, 0.68398005]], dtype=float32),\n",
       " array([[0.5447454 , 0.2261635 , 0.30985296, 0.67321515, 0.26786968,\n",
       "         0.6939542 , 0.8447573 , 0.62455475, 0.68335783, 0.55899453,\n",
       "         0.33264863, 0.66329354]], dtype=float32),\n",
       " array([[0.4848741 , 0.22684854, 0.2554184 , 0.65112484, 0.25136036,\n",
       "         0.75446266, 0.6904352 , 0.7001766 , 0.73395383, 0.60593504,\n",
       "         0.2968451 , 0.72651446]], dtype=float32),\n",
       " array([[0.41956714, 0.2129349 , 0.232452  , 0.6375112 , 0.24521422,\n",
       "         0.80410945, 0.4893829 , 0.74724895, 0.7805112 , 0.663128  ,\n",
       "         0.27718532, 0.7649957 ]], dtype=float32),\n",
       " array([[0.3889361 , 0.20032354, 0.23443444, 0.6545554 , 0.24003883,\n",
       "         0.8084417 , 0.40225452, 0.75554615, 0.7855004 , 0.68860114,\n",
       "         0.2675641 , 0.7672363 ]], dtype=float32),\n",
       " array([[0.26962727, 0.18490271, 0.20112395, 0.66260654, 0.21801202,\n",
       "         0.85353106, 0.10896783, 0.8281396 , 0.8324199 , 0.7876877 ,\n",
       "         0.2134746 , 0.8233041 ]], dtype=float32),\n",
       " array([[0.20752876, 0.17885283, 0.15935165, 0.62790084, 0.21041365,\n",
       "         0.89377457, 0.03983141, 0.87309265, 0.8685744 , 0.8328276 ,\n",
       "         0.18471286, 0.86324364]], dtype=float32),\n",
       " array([[0.11596081, 0.15900204, 0.16041088, 0.657762  , 0.1954843 ,\n",
       "         0.8974109 , 0.00560192, 0.9216314 , 0.8792032 , 0.9041815 ,\n",
       "         0.14559725, 0.9047663 ]], dtype=float32),\n",
       " array([[0.08933561, 0.15429859, 0.16464245, 0.6191302 , 0.20289974,\n",
       "         0.8999391 , 0.00211245, 0.9403676 , 0.8781847 , 0.93341905,\n",
       "         0.13791583, 0.9223243 ]], dtype=float32),\n",
       " array([[0.3345877 , 0.18397129, 0.21822701, 0.6392691 , 0.24424358,\n",
       "         0.836511  , 0.31015298, 0.7766352 , 0.8070381 , 0.70149845,\n",
       "         0.25202703, 0.7862099 ]], dtype=float32),\n",
       " array([[0.16413538, 0.16303788, 0.18608129, 0.63358057, 0.21109249,\n",
       "         0.8802545 , 0.01682156, 0.8908737 , 0.8528596 , 0.8792811 ,\n",
       "         0.17753045, 0.87364787]], dtype=float32),\n",
       " array([[0.2740733 , 0.17725484, 0.21668993, 0.6420915 , 0.22743352,\n",
       "         0.8378845 , 0.11882395, 0.83548194, 0.8107689 , 0.7834204 ,\n",
       "         0.23431665, 0.82676196]], dtype=float32),\n",
       " array([[0.41841382, 0.193148  , 0.2578927 , 0.6587627 , 0.24407518,\n",
       "         0.77708733, 0.5365899 , 0.74690485, 0.7537963 , 0.6366773 ,\n",
       "         0.29884943, 0.7592013 ]], dtype=float32),\n",
       " array([[0.49213135, 0.19647671, 0.31159788, 0.66085327, 0.26140764,\n",
       "         0.72402996, 0.74736935, 0.6820919 , 0.7029988 , 0.5858056 ,\n",
       "         0.34646907, 0.70922214]], dtype=float32),\n",
       " array([[0.6547096 , 0.21623695, 0.3416925 , 0.6738602 , 0.287434  ,\n",
       "         0.680419  , 0.96803665, 0.51977044, 0.6669762 , 0.4008918 ,\n",
       "         0.41009685, 0.5893988 ]], dtype=float32),\n",
       " array([[0.63930815, 0.21836953, 0.3492608 , 0.70808446, 0.26935682,\n",
       "         0.6533209 , 0.95781744, 0.52164936, 0.6533967 , 0.4382322 ,\n",
       "         0.39650634, 0.5819225 ]], dtype=float32),\n",
       " array([[0.6976644 , 0.22901253, 0.3620478 , 0.6991383 , 0.28767675,\n",
       "         0.6508808 , 0.981371  , 0.44447854, 0.6520316 , 0.39015654,\n",
       "         0.42032865, 0.52171725]], dtype=float32),\n",
       " array([[0.6829838 , 0.23367664, 0.3745323 , 0.72864425, 0.2699744 ,\n",
       "         0.6005437 , 0.9726725 , 0.4743609 , 0.62444764, 0.4380261 ,\n",
       "         0.4206256 , 0.53448796]], dtype=float32),\n",
       " array([[0.6652906 , 0.23843539, 0.37613449, 0.7207214 , 0.27301893,\n",
       "         0.6071767 , 0.9641254 , 0.49372664, 0.6352693 , 0.47388694,\n",
       "         0.4108874 , 0.5504219 ]], dtype=float32),\n",
       " array([[0.62380546, 0.23141667, 0.32391277, 0.69399875, 0.26491043,\n",
       "         0.6778163 , 0.9255794 , 0.5678133 , 0.6811906 , 0.5012126 ,\n",
       "         0.3752746 , 0.6132207 ]], dtype=float32),\n",
       " array([[0.5785629 , 0.23156263, 0.3285029 , 0.7071245 , 0.2589333 ,\n",
       "         0.6642284 , 0.88095075, 0.5957415 , 0.6806301 , 0.5612251 ,\n",
       "         0.35849574, 0.6297477 ]], dtype=float32),\n",
       " array([[0.58000094, 0.21997887, 0.32975772, 0.69690853, 0.26784873,\n",
       "         0.68134755, 0.8846003 , 0.5777237 , 0.6835675 , 0.55857134,\n",
       "         0.36588672, 0.6180342 ]], dtype=float32),\n",
       " array([[0.5526017 , 0.23247138, 0.34218833, 0.7266155 , 0.25187787,\n",
       "         0.63488585, 0.835156  , 0.609583  , 0.668572  , 0.6171763 ,\n",
       "         0.3536127 , 0.6312963 ]], dtype=float32),\n",
       " array([[0.49430868, 0.22164017, 0.29298267, 0.69792205, 0.24686874,\n",
       "         0.7097847 , 0.7076277 , 0.67389554, 0.7143445 , 0.63070625,\n",
       "         0.31935996, 0.6957472 ]], dtype=float32),\n",
       " array([[0.3657966 , 0.19349164, 0.2401105 , 0.6768379 , 0.23651223,\n",
       "         0.8086685 , 0.33970097, 0.746877  , 0.7885505 , 0.71608883,\n",
       "         0.25712943, 0.7580447 ]], dtype=float32),\n",
       " array([[0.34213236, 0.19862306, 0.23554724, 0.6682059 , 0.23233834,\n",
       "         0.8038571 , 0.28116423, 0.79029506, 0.7864303 , 0.7131403 ,\n",
       "         0.25003058, 0.7989846 ]], dtype=float32),\n",
       " array([[0.4407881 , 0.20053114, 0.27670482, 0.66345924, 0.25244498,\n",
       "         0.7703546 , 0.5727312 , 0.71417236, 0.7500545 , 0.6481226 ,\n",
       "         0.30030194, 0.7354578 ]], dtype=float32),\n",
       " array([[0.3470162 , 0.18520539, 0.26356938, 0.6939899 , 0.23210934,\n",
       "         0.78190166, 0.29735795, 0.7631127 , 0.7667087 , 0.7279514 ,\n",
       "         0.2655447 , 0.7694381 ]], dtype=float32),\n",
       " array([[0.39778048, 0.18868372, 0.27474755, 0.69410425, 0.23216017,\n",
       "         0.7645591 , 0.3946889 , 0.75907713, 0.75089914, 0.69273794,\n",
       "         0.2870344 , 0.7616706 ]], dtype=float32),\n",
       " array([[0.26302743, 0.16573405, 0.2237264 , 0.65716034, 0.23462968,\n",
       "         0.854817  , 0.10356831, 0.8336657 , 0.83074707, 0.7842424 ,\n",
       "         0.22348346, 0.82533133]], dtype=float32),\n",
       " array([[0.2546198 , 0.16660194, 0.22434784, 0.66465634, 0.23293893,\n",
       "         0.8389478 , 0.10967457, 0.83204937, 0.81778646, 0.78300124,\n",
       "         0.23504364, 0.828415  ]], dtype=float32),\n",
       " array([[0.42840225, 0.1886242 , 0.2992118 , 0.6761366 , 0.25681874,\n",
       "         0.7460246 , 0.6008834 , 0.68172777, 0.7210903 , 0.6532615 ,\n",
       "         0.30960795, 0.70874774]], dtype=float32),\n",
       " array([[0.4303667 , 0.18618546, 0.3167849 , 0.6918968 , 0.25393584,\n",
       "         0.7228049 , 0.6013723 , 0.6867898 , 0.7036256 , 0.65276027,\n",
       "         0.31458792, 0.7085697 ]], dtype=float32),\n",
       " array([[0.33857504, 0.17429507, 0.23531368, 0.6618983 , 0.2345975 ,\n",
       "         0.82052404, 0.2606577 , 0.77118665, 0.78864473, 0.7326542 ,\n",
       "         0.2629055 , 0.7746791 ]], dtype=float32),\n",
       " array([[0.39877892, 0.17670381, 0.25390813, 0.65799165, 0.250567  ,\n",
       "         0.80019414, 0.49121523, 0.7039977 , 0.7625589 , 0.67306966,\n",
       "         0.29435202, 0.7250355 ]], dtype=float32),\n",
       " array([[0.42366293, 0.1936962 , 0.26999876, 0.66957504, 0.24953862,\n",
       "         0.77188283, 0.5587202 , 0.73091096, 0.7559894 , 0.6414761 ,\n",
       "         0.3060849 , 0.74864924]], dtype=float32),\n",
       " array([[0.26581392, 0.17655522, 0.19796628, 0.64880675, 0.23111361,\n",
       "         0.85478896, 0.13627578, 0.8188853 , 0.8274888 , 0.7637519 ,\n",
       "         0.21961354, 0.8194332 ]], dtype=float32),\n",
       " array([[0.2465254 , 0.17222932, 0.20248187, 0.66673756, 0.22555341,\n",
       "         0.8494576 , 0.11105541, 0.82051915, 0.8216402 , 0.7763237 ,\n",
       "         0.205698  , 0.8185903 ]], dtype=float32),\n",
       " array([[0.4381309 , 0.1992773 , 0.25172853, 0.6689987 , 0.23953523,\n",
       "         0.78078336, 0.5700574 , 0.7209163 , 0.75708705, 0.6365227 ,\n",
       "         0.29209477, 0.737206  ]], dtype=float32),\n",
       " array([[0.50430095, 0.21118169, 0.2793396 , 0.6661507 , 0.25066355,\n",
       "         0.74102557, 0.7528593 , 0.68273735, 0.72063744, 0.57551414,\n",
       "         0.32266644, 0.71018255]], dtype=float32),\n",
       " array([[0.5344174 , 0.21770701, 0.29371405, 0.6667185 , 0.25301716,\n",
       "         0.72081566, 0.81043667, 0.6474242 , 0.7015808 , 0.56822187,\n",
       "         0.33974934, 0.6831799 ]], dtype=float32),\n",
       " array([[0.48842412, 0.2182517 , 0.26229915, 0.65225357, 0.25100848,\n",
       "         0.75601524, 0.7243808 , 0.68257475, 0.7326762 , 0.5961129 ,\n",
       "         0.31215343, 0.7148069 ]], dtype=float32),\n",
       " array([[0.5359985 , 0.2228066 , 0.27028668, 0.651842  , 0.25531298,\n",
       "         0.7446707 , 0.81478876, 0.66097707, 0.7230321 , 0.55227274,\n",
       "         0.3331621 , 0.6976558 ]], dtype=float32),\n",
       " array([[0.29071766, 0.18802999, 0.17969275, 0.60651803, 0.23187532,\n",
       "         0.8598305 , 0.151638  , 0.82552963, 0.8227826 , 0.7574261 ,\n",
       "         0.22832103, 0.82609034]], dtype=float32),\n",
       " array([[0.33520788, 0.1874877 , 0.2081874 , 0.6447936 , 0.23627187,\n",
       "         0.8335971 , 0.27768794, 0.7841221 , 0.80356985, 0.71301574,\n",
       "         0.24764246, 0.7904283 ]], dtype=float32),\n",
       " array([[0.5661074 , 0.22455628, 0.3078842 , 0.677674  , 0.2580919 ,\n",
       "         0.7151985 , 0.86621714, 0.6135201 , 0.7053113 , 0.54365766,\n",
       "         0.34209195, 0.6521858 ]], dtype=float32),\n",
       " array([[0.55387235, 0.22095951, 0.33001572, 0.704464  , 0.24890721,\n",
       "         0.68078786, 0.84130657, 0.62017375, 0.683834  , 0.57189924,\n",
       "         0.3471353 , 0.65123534]], dtype=float32),\n",
       " array([[0.5443997 , 0.2206259 , 0.32758352, 0.6994874 , 0.25443536,\n",
       "         0.6875411 , 0.83461684, 0.63257754, 0.6918555 , 0.5679972 ,\n",
       "         0.34266475, 0.66367877]], dtype=float32),\n",
       " array([[0.56011003, 0.2259212 , 0.3734588 , 0.72499925, 0.26095316,\n",
       "         0.641707  , 0.8722626 , 0.6044492 , 0.6733163 , 0.56968504,\n",
       "         0.3547026 , 0.633745  ]], dtype=float32),\n",
       " array([[0.52328664, 0.21323647, 0.332073  , 0.69558287, 0.26392686,\n",
       "         0.69295514, 0.8184915 , 0.63115275, 0.69447285, 0.58036226,\n",
       "         0.34056923, 0.66503936]], dtype=float32),\n",
       " array([[0.47154805, 0.20714986, 0.29803535, 0.6921403 , 0.24878204,\n",
       "         0.73011196, 0.66578585, 0.6913288 , 0.72517186, 0.62852985,\n",
       "         0.31293792, 0.71058536]], dtype=float32),\n",
       " array([[0.42106727, 0.19792601, 0.2756996 , 0.6852244 , 0.24493338,\n",
       "         0.7623187 , 0.52027875, 0.728699  , 0.7500518 , 0.6602387 ,\n",
       "         0.2883569 , 0.7408513 ]], dtype=float32),\n",
       " array([[0.3340135 , 0.18450251, 0.22137044, 0.6679453 , 0.23143603,\n",
       "         0.8349418 , 0.24115868, 0.7884464 , 0.8129534 , 0.72821164,\n",
       "         0.2391619 , 0.7871396 ]], dtype=float32),\n",
       " array([[0.44298363, 0.19764428, 0.2592423 , 0.6562632 , 0.25620118,\n",
       "         0.78313494, 0.61146444, 0.6849248 , 0.7551653 , 0.6454526 ,\n",
       "         0.29994887, 0.71150446]], dtype=float32),\n",
       " array([[0.46533257, 0.20684224, 0.29295838, 0.69089466, 0.24985152,\n",
       "         0.7375925 , 0.6629789 , 0.683853  , 0.7353074 , 0.64120036,\n",
       "         0.31843713, 0.7053383 ]], dtype=float32),\n",
       " array([[0.43535087, 0.20375462, 0.26130545, 0.6609007 , 0.25088438,\n",
       "         0.75726885, 0.59576726, 0.6926572 , 0.7298063 , 0.6514822 ,\n",
       "         0.29915327, 0.72006655]], dtype=float32),\n",
       " array([[0.4388188 , 0.19948417, 0.26377442, 0.6516348 , 0.25758216,\n",
       "         0.7667681 , 0.61099625, 0.6898795 , 0.7345446 , 0.64109504,\n",
       "         0.2989161 , 0.7183449 ]], dtype=float32),\n",
       " array([[0.44079778, 0.19709204, 0.28407308, 0.67189854, 0.25503615,\n",
       "         0.7529684 , 0.6039752 , 0.6957809 , 0.7338358 , 0.64943814,\n",
       "         0.3087092 , 0.7185159 ]], dtype=float32),\n",
       " array([[0.46898997, 0.20230871, 0.28853717, 0.6698408 , 0.2573622 ,\n",
       "         0.74455076, 0.6714521 , 0.68950903, 0.72803974, 0.6236878 ,\n",
       "         0.3200163 , 0.7143045 ]], dtype=float32),\n",
       " array([[0.31652144, 0.17989764, 0.22777528, 0.6552199 , 0.23809822,\n",
       "         0.82692087, 0.21487926, 0.78753126, 0.7987855 , 0.74664646,\n",
       "         0.24621858, 0.7902709 ]], dtype=float32),\n",
       " array([[0.38730097, 0.18725638, 0.26401502, 0.67206234, 0.24823281,\n",
       "         0.7880233 , 0.43221456, 0.7338528 , 0.76770556, 0.6921175 ,\n",
       "         0.2829884 , 0.7459715 ]], dtype=float32),\n",
       " array([[0.41804317, 0.19283502, 0.274274  , 0.68764925, 0.24317777,\n",
       "         0.762076  , 0.5129204 , 0.72170764, 0.74805516, 0.6706064 ,\n",
       "         0.2962616 , 0.7334684 ]], dtype=float32),\n",
       " array([[0.2579901 , 0.17543375, 0.19781463, 0.649398  , 0.22655995,\n",
       "         0.85972345, 0.10310888, 0.8249285 , 0.8323976 , 0.79019475,\n",
       "         0.21518779, 0.82168037]], dtype=float32),\n",
       " array([[0.39516547, 0.19618748, 0.24624945, 0.66364133, 0.24427387,\n",
       "         0.7976363 , 0.46144146, 0.73013395, 0.7773941 , 0.68362325,\n",
       "         0.28258532, 0.74743634]], dtype=float32),\n",
       " array([[0.32169443, 0.19088304, 0.21195124, 0.62795883, 0.24154183,\n",
       "         0.8375778 , 0.23834065, 0.79469764, 0.8037843 , 0.72508466,\n",
       "         0.23397177, 0.8011348 ]], dtype=float32),\n",
       " array([[0.11004847, 0.15111335, 0.14292236, 0.6228696 , 0.20499767,\n",
       "         0.91579777, 0.00494324, 0.91573304, 0.8891591 , 0.9095968 ,\n",
       "         0.14069428, 0.8991257 ]], dtype=float32),\n",
       " array([[6.0853880e-02, 1.4906043e-01, 1.5627542e-01, 5.8902419e-01,\n",
       "         2.0524529e-01, 9.0964293e-01, 5.1040924e-04, 9.6278048e-01,\n",
       "         8.8934332e-01, 9.5713556e-01, 1.1918289e-01, 9.4539082e-01]],\n",
       "       dtype=float32),\n",
       " array([[0.11540654, 0.15059733, 0.17454141, 0.6584551 , 0.20351894,\n",
       "         0.89020354, 0.0061772 , 0.91946065, 0.87123466, 0.9014738 ,\n",
       "         0.15187347, 0.9006476 ]], dtype=float32),\n",
       " array([[0.18748298, 0.16811329, 0.17511232, 0.65075904, 0.20456658,\n",
       "         0.87961215, 0.02948361, 0.882643  , 0.8546694 , 0.84481114,\n",
       "         0.17966694, 0.8666596 ]], dtype=float32),\n",
       " array([[0.23223655, 0.176229  , 0.18384278, 0.6525985 , 0.20977776,\n",
       "         0.8671593 , 0.07304116, 0.84110063, 0.83808124, 0.8060932 ,\n",
       "         0.19670367, 0.83297634]], dtype=float32),\n",
       " array([[0.28229615, 0.19075766, 0.19781922, 0.63529384, 0.2185973 ,\n",
       "         0.8524038 , 0.13687778, 0.82520294, 0.8241095 , 0.7734441 ,\n",
       "         0.22072022, 0.82182646]], dtype=float32),\n",
       " array([[0.43301952, 0.21322075, 0.23504755, 0.61880696, 0.24272443,\n",
       "         0.79905254, 0.5350462 , 0.7529797 , 0.7635488 , 0.6380434 ,\n",
       "         0.2778324 , 0.7667887 ]], dtype=float32),\n",
       " array([[0.61216056, 0.23719162, 0.3035158 , 0.624313  , 0.2735552 ,\n",
       "         0.7068794 , 0.91983014, 0.6538172 , 0.6871652 , 0.45476866,\n",
       "         0.37491742, 0.6972144 ]], dtype=float32),\n",
       " array([[0.65619355, 0.2345475 , 0.2998676 , 0.64644754, 0.273972  ,\n",
       "         0.70773625, 0.95980924, 0.5695111 , 0.6879281 , 0.40616506,\n",
       "         0.39488906, 0.63290167]], dtype=float32),\n",
       " array([[0.65546584, 0.23320286, 0.30505323, 0.6655214 , 0.26726094,\n",
       "         0.68978804, 0.95847875, 0.56998223, 0.673069  , 0.40452746,\n",
       "         0.387643  , 0.62879235]], dtype=float32),\n",
       " array([[0.420205  , 0.19312416, 0.2140944 , 0.6306585 , 0.2355383 ,\n",
       "         0.83183587, 0.44428927, 0.75199956, 0.79432386, 0.67139995,\n",
       "         0.27757862, 0.7563591 ]], dtype=float32),\n",
       " array([[0.4287147 , 0.19694729, 0.22184059, 0.6347503 , 0.24697903,\n",
       "         0.81123286, 0.5628008 , 0.7301174 , 0.7766663 , 0.6295307 ,\n",
       "         0.28789353, 0.74639845]], dtype=float32),\n",
       " array([[0.4965569 , 0.22075847, 0.2517946 , 0.6565097 , 0.24692692,\n",
       "         0.7686413 , 0.74758214, 0.7046978 , 0.74936515, 0.559035  ,\n",
       "         0.3025089 , 0.72991174]], dtype=float32),\n",
       " array([[0.5775526 , 0.23661944, 0.2688288 , 0.65456337, 0.26317006,\n",
       "         0.737941  , 0.9140522 , 0.58677673, 0.7142861 , 0.47965765,\n",
       "         0.33044568, 0.64626664]], dtype=float32),\n",
       " array([[0.49532562, 0.21906613, 0.25296265, 0.6883476 , 0.23832475,\n",
       "         0.76073474, 0.7666808 , 0.65556926, 0.7443628 , 0.56996137,\n",
       "         0.29354626, 0.68845487]], dtype=float32),\n",
       " array([[0.6015042 , 0.23154052, 0.29834804, 0.6825485 , 0.26123494,\n",
       "         0.7040173 , 0.92240465, 0.5699682 , 0.69311535, 0.4865974 ,\n",
       "         0.35132065, 0.6228127 ]], dtype=float32),\n",
       " array([[0.6117171 , 0.23562466, 0.30231598, 0.6664898 , 0.26789662,\n",
       "         0.7019231 , 0.92739505, 0.5992993 , 0.69278467, 0.46526527,\n",
       "         0.3627224 , 0.65155774]], dtype=float32),\n",
       " array([[0.6324392 , 0.23615894, 0.3419888 , 0.6901936 , 0.2748302 ,\n",
       "         0.6597082 , 0.9489267 , 0.5299241 , 0.6618808 , 0.4732129 ,\n",
       "         0.37630212, 0.590776  ]], dtype=float32),\n",
       " array([[0.62909555, 0.23007023, 0.38159162, 0.72566   , 0.26974478,\n",
       "         0.59406614, 0.94943494, 0.50845563, 0.6143587 , 0.49469638,\n",
       "         0.3905656 , 0.5652486 ]], dtype=float32),\n",
       " array([[0.6106178 , 0.22483553, 0.37110996, 0.72755617, 0.2651484 ,\n",
       "         0.622782  , 0.9250018 , 0.5341388 , 0.6474096 , 0.5383891 ,\n",
       "         0.3856085 , 0.5776536 ]], dtype=float32),\n",
       " array([[0.6042526 , 0.21993077, 0.35618606, 0.7249754 , 0.26231116,\n",
       "         0.65000874, 0.9065934 , 0.5610724 , 0.67337817, 0.54897785,\n",
       "         0.38977593, 0.60026824]], dtype=float32),\n",
       " array([[0.56195277, 0.2131065 , 0.35112154, 0.7300518 , 0.2578387 ,\n",
       "         0.65499777, 0.85554636, 0.59489304, 0.68004376, 0.5881328 ,\n",
       "         0.37529933, 0.6249422 ]], dtype=float32),\n",
       " array([[0.51993376, 0.21545386, 0.29914412, 0.6781542 , 0.26366934,\n",
       "         0.7221659 , 0.7867553 , 0.6441399 , 0.7131695 , 0.58959085,\n",
       "         0.33201095, 0.67839354]], dtype=float32),\n",
       " array([[0.5104849 , 0.20772807, 0.33211067, 0.7040167 , 0.26350385,\n",
       "         0.6820464 , 0.78146714, 0.6270271 , 0.6810189 , 0.6073478 ,\n",
       "         0.33599225, 0.65811485]], dtype=float32),\n",
       " array([[0.4656659 , 0.19537237, 0.3254199 , 0.68585044, 0.2720966 ,\n",
       "         0.7097403 , 0.7079756 , 0.6438141 , 0.69044226, 0.6261852 ,\n",
       "         0.3157061 , 0.6766666 ]], dtype=float32),\n",
       " array([[0.43845543, 0.19002935, 0.3336783 , 0.7202724 , 0.25450328,\n",
       "         0.6996213 , 0.61303794, 0.67236733, 0.7022508 , 0.66998065,\n",
       "         0.32081082, 0.69048595]], dtype=float32),\n",
       " array([[0.4778725 , 0.20223235, 0.3421148 , 0.7195998 , 0.25971437,\n",
       "         0.6917123 , 0.72356933, 0.64162886, 0.7103416 , 0.6559882 ,\n",
       "         0.346927  , 0.6667276 ]], dtype=float32),\n",
       " array([[0.42756972, 0.194268  , 0.35399407, 0.742965  , 0.24493739,\n",
       "         0.6746662 , 0.5569136 , 0.6644204 , 0.70188224, 0.7300076 ,\n",
       "         0.33479533, 0.67468876]], dtype=float32),\n",
       " array([[0.4515588 , 0.20158479, 0.33550316, 0.7214386 , 0.2501287 ,\n",
       "         0.6967222 , 0.6138041 , 0.6727777 , 0.71721   , 0.6967035 ,\n",
       "         0.33768085, 0.68813163]], dtype=float32),\n",
       " array([[0.41023687, 0.18944614, 0.31834564, 0.7232278 , 0.24298711,\n",
       "         0.72495663, 0.47987738, 0.70764405, 0.73668265, 0.7187973 ,\n",
       "         0.3213359 , 0.7163607 ]], dtype=float32),\n",
       " array([[0.4869127 , 0.19886203, 0.36583492, 0.7268806 , 0.26130727,\n",
       "         0.67845786, 0.72103554, 0.62771213, 0.70284605, 0.68481123,\n",
       "         0.3627097 , 0.64654833]], dtype=float32),\n",
       " array([[0.45978853, 0.19673568, 0.32492256, 0.72251934, 0.24516302,\n",
       "         0.70296216, 0.6045722 , 0.68925655, 0.71611655, 0.67969984,\n",
       "         0.33586025, 0.6986994 ]], dtype=float32),\n",
       " array([[0.40375397, 0.18896343, 0.26792204, 0.68583935, 0.24285927,\n",
       "         0.77469176, 0.4330526 , 0.7271744 , 0.7607893 , 0.7043069 ,\n",
       "         0.3001702 , 0.73870957]], dtype=float32),\n",
       " array([[0.3899032 , 0.18316767, 0.27242225, 0.6805783 , 0.24643408,\n",
       "         0.7673134 , 0.41331246, 0.7343446 , 0.7407833 , 0.6939734 ,\n",
       "         0.2859634 , 0.74586034]], dtype=float32),\n",
       " array([[0.41045642, 0.18922602, 0.30348477, 0.69586384, 0.2568821 ,\n",
       "         0.73998815, 0.52531606, 0.7039666 , 0.72888225, 0.6823861 ,\n",
       "         0.29857355, 0.7189055 ]], dtype=float32),\n",
       " array([[0.36506003, 0.18335648, 0.27238566, 0.6868332 , 0.2441679 ,\n",
       "         0.7721663 , 0.35003462, 0.75515217, 0.7540911 , 0.7117056 ,\n",
       "         0.277691  , 0.7625806 ]], dtype=float32),\n",
       " array([[0.31339666, 0.17628974, 0.25660816, 0.6979902 , 0.23511389,\n",
       "         0.80090845, 0.21785414, 0.7785659 , 0.7862796 , 0.7556385 ,\n",
       "         0.25163198, 0.77856255]], dtype=float32),\n",
       " array([[0.3782952 , 0.18704095, 0.27907345, 0.69066405, 0.24630861,\n",
       "         0.7687408 , 0.39576986, 0.7395766 , 0.75533015, 0.7085812 ,\n",
       "         0.2816277 , 0.7480673 ]], dtype=float32),\n",
       " array([[0.40386072, 0.18843067, 0.28604743, 0.6818408 , 0.25078276,\n",
       "         0.75923413, 0.47339764, 0.7234522 , 0.7402339 , 0.68579507,\n",
       "         0.29363447, 0.7367866 ]], dtype=float32),\n",
       " array([[0.36440408, 0.18885948, 0.26056442, 0.6739015 , 0.23960412,\n",
       "         0.7863543 , 0.33783302, 0.7674697 , 0.76622355, 0.7049284 ,\n",
       "         0.26790288, 0.7748504 ]], dtype=float32),\n",
       " array([[0.30280367, 0.17902645, 0.21606821, 0.6486324 , 0.23224866,\n",
       "         0.83995855, 0.17518917, 0.8008008 , 0.80751354, 0.75000316,\n",
       "         0.23377383, 0.8046745 ]], dtype=float32),\n",
       " array([[0.35998648, 0.19113775, 0.23113613, 0.64858764, 0.23894997,\n",
       "         0.8206515 , 0.31127554, 0.779854  , 0.7931496 , 0.7000927 ,\n",
       "         0.25420964, 0.78753066]], dtype=float32),\n",
       " array([[0.40506673, 0.19618268, 0.24777858, 0.64822936, 0.24206585,\n",
       "         0.7961769 , 0.42878687, 0.76420873, 0.7681654 , 0.66388667,\n",
       "         0.27697253, 0.77496463]], dtype=float32),\n",
       " array([[0.3217312 , 0.18874596, 0.21047434, 0.6460534 , 0.2250848 ,\n",
       "         0.8345902 , 0.19656672, 0.81309134, 0.8046825 , 0.7316378 ,\n",
       "         0.23574   , 0.814198  ]], dtype=float32),\n",
       " array([[0.2987017 , 0.18595932, 0.18793014, 0.6243889 , 0.22256884,\n",
       "         0.8602488 , 0.14862478, 0.82061505, 0.82287294, 0.7503306 ,\n",
       "         0.21988298, 0.8219669 ]], dtype=float32),\n",
       " array([[0.29340073, 0.18398987, 0.19364853, 0.6388727 , 0.22202843,\n",
       "         0.85629255, 0.14397317, 0.828586  , 0.82515746, 0.74850136,\n",
       "         0.2190301 , 0.82639205]], dtype=float32),\n",
       " array([[0.3851891 , 0.19445698, 0.24680974, 0.6511961 , 0.2409872 ,\n",
       "         0.7961085 , 0.40526438, 0.76944375, 0.7694802 , 0.66871434,\n",
       "         0.26978245, 0.779551  ]], dtype=float32),\n",
       " array([[0.37692952, 0.19827072, 0.2403623 , 0.6491593 , 0.23708577,\n",
       "         0.802105  , 0.37169638, 0.77557963, 0.7759682 , 0.6801796 ,\n",
       "         0.26081184, 0.7845685 ]], dtype=float32),\n",
       " array([[0.29374975, 0.18592666, 0.20687008, 0.647887  , 0.22523043,\n",
       "         0.83891267, 0.16891102, 0.8123556 , 0.80711186, 0.74264294,\n",
       "         0.21654548, 0.8125559 ]], dtype=float32),\n",
       " array([[0.45355526, 0.20518689, 0.26075312, 0.6504987 , 0.24664457,\n",
       "         0.7771428 , 0.5996797 , 0.7250094 , 0.7518963 , 0.62435657,\n",
       "         0.2969167 , 0.74307954]], dtype=float32),\n",
       " array([[0.53542775, 0.21812233, 0.29119924, 0.6606759 , 0.2512751 ,\n",
       "         0.73334664, 0.7937337 , 0.6689851 , 0.7153666 , 0.5667111 ,\n",
       "         0.3370176 , 0.6988277 ]], dtype=float32),\n",
       " array([[0.50216246, 0.21360695, 0.28284454, 0.659324  , 0.2514953 ,\n",
       "         0.7445608 , 0.73640245, 0.6844266 , 0.7251914 , 0.59076816,\n",
       "         0.32362628, 0.7122284 ]], dtype=float32),\n",
       " array([[0.38861224, 0.19801286, 0.22372031, 0.6364299 , 0.24170135,\n",
       "         0.8153925 , 0.4249549 , 0.75550175, 0.78283167, 0.6693967 ,\n",
       "         0.26672867, 0.7705941 ]], dtype=float32),\n",
       " array([[0.40316123, 0.1992943 , 0.228393  , 0.64006567, 0.24411024,\n",
       "         0.81156987, 0.46792012, 0.751747  , 0.78198844, 0.655022  ,\n",
       "         0.27199548, 0.76638997]], dtype=float32),\n",
       " array([[0.47276214, 0.20978813, 0.25679997, 0.6501018 , 0.24896958,\n",
       "         0.77001363, 0.6614891 , 0.7157149 , 0.74570006, 0.60167015,\n",
       "         0.30491778, 0.7371942 ]], dtype=float32),\n",
       " array([[0.44832462, 0.20805569, 0.25947598, 0.6623643 , 0.2452748 ,\n",
       "         0.7634717 , 0.6123183 , 0.716112  , 0.7422582 , 0.6256816 ,\n",
       "         0.29591545, 0.7368413 ]], dtype=float32),\n",
       " array([[0.41909233, 0.20333946, 0.23518926, 0.64251786, 0.24811883,\n",
       "         0.7969871 , 0.53817695, 0.7297746 , 0.76755494, 0.64263994,\n",
       "         0.28080624, 0.7505626 ]], dtype=float32),\n",
       " array([[0.47415918, 0.20873228, 0.2617467 , 0.65661466, 0.25412503,\n",
       "         0.7643178 , 0.6984893 , 0.67185   , 0.73816425, 0.6128902 ,\n",
       "         0.30648944, 0.7019737 ]], dtype=float32),\n",
       " array([[0.4612285 , 0.20851637, 0.25513488, 0.65528756, 0.24947806,\n",
       "         0.76669115, 0.6517987 , 0.70425206, 0.7427364 , 0.6157517 ,\n",
       "         0.3049853 , 0.72929895]], dtype=float32),\n",
       " array([[0.2836771 , 0.18449767, 0.18608584, 0.6121535 , 0.23533906,\n",
       "         0.86305845, 0.15525675, 0.8071937 , 0.8252771 , 0.76208055,\n",
       "         0.22178248, 0.8122982 ]], dtype=float32),\n",
       " array([[0.27396336, 0.18282722, 0.19239067, 0.64762825, 0.22843066,\n",
       "         0.85531974, 0.14971048, 0.81050426, 0.82702327, 0.75993073,\n",
       "         0.2149245 , 0.81260055]], dtype=float32),\n",
       " array([[0.41667914, 0.20210296, 0.24944417, 0.6646377 , 0.24172695,\n",
       "         0.78656936, 0.51584905, 0.7358899 , 0.7658139 , 0.65179324,\n",
       "         0.27850825, 0.75022644]], dtype=float32),\n",
       " array([[0.40079615, 0.20129904, 0.23638485, 0.65557486, 0.23823722,\n",
       "         0.8025794 , 0.4499236 , 0.7548778 , 0.78046703, 0.6679973 ,\n",
       "         0.27296144, 0.76589936]], dtype=float32),\n",
       " array([[0.33607897, 0.18785113, 0.21970427, 0.651876  , 0.23555557,\n",
       "         0.83187646, 0.27968705, 0.77289754, 0.8030998 , 0.72019887,\n",
       "         0.24269773, 0.77958924]], dtype=float32),\n",
       " array([[0.44322428, 0.1997535 , 0.2914576 , 0.68661535, 0.2504913 ,\n",
       "         0.7435441 , 0.6384092 , 0.68259484, 0.72997075, 0.638999  ,\n",
       "         0.30228105, 0.70599985]], dtype=float32),\n",
       " array([[0.46003887, 0.20667166, 0.2775482 , 0.66365236, 0.25192115,\n",
       "         0.7509555 , 0.6543919 , 0.70855117, 0.73283535, 0.61481667,\n",
       "         0.30726027, 0.73078436]], dtype=float32),\n",
       " array([[0.1450399 , 0.16246217, 0.15445852, 0.61229175, 0.21448623,\n",
       "         0.90665466, 0.01287982, 0.8978303 , 0.8784481 , 0.8798336 ,\n",
       "         0.15708683, 0.8839163 ]], dtype=float32),\n",
       " array([[0.14542316, 0.15645064, 0.16611558, 0.65917104, 0.20860595,\n",
       "         0.89326096, 0.01570075, 0.89122015, 0.8712504 , 0.86955607,\n",
       "         0.16102917, 0.8763614 ]], dtype=float32),\n",
       " array([[0.43266106, 0.19267777, 0.25798193, 0.6646453 , 0.2509209 ,\n",
       "         0.7852373 , 0.6157767 , 0.6981555 , 0.7581195 , 0.6228237 ,\n",
       "         0.29135415, 0.72068053]], dtype=float32),\n",
       " array([[0.21122855, 0.16281891, 0.18808533, 0.6602629 , 0.21508707,\n",
       "         0.87520343, 0.0483642 , 0.85632396, 0.8504097 , 0.8274048 ,\n",
       "         0.19385804, 0.84169936]], dtype=float32),\n",
       " array([[0.40079972, 0.19534378, 0.25423026, 0.6648702 , 0.24361818,\n",
       "         0.7934355 , 0.48004588, 0.7456462 , 0.77381307, 0.6601343 ,\n",
       "         0.27708322, 0.75674784]], dtype=float32),\n",
       " array([[0.16169389, 0.1616191 , 0.17159793, 0.642699  , 0.21554784,\n",
       "         0.8908632 , 0.02258076, 0.869419  , 0.8613517 , 0.86396706,\n",
       "         0.16244744, 0.8563763 ]], dtype=float32),\n",
       " array([[0.15154065, 0.16315809, 0.17517968, 0.65447927, 0.21003878,\n",
       "         0.881853  , 0.01824264, 0.88602686, 0.8605148 , 0.87194735,\n",
       "         0.16914505, 0.871773  ]], dtype=float32),\n",
       " array([[0.15362191, 0.16380775, 0.13935906, 0.5476115 , 0.23593006,\n",
       "         0.9177422 , 0.02237305, 0.8684863 , 0.8756948 , 0.86808056,\n",
       "         0.16604275, 0.86320454]], dtype=float32),\n",
       " array([[0.15237619, 0.17539847, 0.19800627, 0.6105047 , 0.20942603,\n",
       "         0.8563776 , 0.01187918, 0.90704775, 0.8275122 , 0.8992956 ,\n",
       "         0.17830363, 0.887152  ]], dtype=float32),\n",
       " array([[0.58273154, 0.22135758, 0.2559204 , 0.636538  , 0.25723234,\n",
       "         0.7753512 , 0.90492463, 0.5979153 , 0.7356766 , 0.4766628 ,\n",
       "         0.33207992, 0.64844286]], dtype=float32),\n",
       " array([[0.6075821 , 0.22603987, 0.31266832, 0.6761847 , 0.25182596,\n",
       "         0.689518  , 0.9180288 , 0.62901944, 0.67989105, 0.46243235,\n",
       "         0.37227416, 0.6685433 ]], dtype=float32),\n",
       " array([[0.67322755, 0.2373738 , 0.35145724, 0.6815029 , 0.27173603,\n",
       "         0.63262045, 0.96965146, 0.5573032 , 0.6314633 , 0.38331392,\n",
       "         0.40653417, 0.6191772 ]], dtype=float32),\n",
       " array([[0.64446086, 0.24051888, 0.33250198, 0.67464966, 0.26589012,\n",
       "         0.6500389 , 0.9518234 , 0.5881    , 0.64066374, 0.41744354,\n",
       "         0.37333202, 0.64144254]], dtype=float32),\n",
       " array([[0.6151379 , 0.24154952, 0.29940593, 0.6243369 , 0.2761296 ,\n",
       "         0.7134704 , 0.92429435, 0.639855  , 0.69724303, 0.45938283,\n",
       "         0.37533668, 0.6883183 ]], dtype=float32),\n",
       " array([[0.6591431 , 0.2396063 , 0.28896925, 0.6305503 , 0.27460384,\n",
       "         0.7193347 , 0.9512178 , 0.6271763 , 0.70525265, 0.40928605,\n",
       "         0.40054718, 0.6749366 ]], dtype=float32),\n",
       " array([[0.41311592, 0.21066765, 0.22769377, 0.6541844 , 0.22636913,\n",
       "         0.8016351 , 0.44473478, 0.7580963 , 0.7723974 , 0.66965836,\n",
       "         0.25859347, 0.76372546]], dtype=float32),\n",
       " array([[0.38907024, 0.19917303, 0.18806612, 0.6706544 , 0.20993122,\n",
       "         0.84001243, 0.34940198, 0.7833672 , 0.81788474, 0.6870546 ,\n",
       "         0.25495753, 0.7792546 ]], dtype=float32),\n",
       " array([[0.1495975 , 0.16035536, 0.14008904, 0.66683376, 0.18293387,\n",
       "         0.9090053 , 0.01259228, 0.8757731 , 0.8803605 , 0.89076847,\n",
       "         0.14687896, 0.85355055]], dtype=float32),\n",
       " array([[0.3051546 , 0.1910175 , 0.22477056, 0.6762381 , 0.22643515,\n",
       "         0.82489127, 0.23720697, 0.77248484, 0.8042666 , 0.74185216,\n",
       "         0.2258026 , 0.77841103]], dtype=float32),\n",
       " array([[0.38998023, 0.22289911, 0.24181473, 0.6757844 , 0.23087074,\n",
       "         0.7734675 , 0.5239268 , 0.73801905, 0.76070625, 0.64438194,\n",
       "         0.25243804, 0.760664  ]], dtype=float32),\n",
       " array([[0.44146037, 0.21921699, 0.25718248, 0.64978915, 0.25690144,\n",
       "         0.76666594, 0.70663786, 0.6614821 , 0.7410902 , 0.6082663 ,\n",
       "         0.28483889, 0.70546603]], dtype=float32),\n",
       " array([[0.5169411 , 0.22446762, 0.30765772, 0.66098964, 0.25183266,\n",
       "         0.71397954, 0.7638057 , 0.7046341 , 0.7054536 , 0.5753351 ,\n",
       "         0.3296257 , 0.72627586]], dtype=float32),\n",
       " array([[0.70118386, 0.24665244, 0.31924164, 0.6486372 , 0.286528  ,\n",
       "         0.6774515 , 0.9788408 , 0.5116137 , 0.659831  , 0.3670004 ,\n",
       "         0.40656316, 0.5856298 ]], dtype=float32),\n",
       " array([[0.66578454, 0.2348576 , 0.32552174, 0.66581726, 0.27334386,\n",
       "         0.6706064 , 0.9562606 , 0.5985847 , 0.66635084, 0.40881416,\n",
       "         0.40435067, 0.6488856 ]], dtype=float32),\n",
       " array([[0.59891737, 0.22052789, 0.3117781 , 0.67005634, 0.26745757,\n",
       "         0.7062676 , 0.9053165 , 0.620545  , 0.70085454, 0.4947211 ,\n",
       "         0.38182715, 0.6630418 ]], dtype=float32),\n",
       " array([[0.63478464, 0.22787695, 0.32245028, 0.68195206, 0.28019288,\n",
       "         0.68438333, 0.9529543 , 0.538114  , 0.6789874 , 0.44256616,\n",
       "         0.380976  , 0.6012058 ]], dtype=float32),\n",
       " array([[0.6637812 , 0.2364566 , 0.3277463 , 0.71544516, 0.26446727,\n",
       "         0.6477727 , 0.9611702 , 0.52728903, 0.66544473, 0.43721443,\n",
       "         0.3985308 , 0.5829812 ]], dtype=float32),\n",
       " array([[0.42547676, 0.19195221, 0.25940508, 0.6776242 , 0.24677315,\n",
       "         0.78845245, 0.538905  , 0.68128604, 0.76374567, 0.6754076 ,\n",
       "         0.28742665, 0.70240545]], dtype=float32),\n",
       " array([[0.3403914 , 0.19155352, 0.20024024, 0.7001317 , 0.21576042,\n",
       "         0.83849776, 0.26691413, 0.7771159 , 0.8306478 , 0.7284847 ,\n",
       "         0.24808018, 0.7785285 ]], dtype=float32),\n",
       " array([[0.43295094, 0.19736482, 0.2718015 , 0.6907404 , 0.25380376,\n",
       "         0.74759704, 0.6419096 , 0.6649212 , 0.7273615 , 0.6324937 ,\n",
       "         0.28942868, 0.69465774]], dtype=float32),\n",
       " array([[0.5097311 , 0.20761752, 0.29488158, 0.6830725 , 0.26241994,\n",
       "         0.7277011 , 0.79688555, 0.6322676 , 0.7165526 , 0.5814398 ,\n",
       "         0.33445632, 0.669782  ]], dtype=float32),\n",
       " array([[0.57857466, 0.21813558, 0.40292698, 0.7201002 , 0.2837736 ,\n",
       "         0.60628474, 0.9160564 , 0.51424164, 0.62903553, 0.5726635 ,\n",
       "         0.38121203, 0.5640381 ]], dtype=float32),\n",
       " array([[0.576136  , 0.21896788, 0.4542716 , 0.76790816, 0.26696342,\n",
       "         0.52246034, 0.9054678 , 0.5247722 , 0.5885057 , 0.61487263,\n",
       "         0.3997961 , 0.5550647 ]], dtype=float32),\n",
       " array([[0.5691299 , 0.22259173, 0.41143146, 0.74485844, 0.2599684 ,\n",
       "         0.5688727 , 0.8618478 , 0.5685558 , 0.6142487 , 0.62832433,\n",
       "         0.3805793 , 0.5916062 ]], dtype=float32),\n",
       " array([[0.58707327, 0.2178985 , 0.4119531 , 0.7405621 , 0.2694349 ,\n",
       "         0.60141456, 0.8773823 , 0.5558945 , 0.6523414 , 0.6300436 ,\n",
       "         0.4084871 , 0.58325297]], dtype=float32),\n",
       " array([[0.582243  , 0.22671536, 0.41349632, 0.7500078 , 0.2587644 ,\n",
       "         0.5587928 , 0.8588787 , 0.5846305 , 0.62043524, 0.6395316 ,\n",
       "         0.40327984, 0.6044629 ]], dtype=float32),\n",
       " array([[0.5551934 , 0.21460049, 0.3772032 , 0.7216247 , 0.2703316 ,\n",
       "         0.61357576, 0.84259063, 0.6062936 , 0.6322022 , 0.5899263 ,\n",
       "         0.36061865, 0.6337985 ]], dtype=float32),\n",
       " array([[0.5487104 , 0.20423341, 0.3528344 , 0.729449  , 0.2623285 ,\n",
       "         0.65777886, 0.8160528 , 0.6307923 , 0.68070424, 0.59194326,\n",
       "         0.37546358, 0.6545499 ]], dtype=float32),\n",
       " array([[0.5144129 , 0.19845933, 0.33037737, 0.7003311 , 0.26615182,\n",
       "         0.71663696, 0.7218175 , 0.66140044, 0.7203629 , 0.62773615,\n",
       "         0.35252652, 0.6820877 ]], dtype=float32),\n",
       " array([[0.45757544, 0.19555353, 0.29903865, 0.6801205 , 0.2643681 ,\n",
       "         0.74706435, 0.61429507, 0.69616854, 0.73481166, 0.6439315 ,\n",
       "         0.31540632, 0.71656716]], dtype=float32),\n",
       " array([[0.30269852, 0.17648378, 0.2730894 , 0.6892778 , 0.24183433,\n",
       "         0.7709168 , 0.19660015, 0.78312546, 0.7439642 , 0.752258  ,\n",
       "         0.23905864, 0.786866  ]], dtype=float32),\n",
       " array([[0.1631645 , 0.14744268, 0.21146622, 0.6838578 , 0.21759899,\n",
       "         0.8626014 , 0.02154807, 0.86417884, 0.832036  , 0.86244065,\n",
       "         0.17394704, 0.8527077 ]], dtype=float32),\n",
       " array([[0.15056302, 0.15188262, 0.17108414, 0.70000434, 0.19937317,\n",
       "         0.8886523 , 0.01758729, 0.8629389 , 0.8664842 , 0.87241495,\n",
       "         0.16137734, 0.85206956]], dtype=float32),\n",
       " array([[0.14382146, 0.15312645, 0.18722607, 0.71085966, 0.19655988,\n",
       "         0.88325596, 0.01372331, 0.8824051 , 0.8744329 , 0.8851545 ,\n",
       "         0.17338188, 0.8688082 ]], dtype=float32),\n",
       " array([[0.08543256, 0.14157842, 0.15813962, 0.6268162 , 0.20226038,\n",
       "         0.9195516 , 0.00201006, 0.9265565 , 0.89597464, 0.9353369 ,\n",
       "         0.134735  , 0.9109692 ]], dtype=float32),\n",
       " array([[0.09478454, 0.14732738, 0.17237695, 0.64365333, 0.19962832,\n",
       "         0.900718  , 0.00291736, 0.929428  , 0.8800108 , 0.9229993 ,\n",
       "         0.14221601, 0.91331464]], dtype=float32),\n",
       " array([[0.12568706, 0.15545556, 0.17353155, 0.6112238 , 0.20257801,\n",
       "         0.89266044, 0.0049567 , 0.9299554 , 0.866445  , 0.9111026 ,\n",
       "         0.1686014 , 0.91202617]], dtype=float32),\n",
       " array([[0.25369287, 0.17414099, 0.23000194, 0.6438255 , 0.22240001,\n",
       "         0.83505297, 0.07234143, 0.86886793, 0.8136627 , 0.8049506 ,\n",
       "         0.23231705, 0.85539174]], dtype=float32),\n",
       " array([[0.3798962 , 0.18069148, 0.25224498, 0.63104606, 0.24197072,\n",
       "         0.8041168 , 0.3299517 , 0.79038244, 0.76543576, 0.69417816,\n",
       "         0.28015128, 0.7891342 ]], dtype=float32),\n",
       " array([[0.6864165 , 0.22837372, 0.2988677 , 0.61180335, 0.29266414,\n",
       "         0.7239533 , 0.9707927 , 0.5570561 , 0.68357927, 0.36460257,\n",
       "         0.40751436, 0.6265226 ]], dtype=float32),\n",
       " array([[0.7194613 , 0.23626423, 0.30968794, 0.6630362 , 0.2796689 ,\n",
       "         0.68177104, 0.9824654 , 0.5199822 , 0.66540426, 0.3290638 ,\n",
       "         0.42749345, 0.59336007]], dtype=float32),\n",
       " array([[0.70453066, 0.23441161, 0.36224723, 0.70326793, 0.28338236,\n",
       "         0.6234519 , 0.98189056, 0.48847508, 0.63176614, 0.36285236,\n",
       "         0.42577797, 0.5595265 ]], dtype=float32),\n",
       " array([[0.66110265, 0.228244  , 0.36313254, 0.71250826, 0.27782458,\n",
       "         0.63503236, 0.96572745, 0.5164942 , 0.65261066, 0.436554  ,\n",
       "         0.41256934, 0.5756945 ]], dtype=float32),\n",
       " array([[0.65681374, 0.23162547, 0.37497103, 0.70229584, 0.2881927 ,\n",
       "         0.61636657, 0.9634665 , 0.47930938, 0.6269599 , 0.48143268,\n",
       "         0.4040761 , 0.5380186 ]], dtype=float32),\n",
       " array([[0.6358609 , 0.22759779, 0.37902293, 0.720977  , 0.27468023,\n",
       "         0.59997964, 0.94431   , 0.51730424, 0.6224138 , 0.519692  ,\n",
       "         0.40383387, 0.562306  ]], dtype=float32),\n",
       " array([[0.62929356, 0.23284298, 0.37392744, 0.7245259 , 0.26671538,\n",
       "         0.60844505, 0.91549987, 0.540005  , 0.648527  , 0.5931263 ,\n",
       "         0.41366482, 0.56794983]], dtype=float32),\n",
       " array([[0.46220925, 0.20586628, 0.24563792, 0.66401756, 0.24533367,\n",
       "         0.78815943, 0.58808863, 0.6812469 , 0.76079106, 0.6592733 ,\n",
       "         0.29255098, 0.70287853]], dtype=float32),\n",
       " array([[0.4424628 , 0.20806025, 0.27232185, 0.71067613, 0.2353219 ,\n",
       "         0.73684704, 0.5616093 , 0.6909133 , 0.73422533, 0.67784107,\n",
       "         0.2918637 , 0.70266813]], dtype=float32),\n",
       " array([[0.49697188, 0.22072299, 0.2855078 , 0.66638017, 0.2611544 ,\n",
       "         0.73660105, 0.7386514 , 0.6521602 , 0.72407436, 0.6221747 ,\n",
       "         0.31557095, 0.6842708 ]], dtype=float32),\n",
       " array([[0.33521253, 0.19763684, 0.2311024 , 0.6754091 , 0.22852889,\n",
       "         0.8090616 , 0.26574314, 0.7561259 , 0.7855216 , 0.7424542 ,\n",
       "         0.23712787, 0.766755  ]], dtype=float32),\n",
       " array([[0.5037236 , 0.21938637, 0.30584013, 0.67035246, 0.26248035,\n",
       "         0.7152784 , 0.75442374, 0.6457166 , 0.704505  , 0.6227547 ,\n",
       "         0.32505053, 0.67774844]], dtype=float32),\n",
       " array([[0.50496227, 0.21103136, 0.32167333, 0.69310915, 0.25020579,\n",
       "         0.69030386, 0.7166902 , 0.6733689 , 0.68579566, 0.62506986,\n",
       "         0.3376323 , 0.6950925 ]], dtype=float32),\n",
       " array([[0.5632873 , 0.21638894, 0.34948763, 0.6972117 , 0.26519305,\n",
       "         0.6647278 , 0.85579276, 0.6330446 , 0.6720577 , 0.55688727,\n",
       "         0.3698567 , 0.6664188 ]], dtype=float32),\n",
       " array([[0.5058798 , 0.20420898, 0.32101014, 0.6891187 , 0.25669086,\n",
       "         0.7005942 , 0.73526794, 0.6783898 , 0.69364   , 0.60421807,\n",
       "         0.34584707, 0.7031782 ]], dtype=float32),\n",
       " array([[0.4243054 , 0.19388805, 0.29403868, 0.68456846, 0.24556257,\n",
       "         0.7440571 , 0.48049816, 0.75069094, 0.7329338 , 0.6684057 ,\n",
       "         0.30713746, 0.76033884]], dtype=float32),\n",
       " array([[0.4304    , 0.18256897, 0.25974202, 0.65124696, 0.25257933,\n",
       "         0.79792273, 0.48815852, 0.7536364 , 0.7668784 , 0.64444196,\n",
       "         0.3023238 , 0.76354814]], dtype=float32),\n",
       " array([[0.31361374, 0.17018634, 0.2282008 , 0.6764404 , 0.2285669 ,\n",
       "         0.8313948 , 0.1805349 , 0.8093892 , 0.8059589 , 0.742621  ,\n",
       "         0.2455006 , 0.8044264 ]], dtype=float32),\n",
       " array([[0.47221932, 0.19661483, 0.31064355, 0.6820948 , 0.25933084,\n",
       "         0.7359609 , 0.6643413 , 0.6744402 , 0.7208086 , 0.64062285,\n",
       "         0.32311627, 0.6961175 ]], dtype=float32),\n",
       " array([[0.41316843, 0.19588181, 0.30793348, 0.7235754 , 0.24113417,\n",
       "         0.70780647, 0.52586865, 0.6936453 , 0.7124185 , 0.7006541 ,\n",
       "         0.30203733, 0.7031067 ]], dtype=float32),\n",
       " array([[0.41823953, 0.19613704, 0.32231048, 0.7161151 , 0.25054583,\n",
       "         0.70196193, 0.5736308 , 0.69029355, 0.70653105, 0.68335783,\n",
       "         0.31015605, 0.70669985]], dtype=float32),\n",
       " array([[0.39635217, 0.19133985, 0.29710543, 0.6965724 , 0.24834058,\n",
       "         0.742113  , 0.48226005, 0.73529416, 0.7356072 , 0.6775688 ,\n",
       "         0.29547763, 0.7480251 ]], dtype=float32),\n",
       " array([[0.37933862, 0.19226398, 0.27423826, 0.6654307 , 0.25700277,\n",
       "         0.78092855, 0.45865273, 0.73458225, 0.7621529 , 0.6787581 ,\n",
       "         0.27804053, 0.75402653]], dtype=float32),\n",
       " array([[0.40587476, 0.19293271, 0.2789245 , 0.6756973 , 0.2474336 ,\n",
       "         0.7651767 , 0.49721196, 0.7446114 , 0.7490425 , 0.65572107,\n",
       "         0.29129982, 0.7584658 ]], dtype=float32),\n",
       " array([[0.25220224, 0.16600464, 0.20087355, 0.66431063, 0.21923004,\n",
       "         0.8610239 , 0.0901892 , 0.8302697 , 0.8313064 , 0.78834134,\n",
       "         0.21215382, 0.82471716]], dtype=float32),\n",
       " array([[0.10479564, 0.14013256, 0.13595735, 0.61864203, 0.19849229,\n",
       "         0.93068546, 0.00334411, 0.9273153 , 0.90380555, 0.91081756,\n",
       "         0.13360289, 0.9095595 ]], dtype=float32),\n",
       " array([[0.08673634, 0.14263868, 0.14092216, 0.62787104, 0.19275413,\n",
       "         0.91838956, 0.00186291, 0.9441583 , 0.8943979 , 0.9243099 ,\n",
       "         0.12919563, 0.92676264]], dtype=float32),\n",
       " array([[0.11617468, 0.1569896 , 0.16244835, 0.6459526 , 0.19647385,\n",
       "         0.89737093, 0.00615703, 0.92162496, 0.8742672 , 0.8946249 ,\n",
       "         0.14415321, 0.9069344 ]], dtype=float32),\n",
       " array([[0.16650763, 0.16846618, 0.15696087, 0.6339602 , 0.20409633,\n",
       "         0.8992216 , 0.02351114, 0.88850504, 0.87155753, 0.84196055,\n",
       "         0.16069247, 0.8788245 ]], dtype=float32),\n",
       " array([[0.34344473, 0.19312784, 0.2016042 , 0.62454313, 0.23436187,\n",
       "         0.84806794, 0.3409209 , 0.7621773 , 0.80836904, 0.6826565 ,\n",
       "         0.23673949, 0.78130925]], dtype=float32),\n",
       " array([[0.4043646 , 0.19688788, 0.23069698, 0.62925434, 0.23852238,\n",
       "         0.8114562 , 0.46304116, 0.7630085 , 0.7747024 , 0.64490956,\n",
       "         0.27433932, 0.7765554 ]], dtype=float32),\n",
       " array([[0.42993233, 0.1984849 , 0.24785128, 0.60536265, 0.25862363,\n",
       "         0.80071515, 0.55658674, 0.74636704, 0.7611784 , 0.6259968 ,\n",
       "         0.29593742, 0.7653812 ]], dtype=float32),\n",
       " array([[0.39851558, 0.19920895, 0.24267335, 0.6132035 , 0.24800311,\n",
       "         0.7980822 , 0.43559742, 0.7900646 , 0.7658496 , 0.6523897 ,\n",
       "         0.28636906, 0.7984392 ]], dtype=float32),\n",
       " array([[0.4608714 , 0.21089639, 0.25114545, 0.61839926, 0.25090235,\n",
       "         0.7840442 , 0.62022674, 0.74993515, 0.7522621 , 0.6005048 ,\n",
       "         0.30130392, 0.7668031 ]], dtype=float32),\n",
       " array([[0.3578172 , 0.18771768, 0.19831467, 0.6216995 , 0.23371023,\n",
       "         0.846499  , 0.315866  , 0.78568864, 0.8081455 , 0.6914865 ,\n",
       "         0.25176042, 0.7894238 ]], dtype=float32),\n",
       " array([[0.35748306, 0.18807127, 0.18591748, 0.63093853, 0.22487299,\n",
       "         0.85534745, 0.31235915, 0.7822414 , 0.81695324, 0.6888398 ,\n",
       "         0.2430805 , 0.7854568 ]], dtype=float32),\n",
       " array([[0.35445508, 0.19559377, 0.18900411, 0.6435909 , 0.21811774,\n",
       "         0.8485578 , 0.2967884 , 0.78906614, 0.81490415, 0.69420356,\n",
       "         0.234732  , 0.79085875]], dtype=float32),\n",
       " array([[0.6460769 , 0.24998343, 0.2544628 , 0.60963607, 0.2770154 ,\n",
       "         0.7494416 , 0.9618695 , 0.5581982 , 0.7095078 , 0.38916382,\n",
       "         0.35361695, 0.6334242 ]], dtype=float32),\n",
       " array([[0.5489093 , 0.23703934, 0.26500517, 0.64011294, 0.25773853,\n",
       "         0.7471535 , 0.86943084, 0.6474491 , 0.72226226, 0.49929142,\n",
       "         0.31837648, 0.6956596 ]], dtype=float32),\n",
       " array([[0.53270346, 0.22699194, 0.26219705, 0.6402975 , 0.26150373,\n",
       "         0.75010884, 0.8604523 , 0.6356712 , 0.72137636, 0.5125165 ,\n",
       "         0.32413772, 0.688261  ]], dtype=float32),\n",
       " array([[0.6706041 , 0.23648268, 0.3038748 , 0.64953065, 0.28994763,\n",
       "         0.7063378 , 0.97556245, 0.4719172 , 0.67940986, 0.39352047,\n",
       "         0.38796023, 0.55716395]], dtype=float32),\n",
       " array([[0.68627137, 0.23780596, 0.35783672, 0.70952135, 0.27206936,\n",
       "         0.6170192 , 0.9766741 , 0.4641961 , 0.6249004 , 0.4140594 ,\n",
       "         0.41353577, 0.535269  ]], dtype=float32),\n",
       " array([[0.66035455, 0.23669769, 0.36083362, 0.70820194, 0.27369097,\n",
       "         0.62890434, 0.96301466, 0.4904476 , 0.64332175, 0.4686322 ,\n",
       "         0.4003595 , 0.5506321 ]], dtype=float32),\n",
       " array([[0.65450156, 0.23760977, 0.3611879 , 0.71388376, 0.26997042,\n",
       "         0.62504166, 0.9555548 , 0.51190567, 0.6472193 , 0.48609284,\n",
       "         0.40157792, 0.5647557 ]], dtype=float32),\n",
       " array([[0.616807  , 0.23306811, 0.3467945 , 0.70886266, 0.26657766,\n",
       "         0.64372265, 0.9276275 , 0.5522266 , 0.6622911 , 0.5236202 ,\n",
       "         0.38300547, 0.59734046]], dtype=float32),\n",
       " array([[0.58747464, 0.22947833, 0.3612963 , 0.7235323 , 0.26003304,\n",
       "         0.6242358 , 0.88895565, 0.56526434, 0.654931  , 0.5929219 ,\n",
       "         0.3801916 , 0.5965307 ]], dtype=float32),\n",
       " array([[0.56705695, 0.22783911, 0.37876952, 0.732051  , 0.26248348,\n",
       "         0.5969904 , 0.87647855, 0.5718377 , 0.6319364 , 0.6033235 ,\n",
       "         0.37041762, 0.602704  ]], dtype=float32),\n",
       " array([[0.55811626, 0.22244994, 0.36102724, 0.71906877, 0.26594293,\n",
       "         0.6259632 , 0.8514107 , 0.56618774, 0.65075254, 0.63796324,\n",
       "         0.37344974, 0.59418577]], dtype=float32),\n",
       " array([[0.5124836 , 0.21203057, 0.3361784 , 0.7075016 , 0.2618177 ,\n",
       "         0.65994745, 0.76659817, 0.6164692 , 0.66198105, 0.6402287 ,\n",
       "         0.3400977 , 0.64221466]], dtype=float32),\n",
       " array([[0.5140951 , 0.21049136, 0.34821317, 0.71789384, 0.26461345,\n",
       "         0.675887  , 0.7793707 , 0.6339913 , 0.70019   , 0.6344115 ,\n",
       "         0.36133087, 0.65999526]], dtype=float32),\n",
       " array([[0.47247258, 0.20847735, 0.33763766, 0.71536124, 0.25834787,\n",
       "         0.677718  , 0.69211954, 0.6639527 , 0.69390917, 0.6560385 ,\n",
       "         0.3342687 , 0.6863942 ]], dtype=float32),\n",
       " array([[0.41631776, 0.19561845, 0.30147794, 0.68291557, 0.25616217,\n",
       "         0.7307059 , 0.5348417 , 0.70634747, 0.7110067 , 0.66807926,\n",
       "         0.29483053, 0.72875243]], dtype=float32),\n",
       " array([[0.4767171 , 0.19744693, 0.314999  , 0.6873054 , 0.26213714,\n",
       "         0.734415  , 0.66759986, 0.67462456, 0.7242747 , 0.6394795 ,\n",
       "         0.32578367, 0.69715846]], dtype=float32),\n",
       " array([[0.40303254, 0.18851884, 0.27560902, 0.67922646, 0.2427736 ,\n",
       "         0.7669916 , 0.412532  , 0.742399  , 0.744212  , 0.6931827 ,\n",
       "         0.28975907, 0.7523804 ]], dtype=float32),\n",
       " array([[0.3513736 , 0.18260276, 0.240946  , 0.6671045 , 0.2328933 ,\n",
       "         0.8126312 , 0.25340933, 0.79232585, 0.7889052 , 0.72359955,\n",
       "         0.26568785, 0.7947236 ]], dtype=float32),\n",
       " array([[0.26477057, 0.16963024, 0.2193081 , 0.6655318 , 0.22636214,\n",
       "         0.8432543 , 0.10393748, 0.8294218 , 0.8152439 , 0.77973926,\n",
       "         0.2224353 , 0.8262917 ]], dtype=float32),\n",
       " array([[0.44307566, 0.19494922, 0.28297   , 0.6603332 , 0.26037744,\n",
       "         0.7713945 , 0.5976675 , 0.69991666, 0.74801123, 0.64398676,\n",
       "         0.30742523, 0.724991  ]], dtype=float32),\n",
       " array([[0.39555663, 0.19108364, 0.27561748, 0.6824109 , 0.24106492,\n",
       "         0.7657728 , 0.42556512, 0.75541466, 0.75133497, 0.6801681 ,\n",
       "         0.29025006, 0.76546067]], dtype=float32),\n",
       " array([[0.39703748, 0.18864204, 0.2638593 , 0.66996527, 0.25000417,\n",
       "         0.7926734 , 0.4617344 , 0.73526675, 0.7755799 , 0.678355  ,\n",
       "         0.2932144 , 0.7515518 ]], dtype=float32),\n",
       " array([[0.36033565, 0.18535493, 0.24072734, 0.6699214 , 0.23460378,\n",
       "         0.8074174 , 0.3197948 , 0.78148   , 0.7882956 , 0.7011606 ,\n",
       "         0.27415746, 0.78775376]], dtype=float32),\n",
       " array([[0.3566219 , 0.18262109, 0.24036759, 0.6487352 , 0.24400452,\n",
       "         0.82027245, 0.32606685, 0.76792485, 0.7902579 , 0.7008403 ,\n",
       "         0.26383966, 0.7782528 ]], dtype=float32),\n",
       " array([[0.35069457, 0.18862632, 0.24029538, 0.65558136, 0.2384058 ,\n",
       "         0.80771506, 0.30460298, 0.7865844 , 0.78537416, 0.7059641 ,\n",
       "         0.26872283, 0.79503685]], dtype=float32),\n",
       " array([[0.2882174 , 0.17790562, 0.21807139, 0.6554379 , 0.23180707,\n",
       "         0.8433691 , 0.16177958, 0.8170365 , 0.82005435, 0.7520715 ,\n",
       "         0.23366512, 0.8171844 ]], dtype=float32),\n",
       " array([[0.51297206, 0.20682058, 0.28595594, 0.65837526, 0.26306552,\n",
       "         0.75857365, 0.7911039 , 0.63962835, 0.7353542 , 0.57874095,\n",
       "         0.33049345, 0.6779695 ]], dtype=float32),\n",
       " array([[0.49255547, 0.20767231, 0.2745724 , 0.6808751 , 0.24033318,\n",
       "         0.7467215 , 0.6936655 , 0.69444543, 0.7348715 , 0.6090803 ,\n",
       "         0.3272552 , 0.7147422 ]], dtype=float32),\n",
       " array([[0.4478103 , 0.20846681, 0.25508764, 0.6521791 , 0.24393408,\n",
       "         0.778528  , 0.58267796, 0.7323066 , 0.75698555, 0.62948704,\n",
       "         0.2969756 , 0.7513167 ]], dtype=float32),\n",
       " array([[0.43646076, 0.20782591, 0.25284123, 0.6610509 , 0.24015301,\n",
       "         0.7757603 , 0.5474163 , 0.72957605, 0.75324005, 0.64520437,\n",
       "         0.28545383, 0.74595034]], dtype=float32),\n",
       " array([[0.4217579 , 0.20460503, 0.27241573, 0.6755004 , 0.242795  ,\n",
       "         0.7551624 , 0.53559756, 0.7359918 , 0.737156  , 0.6423122 ,\n",
       "         0.27789524, 0.74999905]], dtype=float32),\n",
       " array([[0.40909043, 0.19721206, 0.23486744, 0.64519066, 0.24420245,\n",
       "         0.80801123, 0.4749156 , 0.74674475, 0.77909935, 0.6566634 ,\n",
       "         0.27757615, 0.7615769 ]], dtype=float32),\n",
       " array([[0.45041412, 0.20217371, 0.2522588 , 0.6521092 , 0.24871342,\n",
       "         0.77629954, 0.6184753 , 0.6979645 , 0.7429531 , 0.62744486,\n",
       "         0.29468197, 0.7229116 ]], dtype=float32),\n",
       " array([[0.38952136, 0.1975871 , 0.22318709, 0.6418533 , 0.23954456,\n",
       "         0.8114443 , 0.40993804, 0.7644378 , 0.78035414, 0.67048126,\n",
       "         0.268215  , 0.7765327 ]], dtype=float32),\n",
       " array([[0.41797376, 0.2040121 , 0.21249413, 0.6263858 , 0.24295545,\n",
       "         0.81706774, 0.49879217, 0.7510331 , 0.78064907, 0.6386678 ,\n",
       "         0.2731692 , 0.76834536]], dtype=float32),\n",
       " array([[0.37468198, 0.19756272, 0.24573012, 0.6615446 , 0.23882063,\n",
       "         0.78752667, 0.39296955, 0.7527732 , 0.7577603 , 0.6849142 ,\n",
       "         0.25531211, 0.7648033 ]], dtype=float32),\n",
       " array([[0.217806  , 0.17284434, 0.16812015, 0.62909544, 0.21810435,\n",
       "         0.88727045, 0.05719058, 0.84788406, 0.852822  , 0.8114664 ,\n",
       "         0.18229733, 0.8425538 ]], dtype=float32),\n",
       " array([[0.34515667, 0.19205077, 0.2242109 , 0.6530046 , 0.23644961,\n",
       "         0.8165795 , 0.31815156, 0.76493627, 0.78346217, 0.70307475,\n",
       "         0.24069606, 0.7752047 ]], dtype=float32),\n",
       " array([[0.33499125, 0.18665841, 0.22831143, 0.66325945, 0.23002487,\n",
       "         0.8224668 , 0.26305512, 0.77875936, 0.79605126, 0.7263147 ,\n",
       "         0.24541768, 0.7828156 ]], dtype=float32),\n",
       " array([[0.38266498, 0.19840737, 0.25084144, 0.6852787 , 0.22972818,\n",
       "         0.7831614 , 0.39694813, 0.768873  , 0.7712237 , 0.6807222 ,\n",
       "         0.267245  , 0.7739745 ]], dtype=float32),\n",
       " array([[0.43051583, 0.20338142, 0.2665808 , 0.6682966 , 0.2434142 ,\n",
       "         0.76926273, 0.5637542 , 0.7165241 , 0.7495062 , 0.6496252 ,\n",
       "         0.2906405 , 0.7352965 ]], dtype=float32),\n",
       " array([[0.32618815, 0.18415244, 0.23939447, 0.67161864, 0.23230135,\n",
       "         0.8064339 , 0.25806332, 0.7814229 , 0.7813141 , 0.7264239 ,\n",
       "         0.24553868, 0.7848065 ]], dtype=float32),\n",
       " array([[0.3694987 , 0.18916462, 0.24323136, 0.6489962 , 0.24776633,\n",
       "         0.8049684 , 0.39359942, 0.76391757, 0.77710503, 0.678569  ,\n",
       "         0.26618913, 0.77421814]], dtype=float32),\n",
       " array([[0.36566016, 0.19252561, 0.24011028, 0.6550491 , 0.23794824,\n",
       "         0.8030817 , 0.3532077 , 0.76995564, 0.7755685 , 0.69445616,\n",
       "         0.25963202, 0.77705085]], dtype=float32),\n",
       " array([[0.32677063, 0.18507588, 0.24424674, 0.67438734, 0.23054546,\n",
       "         0.80199426, 0.2453978 , 0.79708815, 0.7827708 , 0.7276053 ,\n",
       "         0.2504566 , 0.79637134]], dtype=float32),\n",
       " array([[0.42806482, 0.19746149, 0.2532746 , 0.656002  , 0.24601954,\n",
       "         0.79063356, 0.5540365 , 0.7151856 , 0.7619236 , 0.6472857 ,\n",
       "         0.28544167, 0.73305845]], dtype=float32),\n",
       " array([[0.4925438 , 0.20696773, 0.3008959 , 0.67690885, 0.25269115,\n",
       "         0.72678554, 0.7428209 , 0.6608693 , 0.7091885 , 0.60128677,\n",
       "         0.32303014, 0.6897611 ]], dtype=float32),\n",
       " array([[0.4737775 , 0.20107855, 0.28614634, 0.6649737 , 0.25581762,\n",
       "         0.7480066 , 0.6997155 , 0.67265725, 0.7237285 , 0.6140433 ,\n",
       "         0.31771067, 0.70060503]], dtype=float32),\n",
       " array([[0.568555  , 0.21754725, 0.32921946, 0.6780947 , 0.27481917,\n",
       "         0.6885055 , 0.9021826 , 0.5391781 , 0.67344826, 0.55418444,\n",
       "         0.3601748 , 0.5938536 ]], dtype=float32),\n",
       " array([[0.5343103 , 0.20928206, 0.3270011 , 0.6970757 , 0.26460126,\n",
       "         0.68015414, 0.85537064, 0.59427357, 0.6734295 , 0.5677087 ,\n",
       "         0.35384378, 0.6369492 ]], dtype=float32),\n",
       " array([[0.5085096 , 0.21087402, 0.3043118 , 0.686252  , 0.2610156 ,\n",
       "         0.71869254, 0.78653795, 0.66261524, 0.71433264, 0.57406855,\n",
       "         0.33058748, 0.6921043 ]], dtype=float32),\n",
       " array([[0.42072186, 0.19627143, 0.25032127, 0.6509827 , 0.25471672,\n",
       "         0.7953902 , 0.54033554, 0.72808367, 0.76990914, 0.6432022 ,\n",
       "         0.28614977, 0.74667096]], dtype=float32),\n",
       " array([[0.38105717, 0.18963121, 0.24159957, 0.66666913, 0.24684443,\n",
       "         0.8048663 , 0.43129924, 0.7471739 , 0.7834084 , 0.6731218 ,\n",
       "         0.26998267, 0.7594403 ]], dtype=float32),\n",
       " array([[0.32903317, 0.18390155, 0.22320668, 0.6726888 , 0.23425935,\n",
       "         0.8289756 , 0.26501098, 0.7833001 , 0.8090791 , 0.71888137,\n",
       "         0.24316096, 0.78602   ]], dtype=float32),\n",
       " array([[0.17302103, 0.15795599, 0.16418959, 0.6829119 , 0.20209435,\n",
       "         0.8967916 , 0.02663565, 0.85996133, 0.8750822 , 0.85418254,\n",
       "         0.16625032, 0.8463777 ]], dtype=float32),\n",
       " array([[0.15572937, 0.15942405, 0.16353878, 0.6930832 , 0.19383602,\n",
       "         0.8939528 , 0.01834323, 0.8788456 , 0.87629956, 0.8659788 ,\n",
       "         0.15883805, 0.86361396]], dtype=float32),\n",
       " array([[0.12289172, 0.15925895, 0.15056524, 0.6386154 , 0.20169927,\n",
       "         0.9094118 , 0.00772177, 0.9042533 , 0.88549894, 0.89861846,\n",
       "         0.1439127 , 0.88883257]], dtype=float32),\n",
       " array([[0.15169354, 0.16867039, 0.18255864, 0.65744287, 0.208425  ,\n",
       "         0.87445736, 0.01782431, 0.89330447, 0.8555516 , 0.86836785,\n",
       "         0.1661607 , 0.88040674]], dtype=float32),\n",
       " array([[0.32062787, 0.18896766, 0.22105499, 0.63728654, 0.24093437,\n",
       "         0.8325243 , 0.2764272 , 0.77479386, 0.80183727, 0.7212335 ,\n",
       "         0.2416802 , 0.7860525 ]], dtype=float32),\n",
       " array([[0.39801767, 0.20095672, 0.25035253, 0.65740526, 0.24269031,\n",
       "         0.7875113 , 0.4778556 , 0.75391346, 0.76747894, 0.65809745,\n",
       "         0.27807814, 0.7672221 ]], dtype=float32),\n",
       " array([[0.45486107, 0.19896606, 0.27221206, 0.6453982 , 0.25541404,\n",
       "         0.7700631 , 0.60789686, 0.7390047 , 0.7483509 , 0.62058246,\n",
       "         0.31337738, 0.75115275]], dtype=float32),\n",
       " array([[0.32051474, 0.18521893, 0.22681202, 0.6336618 , 0.23638485,\n",
       "         0.82915646, 0.19274032, 0.821298  , 0.8038858 , 0.75003487,\n",
       "         0.25291428, 0.81500065]], dtype=float32),\n",
       " array([[0.6115211 , 0.22568372, 0.30790257, 0.63008654, 0.27916563,\n",
       "         0.71407443, 0.9194195 , 0.63914955, 0.6935288 , 0.46092013,\n",
       "         0.38161638, 0.6823563 ]], dtype=float32),\n",
       " array([[0.47838467, 0.20785345, 0.27337855, 0.67584354, 0.24421075,\n",
       "         0.7600586 , 0.6797287 , 0.7158363 , 0.7474409 , 0.5946976 ,\n",
       "         0.30596277, 0.7312942 ]], dtype=float32),\n",
       " array([[0.43542612, 0.19976501, 0.23741223, 0.65491587, 0.24281077,\n",
       "         0.799835  , 0.5713808 , 0.72402793, 0.7743514 , 0.63420767,\n",
       "         0.29080442, 0.7410228 ]], dtype=float32),\n",
       " array([[0.41243744, 0.19610517, 0.22028579, 0.6617116 , 0.23505586,\n",
       "         0.81453085, 0.5063292 , 0.7315443 , 0.788776  , 0.65210176,\n",
       "         0.27898508, 0.74622077]], dtype=float32),\n",
       " array([[0.6560414 , 0.2335115 , 0.31566605, 0.651914  , 0.282308  ,\n",
       "         0.691594  , 0.9646081 , 0.5022917 , 0.6649722 , 0.4303456 ,\n",
       "         0.3892181 , 0.57681924]], dtype=float32),\n",
       " array([[0.65612215, 0.23618183, 0.37194   , 0.70559627, 0.27082366,\n",
       "         0.6100801 , 0.9636686 , 0.46660325, 0.6199315 , 0.4928522 ,\n",
       "         0.41251418, 0.53150135]], dtype=float32),\n",
       " array([[0.66425794, 0.24308157, 0.42281067, 0.7294733 , 0.27515396,\n",
       "         0.5344856 , 0.9687964 , 0.46089154, 0.56926453, 0.49363098,\n",
       "         0.41671368, 0.5191951 ]], dtype=float32),\n",
       " array([[0.6216186 , 0.23170196, 0.37589037, 0.71010715, 0.27151656,\n",
       "         0.5979202 , 0.94259286, 0.5356218 , 0.6083632 , 0.49202222,\n",
       "         0.38344815, 0.58949393]], dtype=float32),\n",
       " array([[0.5769782 , 0.21822661, 0.28168285, 0.65375364, 0.26558876,\n",
       "         0.7168009 , 0.88483196, 0.59219027, 0.68337804, 0.5222281 ,\n",
       "         0.3589008 , 0.64455426]], dtype=float32),\n",
       " array([[0.5713439 , 0.22231573, 0.30236238, 0.6709912 , 0.26732326,\n",
       "         0.7082721 , 0.8764674 , 0.62797844, 0.6986507 , 0.51869303,\n",
       "         0.35678005, 0.6709907 ]], dtype=float32),\n",
       " array([[0.5220254 , 0.22036579, 0.28664085, 0.68381363, 0.25151014,\n",
       "         0.7244216 , 0.77280235, 0.6643715 , 0.7210963 , 0.59045637,\n",
       "         0.33265084, 0.691911  ]], dtype=float32),\n",
       " array([[0.50541216, 0.21916081, 0.2982688 , 0.68594927, 0.25382835,\n",
       "         0.703369  , 0.7470087 , 0.6589992 , 0.6928476 , 0.6052152 ,\n",
       "         0.3148263 , 0.6853024 ]], dtype=float32),\n",
       " array([[0.47785148, 0.21137857, 0.27969152, 0.690895  , 0.24249174,\n",
       "         0.7356572 , 0.63546723, 0.7002275 , 0.72896093, 0.63904256,\n",
       "         0.3103392 , 0.7150693 ]], dtype=float32),\n",
       " array([[0.4595906 , 0.21035324, 0.28961137, 0.6863762 , 0.25037387,\n",
       "         0.7366608 , 0.62351656, 0.6997958 , 0.7327939 , 0.64845765,\n",
       "         0.30941564, 0.71933377]], dtype=float32),\n",
       " array([[0.39533907, 0.20519444, 0.25547177, 0.6664987 , 0.24280824,\n",
       "         0.7832673 , 0.42535248, 0.75103503, 0.7690393 , 0.69039786,\n",
       "         0.27683836, 0.76483196]], dtype=float32),\n",
       " array([[0.4225944 , 0.20709331, 0.26589832, 0.66885895, 0.25036302,\n",
       "         0.76790136, 0.54292625, 0.71591634, 0.7539533 , 0.6656307 ,\n",
       "         0.29070204, 0.73741513]], dtype=float32),\n",
       " array([[0.39110538, 0.19258553, 0.26472104, 0.67878896, 0.24036327,\n",
       "         0.7766132 , 0.41557965, 0.74736416, 0.76048505, 0.69329906,\n",
       "         0.2849407 , 0.7576692 ]], dtype=float32),\n",
       " array([[0.39364833, 0.18969943, 0.27674016, 0.68847704, 0.23844072,\n",
       "         0.77411574, 0.39976954, 0.75197977, 0.7630575 , 0.7008512 ,\n",
       "         0.28763276, 0.75694567]], dtype=float32),\n",
       " array([[0.4486663 , 0.19368313, 0.31791517, 0.6989676 , 0.25047633,\n",
       "         0.7288444 , 0.5991274 , 0.69757915, 0.7246628 , 0.660237  ,\n",
       "         0.3200298 , 0.7124745 ]], dtype=float32),\n",
       " array([[0.47364932, 0.2030204 , 0.3493823 , 0.7203802 , 0.25058442,\n",
       "         0.6902568 , 0.67580307, 0.68627393, 0.70712787, 0.6428582 ,\n",
       "         0.32768437, 0.69848853]], dtype=float32),\n",
       " array([[0.44225562, 0.19960374, 0.30256268, 0.6870088 , 0.2504924 ,\n",
       "         0.7385693 , 0.5811949 , 0.71954215, 0.7332123 , 0.6506249 ,\n",
       "         0.30991656, 0.73421836]], dtype=float32),\n",
       " array([[0.40103632, 0.19371167, 0.28263202, 0.6831673 , 0.24426661,\n",
       "         0.76693195, 0.44187337, 0.74899006, 0.7562679 , 0.68387055,\n",
       "         0.2855879 , 0.756113  ]], dtype=float32),\n",
       " array([[0.3803133 , 0.19016783, 0.26677147, 0.67780817, 0.23968983,\n",
       "         0.7776601 , 0.3787472 , 0.7614446 , 0.76026946, 0.6962708 ,\n",
       "         0.27585685, 0.7671492 ]], dtype=float32),\n",
       " array([[0.36404356, 0.18388116, 0.2627768 , 0.68936545, 0.2354008 ,\n",
       "         0.78742164, 0.3336037 , 0.7623416 , 0.77263373, 0.7145516 ,\n",
       "         0.2716725 , 0.76441723]], dtype=float32),\n",
       " array([[0.3267577 , 0.18365799, 0.23746094, 0.6773792 , 0.23010734,\n",
       "         0.81466925, 0.23047191, 0.7905721 , 0.7962717 , 0.7397332 ,\n",
       "         0.24867101, 0.7896732 ]], dtype=float32),\n",
       " array([[0.3373985 , 0.18565989, 0.24055503, 0.6732153 , 0.2355263 ,\n",
       "         0.8106725 , 0.27746686, 0.77832735, 0.79120815, 0.7222335 ,\n",
       "         0.25042546, 0.7808249 ]], dtype=float32),\n",
       " array([[0.4745257 , 0.20114683, 0.27109608, 0.64020103, 0.2661839 ,\n",
       "         0.7695225 , 0.7161345 , 0.64940673, 0.733647  , 0.6167179 ,\n",
       "         0.31770012, 0.68857354]], dtype=float32),\n",
       " array([[0.43010667, 0.1956771 , 0.26088858, 0.6445804 , 0.2556813 ,\n",
       "         0.77581567, 0.5789783 , 0.6975416 , 0.7412182 , 0.6519481 ,\n",
       "         0.30219075, 0.724911  ]], dtype=float32),\n",
       " array([[0.47033912, 0.20426741, 0.26922008, 0.64656264, 0.2580274 ,\n",
       "         0.7624612 , 0.68755174, 0.6736484 , 0.7309921 , 0.61914057,\n",
       "         0.3154713 , 0.7068436 ]], dtype=float32),\n",
       " array([[0.4360201 , 0.20517729, 0.24548283, 0.64187104, 0.2463628 ,\n",
       "         0.7826748 , 0.5575752 , 0.72538036, 0.75152653, 0.6440701 ,\n",
       "         0.29309577, 0.74649996]], dtype=float32),\n",
       " array([[0.37756634, 0.19684862, 0.216845  , 0.6245713 , 0.24303918,\n",
       "         0.82573783, 0.3679744 , 0.77138174, 0.79168284, 0.6871317 ,\n",
       "         0.26333678, 0.782505  ]], dtype=float32),\n",
       " array([[0.35134274, 0.1924258 , 0.22141163, 0.64562345, 0.2368348 ,\n",
       "         0.82278174, 0.29330367, 0.7927794 , 0.79735124, 0.70666194,\n",
       "         0.25469738, 0.796414  ]], dtype=float32),\n",
       " array([[0.4194257 , 0.2003066 , 0.25323987, 0.65640366, 0.2460982 ,\n",
       "         0.782818  , 0.5226781 , 0.7365678 , 0.75955325, 0.65108216,\n",
       "         0.28756574, 0.75250506]], dtype=float32),\n",
       " array([[0.4757232 , 0.20652798, 0.27912173, 0.6660023 , 0.2532132 ,\n",
       "         0.75161004, 0.69473404, 0.6726796 , 0.72937316, 0.61783177,\n",
       "         0.31066322, 0.7001639 ]], dtype=float32),\n",
       " array([[0.42157826, 0.20174015, 0.2598833 , 0.67311966, 0.23961337,\n",
       "         0.7675575 , 0.5159686 , 0.72336584, 0.747141  , 0.6661963 ,\n",
       "         0.28634402, 0.7377315 ]], dtype=float32),\n",
       " array([[0.47367522, 0.21008755, 0.2759071 , 0.6587932 , 0.25512114,\n",
       "         0.75221467, 0.6867341 , 0.68135875, 0.7302654 , 0.61922145,\n",
       "         0.30986077, 0.70932263]], dtype=float32),\n",
       " array([[0.46025336, 0.20512667, 0.27367866, 0.6677078 , 0.25228307,\n",
       "         0.74996644, 0.65913224, 0.6886287 , 0.73025656, 0.62807333,\n",
       "         0.31214532, 0.71476823]], dtype=float32),\n",
       " array([[0.34048986, 0.19025382, 0.23204179, 0.6525939 , 0.24100514,\n",
       "         0.8185369 , 0.2886384 , 0.7737136 , 0.7936628 , 0.7230489 ,\n",
       "         0.25158855, 0.7810915 ]], dtype=float32),\n",
       " array([[0.23067455, 0.16727033, 0.19212309, 0.6685103 , 0.21935451,\n",
       "         0.8653586 , 0.07277256, 0.83654034, 0.84188485, 0.80853117,\n",
       "         0.20422518, 0.82800204]], dtype=float32),\n",
       " array([[0.3302958 , 0.18607171, 0.22735144, 0.6601623 , 0.23301978,\n",
       "         0.8178415 , 0.25070134, 0.78493375, 0.79100364, 0.73018503,\n",
       "         0.24584241, 0.787049  ]], dtype=float32),\n",
       " array([[0.36927193, 0.18952054, 0.24739406, 0.683056  , 0.23423675,\n",
       "         0.79818064, 0.36624345, 0.7560369 , 0.7818311 , 0.70182073,\n",
       "         0.26565835, 0.7611682 ]], dtype=float32),\n",
       " array([[0.36807922, 0.19028209, 0.24441841, 0.67236364, 0.2390141 ,\n",
       "         0.7988738 , 0.38204235, 0.74889886, 0.7777355 , 0.6978969 ,\n",
       "         0.2656074 , 0.75852793]], dtype=float32),\n",
       " array([[0.44795626, 0.20498484, 0.28504074, 0.6750031 , 0.24941579,\n",
       "         0.743384  , 0.6292688 , 0.6917133 , 0.7269113 , 0.6418938 ,\n",
       "         0.30427128, 0.71513575]], dtype=float32),\n",
       " array([[0.4943752 , 0.2133118 , 0.29247814, 0.6680503 , 0.25672585,\n",
       "         0.72944134, 0.74332523, 0.6783739 , 0.7146596 , 0.59177417,\n",
       "         0.32046846, 0.70650834]], dtype=float32),\n",
       " array([[0.28057095, 0.18169089, 0.20777668, 0.62406313, 0.24008086,\n",
       "         0.8515723 , 0.1467109 , 0.81356966, 0.8188814 , 0.76902765,\n",
       "         0.22327253, 0.81379193]], dtype=float32),\n",
       " array([[0.28536624, 0.18056883, 0.215812  , 0.6616108 , 0.23232685,\n",
       "         0.83865064, 0.16154681, 0.8203245 , 0.8201066 , 0.75566214,\n",
       "         0.23129801, 0.8168327 ]], dtype=float32),\n",
       " array([[0.5481545 , 0.2122834 , 0.31138635, 0.66566145, 0.26635426,\n",
       "         0.7162721 , 0.8527485 , 0.60268635, 0.69293106, 0.5586464 ,\n",
       "         0.34655815, 0.64591664]], dtype=float32),\n",
       " array([[0.5068819 , 0.20977628, 0.30499017, 0.692214  , 0.24689323,\n",
       "         0.7116676 , 0.7475073 , 0.675113  , 0.70647013, 0.59712595,\n",
       "         0.33430263, 0.6973918 ]], dtype=float32),\n",
       " array([[0.4925733 , 0.20562524, 0.28974906, 0.673104  , 0.25606963,\n",
       "         0.7440431 , 0.7338398 , 0.6751325 , 0.7296509 , 0.5980545 ,\n",
       "         0.32507545, 0.7012118 ]], dtype=float32),\n",
       " array([[0.49978814, 0.21078505, 0.30682114, 0.6833417 , 0.25839654,\n",
       "         0.71561253, 0.7695866 , 0.6606662 , 0.7063355 , 0.5864555 ,\n",
       "         0.3246959 , 0.6905607 ]], dtype=float32),\n",
       " array([[0.52681345, 0.2166803 , 0.31014058, 0.6798356 , 0.26147956,\n",
       "         0.7100887 , 0.81696206, 0.6388451 , 0.7009572 , 0.57059354,\n",
       "         0.3336212 , 0.6735332 ]], dtype=float32),\n",
       " array([[0.5094389 , 0.21248877, 0.31057423, 0.68629575, 0.26046264,\n",
       "         0.71025866, 0.78939867, 0.64960563, 0.70442855, 0.5842971 ,\n",
       "         0.33073038, 0.6812517 ]], dtype=float32),\n",
       " array([[0.47290787, 0.2087824 , 0.28541318, 0.67402804, 0.2542052 ,\n",
       "         0.7439316 , 0.6788694 , 0.69748646, 0.73338974, 0.6155158 ,\n",
       "         0.31337944, 0.7198066 ]], dtype=float32),\n",
       " array([[0.44285673, 0.19868517, 0.2661212 , 0.6768521 , 0.24931748,\n",
       "         0.7690342 , 0.60267466, 0.7050291 , 0.7522488 , 0.63812274,\n",
       "         0.2989025 , 0.7232669 ]], dtype=float32),\n",
       " array([[0.46868083, 0.20181918, 0.28137055, 0.68157697, 0.25574267,\n",
       "         0.758613  , 0.6905041 , 0.6732653 , 0.74883556, 0.6248106 ,\n",
       "         0.31833994, 0.69905627]], dtype=float32),\n",
       " array([[0.5041789 , 0.21036728, 0.3030698 , 0.6870877 , 0.26108888,\n",
       "         0.7276341 , 0.7838156 , 0.66918844, 0.7299927 , 0.57837653,\n",
       "         0.33975798, 0.69974256]], dtype=float32),\n",
       " array([[0.4426166 , 0.20536757, 0.2789465 , 0.67234707, 0.256808  ,\n",
       "         0.7503858 , 0.64039516, 0.6997009 , 0.73589677, 0.6264621 ,\n",
       "         0.29896286, 0.7247116 ]], dtype=float32),\n",
       " array([[0.4320417 , 0.20471968, 0.29522806, 0.69564146, 0.24737133,\n",
       "         0.7426901 , 0.57363504, 0.71123976, 0.7408757 , 0.6586596 ,\n",
       "         0.29134205, 0.72460806]], dtype=float32),\n",
       " array([[0.40001008, 0.19498703, 0.28464442, 0.7035634 , 0.23876247,\n",
       "         0.76382565, 0.451959  , 0.730907  , 0.7633593 , 0.6991622 ,\n",
       "         0.28731915, 0.73691857]], dtype=float32),\n",
       " array([[0.41029012, 0.19966663, 0.2888475 , 0.69932646, 0.23937066,\n",
       "         0.7475727 , 0.482501  , 0.7286677 , 0.7450771 , 0.6881228 ,\n",
       "         0.2897362 , 0.73714155]], dtype=float32),\n",
       " array([[0.16134934, 0.15856692, 0.1635426 , 0.6761851 , 0.20287263,\n",
       "         0.9109412 , 0.01838975, 0.87237936, 0.8950053 , 0.87263435,\n",
       "         0.16041292, 0.8571749 ]], dtype=float32),\n",
       " array([[0.10444909, 0.14593494, 0.1460277 , 0.67584234, 0.192751  ,\n",
       "         0.92048764, 0.00427961, 0.918278  , 0.9056123 , 0.9108156 ,\n",
       "         0.13440636, 0.8989376 ]], dtype=float32),\n",
       " array([[0.12379143, 0.15029374, 0.16271444, 0.6703879 , 0.19909082,\n",
       "         0.9027511 , 0.0073049 , 0.9092376 , 0.88444006, 0.8972253 ,\n",
       "         0.14820834, 0.8894081 ]], dtype=float32),\n",
       " array([[0.22765085, 0.16565974, 0.18850662, 0.6565985 , 0.21799015,\n",
       "         0.8628897 , 0.07320528, 0.8298384 , 0.83006895, 0.8090259 ,\n",
       "         0.20334199, 0.82370317]], dtype=float32),\n",
       " array([[0.38608494, 0.1935026 , 0.26417598, 0.6842164 , 0.23369198,\n",
       "         0.7735391 , 0.4267625 , 0.7442885 , 0.7543817 , 0.6834581 ,\n",
       "         0.27108583, 0.7530389 ]], dtype=float32),\n",
       " array([[0.23292395, 0.17024238, 0.19687891, 0.65794677, 0.21699598,\n",
       "         0.86777455, 0.06755636, 0.83737385, 0.8394101 , 0.81406695,\n",
       "         0.19452772, 0.82635605]], dtype=float32),\n",
       " array([[0.3434329 , 0.1930892 , 0.2345044 , 0.6443287 , 0.23787431,\n",
       "         0.8090184 , 0.26945344, 0.8098896 , 0.78672546, 0.71315205,\n",
       "         0.2570403 , 0.80889606]], dtype=float32),\n",
       " array([[0.5935033 , 0.2251981 , 0.2855875 , 0.6113437 , 0.27928007,\n",
       "         0.72515565, 0.9101    , 0.6082435 , 0.6844343 , 0.48621005,\n",
       "         0.37036738, 0.6650138 ]], dtype=float32),\n",
       " array([[0.5192325 , 0.2127886 , 0.2862605 , 0.6238559 , 0.2699714 ,\n",
       "         0.7302144 , 0.7987021 , 0.66498524, 0.6926357 , 0.5616032 ,\n",
       "         0.3409253 , 0.70356   ]], dtype=float32),\n",
       " array([[0.39310002, 0.19419509, 0.2238139 , 0.635283  , 0.2390551 ,\n",
       "         0.81353426, 0.40269625, 0.7576629 , 0.7775115 , 0.68433464,\n",
       "         0.27162898, 0.76581967]], dtype=float32),\n",
       " array([[0.4717906 , 0.20686738, 0.23856637, 0.640995  , 0.24408355,\n",
       "         0.7818893 , 0.6478591 , 0.70657206, 0.74610317, 0.6126924 ,\n",
       "         0.30328232, 0.7280208 ]], dtype=float32),\n",
       " array([[0.5344249 , 0.21567288, 0.27393076, 0.65118873, 0.25389385,\n",
       "         0.7360263 , 0.7984269 , 0.68200046, 0.71207327, 0.55105144,\n",
       "         0.3404325 , 0.7101923 ]], dtype=float32),\n",
       " array([[0.2861649 , 0.19002959, 0.186572  , 0.6263954 , 0.23155127,\n",
       "         0.8574152 , 0.16900824, 0.80618316, 0.8248852 , 0.7566404 ,\n",
       "         0.21853848, 0.8097268 ]], dtype=float32),\n",
       " array([[0.29266903, 0.19017613, 0.20048821, 0.6682378 , 0.22385208,\n",
       "         0.8389137 , 0.20418148, 0.7833402 , 0.8135508 , 0.7454245 ,\n",
       "         0.21732834, 0.7898778 ]], dtype=float32),\n",
       " array([[0.31952068, 0.19285105, 0.1951754 , 0.65766686, 0.22566628,\n",
       "         0.84196985, 0.24928586, 0.78268385, 0.81483775, 0.7246806 ,\n",
       "         0.22789554, 0.78788924]], dtype=float32),\n",
       " array([[0.27560502, 0.18486798, 0.18183212, 0.6248575 , 0.22885938,\n",
       "         0.8669194 , 0.13384815, 0.8190158 , 0.835274  , 0.77464384,\n",
       "         0.21589373, 0.8159349 ]], dtype=float32),\n",
       " array([[0.13961995, 0.1680266 , 0.17764011, 0.6291489 , 0.20445284,\n",
       "         0.8807242 , 0.00966401, 0.90112597, 0.854214  , 0.90332526,\n",
       "         0.16370222, 0.8829871 ]], dtype=float32),\n",
       " array([[0.37685633, 0.20363   , 0.23331153, 0.6620471 , 0.23193073,\n",
       "         0.8005605 , 0.4220677 , 0.74370974, 0.7755037 , 0.68362546,\n",
       "         0.25675747, 0.7584292 ]], dtype=float32),\n",
       " array([[0.60264087, 0.23797491, 0.2972795 , 0.6434595 , 0.26257598,\n",
       "         0.6931489 , 0.9152884 , 0.62646806, 0.67187965, 0.4754162 ,\n",
       "         0.3663019 , 0.67427963]], dtype=float32),\n",
       " array([[0.66096777, 0.23930117, 0.3330958 , 0.65307593, 0.2733204 ,\n",
       "         0.66228557, 0.9558527 , 0.56773424, 0.646533  , 0.43384394,\n",
       "         0.4000863 , 0.6259295 ]], dtype=float32),\n",
       " array([[0.6365998 , 0.23773128, 0.338997  , 0.682328  , 0.2614629 ,\n",
       "         0.63997495, 0.9393848 , 0.598961  , 0.64091116, 0.45554724,\n",
       "         0.39111975, 0.6476581 ]], dtype=float32),\n",
       " array([[0.67064613, 0.24249883, 0.32260635, 0.66502976, 0.2745112 ,\n",
       "         0.6686297 , 0.9629911 , 0.5522267 , 0.6596695 , 0.41633886,\n",
       "         0.396519  , 0.6133318 ]], dtype=float32),\n",
       " array([[0.68460554, 0.24122746, 0.32550773, 0.67202824, 0.27588317,\n",
       "         0.6667077 , 0.96977645, 0.53100604, 0.65999764, 0.40115115,\n",
       "         0.4055877 , 0.5978413 ]], dtype=float32),\n",
       " array([[0.6591531 , 0.23862459, 0.33819896, 0.69316757, 0.26397318,\n",
       "         0.6453325 , 0.9516192 , 0.5494288 , 0.6487366 , 0.45906407,\n",
       "         0.3966635 , 0.6033744 ]], dtype=float32),\n",
       " array([[0.6351492 , 0.23540467, 0.36785343, 0.71505785, 0.2658674 ,\n",
       "         0.61596286, 0.94007987, 0.5432301 , 0.63713   , 0.5030348 ,\n",
       "         0.39064983, 0.5898698 ]], dtype=float32),\n",
       " array([[0.58435285, 0.2186255 , 0.35949987, 0.71656644, 0.26288193,\n",
       "         0.6425479 , 0.8883909 , 0.5655611 , 0.6549997 , 0.5682055 ,\n",
       "         0.37356892, 0.60175264]], dtype=float32),\n",
       " array([[0.6012516 , 0.22332208, 0.38743687, 0.7252653 , 0.26986352,\n",
       "         0.60459316, 0.9150271 , 0.53473586, 0.63004047, 0.56593937,\n",
       "         0.39009786, 0.5757284 ]], dtype=float32),\n",
       " array([[0.5712274 , 0.22764124, 0.36009523, 0.7196702 , 0.26109263,\n",
       "         0.6212158 , 0.87338513, 0.59237987, 0.64516133, 0.5774821 ,\n",
       "         0.36549118, 0.62510717]], dtype=float32),\n",
       " array([[0.55630946, 0.23250528, 0.3534242 , 0.702807  , 0.2690962 ,\n",
       "         0.6361812 , 0.85899997, 0.5903166 , 0.65681434, 0.60599035,\n",
       "         0.35704958, 0.6243564 ]], dtype=float32),\n",
       " array([[0.5138107 , 0.2156133 , 0.3317639 , 0.70993555, 0.25971553,\n",
       "         0.6748242 , 0.7802092 , 0.62928444, 0.6895277 , 0.62704057,\n",
       "         0.3470362 , 0.65743387]], dtype=float32),\n",
       " array([[0.4891651 , 0.21065061, 0.31451514, 0.7034373 , 0.2551992 ,\n",
       "         0.7066837 , 0.71006316, 0.6638581 , 0.71547526, 0.6388659 ,\n",
       "         0.33382803, 0.68708646]], dtype=float32),\n",
       " array([[0.45324844, 0.20487995, 0.28148228, 0.6836862 , 0.2468283 ,\n",
       "         0.75082135, 0.5719884 , 0.71689737, 0.7451774 , 0.65916926,\n",
       "         0.31447133, 0.73347664]], dtype=float32),\n",
       " array([[0.42826867, 0.1985096 , 0.2769586 , 0.6735573 , 0.25139153,\n",
       "         0.76625794, 0.5270441 , 0.7248718 , 0.75222576, 0.6639354 ,\n",
       "         0.29970962, 0.7419403 ]], dtype=float32),\n",
       " array([[0.36302847, 0.18531889, 0.26221275, 0.67335933, 0.2431191 ,\n",
       "         0.7937474 , 0.32251057, 0.76253915, 0.7720051 , 0.71517843,\n",
       "         0.26604086, 0.76874775]], dtype=float32),\n",
       " array([[0.271457  , 0.17402549, 0.22012027, 0.6795042 , 0.22168782,\n",
       "         0.8415801 , 0.10890432, 0.825975  , 0.82290405, 0.78727907,\n",
       "         0.22606051, 0.81978685]], dtype=float32),\n",
       " array([[0.15882377, 0.1558186 , 0.16815072, 0.65954584, 0.20801191,\n",
       "         0.89644724, 0.01676201, 0.8894739 , 0.87387985, 0.8661873 ,\n",
       "         0.16889101, 0.87580216]], dtype=float32),\n",
       " array([[0.16469151, 0.1521404 , 0.17981651, 0.6757849 , 0.20958258,\n",
       "         0.8857644 , 0.02196423, 0.87556654, 0.8615622 , 0.856262  ,\n",
       "         0.17117353, 0.8618861 ]], dtype=float32),\n",
       " array([[0.17042081, 0.1549716 , 0.17874798, 0.66685045, 0.21134634,\n",
       "         0.8873611 , 0.02371333, 0.87699884, 0.8639846 , 0.8541915 ,\n",
       "         0.17592812, 0.86340034]], dtype=float32),\n",
       " array([[0.29559425, 0.17356196, 0.22783495, 0.6738436 , 0.22845323,\n",
       "         0.82904387, 0.1740316 , 0.8038745 , 0.8077673 , 0.7587511 ,\n",
       "         0.24746102, 0.8031383 ]], dtype=float32),\n",
       " array([[0.19434646, 0.15591118, 0.18688387, 0.6474923 , 0.22459574,\n",
       "         0.8859103 , 0.03988546, 0.8583019 , 0.8588031 , 0.8354781 ,\n",
       "         0.19125502, 0.84741056]], dtype=float32),\n",
       " array([[0.32271028, 0.17332736, 0.2551576 , 0.6754962 , 0.23827206,\n",
       "         0.801675  , 0.25195366, 0.78815544, 0.78046346, 0.7288889 ,\n",
       "         0.26480603, 0.7894592 ]], dtype=float32),\n",
       " array([[0.60212725, 0.21367526, 0.3398583 , 0.65703744, 0.28094032,\n",
       "         0.6891302 , 0.9214061 , 0.5779317 , 0.6666607 , 0.49111387,\n",
       "         0.3860086 , 0.632532  ]], dtype=float32),\n",
       " array([[0.61567825, 0.21809353, 0.36644417, 0.69522166, 0.26976663,\n",
       "         0.6355368 , 0.92985463, 0.5686693 , 0.63308895, 0.49100378,\n",
       "         0.3943039 , 0.6173743 ]], dtype=float32),\n",
       " array([[0.58598566, 0.21977086, 0.35391226, 0.6996081 , 0.25927067,\n",
       "         0.6557805 , 0.8819249 , 0.62515193, 0.6616572 , 0.5292477 ,\n",
       "         0.37232468, 0.65730774]], dtype=float32),\n",
       " array([[0.61586684, 0.21888447, 0.34678534, 0.68398994, 0.27551484,\n",
       "         0.66763246, 0.9313266 , 0.54747456, 0.65850043, 0.49982595,\n",
       "         0.38735545, 0.6011176 ]], dtype=float32),\n",
       " array([[0.60380757, 0.22070275, 0.35639885, 0.69425064, 0.27327472,\n",
       "         0.6494572 , 0.9196866 , 0.54837126, 0.6480584 , 0.53003764,\n",
       "         0.38325632, 0.5971661 ]], dtype=float32),\n",
       " array([[0.5744106 , 0.21976842, 0.36096433, 0.7100253 , 0.26450086,\n",
       "         0.63417655, 0.88067424, 0.57566947, 0.64509094, 0.57824284,\n",
       "         0.3763724 , 0.6126852 ]], dtype=float32),\n",
       " array([[0.5423408 , 0.21697028, 0.36317775, 0.7148271 , 0.26400903,\n",
       "         0.63351035, 0.8412832 , 0.60234267, 0.6474214 , 0.5992023 ,\n",
       "         0.35883132, 0.6333972 ]], dtype=float32),\n",
       " array([[0.50766164, 0.20781651, 0.32155296, 0.69297343, 0.262519  ,\n",
       "         0.69862354, 0.7677776 , 0.6360731 , 0.6923913 , 0.61480516,\n",
       "         0.33604586, 0.66442895]], dtype=float32),\n",
       " array([[0.44392267, 0.20049062, 0.27027988, 0.6711812 , 0.25266862,\n",
       "         0.76133513, 0.59528536, 0.7018716 , 0.7410493 , 0.64483714,\n",
       "         0.30048642, 0.72312903]], dtype=float32),\n",
       " array([[0.3664273 , 0.19346566, 0.23407465, 0.6483041 , 0.24259517,\n",
       "         0.8127045 , 0.34028092, 0.7708857 , 0.78568023, 0.6990537 ,\n",
       "         0.26199558, 0.78137606]], dtype=float32),\n",
       " array([[0.23385982, 0.17438135, 0.18805453, 0.66014796, 0.22088253,\n",
       "         0.87124264, 0.08296403, 0.82596874, 0.8450715 , 0.79844296,\n",
       "         0.19523767, 0.8247808 ]], dtype=float32),\n",
       " array([[0.29370677, 0.18270046, 0.20129734, 0.6541333 , 0.22673295,\n",
       "         0.8516706 , 0.17953505, 0.79515254, 0.82220346, 0.7503737 ,\n",
       "         0.2228973 , 0.799876  ]], dtype=float32),\n",
       " array([[0.2699411 , 0.17696345, 0.20532498, 0.6655195 , 0.22101021,\n",
       "         0.845562  , 0.12893909, 0.8178068 , 0.8194149 , 0.7711486 ,\n",
       "         0.2207519 , 0.8164985 ]], dtype=float32),\n",
       " array([[0.39637595, 0.19463013, 0.26012486, 0.66267985, 0.24290772,\n",
       "         0.78249824, 0.45527428, 0.7400053 , 0.7582495 , 0.6767208 ,\n",
       "         0.2824672 , 0.7551219 ]], dtype=float32),\n",
       " array([[0.2712072 , 0.17785883, 0.20830444, 0.646623  , 0.2306856 ,\n",
       "         0.8542067 , 0.13089079, 0.82159597, 0.8277042 , 0.7699103 ,\n",
       "         0.22047272, 0.82037807]], dtype=float32),\n",
       " array([[0.35963267, 0.18975782, 0.23444173, 0.64190656, 0.24639352,\n",
       "         0.82205707, 0.3456814 , 0.78271866, 0.7995391 , 0.6914667 ,\n",
       "         0.26851806, 0.7912804 ]], dtype=float32),\n",
       " array([[0.32030064, 0.18311457, 0.22681127, 0.64015   , 0.239547  ,\n",
       "         0.8329003 , 0.212698  , 0.8224224 , 0.8116423 , 0.72978014,\n",
       "         0.25448346, 0.81989926]], dtype=float32),\n",
       " array([[0.22088246, 0.1654764 , 0.18993752, 0.6478389 , 0.22004245,\n",
       "         0.87171566, 0.05346165, 0.8685677 , 0.8490016 , 0.8155781 ,\n",
       "         0.20747529, 0.8554621 ]], dtype=float32),\n",
       " array([[0.20776409, 0.15944338, 0.1820696 , 0.6626438 , 0.21418332,\n",
       "         0.8757077 , 0.0466766 , 0.86601543, 0.8523471 , 0.82133996,\n",
       "         0.19919121, 0.8515033 ]], dtype=float32),\n",
       " array([[0.38842186, 0.18390788, 0.23856723, 0.6704416 , 0.23698834,\n",
       "         0.8072279 , 0.44195992, 0.73796165, 0.7789981 , 0.67055666,\n",
       "         0.2744314 , 0.74843436]], dtype=float32),\n",
       " array([[0.5372723 , 0.21190986, 0.3013952 , 0.6673239 , 0.25894827,\n",
       "         0.7168993 , 0.83437103, 0.64906114, 0.69757855, 0.540738  ,\n",
       "         0.34471235, 0.6848114 ]], dtype=float32),\n",
       " array([[0.39050078, 0.19786827, 0.23710892, 0.65671694, 0.23871687,\n",
       "         0.7997333 , 0.44945306, 0.74452066, 0.7728199 , 0.6698891 ,\n",
       "         0.26998842, 0.7594046 ]], dtype=float32),\n",
       " array([[0.26472974, 0.18271361, 0.20057803, 0.647241  , 0.2322447 ,\n",
       "         0.8571941 , 0.14181064, 0.81541944, 0.8326275 , 0.76457655,\n",
       "         0.21172018, 0.8166444 ]], dtype=float32),\n",
       " array([[0.3355433 , 0.19383909, 0.20971233, 0.64572316, 0.23288842,\n",
       "         0.8283066 , 0.2837626 , 0.7958455 , 0.8021714 , 0.7042778 ,\n",
       "         0.24498472, 0.8006313 ]], dtype=float32),\n",
       " array([[0.4529833 , 0.21266504, 0.24782018, 0.63210386, 0.25028756,\n",
       "         0.7800639 , 0.6264541 , 0.72802263, 0.7508172 , 0.6127584 ,\n",
       "         0.29567578, 0.74983037]], dtype=float32),\n",
       " array([[0.4957829 , 0.21564439, 0.263595  , 0.652916  , 0.24539264,\n",
       "         0.7617423 , 0.70829415, 0.70425344, 0.73844874, 0.59078   ,\n",
       "         0.31051734, 0.7255886 ]], dtype=float32),\n",
       " array([[0.5666891 , 0.22607698, 0.30282   , 0.67725205, 0.25259325,\n",
       "         0.6997312 , 0.868983  , 0.62393886, 0.6864173 , 0.5306168 ,\n",
       "         0.3454046 , 0.66312164]], dtype=float32),\n",
       " array([[0.63676405, 0.2330913 , 0.31192228, 0.6630053 , 0.2698236 ,\n",
       "         0.68846107, 0.9458874 , 0.54651684, 0.6711218 , 0.46596295,\n",
       "         0.38582292, 0.6079421 ]], dtype=float32),\n",
       " array([[0.51782185, 0.2219863 , 0.2709563 , 0.6208944 , 0.2661411 ,\n",
       "         0.7659288 , 0.77567047, 0.67364585, 0.7360161 , 0.57591575,\n",
       "         0.3234091 , 0.7097554 ]], dtype=float32),\n",
       " array([[0.37567177, 0.20820968, 0.22840312, 0.64705783, 0.23905835,\n",
       "         0.8018156 , 0.38742822, 0.777549  , 0.78029644, 0.68048954,\n",
       "         0.2577234 , 0.78722423]], dtype=float32),\n",
       " array([[0.27051756, 0.19286507, 0.18993837, 0.6499532 , 0.21732168,\n",
       "         0.8517361 , 0.11018453, 0.8418158 , 0.82785326, 0.77790284,\n",
       "         0.20459491, 0.83389163]], dtype=float32),\n",
       " array([[0.20915137, 0.1765358 , 0.16669798, 0.6570585 , 0.20256026,\n",
       "         0.8820048 , 0.0382695 , 0.8763543 , 0.8605141 , 0.83459616,\n",
       "         0.18226641, 0.8594628 ]], dtype=float32),\n",
       " array([[0.25580922, 0.1810111 , 0.1886663 , 0.6672563 , 0.20693593,\n",
       "         0.8551069 , 0.08689427, 0.84076536, 0.83122796, 0.79832405,\n",
       "         0.20647529, 0.8287375 ]], dtype=float32),\n",
       " array([[0.27858463, 0.18497276, 0.20338959, 0.6710242 , 0.21360691,\n",
       "         0.83788675, 0.14141035, 0.81027126, 0.8130062 , 0.7735886 ,\n",
       "         0.21786797, 0.8061412 ]], dtype=float32),\n",
       " array([[0.40230468, 0.1996612 , 0.25468245, 0.6835037 , 0.23618965,\n",
       "         0.78149855, 0.5362593 , 0.6891541 , 0.75803417, 0.66540617,\n",
       "         0.26824868, 0.7133739 ]], dtype=float32),\n",
       " array([[0.44166714, 0.20925455, 0.26944447, 0.6438617 , 0.25362885,\n",
       "         0.7679355 , 0.62749076, 0.6984267 , 0.7404352 , 0.6347356 ,\n",
       "         0.29517347, 0.7259735 ]], dtype=float32),\n",
       " array([[0.43757707, 0.21192037, 0.276549  , 0.6497629 , 0.25027606,\n",
       "         0.7488475 , 0.60660267, 0.71585697, 0.7271487 , 0.63979185,\n",
       "         0.3011626 , 0.74036396]], dtype=float32),\n",
       " array([[0.6459105 , 0.234492  , 0.3196281 , 0.6452441 , 0.27952042,\n",
       "         0.690393  , 0.9512988 , 0.5666061 , 0.6702769 , 0.44060796,\n",
       "         0.3892115 , 0.62601477]], dtype=float32),\n",
       " array([[0.5612865 , 0.21612874, 0.30234995, 0.6380727 , 0.27075624,\n",
       "         0.7284603 , 0.8529252 , 0.6447467 , 0.703701  , 0.5391773 ,\n",
       "         0.36053413, 0.68270785]], dtype=float32),\n",
       " array([[0.56153125, 0.2158551 , 0.28824916, 0.6488939 , 0.2605911 ,\n",
       "         0.7350942 , 0.8385946 , 0.6732977 , 0.7187667 , 0.53654057,\n",
       "         0.36491382, 0.7019394 ]], dtype=float32),\n",
       " array([[0.53132933, 0.20913693, 0.2954715 , 0.6632893 , 0.26156256,\n",
       "         0.71211666, 0.8266424 , 0.6335009 , 0.68147665, 0.55089074,\n",
       "         0.3364555 , 0.6712819 ]], dtype=float32),\n",
       " array([[0.60881656, 0.22136986, 0.32649878, 0.6819668 , 0.27486897,\n",
       "         0.682179  , 0.93456596, 0.56601244, 0.67520803, 0.4706392 ,\n",
       "         0.37775293, 0.6212645 ]], dtype=float32),\n",
       " array([[0.63246506, 0.2268375 , 0.35526088, 0.69397265, 0.2817023 ,\n",
       "         0.6457297 , 0.9538824 , 0.49677628, 0.64291704, 0.47852007,\n",
       "         0.38562286, 0.56077045]], dtype=float32),\n",
       " array([[0.5963126 , 0.23036918, 0.3584461 , 0.70744556, 0.26374072,\n",
       "         0.6293407 , 0.9106373 , 0.55705374, 0.6386996 , 0.54210913,\n",
       "         0.3694489 , 0.60256255]], dtype=float32),\n",
       " array([[0.56988657, 0.22131565, 0.2877883 , 0.6583486 , 0.2753808 ,\n",
       "         0.730818  , 0.88827974, 0.59422344, 0.7125883 , 0.52346957,\n",
       "         0.3515557 , 0.64526707]], dtype=float32),\n",
       " array([[0.49369937, 0.21267477, 0.28419858, 0.67777485, 0.25656384,\n",
       "         0.74179494, 0.7332064 , 0.6770569 , 0.7333971 , 0.5977416 ,\n",
       "         0.31946796, 0.70475316]], dtype=float32),\n",
       " array([[0.51806736, 0.21091466, 0.31883034, 0.691142  , 0.2626624 ,\n",
       "         0.7084467 , 0.79597205, 0.6401154 , 0.7072474 , 0.5888868 ,\n",
       "         0.34135455, 0.6737636 ]], dtype=float32),\n",
       " array([[0.5650969 , 0.22134088, 0.37676233, 0.72385883, 0.26514548,\n",
       "         0.62351817, 0.87765306, 0.5572136 , 0.6486474 , 0.60438293,\n",
       "         0.37067512, 0.5915563 ]], dtype=float32),\n",
       " array([[0.56203675, 0.22194459, 0.4122966 , 0.74189943, 0.2607527 ,\n",
       "         0.569306  , 0.86544657, 0.5447622 , 0.6101933 , 0.6487674 ,\n",
       "         0.382029  , 0.5708655 ]], dtype=float32),\n",
       " array([[0.5678313 , 0.2183751 , 0.40734592, 0.7388049 , 0.26571354,\n",
       "         0.58876354, 0.86701554, 0.5527752 , 0.62717205, 0.63425624,\n",
       "         0.38505656, 0.58046216]], dtype=float32),\n",
       " array([[0.5942376 , 0.23357524, 0.44806364, 0.739352  , 0.28367007,\n",
       "         0.5430441 , 0.91062695, 0.5221173 , 0.6088161 , 0.64408255,\n",
       "         0.40037736, 0.54814833]], dtype=float32),\n",
       " array([[0.5599511 , 0.22971448, 0.37421298, 0.7282565 , 0.26286152,\n",
       "         0.60753244, 0.8405774 , 0.6178891 , 0.6508997 , 0.6170909 ,\n",
       "         0.3708281 , 0.6402333 ]], dtype=float32),\n",
       " array([[0.4887804 , 0.20767196, 0.33416983, 0.713632  , 0.2588229 ,\n",
       "         0.6814012 , 0.69002414, 0.6714897 , 0.6951648 , 0.6471421 ,\n",
       "         0.3361895 , 0.6891344 ]], dtype=float32),\n",
       " array([[0.47769234, 0.20148847, 0.32721072, 0.7017482 , 0.2636958 ,\n",
       "         0.70085585, 0.6622694 , 0.66930455, 0.70151436, 0.6556627 ,\n",
       "         0.32906023, 0.68829006]], dtype=float32),\n",
       " array([[0.4064917 , 0.18566297, 0.2859705 , 0.7063726 , 0.24502076,\n",
       "         0.7650094 , 0.40742457, 0.7340513 , 0.7616274 , 0.7127608 ,\n",
       "         0.3014757 , 0.73773575]], dtype=float32),\n",
       " array([[0.20096183, 0.14970109, 0.19441447, 0.7093995 , 0.20904067,\n",
       "         0.87998396, 0.03566674, 0.837491  , 0.8601611 , 0.85066944,\n",
       "         0.19355984, 0.8242816 ]], dtype=float32),\n",
       " array([[0.17283069, 0.15203118, 0.17778666, 0.70464027, 0.2005501 ,\n",
       "         0.88393736, 0.02450389, 0.8621594 , 0.86483   , 0.85590607,\n",
       "         0.17996272, 0.8510699 ]], dtype=float32),\n",
       " array([[0.22623831, 0.16415302, 0.21502   , 0.6891226 , 0.2225957 ,\n",
       "         0.84662056, 0.07630894, 0.8199333 , 0.8215358 , 0.80701774,\n",
       "         0.20300418, 0.81795895]], dtype=float32),\n",
       " array([[0.16716112, 0.15517814, 0.18237363, 0.6660791 , 0.21104015,\n",
       "         0.883641  , 0.02359261, 0.8698227 , 0.854567  , 0.851432  ,\n",
       "         0.17075579, 0.8613634 ]], dtype=float32),\n",
       " array([[0.14449355, 0.14859615, 0.18938048, 0.6908873 , 0.20399275,\n",
       "         0.87618965, 0.01549545, 0.8827603 , 0.85348934, 0.86985564,\n",
       "         0.16795844, 0.87098813]], dtype=float32),\n",
       " array([[0.1452776 , 0.14818507, 0.17947207, 0.65671694, 0.2103229 ,\n",
       "         0.89344186, 0.01333319, 0.8955163 , 0.86820143, 0.8717761 ,\n",
       "         0.16683422, 0.8815749 ]], dtype=float32),\n",
       " array([[0.46066856, 0.19828907, 0.27401096, 0.62187845, 0.26682675,\n",
       "         0.7743198 , 0.6316915 , 0.74067825, 0.74199283, 0.59585166,\n",
       "         0.31665593, 0.7618944 ]], dtype=float32),\n",
       " array([[0.45720625, 0.19859059, 0.29638228, 0.6522626 , 0.25477234,\n",
       "         0.7399021 , 0.58852845, 0.7691618 , 0.727374  , 0.6114935 ,\n",
       "         0.33468702, 0.7805598 ]], dtype=float32),\n",
       " array([[0.570458  , 0.20975973, 0.30573192, 0.6439306 , 0.27458006,\n",
       "         0.7288968 , 0.87205714, 0.6371722 , 0.7031927 , 0.51343477,\n",
       "         0.37094447, 0.6811548 ]], dtype=float32),\n",
       " array([[0.5873125 , 0.21539937, 0.3143651 , 0.67762154, 0.26171046,\n",
       "         0.7007443 , 0.88175714, 0.6484873 , 0.6937743 , 0.5008948 ,\n",
       "         0.37470567, 0.68207055]], dtype=float32),\n",
       " array([[0.5119372 , 0.20299642, 0.2806452 , 0.66010416, 0.25070074,\n",
       "         0.7548301 , 0.7013413 , 0.7227872 , 0.7370971 , 0.58398294,\n",
       "         0.3381196 , 0.73705876]], dtype=float32),\n",
       " array([[0.48611897, 0.2083008 , 0.25819716, 0.6450717 , 0.24811208,\n",
       "         0.7671548 , 0.64409965, 0.7461843 , 0.7451658 , 0.5931555 ,\n",
       "         0.32056388, 0.76083654]], dtype=float32),\n",
       " array([[0.20865025, 0.16621082, 0.16251464, 0.6512871 , 0.21135034,\n",
       "         0.8993102 , 0.04541298, 0.85491735, 0.87361795, 0.82236767,\n",
       "         0.17928955, 0.8447516 ]], dtype=float32),\n",
       " array([[0.16939881, 0.1631685 , 0.14975138, 0.64756125, 0.20516682,\n",
       "         0.90126103, 0.02565868, 0.87369   , 0.8738002 , 0.8463375 ,\n",
       "         0.165904  , 0.86405957]], dtype=float32),\n",
       " array([[0.13778806, 0.15125065, 0.14749505, 0.661402  , 0.19846354,\n",
       "         0.9095042 , 0.01260752, 0.88444304, 0.8840502 , 0.8799905 ,\n",
       "         0.15340346, 0.8697273 ]], dtype=float32),\n",
       " array([[0.1563719 , 0.1614509 , 0.15303792, 0.64339805, 0.20642011,\n",
       "         0.90820116, 0.02215587, 0.86357003, 0.88069606, 0.8633747 ,\n",
       "         0.16070887, 0.8562851 ]], dtype=float32),\n",
       " array([[0.10725372, 0.1599995 , 0.16077441, 0.6170595 , 0.19932356,\n",
       "         0.90355515, 0.00416061, 0.9227427 , 0.8782945 , 0.9196932 ,\n",
       "         0.14432542, 0.9056903 ]], dtype=float32),\n",
       " array([[0.16638458, 0.17831358, 0.16470389, 0.6143791 , 0.21138911,\n",
       "         0.88376594, 0.02761405, 0.8724957 , 0.8506474 , 0.85459137,\n",
       "         0.16700755, 0.8658883 ]], dtype=float32),\n",
       " array([[0.1631499 , 0.17792495, 0.20283481, 0.58877116, 0.21662378,\n",
       "         0.8711845 , 0.0133218 , 0.90827924, 0.84078175, 0.89256114,\n",
       "         0.17746828, 0.8901983 ]], dtype=float32),\n",
       " array([[0.19322102, 0.18615097, 0.18634616, 0.5862275 , 0.2139953 ,\n",
       "         0.8694563 , 0.02930056, 0.889676  , 0.83420575, 0.8586987 ,\n",
       "         0.18591037, 0.8743317 ]], dtype=float32),\n",
       " array([[0.13165145, 0.17506187, 0.24528879, 0.57088256, 0.20637877,\n",
       "         0.84444445, 0.00314727, 0.9472141 , 0.8179543 , 0.93918765,\n",
       "         0.18350473, 0.92295665]], dtype=float32),\n",
       " array([[0.40084437, 0.19727051, 0.2056639 , 0.6100007 , 0.23284313,\n",
       "         0.8490371 , 0.45335445, 0.7621463 , 0.8079988 , 0.6553545 ,\n",
       "         0.25990918, 0.7677346 ]], dtype=float32),\n",
       " array([[0.26131022, 0.19773903, 0.20489636, 0.59041625, 0.21034713,\n",
       "         0.8352301 , 0.07227331, 0.8780923 , 0.798727  , 0.81985784,\n",
       "         0.22493011, 0.8590484 ]], dtype=float32),\n",
       " array([[0.7133964 , 0.24735537, 0.28612867, 0.6044327 , 0.28502133,\n",
       "         0.7151925 , 0.98529226, 0.5035833 , 0.66661274, 0.31282997,\n",
       "         0.40154114, 0.58785856]], dtype=float32),\n",
       " array([[0.75489426, 0.25749406, 0.2941969 , 0.63025415, 0.2859441 ,\n",
       "         0.64569503, 0.99386543, 0.47776493, 0.6118158 , 0.23620194,\n",
       "         0.44273356, 0.5774365 ]], dtype=float32),\n",
       " array([[0.7941218 , 0.25460508, 0.3108231 , 0.6660782 , 0.29824916,\n",
       "         0.6423137 , 0.99754363, 0.37006742, 0.6177828 , 0.19182736,\n",
       "         0.4535282 , 0.48664007]], dtype=float32),\n",
       " array([[0.7857471 , 0.25392818, 0.28233472, 0.64603835, 0.3042035 ,\n",
       "         0.6893109 , 0.9969241 , 0.40440115, 0.66169375, 0.19283836,\n",
       "         0.44521707, 0.52339584]], dtype=float32),\n",
       " array([[0.74387115, 0.24117842, 0.3179487 , 0.6898911 , 0.28297427,\n",
       "         0.6473714 , 0.99140584, 0.4331857 , 0.6350449 , 0.28353238,\n",
       "         0.42676586, 0.52452266]], dtype=float32),\n",
       " array([[0.71176684, 0.24389158, 0.30295056, 0.6236842 , 0.30293816,\n",
       "         0.71960264, 0.98288745, 0.500979  , 0.6905488 , 0.332634  ,\n",
       "         0.40062878, 0.58521503]], dtype=float32),\n",
       " array([[0.48053032, 0.19397028, 0.20717543, 0.6877111 , 0.22203045,\n",
       "         0.8074418 , 0.65657055, 0.69303954, 0.7763772 , 0.5910596 ,\n",
       "         0.29126507, 0.7043784 ]], dtype=float32),\n",
       " array([[0.45957744, 0.21972702, 0.2264344 , 0.68659073, 0.23425108,\n",
       "         0.76897144, 0.7318641 , 0.6568207 , 0.74586606, 0.57602406,\n",
       "         0.2740723 , 0.6958376 ]], dtype=float32),\n",
       " array([[0.63210297, 0.23502226, 0.31003684, 0.6972998 , 0.2723194 ,\n",
       "         0.666631  , 0.95813316, 0.4816026 , 0.6580782 , 0.45998615,\n",
       "         0.36063525, 0.54553044]], dtype=float32),\n",
       " array([[0.7264118 , 0.2888568 , 0.45472875, 0.74188846, 0.2938713 ,\n",
       "         0.4279579 , 0.9915326 , 0.38215786, 0.51647854, 0.45336533,\n",
       "         0.44437945, 0.44243863]], dtype=float32),\n",
       " array([[0.5936827 , 0.23265775, 0.32690567, 0.6939317 , 0.26730287,\n",
       "         0.6656031 , 0.91199845, 0.5520594 , 0.66427034, 0.52737546,\n",
       "         0.35913146, 0.6069413 ]], dtype=float32),\n",
       " array([[0.66766155, 0.25273135, 0.36124784, 0.6863302 , 0.3075557 ,\n",
       "         0.63308156, 0.97517145, 0.4779448 , 0.66191316, 0.4480265 ,\n",
       "         0.4018972 , 0.549651  ]], dtype=float32),\n",
       " array([[0.6715211 , 0.24297616, 0.4250354 , 0.7364559 , 0.2938941 ,\n",
       "         0.562648  , 0.97097397, 0.4724102 , 0.62450206, 0.48935503,\n",
       "         0.42360765, 0.52920103]], dtype=float32),\n",
       " array([[0.6448581 , 0.23132604, 0.43597794, 0.75533754, 0.28230897,\n",
       "         0.5424488 , 0.9538243 , 0.4991679 , 0.6090615 , 0.5313212 ,\n",
       "         0.4245039 , 0.5463485 ]], dtype=float32),\n",
       " array([[0.60357267, 0.21362512, 0.42844158, 0.76607305, 0.26403892,\n",
       "         0.54326797, 0.88650924, 0.5471674 , 0.5984403 , 0.6116788 ,\n",
       "         0.41624197, 0.5721199 ]], dtype=float32),\n",
       " array([[0.5474083 , 0.20314135, 0.39331308, 0.7553298 , 0.25525305,\n",
       "         0.6050892 , 0.7621247 , 0.61467254, 0.642858  , 0.6586843 ,\n",
       "         0.38284966, 0.6261631 ]], dtype=float32),\n",
       " array([[0.436009  , 0.18038678, 0.28537145, 0.7071656 , 0.24263649,\n",
       "         0.7705092 , 0.43739632, 0.73738563, 0.760689  , 0.68217707,\n",
       "         0.31182435, 0.7421924 ]], dtype=float32),\n",
       " array([[0.18315293, 0.1525637 , 0.1992253 , 0.74945843, 0.20245613,\n",
       "         0.86689705, 0.0338802 , 0.80813694, 0.8584566 , 0.8713478 ,\n",
       "         0.1874346 , 0.7981447 ]], dtype=float32),\n",
       " array([[0.4860881 , 0.21365063, 0.39878604, 0.74220407, 0.26574075,\n",
       "         0.60788167, 0.7361688 , 0.6073883 , 0.6531738 , 0.7053606 ,\n",
       "         0.35077932, 0.62596977]], dtype=float32),\n",
       " array([[0.35142112, 0.18094358, 0.3310562 , 0.7533896 , 0.23409034,\n",
       "         0.6894045 , 0.3371869 , 0.70605546, 0.69393104, 0.7566966 ,\n",
       "         0.2741125 , 0.7099075 ]], dtype=float32),\n",
       " array([[0.14699332, 0.14015904, 0.18325868, 0.6914137 , 0.20242299,\n",
       "         0.89835835, 0.01222597, 0.8809244 , 0.8738211 , 0.8769146 ,\n",
       "         0.16511461, 0.8680543 ]], dtype=float32),\n",
       " array([[0.14048254, 0.14099531, 0.20373116, 0.69709384, 0.21063055,\n",
       "         0.878185  , 0.01384865, 0.884488  , 0.8594218 , 0.8747728 ,\n",
       "         0.17843509, 0.87438387]], dtype=float32),\n",
       " array([[0.41424352, 0.19562812, 0.29106346, 0.67049956, 0.25727615,\n",
       "         0.75035894, 0.5414202 , 0.74738485, 0.7384452 , 0.6297447 ,\n",
       "         0.30984303, 0.77220285]], dtype=float32),\n",
       " array([[0.5269953 , 0.20001025, 0.3331828 , 0.6566127 , 0.28500617,\n",
       "         0.7306087 , 0.8228813 , 0.64753956, 0.7131273 , 0.55175275,\n",
       "         0.36025956, 0.6917374 ]], dtype=float32),\n",
       " array([[0.5842236 , 0.20687033, 0.33956242, 0.6934778 , 0.26552388,\n",
       "         0.685619  , 0.86981046, 0.65293443, 0.6869659 , 0.5136458 ,\n",
       "         0.38945034, 0.6853933 ]], dtype=float32),\n",
       " array([[0.5449527 , 0.19962901, 0.34478286, 0.72079587, 0.24993034,\n",
       "         0.6599875 , 0.77855986, 0.65603316, 0.6659573 , 0.6007384 ,\n",
       "         0.37838385, 0.6738453 ]], dtype=float32),\n",
       " array([[0.50997764, 0.19612509, 0.29450807, 0.6782433 , 0.25016543,\n",
       "         0.7517112 , 0.6519649 , 0.7205927 , 0.73869544, 0.6116423 ,\n",
       "         0.34141275, 0.73073447]], dtype=float32),\n",
       " array([[0.5354265 , 0.20920528, 0.3113269 , 0.67497885, 0.25993863,\n",
       "         0.7196927 , 0.77057105, 0.6987481 , 0.71432376, 0.5631229 ,\n",
       "         0.35583916, 0.7237272 ]], dtype=float32),\n",
       " array([[0.30379668, 0.17930415, 0.21877325, 0.6392539 , 0.23737971,\n",
       "         0.8507762 , 0.16483814, 0.8057162 , 0.8209017 , 0.75526077,\n",
       "         0.23455319, 0.80937386]], dtype=float32),\n",
       " array([[0.07743759, 0.12773387, 0.11619905, 0.631038  , 0.18961531,\n",
       "         0.9456675 , 0.0015408 , 0.92313874, 0.9182228 , 0.9319086 ,\n",
       "         0.11228868, 0.9060613 ]], dtype=float32),\n",
       " array([[0.09760951, 0.13558461, 0.14823578, 0.6949745 , 0.17828587,\n",
       "         0.912716  , 0.00312201, 0.9206954 , 0.8948711 , 0.91909343,\n",
       "         0.14268468, 0.9010448 ]], dtype=float32),\n",
       " array([[0.2502955 , 0.1625233 , 0.19809267, 0.6807427 , 0.21641046,\n",
       "         0.86413753, 0.11141481, 0.8013196 , 0.83179116, 0.77657807,\n",
       "         0.20178656, 0.7991097 ]], dtype=float32),\n",
       " array([[0.49913925, 0.21345282, 0.29585946, 0.6502014 , 0.26484373,\n",
       "         0.7244195 , 0.7897459 , 0.63916206, 0.68832725, 0.56941617,\n",
       "         0.31110382, 0.6831206 ]], dtype=float32),\n",
       " array([[0.31359762, 0.19477126, 0.2319275 , 0.654973  , 0.231401  ,\n",
       "         0.82316864, 0.2377603 , 0.77889115, 0.79909194, 0.7383043 ,\n",
       "         0.23553254, 0.79127854]], dtype=float32),\n",
       " array([[0.52029055, 0.22013332, 0.28885412, 0.6116801 , 0.27680773,\n",
       "         0.74653834, 0.80866724, 0.68613935, 0.71702784, 0.53636765,\n",
       "         0.33652014, 0.7282856 ]], dtype=float32),\n",
       " array([[0.45666972, 0.21322499, 0.2780615 , 0.59720397, 0.26299402,\n",
       "         0.762058  , 0.5546057 , 0.79614884, 0.73781914, 0.6124735 ,\n",
       "         0.3176509 , 0.80494225]], dtype=float32),\n",
       " array([[0.22521074, 0.18024693, 0.20071322, 0.5816415 , 0.22441523,\n",
       "         0.86412805, 0.03469768, 0.9042218 , 0.83774644, 0.8410074 ,\n",
       "         0.22222422, 0.8886438 ]], dtype=float32),\n",
       " array([[0.5196109 , 0.2108614 , 0.23543623, 0.5976891 , 0.25974151,\n",
       "         0.81731147, 0.7291402 , 0.7422074 , 0.78722674, 0.5490067 ,\n",
       "         0.3265713 , 0.75858414]], dtype=float32),\n",
       " array([[0.639393  , 0.2298744 , 0.276278  , 0.6580127 , 0.25881693,\n",
       "         0.73643225, 0.9383776 , 0.6269904 , 0.71900463, 0.41085044,\n",
       "         0.36644712, 0.6685587 ]], dtype=float32),\n",
       " array([[0.64461094, 0.22786257, 0.28070548, 0.65743405, 0.26878014,\n",
       "         0.7190067 , 0.9545961 , 0.5538561 , 0.69149846, 0.4132681 ,\n",
       "         0.37692276, 0.6173894 ]], dtype=float32),\n",
       " array([[0.5906099 , 0.22572152, 0.30753693, 0.6701569 , 0.2655004 ,\n",
       "         0.6724367 , 0.9196675 , 0.5816546 , 0.64506775, 0.472857  ,\n",
       "         0.35259843, 0.6388837 ]], dtype=float32),\n",
       " array([[0.6329396 , 0.24070628, 0.38730615, 0.683075  , 0.29568467,\n",
       "         0.5904474 , 0.9602577 , 0.4801945 , 0.5807887 , 0.47619525,\n",
       "         0.35923186, 0.5454957 ]], dtype=float32),\n",
       " array([[0.62650794, 0.24492086, 0.42453936, 0.7423883 , 0.26158148,\n",
       "         0.48130527, 0.9394472 , 0.5177265 , 0.5126521 , 0.53853863,\n",
       "         0.37651554, 0.5560984 ]], dtype=float32),\n",
       " array([[0.5997924 , 0.22983971, 0.39872983, 0.7274527 , 0.26605484,\n",
       "         0.5688474 , 0.8995155 , 0.5391056 , 0.59570664, 0.6012877 ,\n",
       "         0.38620073, 0.57218194]], dtype=float32),\n",
       " array([[0.58699787, 0.22119583, 0.36296213, 0.73303527, 0.25874412,\n",
       "         0.6185831 , 0.8756087 , 0.5957026 , 0.6483468 , 0.5753816 ,\n",
       "         0.38292116, 0.62144935]], dtype=float32),\n",
       " array([[0.6120856 , 0.23841563, 0.41064513, 0.74186945, 0.27152297,\n",
       "         0.554413  , 0.91452223, 0.5433422 , 0.61741734, 0.61060625,\n",
       "         0.40227976, 0.5653012 ]], dtype=float32),\n",
       " array([[0.57431096, 0.22800152, 0.31238443, 0.70418656, 0.26041922,\n",
       "         0.7073759 , 0.8379064 , 0.6330526 , 0.7377115 , 0.60056615,\n",
       "         0.37992483, 0.65641886]], dtype=float32),\n",
       " array([[0.5285036 , 0.22701268, 0.34748635, 0.6987072 , 0.27144936,\n",
       "         0.66712755, 0.77866054, 0.6080586 , 0.6909352 , 0.67971414,\n",
       "         0.35047826, 0.6273579 ]], dtype=float32),\n",
       " array([[0.4015315 , 0.21044524, 0.27817065, 0.6822258 , 0.24437329,\n",
       "         0.7320566 , 0.45531496, 0.7220544 , 0.71358037, 0.6946112 ,\n",
       "         0.26538858, 0.73676145]], dtype=float32),\n",
       " array([[0.3639867 , 0.19964145, 0.2397927 , 0.6845664 , 0.22928259,\n",
       "         0.78243154, 0.29736432, 0.76448894, 0.76121724, 0.7228384 ,\n",
       "         0.24874362, 0.76893115]], dtype=float32),\n",
       " array([[0.47641322, 0.21725257, 0.31041458, 0.69359416, 0.254798  ,\n",
       "         0.7083249 , 0.65918493, 0.68463343, 0.7206735 , 0.66677743,\n",
       "         0.33222947, 0.7044344 ]], dtype=float32),\n",
       " array([[0.48955712, 0.21614753, 0.35869116, 0.73134893, 0.24750288,\n",
       "         0.64621234, 0.66394734, 0.6721363 , 0.6863519 , 0.698987  ,\n",
       "         0.35409373, 0.6792877 ]], dtype=float32),\n",
       " array([[0.4084399 , 0.1998904 , 0.28702614, 0.68826795, 0.2471354 ,\n",
       "         0.7674043 , 0.44823804, 0.7344011 , 0.7712254 , 0.71059895,\n",
       "         0.3091339 , 0.7471305 ]], dtype=float32),\n",
       " array([[0.3231397 , 0.1704257 , 0.25150058, 0.6871499 , 0.23212111,\n",
       "         0.81381714, 0.20294102, 0.7925246 , 0.7930507 , 0.7492203 ,\n",
       "         0.26633957, 0.7931695 ]], dtype=float32),\n",
       " array([[0.5184222 , 0.20147035, 0.2994093 , 0.6505854 , 0.28132954,\n",
       "         0.7619959 , 0.79641557, 0.61535877, 0.73615414, 0.5993411 ,\n",
       "         0.3424346 , 0.6604276 ]], dtype=float32),\n",
       " array([[0.51235   , 0.20941709, 0.33054778, 0.7226211 , 0.24420117,\n",
       "         0.6630002 , 0.71609527, 0.69560206, 0.681758  , 0.6189638 ,\n",
       "         0.3532322 , 0.7063186 ]], dtype=float32),\n",
       " array([[0.26054034, 0.17072636, 0.21318842, 0.6655976 , 0.21913317,\n",
       "         0.8575704 , 0.07902911, 0.84461755, 0.8338309 , 0.7959457 ,\n",
       "         0.21994188, 0.83802664]], dtype=float32),\n",
       " array([[6.12819158e-02, 1.20310016e-01, 1.17128156e-01, 6.47429526e-01,\n",
       "         1.71386868e-01, 9.48445737e-01, 4.63517936e-04, 9.53524172e-01,\n",
       "         9.26206946e-01, 9.48701322e-01, 1.06593877e-01, 9.35869813e-01]],\n",
       "       dtype=float32),\n",
       " array([[0.22417973, 0.16627681, 0.1704084 , 0.6534197 , 0.21346176,\n",
       "         0.8874806 , 0.06759464, 0.86129546, 0.8601087 , 0.77368075,\n",
       "         0.19205004, 0.8576612 ]], dtype=float32),\n",
       " array([[0.35963622, 0.18156494, 0.23722918, 0.64660037, 0.24380139,\n",
       "         0.8211152 , 0.36774245, 0.7722123 , 0.78807634, 0.66875386,\n",
       "         0.26697907, 0.7870726 ]], dtype=float32),\n",
       " array([[0.15180624, 0.15120378, 0.18878731, 0.7139425 , 0.19672911,\n",
       "         0.87804383, 0.02251357, 0.85611546, 0.856891  , 0.86031395,\n",
       "         0.16146745, 0.84624755]], dtype=float32),\n",
       " array([[0.2546464 , 0.16729106, 0.19862287, 0.7022859 , 0.20856102,\n",
       "         0.85563195, 0.11922985, 0.8071837 , 0.83207864, 0.7690224 ,\n",
       "         0.20485476, 0.8038824 ]], dtype=float32),\n",
       " array([[0.51956356, 0.20852527, 0.2821272 , 0.64348906, 0.26041618,\n",
       "         0.7505578 , 0.79026014, 0.6924968 , 0.72216064, 0.5334205 ,\n",
       "         0.33281124, 0.72475386]], dtype=float32),\n",
       " array([[0.2736413 , 0.18093911, 0.22728226, 0.55213815, 0.2556809 ,\n",
       "         0.8549605 , 0.10433251, 0.8660471 , 0.81495774, 0.7716046 ,\n",
       "         0.23925856, 0.8636897 ]], dtype=float32),\n",
       " array([[0.22751662, 0.17720798, 0.2024751 , 0.63660425, 0.22705998,\n",
       "         0.85181934, 0.0853662 , 0.85580355, 0.82403636, 0.7760985 ,\n",
       "         0.20465483, 0.8553818 ]], dtype=float32),\n",
       " array([[0.45138657, 0.20137422, 0.23940775, 0.64541197, 0.24479884,\n",
       "         0.800846  , 0.64447117, 0.7171051 , 0.76699394, 0.5844633 ,\n",
       "         0.28532198, 0.7419553 ]], dtype=float32),\n",
       " array([[0.37047958, 0.17668173, 0.20234768, 0.6564041 , 0.21529023,\n",
       "         0.84125155, 0.26801655, 0.82402474, 0.81045014, 0.6795506 ,\n",
       "         0.26217285, 0.81330955]], dtype=float32),\n",
       " array([[0.37877283, 0.18511982, 0.2111677 , 0.64390373, 0.22573236,\n",
       "         0.8326595 , 0.33718243, 0.79773605, 0.79922825, 0.6695615 ,\n",
       "         0.26475683, 0.7978168 ]], dtype=float32),\n",
       " array([[0.19180879, 0.16829596, 0.17131956, 0.6519697 , 0.2068351 ,\n",
       "         0.8838013 , 0.04133345, 0.85514605, 0.85311973, 0.8280833 ,\n",
       "         0.17438625, 0.8482597 ]], dtype=float32),\n",
       " array([[0.22890449, 0.18840261, 0.15962501, 0.5928869 , 0.23154534,\n",
       "         0.8871383 , 0.10005331, 0.8431154 , 0.8511048 , 0.7641366 ,\n",
       "         0.18435113, 0.8479852 ]], dtype=float32),\n",
       " array([[0.19747011, 0.17602968, 0.17400338, 0.63623416, 0.21433127,\n",
       "         0.8710303 , 0.05212007, 0.8695017 , 0.8418029 , 0.80442166,\n",
       "         0.18216453, 0.8637573 ]], dtype=float32),\n",
       " array([[0.11209562, 0.16023408, 0.17695549, 0.6056653 , 0.20739345,\n",
       "         0.89179593, 0.00482733, 0.92359376, 0.8630369 , 0.9150909 ,\n",
       "         0.14822146, 0.9057175 ]], dtype=float32),\n",
       " array([[0.18076667, 0.16419592, 0.1606995 , 0.64561933, 0.19902985,\n",
       "         0.88663834, 0.02939785, 0.8811626 , 0.8558435 , 0.83845407,\n",
       "         0.17409666, 0.8655364 ]], dtype=float32),\n",
       " array([[0.17064704, 0.16767292, 0.1902197 , 0.6302001 , 0.20521359,\n",
       "         0.8706401 , 0.01988077, 0.8892795 , 0.8400017 , 0.8727112 ,\n",
       "         0.17918462, 0.870934  ]], dtype=float32),\n",
       " array([[0.32221565, 0.20178553, 0.2216633 , 0.6337149 , 0.22362012,\n",
       "         0.8273579 , 0.21817234, 0.8360585 , 0.81133133, 0.7300254 ,\n",
       "         0.25120428, 0.83192456]], dtype=float32),\n",
       " array([[0.71324426, 0.26279408, 0.27693453, 0.5663989 , 0.30159742,\n",
       "         0.7201798 , 0.9877566 , 0.48599353, 0.6565373 , 0.29876772,\n",
       "         0.38405812, 0.5871451 ]], dtype=float32),\n",
       " array([[0.71873045, 0.25295928, 0.3155931 , 0.61002403, 0.29196218,\n",
       "         0.6503472 , 0.98711115, 0.5098144 , 0.6040411 , 0.29785624,\n",
       "         0.4127858 , 0.59967655]], dtype=float32),\n",
       " array([[0.7756309 , 0.25201648, 0.2718349 , 0.59921426, 0.3153604 ,\n",
       "         0.73771596, 0.9959915 , 0.35765335, 0.6832909 , 0.24247268,\n",
       "         0.43333077, 0.48084816]], dtype=float32),\n",
       " array([[0.77013785, 0.262233  , 0.31214038, 0.67101955, 0.2846589 ,\n",
       "         0.64642316, 0.99392563, 0.42987666, 0.6328488 , 0.25947878,\n",
       "         0.42882392, 0.5271917 ]], dtype=float32),\n",
       " array([[0.7435987 , 0.254109  , 0.30755043, 0.6735816 , 0.27981085,\n",
       "         0.6744135 , 0.9885727 , 0.46176684, 0.66887414, 0.3197446 ,\n",
       "         0.42776075, 0.5477112 ]], dtype=float32),\n",
       " array([[0.7248138 , 0.24899176, 0.34668484, 0.693751  , 0.29164013,\n",
       "         0.63672817, 0.9869191 , 0.42730752, 0.6482208 , 0.37280485,\n",
       "         0.4287162 , 0.5081229 ]], dtype=float32),\n",
       " array([[0.69044983, 0.24260513, 0.40999928, 0.73325086, 0.281896  ,\n",
       "         0.53989875, 0.9770858 , 0.4432046 , 0.5764314 , 0.45791945,\n",
       "         0.4263449 , 0.5028378 ]], dtype=float32),\n",
       " array([[0.67077965, 0.24011236, 0.374949  , 0.7148328 , 0.28071612,\n",
       "         0.60117745, 0.9632597 , 0.47719547, 0.63030666, 0.50070095,\n",
       "         0.41696426, 0.5287311 ]], dtype=float32),\n",
       " array([[0.45928806, 0.20378797, 0.27019086, 0.7052949 , 0.23775029,\n",
       "         0.7526345 , 0.6035718 , 0.6495189 , 0.73741835, 0.6770021 ,\n",
       "         0.290389  , 0.66624385]], dtype=float32),\n",
       " array([[0.5460295 , 0.22528109, 0.334921  , 0.7122144 , 0.2603364 ,\n",
       "         0.6652891 , 0.8409    , 0.58995485, 0.68439156, 0.61564404,\n",
       "         0.3526693 , 0.62083644]], dtype=float32),\n",
       " array([[0.44938353, 0.21033026, 0.28399274, 0.69594944, 0.24900459,\n",
       "         0.74073684, 0.6404646 , 0.65542316, 0.73038125, 0.6591466 ,\n",
       "         0.28779978, 0.68094134]], dtype=float32),\n",
       " array([[0.2726817 , 0.18939699, 0.22044374, 0.68012905, 0.22629449,\n",
       "         0.83159053, 0.168455  , 0.7651191 , 0.80666447, 0.7763648 ,\n",
       "         0.20804031, 0.7789523 ]], dtype=float32),\n",
       " array([[0.13073717, 0.15342613, 0.17259099, 0.69391793, 0.19177817,\n",
       "         0.8862878 , 0.01104014, 0.88240045, 0.8614996 , 0.88462174,\n",
       "         0.14917643, 0.8718001 ]], dtype=float32),\n",
       " array([[0.16950902, 0.16152719, 0.18011637, 0.6898407 , 0.1993955 ,\n",
       "         0.8749155 , 0.02718786, 0.86427826, 0.85049427, 0.8466698 ,\n",
       "         0.16788322, 0.85616904]], dtype=float32),\n",
       " array([[0.2781704 , 0.17439497, 0.22646804, 0.6264686 , 0.23118435,\n",
       "         0.827676  , 0.10465672, 0.85610247, 0.7951672 , 0.77743345,\n",
       "         0.24616551, 0.8484469 ]], dtype=float32),\n",
       " array([[0.14548826, 0.15072086, 0.19116713, 0.65976685, 0.20536596,\n",
       "         0.8835263 , 0.01052202, 0.90550643, 0.8607198 , 0.88640845,\n",
       "         0.17035611, 0.88690555]], dtype=float32),\n",
       " array([[0.59068006, 0.21568455, 0.3021523 , 0.6150404 , 0.28736684,\n",
       "         0.74128973, 0.9022486 , 0.62822324, 0.7054715 , 0.47720227,\n",
       "         0.36819482, 0.67943114]], dtype=float32),\n",
       " array([[0.6220724 , 0.21351367, 0.33380517, 0.67382646, 0.26944667,\n",
       "         0.6820102 , 0.92096215, 0.62794256, 0.671349  , 0.45785955,\n",
       "         0.39518753, 0.6666096 ]], dtype=float32),\n",
       " array([[0.6428743 , 0.21636139, 0.35468027, 0.6857873 , 0.2763491 ,\n",
       "         0.65281445, 0.9484935 , 0.57772964, 0.6486402 , 0.4367574 ,\n",
       "         0.41272986, 0.6311553 ]], dtype=float32),\n",
       " array([[0.65455174, 0.22083281, 0.3799854 , 0.71532243, 0.27204546,\n",
       "         0.6245319 , 0.95346075, 0.550412  , 0.6408074 , 0.45393455,\n",
       "         0.41524917, 0.59861887]], dtype=float32),\n",
       " array([[0.64179707, 0.22428954, 0.39282995, 0.7220704 , 0.27548867,\n",
       "         0.59319806, 0.95276815, 0.53654146, 0.61261433, 0.4662762 ,\n",
       "         0.40186396, 0.586103  ]], dtype=float32),\n",
       " array([[0.50840324, 0.1963871 , 0.31832758, 0.7098265 , 0.24960533,\n",
       "         0.722234  , 0.726233  , 0.6587008 , 0.7227914 , 0.62427586,\n",
       "         0.34845653, 0.676374  ]], dtype=float32),\n",
       " array([[0.54468346, 0.20845695, 0.35178295, 0.7178911 , 0.263922  ,\n",
       "         0.6657502 , 0.8474517 , 0.5997643 , 0.67816925, 0.5870485 ,\n",
       "         0.36522892, 0.63154817]], dtype=float32),\n",
       " array([[0.47606564, 0.20339373, 0.32520568, 0.72476846, 0.24767964,\n",
       "         0.6862939 , 0.7064266 , 0.649827  , 0.69567543, 0.64381295,\n",
       "         0.32826978, 0.6706017 ]], dtype=float32),\n",
       " array([[0.55850196, 0.21693057, 0.32705298, 0.67273515, 0.2799764 ,\n",
       "         0.6903995 , 0.8728749 , 0.5637506 , 0.6767757 , 0.5830209 ,\n",
       "         0.35671794, 0.60901207]], dtype=float32),\n",
       " array([[0.47519764, 0.2091542 , 0.30805162, 0.6918545 , 0.25595248,\n",
       "         0.70406556, 0.7026867 , 0.65762806, 0.6980045 , 0.63987803,\n",
       "         0.32326138, 0.685152  ]], dtype=float32),\n",
       " array([[0.48076925, 0.211396  , 0.27429438, 0.65809375, 0.25859177,\n",
       "         0.7493375 , 0.6940103 , 0.6716922 , 0.7265414 , 0.6236654 ,\n",
       "         0.31486827, 0.702994  ]], dtype=float32),\n",
       " array([[0.4561801 , 0.2138298 , 0.2834609 , 0.67891556, 0.2504912 ,\n",
       "         0.7305599 , 0.6400732 , 0.69273365, 0.721286  , 0.64311004,\n",
       "         0.30628294, 0.71781385]], dtype=float32),\n",
       " array([[0.46049878, 0.2045703 , 0.27784404, 0.66069555, 0.25221965,\n",
       "         0.7537434 , 0.6109745 , 0.73149633, 0.7364368 , 0.62073594,\n",
       "         0.31536224, 0.75172365]], dtype=float32),\n",
       " array([[0.48072505, 0.20547417, 0.27921113, 0.6546725 , 0.25730148,\n",
       "         0.7562585 , 0.6726157 , 0.69039893, 0.7320479 , 0.6205502 ,\n",
       "         0.32062474, 0.71782094]], dtype=float32),\n",
       " array([[0.47277877, 0.20162988, 0.2688909 , 0.663759  , 0.24894148,\n",
       "         0.76129663, 0.6317527 , 0.71717304, 0.7397959 , 0.617913  ,\n",
       "         0.31742358, 0.73626286]], dtype=float32),\n",
       " array([[0.40350696, 0.19171034, 0.25655276, 0.66344965, 0.24068706,\n",
       "         0.7869866 , 0.41692278, 0.75405127, 0.7627362 , 0.68482786,\n",
       "         0.2874921 , 0.763246  ]], dtype=float32),\n",
       " array([[0.34343266, 0.17951581, 0.23558775, 0.6634599 , 0.23576714,\n",
       "         0.82464457, 0.2556909 , 0.7815547 , 0.79902494, 0.73041314,\n",
       "         0.25921023, 0.78364646]], dtype=float32),\n",
       " array([[0.39960548, 0.1978592 , 0.26182827, 0.6619165 , 0.24566585,\n",
       "         0.7805497 , 0.45389345, 0.7362829 , 0.7581745 , 0.68335056,\n",
       "         0.28276476, 0.75266474]], dtype=float32),\n",
       " array([[0.4269974 , 0.19543456, 0.27789786, 0.6693826 , 0.2521337 ,\n",
       "         0.7665018 , 0.5470718 , 0.7065486 , 0.74526757, 0.6661543 ,\n",
       "         0.29883796, 0.72597605]], dtype=float32),\n",
       " array([[0.44925433, 0.19976476, 0.30292758, 0.69142675, 0.25234887,\n",
       "         0.7203629 , 0.63399863, 0.6810017 , 0.71060616, 0.6543041 ,\n",
       "         0.31834844, 0.703565  ]], dtype=float32),\n",
       " array([[0.41345438, 0.18904093, 0.29110432, 0.6942269 , 0.24528825,\n",
       "         0.7469465 , 0.5003195 , 0.72549707, 0.7355451 , 0.67634356,\n",
       "         0.30263838, 0.73611337]], dtype=float32),\n",
       " array([[0.41593462, 0.19156127, 0.28167632, 0.67719436, 0.24980974,\n",
       "         0.7660488 , 0.5045289 , 0.725692  , 0.7493676 , 0.6719999 ,\n",
       "         0.29656214, 0.73857445]], dtype=float32),\n",
       " array([[0.36338016, 0.18809955, 0.25201988, 0.66692126, 0.24223708,\n",
       "         0.7982828 , 0.34081933, 0.7725639 , 0.77935046, 0.7026597 ,\n",
       "         0.27044627, 0.7789816 ]], dtype=float32),\n",
       " array([[0.43892962, 0.19730195, 0.26997826, 0.65190196, 0.26161614,\n",
       "         0.7785988 , 0.6097938 , 0.6992061 , 0.75246423, 0.63659036,\n",
       "         0.2985979 , 0.7243867 ]], dtype=float32),\n",
       " array([[0.39333418, 0.1945449 , 0.24504252, 0.64178747, 0.2499063 ,\n",
       "         0.8049767 , 0.43527317, 0.74789566, 0.7760554 , 0.6762304 ,\n",
       "         0.2754405 , 0.76296777]], dtype=float32),\n",
       " array([[0.34836453, 0.18912823, 0.22431467, 0.6602101 , 0.23277444,\n",
       "         0.82003343, 0.28532216, 0.79316396, 0.79923266, 0.70901275,\n",
       "         0.25817436, 0.7957827 ]], dtype=float32),\n",
       " array([[0.33301613, 0.18973762, 0.21046293, 0.6361291 , 0.23698507,\n",
       "         0.8422633 , 0.24316579, 0.81133616, 0.81769127, 0.71347666,\n",
       "         0.245073  , 0.8127387 ]], dtype=float32),\n",
       " array([[0.34274864, 0.19516298, 0.21541482, 0.6304161 , 0.23750414,\n",
       "         0.8331357 , 0.27272803, 0.803479  , 0.80769306, 0.710051  ,\n",
       "         0.25366217, 0.8090383 ]], dtype=float32),\n",
       " array([[0.4437046 , 0.20823438, 0.25196242, 0.63484496, 0.25407028,\n",
       "         0.78602934, 0.61247444, 0.7162111 , 0.7565901 , 0.6234684 ,\n",
       "         0.2928735 , 0.7423644 ]], dtype=float32),\n",
       " array([[0.395224  , 0.19828032, 0.2600428 , 0.67056423, 0.2377794 ,\n",
       "         0.7715009 , 0.45523125, 0.7414778 , 0.74929106, 0.6754463 ,\n",
       "         0.27709162, 0.75496405]], dtype=float32),\n",
       " array([[0.515193  , 0.21141088, 0.29261458, 0.6677884 , 0.2550094 ,\n",
       "         0.73962134, 0.77953726, 0.6351604 , 0.71943843, 0.5992585 ,\n",
       "         0.33108068, 0.66987437]], dtype=float32),\n",
       " array([[0.48077846, 0.20714732, 0.2994257 , 0.69527036, 0.24362084,\n",
       "         0.72555333, 0.6859503 , 0.6868515 , 0.72207564, 0.6246536 ,\n",
       "         0.32202858, 0.7053627 ]], dtype=float32),\n",
       " array([[0.46187136, 0.20715027, 0.27536318, 0.6695737 , 0.24960779,\n",
       "         0.7605095 , 0.64139515, 0.7029649 , 0.74732673, 0.6307012 ,\n",
       "         0.3090455 , 0.723925  ]], dtype=float32),\n",
       " array([[0.4505335 , 0.2042064 , 0.26262885, 0.66994774, 0.24742532,\n",
       "         0.76794434, 0.61670005, 0.7126408 , 0.7523996 , 0.6299363 ,\n",
       "         0.30380473, 0.7322778 ]], dtype=float32),\n",
       " array([[0.40360042, 0.19705226, 0.24874705, 0.67060214, 0.24164857,\n",
       "         0.7866981 , 0.47667053, 0.7351354 , 0.76635116, 0.66976744,\n",
       "         0.2789943 , 0.7485182 ]], dtype=float32),\n",
       " array([[0.30929655, 0.17912975, 0.21175611, 0.6624807 , 0.22828515,\n",
       "         0.842911  , 0.19043598, 0.8036276 , 0.8182072 , 0.74478465,\n",
       "         0.23582345, 0.8010637 ]], dtype=float32),\n",
       " array([[0.31178844, 0.18077786, 0.21962044, 0.6818817 , 0.2251026 ,\n",
       "         0.82675236, 0.21690437, 0.7821173 , 0.80173296, 0.74022645,\n",
       "         0.23028196, 0.78207874]], dtype=float32),\n",
       " array([[0.30104718, 0.18362218, 0.21234411, 0.666422  , 0.22699045,\n",
       "         0.8335776 , 0.19651823, 0.7931776 , 0.80587196, 0.74381006,\n",
       "         0.22437702, 0.7946764 ]], dtype=float32),\n",
       " array([[0.27038783, 0.17958851, 0.19904828, 0.65961677, 0.2228379 ,\n",
       "         0.8524453 , 0.13545328, 0.8067202 , 0.8225046 , 0.7704631 ,\n",
       "         0.20879105, 0.80600166]], dtype=float32),\n",
       " array([[0.3920742 , 0.20071821, 0.2500147 , 0.6495011 , 0.24996522,\n",
       "         0.79147923, 0.4875838 , 0.7244265 , 0.76176417, 0.6667808 ,\n",
       "         0.26524928, 0.74568564]], dtype=float32),\n",
       " array([[0.42524728, 0.20122664, 0.2846807 , 0.6797821 , 0.24473433,\n",
       "         0.7414298 , 0.56861514, 0.7111855 , 0.72299904, 0.65015095,\n",
       "         0.29026392, 0.7295559 ]], dtype=float32),\n",
       " array([[0.4407185 , 0.20226607, 0.29114148, 0.6663193 , 0.25046736,\n",
       "         0.73755544, 0.59767985, 0.70615345, 0.7117021 , 0.6407452 ,\n",
       "         0.2941493 , 0.7257485 ]], dtype=float32),\n",
       " array([[0.37490842, 0.19532497, 0.2490176 , 0.65932095, 0.23544353,\n",
       "         0.7910092 , 0.350718  , 0.7788506 , 0.7687391 , 0.6967511 ,\n",
       "         0.26747927, 0.78241014]], dtype=float32),\n",
       " array([[0.44840193, 0.20780905, 0.26116833, 0.6396934 , 0.25245202,\n",
       "         0.7737045 , 0.59097284, 0.734709  , 0.7475272 , 0.62616634,\n",
       "         0.2950113 , 0.7517466 ]], dtype=float32),\n",
       " array([[0.42572138, 0.20213062, 0.26070708, 0.6705527 , 0.23758116,\n",
       "         0.76851904, 0.51165897, 0.7385741 , 0.748464  , 0.65760523,\n",
       "         0.28637463, 0.7491091 ]], dtype=float32),\n",
       " array([[0.4040152 , 0.19791612, 0.24735382, 0.6501509 , 0.2457105 ,\n",
       "         0.79983836, 0.4651094 , 0.74083614, 0.7737976 , 0.67220837,\n",
       "         0.27575922, 0.7538312 ]], dtype=float32),\n",
       " array([[0.43901747, 0.20255066, 0.26651505, 0.673508  , 0.24417935,\n",
       "         0.7655564 , 0.5845941 , 0.715757  , 0.7500526 , 0.64382744,\n",
       "         0.2994733 , 0.7331288 ]], dtype=float32),\n",
       " array([[0.3927617 , 0.19737023, 0.23372185, 0.6464816 , 0.24252899,\n",
       "         0.8049183 , 0.4423716 , 0.7408483 , 0.7727199 , 0.6753765 ,\n",
       "         0.2667252 , 0.75507915]], dtype=float32),\n",
       " array([[0.4471367 , 0.20368773, 0.26653713, 0.65842396, 0.25294083,\n",
       "         0.7691282 , 0.62811077, 0.7082689 , 0.7485562 , 0.626382  ,\n",
       "         0.30277345, 0.73128855]], dtype=float32),\n",
       " array([[0.38101226, 0.19573182, 0.248617  , 0.67212576, 0.23994723,\n",
       "         0.79483587, 0.4267093 , 0.7490797 , 0.7788097 , 0.6828555 ,\n",
       "         0.27237567, 0.7607897 ]], dtype=float32),\n",
       " array([[0.29073772, 0.18179666, 0.21498914, 0.66185564, 0.23228826,\n",
       "         0.8362337 , 0.18735212, 0.7984657 , 0.8107423 , 0.74777776,\n",
       "         0.22455342, 0.799742  ]], dtype=float32),\n",
       " array([[0.11375643, 0.14685431, 0.14115849, 0.63887113, 0.20586875,\n",
       "         0.92248225, 0.00601786, 0.9107265 , 0.9003996 , 0.90261394,\n",
       "         0.14102903, 0.89240444]], dtype=float32),\n",
       " array([[0.17744417, 0.16238792, 0.16738914, 0.66211706, 0.21161957,\n",
       "         0.8898701 , 0.0306851 , 0.87312984, 0.8689577 , 0.842994  ,\n",
       "         0.1753701 , 0.85965765]], dtype=float32),\n",
       " array([[0.45137793, 0.20388883, 0.25927386, 0.64862525, 0.25469565,\n",
       "         0.78045666, 0.6526571 , 0.70350206, 0.75508857, 0.61236143,\n",
       "         0.29955584, 0.72865105]], dtype=float32),\n",
       " array([[0.5269852 , 0.21860583, 0.29309505, 0.6691586 , 0.25278497,\n",
       "         0.72174186, 0.8171437 , 0.6442898 , 0.70405513, 0.5623805 ,\n",
       "         0.3342287 , 0.6819889 ]], dtype=float32),\n",
       " array([[0.50502664, 0.21443173, 0.2923053 , 0.6719679 , 0.2518709 ,\n",
       "         0.7284088 , 0.76473176, 0.6742262 , 0.71514285, 0.58162296,\n",
       "         0.3274196 , 0.7036497 ]], dtype=float32),\n",
       " array([[0.6223056 , 0.2270493 , 0.32485402, 0.6640437 , 0.27516863,\n",
       "         0.69364846, 0.93902314, 0.5278864 , 0.67368656, 0.49430272,\n",
       "         0.37815392, 0.5902142 ]], dtype=float32),\n",
       " array([[0.62894964, 0.2305756 , 0.31962997, 0.67325294, 0.26810926,\n",
       "         0.68142545, 0.9401707 , 0.5574042 , 0.670424  , 0.4742795 ,\n",
       "         0.38617992, 0.6158566 ]], dtype=float32),\n",
       " array([[0.6002839 , 0.22379915, 0.31888497, 0.6783193 , 0.2681332 ,\n",
       "         0.6885359 , 0.9140267 , 0.58481336, 0.6809417 , 0.5055845 ,\n",
       "         0.37616044, 0.63427705]], dtype=float32),\n",
       " array([[0.5401762 , 0.21210472, 0.30869538, 0.6868531 , 0.26196843,\n",
       "         0.69453496, 0.8416262 , 0.6196241 , 0.68535334, 0.5645665 ,\n",
       "         0.3570881 , 0.6592248 ]], dtype=float32),\n",
       " array([[0.5369393 , 0.2111865 , 0.3058756 , 0.68575794, 0.26213783,\n",
       "         0.7156979 , 0.8159339 , 0.6393637 , 0.7092023 , 0.57358044,\n",
       "         0.34607434, 0.6696611 ]], dtype=float32),\n",
       " array([[0.4822193 , 0.20582955, 0.28489757, 0.6782802 , 0.2572148 ,\n",
       "         0.7468804 , 0.6982824 , 0.68695587, 0.7368892 , 0.6120017 ,\n",
       "         0.31902233, 0.7092192 ]], dtype=float32),\n",
       " array([[0.34762728, 0.1881286 , 0.25115296, 0.7019827 , 0.23126842,\n",
       "         0.789178  , 0.30885717, 0.75475633, 0.7787625 , 0.7297333 ,\n",
       "         0.25824934, 0.7587062 ]], dtype=float32),\n",
       " array([[0.30530524, 0.18863016, 0.21805955, 0.67800784, 0.23017858,\n",
       "         0.8297566 , 0.21798548, 0.77401996, 0.810049  , 0.75060564,\n",
       "         0.22685346, 0.77934104]], dtype=float32),\n",
       " array([[0.30230132, 0.18694867, 0.21444333, 0.6803587 , 0.2256248 ,\n",
       "         0.8325464 , 0.19936857, 0.7852978 , 0.8131881 , 0.7527297 ,\n",
       "         0.22545983, 0.7869388 ]], dtype=float32),\n",
       " array([[0.46163705, 0.21009848, 0.28810367, 0.6608828 , 0.25992456,\n",
       "         0.749868  , 0.66149676, 0.6875461 , 0.73329103, 0.63278824,\n",
       "         0.30547655, 0.7138288 ]], dtype=float32),\n",
       " array([[0.41537443, 0.20125921, 0.28061727, 0.68385345, 0.2415383 ,\n",
       "         0.75004405, 0.50117016, 0.72659904, 0.7384278 , 0.67803884,\n",
       "         0.2914799 , 0.7395564 ]], dtype=float32),\n",
       " array([[0.34791654, 0.1933049 , 0.24256068, 0.65652686, 0.2402056 ,\n",
       "         0.80625165, 0.30213565, 0.77140975, 0.7833633 , 0.72208226,\n",
       "         0.2554778 , 0.7789682 ]], dtype=float32),\n",
       " array([[0.28735664, 0.1805501 , 0.21842676, 0.6521069 , 0.228664  ,\n",
       "         0.83689344, 0.13319507, 0.83133614, 0.81468606, 0.77261716,\n",
       "         0.23444398, 0.824373  ]], dtype=float32),\n",
       " array([[0.43271866, 0.20303124, 0.2779002 , 0.652972  , 0.25139546,\n",
       "         0.75625825, 0.54379183, 0.7448073 , 0.7367051 , 0.64565575,\n",
       "         0.29984775, 0.75816697]], dtype=float32),\n",
       " array([[0.54465324, 0.21602628, 0.30274782, 0.6568709 , 0.2611352 ,\n",
       "         0.7303847 , 0.81433386, 0.6581868 , 0.71527284, 0.56691647,\n",
       "         0.3518064 , 0.6904774 ]], dtype=float32),\n",
       " array([[0.46707177, 0.20369968, 0.2756539 , 0.65672255, 0.25207683,\n",
       "         0.7623947 , 0.6373095 , 0.71606374, 0.7443912 , 0.6260469 ,\n",
       "         0.31966412, 0.7348508 ]], dtype=float32),\n",
       " array([[0.26795506, 0.17577113, 0.18729454, 0.6439676 , 0.22442602,\n",
       "         0.8697014 , 0.10422027, 0.84352815, 0.8471921 , 0.7814252 ,\n",
       "         0.22259068, 0.8342699 ]], dtype=float32),\n",
       " array([[0.21460576, 0.1677258 , 0.18073544, 0.6667702 , 0.21351348,\n",
       "         0.87263817, 0.05212073, 0.86659783, 0.8528983 , 0.81430787,\n",
       "         0.1956262 , 0.85309774]], dtype=float32),\n",
       " array([[0.12355773, 0.15200916, 0.16479683, 0.65982676, 0.2045782 ,\n",
       "         0.9008441 , 0.00797966, 0.90354234, 0.87985337, 0.89779234,\n",
       "         0.14883101, 0.8853316 ]], dtype=float32),\n",
       " array([[0.09065364, 0.14749141, 0.16667335, 0.62927014, 0.20889941,\n",
       "         0.9012294 , 0.00286565, 0.92504585, 0.87625945, 0.9289349 ,\n",
       "         0.1359601 , 0.9059058 ]], dtype=float32),\n",
       " array([[0.19018792, 0.16562688, 0.17733349, 0.66001683, 0.21094848,\n",
       "         0.8784685 , 0.04042349, 0.85956085, 0.8532775 , 0.83513635,\n",
       "         0.181513  , 0.8476685 ]], dtype=float32),\n",
       " array([[0.43790463, 0.20018564, 0.2390754 , 0.6588317 , 0.24030909,\n",
       "         0.8021642 , 0.60358   , 0.7096075 , 0.7779717 , 0.6279059 ,\n",
       "         0.2926551 , 0.7307467 ]], dtype=float32),\n",
       " array([[0.3809933 , 0.19752374, 0.23638189, 0.65498483, 0.23359412,\n",
       "         0.80622274, 0.39698145, 0.76064676, 0.78229374, 0.68928635,\n",
       "         0.2691996 , 0.7689976 ]], dtype=float32),\n",
       " array([[0.38584998, 0.20019864, 0.2531507 , 0.6531561 , 0.238513  ,\n",
       "         0.78108704, 0.4268593 , 0.7546723 , 0.7530811 , 0.67981416,\n",
       "         0.26878986, 0.76539016]], dtype=float32),\n",
       " array([[0.66354346, 0.24249174, 0.3203088 , 0.6302559 , 0.2848793 ,\n",
       "         0.6816554 , 0.9635753 , 0.5565738 , 0.65398204, 0.407155  ,\n",
       "         0.38983753, 0.6237147 ]], dtype=float32),\n",
       " array([[0.643759  , 0.23740605, 0.31025442, 0.65274715, 0.26966107,\n",
       "         0.6808056 , 0.94686824, 0.60132486, 0.66594744, 0.42914715,\n",
       "         0.38871646, 0.6541546 ]], dtype=float32),\n",
       " array([[0.58349967, 0.22915244, 0.28171927, 0.63199544, 0.2636974 ,\n",
       "         0.73365635, 0.87552536, 0.6527702 , 0.7095946 , 0.51164824,\n",
       "         0.3585273 , 0.69060534]], dtype=float32),\n",
       " array([[0.51849234, 0.21894002, 0.26747236, 0.6667098 , 0.24220812,\n",
       "         0.74113905, 0.75736874, 0.6849572 , 0.7200995 , 0.5744363 ,\n",
       "         0.31851754, 0.7085268 ]], dtype=float32),\n",
       " array([[0.5049164 , 0.21572721, 0.25039107, 0.6503274 , 0.25106308,\n",
       "         0.77303153, 0.74320406, 0.68903816, 0.7471845 , 0.5740653 ,\n",
       "         0.30748957, 0.7136577 ]], dtype=float32),\n",
       " array([[0.5219202 , 0.21795413, 0.27235585, 0.6664107 , 0.25125006,\n",
       "         0.7365394 , 0.79599863, 0.6720906 , 0.7176476 , 0.553469  ,\n",
       "         0.32453072, 0.70230705]], dtype=float32),\n",
       " array([[0.6014316 , 0.22955383, 0.3344257 , 0.6825496 , 0.26917028,\n",
       "         0.6663276 , 0.92683023, 0.5357324 , 0.65463257, 0.51332873,\n",
       "         0.36526453, 0.59456784]], dtype=float32),\n",
       " array([[0.64728904, 0.23911662, 0.40251908, 0.720336  , 0.27430272,\n",
       "         0.56671417, 0.96108   , 0.45620847, 0.5882195 , 0.51738656,\n",
       "         0.4006256 , 0.51434577]], dtype=float32),\n",
       " array([[0.62995166, 0.23362894, 0.3915987 , 0.724318  , 0.2676075 ,\n",
       "         0.5833325 , 0.9452545 , 0.5005688 , 0.60632724, 0.52536047,\n",
       "         0.39303458, 0.5515259 ]], dtype=float32),\n",
       " array([[0.5721322 , 0.22417498, 0.32543442, 0.6974389 , 0.2567173 ,\n",
       "         0.6823224 , 0.86660856, 0.6129491 , 0.6889674 , 0.55615383,\n",
       "         0.366907  , 0.65203094]], dtype=float32),\n",
       " array([[0.57442695, 0.22188483, 0.33728597, 0.68933296, 0.27078095,\n",
       "         0.6786132 , 0.8865499 , 0.5739142 , 0.67655486, 0.5562152 ,\n",
       "         0.36125848, 0.6204013 ]], dtype=float32),\n",
       " array([[0.51378953, 0.20959343, 0.31222764, 0.6859587 , 0.26239532,\n",
       "         0.7026195 , 0.78724295, 0.6416082 , 0.68952775, 0.58302295,\n",
       "         0.3308089 , 0.6757312 ]], dtype=float32),\n",
       " array([[0.4625926 , 0.20052387, 0.26839456, 0.6691751 , 0.2527664 ,\n",
       "         0.77135694, 0.6289003 , 0.7123235 , 0.7581954 , 0.62591004,\n",
       "         0.31930253, 0.73362786]], dtype=float32),\n",
       " array([[0.248159  , 0.1699157 , 0.18063599, 0.656772  , 0.22194156,\n",
       "         0.8801678 , 0.08316444, 0.8398269 , 0.85790044, 0.7945625 ,\n",
       "         0.21025349, 0.8324109 ]], dtype=float32),\n",
       " array([[0.16687639, 0.1579916 , 0.16292466, 0.68519026, 0.19979602,\n",
       "         0.88988096, 0.02171815, 0.87901103, 0.86783636, 0.8532778 ,\n",
       "         0.16370653, 0.86371577]], dtype=float32),\n",
       " array([[0.14467631, 0.15423715, 0.16117515, 0.66860753, 0.20428322,\n",
       "         0.90090245, 0.01500415, 0.87728894, 0.87661403, 0.8765239 ,\n",
       "         0.15537618, 0.8637437 ]], dtype=float32),\n",
       " array([[0.14171869, 0.15552202, 0.17206669, 0.674354  , 0.20538543,\n",
       "         0.8910043 , 0.01607444, 0.86900145, 0.8658636 , 0.87770826,\n",
       "         0.15453786, 0.85744876]], dtype=float32),\n",
       " array([[0.22381021, 0.17000172, 0.2103933 , 0.6881998 , 0.21441326,\n",
       "         0.8446963 , 0.07730787, 0.8236414 , 0.8228164 , 0.81016517,\n",
       "         0.20078146, 0.8191996 ]], dtype=float32),\n",
       " array([[0.29968494, 0.17785391, 0.22705881, 0.67374384, 0.22815447,\n",
       "         0.83172995, 0.19411242, 0.791641  , 0.8131033 , 0.7576546 ,\n",
       "         0.24634853, 0.7927461 ]], dtype=float32),\n",
       " array([[0.29256374, 0.17665495, 0.24000812, 0.6581077 , 0.23447512,\n",
       "         0.825412  , 0.16330467, 0.818117  , 0.8096926 , 0.76978683,\n",
       "         0.25756836, 0.81407666]], dtype=float32),\n",
       " array([[0.28376234, 0.17639937, 0.23129378, 0.65081716, 0.22925833,\n",
       "         0.8280889 , 0.13360642, 0.82785326, 0.8055847 , 0.78136545,\n",
       "         0.24709994, 0.82035464]], dtype=float32),\n",
       " array([[0.3425465 , 0.18763342, 0.23773201, 0.641165  , 0.23536037,\n",
       "         0.8100508 , 0.2569853 , 0.7994803 , 0.78142846, 0.7297565 ,\n",
       "         0.26303017, 0.79791886]], dtype=float32),\n",
       " array([[0.28219908, 0.17231254, 0.21143793, 0.64208895, 0.22411557,\n",
       "         0.8456465 , 0.11565662, 0.8341066 , 0.81666243, 0.7880543 ,\n",
       "         0.24024034, 0.8210966 ]], dtype=float32),\n",
       " array([[0.25221762, 0.17184007, 0.20551892, 0.65039766, 0.21744025,\n",
       "         0.8504145 , 0.08132296, 0.8430811 , 0.82274824, 0.80917084,\n",
       "         0.22144818, 0.82904655]], dtype=float32),\n",
       " array([[0.541706  , 0.21619801, 0.2784439 , 0.6434689 , 0.2619976 ,\n",
       "         0.74606127, 0.84320736, 0.65189165, 0.7171169 , 0.5269106 ,\n",
       "         0.3356066 , 0.6891152 ]], dtype=float32),\n",
       " array([[0.6142311 , 0.2284143 , 0.30846584, 0.6507233 , 0.27602476,\n",
       "         0.69704753, 0.9406585 , 0.57167214, 0.6718131 , 0.44857603,\n",
       "         0.37029356, 0.6328649 ]], dtype=float32),\n",
       " array([[0.6384629 , 0.22966586, 0.32027534, 0.64534825, 0.28749493,\n",
       "         0.6898497 , 0.95794284, 0.54393077, 0.6646934 , 0.42307067,\n",
       "         0.3848425 , 0.61309475]], dtype=float32),\n",
       " array([[0.6405652 , 0.23199862, 0.32794544, 0.66836804, 0.27828187,\n",
       "         0.6663416 , 0.95690084, 0.5502409 , 0.6529547 , 0.42560917,\n",
       "         0.38752666, 0.6155499 ]], dtype=float32),\n",
       " array([[0.63231647, 0.23028305, 0.3325299 , 0.6829181 , 0.27519372,\n",
       "         0.6659643 , 0.950564  , 0.5638749 , 0.66290027, 0.43627298,\n",
       "         0.3827053 , 0.6227038 ]], dtype=float32),\n",
       " array([[0.65261304, 0.2321941 , 0.34012115, 0.6866447 , 0.27883014,\n",
       "         0.6605039 , 0.96057606, 0.52010894, 0.6580875 , 0.4408978 ,\n",
       "         0.39366215, 0.5848868 ]], dtype=float32),\n",
       " array([[0.5662322 , 0.22200136, 0.29745796, 0.6707589 , 0.2628057 ,\n",
       "         0.7239055 , 0.865004  , 0.6232057 , 0.71275723, 0.536805  ,\n",
       "         0.35059464, 0.66419816]], dtype=float32),\n",
       " array([[0.53315794, 0.21880625, 0.26526996, 0.6620037 , 0.25807205,\n",
       "         0.75015527, 0.8159648 , 0.64328206, 0.72877663, 0.55689573,\n",
       "         0.32711852, 0.6807354 ]], dtype=float32),\n",
       " array([[0.27579695, 0.17900848, 0.17739266, 0.66024345, 0.22046396,\n",
       "         0.87362516, 0.13087495, 0.80565506, 0.8468144 , 0.7746818 ,\n",
       "         0.20780778, 0.8023322 ]], dtype=float32),\n",
       " array([[0.2433184 , 0.1789285 , 0.18449906, 0.6832851 , 0.21507584,\n",
       "         0.8619773 , 0.098557  , 0.82488966, 0.84546566, 0.79035276,\n",
       "         0.20335235, 0.821156  ]], dtype=float32),\n",
       " array([[0.43242553, 0.21067685, 0.2625413 , 0.68575114, 0.2438778 ,\n",
       "         0.7588752 , 0.61499304, 0.6998667 , 0.74791616, 0.6335232 ,\n",
       "         0.28449184, 0.7248206 ]], dtype=float32),\n",
       " array([[0.61037844, 0.23232508, 0.3614062 , 0.67533755, 0.28422156,\n",
       "         0.63302755, 0.93478113, 0.5246556 , 0.62051684, 0.51410085,\n",
       "         0.367363  , 0.58294946]], dtype=float32),\n",
       " array([[0.59386253, 0.22393326, 0.3622718 , 0.70047957, 0.26674214,\n",
       "         0.6347008 , 0.90356266, 0.5713002 , 0.6405345 , 0.54412013,\n",
       "         0.37985182, 0.6159588 ]], dtype=float32),\n",
       " array([[0.6176222 , 0.22544266, 0.39405861, 0.71708846, 0.2753791 ,\n",
       "         0.6033632 , 0.9305417 , 0.5390535 , 0.6267155 , 0.53318244,\n",
       "         0.39801338, 0.58519083]], dtype=float32),\n",
       " array([[0.5863374 , 0.21773413, 0.34753317, 0.6789713 , 0.2778253 ,\n",
       "         0.6862452 , 0.89031863, 0.60029393, 0.68458575, 0.5337986 ,\n",
       "         0.37585086, 0.6458868 ]], dtype=float32),\n",
       " array([[0.57262427, 0.21637905, 0.34374765, 0.7014699 , 0.26969734,\n",
       "         0.67170995, 0.8781696 , 0.60543084, 0.68125904, 0.5476779 ,\n",
       "         0.3715965 , 0.6439202 ]], dtype=float32),\n",
       " array([[0.5331799 , 0.20921755, 0.33822742, 0.7001089 , 0.26178902,\n",
       "         0.680952  , 0.79310036, 0.6488944 , 0.68613005, 0.59479976,\n",
       "         0.3581953 , 0.6760155 ]], dtype=float32),\n",
       " array([[0.5304289 , 0.20513125, 0.35036474, 0.7188741 , 0.25445706,\n",
       "         0.66418815, 0.75982463, 0.6324717 , 0.67425317, 0.6370698 ,\n",
       "         0.35963842, 0.6502847 ]], dtype=float32),\n",
       " array([[0.5585764 , 0.21485606, 0.4073345 , 0.74228925, 0.26493603,\n",
       "         0.57486844, 0.8497463 , 0.56571084, 0.61339736, 0.64520985,\n",
       "         0.3892912 , 0.5890235 ]], dtype=float32),\n",
       " array([[0.54032844, 0.21466912, 0.43159193, 0.75523347, 0.26246634,\n",
       "         0.5567757 , 0.8146385 , 0.5873072 , 0.61076194, 0.67157847,\n",
       "         0.38264227, 0.600966  ]], dtype=float32),\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "togive100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
