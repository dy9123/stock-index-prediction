{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "df=pd.read_csv('C:/Users/yy2895/Desktop/RawData.csv')\n",
    "d = df.values\n",
    "ntotal=len(df)\n",
    "\n",
    "\n",
    "d = normalize(d, axis=0, norm='l2')\n",
    "\n",
    "\n",
    "resultu = []\n",
    "np.random.rand(4)\n",
    "# Return 100 results (for instance)\n",
    "for i in range(ntotal):\n",
    "    \n",
    "    res = random.random()\n",
    "    if res < 0.1:\n",
    "        resultu.append(1)\n",
    "    elif res < 0.2 and res>=0.1:\n",
    "        resultu.append(2)\n",
    "    elif res < 0.3 and res>=0.2:\n",
    "        resultu.append(3)\n",
    "    elif res < 0.4 and res>=0.3:\n",
    "        resultu.append(4)\n",
    "    elif res < 0.5 and res>=0.4:\n",
    "        resultu.append(5)\n",
    "    elif res < 0.6 and res>=0.5:\n",
    "        resultu.append(6)\n",
    "    elif res < 0.7 and res>=0.6:\n",
    "        resultu.append(7)\n",
    "    elif res < 0.8 and res>=0.7:\n",
    "        resultu.append(8)\n",
    "    else:\n",
    "        resultu.append(9)\n",
    "resultu=np.array(resultu)\n",
    "trainset=[]\n",
    "for i in range(1,8):\n",
    "    toinsert=d[resultu==i].astype(np.float32)\n",
    "    trainset.append(toinsert)\n",
    "validationset=d[resultu==8].astype(np.float32)\n",
    "testset=d[resultu==9].astype(np.float32)\n",
    "\n",
    "\n",
    "#x = data\n",
    "\n",
    "# Following Hinton-Salakhutdinov Architecture\n",
    "\n",
    "# 3 hidden layers for encoder\n",
    "n_encoder_h_1 = 14\n",
    "n_encoder_h_2 = 9\n",
    "\n",
    "\n",
    "\n",
    "#n_encoder_h_5 = 10\n",
    "\n",
    "\n",
    "# 3 hidden layers for decoder\n",
    "#n_decoder_h_1 = 10\n",
    "n_decoder_h_1 = 14\n",
    "n_decoder_h_2 = 19\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.005\n",
    "\n",
    "#batch_size = 7\n",
    "display_step = 1\n",
    "\n",
    "total_batch=7\n",
    "training_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we begin\n",
      "Epoch: 0001 cost = 2.260183539\n",
      "Validation Loss: 2.8845406\n",
      "Epoch: 0002 cost = 2.241298267\n",
      "Validation Loss: 2.6508455\n",
      "Epoch: 0003 cost = 2.223184041\n",
      "Validation Loss: 2.339541\n",
      "Epoch: 0004 cost = 2.205044133\n",
      "Validation Loss: 2.171406\n",
      "Epoch: 0005 cost = 2.185960906\n",
      "Validation Loss: 2.1097667\n",
      "Epoch: 0006 cost = 2.164894955\n",
      "Validation Loss: 2.0566497\n",
      "Epoch: 0007 cost = 2.141316244\n",
      "Validation Loss: 2.0342026\n",
      "Epoch: 0008 cost = 2.116648742\n",
      "Validation Loss: 2.0022588\n",
      "Epoch: 0009 cost = 2.093047244\n",
      "Validation Loss: 1.980436\n",
      "Epoch: 0010 cost = 2.071268184\n",
      "Validation Loss: 1.9766514\n",
      "Epoch: 0011 cost = 2.051053081\n",
      "Validation Loss: 1.9592553\n",
      "Epoch: 0012 cost = 2.032597780\n",
      "Validation Loss: 1.9445931\n",
      "Epoch: 0013 cost = 2.016433784\n",
      "Validation Loss: 1.922557\n",
      "Epoch: 0014 cost = 2.002447162\n",
      "Validation Loss: 1.9207329\n",
      "Epoch: 0015 cost = 1.990024362\n",
      "Validation Loss: 1.9288937\n",
      "Epoch: 0016 cost = 1.978590659\n",
      "Validation Loss: 1.9388604\n",
      "Epoch: 0017 cost = 1.967752576\n",
      "Validation Loss: 1.9466479\n",
      "Epoch: 0018 cost = 1.957258889\n",
      "Validation Loss: 1.9319904\n",
      "Epoch: 0019 cost = 1.946953893\n",
      "Validation Loss: 1.9055321\n",
      "Epoch: 0020 cost = 1.936738610\n",
      "Validation Loss: 1.8417497\n",
      "Epoch: 0021 cost = 1.926548396\n",
      "Validation Loss: 1.8618908\n",
      "Epoch: 0022 cost = 1.916338393\n",
      "Validation Loss: 1.8736371\n",
      "Epoch: 0023 cost = 1.906072225\n",
      "Validation Loss: 1.8589638\n",
      "Epoch: 0024 cost = 1.895713908\n",
      "Validation Loss: 1.8681653\n",
      "Epoch: 0025 cost = 1.885221822\n",
      "Validation Loss: 1.8550073\n",
      "Epoch: 0026 cost = 1.874553885\n",
      "Validation Loss: 1.8514923\n",
      "Epoch: 0027 cost = 1.863676429\n",
      "Validation Loss: 1.8372015\n",
      "Epoch: 0028 cost = 1.852566021\n",
      "Validation Loss: 1.7191894\n",
      "Epoch: 0029 cost = 1.841214180\n",
      "Validation Loss: 1.700367\n",
      "Epoch: 0030 cost = 1.829633951\n",
      "Validation Loss: 1.6658282\n",
      "Epoch: 0031 cost = 1.817861097\n",
      "Validation Loss: 1.6981837\n",
      "Epoch: 0032 cost = 1.805948939\n",
      "Validation Loss: 1.7932936\n",
      "Epoch: 0033 cost = 1.793989471\n",
      "Validation Loss: 1.7887901\n",
      "Epoch: 0034 cost = 1.782157370\n",
      "Validation Loss: 1.8012561\n",
      "Epoch: 0035 cost = 1.770678844\n",
      "Validation Loss: 1.7814844\n",
      "Epoch: 0036 cost = 1.759697539\n",
      "Validation Loss: 1.7560673\n",
      "Epoch: 0037 cost = 1.749192289\n",
      "Validation Loss: 1.7372932\n",
      "Epoch: 0038 cost = 1.739056332\n",
      "Validation Loss: 1.6952877\n",
      "Epoch: 0039 cost = 1.729204263\n",
      "Validation Loss: 1.6333926\n",
      "Epoch: 0040 cost = 1.719592605\n",
      "Validation Loss: 1.3822343\n",
      "Epoch: 0041 cost = 1.710191744\n",
      "Validation Loss: 1.3397639\n",
      "Epoch: 0042 cost = 1.700973511\n",
      "Validation Loss: 1.3293849\n",
      "Epoch: 0043 cost = 1.691910999\n",
      "Validation Loss: 1.3301551\n",
      "Epoch: 0044 cost = 1.682983194\n",
      "Validation Loss: 1.4069518\n",
      "Epoch: 0045 cost = 1.674173747\n",
      "Validation Loss: 1.4114132\n",
      "Epoch: 0046 cost = 1.665470140\n",
      "Validation Loss: 1.456772\n",
      "Epoch: 0047 cost = 1.656862003\n",
      "Validation Loss: 1.4835433\n",
      "Epoch: 0048 cost = 1.648341468\n",
      "Validation Loss: 1.4718599\n",
      "Epoch: 0049 cost = 1.639901842\n",
      "Validation Loss: 1.4972732\n",
      "Epoch: 0050 cost = 1.631537471\n",
      "Validation Loss: 1.4534429\n",
      "Epoch: 0051 cost = 1.623244064\n",
      "Validation Loss: 1.4441817\n",
      "Epoch: 0052 cost = 1.615017993\n",
      "Validation Loss: 1.465172\n",
      "Epoch: 0053 cost = 1.606855375\n",
      "Validation Loss: 1.4172925\n",
      "Epoch: 0054 cost = 1.598753878\n",
      "Validation Loss: 1.3892394\n",
      "Epoch: 0055 cost = 1.590710385\n",
      "Validation Loss: 1.3802685\n",
      "Epoch: 0056 cost = 1.582723413\n",
      "Validation Loss: 1.3740432\n",
      "Epoch: 0057 cost = 1.574790733\n",
      "Validation Loss: 1.3795993\n",
      "Epoch: 0058 cost = 1.566910727\n",
      "Validation Loss: 1.3976393\n",
      "Epoch: 0059 cost = 1.559081810\n",
      "Validation Loss: 1.4066269\n",
      "Epoch: 0060 cost = 1.551302791\n",
      "Validation Loss: 1.4771426\n",
      "Epoch: 0061 cost = 1.543572000\n",
      "Validation Loss: 1.5683005\n",
      "Epoch: 0062 cost = 1.535888893\n",
      "Validation Loss: 1.58195\n",
      "Epoch: 0063 cost = 1.528252227\n",
      "Validation Loss: 1.5174104\n",
      "Epoch: 0064 cost = 1.520661099\n",
      "Validation Loss: 1.4693403\n",
      "Epoch: 0065 cost = 1.513114657\n",
      "Validation Loss: 1.4035648\n",
      "Epoch: 0066 cost = 1.505612305\n",
      "Validation Loss: 1.367594\n",
      "Epoch: 0067 cost = 1.498153090\n",
      "Validation Loss: 1.3195559\n",
      "Epoch: 0068 cost = 1.490736621\n",
      "Validation Loss: 1.0964246\n",
      "Epoch: 0069 cost = 1.483361925\n",
      "Validation Loss: 1.1399916\n",
      "Epoch: 0070 cost = 1.476029328\n",
      "Validation Loss: 1.2583038\n",
      "Epoch: 0071 cost = 1.468737432\n",
      "Validation Loss: 1.3481922\n",
      "Epoch: 0072 cost = 1.461486101\n",
      "Validation Loss: 1.4089333\n",
      "Epoch: 0073 cost = 1.454275063\n",
      "Validation Loss: 1.3988113\n",
      "Epoch: 0074 cost = 1.447103705\n",
      "Validation Loss: 1.3797748\n",
      "Epoch: 0075 cost = 1.439971600\n",
      "Validation Loss: 1.373036\n",
      "Epoch: 0076 cost = 1.432878443\n",
      "Validation Loss: 1.30411\n",
      "Epoch: 0077 cost = 1.425824097\n",
      "Validation Loss: 1.3431301\n",
      "Epoch: 0078 cost = 1.418807898\n",
      "Validation Loss: 1.3764268\n",
      "Epoch: 0079 cost = 1.411829642\n",
      "Validation Loss: 1.4035832\n",
      "Epoch: 0080 cost = 1.404889090\n",
      "Validation Loss: 1.3506775\n",
      "Epoch: 0081 cost = 1.397986242\n",
      "Validation Loss: 1.2895057\n",
      "Epoch: 0082 cost = 1.391120195\n",
      "Validation Loss: 1.2867208\n",
      "Epoch: 0083 cost = 1.384291036\n",
      "Validation Loss: 1.3427912\n",
      "Epoch: 0084 cost = 1.377498712\n",
      "Validation Loss: 1.3598766\n",
      "Epoch: 0085 cost = 1.370742645\n",
      "Validation Loss: 1.3438658\n",
      "Epoch: 0086 cost = 1.364023038\n",
      "Validation Loss: 1.2821349\n",
      "Epoch: 0087 cost = 1.357339161\n",
      "Validation Loss: 1.2121781\n",
      "Epoch: 0088 cost = 1.350690995\n",
      "Validation Loss: 1.1789548\n",
      "Epoch: 0089 cost = 1.344078217\n",
      "Validation Loss: 1.2078716\n",
      "Epoch: 0090 cost = 1.337501032\n",
      "Validation Loss: 1.199783\n",
      "Epoch: 0091 cost = 1.330958520\n",
      "Validation Loss: 1.2226013\n",
      "Epoch: 0092 cost = 1.324451276\n",
      "Validation Loss: 1.1448516\n",
      "Epoch: 0093 cost = 1.317978365\n",
      "Validation Loss: 1.1476318\n",
      "Epoch: 0094 cost = 1.311539991\n",
      "Validation Loss: 1.1452532\n",
      "Epoch: 0095 cost = 1.305136068\n",
      "Validation Loss: 1.1951523\n",
      "Epoch: 0096 cost = 1.298766238\n",
      "Validation Loss: 1.1922305\n",
      "Epoch: 0097 cost = 1.292430060\n",
      "Validation Loss: 1.1989192\n",
      "Epoch: 0098 cost = 1.286127704\n",
      "Validation Loss: 1.1888075\n",
      "Epoch: 0099 cost = 1.279858913\n",
      "Validation Loss: 1.1512029\n",
      "Epoch: 0100 cost = 1.273623347\n",
      "Validation Loss: 1.155955\n",
      "Epoch: 0101 cost = 1.267420905\n",
      "Validation Loss: 1.1962053\n",
      "Epoch: 0102 cost = 1.261251313\n",
      "Validation Loss: 1.1519884\n",
      "Epoch: 0103 cost = 1.255114385\n",
      "Validation Loss: 1.1606641\n",
      "Epoch: 0104 cost = 1.249010342\n",
      "Validation Loss: 1.1880193\n",
      "Epoch: 0105 cost = 1.242938314\n",
      "Validation Loss: 1.2033068\n",
      "Epoch: 0106 cost = 1.236898473\n",
      "Validation Loss: 1.1600915\n",
      "Epoch: 0107 cost = 1.230890819\n",
      "Validation Loss: 1.1391683\n",
      "Epoch: 0108 cost = 1.224914704\n",
      "Validation Loss: 1.1583375\n",
      "Epoch: 0109 cost = 1.218970282\n",
      "Validation Loss: 1.2141966\n",
      "Epoch: 0110 cost = 1.213057160\n",
      "Validation Loss: 1.2183203\n",
      "Epoch: 0111 cost = 1.207175340\n",
      "Validation Loss: 1.1122212\n",
      "Epoch: 0112 cost = 1.201324514\n",
      "Validation Loss: 1.0289307\n",
      "Epoch: 0113 cost = 1.195504427\n",
      "Validation Loss: 0.8904365\n",
      "Epoch: 0114 cost = 1.189715028\n",
      "Validation Loss: 0.86761886\n",
      "Epoch: 0115 cost = 1.183956078\n",
      "Validation Loss: 0.829342\n",
      "Epoch: 0116 cost = 1.178227322\n",
      "Validation Loss: 0.8554148\n",
      "Epoch: 0117 cost = 1.172528556\n",
      "Validation Loss: 0.92081434\n",
      "Epoch: 0118 cost = 1.166859882\n",
      "Validation Loss: 0.9527978\n",
      "Epoch: 0119 cost = 1.161220619\n",
      "Validation Loss: 0.9558057\n",
      "Epoch: 0120 cost = 1.155610953\n",
      "Validation Loss: 0.9446699\n",
      "Epoch: 0121 cost = 1.150030545\n",
      "Validation Loss: 0.9702868\n",
      "Epoch: 0122 cost = 1.144479411\n",
      "Validation Loss: 0.9922488\n",
      "Epoch: 0123 cost = 1.138956836\n",
      "Validation Loss: 1.0097547\n",
      "Epoch: 0124 cost = 1.133463127\n",
      "Validation Loss: 1.004125\n",
      "Epoch: 0125 cost = 1.127998063\n",
      "Validation Loss: 0.99898916\n",
      "Epoch: 0126 cost = 1.122561472\n",
      "Validation Loss: 0.9639035\n",
      "Epoch: 0127 cost = 1.117152572\n",
      "Validation Loss: 0.9375967\n",
      "Epoch: 0128 cost = 1.111772060\n",
      "Validation Loss: 0.9858179\n",
      "Epoch: 0129 cost = 1.106419189\n",
      "Validation Loss: 1.0011604\n",
      "Epoch: 0130 cost = 1.101094076\n",
      "Validation Loss: 0.95979\n",
      "Epoch: 0131 cost = 1.095796193\n",
      "Validation Loss: 0.9125898\n",
      "Epoch: 0132 cost = 1.090525610\n",
      "Validation Loss: 0.86659855\n",
      "Epoch: 0133 cost = 1.085282190\n",
      "Validation Loss: 0.85162073\n",
      "Epoch: 0134 cost = 1.080065506\n",
      "Validation Loss: 0.87347025\n",
      "Epoch: 0135 cost = 1.074875781\n",
      "Validation Loss: 0.9016295\n",
      "Epoch: 0136 cost = 1.069712571\n",
      "Validation Loss: 0.9700284\n",
      "Epoch: 0137 cost = 1.064575689\n",
      "Validation Loss: 0.99507976\n",
      "Epoch: 0138 cost = 1.059465136\n",
      "Validation Loss: 0.9853659\n",
      "Epoch: 0139 cost = 1.054380655\n",
      "Validation Loss: 1.0152198\n",
      "Epoch: 0140 cost = 1.049322179\n",
      "Validation Loss: 1.0191643\n",
      "Epoch: 0141 cost = 1.044289521\n",
      "Validation Loss: 0.99994695\n",
      "Epoch: 0142 cost = 1.039282407\n",
      "Validation Loss: 0.9482187\n",
      "Epoch: 0143 cost = 1.034301060\n",
      "Validation Loss: 0.9618033\n",
      "Epoch: 0144 cost = 1.029344746\n",
      "Validation Loss: 0.9527401\n",
      "Epoch: 0145 cost = 1.024413909\n",
      "Validation Loss: 0.9488219\n",
      "Epoch: 0146 cost = 1.019508192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.978444\n",
      "Epoch: 0147 cost = 1.014627542\n",
      "Validation Loss: 0.9520143\n",
      "Epoch: 0148 cost = 1.009771705\n",
      "Validation Loss: 0.9751883\n",
      "Epoch: 0149 cost = 1.004940552\n",
      "Validation Loss: 0.94802904\n",
      "Epoch: 0150 cost = 1.000134494\n",
      "Validation Loss: 0.9448342\n",
      "Epoch: 0151 cost = 0.995352600\n",
      "Validation Loss: 0.9834886\n",
      "Epoch: 0152 cost = 0.990595332\n",
      "Validation Loss: 0.9905404\n",
      "Epoch: 0153 cost = 0.985862587\n",
      "Validation Loss: 0.9619357\n",
      "Epoch: 0154 cost = 0.981154101\n",
      "Validation Loss: 0.9206453\n",
      "Epoch: 0155 cost = 0.976469823\n",
      "Validation Loss: 0.92438936\n",
      "Epoch: 0156 cost = 0.971809890\n",
      "Validation Loss: 0.9184471\n",
      "Epoch: 0157 cost = 0.967174028\n",
      "Validation Loss: 0.9066758\n",
      "Epoch: 0158 cost = 0.962562263\n",
      "Validation Loss: 0.91955197\n",
      "Epoch: 0159 cost = 0.957974391\n",
      "Validation Loss: 0.8859887\n",
      "Epoch: 0160 cost = 0.953410498\n",
      "Validation Loss: 0.8811079\n",
      "Epoch: 0161 cost = 0.948870608\n",
      "Validation Loss: 0.9038403\n",
      "Epoch: 0162 cost = 0.944354662\n",
      "Validation Loss: 0.89100426\n",
      "Epoch: 0163 cost = 0.939862302\n",
      "Validation Loss: 0.8527732\n",
      "Epoch: 0164 cost = 0.935393793\n",
      "Validation Loss: 0.8192902\n",
      "Epoch: 0165 cost = 0.930949228\n",
      "Validation Loss: 0.69011784\n",
      "Epoch: 0166 cost = 0.926528028\n",
      "Validation Loss: 0.69011563\n",
      "Epoch: 0167 cost = 0.922130985\n",
      "Validation Loss: 0.70544857\n",
      "Epoch: 0168 cost = 0.917757154\n",
      "Validation Loss: 0.7471653\n",
      "Epoch: 0169 cost = 0.913407155\n",
      "Validation Loss: 0.7577998\n",
      "Epoch: 0170 cost = 0.909080727\n",
      "Validation Loss: 0.74484265\n",
      "Epoch: 0171 cost = 0.904777859\n",
      "Validation Loss: 0.7558714\n",
      "Epoch: 0172 cost = 0.900498475\n",
      "Validation Loss: 0.78034914\n",
      "Epoch: 0173 cost = 0.896242661\n",
      "Validation Loss: 0.83249694\n",
      "Epoch: 0174 cost = 0.892010246\n",
      "Validation Loss: 0.82892406\n",
      "Epoch: 0175 cost = 0.887801315\n",
      "Validation Loss: 0.8092454\n",
      "Epoch: 0176 cost = 0.883615579\n",
      "Validation Loss: 0.78997475\n",
      "Epoch: 0177 cost = 0.879453438\n",
      "Validation Loss: 0.79102105\n",
      "Epoch: 0178 cost = 0.875314474\n",
      "Validation Loss: 0.81213367\n",
      "Epoch: 0179 cost = 0.871198637\n",
      "Validation Loss: 0.7519225\n",
      "Epoch: 0180 cost = 0.867106097\n",
      "Validation Loss: 0.7465657\n",
      "Epoch: 0181 cost = 0.863036607\n",
      "Validation Loss: 0.77567834\n",
      "Epoch: 0182 cost = 0.858990286\n",
      "Validation Loss: 0.79774135\n",
      "Epoch: 0183 cost = 0.854966726\n",
      "Validation Loss: 0.8275148\n",
      "Epoch: 0184 cost = 0.850966036\n",
      "Validation Loss: 0.8188707\n",
      "Epoch: 0185 cost = 0.846988320\n",
      "Validation Loss: 0.7990029\n",
      "Epoch: 0186 cost = 0.843033348\n",
      "Validation Loss: 0.7686978\n",
      "Epoch: 0187 cost = 0.839101195\n",
      "Validation Loss: 0.76029485\n",
      "Epoch: 0188 cost = 0.835191267\n",
      "Validation Loss: 0.73867005\n",
      "Epoch: 0189 cost = 0.831303852\n",
      "Validation Loss: 0.7348153\n",
      "Epoch: 0190 cost = 0.827438874\n",
      "Validation Loss: 0.73785204\n",
      "Epoch: 0191 cost = 0.823596188\n",
      "Validation Loss: 0.749688\n",
      "Epoch: 0192 cost = 0.819775820\n",
      "Validation Loss: 0.7422094\n",
      "Epoch: 0193 cost = 0.815977207\n",
      "Validation Loss: 0.7312842\n",
      "Epoch: 0194 cost = 0.812200648\n",
      "Validation Loss: 0.697379\n",
      "Epoch: 0195 cost = 0.808445939\n",
      "Validation Loss: 0.69426847\n",
      "Epoch: 0196 cost = 0.804712926\n",
      "Validation Loss: 0.7006944\n",
      "Epoch: 0197 cost = 0.801001583\n",
      "Validation Loss: 0.687994\n",
      "Epoch: 0198 cost = 0.797311621\n",
      "Validation Loss: 0.59894854\n",
      "Epoch: 0199 cost = 0.793643296\n",
      "Validation Loss: 0.5942145\n",
      "Epoch: 0200 cost = 0.789996105\n",
      "Validation Loss: 0.6368485\n",
      "Epoch: 0201 cost = 0.786370107\n",
      "Validation Loss: 0.68793505\n",
      "Epoch: 0202 cost = 0.782765440\n",
      "Validation Loss: 0.6963644\n",
      "Epoch: 0203 cost = 0.779181685\n",
      "Validation Loss: 0.6964743\n",
      "Epoch: 0204 cost = 0.775619081\n",
      "Validation Loss: 0.7177478\n",
      "Epoch: 0205 cost = 0.772077262\n",
      "Validation Loss: 0.72701335\n",
      "Epoch: 0206 cost = 0.768556365\n",
      "Validation Loss: 0.72588557\n",
      "Epoch: 0207 cost = 0.765056159\n",
      "Validation Loss: 0.72425604\n",
      "Epoch: 0208 cost = 0.761576618\n",
      "Validation Loss: 0.7112683\n",
      "Epoch: 0209 cost = 0.758117608\n",
      "Validation Loss: 0.6936054\n",
      "Epoch: 0210 cost = 0.754679501\n",
      "Validation Loss: 0.70030695\n",
      "Epoch: 0211 cost = 0.751261575\n",
      "Validation Loss: 0.73111117\n",
      "Epoch: 0212 cost = 0.747864314\n",
      "Validation Loss: 0.712811\n",
      "Epoch: 0213 cost = 0.744487371\n",
      "Validation Loss: 0.68874705\n",
      "Epoch: 0214 cost = 0.741130752\n",
      "Validation Loss: 0.6710143\n",
      "Epoch: 0215 cost = 0.737794578\n",
      "Validation Loss: 0.67522025\n",
      "Epoch: 0216 cost = 0.734478601\n",
      "Validation Loss: 0.67805684\n",
      "Epoch: 0217 cost = 0.731182720\n",
      "Validation Loss: 0.6731015\n",
      "Epoch: 0218 cost = 0.727907249\n",
      "Validation Loss: 0.67528814\n",
      "Epoch: 0219 cost = 0.724651899\n",
      "Validation Loss: 0.65983605\n",
      "Epoch: 0220 cost = 0.721416507\n",
      "Validation Loss: 0.63574374\n",
      "Epoch: 0221 cost = 0.718201288\n",
      "Validation Loss: 0.62658185\n",
      "Epoch: 0222 cost = 0.715006105\n",
      "Validation Loss: 0.6252221\n",
      "Epoch: 0223 cost = 0.711830923\n",
      "Validation Loss: 0.6565099\n",
      "Epoch: 0224 cost = 0.708675708\n",
      "Validation Loss: 0.67720056\n",
      "Epoch: 0225 cost = 0.705540325\n",
      "Validation Loss: 0.6837669\n",
      "Epoch: 0226 cost = 0.702424756\n",
      "Validation Loss: 0.6763248\n",
      "Epoch: 0227 cost = 0.699329121\n",
      "Validation Loss: 0.6516671\n",
      "Epoch: 0228 cost = 0.696253181\n",
      "Validation Loss: 0.6518707\n",
      "Epoch: 0229 cost = 0.693197055\n",
      "Validation Loss: 0.6546693\n",
      "Epoch: 0230 cost = 0.690160283\n",
      "Validation Loss: 0.6371709\n",
      "Epoch: 0231 cost = 0.687143300\n",
      "Validation Loss: 0.63178194\n",
      "Epoch: 0232 cost = 0.684145859\n",
      "Validation Loss: 0.6667682\n",
      "Epoch: 0233 cost = 0.681167603\n",
      "Validation Loss: 0.6971487\n",
      "Epoch: 0234 cost = 0.678208956\n",
      "Validation Loss: 0.69488007\n",
      "Epoch: 0235 cost = 0.675269280\n",
      "Validation Loss: 0.6362035\n",
      "Epoch: 0236 cost = 0.672349104\n",
      "Validation Loss: 0.60519207\n",
      "Epoch: 0237 cost = 0.669447984\n",
      "Validation Loss: 0.60657716\n",
      "Epoch: 0238 cost = 0.666565589\n",
      "Validation Loss: 0.6096576\n",
      "Epoch: 0239 cost = 0.663702284\n",
      "Validation Loss: 0.6208276\n",
      "Epoch: 0240 cost = 0.660857720\n",
      "Validation Loss: 0.6148897\n",
      "Epoch: 0241 cost = 0.658031676\n",
      "Validation Loss: 0.6071212\n",
      "Epoch: 0242 cost = 0.655224144\n",
      "Validation Loss: 0.5967117\n",
      "Epoch: 0243 cost = 0.652434877\n",
      "Validation Loss: 0.62021136\n",
      "Epoch: 0244 cost = 0.649663814\n",
      "Validation Loss: 0.6299466\n",
      "Epoch: 0245 cost = 0.646910727\n",
      "Validation Loss: 0.60970366\n",
      "Epoch: 0246 cost = 0.644175342\n",
      "Validation Loss: 0.6173122\n",
      "Epoch: 0247 cost = 0.641457822\n",
      "Validation Loss: 0.61407423\n",
      "Epoch: 0248 cost = 0.638757655\n",
      "Validation Loss: 0.6341956\n",
      "Epoch: 0249 cost = 0.636074620\n",
      "Validation Loss: 0.6769002\n",
      "Epoch: 0250 cost = 0.633408495\n",
      "Validation Loss: 0.66440815\n",
      "Epoch: 0251 cost = 0.630758899\n",
      "Validation Loss: 0.6275524\n",
      "Epoch: 0252 cost = 0.628125761\n",
      "Validation Loss: 0.62410504\n",
      "Epoch: 0253 cost = 0.625508300\n",
      "Validation Loss: 0.64865327\n",
      "Epoch: 0254 cost = 0.622906574\n",
      "Validation Loss: 0.6380346\n",
      "Epoch: 0255 cost = 0.620319869\n",
      "Validation Loss: 0.6177979\n",
      "Epoch: 0256 cost = 0.617747596\n",
      "Validation Loss: 0.57844585\n",
      "Epoch: 0257 cost = 0.615189024\n",
      "Validation Loss: 0.53379196\n",
      "Epoch: 0258 cost = 0.612643489\n",
      "Validation Loss: 0.5623427\n",
      "Epoch: 0259 cost = 0.610109602\n",
      "Validation Loss: 0.5587435\n",
      "Epoch: 0260 cost = 0.607586026\n",
      "Validation Loss: 0.549418\n",
      "Epoch: 0261 cost = 0.605071110\n",
      "Validation Loss: 0.54491043\n",
      "Epoch: 0262 cost = 0.602561823\n",
      "Validation Loss: 0.5535559\n",
      "Epoch: 0263 cost = 0.600054809\n",
      "Validation Loss: 0.5598101\n",
      "Epoch: 0264 cost = 0.597544730\n",
      "Validation Loss: 0.5526084\n",
      "Epoch: 0265 cost = 0.595023598\n",
      "Validation Loss: 0.5722084\n",
      "Epoch: 0266 cost = 0.592479876\n",
      "Validation Loss: 0.58782524\n",
      "Epoch: 0267 cost = 0.589894993\n",
      "Validation Loss: 0.5723763\n",
      "Epoch: 0268 cost = 0.587241931\n",
      "Validation Loss: 0.5456467\n",
      "Epoch: 0269 cost = 0.584488264\n",
      "Validation Loss: 0.5469333\n",
      "Epoch: 0270 cost = 0.581623401\n",
      "Validation Loss: 0.5512335\n",
      "Epoch: 0271 cost = 0.578707142\n",
      "Validation Loss: 0.55306715\n",
      "Epoch: 0272 cost = 0.575848000\n",
      "Validation Loss: 0.56417793\n",
      "Epoch: 0273 cost = 0.573113731\n",
      "Validation Loss: 0.54495114\n",
      "Epoch: 0274 cost = 0.570501293\n",
      "Validation Loss: 0.5247876\n",
      "Epoch: 0275 cost = 0.567971289\n",
      "Validation Loss: 0.534032\n",
      "Epoch: 0276 cost = 0.565497935\n",
      "Validation Loss: 0.55194634\n",
      "Epoch: 0277 cost = 0.563069182\n",
      "Validation Loss: 0.5208741\n",
      "Epoch: 0278 cost = 0.560675774\n",
      "Validation Loss: 0.50456274\n",
      "Epoch: 0279 cost = 0.558311735\n",
      "Validation Loss: 0.51723874\n",
      "Epoch: 0280 cost = 0.555972959\n",
      "Validation Loss: 0.5254837\n",
      "Epoch: 0281 cost = 0.553657464\n",
      "Validation Loss: 0.58022344\n",
      "Epoch: 0282 cost = 0.551363690\n",
      "Validation Loss: 0.56477183\n",
      "Epoch: 0283 cost = 0.549090692\n",
      "Validation Loss: 0.5679049\n",
      "Epoch: 0284 cost = 0.546837330\n",
      "Validation Loss: 0.5560697\n",
      "Epoch: 0285 cost = 0.544602888\n",
      "Validation Loss: 0.5316516\n",
      "Epoch: 0286 cost = 0.542386523\n",
      "Validation Loss: 0.5161965\n",
      "Epoch: 0287 cost = 0.540187665\n",
      "Validation Loss: 0.5432032\n",
      "Epoch: 0288 cost = 0.538005463\n",
      "Validation Loss: 0.49782592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0289 cost = 0.535839311\n",
      "Validation Loss: 0.48570815\n",
      "Epoch: 0290 cost = 0.533688528\n",
      "Validation Loss: 0.45827594\n",
      "Epoch: 0291 cost = 0.531552374\n",
      "Validation Loss: 0.46786976\n",
      "Epoch: 0292 cost = 0.529429649\n",
      "Validation Loss: 0.48067415\n",
      "Epoch: 0293 cost = 0.527319508\n",
      "Validation Loss: 0.48661083\n",
      "Epoch: 0294 cost = 0.525220352\n",
      "Validation Loss: 0.47834203\n",
      "Epoch: 0295 cost = 0.523130485\n",
      "Validation Loss: 0.4788713\n",
      "Epoch: 0296 cost = 0.521047073\n",
      "Validation Loss: 0.49568248\n",
      "Epoch: 0297 cost = 0.518966496\n",
      "Validation Loss: 0.47527137\n",
      "Epoch: 0298 cost = 0.516884433\n",
      "Validation Loss: 0.48032498\n",
      "Epoch: 0299 cost = 0.514795406\n",
      "Validation Loss: 0.48877504\n",
      "Epoch: 0300 cost = 0.512695743\n",
      "Validation Loss: 0.47526738\n",
      "Epoch: 0301 cost = 0.510585338\n",
      "Validation Loss: 0.43280238\n",
      "Epoch: 0302 cost = 0.508470425\n",
      "Validation Loss: 0.47554088\n",
      "Epoch: 0303 cost = 0.506362230\n",
      "Validation Loss: 0.47365826\n",
      "Epoch: 0304 cost = 0.504270762\n",
      "Validation Loss: 0.48408005\n",
      "Epoch: 0305 cost = 0.502201898\n",
      "Validation Loss: 0.4611912\n",
      "Epoch: 0306 cost = 0.500156207\n",
      "Validation Loss: 0.4451053\n",
      "Epoch: 0307 cost = 0.498131841\n",
      "Validation Loss: 0.44618887\n",
      "Epoch: 0308 cost = 0.496126643\n",
      "Validation Loss: 0.43602917\n",
      "Epoch: 0309 cost = 0.494138547\n",
      "Validation Loss: 0.41530064\n",
      "Epoch: 0310 cost = 0.492165842\n",
      "Validation Loss: 0.47032797\n",
      "Epoch: 0311 cost = 0.490207881\n",
      "Validation Loss: 0.4426005\n",
      "Epoch: 0312 cost = 0.488264029\n",
      "Validation Loss: 0.4226849\n",
      "Epoch: 0313 cost = 0.486333638\n",
      "Validation Loss: 0.43282372\n",
      "Epoch: 0314 cost = 0.484416749\n",
      "Validation Loss: 0.44827372\n",
      "Epoch: 0315 cost = 0.482512806\n",
      "Validation Loss: 0.43177992\n",
      "Epoch: 0316 cost = 0.480621683\n",
      "Validation Loss: 0.40007716\n",
      "Epoch: 0317 cost = 0.478743302\n",
      "Validation Loss: 0.45965576\n",
      "Epoch: 0318 cost = 0.476877549\n",
      "Validation Loss: 0.43865123\n",
      "Epoch: 0319 cost = 0.475024049\n",
      "Validation Loss: 0.42232585\n",
      "Epoch: 0320 cost = 0.473182678\n",
      "Validation Loss: 0.4297894\n",
      "Epoch: 0321 cost = 0.471353510\n",
      "Validation Loss: 0.4337057\n",
      "Epoch: 0322 cost = 0.469536066\n",
      "Validation Loss: 0.4207117\n",
      "Epoch: 0323 cost = 0.467730654\n",
      "Validation Loss: 0.41757128\n",
      "Epoch: 0324 cost = 0.465936588\n",
      "Validation Loss: 0.39497787\n",
      "Epoch: 0325 cost = 0.464154141\n",
      "Validation Loss: 0.4746687\n",
      "Epoch: 0326 cost = 0.462383070\n",
      "Validation Loss: 0.4669575\n",
      "Epoch: 0327 cost = 0.460623260\n",
      "Validation Loss: 0.44528112\n",
      "Epoch: 0328 cost = 0.458874596\n",
      "Validation Loss: 0.42027092\n",
      "Epoch: 0329 cost = 0.457136823\n",
      "Validation Loss: 0.4459062\n",
      "Epoch: 0330 cost = 0.455410029\n",
      "Validation Loss: 0.42335138\n",
      "Epoch: 0331 cost = 0.453693926\n",
      "Validation Loss: 0.4259187\n",
      "Epoch: 0332 cost = 0.451988595\n",
      "Validation Loss: 0.41836524\n",
      "Epoch: 0333 cost = 0.450293805\n",
      "Validation Loss: 0.42340052\n",
      "Epoch: 0334 cost = 0.448609446\n",
      "Validation Loss: 0.42617464\n",
      "Epoch: 0335 cost = 0.446935590\n",
      "Validation Loss: 0.4266498\n",
      "Epoch: 0336 cost = 0.445272011\n",
      "Validation Loss: 0.44386667\n",
      "Epoch: 0337 cost = 0.443618574\n",
      "Validation Loss: 0.4426118\n",
      "Epoch: 0338 cost = 0.441975164\n",
      "Validation Loss: 0.45301408\n",
      "Epoch: 0339 cost = 0.440341954\n",
      "Validation Loss: 0.439433\n",
      "Epoch: 0340 cost = 0.438718604\n",
      "Validation Loss: 0.3921256\n",
      "Epoch: 0341 cost = 0.437105204\n",
      "Validation Loss: 0.3967486\n",
      "Epoch: 0342 cost = 0.435501682\n",
      "Validation Loss: 0.37258884\n",
      "Epoch: 0343 cost = 0.433907926\n",
      "Validation Loss: 0.39504063\n",
      "Epoch: 0344 cost = 0.432323711\n",
      "Validation Loss: 0.3993935\n",
      "Epoch: 0345 cost = 0.430749076\n",
      "Validation Loss: 0.39885423\n",
      "Epoch: 0346 cost = 0.429184075\n",
      "Validation Loss: 0.40476096\n",
      "Epoch: 0347 cost = 0.427628543\n",
      "Validation Loss: 0.36233008\n",
      "Epoch: 0348 cost = 0.426082377\n",
      "Validation Loss: 0.40049323\n",
      "Epoch: 0349 cost = 0.424545535\n",
      "Validation Loss: 0.41917253\n",
      "Epoch: 0350 cost = 0.423017949\n",
      "Validation Loss: 0.4493386\n",
      "Epoch: 0351 cost = 0.421499529\n",
      "Validation Loss: 0.47278267\n",
      "Epoch: 0352 cost = 0.419990386\n",
      "Validation Loss: 0.4881136\n",
      "Epoch: 0353 cost = 0.418490252\n",
      "Validation Loss: 0.456425\n",
      "Epoch: 0354 cost = 0.416999157\n",
      "Validation Loss: 0.4151072\n",
      "Epoch: 0355 cost = 0.415517075\n",
      "Validation Loss: 0.3860114\n",
      "Epoch: 0356 cost = 0.414043810\n",
      "Validation Loss: 0.36976025\n",
      "Epoch: 0357 cost = 0.412579307\n",
      "Validation Loss: 0.36673126\n",
      "Epoch: 0358 cost = 0.411123595\n",
      "Validation Loss: 0.33381993\n",
      "Epoch: 0359 cost = 0.409676731\n",
      "Validation Loss: 0.35393912\n",
      "Epoch: 0360 cost = 0.408238483\n",
      "Validation Loss: 0.34846774\n",
      "Epoch: 0361 cost = 0.406808742\n",
      "Validation Loss: 0.36943617\n",
      "Epoch: 0362 cost = 0.405387534\n",
      "Validation Loss: 0.37532607\n",
      "Epoch: 0363 cost = 0.403974844\n",
      "Validation Loss: 0.37545928\n",
      "Epoch: 0364 cost = 0.402570456\n",
      "Validation Loss: 0.35379627\n",
      "Epoch: 0365 cost = 0.401174413\n",
      "Validation Loss: 0.32735917\n",
      "Epoch: 0366 cost = 0.399786706\n",
      "Validation Loss: 0.37236506\n",
      "Epoch: 0367 cost = 0.398407221\n",
      "Validation Loss: 0.34367913\n",
      "Epoch: 0368 cost = 0.397035841\n",
      "Validation Loss: 0.35072404\n",
      "Epoch: 0369 cost = 0.395672696\n",
      "Validation Loss: 0.3798056\n",
      "Epoch: 0370 cost = 0.394317448\n",
      "Validation Loss: 0.37279117\n",
      "Epoch: 0371 cost = 0.392970166\n",
      "Validation Loss: 0.37168625\n",
      "Epoch: 0372 cost = 0.391630884\n",
      "Validation Loss: 0.41325438\n",
      "Epoch: 0373 cost = 0.390299491\n",
      "Validation Loss: 0.38860363\n",
      "Epoch: 0374 cost = 0.388975761\n",
      "Validation Loss: 0.3376131\n",
      "Epoch: 0375 cost = 0.387659933\n",
      "Validation Loss: 0.32163268\n",
      "Epoch: 0376 cost = 0.386351781\n",
      "Validation Loss: 0.36299247\n",
      "Epoch: 0377 cost = 0.385051080\n",
      "Validation Loss: 0.36258507\n",
      "Epoch: 0378 cost = 0.383758281\n",
      "Validation Loss: 0.37286344\n",
      "Epoch: 0379 cost = 0.382472920\n",
      "Validation Loss: 0.34778187\n",
      "Epoch: 0380 cost = 0.381194838\n",
      "Validation Loss: 0.31738168\n",
      "Epoch: 0381 cost = 0.379924285\n",
      "Validation Loss: 0.33863866\n",
      "Epoch: 0382 cost = 0.378661019\n",
      "Validation Loss: 0.307792\n",
      "Epoch: 0383 cost = 0.377405052\n",
      "Validation Loss: 0.3599659\n",
      "Epoch: 0384 cost = 0.376156411\n",
      "Validation Loss: 0.34741744\n",
      "Epoch: 0385 cost = 0.374914897\n",
      "Validation Loss: 0.36266327\n",
      "Epoch: 0386 cost = 0.373680596\n",
      "Validation Loss: 0.3524498\n",
      "Epoch: 0387 cost = 0.372453349\n",
      "Validation Loss: 0.32972354\n",
      "Epoch: 0388 cost = 0.371233161\n",
      "Validation Loss: 0.2892996\n",
      "Epoch: 0389 cost = 0.370019887\n",
      "Validation Loss: 0.32165033\n",
      "Epoch: 0390 cost = 0.368813591\n",
      "Validation Loss: 0.2930709\n",
      "Epoch: 0391 cost = 0.367614218\n",
      "Validation Loss: 0.3042805\n",
      "Epoch: 0392 cost = 0.366421597\n",
      "Validation Loss: 0.2956008\n",
      "Epoch: 0393 cost = 0.365235742\n",
      "Validation Loss: 0.3174943\n",
      "Epoch: 0394 cost = 0.364056766\n",
      "Validation Loss: 0.31710425\n",
      "Epoch: 0395 cost = 0.362884347\n",
      "Validation Loss: 0.30172595\n",
      "Epoch: 0396 cost = 0.361718676\n",
      "Validation Loss: 0.316679\n",
      "Epoch: 0397 cost = 0.360559455\n",
      "Validation Loss: 0.32611993\n",
      "Epoch: 0398 cost = 0.359406842\n",
      "Validation Loss: 0.35641047\n",
      "Epoch: 0399 cost = 0.358260802\n",
      "Validation Loss: 0.35820678\n",
      "Epoch: 0400 cost = 0.357121127\n",
      "Validation Loss: 0.3676084\n",
      "Epoch: 0401 cost = 0.355987868\n",
      "Validation Loss: 0.38392365\n",
      "Epoch: 0402 cost = 0.354861089\n",
      "Validation Loss: 0.377182\n",
      "Epoch: 0403 cost = 0.353740398\n",
      "Validation Loss: 0.33766758\n",
      "Epoch: 0404 cost = 0.352626141\n",
      "Validation Loss: 0.31752798\n",
      "Epoch: 0405 cost = 0.351518026\n",
      "Validation Loss: 0.3048115\n",
      "Epoch: 0406 cost = 0.350416269\n",
      "Validation Loss: 0.30823812\n",
      "Epoch: 0407 cost = 0.349320531\n",
      "Validation Loss: 0.28479642\n",
      "Epoch: 0408 cost = 0.348230856\n",
      "Validation Loss: 0.28969744\n",
      "Epoch: 0409 cost = 0.347147303\n",
      "Validation Loss: 0.29187185\n",
      "Epoch: 0410 cost = 0.346069753\n",
      "Validation Loss: 0.30582887\n",
      "Epoch: 0411 cost = 0.344998181\n",
      "Validation Loss: 0.27203327\n",
      "Epoch: 0412 cost = 0.343932586\n",
      "Validation Loss: 0.2797421\n",
      "Epoch: 0413 cost = 0.342872815\n",
      "Validation Loss: 0.28020072\n",
      "Epoch: 0414 cost = 0.341818954\n",
      "Validation Loss: 0.29583967\n",
      "Epoch: 0415 cost = 0.340770836\n",
      "Validation Loss: 0.29407647\n",
      "Epoch: 0416 cost = 0.339728577\n",
      "Validation Loss: 0.31882322\n",
      "Epoch: 0417 cost = 0.338692124\n",
      "Validation Loss: 0.31157118\n",
      "Epoch: 0418 cost = 0.337661288\n",
      "Validation Loss: 0.32203117\n",
      "Epoch: 0419 cost = 0.336636049\n",
      "Validation Loss: 0.34654877\n",
      "Epoch: 0420 cost = 0.335616610\n",
      "Validation Loss: 0.34653035\n",
      "Epoch: 0421 cost = 0.334602577\n",
      "Validation Loss: 0.35140148\n",
      "Epoch: 0422 cost = 0.333594109\n",
      "Validation Loss: 0.30850947\n",
      "Epoch: 0423 cost = 0.332591312\n",
      "Validation Loss: 0.29066435\n",
      "Epoch: 0424 cost = 0.331593973\n",
      "Validation Loss: 0.30199388\n",
      "Epoch: 0425 cost = 0.330601986\n",
      "Validation Loss: 0.28434536\n",
      "Epoch: 0426 cost = 0.329615495\n",
      "Validation Loss: 0.2725997\n",
      "Epoch: 0427 cost = 0.328634275\n",
      "Validation Loss: 0.27111152\n",
      "Epoch: 0428 cost = 0.327658509\n",
      "Validation Loss: 0.2905393\n",
      "Epoch: 0429 cost = 0.326688021\n",
      "Validation Loss: 0.28329688\n",
      "Epoch: 0430 cost = 0.325722703\n",
      "Validation Loss: 0.28547886\n",
      "Epoch: 0431 cost = 0.324762766\n",
      "Validation Loss: 0.27626503\n",
      "Epoch: 0432 cost = 0.323808036\n",
      "Validation Loss: 0.29058152\n",
      "Epoch: 0433 cost = 0.322858338\n",
      "Validation Loss: 0.2828933\n",
      "Epoch: 0434 cost = 0.321913889\n",
      "Validation Loss: 0.25638688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0435 cost = 0.320974525\n",
      "Validation Loss: 0.2707377\n",
      "Epoch: 0436 cost = 0.320040230\n",
      "Validation Loss: 0.27776787\n",
      "Epoch: 0437 cost = 0.319111011\n",
      "Validation Loss: 0.29835814\n",
      "Epoch: 0438 cost = 0.318186773\n",
      "Validation Loss: 0.31544966\n",
      "Epoch: 0439 cost = 0.317267541\n",
      "Validation Loss: 0.29758796\n",
      "Epoch: 0440 cost = 0.316353283\n",
      "Validation Loss: 0.3080618\n",
      "Epoch: 0441 cost = 0.315443920\n",
      "Validation Loss: 0.30051696\n",
      "Epoch: 0442 cost = 0.314539386\n",
      "Validation Loss: 0.3077827\n",
      "Epoch: 0443 cost = 0.313639747\n",
      "Validation Loss: 0.3108242\n",
      "Epoch: 0444 cost = 0.312744958\n",
      "Validation Loss: 0.31433478\n",
      "Epoch: 0445 cost = 0.311854912\n",
      "Validation Loss: 0.30233476\n",
      "Epoch: 0446 cost = 0.310969817\n",
      "Validation Loss: 0.3200366\n",
      "Epoch: 0447 cost = 0.310089282\n",
      "Validation Loss: 0.32951725\n",
      "Epoch: 0448 cost = 0.309213553\n",
      "Validation Loss: 0.31874648\n",
      "Epoch: 0449 cost = 0.308342423\n",
      "Validation Loss: 0.3195128\n",
      "Epoch: 0450 cost = 0.307475984\n",
      "Validation Loss: 0.30110955\n",
      "Epoch: 0451 cost = 0.306614203\n",
      "Validation Loss: 0.28281435\n",
      "Epoch: 0452 cost = 0.305757059\n",
      "Validation Loss: 0.2876207\n",
      "Epoch: 0453 cost = 0.304904427\n",
      "Validation Loss: 0.28304854\n",
      "Epoch: 0454 cost = 0.304056355\n",
      "Validation Loss: 0.28965458\n",
      "Epoch: 0455 cost = 0.303212762\n",
      "Validation Loss: 0.274251\n",
      "Epoch: 0456 cost = 0.302373712\n",
      "Validation Loss: 0.29139575\n",
      "Epoch: 0457 cost = 0.301539106\n",
      "Validation Loss: 0.28629643\n",
      "Epoch: 0458 cost = 0.300708950\n",
      "Validation Loss: 0.29441878\n",
      "Epoch: 0459 cost = 0.299883200\n",
      "Validation Loss: 0.3166315\n",
      "Epoch: 0460 cost = 0.299061848\n",
      "Validation Loss: 0.3088525\n",
      "Epoch: 0461 cost = 0.298244842\n",
      "Validation Loss: 0.28791207\n",
      "Epoch: 0462 cost = 0.297432210\n",
      "Validation Loss: 0.26297268\n",
      "Epoch: 0463 cost = 0.296623805\n",
      "Validation Loss: 0.25492764\n",
      "Epoch: 0464 cost = 0.295819738\n",
      "Validation Loss: 0.2799323\n",
      "Epoch: 0465 cost = 0.295019946\n",
      "Validation Loss: 0.30362657\n",
      "Epoch: 0466 cost = 0.294224364\n",
      "Validation Loss: 0.2941447\n",
      "Epoch: 0467 cost = 0.293432972\n",
      "Validation Loss: 0.27945024\n",
      "Epoch: 0468 cost = 0.292645782\n",
      "Validation Loss: 0.27666903\n",
      "Epoch: 0469 cost = 0.291862730\n",
      "Validation Loss: 0.26218227\n",
      "Epoch: 0470 cost = 0.291083800\n",
      "Validation Loss: 0.26477876\n",
      "Epoch: 0471 cost = 0.290309055\n",
      "Validation Loss: 0.25849834\n",
      "Epoch: 0472 cost = 0.289538354\n",
      "Validation Loss: 0.26722774\n",
      "Epoch: 0473 cost = 0.288771757\n",
      "Validation Loss: 0.2734905\n",
      "Epoch: 0474 cost = 0.288009111\n",
      "Validation Loss: 0.27176464\n",
      "Epoch: 0475 cost = 0.287250566\n",
      "Validation Loss: 0.2738482\n",
      "Epoch: 0476 cost = 0.286496026\n",
      "Validation Loss: 0.26870552\n",
      "Epoch: 0477 cost = 0.285745361\n",
      "Validation Loss: 0.24838395\n",
      "Epoch: 0478 cost = 0.284998770\n",
      "Validation Loss: 0.24662542\n",
      "Epoch: 0479 cost = 0.284256058\n",
      "Validation Loss: 0.24180377\n",
      "Epoch: 0480 cost = 0.283517284\n",
      "Validation Loss: 0.24223019\n",
      "Epoch: 0481 cost = 0.282782380\n",
      "Validation Loss: 0.2491379\n",
      "Epoch: 0482 cost = 0.282051287\n",
      "Validation Loss: 0.22960931\n",
      "Epoch: 0483 cost = 0.281324114\n",
      "Validation Loss: 0.23334293\n",
      "Epoch: 0484 cost = 0.280600684\n",
      "Validation Loss: 0.21133259\n",
      "Epoch: 0485 cost = 0.279881047\n",
      "Validation Loss: 0.21529168\n",
      "Epoch: 0486 cost = 0.279165221\n",
      "Validation Loss: 0.20918171\n",
      "Epoch: 0487 cost = 0.278453163\n",
      "Validation Loss: 0.23790352\n",
      "Epoch: 0488 cost = 0.277744847\n",
      "Validation Loss: 0.24339068\n",
      "Epoch: 0489 cost = 0.277040218\n",
      "Validation Loss: 0.23649767\n",
      "Epoch: 0490 cost = 0.276339382\n",
      "Validation Loss: 0.2125604\n",
      "Epoch: 0491 cost = 0.275642093\n",
      "Validation Loss: 0.20411135\n",
      "Epoch: 0492 cost = 0.274948520\n",
      "Validation Loss: 0.23235835\n",
      "Epoch: 0493 cost = 0.274258558\n",
      "Validation Loss: 0.23673436\n",
      "Epoch: 0494 cost = 0.273572228\n",
      "Validation Loss: 0.24070968\n",
      "Epoch: 0495 cost = 0.272889520\n",
      "Validation Loss: 0.22950682\n",
      "Epoch: 0496 cost = 0.272210360\n",
      "Validation Loss: 0.22341835\n",
      "Epoch: 0497 cost = 0.271534749\n",
      "Validation Loss: 0.2139578\n",
      "Epoch: 0498 cost = 0.270862724\n",
      "Validation Loss: 0.21076222\n",
      "Epoch: 0499 cost = 0.270194158\n",
      "Validation Loss: 0.21238405\n",
      "Epoch: 0500 cost = 0.269529106\n",
      "Validation Loss: 0.20561048\n",
      "Epoch: 0501 cost = 0.268867522\n",
      "Validation Loss: 0.18908906\n",
      "Epoch: 0502 cost = 0.268209408\n",
      "Validation Loss: 0.1968418\n",
      "Epoch: 0503 cost = 0.267554805\n",
      "Validation Loss: 0.19634992\n",
      "Epoch: 0504 cost = 0.266903592\n",
      "Validation Loss: 0.20754525\n",
      "Epoch: 0505 cost = 0.266255783\n",
      "Validation Loss: 0.23551\n",
      "Epoch: 0506 cost = 0.265611378\n",
      "Validation Loss: 0.23300436\n",
      "Epoch: 0507 cost = 0.264970315\n",
      "Validation Loss: 0.2135153\n",
      "Epoch: 0508 cost = 0.264332599\n",
      "Validation Loss: 0.22234198\n",
      "Epoch: 0509 cost = 0.263698254\n",
      "Validation Loss: 0.23934191\n",
      "Epoch: 0510 cost = 0.263067305\n",
      "Validation Loss: 0.23022653\n",
      "Epoch: 0511 cost = 0.262439589\n",
      "Validation Loss: 0.23217219\n",
      "Epoch: 0512 cost = 0.261815199\n",
      "Validation Loss: 0.22779657\n",
      "Epoch: 0513 cost = 0.261193955\n",
      "Validation Loss: 0.23283164\n",
      "Epoch: 0514 cost = 0.260576061\n",
      "Validation Loss: 0.24156329\n",
      "Epoch: 0515 cost = 0.259961435\n",
      "Validation Loss: 0.22739343\n",
      "Epoch: 0516 cost = 0.259349951\n",
      "Validation Loss: 0.22299054\n",
      "Epoch: 0517 cost = 0.258741775\n",
      "Validation Loss: 0.22512358\n",
      "Epoch: 0518 cost = 0.258136694\n",
      "Validation Loss: 0.23204422\n",
      "Epoch: 0519 cost = 0.257534832\n",
      "Validation Loss: 0.24421282\n",
      "Epoch: 0520 cost = 0.256936201\n",
      "Validation Loss: 0.24379896\n",
      "Epoch: 0521 cost = 0.256340529\n",
      "Validation Loss: 0.2765543\n",
      "Epoch: 0522 cost = 0.255748119\n",
      "Validation Loss: 0.27724674\n",
      "Epoch: 0523 cost = 0.255158822\n",
      "Validation Loss: 0.25767305\n",
      "Epoch: 0524 cost = 0.254572526\n",
      "Validation Loss: 0.22662418\n",
      "Epoch: 0525 cost = 0.253989377\n",
      "Validation Loss: 0.19786368\n",
      "Epoch: 0526 cost = 0.253409262\n",
      "Validation Loss: 0.19899273\n",
      "Epoch: 0527 cost = 0.252832225\n",
      "Validation Loss: 0.21008344\n",
      "Epoch: 0528 cost = 0.252258224\n",
      "Validation Loss: 0.2085241\n",
      "Epoch: 0529 cost = 0.251687214\n",
      "Validation Loss: 0.20500492\n",
      "Epoch: 0530 cost = 0.251119271\n",
      "Validation Loss: 0.1948746\n",
      "Epoch: 0531 cost = 0.250554204\n",
      "Validation Loss: 0.2073488\n",
      "Epoch: 0532 cost = 0.249992234\n",
      "Validation Loss: 0.2218115\n",
      "Epoch: 0533 cost = 0.249433185\n",
      "Validation Loss: 0.23367676\n",
      "Epoch: 0534 cost = 0.248877125\n",
      "Validation Loss: 0.22251965\n",
      "Epoch: 0535 cost = 0.248323962\n",
      "Validation Loss: 0.20957553\n",
      "Epoch: 0536 cost = 0.247773803\n",
      "Validation Loss: 0.20384665\n",
      "Epoch: 0537 cost = 0.247226485\n",
      "Validation Loss: 0.218419\n",
      "Epoch: 0538 cost = 0.246682061\n",
      "Validation Loss: 0.22716743\n",
      "Epoch: 0539 cost = 0.246140499\n",
      "Validation Loss: 0.2250365\n",
      "Epoch: 0540 cost = 0.245601805\n",
      "Validation Loss: 0.23152526\n",
      "Epoch: 0541 cost = 0.245066025\n",
      "Validation Loss: 0.21761273\n",
      "Epoch: 0542 cost = 0.244533090\n",
      "Validation Loss: 0.21685614\n",
      "Epoch: 0543 cost = 0.244002979\n",
      "Validation Loss: 0.20467247\n",
      "Epoch: 0544 cost = 0.243475682\n",
      "Validation Loss: 0.18266496\n",
      "Epoch: 0545 cost = 0.242951210\n",
      "Validation Loss: 0.1971886\n",
      "Epoch: 0546 cost = 0.242429516\n",
      "Validation Loss: 0.20072503\n",
      "Epoch: 0547 cost = 0.241910560\n",
      "Validation Loss: 0.19766797\n",
      "Epoch: 0548 cost = 0.241394413\n",
      "Validation Loss: 0.19497383\n",
      "Epoch: 0549 cost = 0.240881045\n",
      "Validation Loss: 0.19629477\n",
      "Epoch: 0550 cost = 0.240370367\n",
      "Validation Loss: 0.20479469\n",
      "Epoch: 0551 cost = 0.239862476\n",
      "Validation Loss: 0.20999563\n",
      "Epoch: 0552 cost = 0.239357335\n",
      "Validation Loss: 0.21497037\n",
      "Epoch: 0553 cost = 0.238854821\n",
      "Validation Loss: 0.21426113\n",
      "Epoch: 0554 cost = 0.238355072\n",
      "Validation Loss: 0.20561638\n",
      "Epoch: 0555 cost = 0.237858012\n",
      "Validation Loss: 0.20646946\n",
      "Epoch: 0556 cost = 0.237363579\n",
      "Validation Loss: 0.19531082\n",
      "Epoch: 0557 cost = 0.236871849\n",
      "Validation Loss: 0.19834155\n",
      "Epoch: 0558 cost = 0.236382797\n",
      "Validation Loss: 0.1987752\n",
      "Epoch: 0559 cost = 0.235896360\n",
      "Validation Loss: 0.19936676\n",
      "Epoch: 0560 cost = 0.235412600\n",
      "Validation Loss: 0.1924782\n",
      "Epoch: 0561 cost = 0.234931409\n",
      "Validation Loss: 0.18696316\n",
      "Epoch: 0562 cost = 0.234452895\n",
      "Validation Loss: 0.18087025\n",
      "Epoch: 0563 cost = 0.233976939\n",
      "Validation Loss: 0.18699327\n",
      "Epoch: 0564 cost = 0.233503612\n",
      "Validation Loss: 0.1761184\n",
      "Epoch: 0565 cost = 0.233032831\n",
      "Validation Loss: 0.18103117\n",
      "Epoch: 0566 cost = 0.232564652\n",
      "Validation Loss: 0.17833157\n",
      "Epoch: 0567 cost = 0.232099065\n",
      "Validation Loss: 0.18894166\n",
      "Epoch: 0568 cost = 0.231635981\n",
      "Validation Loss: 0.2163927\n",
      "Epoch: 0569 cost = 0.231175378\n",
      "Validation Loss: 0.22711915\n",
      "Epoch: 0570 cost = 0.230717450\n",
      "Validation Loss: 0.20644577\n",
      "Epoch: 0571 cost = 0.230261988\n",
      "Validation Loss: 0.19106022\n",
      "Epoch: 0572 cost = 0.229809067\n",
      "Validation Loss: 0.17346326\n",
      "Epoch: 0573 cost = 0.229358599\n",
      "Validation Loss: 0.18505491\n",
      "Epoch: 0574 cost = 0.228910625\n",
      "Validation Loss: 0.17966385\n",
      "Epoch: 0575 cost = 0.228465236\n",
      "Validation Loss: 0.1822767\n",
      "Epoch: 0576 cost = 0.228022209\n",
      "Validation Loss: 0.19079277\n",
      "Epoch: 0577 cost = 0.227581720\n",
      "Validation Loss: 0.18896711\n",
      "Epoch: 0578 cost = 0.227143692\n",
      "Validation Loss: 0.18940696\n",
      "Epoch: 0579 cost = 0.226708093\n",
      "Validation Loss: 0.1847844\n",
      "Epoch: 0580 cost = 0.226274927\n",
      "Validation Loss: 0.19001813\n",
      "Epoch: 0581 cost = 0.225844287\n",
      "Validation Loss: 0.19624831\n",
      "Epoch: 0582 cost = 0.225415937\n",
      "Validation Loss: 0.18473622\n",
      "Epoch: 0583 cost = 0.224990121\n",
      "Validation Loss: 0.18067414\n",
      "Epoch: 0584 cost = 0.224566660\n",
      "Validation Loss: 0.17820355\n",
      "Epoch: 0585 cost = 0.224145608\n",
      "Validation Loss: 0.17117597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0586 cost = 0.223726973\n",
      "Validation Loss: 0.18599658\n",
      "Epoch: 0587 cost = 0.223310705\n",
      "Validation Loss: 0.19139326\n",
      "Epoch: 0588 cost = 0.222896814\n",
      "Validation Loss: 0.17916645\n",
      "Epoch: 0589 cost = 0.222485263\n",
      "Validation Loss: 0.18076463\n",
      "Epoch: 0590 cost = 0.222076163\n",
      "Validation Loss: 0.1817307\n",
      "Epoch: 0591 cost = 0.221669374\n",
      "Validation Loss: 0.18474367\n",
      "Epoch: 0592 cost = 0.221264907\n",
      "Validation Loss: 0.18909556\n",
      "Epoch: 0593 cost = 0.220862804\n",
      "Validation Loss: 0.18010564\n",
      "Epoch: 0594 cost = 0.220463023\n",
      "Validation Loss: 0.17764336\n",
      "Epoch: 0595 cost = 0.220065604\n",
      "Validation Loss: 0.16938068\n",
      "Epoch: 0596 cost = 0.219670481\n",
      "Validation Loss: 0.17266963\n",
      "Epoch: 0597 cost = 0.219277639\n",
      "Validation Loss: 0.17213428\n",
      "Epoch: 0598 cost = 0.218887161\n",
      "Validation Loss: 0.17687261\n",
      "Epoch: 0599 cost = 0.218498909\n",
      "Validation Loss: 0.16766547\n",
      "Epoch: 0600 cost = 0.218113016\n",
      "Validation Loss: 0.17029803\n",
      "Epoch: 0601 cost = 0.217729347\n",
      "Validation Loss: 0.17951643\n",
      "Epoch: 0602 cost = 0.217347967\n",
      "Validation Loss: 0.18531893\n",
      "Epoch: 0603 cost = 0.216968900\n",
      "Validation Loss: 0.18434724\n",
      "Epoch: 0604 cost = 0.216592050\n",
      "Validation Loss: 0.17898989\n",
      "Epoch: 0605 cost = 0.216217390\n",
      "Validation Loss: 0.171775\n",
      "Epoch: 0606 cost = 0.215845061\n",
      "Validation Loss: 0.18197846\n",
      "Epoch: 0607 cost = 0.215474953\n",
      "Validation Loss: 0.18903644\n",
      "Epoch: 0608 cost = 0.215107100\n",
      "Validation Loss: 0.19680119\n",
      "Epoch: 0609 cost = 0.214741458\n",
      "Validation Loss: 0.20943022\n",
      "Epoch: 0610 cost = 0.214378059\n",
      "Validation Loss: 0.1998739\n",
      "Epoch: 0611 cost = 0.214016814\n",
      "Validation Loss: 0.18299043\n",
      "Epoch: 0612 cost = 0.213657777\n",
      "Validation Loss: 0.17237109\n",
      "Epoch: 0613 cost = 0.213301050\n",
      "Validation Loss: 0.18573053\n",
      "Epoch: 0614 cost = 0.212946392\n",
      "Validation Loss: 0.19982436\n",
      "Epoch: 0615 cost = 0.212593943\n",
      "Validation Loss: 0.20374495\n",
      "Epoch: 0616 cost = 0.212243736\n",
      "Validation Loss: 0.19266619\n",
      "Epoch: 0617 cost = 0.211895640\n",
      "Validation Loss: 0.18012403\n",
      "Epoch: 0618 cost = 0.211549761\n",
      "Validation Loss: 0.1678561\n",
      "Epoch: 0619 cost = 0.211206006\n",
      "Validation Loss: 0.17139076\n",
      "Epoch: 0620 cost = 0.210864442\n",
      "Validation Loss: 0.17534898\n",
      "Epoch: 0621 cost = 0.210524991\n",
      "Validation Loss: 0.16874824\n",
      "Epoch: 0622 cost = 0.210187684\n",
      "Validation Loss: 0.15762947\n",
      "Epoch: 0623 cost = 0.209852544\n",
      "Validation Loss: 0.16423936\n",
      "Epoch: 0624 cost = 0.209519476\n",
      "Validation Loss: 0.16075937\n",
      "Epoch: 0625 cost = 0.209188583\n",
      "Validation Loss: 0.15595473\n",
      "Epoch: 0626 cost = 0.208859803\n",
      "Validation Loss: 0.163885\n",
      "Epoch: 0627 cost = 0.208533104\n",
      "Validation Loss: 0.16059725\n",
      "Epoch: 0628 cost = 0.208208501\n",
      "Validation Loss: 0.1708864\n",
      "Epoch: 0629 cost = 0.207886006\n",
      "Validation Loss: 0.17813082\n",
      "Epoch: 0630 cost = 0.207565593\n",
      "Validation Loss: 0.16892225\n",
      "Epoch: 0631 cost = 0.207247255\n",
      "Validation Loss: 0.15983632\n",
      "Epoch: 0632 cost = 0.206931035\n",
      "Validation Loss: 0.15442525\n",
      "Epoch: 0633 cost = 0.206616847\n",
      "Validation Loss: 0.16322711\n",
      "Epoch: 0634 cost = 0.206304740\n",
      "Validation Loss: 0.16500221\n",
      "Epoch: 0635 cost = 0.205994672\n",
      "Validation Loss: 0.16396429\n",
      "Epoch: 0636 cost = 0.205686650\n",
      "Validation Loss: 0.1713369\n",
      "Epoch: 0637 cost = 0.205380670\n",
      "Validation Loss: 0.16750973\n",
      "Epoch: 0638 cost = 0.205076726\n",
      "Validation Loss: 0.1681612\n",
      "Epoch: 0639 cost = 0.204774865\n",
      "Validation Loss: 0.18364772\n",
      "Epoch: 0640 cost = 0.204474909\n",
      "Validation Loss: 0.17256978\n",
      "Epoch: 0641 cost = 0.204177048\n",
      "Validation Loss: 0.17435515\n",
      "Epoch: 0642 cost = 0.203881151\n",
      "Validation Loss: 0.16942905\n",
      "Epoch: 0643 cost = 0.203587321\n",
      "Validation Loss: 0.17236939\n",
      "Epoch: 0644 cost = 0.203295408\n",
      "Validation Loss: 0.17508812\n",
      "Epoch: 0645 cost = 0.203005563\n",
      "Validation Loss: 0.17366944\n",
      "Epoch: 0646 cost = 0.202717613\n",
      "Validation Loss: 0.16459145\n",
      "Epoch: 0647 cost = 0.202431694\n",
      "Validation Loss: 0.16611105\n",
      "Epoch: 0648 cost = 0.202147671\n",
      "Validation Loss: 0.15712692\n",
      "Epoch: 0649 cost = 0.201865620\n",
      "Validation Loss: 0.15343593\n",
      "Epoch: 0650 cost = 0.201585561\n",
      "Validation Loss: 0.16173986\n",
      "Epoch: 0651 cost = 0.201307452\n",
      "Validation Loss: 0.1599284\n",
      "Epoch: 0652 cost = 0.201031217\n",
      "Validation Loss: 0.1636639\n",
      "Epoch: 0653 cost = 0.200756948\n",
      "Validation Loss: 0.16064003\n",
      "Epoch: 0654 cost = 0.200484544\n",
      "Validation Loss: 0.15180643\n",
      "Epoch: 0655 cost = 0.200214118\n",
      "Validation Loss: 0.15537255\n",
      "Epoch: 0656 cost = 0.199945563\n",
      "Validation Loss: 0.1522952\n",
      "Epoch: 0657 cost = 0.199678940\n",
      "Validation Loss: 0.14596312\n",
      "Epoch: 0658 cost = 0.199414134\n",
      "Validation Loss: 0.15936887\n",
      "Epoch: 0659 cost = 0.199151275\n",
      "Validation Loss: 0.15759556\n",
      "Epoch: 0660 cost = 0.198890282\n",
      "Validation Loss: 0.15366179\n",
      "Epoch: 0661 cost = 0.198631125\n",
      "Validation Loss: 0.15293811\n",
      "Epoch: 0662 cost = 0.198373833\n",
      "Validation Loss: 0.15237762\n",
      "Epoch: 0663 cost = 0.198118399\n",
      "Validation Loss: 0.15607822\n",
      "Epoch: 0664 cost = 0.197864803\n",
      "Validation Loss: 0.15260379\n",
      "Epoch: 0665 cost = 0.197613058\n",
      "Validation Loss: 0.14568777\n",
      "Epoch: 0666 cost = 0.197363121\n",
      "Validation Loss: 0.15010118\n",
      "Epoch: 0667 cost = 0.197115008\n",
      "Validation Loss: 0.1530575\n",
      "Epoch: 0668 cost = 0.196868705\n",
      "Validation Loss: 0.15655419\n",
      "Epoch: 0669 cost = 0.196624251\n",
      "Validation Loss: 0.15410355\n",
      "Epoch: 0670 cost = 0.196381516\n",
      "Validation Loss: 0.16159011\n",
      "Epoch: 0671 cost = 0.196140617\n",
      "Validation Loss: 0.16136412\n",
      "Epoch: 0672 cost = 0.195901496\n",
      "Validation Loss: 0.16149594\n",
      "Epoch: 0673 cost = 0.195664127\n",
      "Validation Loss: 0.15567039\n",
      "Epoch: 0674 cost = 0.195428503\n",
      "Validation Loss: 0.15554574\n",
      "Epoch: 0675 cost = 0.195194694\n",
      "Validation Loss: 0.15867148\n",
      "Epoch: 0676 cost = 0.194962578\n",
      "Validation Loss: 0.16376458\n",
      "Epoch: 0677 cost = 0.194732232\n",
      "Validation Loss: 0.16405113\n",
      "Epoch: 0678 cost = 0.194503582\n",
      "Validation Loss: 0.15543196\n",
      "Epoch: 0679 cost = 0.194276695\n",
      "Validation Loss: 0.16010214\n",
      "Epoch: 0680 cost = 0.194051508\n",
      "Validation Loss: 0.15546738\n",
      "Epoch: 0681 cost = 0.193828023\n",
      "Validation Loss: 0.15394796\n",
      "Epoch: 0682 cost = 0.193606266\n",
      "Validation Loss: 0.14656885\n",
      "Epoch: 0683 cost = 0.193386184\n",
      "Validation Loss: 0.15115312\n",
      "Epoch: 0684 cost = 0.193167776\n",
      "Validation Loss: 0.14684422\n",
      "Epoch: 0685 cost = 0.192951041\n",
      "Validation Loss: 0.14252472\n",
      "Epoch: 0686 cost = 0.192735970\n",
      "Validation Loss: 0.15137504\n",
      "Epoch: 0687 cost = 0.192522583\n",
      "Validation Loss: 0.15187992\n",
      "Epoch: 0688 cost = 0.192310795\n",
      "Validation Loss: 0.15342286\n",
      "Epoch: 0689 cost = 0.192100716\n",
      "Validation Loss: 0.15711656\n",
      "Epoch: 0690 cost = 0.191892215\n",
      "Validation Loss: 0.15396543\n",
      "Epoch: 0691 cost = 0.191685391\n",
      "Validation Loss: 0.16898727\n",
      "Epoch: 0692 cost = 0.191480124\n",
      "Validation Loss: 0.1779563\n",
      "Epoch: 0693 cost = 0.191276508\n",
      "Validation Loss: 0.16814445\n",
      "Epoch: 0694 cost = 0.191074499\n",
      "Validation Loss: 0.17235617\n",
      "Epoch: 0695 cost = 0.190874044\n",
      "Validation Loss: 0.16421877\n",
      "Epoch: 0696 cost = 0.190675220\n",
      "Validation Loss: 0.1702546\n",
      "Epoch: 0697 cost = 0.190477916\n",
      "Validation Loss: 0.15216142\n",
      "Epoch: 0698 cost = 0.190282230\n",
      "Validation Loss: 0.14598344\n",
      "Epoch: 0699 cost = 0.190088032\n",
      "Validation Loss: 0.15124817\n",
      "Epoch: 0700 cost = 0.189895474\n",
      "Validation Loss: 0.1571165\n",
      "Epoch: 0701 cost = 0.189704442\n",
      "Validation Loss: 0.15421239\n",
      "Epoch: 0702 cost = 0.189514914\n",
      "Validation Loss: 0.1525973\n",
      "Epoch: 0703 cost = 0.189326899\n",
      "Validation Loss: 0.1572037\n",
      "Epoch: 0704 cost = 0.189140435\n",
      "Validation Loss: 0.1499326\n",
      "Epoch: 0705 cost = 0.188955467\n",
      "Validation Loss: 0.14041917\n",
      "Epoch: 0706 cost = 0.188771974\n",
      "Validation Loss: 0.14578298\n",
      "Epoch: 0707 cost = 0.188590011\n",
      "Validation Loss: 0.14824277\n",
      "Epoch: 0708 cost = 0.188409516\n",
      "Validation Loss: 0.15383725\n",
      "Epoch: 0709 cost = 0.188230512\n",
      "Validation Loss: 0.15486017\n",
      "Epoch: 0710 cost = 0.188052976\n",
      "Validation Loss: 0.14872028\n",
      "Epoch: 0711 cost = 0.187876874\n",
      "Validation Loss: 0.14352337\n",
      "Epoch: 0712 cost = 0.187702245\n",
      "Validation Loss: 0.14260882\n",
      "Epoch: 0713 cost = 0.187529072\n",
      "Validation Loss: 0.14097738\n",
      "Epoch: 0714 cost = 0.187357309\n",
      "Validation Loss: 0.14014754\n",
      "Epoch: 0715 cost = 0.187186933\n",
      "Validation Loss: 0.14494155\n",
      "Epoch: 0716 cost = 0.187018054\n",
      "Validation Loss: 0.13978443\n",
      "Epoch: 0717 cost = 0.186850544\n",
      "Validation Loss: 0.14245142\n",
      "Epoch: 0718 cost = 0.186684436\n",
      "Validation Loss: 0.13965909\n",
      "Epoch: 0719 cost = 0.186519697\n",
      "Validation Loss: 0.14162226\n",
      "Epoch: 0720 cost = 0.186356423\n",
      "Validation Loss: 0.13853814\n",
      "Epoch: 0721 cost = 0.186194384\n",
      "Validation Loss: 0.14578067\n",
      "Epoch: 0722 cost = 0.186033866\n",
      "Validation Loss: 0.15194261\n",
      "Epoch: 0723 cost = 0.185874564\n",
      "Validation Loss: 0.14691862\n",
      "Epoch: 0724 cost = 0.185716750\n",
      "Validation Loss: 0.14164518\n",
      "Epoch: 0725 cost = 0.185560150\n",
      "Validation Loss: 0.14604169\n",
      "Epoch: 0726 cost = 0.185405029\n",
      "Validation Loss: 0.13885815\n",
      "Epoch: 0727 cost = 0.185251047\n",
      "Validation Loss: 0.14162838\n",
      "Epoch: 0728 cost = 0.185098567\n",
      "Validation Loss: 0.14337458\n",
      "Epoch: 0729 cost = 0.184947199\n",
      "Validation Loss: 0.14464845\n",
      "Epoch: 0730 cost = 0.184797387\n",
      "Validation Loss: 0.14956747\n",
      "Epoch: 0731 cost = 0.184648586\n",
      "Validation Loss: 0.14693372\n",
      "Epoch: 0732 cost = 0.184501331\n",
      "Validation Loss: 0.15423582\n",
      "Epoch: 0733 cost = 0.184355067\n",
      "Validation Loss: 0.17378174\n",
      "Epoch: 0734 cost = 0.184210405\n",
      "Validation Loss: 0.16362222\n",
      "Epoch: 0735 cost = 0.184066606\n",
      "Validation Loss: 0.15858877\n",
      "Epoch: 0736 cost = 0.183924451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.15529612\n",
      "Epoch: 0737 cost = 0.183783157\n",
      "Validation Loss: 0.14900172\n",
      "Epoch: 0738 cost = 0.183643518\n",
      "Validation Loss: 0.14860125\n",
      "Epoch: 0739 cost = 0.183504624\n",
      "Validation Loss: 0.14172713\n",
      "Epoch: 0740 cost = 0.183367482\n",
      "Validation Loss: 0.1380287\n",
      "Epoch: 0741 cost = 0.183230949\n",
      "Validation Loss: 0.14864056\n",
      "Epoch: 0742 cost = 0.183096239\n",
      "Validation Loss: 0.15130763\n",
      "Epoch: 0743 cost = 0.182962068\n",
      "Validation Loss: 0.13767016\n",
      "Epoch: 0744 cost = 0.182829836\n",
      "Validation Loss: 0.13886942\n",
      "Epoch: 0745 cost = 0.182697892\n",
      "Validation Loss: 0.13872401\n",
      "Epoch: 0746 cost = 0.182568056\n",
      "Validation Loss: 0.13764618\n",
      "Epoch: 0747 cost = 0.182438386\n",
      "Validation Loss: 0.14245579\n",
      "Epoch: 0748 cost = 0.182310952\n",
      "Validation Loss: 0.13974503\n",
      "Epoch: 0749 cost = 0.182183464\n",
      "Validation Loss: 0.14052317\n",
      "Epoch: 0750 cost = 0.182058449\n",
      "Validation Loss: 0.13901122\n",
      "Epoch: 0751 cost = 0.181933096\n",
      "Validation Loss: 0.14169616\n",
      "Epoch: 0752 cost = 0.181810396\n",
      "Validation Loss: 0.14427267\n",
      "Epoch: 0753 cost = 0.181687151\n",
      "Validation Loss: 0.14367001\n",
      "Epoch: 0754 cost = 0.181566779\n",
      "Validation Loss: 0.1504661\n",
      "Epoch: 0755 cost = 0.181445594\n",
      "Validation Loss: 0.14599675\n",
      "Epoch: 0756 cost = 0.181327598\n",
      "Validation Loss: 0.14558382\n",
      "Epoch: 0757 cost = 0.181208323\n",
      "Validation Loss: 0.14095195\n",
      "Epoch: 0758 cost = 0.181092701\n",
      "Validation Loss: 0.14587964\n",
      "Epoch: 0759 cost = 0.180975356\n",
      "Validation Loss: 0.13865654\n",
      "Epoch: 0760 cost = 0.180862044\n",
      "Validation Loss: 0.13709436\n",
      "Epoch: 0761 cost = 0.180746534\n",
      "Validation Loss: 0.14005882\n",
      "Epoch: 0762 cost = 0.180635608\n",
      "Validation Loss: 0.1350863\n",
      "Epoch: 0763 cost = 0.180521854\n",
      "Validation Loss: 0.13997373\n",
      "Epoch: 0764 cost = 0.180413295\n",
      "Validation Loss: 0.15962291\n",
      "Epoch: 0765 cost = 0.180301187\n",
      "Validation Loss: 0.17521635\n",
      "Epoch: 0766 cost = 0.180195063\n",
      "Validation Loss: 0.15271644\n",
      "Epoch: 0767 cost = 0.180084529\n",
      "Validation Loss: 0.13313615\n",
      "Epoch: 0768 cost = 0.179980844\n",
      "Validation Loss: 0.13792709\n",
      "Epoch: 0769 cost = 0.179871793\n",
      "Validation Loss: 0.13716954\n",
      "Epoch: 0770 cost = 0.179770529\n",
      "Validation Loss: 0.13535264\n",
      "Epoch: 0771 cost = 0.179662868\n",
      "Validation Loss: 0.13590392\n",
      "Epoch: 0772 cost = 0.179564174\n",
      "Validation Loss: 0.13506734\n",
      "Epoch: 0773 cost = 0.179457762\n",
      "Validation Loss: 0.14393887\n",
      "Epoch: 0774 cost = 0.179361639\n",
      "Validation Loss: 0.1524241\n",
      "Epoch: 0775 cost = 0.179256341\n",
      "Validation Loss: 0.1520139\n",
      "Epoch: 0776 cost = 0.179162983\n",
      "Validation Loss: 0.14768887\n",
      "Epoch: 0777 cost = 0.179058565\n",
      "Validation Loss: 0.14012952\n",
      "Epoch: 0778 cost = 0.178968025\n",
      "Validation Loss: 0.1336914\n",
      "Epoch: 0779 cost = 0.178864370\n",
      "Validation Loss: 0.13351575\n",
      "Epoch: 0780 cost = 0.178776779\n",
      "Validation Loss: 0.13615073\n",
      "Epoch: 0781 cost = 0.178673699\n",
      "Validation Loss: 0.13237953\n",
      "Epoch: 0782 cost = 0.178589210\n",
      "Validation Loss: 0.13651167\n",
      "Epoch: 0783 cost = 0.178486464\n",
      "Validation Loss: 0.13308825\n",
      "Epoch: 0784 cost = 0.178405266\n",
      "Validation Loss: 0.13666552\n",
      "Epoch: 0785 cost = 0.178302673\n",
      "Validation Loss: 0.13796033\n",
      "Epoch: 0786 cost = 0.178225015\n",
      "Validation Loss: 0.13618052\n",
      "Epoch: 0787 cost = 0.178122214\n",
      "Validation Loss: 0.138635\n",
      "Epoch: 0788 cost = 0.178048362\n",
      "Validation Loss: 0.13656713\n",
      "Epoch: 0789 cost = 0.177945048\n",
      "Validation Loss: 0.13396709\n",
      "Epoch: 0790 cost = 0.177875263\n",
      "Validation Loss: 0.13506298\n",
      "Epoch: 0791 cost = 0.177771157\n",
      "Validation Loss: 0.13415389\n",
      "Epoch: 0792 cost = 0.177705769\n",
      "Validation Loss: 0.13441397\n",
      "Epoch: 0793 cost = 0.177600482\n",
      "Validation Loss: 0.13869113\n",
      "Epoch: 0794 cost = 0.177539879\n",
      "Validation Loss: 0.13427679\n",
      "Epoch: 0795 cost = 0.177433029\n",
      "Validation Loss: 0.13637002\n",
      "Epoch: 0796 cost = 0.177377660\n",
      "Validation Loss: 0.13308732\n",
      "Epoch: 0797 cost = 0.177268829\n",
      "Validation Loss: 0.1321569\n",
      "Epoch: 0798 cost = 0.177219112\n",
      "Validation Loss: 0.13722964\n",
      "Epoch: 0799 cost = 0.177107881\n",
      "Validation Loss: 0.13457742\n",
      "Epoch: 0800 cost = 0.177064372\n",
      "Validation Loss: 0.14388959\n",
      "Epoch: 0801 cost = 0.176950189\n",
      "Validation Loss: 0.15031965\n",
      "Epoch: 0802 cost = 0.176913462\n",
      "Validation Loss: 0.13176975\n",
      "Epoch: 0803 cost = 0.176795942\n",
      "Validation Loss: 0.1352121\n",
      "Epoch: 0804 cost = 0.176766613\n",
      "Validation Loss: 0.13170953\n",
      "Epoch: 0805 cost = 0.176645249\n",
      "Validation Loss: 0.13501853\n",
      "Epoch: 0806 cost = 0.176623970\n",
      "Validation Loss: 0.13216448\n",
      "Epoch: 0807 cost = 0.176498358\n",
      "Validation Loss: 0.13444337\n",
      "Epoch: 0808 cost = 0.176485756\n",
      "Validation Loss: 0.13492978\n",
      "Epoch: 0809 cost = 0.176355613\n",
      "Validation Loss: 0.13120545\n",
      "Epoch: 0810 cost = 0.176352158\n",
      "Validation Loss: 0.13839658\n",
      "Epoch: 0811 cost = 0.176217315\n",
      "Validation Loss: 0.14348812\n",
      "Epoch: 0812 cost = 0.176223357\n",
      "Validation Loss: 0.15190892\n",
      "Epoch: 0813 cost = 0.176083948\n",
      "Validation Loss: 0.13615246\n",
      "Epoch: 0814 cost = 0.176099068\n",
      "Validation Loss: 0.13158183\n",
      "Epoch: 0815 cost = 0.175955540\n",
      "Validation Loss: 0.1337115\n",
      "Epoch: 0816 cost = 0.175978214\n",
      "Validation Loss: 0.13500682\n",
      "Epoch: 0817 cost = 0.175831407\n",
      "Validation Loss: 0.13284071\n",
      "Epoch: 0818 cost = 0.175858334\n",
      "Validation Loss: 0.13228376\n",
      "Epoch: 0819 cost = 0.175709401\n",
      "Validation Loss: 0.13394801\n",
      "Epoch: 0820 cost = 0.175735474\n",
      "Validation Loss: 0.13119833\n",
      "Epoch: 0821 cost = 0.175586068\n",
      "Validation Loss: 0.1507831\n",
      "Epoch: 0822 cost = 0.175605582\n",
      "Validation Loss: 0.17815974\n",
      "Epoch: 0823 cost = 0.175458344\n",
      "Validation Loss: 0.20147625\n",
      "Epoch: 0824 cost = 0.175467451\n",
      "Validation Loss: 0.16101733\n",
      "Epoch: 0825 cost = 0.175325885\n",
      "Validation Loss: 0.14971955\n",
      "Epoch: 0826 cost = 0.175324259\n",
      "Validation Loss: 0.15299262\n",
      "Epoch: 0827 cost = 0.175191334\n",
      "Validation Loss: 0.16553086\n",
      "Epoch: 0828 cost = 0.175181302\n",
      "Validation Loss: 0.15360664\n",
      "Epoch: 0829 cost = 0.175058297\n",
      "Validation Loss: 0.15134507\n",
      "Epoch: 0830 cost = 0.175042876\n",
      "Validation Loss: 0.1439916\n",
      "Epoch: 0831 cost = 0.174929046\n",
      "Validation Loss: 0.14054334\n",
      "Epoch: 0832 cost = 0.174910584\n",
      "Validation Loss: 0.13223061\n",
      "Epoch: 0833 cost = 0.174804287\n",
      "Validation Loss: 0.13286625\n",
      "Epoch: 0834 cost = 0.174784235\n",
      "Validation Loss: 0.13140434\n",
      "Epoch: 0835 cost = 0.174683848\n",
      "Validation Loss: 0.13011183\n",
      "Epoch: 0836 cost = 0.174662863\n",
      "Validation Loss: 0.1327936\n",
      "Epoch: 0837 cost = 0.174567142\n",
      "Validation Loss: 0.12954597\n",
      "Epoch: 0838 cost = 0.174545514\n",
      "Validation Loss: 0.13771759\n",
      "Epoch: 0839 cost = 0.174453682\n",
      "Validation Loss: 0.14441155\n",
      "Epoch: 0840 cost = 0.174431571\n",
      "Validation Loss: 0.14599372\n",
      "Epoch: 0841 cost = 0.174343056\n",
      "Validation Loss: 0.151576\n",
      "Epoch: 0842 cost = 0.174320517\n",
      "Validation Loss: 0.14179872\n",
      "Epoch: 0843 cost = 0.174234912\n",
      "Validation Loss: 0.13662316\n",
      "Epoch: 0844 cost = 0.174212147\n",
      "Validation Loss: 0.12907511\n",
      "Epoch: 0845 cost = 0.174129007\n",
      "Validation Loss: 0.1338837\n",
      "Epoch: 0846 cost = 0.174106217\n",
      "Validation Loss: 0.131588\n",
      "Epoch: 0847 cost = 0.174025218\n",
      "Validation Loss: 0.13119927\n",
      "Epoch: 0848 cost = 0.174002511\n",
      "Validation Loss: 0.12847257\n",
      "Epoch: 0849 cost = 0.173923431\n",
      "Validation Loss: 0.13631877\n",
      "Epoch: 0850 cost = 0.173901011\n",
      "Validation Loss: 0.13678636\n",
      "Epoch: 0851 cost = 0.173823508\n",
      "Validation Loss: 0.14851817\n",
      "Epoch: 0852 cost = 0.173801629\n",
      "Validation Loss: 0.1496019\n",
      "Epoch: 0853 cost = 0.173725407\n",
      "Validation Loss: 0.14649546\n",
      "Epoch: 0854 cost = 0.173704194\n",
      "Validation Loss: 0.14734218\n",
      "Epoch: 0855 cost = 0.173629071\n",
      "Validation Loss: 0.13469975\n",
      "Epoch: 0856 cost = 0.173608654\n",
      "Validation Loss: 0.13997085\n",
      "Epoch: 0857 cost = 0.173534474\n",
      "Validation Loss: 0.15857\n",
      "Epoch: 0858 cost = 0.173514975\n",
      "Validation Loss: 0.15418117\n",
      "Epoch: 0859 cost = 0.173441578\n",
      "Validation Loss: 0.15407628\n",
      "Epoch: 0860 cost = 0.173423111\n",
      "Validation Loss: 0.12969714\n",
      "Epoch: 0861 cost = 0.173350292\n",
      "Validation Loss: 0.12803912\n",
      "Epoch: 0862 cost = 0.173332932\n",
      "Validation Loss: 0.13272439\n",
      "Epoch: 0863 cost = 0.173260674\n",
      "Validation Loss: 0.12926172\n",
      "Epoch: 0864 cost = 0.173244487\n",
      "Validation Loss: 0.13045299\n",
      "Epoch: 0865 cost = 0.173172651\n",
      "Validation Loss: 0.12875473\n",
      "Epoch: 0866 cost = 0.173157683\n",
      "Validation Loss: 0.12754801\n",
      "Epoch: 0867 cost = 0.173086120\n",
      "Validation Loss: 0.13300605\n",
      "Epoch: 0868 cost = 0.173072410\n",
      "Validation Loss: 0.13010065\n",
      "Epoch: 0869 cost = 0.173001194\n",
      "Validation Loss: 0.13060826\n",
      "Epoch: 0870 cost = 0.172988713\n",
      "Validation Loss: 0.12976813\n",
      "Epoch: 0871 cost = 0.172917694\n",
      "Validation Loss: 0.12931712\n",
      "Epoch: 0872 cost = 0.172906484\n",
      "Validation Loss: 0.1312319\n",
      "Epoch: 0873 cost = 0.172835640\n",
      "Validation Loss: 0.13310847\n",
      "Epoch: 0874 cost = 0.172825675\n",
      "Validation Loss: 0.14354405\n",
      "Epoch: 0875 cost = 0.172755046\n",
      "Validation Loss: 0.1463121\n",
      "Epoch: 0876 cost = 0.172746235\n",
      "Validation Loss: 0.14595774\n",
      "Epoch: 0877 cost = 0.172675799\n",
      "Validation Loss: 0.13997409\n",
      "Epoch: 0878 cost = 0.172668091\n",
      "Validation Loss: 0.13511397\n",
      "Epoch: 0879 cost = 0.172597921\n",
      "Validation Loss: 0.1340765\n",
      "Epoch: 0880 cost = 0.172591220\n",
      "Validation Loss: 0.12827383\n",
      "Epoch: 0881 cost = 0.172521297\n",
      "Validation Loss: 0.12999462\n",
      "Epoch: 0882 cost = 0.172515522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.13287373\n",
      "Epoch: 0883 cost = 0.172445995\n",
      "Validation Loss: 0.13333513\n",
      "Epoch: 0884 cost = 0.172441023\n",
      "Validation Loss: 0.13292219\n",
      "Epoch: 0885 cost = 0.172371837\n",
      "Validation Loss: 0.1296357\n",
      "Epoch: 0886 cost = 0.172367624\n",
      "Validation Loss: 0.12886411\n",
      "Epoch: 0887 cost = 0.172298923\n",
      "Validation Loss: 0.13114671\n",
      "Epoch: 0888 cost = 0.172295281\n",
      "Validation Loss: 0.1299528\n",
      "Epoch: 0889 cost = 0.172227151\n",
      "Validation Loss: 0.13094041\n",
      "Epoch: 0890 cost = 0.172224011\n",
      "Validation Loss: 0.12904836\n",
      "Epoch: 0891 cost = 0.172156491\n",
      "Validation Loss: 0.13563831\n",
      "Epoch: 0892 cost = 0.172153752\n",
      "Validation Loss: 0.12640819\n",
      "Epoch: 0893 cost = 0.172086933\n",
      "Validation Loss: 0.13229062\n",
      "Epoch: 0894 cost = 0.172084466\n",
      "Validation Loss: 0.13063118\n",
      "Epoch: 0895 cost = 0.172018439\n",
      "Validation Loss: 0.12758887\n",
      "Epoch: 0896 cost = 0.172016210\n",
      "Validation Loss: 0.12877725\n",
      "Epoch: 0897 cost = 0.171951028\n",
      "Validation Loss: 0.12707351\n",
      "Epoch: 0898 cost = 0.171948950\n",
      "Validation Loss: 0.12715702\n",
      "Epoch: 0899 cost = 0.171884662\n",
      "Validation Loss: 0.12708792\n",
      "Epoch: 0900 cost = 0.171882636\n",
      "Validation Loss: 0.13435109\n",
      "Epoch: 0901 cost = 0.171819293\n",
      "Validation Loss: 0.13755155\n",
      "Epoch: 0902 cost = 0.171817341\n",
      "Validation Loss: 0.13777237\n",
      "Epoch: 0903 cost = 0.171754965\n",
      "Validation Loss: 0.13221917\n",
      "Epoch: 0904 cost = 0.171752974\n",
      "Validation Loss: 0.12624477\n",
      "Epoch: 0905 cost = 0.171691654\n",
      "Validation Loss: 0.13227943\n",
      "Epoch: 0906 cost = 0.171689606\n",
      "Validation Loss: 0.12722133\n",
      "Epoch: 0907 cost = 0.171629325\n",
      "Validation Loss: 0.12609659\n",
      "Epoch: 0908 cost = 0.171627213\n",
      "Validation Loss: 0.13197803\n",
      "Epoch: 0909 cost = 0.171567983\n",
      "Validation Loss: 0.12862338\n",
      "Epoch: 0910 cost = 0.171565771\n",
      "Validation Loss: 0.12812819\n",
      "Epoch: 0911 cost = 0.171507629\n",
      "Validation Loss: 0.12818408\n",
      "Epoch: 0912 cost = 0.171505266\n",
      "Validation Loss: 0.13080582\n",
      "Epoch: 0913 cost = 0.171448235\n",
      "Validation Loss: 0.12873589\n",
      "Epoch: 0914 cost = 0.171445761\n",
      "Validation Loss: 0.12916932\n",
      "Epoch: 0915 cost = 0.171389788\n",
      "Validation Loss: 0.13547887\n",
      "Epoch: 0916 cost = 0.171387219\n",
      "Validation Loss: 0.13211049\n",
      "Epoch: 0917 cost = 0.171332255\n",
      "Validation Loss: 0.12845507\n",
      "Epoch: 0918 cost = 0.171329562\n",
      "Validation Loss: 0.12736514\n",
      "Epoch: 0919 cost = 0.171275637\n",
      "Validation Loss: 0.13591264\n",
      "Epoch: 0920 cost = 0.171272821\n",
      "Validation Loss: 0.15687804\n",
      "Epoch: 0921 cost = 0.171219924\n",
      "Validation Loss: 0.14689822\n",
      "Epoch: 0922 cost = 0.171217005\n",
      "Validation Loss: 0.16585527\n",
      "Epoch: 0923 cost = 0.171165109\n",
      "Validation Loss: 0.16738112\n",
      "Epoch: 0924 cost = 0.171162090\n",
      "Validation Loss: 0.16002136\n",
      "Epoch: 0925 cost = 0.171111128\n",
      "Validation Loss: 0.16701262\n",
      "Epoch: 0926 cost = 0.171108029\n",
      "Validation Loss: 0.14833716\n",
      "Epoch: 0927 cost = 0.171058010\n",
      "Validation Loss: 0.14183469\n",
      "Epoch: 0928 cost = 0.171054853\n",
      "Validation Loss: 0.14243113\n",
      "Epoch: 0929 cost = 0.171005722\n",
      "Validation Loss: 0.14645147\n",
      "Epoch: 0930 cost = 0.171002494\n",
      "Validation Loss: 0.12675805\n",
      "Epoch: 0931 cost = 0.170954268\n",
      "Validation Loss: 0.12632315\n",
      "Epoch: 0932 cost = 0.170950975\n",
      "Validation Loss: 0.12602408\n",
      "Epoch: 0933 cost = 0.170903610\n",
      "Validation Loss: 0.13750598\n",
      "Epoch: 0934 cost = 0.170900298\n",
      "Validation Loss: 0.14788502\n",
      "Epoch: 0935 cost = 0.170853702\n",
      "Validation Loss: 0.16615388\n",
      "Epoch: 0936 cost = 0.170850407\n",
      "Validation Loss: 0.15253253\n",
      "Epoch: 0937 cost = 0.170804603\n",
      "Validation Loss: 0.14403936\n",
      "Epoch: 0938 cost = 0.170801305\n",
      "Validation Loss: 0.12818313\n",
      "Epoch: 0939 cost = 0.170756255\n",
      "Validation Loss: 0.12952144\n",
      "Epoch: 0940 cost = 0.170752940\n",
      "Validation Loss: 0.1283805\n",
      "Epoch: 0941 cost = 0.170708633\n",
      "Validation Loss: 0.12611744\n",
      "Epoch: 0942 cost = 0.170705361\n",
      "Validation Loss: 0.12953426\n",
      "Epoch: 0943 cost = 0.170661737\n",
      "Validation Loss: 0.13220458\n",
      "Epoch: 0944 cost = 0.170658497\n",
      "Validation Loss: 0.13489304\n",
      "Epoch: 0945 cost = 0.170615577\n",
      "Validation Loss: 0.14335749\n",
      "Epoch: 0946 cost = 0.170612388\n",
      "Validation Loss: 0.1324937\n",
      "Epoch: 0947 cost = 0.170570078\n",
      "Validation Loss: 0.12765807\n",
      "Epoch: 0948 cost = 0.170566991\n",
      "Validation Loss: 0.13611947\n",
      "Epoch: 0949 cost = 0.170525278\n",
      "Validation Loss: 0.13520409\n",
      "Epoch: 0950 cost = 0.170522268\n",
      "Validation Loss: 0.13377942\n",
      "Epoch: 0951 cost = 0.170481135\n",
      "Validation Loss: 0.12705311\n",
      "Epoch: 0952 cost = 0.170478195\n",
      "Validation Loss: 0.12865914\n",
      "Epoch: 0953 cost = 0.170437670\n",
      "Validation Loss: 0.14066301\n",
      "Epoch: 0954 cost = 0.170434850\n",
      "Validation Loss: 0.13260183\n",
      "Epoch: 0955 cost = 0.170394859\n",
      "Validation Loss: 0.12478498\n",
      "Epoch: 0956 cost = 0.170392115\n",
      "Validation Loss: 0.13230027\n",
      "Epoch: 0957 cost = 0.170352687\n",
      "Validation Loss: 0.13255449\n",
      "Epoch: 0958 cost = 0.170350045\n",
      "Validation Loss: 0.14105931\n",
      "Epoch: 0959 cost = 0.170311123\n",
      "Validation Loss: 0.15184706\n",
      "Epoch: 0960 cost = 0.170308590\n",
      "Validation Loss: 0.1503913\n",
      "Epoch: 0961 cost = 0.170270209\n",
      "Validation Loss: 0.13331664\n",
      "Epoch: 0962 cost = 0.170267780\n",
      "Validation Loss: 0.12524876\n",
      "Epoch: 0963 cost = 0.170229816\n",
      "Validation Loss: 0.12871473\n",
      "Epoch: 0964 cost = 0.170227555\n",
      "Validation Loss: 0.13202895\n",
      "Epoch: 0965 cost = 0.170190053\n",
      "Validation Loss: 0.13114032\n",
      "Epoch: 0966 cost = 0.170187918\n",
      "Validation Loss: 0.12900318\n",
      "Epoch: 0967 cost = 0.170150893\n",
      "Validation Loss: 0.12600365\n",
      "Epoch: 0968 cost = 0.170148913\n",
      "Validation Loss: 0.13622552\n",
      "Epoch: 0969 cost = 0.170112284\n",
      "Validation Loss: 0.13862306\n",
      "Epoch: 0970 cost = 0.170110383\n",
      "Validation Loss: 0.13870223\n",
      "Epoch: 0971 cost = 0.170074210\n",
      "Validation Loss: 0.12934352\n",
      "Epoch: 0972 cost = 0.170072466\n",
      "Validation Loss: 0.1259323\n",
      "Epoch: 0973 cost = 0.170036699\n",
      "Validation Loss: 0.12523386\n",
      "Epoch: 0974 cost = 0.170035094\n",
      "Validation Loss: 0.12533881\n",
      "Epoch: 0975 cost = 0.169999736\n",
      "Validation Loss: 0.12517777\n",
      "Epoch: 0976 cost = 0.169998263\n",
      "Validation Loss: 0.12656745\n",
      "Epoch: 0977 cost = 0.169963311\n",
      "Validation Loss: 0.13014491\n",
      "Epoch: 0978 cost = 0.169961968\n",
      "Validation Loss: 0.13708694\n",
      "Epoch: 0979 cost = 0.169927374\n",
      "Validation Loss: 0.13978112\n",
      "Epoch: 0980 cost = 0.169926171\n",
      "Validation Loss: 0.12590171\n",
      "Epoch: 0981 cost = 0.169891945\n",
      "Validation Loss: 0.12649097\n",
      "Epoch: 0982 cost = 0.169890864\n",
      "Validation Loss: 0.12631212\n",
      "Epoch: 0983 cost = 0.169857040\n",
      "Validation Loss: 0.12667236\n",
      "Epoch: 0984 cost = 0.169856082\n",
      "Validation Loss: 0.12634191\n",
      "Epoch: 0985 cost = 0.169822608\n",
      "Validation Loss: 0.1266673\n",
      "Epoch: 0986 cost = 0.169821767\n",
      "Validation Loss: 0.12993237\n",
      "Epoch: 0987 cost = 0.169788661\n",
      "Validation Loss: 0.12733585\n",
      "Epoch: 0988 cost = 0.169787960\n",
      "Validation Loss: 0.124331\n",
      "Epoch: 0989 cost = 0.169755208\n",
      "Validation Loss: 0.12801309\n",
      "Epoch: 0990 cost = 0.169754599\n",
      "Validation Loss: 0.1302089\n",
      "Epoch: 0991 cost = 0.169722219\n",
      "Validation Loss: 0.12821998\n",
      "Epoch: 0992 cost = 0.169721710\n",
      "Validation Loss: 0.12725966\n",
      "Epoch: 0993 cost = 0.169689666\n",
      "Validation Loss: 0.12867345\n",
      "Epoch: 0994 cost = 0.169689251\n",
      "Validation Loss: 0.12649283\n",
      "Epoch: 0995 cost = 0.169657545\n",
      "Validation Loss: 0.13174303\n",
      "Epoch: 0996 cost = 0.169657245\n",
      "Validation Loss: 0.13598055\n",
      "Epoch: 0997 cost = 0.169625912\n",
      "Validation Loss: 0.1461129\n",
      "Epoch: 0998 cost = 0.169625710\n",
      "Validation Loss: 0.16072711\n",
      "Epoch: 0999 cost = 0.169594654\n",
      "Validation Loss: 0.14828041\n",
      "Epoch: 1000 cost = 0.169594582\n",
      "Validation Loss: 0.13026434\n",
      "Epoch: 1001 cost = 0.169563860\n",
      "Validation Loss: 0.12574144\n",
      "Epoch: 1002 cost = 0.169563858\n",
      "Validation Loss: 0.12629758\n",
      "Epoch: 1003 cost = 0.169533476\n",
      "Validation Loss: 0.12719962\n",
      "Epoch: 1004 cost = 0.169533521\n",
      "Validation Loss: 0.13460308\n",
      "Epoch: 1005 cost = 0.169503487\n",
      "Validation Loss: 0.12926024\n",
      "Epoch: 1006 cost = 0.169503653\n",
      "Validation Loss: 0.1242358\n",
      "Epoch: 1007 cost = 0.169473933\n",
      "Validation Loss: 0.13019407\n",
      "Epoch: 1008 cost = 0.169474129\n",
      "Validation Loss: 0.1290782\n",
      "Epoch: 1009 cost = 0.169444780\n",
      "Validation Loss: 0.12465427\n",
      "Epoch: 1010 cost = 0.169445023\n",
      "Validation Loss: 0.12501854\n",
      "Epoch: 1011 cost = 0.169415987\n",
      "Validation Loss: 0.13099182\n",
      "Epoch: 1012 cost = 0.169416285\n",
      "Validation Loss: 0.13664624\n",
      "Epoch: 1013 cost = 0.169387581\n",
      "Validation Loss: 0.13142647\n",
      "Epoch: 1014 cost = 0.169387966\n",
      "Validation Loss: 0.12567164\n",
      "Epoch: 1015 cost = 0.169359548\n",
      "Validation Loss: 0.15695065\n",
      "Epoch: 1016 cost = 0.169359988\n",
      "Validation Loss: 0.18225569\n",
      "Epoch: 1017 cost = 0.169331885\n",
      "Validation Loss: 0.21341708\n",
      "Epoch: 1018 cost = 0.169332355\n",
      "Validation Loss: 0.19639008\n",
      "Epoch: 1019 cost = 0.169304592\n",
      "Validation Loss: 0.15239021\n",
      "Epoch: 1020 cost = 0.169305097\n",
      "Validation Loss: 0.13560404\n",
      "Epoch: 1021 cost = 0.169277653\n",
      "Validation Loss: 0.13075481\n",
      "Epoch: 1022 cost = 0.169278202\n",
      "Validation Loss: 0.12341848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1023 cost = 0.169251052\n",
      "Validation Loss: 0.13070309\n",
      "Epoch: 1024 cost = 0.169251644\n",
      "Validation Loss: 0.12882489\n",
      "Epoch: 1025 cost = 0.169224858\n",
      "Validation Loss: 0.12570222\n",
      "Epoch: 1026 cost = 0.169225435\n",
      "Validation Loss: 0.13083921\n",
      "Epoch: 1027 cost = 0.169198932\n",
      "Validation Loss: 0.1436115\n",
      "Epoch: 1028 cost = 0.169199560\n",
      "Validation Loss: 0.14780752\n",
      "Epoch: 1029 cost = 0.169173371\n",
      "Validation Loss: 0.15268014\n",
      "Epoch: 1030 cost = 0.169174009\n",
      "Validation Loss: 0.14596413\n",
      "Epoch: 1031 cost = 0.169148130\n",
      "Validation Loss: 0.14594312\n",
      "Epoch: 1032 cost = 0.169148762\n",
      "Validation Loss: 0.1374017\n",
      "Epoch: 1033 cost = 0.169123194\n",
      "Validation Loss: 0.12666887\n",
      "Epoch: 1034 cost = 0.169123877\n",
      "Validation Loss: 0.13198884\n",
      "Epoch: 1035 cost = 0.169098620\n",
      "Validation Loss: 0.1405512\n",
      "Epoch: 1036 cost = 0.169099293\n",
      "Validation Loss: 0.12586305\n",
      "Epoch: 1037 cost = 0.169074320\n",
      "Validation Loss: 0.12432899\n",
      "Epoch: 1038 cost = 0.169075040\n",
      "Validation Loss: 0.130552\n",
      "Epoch: 1039 cost = 0.169050347\n",
      "Validation Loss: 0.12593615\n",
      "Epoch: 1040 cost = 0.169051064\n",
      "Validation Loss: 0.12992771\n",
      "Epoch: 1041 cost = 0.169026671\n",
      "Validation Loss: 0.12833852\n",
      "Epoch: 1042 cost = 0.169027382\n",
      "Validation Loss: 0.12679152\n",
      "Epoch: 1043 cost = 0.169003272\n",
      "Validation Loss: 0.13962881\n",
      "Epoch: 1044 cost = 0.169004017\n",
      "Validation Loss: 0.14103378\n",
      "Epoch: 1045 cost = 0.168980177\n",
      "Validation Loss: 0.12748016\n",
      "Epoch: 1046 cost = 0.168980928\n",
      "Validation Loss: 0.12374058\n",
      "Epoch: 1047 cost = 0.168957353\n",
      "Validation Loss: 0.12382481\n",
      "Epoch: 1048 cost = 0.168958153\n",
      "Validation Loss: 0.13225383\n",
      "Epoch: 1049 cost = 0.168934839\n",
      "Validation Loss: 0.13103399\n",
      "Epoch: 1050 cost = 0.168935657\n",
      "Validation Loss: 0.13166532\n",
      "Epoch: 1051 cost = 0.168912607\n",
      "Validation Loss: 0.15813218\n",
      "Epoch: 1052 cost = 0.168913420\n",
      "Validation Loss: 0.15189743\n",
      "Epoch: 1053 cost = 0.168890627\n",
      "Validation Loss: 0.1379289\n",
      "Epoch: 1054 cost = 0.168891449\n",
      "Validation Loss: 0.12950568\n",
      "Epoch: 1055 cost = 0.168868955\n",
      "Validation Loss: 0.13087508\n",
      "Epoch: 1056 cost = 0.168869789\n",
      "Validation Loss: 0.12672058\n",
      "Epoch: 1057 cost = 0.168847491\n",
      "Validation Loss: 0.12907332\n",
      "Epoch: 1058 cost = 0.168848349\n",
      "Validation Loss: 0.13095929\n",
      "Epoch: 1059 cost = 0.168826310\n",
      "Validation Loss: 0.1305674\n",
      "Epoch: 1060 cost = 0.168827195\n",
      "Validation Loss: 0.1279822\n",
      "Epoch: 1061 cost = 0.168805397\n",
      "Validation Loss: 0.13367659\n",
      "Epoch: 1062 cost = 0.168806302\n",
      "Validation Loss: 0.14209366\n",
      "Epoch: 1063 cost = 0.168784718\n",
      "Validation Loss: 0.1466782\n",
      "Epoch: 1064 cost = 0.168785661\n",
      "Validation Loss: 0.13551435\n",
      "Epoch: 1065 cost = 0.168764295\n",
      "Validation Loss: 0.12591293\n",
      "Epoch: 1066 cost = 0.168765258\n",
      "Validation Loss: 0.12513469\n",
      "Epoch: 1067 cost = 0.168744136\n",
      "Validation Loss: 0.12403922\n",
      "Epoch: 1068 cost = 0.168745090\n",
      "Validation Loss: 0.12352661\n",
      "Epoch: 1069 cost = 0.168724192\n",
      "Validation Loss: 0.12752822\n",
      "Epoch: 1070 cost = 0.168725190\n",
      "Validation Loss: 0.1318052\n",
      "Epoch: 1071 cost = 0.168704474\n",
      "Validation Loss: 0.12813553\n",
      "Epoch: 1072 cost = 0.168705485\n",
      "Validation Loss: 0.12587692\n",
      "Epoch: 1073 cost = 0.168684976\n",
      "Validation Loss: 0.12420035\n",
      "Epoch: 1074 cost = 0.168686086\n",
      "Validation Loss: 0.12458869\n",
      "Epoch: 1075 cost = 0.168665771\n",
      "Validation Loss: 0.12631421\n",
      "Epoch: 1076 cost = 0.168666895\n",
      "Validation Loss: 0.13406111\n",
      "Epoch: 1077 cost = 0.168646727\n",
      "Validation Loss: 0.13047814\n",
      "Epoch: 1078 cost = 0.168647890\n",
      "Validation Loss: 0.128088\n",
      "Epoch: 1079 cost = 0.168627924\n",
      "Validation Loss: 0.12538955\n",
      "Epoch: 1080 cost = 0.168629133\n",
      "Validation Loss: 0.12649639\n",
      "Epoch: 1081 cost = 0.168609330\n",
      "Validation Loss: 0.12718914\n",
      "Epoch: 1082 cost = 0.168610579\n",
      "Validation Loss: 0.12526876\n",
      "Epoch: 1083 cost = 0.168590959\n",
      "Validation Loss: 0.124884404\n",
      "Epoch: 1084 cost = 0.168592247\n",
      "Validation Loss: 0.12580512\n",
      "Epoch: 1085 cost = 0.168572779\n",
      "Validation Loss: 0.13308494\n",
      "Epoch: 1086 cost = 0.168574125\n",
      "Validation Loss: 0.13179377\n",
      "Epoch: 1087 cost = 0.168554842\n",
      "Validation Loss: 0.1372367\n",
      "Epoch: 1088 cost = 0.168556211\n",
      "Validation Loss: 0.13303696\n",
      "Epoch: 1089 cost = 0.168537091\n",
      "Validation Loss: 0.12683712\n",
      "Epoch: 1090 cost = 0.168538528\n",
      "Validation Loss: 0.12426487\n",
      "Epoch: 1091 cost = 0.168519527\n",
      "Validation Loss: 0.124379665\n",
      "Epoch: 1092 cost = 0.168521027\n",
      "Validation Loss: 0.12500969\n",
      "Epoch: 1093 cost = 0.168502173\n",
      "Validation Loss: 0.12679563\n",
      "Epoch: 1094 cost = 0.168503725\n",
      "Validation Loss: 0.12664293\n",
      "Epoch: 1095 cost = 0.168484990\n",
      "Validation Loss: 0.13566414\n",
      "Epoch: 1096 cost = 0.168486612\n",
      "Validation Loss: 0.146098\n",
      "Epoch: 1097 cost = 0.168468035\n",
      "Validation Loss: 0.16101642\n",
      "Epoch: 1098 cost = 0.168469684\n",
      "Validation Loss: 0.13663325\n",
      "Epoch: 1099 cost = 0.168451241\n",
      "Validation Loss: 0.1337409\n",
      "Epoch: 1100 cost = 0.168452970\n",
      "Validation Loss: 0.14228909\n",
      "Epoch: 1101 cost = 0.168434637\n",
      "Validation Loss: 0.15358509\n",
      "Epoch: 1102 cost = 0.168436429\n",
      "Validation Loss: 0.14111142\n",
      "Epoch: 1103 cost = 0.168418184\n",
      "Validation Loss: 0.12952684\n",
      "Epoch: 1104 cost = 0.168420036\n",
      "Validation Loss: 0.123692416\n",
      "Epoch: 1105 cost = 0.168401944\n",
      "Validation Loss: 0.12617144\n",
      "Epoch: 1106 cost = 0.168403862\n",
      "Validation Loss: 0.12773027\n",
      "Epoch: 1107 cost = 0.168385868\n",
      "Validation Loss: 0.12731762\n",
      "Epoch: 1108 cost = 0.168387864\n",
      "Validation Loss: 0.12881495\n",
      "Epoch: 1109 cost = 0.168369989\n",
      "Validation Loss: 0.12870196\n",
      "Epoch: 1110 cost = 0.168372020\n",
      "Validation Loss: 0.12643127\n",
      "Epoch: 1111 cost = 0.168354217\n",
      "Validation Loss: 0.12936342\n",
      "Epoch: 1112 cost = 0.168356333\n",
      "Validation Loss: 0.133589\n",
      "Epoch: 1113 cost = 0.168338693\n",
      "Validation Loss: 0.14363064\n",
      "Epoch: 1114 cost = 0.168340838\n",
      "Validation Loss: 0.13092446\n",
      "Epoch: 1115 cost = 0.168323285\n",
      "Validation Loss: 0.12523036\n",
      "Epoch: 1116 cost = 0.168325524\n",
      "Validation Loss: 0.12459299\n",
      "Epoch: 1117 cost = 0.168308007\n",
      "Validation Loss: 0.13260558\n",
      "Epoch: 1118 cost = 0.168310331\n",
      "Validation Loss: 0.13168469\n",
      "Epoch: 1119 cost = 0.168292933\n",
      "Validation Loss: 0.13287173\n",
      "Epoch: 1120 cost = 0.168295317\n",
      "Validation Loss: 0.13180089\n",
      "Epoch: 1121 cost = 0.168277998\n",
      "Validation Loss: 0.12704644\n",
      "Epoch: 1122 cost = 0.168280455\n",
      "Validation Loss: 0.12902932\n",
      "Epoch: 1123 cost = 0.168263229\n",
      "Validation Loss: 0.12908138\n",
      "Epoch: 1124 cost = 0.168265745\n",
      "Validation Loss: 0.12638213\n",
      "Epoch: 1125 cost = 0.168248617\n",
      "Validation Loss: 0.1298695\n",
      "Epoch: 1126 cost = 0.168251172\n",
      "Validation Loss: 0.12517978\n",
      "Epoch: 1127 cost = 0.168234131\n",
      "Validation Loss: 0.12714997\n",
      "Epoch: 1128 cost = 0.168236756\n",
      "Validation Loss: 0.1319073\n",
      "Epoch: 1129 cost = 0.168219775\n",
      "Validation Loss: 0.13009998\n",
      "Epoch: 1130 cost = 0.168222489\n",
      "Validation Loss: 0.1248853\n",
      "Epoch: 1131 cost = 0.168205581\n",
      "Validation Loss: 0.1275119\n",
      "Epoch: 1132 cost = 0.168208363\n",
      "Validation Loss: 0.1310665\n",
      "Epoch: 1133 cost = 0.168191529\n",
      "Validation Loss: 0.12621075\n",
      "Epoch: 1134 cost = 0.168194341\n",
      "Validation Loss: 0.13093807\n",
      "Epoch: 1135 cost = 0.168177611\n",
      "Validation Loss: 0.12618883\n",
      "Epoch: 1136 cost = 0.168180493\n",
      "Validation Loss: 0.12904908\n",
      "Epoch: 1137 cost = 0.168163851\n",
      "Validation Loss: 0.1307941\n",
      "Epoch: 1138 cost = 0.168166765\n",
      "Validation Loss: 0.12537493\n",
      "Epoch: 1139 cost = 0.168150172\n",
      "Validation Loss: 0.12604713\n",
      "Epoch: 1140 cost = 0.168153173\n",
      "Validation Loss: 0.13171335\n",
      "Epoch: 1141 cost = 0.168136661\n",
      "Validation Loss: 0.13162372\n",
      "Epoch: 1142 cost = 0.168139728\n",
      "Validation Loss: 0.1267375\n",
      "Epoch: 1143 cost = 0.168123267\n",
      "Validation Loss: 0.124320254\n",
      "Epoch: 1144 cost = 0.168126347\n",
      "Validation Loss: 0.12563793\n",
      "Epoch: 1145 cost = 0.168109994\n",
      "Validation Loss: 0.1309194\n",
      "Epoch: 1146 cost = 0.168113134\n",
      "Validation Loss: 0.13193013\n",
      "Epoch: 1147 cost = 0.168096840\n",
      "Validation Loss: 0.124856815\n",
      "Epoch: 1148 cost = 0.168100040\n",
      "Validation Loss: 0.12563485\n",
      "Epoch: 1149 cost = 0.168083817\n",
      "Validation Loss: 0.12449656\n",
      "Epoch: 1150 cost = 0.168087065\n",
      "Validation Loss: 0.13084505\n",
      "Epoch: 1151 cost = 0.168070908\n",
      "Validation Loss: 0.14611173\n",
      "Epoch: 1152 cost = 0.168074208\n",
      "Validation Loss: 0.14782967\n",
      "Epoch: 1153 cost = 0.168058134\n",
      "Validation Loss: 0.14047761\n",
      "Epoch: 1154 cost = 0.168061452\n",
      "Validation Loss: 0.13724923\n",
      "Epoch: 1155 cost = 0.168045448\n",
      "Validation Loss: 0.1444586\n",
      "Epoch: 1156 cost = 0.168048829\n",
      "Validation Loss: 0.13034411\n",
      "Epoch: 1157 cost = 0.168032902\n",
      "Validation Loss: 0.13284233\n",
      "Epoch: 1158 cost = 0.168036301\n",
      "Validation Loss: 0.12967816\n",
      "Epoch: 1159 cost = 0.168020429\n",
      "Validation Loss: 0.12542716\n",
      "Epoch: 1160 cost = 0.168023884\n",
      "Validation Loss: 0.1266985\n",
      "Epoch: 1161 cost = 0.168008106\n",
      "Validation Loss: 0.12509169\n",
      "Epoch: 1162 cost = 0.168011578\n",
      "Validation Loss: 0.12678243\n",
      "Epoch: 1163 cost = 0.167995864\n",
      "Validation Loss: 0.13189386\n",
      "Epoch: 1164 cost = 0.167999404\n",
      "Validation Loss: 0.12859778\n",
      "Epoch: 1165 cost = 0.167983724\n",
      "Validation Loss: 0.12620264\n",
      "Epoch: 1166 cost = 0.167987291\n",
      "Validation Loss: 0.124772206\n",
      "Epoch: 1167 cost = 0.167971700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1257978\n",
      "Epoch: 1168 cost = 0.167975283\n",
      "Validation Loss: 0.12494319\n",
      "Epoch: 1169 cost = 0.167959765\n",
      "Validation Loss: 0.12692769\n",
      "Epoch: 1170 cost = 0.167963415\n",
      "Validation Loss: 0.12410381\n",
      "Epoch: 1171 cost = 0.167947986\n",
      "Validation Loss: 0.12328173\n",
      "Epoch: 1172 cost = 0.167951603\n",
      "Validation Loss: 0.13220076\n",
      "Epoch: 1173 cost = 0.167936225\n",
      "Validation Loss: 0.13972883\n",
      "Epoch: 1174 cost = 0.167939895\n",
      "Validation Loss: 0.13285603\n",
      "Epoch: 1175 cost = 0.167924611\n",
      "Validation Loss: 0.12667868\n",
      "Epoch: 1176 cost = 0.167928285\n",
      "Validation Loss: 0.12576067\n",
      "Epoch: 1177 cost = 0.167913071\n",
      "Validation Loss: 0.12338441\n",
      "Epoch: 1178 cost = 0.167916815\n",
      "Validation Loss: 0.12583178\n",
      "Epoch: 1179 cost = 0.167901612\n",
      "Validation Loss: 0.12862433\n",
      "Epoch: 1180 cost = 0.167905412\n",
      "Validation Loss: 0.12284352\n",
      "Epoch: 1181 cost = 0.167890259\n",
      "Validation Loss: 0.12805793\n",
      "Epoch: 1182 cost = 0.167894078\n",
      "Validation Loss: 0.13165045\n",
      "Epoch: 1183 cost = 0.167879000\n",
      "Validation Loss: 0.13228899\n",
      "Epoch: 1184 cost = 0.167882872\n",
      "Validation Loss: 0.1294143\n",
      "Epoch: 1185 cost = 0.167867820\n",
      "Validation Loss: 0.14315663\n",
      "Epoch: 1186 cost = 0.167871675\n",
      "Validation Loss: 0.14137469\n",
      "Epoch: 1187 cost = 0.167856783\n",
      "Validation Loss: 0.13723685\n",
      "Epoch: 1188 cost = 0.167860651\n",
      "Validation Loss: 0.13007168\n",
      "Epoch: 1189 cost = 0.167845762\n",
      "Validation Loss: 0.13042405\n",
      "Epoch: 1190 cost = 0.167849679\n",
      "Validation Loss: 0.14637072\n",
      "Epoch: 1191 cost = 0.167834844\n",
      "Validation Loss: 0.1519381\n",
      "Epoch: 1192 cost = 0.167838829\n",
      "Validation Loss: 0.13552758\n",
      "Epoch: 1193 cost = 0.167824021\n",
      "Validation Loss: 0.12630779\n",
      "Epoch: 1194 cost = 0.167828009\n",
      "Validation Loss: 0.12723266\n",
      "Epoch: 1195 cost = 0.167813259\n",
      "Validation Loss: 0.12580141\n",
      "Epoch: 1196 cost = 0.167817284\n",
      "Validation Loss: 0.12388547\n",
      "Epoch: 1197 cost = 0.167802613\n",
      "Validation Loss: 0.12619434\n",
      "Epoch: 1198 cost = 0.167806653\n",
      "Validation Loss: 0.13477029\n",
      "Epoch: 1199 cost = 0.167792012\n",
      "Validation Loss: 0.14163752\n",
      "Epoch: 1200 cost = 0.167796116\n",
      "Validation Loss: 0.124941714\n",
      "Epoch: 1201 cost = 0.167781466\n",
      "Validation Loss: 0.12231749\n",
      "Epoch: 1202 cost = 0.167785600\n",
      "Validation Loss: 0.12703869\n",
      "Epoch: 1203 cost = 0.167771001\n",
      "Validation Loss: 0.12323051\n",
      "Epoch: 1204 cost = 0.167775214\n",
      "Validation Loss: 0.123557195\n",
      "Epoch: 1205 cost = 0.167760662\n",
      "Validation Loss: 0.122708626\n",
      "Epoch: 1206 cost = 0.167764879\n",
      "Validation Loss: 0.12532902\n",
      "Epoch: 1207 cost = 0.167750339\n",
      "Validation Loss: 0.1418721\n",
      "Epoch: 1208 cost = 0.167754627\n",
      "Validation Loss: 0.1461649\n",
      "Epoch: 1209 cost = 0.167740117\n",
      "Validation Loss: 0.13963087\n",
      "Epoch: 1210 cost = 0.167744439\n",
      "Validation Loss: 0.15097864\n",
      "Epoch: 1211 cost = 0.167729959\n",
      "Validation Loss: 0.16716191\n",
      "Epoch: 1212 cost = 0.167734314\n",
      "Validation Loss: 0.14970781\n",
      "Epoch: 1213 cost = 0.167719815\n",
      "Validation Loss: 0.14191784\n",
      "Epoch: 1214 cost = 0.167724286\n",
      "Validation Loss: 0.13163134\n",
      "Epoch: 1215 cost = 0.167709789\n",
      "Validation Loss: 0.1339703\n",
      "Epoch: 1216 cost = 0.167714266\n",
      "Validation Loss: 0.12754303\n",
      "Epoch: 1217 cost = 0.167699805\n",
      "Validation Loss: 0.13316394\n",
      "Epoch: 1218 cost = 0.167704357\n",
      "Validation Loss: 0.13058683\n",
      "Epoch: 1219 cost = 0.167689902\n",
      "Validation Loss: 0.13209844\n",
      "Epoch: 1220 cost = 0.167694477\n",
      "Validation Loss: 0.1298701\n",
      "Epoch: 1221 cost = 0.167680010\n",
      "Validation Loss: 0.1263856\n",
      "Epoch: 1222 cost = 0.167684657\n",
      "Validation Loss: 0.12457978\n",
      "Epoch: 1223 cost = 0.167670169\n",
      "Validation Loss: 0.1384964\n",
      "Epoch: 1224 cost = 0.167674882\n",
      "Validation Loss: 0.12523744\n",
      "Epoch: 1225 cost = 0.167660396\n",
      "Validation Loss: 0.12498877\n",
      "Epoch: 1226 cost = 0.167665179\n",
      "Validation Loss: 0.1252381\n",
      "Epoch: 1227 cost = 0.167650670\n",
      "Validation Loss: 0.12705716\n",
      "Epoch: 1228 cost = 0.167655506\n",
      "Validation Loss: 0.12365413\n",
      "Epoch: 1229 cost = 0.167640959\n",
      "Validation Loss: 0.12361843\n",
      "Epoch: 1230 cost = 0.167645863\n",
      "Validation Loss: 0.12372769\n",
      "Epoch: 1231 cost = 0.167631313\n",
      "Validation Loss: 0.12499155\n",
      "Epoch: 1232 cost = 0.167636290\n",
      "Validation Loss: 0.13135192\n",
      "Epoch: 1233 cost = 0.167621668\n",
      "Validation Loss: 0.13114959\n",
      "Epoch: 1234 cost = 0.167626668\n",
      "Validation Loss: 0.12462193\n",
      "Epoch: 1235 cost = 0.167612095\n",
      "Validation Loss: 0.12663287\n",
      "Epoch: 1236 cost = 0.167617191\n",
      "Validation Loss: 0.1270419\n",
      "Epoch: 1237 cost = 0.167602501\n",
      "Validation Loss: 0.12297746\n",
      "Epoch: 1238 cost = 0.167607644\n",
      "Validation Loss: 0.1237957\n",
      "Epoch: 1239 cost = 0.167592907\n",
      "Validation Loss: 0.12273232\n",
      "Epoch: 1240 cost = 0.167598111\n",
      "Validation Loss: 0.12882385\n",
      "Epoch: 1241 cost = 0.167583302\n",
      "Validation Loss: 0.13086587\n",
      "Epoch: 1242 cost = 0.167588585\n",
      "Validation Loss: 0.13075842\n",
      "Epoch: 1243 cost = 0.167573735\n",
      "Validation Loss: 0.12777436\n",
      "Epoch: 1244 cost = 0.167579051\n",
      "Validation Loss: 0.13135743\n",
      "Epoch: 1245 cost = 0.167564120\n",
      "Validation Loss: 0.12945816\n",
      "Epoch: 1246 cost = 0.167569518\n",
      "Validation Loss: 0.1289516\n",
      "Epoch: 1247 cost = 0.167554436\n",
      "Validation Loss: 0.14179596\n",
      "Epoch: 1248 cost = 0.167559915\n",
      "Validation Loss: 0.12765692\n",
      "Epoch: 1249 cost = 0.167544744\n",
      "Validation Loss: 0.12444623\n",
      "Epoch: 1250 cost = 0.167550200\n",
      "Validation Loss: 0.12781653\n",
      "Epoch: 1251 cost = 0.167534920\n",
      "Validation Loss: 0.1227354\n",
      "Epoch: 1252 cost = 0.167540437\n",
      "Validation Loss: 0.123166904\n",
      "Epoch: 1253 cost = 0.167524998\n",
      "Validation Loss: 0.12427583\n",
      "Epoch: 1254 cost = 0.167530554\n",
      "Validation Loss: 0.12751812\n",
      "Epoch: 1255 cost = 0.167514916\n",
      "Validation Loss: 0.12716359\n",
      "Epoch: 1256 cost = 0.167520466\n",
      "Validation Loss: 0.12406539\n",
      "Epoch: 1257 cost = 0.167504647\n",
      "Validation Loss: 0.12557475\n",
      "Epoch: 1258 cost = 0.167510173\n",
      "Validation Loss: 0.12529397\n",
      "Epoch: 1259 cost = 0.167494097\n",
      "Validation Loss: 0.12410676\n",
      "Epoch: 1260 cost = 0.167499589\n",
      "Validation Loss: 0.12396099\n",
      "Epoch: 1261 cost = 0.167483240\n",
      "Validation Loss: 0.13504753\n",
      "Epoch: 1262 cost = 0.167488662\n",
      "Validation Loss: 0.1472135\n",
      "Epoch: 1263 cost = 0.167471979\n",
      "Validation Loss: 0.15636538\n",
      "Epoch: 1264 cost = 0.167477308\n",
      "Validation Loss: 0.15002061\n",
      "Epoch: 1265 cost = 0.167460201\n",
      "Validation Loss: 0.13243125\n",
      "Epoch: 1266 cost = 0.167465399\n",
      "Validation Loss: 0.12541527\n",
      "Epoch: 1267 cost = 0.167447874\n",
      "Validation Loss: 0.12818857\n",
      "Epoch: 1268 cost = 0.167452951\n",
      "Validation Loss: 0.1379252\n",
      "Epoch: 1269 cost = 0.167434939\n",
      "Validation Loss: 0.17146432\n",
      "Epoch: 1270 cost = 0.167439887\n",
      "Validation Loss: 0.16810365\n",
      "Epoch: 1271 cost = 0.167421454\n",
      "Validation Loss: 0.13890457\n",
      "Epoch: 1272 cost = 0.167426337\n",
      "Validation Loss: 0.12312312\n",
      "Epoch: 1273 cost = 0.167407517\n",
      "Validation Loss: 0.12304897\n",
      "Epoch: 1274 cost = 0.167412490\n",
      "Validation Loss: 0.12789531\n",
      "Epoch: 1275 cost = 0.167393418\n",
      "Validation Loss: 0.15650706\n",
      "Epoch: 1276 cost = 0.167398568\n",
      "Validation Loss: 0.16770947\n",
      "Epoch: 1277 cost = 0.167379307\n",
      "Validation Loss: 0.16470978\n",
      "Epoch: 1278 cost = 0.167384808\n",
      "Validation Loss: 0.15107612\n",
      "Epoch: 1279 cost = 0.167365402\n",
      "Validation Loss: 0.14816996\n",
      "Epoch: 1280 cost = 0.167371265\n",
      "Validation Loss: 0.1418176\n",
      "Epoch: 1281 cost = 0.167351797\n",
      "Validation Loss: 0.14118467\n",
      "Epoch: 1282 cost = 0.167358015\n",
      "Validation Loss: 0.13011453\n",
      "Epoch: 1283 cost = 0.167338469\n",
      "Validation Loss: 0.1265872\n",
      "Epoch: 1284 cost = 0.167344970\n",
      "Validation Loss: 0.12278539\n",
      "Epoch: 1285 cost = 0.167325329\n",
      "Validation Loss: 0.1396229\n",
      "Epoch: 1286 cost = 0.167332113\n",
      "Validation Loss: 0.14240159\n",
      "Epoch: 1287 cost = 0.167312326\n",
      "Validation Loss: 0.14899734\n",
      "Epoch: 1288 cost = 0.167319285\n",
      "Validation Loss: 0.13640697\n",
      "Epoch: 1289 cost = 0.167299286\n",
      "Validation Loss: 0.13706711\n",
      "Epoch: 1290 cost = 0.167306323\n",
      "Validation Loss: 0.1282496\n",
      "Epoch: 1291 cost = 0.167286145\n",
      "Validation Loss: 0.1243558\n",
      "Epoch: 1292 cost = 0.167293148\n",
      "Validation Loss: 0.12542555\n",
      "Epoch: 1293 cost = 0.167272670\n",
      "Validation Loss: 0.12578802\n",
      "Epoch: 1294 cost = 0.167279507\n",
      "Validation Loss: 0.12435074\n",
      "Epoch: 1295 cost = 0.167258714\n",
      "Validation Loss: 0.1264643\n",
      "Epoch: 1296 cost = 0.167265243\n",
      "Validation Loss: 0.12597878\n",
      "Epoch: 1297 cost = 0.167243949\n",
      "Validation Loss: 0.12528028\n",
      "Epoch: 1298 cost = 0.167249984\n",
      "Validation Loss: 0.12289727\n",
      "Epoch: 1299 cost = 0.167228075\n",
      "Validation Loss: 0.12545957\n",
      "Epoch: 1300 cost = 0.167233310\n",
      "Validation Loss: 0.1312383\n",
      "Epoch: 1301 cost = 0.167210402\n",
      "Validation Loss: 0.16174576\n",
      "Epoch: 1302 cost = 0.167214381\n",
      "Validation Loss: 0.16127737\n",
      "Epoch: 1303 cost = 0.167189871\n",
      "Validation Loss: 0.15646152\n",
      "Epoch: 1304 cost = 0.167191746\n",
      "Validation Loss: 0.14348021\n",
      "Epoch: 1305 cost = 0.167164426\n",
      "Validation Loss: 0.12833364\n",
      "Epoch: 1306 cost = 0.167162382\n",
      "Validation Loss: 0.12640883\n",
      "Epoch: 1307 cost = 0.167129412\n",
      "Validation Loss: 0.12694559\n",
      "Epoch: 1308 cost = 0.167119277\n",
      "Validation Loss: 0.12872086\n",
      "Epoch: 1309 cost = 0.167073397\n",
      "Validation Loss: 0.12893625\n",
      "Epoch: 1310 cost = 0.167043250\n",
      "Validation Loss: 0.123334885\n",
      "Epoch: 1311 cost = 0.166962368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.12534185\n",
      "Epoch: 1312 cost = 0.166873378\n",
      "Validation Loss: 0.13034539\n",
      "Epoch: 1313 cost = 0.166683518\n",
      "Validation Loss: 0.13312002\n",
      "Epoch: 1314 cost = 0.166413135\n",
      "Validation Loss: 0.13223849\n",
      "Epoch: 1315 cost = 0.165956587\n",
      "Validation Loss: 0.12715976\n",
      "Epoch: 1316 cost = 0.165523772\n",
      "Validation Loss: 0.1278456\n",
      "Epoch: 1317 cost = 0.165191114\n",
      "Validation Loss: 0.1262313\n",
      "Epoch: 1318 cost = 0.165027139\n",
      "Validation Loss: 0.12648003\n",
      "Epoch: 1319 cost = 0.164827225\n",
      "Validation Loss: 0.1659992\n",
      "Epoch: 1320 cost = 0.164671374\n",
      "Validation Loss: 0.1635369\n",
      "Epoch: 1321 cost = 0.164515127\n",
      "Validation Loss: 0.16877851\n",
      "Epoch: 1322 cost = 0.164442807\n",
      "Validation Loss: 0.15220611\n",
      "Epoch: 1323 cost = 0.164318740\n",
      "Validation Loss: 0.12751989\n",
      "Epoch: 1324 cost = 0.164265218\n",
      "Validation Loss: 0.12889549\n",
      "Epoch: 1325 cost = 0.164139884\n",
      "Validation Loss: 0.13496113\n",
      "Epoch: 1326 cost = 0.164089033\n",
      "Validation Loss: 0.13708559\n",
      "Epoch: 1327 cost = 0.163951329\n",
      "Validation Loss: 0.122140035\n",
      "Epoch: 1328 cost = 0.163898104\n",
      "Validation Loss: 0.13116826\n",
      "Epoch: 1329 cost = 0.163742981\n",
      "Validation Loss: 0.12301546\n",
      "Epoch: 1330 cost = 0.163685411\n",
      "Validation Loss: 0.1374263\n",
      "Epoch: 1331 cost = 0.163514593\n",
      "Validation Loss: 0.13746193\n",
      "Epoch: 1332 cost = 0.163459908\n",
      "Validation Loss: 0.13612151\n",
      "Epoch: 1333 cost = 0.163291456\n",
      "Validation Loss: 0.12889367\n",
      "Epoch: 1334 cost = 0.163256105\n",
      "Validation Loss: 0.11879737\n",
      "Epoch: 1335 cost = 0.163105224\n",
      "Validation Loss: 0.12819885\n",
      "Epoch: 1336 cost = 0.163092430\n",
      "Validation Loss: 0.122983545\n",
      "Epoch: 1337 cost = 0.162956998\n",
      "Validation Loss: 0.13293259\n",
      "Epoch: 1338 cost = 0.162960378\n",
      "Validation Loss: 0.12705025\n",
      "Epoch: 1339 cost = 0.162833203\n",
      "Validation Loss: 0.12845846\n",
      "Epoch: 1340 cost = 0.162848724\n",
      "Validation Loss: 0.12424552\n",
      "Epoch: 1341 cost = 0.162724229\n",
      "Validation Loss: 0.11811917\n",
      "Epoch: 1342 cost = 0.162749167\n",
      "Validation Loss: 0.13124983\n",
      "Epoch: 1343 cost = 0.162622154\n",
      "Validation Loss: 0.13457313\n",
      "Epoch: 1344 cost = 0.162652363\n",
      "Validation Loss: 0.13083518\n",
      "Epoch: 1345 cost = 0.162516075\n",
      "Validation Loss: 0.12221745\n",
      "Epoch: 1346 cost = 0.162545734\n",
      "Validation Loss: 0.13358974\n",
      "Epoch: 1347 cost = 0.162389902\n",
      "Validation Loss: 0.13708037\n",
      "Epoch: 1348 cost = 0.162408486\n",
      "Validation Loss: 0.12639213\n",
      "Epoch: 1349 cost = 0.162210318\n",
      "Validation Loss: 0.14413364\n",
      "Epoch: 1350 cost = 0.162183048\n",
      "Validation Loss: 0.123413764\n",
      "Epoch: 1351 cost = 0.161867438\n",
      "Validation Loss: 0.116551556\n",
      "Epoch: 1352 cost = 0.161705773\n",
      "Validation Loss: 0.10517255\n",
      "Epoch: 1353 cost = 0.161274793\n",
      "Validation Loss: 0.109810196\n",
      "Epoch: 1354 cost = 0.161012779\n",
      "Validation Loss: 0.10696385\n",
      "Epoch: 1355 cost = 0.160325338\n",
      "Validation Loss: 0.106197044\n",
      "Epoch: 1356 cost = 0.159669346\n",
      "Validation Loss: 0.10034538\n",
      "Epoch: 1357 cost = 0.158283489\n",
      "Validation Loss: 0.13097021\n",
      "Epoch: 1358 cost = 0.155972332\n",
      "Validation Loss: 0.11645241\n",
      "Epoch: 1359 cost = 0.152196373\n",
      "Validation Loss: 0.1073499\n",
      "Epoch: 1360 cost = 0.148302977\n",
      "Validation Loss: 0.11896891\n",
      "Epoch: 1361 cost = 0.146042446\n",
      "Validation Loss: 0.20102988\n",
      "Epoch: 1362 cost = 0.144576182\n",
      "Validation Loss: 0.16661847\n",
      "Epoch: 1363 cost = 0.143568744\n",
      "Validation Loss: 0.11495024\n",
      "Epoch: 1364 cost = 0.142604736\n",
      "Validation Loss: 0.122037396\n",
      "Epoch: 1365 cost = 0.141859007\n",
      "Validation Loss: 0.116627984\n",
      "Epoch: 1366 cost = 0.141192092\n",
      "Validation Loss: 0.10746982\n",
      "Epoch: 1367 cost = 0.140679175\n",
      "Validation Loss: 0.1304071\n",
      "Epoch: 1368 cost = 0.140171216\n",
      "Validation Loss: 0.099081896\n",
      "Epoch: 1369 cost = 0.139770223\n",
      "Validation Loss: 0.14697532\n",
      "Epoch: 1370 cost = 0.139383255\n",
      "Validation Loss: 0.12921208\n",
      "Epoch: 1371 cost = 0.139069673\n",
      "Validation Loss: 0.10312671\n",
      "Epoch: 1372 cost = 0.138765699\n",
      "Validation Loss: 0.095286876\n",
      "Epoch: 1373 cost = 0.138479471\n",
      "Validation Loss: 0.10200642\n",
      "Epoch: 1374 cost = 0.138195887\n",
      "Validation Loss: 0.10345015\n",
      "Epoch: 1375 cost = 0.137891932\n",
      "Validation Loss: 0.109090075\n",
      "Epoch: 1376 cost = 0.137537712\n",
      "Validation Loss: 0.12079179\n",
      "Epoch: 1377 cost = 0.136965827\n",
      "Validation Loss: 0.17076659\n",
      "Epoch: 1378 cost = 0.135787530\n",
      "Validation Loss: 0.20082915\n",
      "Epoch: 1379 cost = 0.133928896\n",
      "Validation Loss: 0.39289084\n",
      "Epoch: 1380 cost = 0.130731215\n",
      "Validation Loss: 0.4254354\n",
      "Epoch: 1381 cost = 0.128082959\n",
      "Validation Loss: 0.1981165\n",
      "Epoch: 1382 cost = 0.125608620\n",
      "Validation Loss: 0.15841153\n",
      "Epoch: 1383 cost = 0.124054129\n",
      "Validation Loss: 0.25448036\n",
      "Epoch: 1384 cost = 0.122629155\n",
      "Validation Loss: 0.37146533\n",
      "Epoch: 1385 cost = 0.121437564\n",
      "Validation Loss: 0.16753103\n",
      "Epoch: 1386 cost = 0.120419546\n",
      "Validation Loss: 0.11373456\n",
      "Epoch: 1387 cost = 0.119538035\n",
      "Validation Loss: 0.11347011\n",
      "Epoch: 1388 cost = 0.118750185\n",
      "Validation Loss: 0.12263346\n",
      "Epoch: 1389 cost = 0.118035829\n",
      "Validation Loss: 0.12162529\n",
      "Epoch: 1390 cost = 0.117303403\n",
      "Validation Loss: 0.19919242\n",
      "Epoch: 1391 cost = 0.116526625\n",
      "Validation Loss: 0.26863977\n",
      "Epoch: 1392 cost = 0.115714021\n",
      "Validation Loss: 0.20201331\n",
      "Epoch: 1393 cost = 0.115064124\n",
      "Validation Loss: 0.16894405\n",
      "Epoch: 1394 cost = 0.114476148\n",
      "Validation Loss: 0.19516164\n",
      "Epoch: 1395 cost = 0.113821942\n",
      "Validation Loss: 0.5118424\n",
      "Epoch: 1396 cost = 0.113118737\n",
      "Validation Loss: 0.7613914\n",
      "Epoch: 1397 cost = 0.112626272\n",
      "Validation Loss: 1.0776728\n",
      "Epoch: 1398 cost = 0.112180542\n",
      "Validation Loss: 1.0697919\n",
      "Epoch: 1399 cost = 0.111785392\n",
      "Validation Loss: 0.8270701\n",
      "Epoch: 1400 cost = 0.111389344\n",
      "Validation Loss: 0.34214398\n",
      "Epoch: 1401 cost = 0.111004288\n",
      "Validation Loss: 0.2553794\n",
      "Epoch: 1402 cost = 0.110621255\n",
      "Validation Loss: 0.25903043\n",
      "Epoch: 1403 cost = 0.110206996\n",
      "Validation Loss: 0.37444043\n",
      "Epoch: 1404 cost = 0.109776238\n",
      "Validation Loss: 0.21899772\n",
      "Epoch: 1405 cost = 0.109336062\n",
      "Validation Loss: 0.14217918\n",
      "Epoch: 1406 cost = 0.108879162\n",
      "Validation Loss: 0.13704927\n",
      "Epoch: 1407 cost = 0.108413511\n",
      "Validation Loss: 0.14419669\n",
      "Epoch: 1408 cost = 0.107905490\n",
      "Validation Loss: 0.15148841\n",
      "Epoch: 1409 cost = 0.107505280\n",
      "Validation Loss: 0.1314875\n",
      "Epoch: 1410 cost = 0.107114235\n",
      "Validation Loss: 0.12492341\n",
      "Epoch: 1411 cost = 0.106758854\n",
      "Validation Loss: 0.11943149\n",
      "Epoch: 1412 cost = 0.106419171\n",
      "Validation Loss: 0.12185668\n",
      "Epoch: 1413 cost = 0.106103151\n",
      "Validation Loss: 0.12060716\n",
      "Epoch: 1414 cost = 0.105805511\n",
      "Validation Loss: 0.11937397\n",
      "Epoch: 1415 cost = 0.105535597\n",
      "Validation Loss: 0.116877675\n",
      "Epoch: 1416 cost = 0.105275126\n",
      "Validation Loss: 0.11658828\n",
      "Epoch: 1417 cost = 0.105027054\n",
      "Validation Loss: 0.1119409\n",
      "Epoch: 1418 cost = 0.104798576\n",
      "Validation Loss: 0.118397966\n",
      "Epoch: 1419 cost = 0.104577227\n",
      "Validation Loss: 0.11535987\n",
      "Epoch: 1420 cost = 0.104368019\n",
      "Validation Loss: 0.11718109\n",
      "Epoch: 1421 cost = 0.104170916\n",
      "Validation Loss: 0.11575498\n",
      "Epoch: 1422 cost = 0.103980098\n",
      "Validation Loss: 0.11170067\n",
      "Epoch: 1423 cost = 0.103799453\n",
      "Validation Loss: 0.12576273\n",
      "Epoch: 1424 cost = 0.103626525\n",
      "Validation Loss: 0.13234258\n",
      "Epoch: 1425 cost = 0.103459982\n",
      "Validation Loss: 0.12436438\n",
      "Epoch: 1426 cost = 0.103300706\n",
      "Validation Loss: 0.23245984\n",
      "Epoch: 1427 cost = 0.103147241\n",
      "Validation Loss: 0.30549413\n",
      "Epoch: 1428 cost = 0.102999068\n",
      "Validation Loss: 0.14928672\n",
      "Epoch: 1429 cost = 0.102856408\n",
      "Validation Loss: 0.12296209\n",
      "Epoch: 1430 cost = 0.102718046\n",
      "Validation Loss: 0.123001926\n",
      "Epoch: 1431 cost = 0.102584121\n",
      "Validation Loss: 0.10950825\n",
      "Epoch: 1432 cost = 0.102454262\n",
      "Validation Loss: 0.10489203\n",
      "Epoch: 1433 cost = 0.102327766\n",
      "Validation Loss: 0.10916041\n",
      "Epoch: 1434 cost = 0.102204526\n",
      "Validation Loss: 0.10259644\n",
      "Epoch: 1435 cost = 0.102084287\n",
      "Validation Loss: 0.10068863\n",
      "Epoch: 1436 cost = 0.101966494\n",
      "Validation Loss: 0.1173944\n",
      "Epoch: 1437 cost = 0.101850887\n",
      "Validation Loss: 0.12950817\n",
      "Epoch: 1438 cost = 0.101737247\n",
      "Validation Loss: 0.12826793\n",
      "Epoch: 1439 cost = 0.101625090\n",
      "Validation Loss: 0.123390935\n",
      "Epoch: 1440 cost = 0.101514104\n",
      "Validation Loss: 0.11390799\n",
      "Epoch: 1441 cost = 0.101403820\n",
      "Validation Loss: 0.17384058\n",
      "Epoch: 1442 cost = 0.101293821\n",
      "Validation Loss: 0.32601044\n",
      "Epoch: 1443 cost = 0.101183602\n",
      "Validation Loss: 0.22355737\n",
      "Epoch: 1444 cost = 0.101072537\n",
      "Validation Loss: 0.17101339\n",
      "Epoch: 1445 cost = 0.100959910\n",
      "Validation Loss: 0.13853627\n",
      "Epoch: 1446 cost = 0.100844744\n",
      "Validation Loss: 0.14343424\n",
      "Epoch: 1447 cost = 0.100725800\n",
      "Validation Loss: 0.1209705\n",
      "Epoch: 1448 cost = 0.100601409\n",
      "Validation Loss: 0.12957591\n",
      "Epoch: 1449 cost = 0.100468650\n",
      "Validation Loss: 0.13599259\n",
      "Epoch: 1450 cost = 0.100323789\n",
      "Validation Loss: 0.16090414\n",
      "Epoch: 1451 cost = 0.100161558\n",
      "Validation Loss: 0.11795951\n",
      "Epoch: 1452 cost = 0.099974561\n",
      "Validation Loss: 0.109131515\n",
      "Epoch: 1453 cost = 0.099755834\n",
      "Validation Loss: 0.105011575\n",
      "Epoch: 1454 cost = 0.099504949\n",
      "Validation Loss: 0.11364772\n",
      "Epoch: 1455 cost = 0.099226552\n",
      "Validation Loss: 0.10687461\n",
      "Epoch: 1456 cost = 0.098924122\n",
      "Validation Loss: 0.10820595\n",
      "Epoch: 1457 cost = 0.098583686\n",
      "Validation Loss: 0.108591326\n",
      "Epoch: 1458 cost = 0.098103413\n",
      "Validation Loss: 0.10658339\n",
      "Epoch: 1459 cost = 0.097154085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.15860897\n",
      "Epoch: 1460 cost = 0.095003531\n",
      "Validation Loss: 0.21880504\n",
      "Epoch: 1461 cost = 0.091059755\n",
      "Validation Loss: 0.7599693\n",
      "Epoch: 1462 cost = 0.088600261\n",
      "Validation Loss: 1.1614807\n",
      "Epoch: 1463 cost = 0.087090551\n",
      "Validation Loss: 0.78960824\n",
      "Epoch: 1464 cost = 0.084280276\n",
      "Validation Loss: 1.0437034\n",
      "Epoch: 1465 cost = 0.081525495\n",
      "Validation Loss: 1.3721405\n",
      "Epoch: 1466 cost = 0.080109893\n",
      "Validation Loss: 0.7900853\n",
      "Epoch: 1467 cost = 0.078543533\n",
      "Validation Loss: 0.7394631\n",
      "Epoch: 1468 cost = 0.077213315\n",
      "Validation Loss: 0.76207113\n",
      "Epoch: 1469 cost = 0.075998531\n",
      "Validation Loss: 0.2750957\n",
      "Epoch: 1470 cost = 0.074957276\n",
      "Validation Loss: 0.44695494\n",
      "Epoch: 1471 cost = 0.073999209\n",
      "Validation Loss: 0.17488854\n",
      "Epoch: 1472 cost = 0.073128814\n",
      "Validation Loss: 0.12671268\n",
      "Epoch: 1473 cost = 0.072311119\n",
      "Validation Loss: 0.1243459\n",
      "Epoch: 1474 cost = 0.071560957\n",
      "Validation Loss: 0.11263517\n",
      "Epoch: 1475 cost = 0.070862323\n",
      "Validation Loss: 0.10230221\n",
      "Epoch: 1476 cost = 0.070212056\n",
      "Validation Loss: 0.096601374\n",
      "Epoch: 1477 cost = 0.069593141\n",
      "Validation Loss: 0.12878549\n",
      "Epoch: 1478 cost = 0.069000974\n",
      "Validation Loss: 0.13575503\n",
      "Epoch: 1479 cost = 0.068420269\n",
      "Validation Loss: 0.1796384\n",
      "Epoch: 1480 cost = 0.067839224\n",
      "Validation Loss: 0.15061882\n",
      "Epoch: 1481 cost = 0.067255177\n",
      "Validation Loss: 0.11229582\n",
      "Epoch: 1482 cost = 0.066673875\n",
      "Validation Loss: 0.10657792\n",
      "Epoch: 1483 cost = 0.066070985\n",
      "Validation Loss: 0.10165316\n",
      "Epoch: 1484 cost = 0.065364299\n",
      "Validation Loss: 0.109723665\n",
      "Epoch: 1485 cost = 0.064414824\n",
      "Validation Loss: 0.14537431\n",
      "Epoch: 1486 cost = 0.063179120\n",
      "Validation Loss: 0.15481746\n",
      "Epoch: 1487 cost = 0.061867207\n",
      "Validation Loss: 0.112515084\n",
      "Epoch: 1488 cost = 0.060454777\n",
      "Validation Loss: 0.1301794\n",
      "Epoch: 1489 cost = 0.058791766\n",
      "Validation Loss: 0.19716452\n",
      "Epoch: 1490 cost = 0.056999608\n",
      "Validation Loss: 0.30835843\n",
      "Epoch: 1491 cost = 0.055115924\n",
      "Validation Loss: 0.20165123\n",
      "Epoch: 1492 cost = 0.053627228\n",
      "Validation Loss: 0.14821023\n",
      "Epoch: 1493 cost = 0.052566385\n",
      "Validation Loss: 0.09857142\n",
      "Epoch: 1494 cost = 0.051552118\n",
      "Validation Loss: 0.08630166\n",
      "Epoch: 1495 cost = 0.050653988\n",
      "Validation Loss: 0.103361145\n",
      "Epoch: 1496 cost = 0.049794400\n",
      "Validation Loss: 0.09630769\n",
      "Epoch: 1497 cost = 0.048992043\n",
      "Validation Loss: 0.10894702\n",
      "Epoch: 1498 cost = 0.048269491\n",
      "Validation Loss: 0.12878162\n",
      "Epoch: 1499 cost = 0.047606168\n",
      "Validation Loss: 0.09633061\n",
      "Epoch: 1500 cost = 0.047006856\n",
      "Validation Loss: 0.08508982\n",
      "Epoch: 1501 cost = 0.046463905\n",
      "Validation Loss: 0.18425539\n",
      "Epoch: 1502 cost = 0.045972173\n",
      "Validation Loss: 0.18290405\n",
      "Epoch: 1503 cost = 0.045514209\n",
      "Validation Loss: 0.1670401\n",
      "Epoch: 1504 cost = 0.045091519\n",
      "Validation Loss: 0.1263608\n",
      "Epoch: 1505 cost = 0.044689189\n",
      "Validation Loss: 0.08863177\n",
      "Epoch: 1506 cost = 0.044304118\n",
      "Validation Loss: 0.09117226\n",
      "Epoch: 1507 cost = 0.043948367\n",
      "Validation Loss: 0.082665175\n",
      "Epoch: 1508 cost = 0.043627324\n",
      "Validation Loss: 0.115049854\n",
      "Epoch: 1509 cost = 0.043333951\n",
      "Validation Loss: 0.16699524\n",
      "Epoch: 1510 cost = 0.043059704\n",
      "Validation Loss: 0.14397849\n",
      "Epoch: 1511 cost = 0.042801404\n",
      "Validation Loss: 0.48993146\n",
      "Epoch: 1512 cost = 0.042559155\n",
      "Validation Loss: 0.26936653\n",
      "Epoch: 1513 cost = 0.042331479\n",
      "Validation Loss: 0.08731222\n",
      "Epoch: 1514 cost = 0.042117322\n",
      "Validation Loss: 0.08086518\n",
      "Epoch: 1515 cost = 0.041914623\n",
      "Validation Loss: 0.091780126\n",
      "Epoch: 1516 cost = 0.041722736\n",
      "Validation Loss: 0.08699224\n",
      "Epoch: 1517 cost = 0.041540484\n",
      "Validation Loss: 0.078880474\n",
      "Epoch: 1518 cost = 0.041366711\n",
      "Validation Loss: 0.096193634\n",
      "Epoch: 1519 cost = 0.041200946\n",
      "Validation Loss: 0.09548187\n",
      "Epoch: 1520 cost = 0.041042500\n",
      "Validation Loss: 0.084973544\n",
      "Epoch: 1521 cost = 0.040890769\n",
      "Validation Loss: 0.070478715\n",
      "Epoch: 1522 cost = 0.040744937\n",
      "Validation Loss: 0.19317362\n",
      "Epoch: 1523 cost = 0.040604882\n",
      "Validation Loss: 0.12442548\n",
      "Epoch: 1524 cost = 0.040469666\n",
      "Validation Loss: 0.07804345\n",
      "Epoch: 1525 cost = 0.040339425\n",
      "Validation Loss: 0.071997315\n",
      "Epoch: 1526 cost = 0.040213174\n",
      "Validation Loss: 0.07024917\n",
      "Epoch: 1527 cost = 0.040091174\n",
      "Validation Loss: 0.09848162\n",
      "Epoch: 1528 cost = 0.039972680\n",
      "Validation Loss: 0.08207017\n",
      "Epoch: 1529 cost = 0.039857503\n",
      "Validation Loss: 0.20065789\n",
      "Epoch: 1530 cost = 0.039745564\n",
      "Validation Loss: 0.17051582\n",
      "Epoch: 1531 cost = 0.039636493\n",
      "Validation Loss: 0.08157611\n",
      "Epoch: 1532 cost = 0.039530237\n",
      "Validation Loss: 0.059742678\n",
      "Epoch: 1533 cost = 0.039426438\n",
      "Validation Loss: 0.09217064\n",
      "Epoch: 1534 cost = 0.039324877\n",
      "Validation Loss: 0.076619536\n",
      "Epoch: 1535 cost = 0.039225971\n",
      "Validation Loss: 0.07289123\n",
      "Epoch: 1536 cost = 0.039129203\n",
      "Validation Loss: 0.06788474\n",
      "Epoch: 1537 cost = 0.039034652\n",
      "Validation Loss: 0.071088165\n",
      "Epoch: 1538 cost = 0.038941908\n",
      "Validation Loss: 0.06318724\n",
      "Epoch: 1539 cost = 0.038851393\n",
      "Validation Loss: 0.12243492\n",
      "Epoch: 1540 cost = 0.038762623\n",
      "Validation Loss: 0.18764825\n",
      "Epoch: 1541 cost = 0.038675727\n",
      "Validation Loss: 0.202839\n",
      "Epoch: 1542 cost = 0.038590435\n",
      "Validation Loss: 0.1312125\n",
      "Epoch: 1543 cost = 0.038506655\n",
      "Validation Loss: 0.2169148\n",
      "Epoch: 1544 cost = 0.038424441\n",
      "Validation Loss: 0.22620155\n",
      "Epoch: 1545 cost = 0.038343597\n",
      "Validation Loss: 0.11028529\n",
      "Epoch: 1546 cost = 0.038263964\n",
      "Validation Loss: 0.10890563\n",
      "Epoch: 1547 cost = 0.038185523\n",
      "Validation Loss: 0.13677926\n",
      "Epoch: 1548 cost = 0.038108231\n",
      "Validation Loss: 0.18284157\n",
      "Epoch: 1549 cost = 0.038031963\n",
      "Validation Loss: 0.130297\n",
      "Epoch: 1550 cost = 0.037956581\n",
      "Validation Loss: 0.10953942\n",
      "Epoch: 1551 cost = 0.037882091\n",
      "Validation Loss: 0.12956622\n",
      "Epoch: 1552 cost = 0.037808162\n",
      "Validation Loss: 0.17627308\n",
      "Epoch: 1553 cost = 0.037735110\n",
      "Validation Loss: 0.19460648\n",
      "Epoch: 1554 cost = 0.037662511\n",
      "Validation Loss: 0.10983991\n",
      "Epoch: 1555 cost = 0.037590184\n",
      "Validation Loss: 0.15401395\n",
      "Epoch: 1556 cost = 0.037518473\n",
      "Validation Loss: 0.13774525\n",
      "Epoch: 1557 cost = 0.037446637\n",
      "Validation Loss: 0.18231535\n",
      "Epoch: 1558 cost = 0.037375033\n",
      "Validation Loss: 0.12504731\n",
      "Epoch: 1559 cost = 0.037303117\n",
      "Validation Loss: 0.14091656\n",
      "Epoch: 1560 cost = 0.037231017\n",
      "Validation Loss: 0.095237054\n",
      "Epoch: 1561 cost = 0.037158423\n",
      "Validation Loss: 0.07955023\n",
      "Epoch: 1562 cost = 0.037085160\n",
      "Validation Loss: 0.09144697\n",
      "Epoch: 1563 cost = 0.037011116\n",
      "Validation Loss: 0.12160383\n",
      "Epoch: 1564 cost = 0.036935846\n",
      "Validation Loss: 0.07302738\n",
      "Epoch: 1565 cost = 0.036859590\n",
      "Validation Loss: 0.057893805\n",
      "Epoch: 1566 cost = 0.036781646\n",
      "Validation Loss: 0.07749094\n",
      "Epoch: 1567 cost = 0.036702620\n",
      "Validation Loss: 0.066763215\n",
      "Epoch: 1568 cost = 0.036622222\n",
      "Validation Loss: 0.06743999\n",
      "Epoch: 1569 cost = 0.036540791\n",
      "Validation Loss: 0.08482752\n",
      "Epoch: 1570 cost = 0.036458659\n",
      "Validation Loss: 0.078123115\n",
      "Epoch: 1571 cost = 0.036376681\n",
      "Validation Loss: 0.060802672\n",
      "Epoch: 1572 cost = 0.036295138\n",
      "Validation Loss: 0.059289724\n",
      "Epoch: 1573 cost = 0.036214940\n",
      "Validation Loss: 0.055268448\n",
      "Epoch: 1574 cost = 0.036136360\n",
      "Validation Loss: 0.13274062\n",
      "Epoch: 1575 cost = 0.036059705\n",
      "Validation Loss: 0.12292426\n",
      "Epoch: 1576 cost = 0.035984967\n",
      "Validation Loss: 0.08529349\n",
      "Epoch: 1577 cost = 0.035912015\n",
      "Validation Loss: 0.060728\n",
      "Epoch: 1578 cost = 0.035840930\n",
      "Validation Loss: 0.074162014\n",
      "Epoch: 1579 cost = 0.035771437\n",
      "Validation Loss: 0.07996425\n",
      "Epoch: 1580 cost = 0.035703243\n",
      "Validation Loss: 0.07089802\n",
      "Epoch: 1581 cost = 0.035636571\n",
      "Validation Loss: 0.063954405\n",
      "Epoch: 1582 cost = 0.035570860\n",
      "Validation Loss: 0.063710965\n",
      "Epoch: 1583 cost = 0.035506514\n",
      "Validation Loss: 0.06833004\n",
      "Epoch: 1584 cost = 0.035442561\n",
      "Validation Loss: 0.073165834\n",
      "Epoch: 1585 cost = 0.035379512\n",
      "Validation Loss: 0.075465515\n",
      "Epoch: 1586 cost = 0.035316954\n",
      "Validation Loss: 0.068278775\n",
      "Epoch: 1587 cost = 0.035254814\n",
      "Validation Loss: 0.06331915\n",
      "Epoch: 1588 cost = 0.035193057\n",
      "Validation Loss: 0.0819738\n",
      "Epoch: 1589 cost = 0.035131308\n",
      "Validation Loss: 0.06611271\n",
      "Epoch: 1590 cost = 0.035070045\n",
      "Validation Loss: 0.060368743\n",
      "Epoch: 1591 cost = 0.035008753\n",
      "Validation Loss: 0.062147107\n",
      "Epoch: 1592 cost = 0.034948100\n",
      "Validation Loss: 0.069006726\n",
      "Epoch: 1593 cost = 0.034887422\n",
      "Validation Loss: 0.09164838\n",
      "Epoch: 1594 cost = 0.034827696\n",
      "Validation Loss: 0.09908906\n",
      "Epoch: 1595 cost = 0.034768296\n",
      "Validation Loss: 0.071482465\n",
      "Epoch: 1596 cost = 0.034709730\n",
      "Validation Loss: 0.06858997\n",
      "Epoch: 1597 cost = 0.034651729\n",
      "Validation Loss: 0.058928575\n",
      "Epoch: 1598 cost = 0.034594720\n",
      "Validation Loss: 0.050261877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1599 cost = 0.034538175\n",
      "Validation Loss: 0.06756195\n",
      "Epoch: 1600 cost = 0.034482476\n",
      "Validation Loss: 0.053035803\n",
      "Epoch: 1601 cost = 0.034427437\n",
      "Validation Loss: 0.064418115\n",
      "Epoch: 1602 cost = 0.034373229\n",
      "Validation Loss: 0.06389205\n",
      "Epoch: 1603 cost = 0.034319276\n",
      "Validation Loss: 0.06979909\n",
      "Epoch: 1604 cost = 0.034266126\n",
      "Validation Loss: 0.07903745\n",
      "Epoch: 1605 cost = 0.034213368\n",
      "Validation Loss: 0.09198857\n",
      "Epoch: 1606 cost = 0.034161291\n",
      "Validation Loss: 0.06420213\n",
      "Epoch: 1607 cost = 0.034109512\n",
      "Validation Loss: 0.06458199\n",
      "Epoch: 1608 cost = 0.034058347\n",
      "Validation Loss: 0.08063657\n",
      "Epoch: 1609 cost = 0.034007575\n",
      "Validation Loss: 0.077646375\n",
      "Epoch: 1610 cost = 0.033957118\n",
      "Validation Loss: 0.05920965\n",
      "Epoch: 1611 cost = 0.033907344\n",
      "Validation Loss: 0.056231175\n",
      "Epoch: 1612 cost = 0.033857750\n",
      "Validation Loss: 0.059501667\n",
      "Epoch: 1613 cost = 0.033808603\n",
      "Validation Loss: 0.10239938\n",
      "Epoch: 1614 cost = 0.033759900\n",
      "Validation Loss: 0.07185019\n",
      "Epoch: 1615 cost = 0.033711409\n",
      "Validation Loss: 0.07916638\n",
      "Epoch: 1616 cost = 0.033663511\n",
      "Validation Loss: 0.11170496\n",
      "Epoch: 1617 cost = 0.033615540\n",
      "Validation Loss: 0.13258797\n",
      "Epoch: 1618 cost = 0.033568236\n",
      "Validation Loss: 0.122329764\n",
      "Epoch: 1619 cost = 0.033520707\n",
      "Validation Loss: 0.10989291\n",
      "Epoch: 1620 cost = 0.033473626\n",
      "Validation Loss: 0.14884521\n",
      "Epoch: 1621 cost = 0.033426029\n",
      "Validation Loss: 0.12960646\n",
      "Epoch: 1622 cost = 0.033378349\n",
      "Validation Loss: 0.07780157\n",
      "Epoch: 1623 cost = 0.033329651\n",
      "Validation Loss: 0.08125295\n",
      "Epoch: 1624 cost = 0.033279655\n",
      "Validation Loss: 0.10103035\n",
      "Epoch: 1625 cost = 0.033226981\n",
      "Validation Loss: 0.08974853\n",
      "Epoch: 1626 cost = 0.033170437\n",
      "Validation Loss: 0.08537379\n",
      "Epoch: 1627 cost = 0.033108654\n",
      "Validation Loss: 0.06377528\n",
      "Epoch: 1628 cost = 0.033041299\n",
      "Validation Loss: 0.056799367\n",
      "Epoch: 1629 cost = 0.032969875\n",
      "Validation Loss: 0.05047396\n",
      "Epoch: 1630 cost = 0.032893538\n",
      "Validation Loss: 0.0759205\n",
      "Epoch: 1631 cost = 0.032808119\n",
      "Validation Loss: 0.09352731\n",
      "Epoch: 1632 cost = 0.032715382\n",
      "Validation Loss: 0.060314234\n",
      "Epoch: 1633 cost = 0.032635590\n",
      "Validation Loss: 0.07956112\n",
      "Epoch: 1634 cost = 0.032582860\n",
      "Validation Loss: 0.0696967\n",
      "Epoch: 1635 cost = 0.032533107\n",
      "Validation Loss: 0.055356342\n",
      "Epoch: 1636 cost = 0.032480395\n",
      "Validation Loss: 0.05562029\n",
      "Epoch: 1637 cost = 0.032430142\n",
      "Validation Loss: 0.067460895\n",
      "Epoch: 1638 cost = 0.032382321\n",
      "Validation Loss: 0.06397513\n",
      "Epoch: 1639 cost = 0.032336286\n",
      "Validation Loss: 0.05916329\n",
      "Epoch: 1640 cost = 0.032291906\n",
      "Validation Loss: 0.056428038\n",
      "Epoch: 1641 cost = 0.032249035\n",
      "Validation Loss: 0.05956883\n",
      "Epoch: 1642 cost = 0.032207039\n",
      "Validation Loss: 0.06659175\n",
      "Epoch: 1643 cost = 0.032165974\n",
      "Validation Loss: 0.04935181\n",
      "Epoch: 1644 cost = 0.032125948\n",
      "Validation Loss: 0.07607106\n",
      "Epoch: 1645 cost = 0.032086742\n",
      "Validation Loss: 0.09960665\n",
      "Epoch: 1646 cost = 0.032048543\n",
      "Validation Loss: 0.054483194\n",
      "Epoch: 1647 cost = 0.032011024\n",
      "Validation Loss: 0.05765766\n",
      "Epoch: 1648 cost = 0.031974217\n",
      "Validation Loss: 0.06509675\n",
      "Epoch: 1649 cost = 0.031938241\n",
      "Validation Loss: 0.06827228\n",
      "Epoch: 1650 cost = 0.031902776\n",
      "Validation Loss: 0.060790204\n",
      "Epoch: 1651 cost = 0.031868103\n",
      "Validation Loss: 0.04666075\n",
      "Epoch: 1652 cost = 0.031833926\n",
      "Validation Loss: 0.06615246\n",
      "Epoch: 1653 cost = 0.031800333\n",
      "Validation Loss: 0.05078706\n",
      "Epoch: 1654 cost = 0.031767378\n",
      "Validation Loss: 0.063197434\n",
      "Epoch: 1655 cost = 0.031735021\n",
      "Validation Loss: 0.06308768\n",
      "Epoch: 1656 cost = 0.031703028\n",
      "Validation Loss: 0.05448595\n",
      "Epoch: 1657 cost = 0.031671732\n",
      "Validation Loss: 0.058992658\n",
      "Epoch: 1658 cost = 0.031640788\n",
      "Validation Loss: 0.06035877\n",
      "Epoch: 1659 cost = 0.031610483\n",
      "Validation Loss: 0.05778094\n",
      "Epoch: 1660 cost = 0.031580406\n",
      "Validation Loss: 0.061532345\n",
      "Epoch: 1661 cost = 0.031551014\n",
      "Validation Loss: 0.06289892\n",
      "Epoch: 1662 cost = 0.031521893\n",
      "Validation Loss: 0.057637595\n",
      "Epoch: 1663 cost = 0.031493384\n",
      "Validation Loss: 0.05853189\n",
      "Epoch: 1664 cost = 0.031465048\n",
      "Validation Loss: 0.04540905\n",
      "Epoch: 1665 cost = 0.031437391\n",
      "Validation Loss: 0.05413342\n",
      "Epoch: 1666 cost = 0.031409948\n",
      "Validation Loss: 0.05123506\n",
      "Epoch: 1667 cost = 0.031383068\n",
      "Validation Loss: 0.044487473\n",
      "Epoch: 1668 cost = 0.031356338\n",
      "Validation Loss: 0.042039298\n",
      "Epoch: 1669 cost = 0.031330268\n",
      "Validation Loss: 0.05036494\n",
      "Epoch: 1670 cost = 0.031304294\n",
      "Validation Loss: 0.050928142\n",
      "Epoch: 1671 cost = 0.031278937\n",
      "Validation Loss: 0.051844712\n",
      "Epoch: 1672 cost = 0.031253679\n",
      "Validation Loss: 0.043779854\n",
      "Epoch: 1673 cost = 0.031229060\n",
      "Validation Loss: 0.04547413\n",
      "Epoch: 1674 cost = 0.031204580\n",
      "Validation Loss: 0.0577702\n",
      "Epoch: 1675 cost = 0.031180538\n",
      "Validation Loss: 0.07099497\n",
      "Epoch: 1676 cost = 0.031156688\n",
      "Validation Loss: 0.0721199\n",
      "Epoch: 1677 cost = 0.031133309\n",
      "Validation Loss: 0.07870906\n",
      "Epoch: 1678 cost = 0.031110191\n",
      "Validation Loss: 0.08704583\n",
      "Epoch: 1679 cost = 0.031087438\n",
      "Validation Loss: 0.10238415\n",
      "Epoch: 1680 cost = 0.031064988\n",
      "Validation Loss: 0.046103537\n",
      "Epoch: 1681 cost = 0.031042756\n",
      "Validation Loss: 0.04451997\n",
      "Epoch: 1682 cost = 0.031020945\n",
      "Validation Loss: 0.05689742\n",
      "Epoch: 1683 cost = 0.030999294\n",
      "Validation Loss: 0.048424423\n",
      "Epoch: 1684 cost = 0.030978091\n",
      "Validation Loss: 0.044297967\n",
      "Epoch: 1685 cost = 0.030956964\n",
      "Validation Loss: 0.0553254\n",
      "Epoch: 1686 cost = 0.030936340\n",
      "Validation Loss: 0.0626975\n",
      "Epoch: 1687 cost = 0.030915888\n",
      "Validation Loss: 0.08415115\n",
      "Epoch: 1688 cost = 0.030895707\n",
      "Validation Loss: 0.06914764\n",
      "Epoch: 1689 cost = 0.030875797\n",
      "Validation Loss: 0.062124375\n",
      "Epoch: 1690 cost = 0.030856156\n",
      "Validation Loss: 0.051855672\n",
      "Epoch: 1691 cost = 0.030836781\n",
      "Validation Loss: 0.051751427\n",
      "Epoch: 1692 cost = 0.030817624\n",
      "Validation Loss: 0.05572975\n",
      "Epoch: 1693 cost = 0.030798693\n",
      "Validation Loss: 0.069597565\n",
      "Epoch: 1694 cost = 0.030780062\n",
      "Validation Loss: 0.087577134\n",
      "Epoch: 1695 cost = 0.030761594\n",
      "Validation Loss: 0.060901143\n",
      "Epoch: 1696 cost = 0.030743412\n",
      "Validation Loss: 0.0478251\n",
      "Epoch: 1697 cost = 0.030725425\n",
      "Validation Loss: 0.04384149\n",
      "Epoch: 1698 cost = 0.030707806\n",
      "Validation Loss: 0.041023806\n",
      "Epoch: 1699 cost = 0.030690144\n",
      "Validation Loss: 0.047609627\n",
      "Epoch: 1700 cost = 0.030672964\n",
      "Validation Loss: 0.046769623\n",
      "Epoch: 1701 cost = 0.030655731\n",
      "Validation Loss: 0.051238213\n",
      "Epoch: 1702 cost = 0.030638914\n",
      "Validation Loss: 0.065847486\n",
      "Epoch: 1703 cost = 0.030622179\n",
      "Validation Loss: 0.05594466\n",
      "Epoch: 1704 cost = 0.030605665\n",
      "Validation Loss: 0.043026756\n",
      "Epoch: 1705 cost = 0.030589262\n",
      "Validation Loss: 0.043086223\n",
      "Epoch: 1706 cost = 0.030573218\n",
      "Validation Loss: 0.046189215\n",
      "Epoch: 1707 cost = 0.030557139\n",
      "Validation Loss: 0.066629484\n",
      "Epoch: 1708 cost = 0.030541492\n",
      "Validation Loss: 0.07282147\n",
      "Epoch: 1709 cost = 0.030525830\n",
      "Validation Loss: 0.10057012\n",
      "Epoch: 1710 cost = 0.030510424\n",
      "Validation Loss: 0.08511724\n",
      "Epoch: 1711 cost = 0.030495133\n",
      "Validation Loss: 0.060249545\n",
      "Epoch: 1712 cost = 0.030480007\n",
      "Validation Loss: 0.07063029\n",
      "Epoch: 1713 cost = 0.030465045\n",
      "Validation Loss: 0.053708673\n",
      "Epoch: 1714 cost = 0.030450292\n",
      "Validation Loss: 0.04452631\n",
      "Epoch: 1715 cost = 0.030435680\n",
      "Validation Loss: 0.059934318\n",
      "Epoch: 1716 cost = 0.030421158\n",
      "Validation Loss: 0.058369238\n",
      "Epoch: 1717 cost = 0.030406829\n",
      "Validation Loss: 0.055056147\n",
      "Epoch: 1718 cost = 0.030392564\n",
      "Validation Loss: 0.06017792\n",
      "Epoch: 1719 cost = 0.030378581\n",
      "Validation Loss: 0.07224771\n",
      "Epoch: 1720 cost = 0.030364615\n",
      "Validation Loss: 0.082641505\n",
      "Epoch: 1721 cost = 0.030350805\n",
      "Validation Loss: 0.08564899\n",
      "Epoch: 1722 cost = 0.030337153\n",
      "Validation Loss: 0.08247014\n",
      "Epoch: 1723 cost = 0.030323610\n",
      "Validation Loss: 0.070640974\n",
      "Epoch: 1724 cost = 0.030310226\n",
      "Validation Loss: 0.06451915\n",
      "Epoch: 1725 cost = 0.030296922\n",
      "Validation Loss: 0.05538837\n",
      "Epoch: 1726 cost = 0.030283794\n",
      "Validation Loss: 0.06152194\n",
      "Epoch: 1727 cost = 0.030270586\n",
      "Validation Loss: 0.046474416\n",
      "Epoch: 1728 cost = 0.030257724\n",
      "Validation Loss: 0.068973824\n",
      "Epoch: 1729 cost = 0.030244986\n",
      "Validation Loss: 0.10255769\n",
      "Epoch: 1730 cost = 0.030232242\n",
      "Validation Loss: 0.07963602\n",
      "Epoch: 1731 cost = 0.030219656\n",
      "Validation Loss: 0.044114247\n",
      "Epoch: 1732 cost = 0.030207175\n",
      "Validation Loss: 0.046690978\n",
      "Epoch: 1733 cost = 0.030194738\n",
      "Validation Loss: 0.05086415\n",
      "Epoch: 1734 cost = 0.030182436\n",
      "Validation Loss: 0.04180639\n",
      "Epoch: 1735 cost = 0.030170400\n",
      "Validation Loss: 0.040548485\n",
      "Epoch: 1736 cost = 0.030158212\n",
      "Validation Loss: 0.055468753\n",
      "Epoch: 1737 cost = 0.030146299\n",
      "Validation Loss: 0.05660331\n",
      "Epoch: 1738 cost = 0.030134360\n",
      "Validation Loss: 0.06014189\n",
      "Epoch: 1739 cost = 0.030122566\n",
      "Validation Loss: 0.05716524\n",
      "Epoch: 1740 cost = 0.030110858\n",
      "Validation Loss: 0.049744677\n",
      "Epoch: 1741 cost = 0.030099357\n",
      "Validation Loss: 0.05893244\n",
      "Epoch: 1742 cost = 0.030087700\n",
      "Validation Loss: 0.06715049\n",
      "Epoch: 1743 cost = 0.030076358\n",
      "Validation Loss: 0.07379061\n",
      "Epoch: 1744 cost = 0.030064939\n",
      "Validation Loss: 0.07013917\n",
      "Epoch: 1745 cost = 0.030053750\n",
      "Validation Loss: 0.049923033\n",
      "Epoch: 1746 cost = 0.030042565\n",
      "Validation Loss: 0.057710234\n",
      "Epoch: 1747 cost = 0.030031489\n",
      "Validation Loss: 0.06481015\n",
      "Epoch: 1748 cost = 0.030020530\n",
      "Validation Loss: 0.061045893\n",
      "Epoch: 1749 cost = 0.030009595\n",
      "Validation Loss: 0.056909867\n",
      "Epoch: 1750 cost = 0.029998728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.05304884\n",
      "Epoch: 1751 cost = 0.029988032\n",
      "Validation Loss: 0.05296787\n",
      "Epoch: 1752 cost = 0.029977296\n",
      "Validation Loss: 0.047644194\n",
      "Epoch: 1753 cost = 0.029966722\n",
      "Validation Loss: 0.04786609\n",
      "Epoch: 1754 cost = 0.029956179\n",
      "Validation Loss: 0.04522045\n",
      "Epoch: 1755 cost = 0.029945716\n",
      "Validation Loss: 0.04382945\n",
      "Epoch: 1756 cost = 0.029935390\n",
      "Validation Loss: 0.03559596\n",
      "Epoch: 1757 cost = 0.029925061\n",
      "Validation Loss: 0.04904389\n",
      "Epoch: 1758 cost = 0.029914843\n",
      "Validation Loss: 0.04100146\n",
      "Epoch: 1759 cost = 0.029904700\n",
      "Validation Loss: 0.047489516\n",
      "Epoch: 1760 cost = 0.029894611\n",
      "Validation Loss: 0.05384173\n",
      "Epoch: 1761 cost = 0.029884563\n",
      "Validation Loss: 0.046171557\n",
      "Epoch: 1762 cost = 0.029874657\n",
      "Validation Loss: 0.04806041\n",
      "Epoch: 1763 cost = 0.029864790\n",
      "Validation Loss: 0.05046994\n",
      "Epoch: 1764 cost = 0.029854941\n",
      "Validation Loss: 0.04334797\n",
      "Epoch: 1765 cost = 0.029845182\n",
      "Validation Loss: 0.042256262\n",
      "Epoch: 1766 cost = 0.029835530\n",
      "Validation Loss: 0.03964143\n",
      "Epoch: 1767 cost = 0.029825958\n",
      "Validation Loss: 0.047387887\n",
      "Epoch: 1768 cost = 0.029816369\n",
      "Validation Loss: 0.041152265\n",
      "Epoch: 1769 cost = 0.029806899\n",
      "Validation Loss: 0.043992788\n",
      "Epoch: 1770 cost = 0.029797484\n",
      "Validation Loss: 0.042245258\n",
      "Epoch: 1771 cost = 0.029788139\n",
      "Validation Loss: 0.04380338\n",
      "Epoch: 1772 cost = 0.029778875\n",
      "Validation Loss: 0.048425958\n",
      "Epoch: 1773 cost = 0.029769645\n",
      "Validation Loss: 0.049882177\n",
      "Epoch: 1774 cost = 0.029760470\n",
      "Validation Loss: 0.04513916\n",
      "Epoch: 1775 cost = 0.029751393\n",
      "Validation Loss: 0.060742952\n",
      "Epoch: 1776 cost = 0.029742355\n",
      "Validation Loss: 0.07203833\n",
      "Epoch: 1777 cost = 0.029733370\n",
      "Validation Loss: 0.076045394\n",
      "Epoch: 1778 cost = 0.029724492\n",
      "Validation Loss: 0.07544111\n",
      "Epoch: 1779 cost = 0.029715587\n",
      "Validation Loss: 0.09269994\n",
      "Epoch: 1780 cost = 0.029706759\n",
      "Validation Loss: 0.0713844\n",
      "Epoch: 1781 cost = 0.029697981\n",
      "Validation Loss: 0.04224602\n",
      "Epoch: 1782 cost = 0.029689306\n",
      "Validation Loss: 0.037673485\n",
      "Epoch: 1783 cost = 0.029680724\n",
      "Validation Loss: 0.052559704\n",
      "Epoch: 1784 cost = 0.029672018\n",
      "Validation Loss: 0.054950498\n",
      "Epoch: 1785 cost = 0.029663615\n",
      "Validation Loss: 0.040376153\n",
      "Epoch: 1786 cost = 0.029655182\n",
      "Validation Loss: 0.04410034\n",
      "Epoch: 1787 cost = 0.029646669\n",
      "Validation Loss: 0.050013375\n",
      "Epoch: 1788 cost = 0.029638393\n",
      "Validation Loss: 0.05097542\n",
      "Epoch: 1789 cost = 0.029630102\n",
      "Validation Loss: 0.050262786\n",
      "Epoch: 1790 cost = 0.029621792\n",
      "Validation Loss: 0.06652979\n",
      "Epoch: 1791 cost = 0.029613637\n",
      "Validation Loss: 0.07986689\n",
      "Epoch: 1792 cost = 0.029605537\n",
      "Validation Loss: 0.06375193\n",
      "Epoch: 1793 cost = 0.029597418\n",
      "Validation Loss: 0.051846106\n",
      "Epoch: 1794 cost = 0.029589316\n",
      "Validation Loss: 0.05014296\n",
      "Epoch: 1795 cost = 0.029581353\n",
      "Validation Loss: 0.04153174\n",
      "Epoch: 1796 cost = 0.029573413\n",
      "Validation Loss: 0.03714888\n",
      "Epoch: 1797 cost = 0.029565579\n",
      "Validation Loss: 0.041313294\n",
      "Epoch: 1798 cost = 0.029557778\n",
      "Validation Loss: 0.048292466\n",
      "Epoch: 1799 cost = 0.029549910\n",
      "Validation Loss: 0.0631558\n",
      "Epoch: 1800 cost = 0.029542173\n",
      "Validation Loss: 0.0552355\n",
      "Epoch: 1801 cost = 0.029534485\n",
      "Validation Loss: 0.060502976\n",
      "Epoch: 1802 cost = 0.029526871\n",
      "Validation Loss: 0.055021577\n",
      "Epoch: 1803 cost = 0.029519301\n",
      "Validation Loss: 0.058964\n",
      "Epoch: 1804 cost = 0.029511734\n",
      "Validation Loss: 0.050345615\n",
      "Epoch: 1805 cost = 0.029504263\n",
      "Validation Loss: 0.04809308\n",
      "Epoch: 1806 cost = 0.029496826\n",
      "Validation Loss: 0.040138748\n",
      "Epoch: 1807 cost = 0.029489325\n",
      "Validation Loss: 0.05108095\n",
      "Epoch: 1808 cost = 0.029481989\n",
      "Validation Loss: 0.043637328\n",
      "Epoch: 1809 cost = 0.029474709\n",
      "Validation Loss: 0.03661969\n",
      "Epoch: 1810 cost = 0.029467474\n",
      "Validation Loss: 0.04112462\n",
      "Epoch: 1811 cost = 0.029460232\n",
      "Validation Loss: 0.035934974\n",
      "Epoch: 1812 cost = 0.029453089\n",
      "Validation Loss: 0.042957596\n",
      "Epoch: 1813 cost = 0.029445939\n",
      "Validation Loss: 0.047873456\n",
      "Epoch: 1814 cost = 0.029438789\n",
      "Validation Loss: 0.044862542\n",
      "Epoch: 1815 cost = 0.029431791\n",
      "Validation Loss: 0.050531674\n",
      "Epoch: 1816 cost = 0.029424816\n",
      "Validation Loss: 0.046749987\n",
      "Epoch: 1817 cost = 0.029417845\n",
      "Validation Loss: 0.045088325\n",
      "Epoch: 1818 cost = 0.029410951\n",
      "Validation Loss: 0.048071336\n",
      "Epoch: 1819 cost = 0.029403999\n",
      "Validation Loss: 0.03568682\n",
      "Epoch: 1820 cost = 0.029397231\n",
      "Validation Loss: 0.035382576\n",
      "Epoch: 1821 cost = 0.029390383\n",
      "Validation Loss: 0.047803566\n",
      "Epoch: 1822 cost = 0.029383624\n",
      "Validation Loss: 0.035206918\n",
      "Epoch: 1823 cost = 0.029376948\n",
      "Validation Loss: 0.05349706\n",
      "Epoch: 1824 cost = 0.029370241\n",
      "Validation Loss: 0.06624453\n",
      "Epoch: 1825 cost = 0.029363615\n",
      "Validation Loss: 0.06233228\n",
      "Epoch: 1826 cost = 0.029356997\n",
      "Validation Loss: 0.05375298\n",
      "Epoch: 1827 cost = 0.029350514\n",
      "Validation Loss: 0.043843817\n",
      "Epoch: 1828 cost = 0.029343923\n",
      "Validation Loss: 0.049123973\n",
      "Epoch: 1829 cost = 0.029337468\n",
      "Validation Loss: 0.050318576\n",
      "Epoch: 1830 cost = 0.029331018\n",
      "Validation Loss: 0.046545137\n",
      "Epoch: 1831 cost = 0.029324608\n",
      "Validation Loss: 0.04427864\n",
      "Epoch: 1832 cost = 0.029318279\n",
      "Validation Loss: 0.04534826\n",
      "Epoch: 1833 cost = 0.029311927\n",
      "Validation Loss: 0.05542639\n",
      "Epoch: 1834 cost = 0.029305692\n",
      "Validation Loss: 0.05270217\n",
      "Epoch: 1835 cost = 0.029299314\n",
      "Validation Loss: 0.051904943\n",
      "Epoch: 1836 cost = 0.029293169\n",
      "Validation Loss: 0.04178679\n",
      "Epoch: 1837 cost = 0.029286967\n",
      "Validation Loss: 0.038952444\n",
      "Epoch: 1838 cost = 0.029280846\n",
      "Validation Loss: 0.04688907\n",
      "Epoch: 1839 cost = 0.029274703\n",
      "Validation Loss: 0.06005187\n",
      "Epoch: 1840 cost = 0.029268673\n",
      "Validation Loss: 0.053593483\n",
      "Epoch: 1841 cost = 0.029262578\n",
      "Validation Loss: 0.05877019\n",
      "Epoch: 1842 cost = 0.029256581\n",
      "Validation Loss: 0.050436616\n",
      "Epoch: 1843 cost = 0.029250604\n",
      "Validation Loss: 0.03457105\n",
      "Epoch: 1844 cost = 0.029244589\n",
      "Validation Loss: 0.04573289\n",
      "Epoch: 1845 cost = 0.029238801\n",
      "Validation Loss: 0.057031553\n",
      "Epoch: 1846 cost = 0.029232809\n",
      "Validation Loss: 0.07566785\n",
      "Epoch: 1847 cost = 0.029227001\n",
      "Validation Loss: 0.060225062\n",
      "Epoch: 1848 cost = 0.029221181\n",
      "Validation Loss: 0.07117681\n",
      "Epoch: 1849 cost = 0.029215387\n",
      "Validation Loss: 0.076988116\n",
      "Epoch: 1850 cost = 0.029209688\n",
      "Validation Loss: 0.08495417\n",
      "Epoch: 1851 cost = 0.029203883\n",
      "Validation Loss: 0.04376621\n",
      "Epoch: 1852 cost = 0.029198209\n",
      "Validation Loss: 0.047392905\n",
      "Epoch: 1853 cost = 0.029192540\n",
      "Validation Loss: 0.042288076\n",
      "Epoch: 1854 cost = 0.029186903\n",
      "Validation Loss: 0.041351706\n",
      "Epoch: 1855 cost = 0.029181327\n",
      "Validation Loss: 0.03756021\n",
      "Epoch: 1856 cost = 0.029175680\n",
      "Validation Loss: 0.034631222\n",
      "Epoch: 1857 cost = 0.029170249\n",
      "Validation Loss: 0.046035103\n",
      "Epoch: 1858 cost = 0.029164717\n",
      "Validation Loss: 0.06390799\n",
      "Epoch: 1859 cost = 0.029159199\n",
      "Validation Loss: 0.05204593\n",
      "Epoch: 1860 cost = 0.029153712\n",
      "Validation Loss: 0.053290833\n",
      "Epoch: 1861 cost = 0.029148267\n",
      "Validation Loss: 0.04361553\n",
      "Epoch: 1862 cost = 0.029142879\n",
      "Validation Loss: 0.04145282\n",
      "Epoch: 1863 cost = 0.029137593\n",
      "Validation Loss: 0.046485253\n",
      "Epoch: 1864 cost = 0.029132126\n",
      "Validation Loss: 0.040995363\n",
      "Epoch: 1865 cost = 0.029126930\n",
      "Validation Loss: 0.041766156\n",
      "Epoch: 1866 cost = 0.029121575\n",
      "Validation Loss: 0.044612397\n",
      "Epoch: 1867 cost = 0.029116270\n",
      "Validation Loss: 0.034931164\n",
      "Epoch: 1868 cost = 0.029111120\n",
      "Validation Loss: 0.037668396\n",
      "Epoch: 1869 cost = 0.029105783\n",
      "Validation Loss: 0.053566698\n",
      "Epoch: 1870 cost = 0.029100648\n",
      "Validation Loss: 0.04014023\n",
      "Epoch: 1871 cost = 0.029095564\n",
      "Validation Loss: 0.037799444\n",
      "Epoch: 1872 cost = 0.029090324\n",
      "Validation Loss: 0.04397361\n",
      "Epoch: 1873 cost = 0.029085253\n",
      "Validation Loss: 0.042353168\n",
      "Epoch: 1874 cost = 0.029080091\n",
      "Validation Loss: 0.04011686\n",
      "Epoch: 1875 cost = 0.029075082\n",
      "Validation Loss: 0.03836515\n",
      "Epoch: 1876 cost = 0.029070001\n",
      "Validation Loss: 0.041570373\n",
      "Epoch: 1877 cost = 0.029065043\n",
      "Validation Loss: 0.035806045\n",
      "Epoch: 1878 cost = 0.029060017\n",
      "Validation Loss: 0.04442035\n",
      "Epoch: 1879 cost = 0.029055120\n",
      "Validation Loss: 0.043435354\n",
      "Epoch: 1880 cost = 0.029050129\n",
      "Validation Loss: 0.048625298\n",
      "Epoch: 1881 cost = 0.029045215\n",
      "Validation Loss: 0.05316759\n",
      "Epoch: 1882 cost = 0.029040315\n",
      "Validation Loss: 0.111074\n",
      "Epoch: 1883 cost = 0.029035422\n",
      "Validation Loss: 0.08499013\n",
      "Epoch: 1884 cost = 0.029030570\n",
      "Validation Loss: 0.04882435\n",
      "Epoch: 1885 cost = 0.029025732\n",
      "Validation Loss: 0.045924533\n",
      "Epoch: 1886 cost = 0.029021029\n",
      "Validation Loss: 0.05506106\n",
      "Epoch: 1887 cost = 0.029016213\n",
      "Validation Loss: 0.048171002\n",
      "Epoch: 1888 cost = 0.029011366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.038810037\n",
      "Epoch: 1889 cost = 0.029006681\n",
      "Validation Loss: 0.05096858\n",
      "Epoch: 1890 cost = 0.029001958\n",
      "Validation Loss: 0.047577318\n",
      "Epoch: 1891 cost = 0.028997282\n",
      "Validation Loss: 0.062416863\n",
      "Epoch: 1892 cost = 0.028992550\n",
      "Validation Loss: 0.06502361\n",
      "Epoch: 1893 cost = 0.028987939\n",
      "Validation Loss: 0.08131381\n",
      "Epoch: 1894 cost = 0.028983277\n",
      "Validation Loss: 0.051060632\n",
      "Epoch: 1895 cost = 0.028978623\n",
      "Validation Loss: 0.04219549\n",
      "Epoch: 1896 cost = 0.028974072\n",
      "Validation Loss: 0.038085554\n",
      "Epoch: 1897 cost = 0.028969483\n",
      "Validation Loss: 0.040914714\n",
      "Epoch: 1898 cost = 0.028964935\n",
      "Validation Loss: 0.04975878\n",
      "Epoch: 1899 cost = 0.028960355\n",
      "Validation Loss: 0.06729165\n",
      "Epoch: 1900 cost = 0.028955844\n",
      "Validation Loss: 0.06262564\n",
      "Epoch: 1901 cost = 0.028951425\n",
      "Validation Loss: 0.04718861\n",
      "Epoch: 1902 cost = 0.028946895\n",
      "Validation Loss: 0.04454349\n",
      "Epoch: 1903 cost = 0.028942431\n",
      "Validation Loss: 0.05238869\n",
      "Epoch: 1904 cost = 0.028937979\n",
      "Validation Loss: 0.054337308\n",
      "Epoch: 1905 cost = 0.028933563\n",
      "Validation Loss: 0.043889288\n",
      "Epoch: 1906 cost = 0.028929193\n",
      "Validation Loss: 0.055046123\n",
      "Epoch: 1907 cost = 0.028924758\n",
      "Validation Loss: 0.03719347\n",
      "Epoch: 1908 cost = 0.028920432\n",
      "Validation Loss: 0.040043365\n",
      "Epoch: 1909 cost = 0.028916103\n",
      "Validation Loss: 0.06280317\n",
      "Epoch: 1910 cost = 0.028911725\n",
      "Validation Loss: 0.07316866\n",
      "Epoch: 1911 cost = 0.028907460\n",
      "Validation Loss: 0.07864474\n",
      "Epoch: 1912 cost = 0.028903154\n",
      "Validation Loss: 0.1172976\n",
      "Epoch: 1913 cost = 0.028898827\n",
      "Validation Loss: 0.07519979\n",
      "Epoch: 1914 cost = 0.028894560\n",
      "Validation Loss: 0.050307494\n",
      "Epoch: 1915 cost = 0.028890337\n",
      "Validation Loss: 0.036569856\n",
      "Epoch: 1916 cost = 0.028886160\n",
      "Validation Loss: 0.05849623\n",
      "Epoch: 1917 cost = 0.028881881\n",
      "Validation Loss: 0.04882695\n",
      "Epoch: 1918 cost = 0.028877715\n",
      "Validation Loss: 0.043251425\n",
      "Epoch: 1919 cost = 0.028873515\n",
      "Validation Loss: 0.042455934\n",
      "Epoch: 1920 cost = 0.028869356\n",
      "Validation Loss: 0.043413788\n",
      "Epoch: 1921 cost = 0.028865182\n",
      "Validation Loss: 0.04861413\n",
      "Epoch: 1922 cost = 0.028861097\n",
      "Validation Loss: 0.042477854\n",
      "Epoch: 1923 cost = 0.028856940\n",
      "Validation Loss: 0.043035846\n",
      "Epoch: 1924 cost = 0.028852925\n",
      "Validation Loss: 0.04373488\n",
      "Epoch: 1925 cost = 0.028848774\n",
      "Validation Loss: 0.03976033\n",
      "Epoch: 1926 cost = 0.028844776\n",
      "Validation Loss: 0.04144253\n",
      "Epoch: 1927 cost = 0.028840696\n",
      "Validation Loss: 0.037285876\n",
      "Epoch: 1928 cost = 0.028836619\n",
      "Validation Loss: 0.035830155\n",
      "Epoch: 1929 cost = 0.028832601\n",
      "Validation Loss: 0.041562427\n",
      "Epoch: 1930 cost = 0.028828664\n",
      "Validation Loss: 0.035885587\n",
      "Epoch: 1931 cost = 0.028824583\n",
      "Validation Loss: 0.039912768\n",
      "Epoch: 1932 cost = 0.028820663\n",
      "Validation Loss: 0.042938653\n",
      "Epoch: 1933 cost = 0.028816650\n",
      "Validation Loss: 0.044896018\n",
      "Epoch: 1934 cost = 0.028812762\n",
      "Validation Loss: 0.045593936\n",
      "Epoch: 1935 cost = 0.028808807\n",
      "Validation Loss: 0.04105206\n",
      "Epoch: 1936 cost = 0.028804936\n",
      "Validation Loss: 0.05210237\n",
      "Epoch: 1937 cost = 0.028801021\n",
      "Validation Loss: 0.070474215\n",
      "Epoch: 1938 cost = 0.028797054\n",
      "Validation Loss: 0.05505085\n",
      "Epoch: 1939 cost = 0.028793277\n",
      "Validation Loss: 0.074515164\n",
      "Epoch: 1940 cost = 0.028789365\n",
      "Validation Loss: 0.06465421\n",
      "Epoch: 1941 cost = 0.028785483\n",
      "Validation Loss: 0.05237064\n",
      "Epoch: 1942 cost = 0.028781679\n",
      "Validation Loss: 0.05052871\n",
      "Epoch: 1943 cost = 0.028777848\n",
      "Validation Loss: 0.059272803\n",
      "Epoch: 1944 cost = 0.028774022\n",
      "Validation Loss: 0.051420692\n",
      "Epoch: 1945 cost = 0.028770261\n",
      "Validation Loss: 0.059796836\n",
      "Epoch: 1946 cost = 0.028766431\n",
      "Validation Loss: 0.05473087\n",
      "Epoch: 1947 cost = 0.028762745\n",
      "Validation Loss: 0.05653297\n",
      "Epoch: 1948 cost = 0.028758883\n",
      "Validation Loss: 0.06646172\n",
      "Epoch: 1949 cost = 0.028755239\n",
      "Validation Loss: 0.07047025\n",
      "Epoch: 1950 cost = 0.028751432\n",
      "Validation Loss: 0.057377946\n",
      "Epoch: 1951 cost = 0.028747762\n",
      "Validation Loss: 0.08218611\n",
      "Epoch: 1952 cost = 0.028744049\n",
      "Validation Loss: 0.0697205\n",
      "Epoch: 1953 cost = 0.028740320\n",
      "Validation Loss: 0.046207875\n",
      "Epoch: 1954 cost = 0.028736697\n",
      "Validation Loss: 0.038193654\n",
      "Epoch: 1955 cost = 0.028732945\n",
      "Validation Loss: 0.03916255\n",
      "Epoch: 1956 cost = 0.028729356\n",
      "Validation Loss: 0.042774603\n",
      "Epoch: 1957 cost = 0.028725643\n",
      "Validation Loss: 0.043668877\n",
      "Epoch: 1958 cost = 0.028722101\n",
      "Validation Loss: 0.036700953\n",
      "Epoch: 1959 cost = 0.028718464\n",
      "Validation Loss: 0.03960216\n",
      "Epoch: 1960 cost = 0.028714785\n",
      "Validation Loss: 0.041035824\n",
      "Epoch: 1961 cost = 0.028711222\n",
      "Validation Loss: 0.07452171\n",
      "Epoch: 1962 cost = 0.028707601\n",
      "Validation Loss: 0.05970233\n",
      "Epoch: 1963 cost = 0.028704096\n",
      "Validation Loss: 0.04739827\n",
      "Epoch: 1964 cost = 0.028700507\n",
      "Validation Loss: 0.037768688\n",
      "Epoch: 1965 cost = 0.028696971\n",
      "Validation Loss: 0.043385856\n",
      "Epoch: 1966 cost = 0.028693408\n",
      "Validation Loss: 0.04882016\n",
      "Epoch: 1967 cost = 0.028689879\n",
      "Validation Loss: 0.05550054\n",
      "Epoch: 1968 cost = 0.028686393\n",
      "Validation Loss: 0.05650522\n",
      "Epoch: 1969 cost = 0.028682875\n",
      "Validation Loss: 0.046068367\n",
      "Epoch: 1970 cost = 0.028679353\n",
      "Validation Loss: 0.040813528\n",
      "Epoch: 1971 cost = 0.028675882\n",
      "Validation Loss: 0.03565192\n",
      "Epoch: 1972 cost = 0.028672441\n",
      "Validation Loss: 0.040859997\n",
      "Epoch: 1973 cost = 0.028668897\n",
      "Validation Loss: 0.037591327\n",
      "Epoch: 1974 cost = 0.028665493\n",
      "Validation Loss: 0.04645684\n",
      "Epoch: 1975 cost = 0.028662059\n",
      "Validation Loss: 0.04155304\n",
      "Epoch: 1976 cost = 0.028658618\n",
      "Validation Loss: 0.040496662\n",
      "Epoch: 1977 cost = 0.028655201\n",
      "Validation Loss: 0.037883036\n",
      "Epoch: 1978 cost = 0.028651789\n",
      "Validation Loss: 0.042112593\n",
      "Epoch: 1979 cost = 0.028648365\n",
      "Validation Loss: 0.04211198\n",
      "Epoch: 1980 cost = 0.028644961\n",
      "Validation Loss: 0.042138133\n",
      "Epoch: 1981 cost = 0.028641646\n",
      "Validation Loss: 0.04428297\n",
      "Epoch: 1982 cost = 0.028638241\n",
      "Validation Loss: 0.045388184\n",
      "Epoch: 1983 cost = 0.028634962\n",
      "Validation Loss: 0.040588826\n",
      "Epoch: 1984 cost = 0.028631514\n",
      "Validation Loss: 0.04603421\n",
      "Epoch: 1985 cost = 0.028628236\n",
      "Validation Loss: 0.043238975\n",
      "Epoch: 1986 cost = 0.028624838\n",
      "Validation Loss: 0.040012818\n",
      "Epoch: 1987 cost = 0.028621553\n",
      "Validation Loss: 0.036188323\n",
      "Epoch: 1988 cost = 0.028618271\n",
      "Validation Loss: 0.040894236\n",
      "Epoch: 1989 cost = 0.028614895\n",
      "Validation Loss: 0.040370263\n",
      "Epoch: 1990 cost = 0.028611683\n",
      "Validation Loss: 0.042772286\n",
      "Epoch: 1991 cost = 0.028608290\n",
      "Validation Loss: 0.037981916\n",
      "Epoch: 1992 cost = 0.028605029\n",
      "Validation Loss: 0.04206305\n",
      "Epoch: 1993 cost = 0.028601820\n",
      "Validation Loss: 0.07866758\n",
      "Epoch: 1994 cost = 0.028598491\n",
      "Validation Loss: 0.06757725\n",
      "Epoch: 1995 cost = 0.028595313\n",
      "Validation Loss: 0.03774457\n",
      "Epoch: 1996 cost = 0.028592077\n",
      "Validation Loss: 0.045150872\n",
      "Epoch: 1997 cost = 0.028588849\n",
      "Validation Loss: 0.044124916\n",
      "Epoch: 1998 cost = 0.028585598\n",
      "Validation Loss: 0.04704735\n",
      "Epoch: 1999 cost = 0.028582425\n",
      "Validation Loss: 0.06937125\n",
      "Epoch: 2000 cost = 0.028579237\n",
      "Validation Loss: 0.083517976\n",
      "Epoch: 2001 cost = 0.028576013\n",
      "Validation Loss: 0.115668416\n",
      "Epoch: 2002 cost = 0.028572864\n",
      "Validation Loss: 0.12168791\n",
      "Epoch: 2003 cost = 0.028569682\n",
      "Validation Loss: 0.10003171\n",
      "Epoch: 2004 cost = 0.028566490\n",
      "Validation Loss: 0.057592995\n",
      "Epoch: 2005 cost = 0.028563415\n",
      "Validation Loss: 0.07189138\n",
      "Epoch: 2006 cost = 0.028560205\n",
      "Validation Loss: 0.09164706\n",
      "Epoch: 2007 cost = 0.028556991\n",
      "Validation Loss: 0.0614408\n",
      "Epoch: 2008 cost = 0.028554002\n",
      "Validation Loss: 0.053574752\n",
      "Epoch: 2009 cost = 0.028550784\n",
      "Validation Loss: 0.041770857\n",
      "Epoch: 2010 cost = 0.028547719\n",
      "Validation Loss: 0.03815346\n",
      "Epoch: 2011 cost = 0.028544593\n",
      "Validation Loss: 0.03633391\n",
      "Epoch: 2012 cost = 0.028541485\n",
      "Validation Loss: 0.04068396\n",
      "Epoch: 2013 cost = 0.028538365\n",
      "Validation Loss: 0.041718513\n",
      "Epoch: 2014 cost = 0.028535377\n",
      "Validation Loss: 0.10688168\n",
      "Epoch: 2015 cost = 0.028532244\n",
      "Validation Loss: 0.18519033\n",
      "Epoch: 2016 cost = 0.028529081\n",
      "Validation Loss: 0.1403981\n",
      "Epoch: 2017 cost = 0.028526134\n",
      "Validation Loss: 0.14637405\n",
      "Epoch: 2018 cost = 0.028523041\n",
      "Validation Loss: 0.080512054\n",
      "Epoch: 2019 cost = 0.028520023\n",
      "Validation Loss: 0.1059056\n",
      "Epoch: 2020 cost = 0.028516941\n",
      "Validation Loss: 0.14335848\n",
      "Epoch: 2021 cost = 0.028513930\n",
      "Validation Loss: 0.12789449\n",
      "Epoch: 2022 cost = 0.028510861\n",
      "Validation Loss: 0.06825828\n",
      "Epoch: 2023 cost = 0.028507887\n",
      "Validation Loss: 0.050082147\n",
      "Epoch: 2024 cost = 0.028504937\n",
      "Validation Loss: 0.03979848\n",
      "Epoch: 2025 cost = 0.028501882\n",
      "Validation Loss: 0.04083718\n",
      "Epoch: 2026 cost = 0.028498939\n",
      "Validation Loss: 0.043486264\n",
      "Epoch: 2027 cost = 0.028495974\n",
      "Validation Loss: 0.043944098\n",
      "Epoch: 2028 cost = 0.028492963\n",
      "Validation Loss: 0.044105854\n",
      "Epoch: 2029 cost = 0.028489999\n",
      "Validation Loss: 0.05328652\n",
      "Epoch: 2030 cost = 0.028487048\n",
      "Validation Loss: 0.06952918\n",
      "Epoch: 2031 cost = 0.028484078\n",
      "Validation Loss: 0.050586507\n",
      "Epoch: 2032 cost = 0.028481128\n",
      "Validation Loss: 0.03933469\n",
      "Epoch: 2033 cost = 0.028478228\n",
      "Validation Loss: 0.038938403\n",
      "Epoch: 2034 cost = 0.028475262\n",
      "Validation Loss: 0.042869087\n",
      "Epoch: 2035 cost = 0.028472318\n",
      "Validation Loss: 0.03960752\n",
      "Epoch: 2036 cost = 0.028469426\n",
      "Validation Loss: 0.04062701\n",
      "Epoch: 2037 cost = 0.028466555\n",
      "Validation Loss: 0.03816186\n",
      "Epoch: 2038 cost = 0.028463615\n",
      "Validation Loss: 0.03856224\n",
      "Epoch: 2039 cost = 0.028460783\n",
      "Validation Loss: 0.03807\n",
      "Epoch: 2040 cost = 0.028457806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.038242187\n",
      "Epoch: 2041 cost = 0.028454960\n",
      "Validation Loss: 0.048398837\n",
      "Epoch: 2042 cost = 0.028452074\n",
      "Validation Loss: 0.043330036\n",
      "Epoch: 2043 cost = 0.028449249\n",
      "Validation Loss: 0.05253834\n",
      "Epoch: 2044 cost = 0.028446320\n",
      "Validation Loss: 0.056436885\n",
      "Epoch: 2045 cost = 0.028443487\n",
      "Validation Loss: 0.041713096\n",
      "Epoch: 2046 cost = 0.028440633\n",
      "Validation Loss: 0.045174476\n",
      "Epoch: 2047 cost = 0.028437801\n",
      "Validation Loss: 0.059981838\n",
      "Epoch: 2048 cost = 0.028434969\n",
      "Validation Loss: 0.06090256\n",
      "Epoch: 2049 cost = 0.028432138\n",
      "Validation Loss: 0.05796745\n",
      "Epoch: 2050 cost = 0.028429287\n",
      "Validation Loss: 0.04700912\n",
      "Epoch: 2051 cost = 0.028426503\n",
      "Validation Loss: 0.04241831\n",
      "Epoch: 2052 cost = 0.028423652\n",
      "Validation Loss: 0.06030411\n",
      "Epoch: 2053 cost = 0.028420941\n",
      "Validation Loss: 0.07949018\n",
      "Epoch: 2054 cost = 0.028418115\n",
      "Validation Loss: 0.056783125\n",
      "Epoch: 2055 cost = 0.028415247\n",
      "Validation Loss: 0.041160334\n",
      "Epoch: 2056 cost = 0.028412603\n",
      "Validation Loss: 0.03957772\n",
      "Epoch: 2057 cost = 0.028409780\n",
      "Validation Loss: 0.037702024\n",
      "Epoch: 2058 cost = 0.028406946\n",
      "Validation Loss: 0.035598703\n",
      "Epoch: 2059 cost = 0.028404209\n",
      "Validation Loss: 0.051850498\n",
      "Epoch: 2060 cost = 0.028401393\n",
      "Validation Loss: 0.11692943\n",
      "Epoch: 2061 cost = 0.028398756\n",
      "Validation Loss: 0.1285791\n",
      "Epoch: 2062 cost = 0.028395947\n",
      "Validation Loss: 0.094178185\n",
      "Epoch: 2063 cost = 0.028393194\n",
      "Validation Loss: 0.075695254\n",
      "Epoch: 2064 cost = 0.028390498\n",
      "Validation Loss: 0.050106034\n",
      "Epoch: 2065 cost = 0.028387761\n",
      "Validation Loss: 0.05368397\n",
      "Epoch: 2066 cost = 0.028385103\n",
      "Validation Loss: 0.04486864\n",
      "Epoch: 2067 cost = 0.028382301\n",
      "Validation Loss: 0.035591286\n",
      "Epoch: 2068 cost = 0.028379626\n",
      "Validation Loss: 0.039126568\n",
      "Epoch: 2069 cost = 0.028376871\n",
      "Validation Loss: 0.039119307\n",
      "Epoch: 2070 cost = 0.028374161\n",
      "Validation Loss: 0.036567148\n",
      "Epoch: 2071 cost = 0.028371476\n",
      "Validation Loss: 0.042360596\n",
      "Epoch: 2072 cost = 0.028368813\n",
      "Validation Loss: 0.04061785\n",
      "Epoch: 2073 cost = 0.028366128\n",
      "Validation Loss: 0.036214832\n",
      "Epoch: 2074 cost = 0.028363457\n",
      "Validation Loss: 0.036880605\n",
      "Epoch: 2075 cost = 0.028360778\n",
      "Validation Loss: 0.041075356\n",
      "Epoch: 2076 cost = 0.028358086\n",
      "Validation Loss: 0.040960606\n",
      "Epoch: 2077 cost = 0.028355460\n",
      "Validation Loss: 0.051342104\n",
      "Epoch: 2078 cost = 0.028352753\n",
      "Validation Loss: 0.05540874\n",
      "Epoch: 2079 cost = 0.028350183\n",
      "Validation Loss: 0.038732808\n",
      "Epoch: 2080 cost = 0.028347526\n",
      "Validation Loss: 0.045185957\n",
      "Epoch: 2081 cost = 0.028344869\n",
      "Validation Loss: 0.081503734\n",
      "Epoch: 2082 cost = 0.028342235\n",
      "Validation Loss: 0.059368588\n",
      "Epoch: 2083 cost = 0.028339603\n",
      "Validation Loss: 0.043971077\n",
      "Epoch: 2084 cost = 0.028337065\n",
      "Validation Loss: 0.048202094\n",
      "Epoch: 2085 cost = 0.028334338\n",
      "Validation Loss: 0.047314618\n",
      "Epoch: 2086 cost = 0.028331754\n",
      "Validation Loss: 0.040782712\n",
      "Epoch: 2087 cost = 0.028329125\n",
      "Validation Loss: 0.04062908\n",
      "Epoch: 2088 cost = 0.028326577\n",
      "Validation Loss: 0.040225968\n",
      "Epoch: 2089 cost = 0.028323999\n",
      "Validation Loss: 0.03770611\n",
      "Epoch: 2090 cost = 0.028321330\n",
      "Validation Loss: 0.035090096\n",
      "Epoch: 2091 cost = 0.028318790\n",
      "Validation Loss: 0.06496206\n",
      "Epoch: 2092 cost = 0.028316216\n",
      "Validation Loss: 0.05985077\n",
      "Epoch: 2093 cost = 0.028313640\n",
      "Validation Loss: 0.062856056\n",
      "Epoch: 2094 cost = 0.028311065\n",
      "Validation Loss: 0.07095323\n",
      "Epoch: 2095 cost = 0.028308504\n",
      "Validation Loss: 0.036231045\n",
      "Epoch: 2096 cost = 0.028305936\n",
      "Validation Loss: 0.039565105\n",
      "Epoch: 2097 cost = 0.028303408\n",
      "Validation Loss: 0.038184114\n",
      "Epoch: 2098 cost = 0.028300765\n",
      "Validation Loss: 0.04312478\n",
      "Epoch: 2099 cost = 0.028298295\n",
      "Validation Loss: 0.044466116\n",
      "Epoch: 2100 cost = 0.028295727\n",
      "Validation Loss: 0.05086253\n",
      "Epoch: 2101 cost = 0.028293178\n",
      "Validation Loss: 0.046756797\n",
      "Epoch: 2102 cost = 0.028290642\n",
      "Validation Loss: 0.08472287\n",
      "Epoch: 2103 cost = 0.028288184\n",
      "Validation Loss: 0.08548589\n",
      "Epoch: 2104 cost = 0.028285657\n",
      "Validation Loss: 0.07358424\n",
      "Epoch: 2105 cost = 0.028283102\n",
      "Validation Loss: 0.056162465\n",
      "Epoch: 2106 cost = 0.028280609\n",
      "Validation Loss: 0.044737816\n",
      "Epoch: 2107 cost = 0.028278097\n",
      "Validation Loss: 0.047951095\n",
      "Epoch: 2108 cost = 0.028275622\n",
      "Validation Loss: 0.041685216\n",
      "Epoch: 2109 cost = 0.028273114\n",
      "Validation Loss: 0.03726912\n",
      "Epoch: 2110 cost = 0.028270581\n",
      "Validation Loss: 0.039139748\n",
      "Epoch: 2111 cost = 0.028268105\n",
      "Validation Loss: 0.036722716\n",
      "Epoch: 2112 cost = 0.028265665\n",
      "Validation Loss: 0.03705912\n",
      "Epoch: 2113 cost = 0.028263172\n",
      "Validation Loss: 0.036626033\n",
      "Epoch: 2114 cost = 0.028260659\n",
      "Validation Loss: 0.05103307\n",
      "Epoch: 2115 cost = 0.028258208\n",
      "Validation Loss: 0.047883783\n",
      "Epoch: 2116 cost = 0.028255752\n",
      "Validation Loss: 0.04121475\n",
      "Epoch: 2117 cost = 0.028253254\n",
      "Validation Loss: 0.038089555\n",
      "Epoch: 2118 cost = 0.028250763\n",
      "Validation Loss: 0.03866107\n",
      "Epoch: 2119 cost = 0.028248393\n",
      "Validation Loss: 0.03661776\n",
      "Epoch: 2120 cost = 0.028245941\n",
      "Validation Loss: 0.03801253\n",
      "Epoch: 2121 cost = 0.028243511\n",
      "Validation Loss: 0.050612215\n",
      "Epoch: 2122 cost = 0.028241032\n",
      "Validation Loss: 0.03427591\n",
      "Epoch: 2123 cost = 0.028238580\n",
      "Validation Loss: 0.0418564\n",
      "Epoch: 2124 cost = 0.028236145\n",
      "Validation Loss: 0.03700365\n",
      "Epoch: 2125 cost = 0.028233759\n",
      "Validation Loss: 0.0357209\n",
      "Epoch: 2126 cost = 0.028231325\n",
      "Validation Loss: 0.037981477\n",
      "Epoch: 2127 cost = 0.028228915\n",
      "Validation Loss: 0.039797872\n",
      "Epoch: 2128 cost = 0.028226512\n",
      "Validation Loss: 0.039518815\n",
      "Epoch: 2129 cost = 0.028224096\n",
      "Validation Loss: 0.049006354\n",
      "Epoch: 2130 cost = 0.028221657\n",
      "Validation Loss: 0.043576464\n",
      "Epoch: 2131 cost = 0.028219305\n",
      "Validation Loss: 0.038152844\n",
      "Epoch: 2132 cost = 0.028216834\n",
      "Validation Loss: 0.0334336\n",
      "Epoch: 2133 cost = 0.028214520\n",
      "Validation Loss: 0.04122883\n",
      "Epoch: 2134 cost = 0.028212123\n",
      "Validation Loss: 0.039508514\n",
      "Epoch: 2135 cost = 0.028209693\n",
      "Validation Loss: 0.042723604\n",
      "Epoch: 2136 cost = 0.028207344\n",
      "Validation Loss: 0.037764005\n",
      "Epoch: 2137 cost = 0.028204960\n",
      "Validation Loss: 0.046658076\n",
      "Epoch: 2138 cost = 0.028202612\n",
      "Validation Loss: 0.0447808\n",
      "Epoch: 2139 cost = 0.028200225\n",
      "Validation Loss: 0.045547307\n",
      "Epoch: 2140 cost = 0.028197819\n",
      "Validation Loss: 0.06076029\n",
      "Epoch: 2141 cost = 0.028195493\n",
      "Validation Loss: 0.055904437\n",
      "Epoch: 2142 cost = 0.028193085\n",
      "Validation Loss: 0.06485265\n",
      "Epoch: 2143 cost = 0.028190817\n",
      "Validation Loss: 0.05153363\n",
      "Epoch: 2144 cost = 0.028188387\n",
      "Validation Loss: 0.047432408\n",
      "Epoch: 2145 cost = 0.028186134\n",
      "Validation Loss: 0.044085134\n",
      "Epoch: 2146 cost = 0.028183709\n",
      "Validation Loss: 0.04533333\n",
      "Epoch: 2147 cost = 0.028181410\n",
      "Validation Loss: 0.051431887\n",
      "Epoch: 2148 cost = 0.028179089\n",
      "Validation Loss: 0.048271306\n",
      "Epoch: 2149 cost = 0.028176760\n",
      "Validation Loss: 0.041443102\n",
      "Epoch: 2150 cost = 0.028174359\n",
      "Validation Loss: 0.040967185\n",
      "Epoch: 2151 cost = 0.028172067\n",
      "Validation Loss: 0.035593193\n",
      "Epoch: 2152 cost = 0.028169746\n",
      "Validation Loss: 0.037903395\n",
      "Epoch: 2153 cost = 0.028167432\n",
      "Validation Loss: 0.06316947\n",
      "Epoch: 2154 cost = 0.028165169\n",
      "Validation Loss: 0.08386026\n",
      "Epoch: 2155 cost = 0.028162840\n",
      "Validation Loss: 0.096245855\n",
      "Epoch: 2156 cost = 0.028160534\n",
      "Validation Loss: 0.09184453\n",
      "Epoch: 2157 cost = 0.028158219\n",
      "Validation Loss: 0.14268807\n",
      "Epoch: 2158 cost = 0.028155861\n",
      "Validation Loss: 0.10099421\n",
      "Epoch: 2159 cost = 0.028153628\n",
      "Validation Loss: 0.044584494\n",
      "Epoch: 2160 cost = 0.028151352\n",
      "Validation Loss: 0.03418857\n",
      "Epoch: 2161 cost = 0.028149056\n",
      "Validation Loss: 0.035936557\n",
      "Epoch: 2162 cost = 0.028146751\n",
      "Validation Loss: 0.041564062\n",
      "Epoch: 2163 cost = 0.028144483\n",
      "Validation Loss: 0.04892174\n",
      "Epoch: 2164 cost = 0.028142204\n",
      "Validation Loss: 0.041770402\n",
      "Epoch: 2165 cost = 0.028139887\n",
      "Validation Loss: 0.040892687\n",
      "Epoch: 2166 cost = 0.028137654\n",
      "Validation Loss: 0.038696196\n",
      "Epoch: 2167 cost = 0.028135369\n",
      "Validation Loss: 0.040027175\n",
      "Epoch: 2168 cost = 0.028133097\n",
      "Validation Loss: 0.044598486\n",
      "Epoch: 2169 cost = 0.028130877\n",
      "Validation Loss: 0.042089045\n",
      "Epoch: 2170 cost = 0.028128568\n",
      "Validation Loss: 0.041254986\n",
      "Epoch: 2171 cost = 0.028126370\n",
      "Validation Loss: 0.044402003\n",
      "Epoch: 2172 cost = 0.028124085\n",
      "Validation Loss: 0.044331916\n",
      "Epoch: 2173 cost = 0.028121837\n",
      "Validation Loss: 0.047538202\n",
      "Epoch: 2174 cost = 0.028119571\n",
      "Validation Loss: 0.046575185\n",
      "Epoch: 2175 cost = 0.028117389\n",
      "Validation Loss: 0.042754285\n",
      "Epoch: 2176 cost = 0.028115138\n",
      "Validation Loss: 0.06275615\n",
      "Epoch: 2177 cost = 0.028112909\n",
      "Validation Loss: 0.0959047\n",
      "Epoch: 2178 cost = 0.028110637\n",
      "Validation Loss: 0.07816688\n",
      "Epoch: 2179 cost = 0.028108401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.054172356\n",
      "Epoch: 2180 cost = 0.028106230\n",
      "Validation Loss: 0.044045255\n",
      "Epoch: 2181 cost = 0.028104015\n",
      "Validation Loss: 0.058397625\n",
      "Epoch: 2182 cost = 0.028101732\n",
      "Validation Loss: 0.10410594\n",
      "Epoch: 2183 cost = 0.028099519\n",
      "Validation Loss: 0.06634959\n",
      "Epoch: 2184 cost = 0.028097351\n",
      "Validation Loss: 0.04846465\n",
      "Epoch: 2185 cost = 0.028095142\n",
      "Validation Loss: 0.040678717\n",
      "Epoch: 2186 cost = 0.028092909\n",
      "Validation Loss: 0.035706114\n",
      "Epoch: 2187 cost = 0.028090762\n",
      "Validation Loss: 0.039554056\n",
      "Epoch: 2188 cost = 0.028088491\n",
      "Validation Loss: 0.038031437\n",
      "Epoch: 2189 cost = 0.028086307\n",
      "Validation Loss: 0.035211023\n",
      "Epoch: 2190 cost = 0.028084078\n",
      "Validation Loss: 0.03932129\n",
      "Epoch: 2191 cost = 0.028081947\n",
      "Validation Loss: 0.03893233\n",
      "Epoch: 2192 cost = 0.028079799\n",
      "Validation Loss: 0.03979767\n",
      "Epoch: 2193 cost = 0.028077569\n",
      "Validation Loss: 0.03412943\n",
      "Epoch: 2194 cost = 0.028075379\n",
      "Validation Loss: 0.034042917\n",
      "Epoch: 2195 cost = 0.028073183\n",
      "Validation Loss: 0.036918923\n",
      "Epoch: 2196 cost = 0.028070999\n",
      "Validation Loss: 0.03476399\n",
      "Epoch: 2197 cost = 0.028068829\n",
      "Validation Loss: 0.03800193\n",
      "Epoch: 2198 cost = 0.028066668\n",
      "Validation Loss: 0.04617143\n",
      "Epoch: 2199 cost = 0.028064441\n",
      "Validation Loss: 0.051666785\n",
      "Epoch: 2200 cost = 0.028062336\n",
      "Validation Loss: 0.043656588\n",
      "Epoch: 2201 cost = 0.028060144\n",
      "Validation Loss: 0.04733416\n",
      "Epoch: 2202 cost = 0.028058009\n",
      "Validation Loss: 0.047701187\n",
      "Epoch: 2203 cost = 0.028055892\n",
      "Validation Loss: 0.03837273\n",
      "Epoch: 2204 cost = 0.028053675\n",
      "Validation Loss: 0.03971302\n",
      "Epoch: 2205 cost = 0.028051598\n",
      "Validation Loss: 0.055038277\n",
      "Epoch: 2206 cost = 0.028049380\n",
      "Validation Loss: 0.045683317\n",
      "Epoch: 2207 cost = 0.028047297\n",
      "Validation Loss: 0.06743436\n",
      "Epoch: 2208 cost = 0.028045127\n",
      "Validation Loss: 0.07510797\n",
      "Epoch: 2209 cost = 0.028042960\n",
      "Validation Loss: 0.07936207\n",
      "Epoch: 2210 cost = 0.028040844\n",
      "Validation Loss: 0.04502882\n",
      "Epoch: 2211 cost = 0.028038699\n",
      "Validation Loss: 0.03543834\n",
      "Epoch: 2212 cost = 0.028036569\n",
      "Validation Loss: 0.034296952\n",
      "Epoch: 2213 cost = 0.028034425\n",
      "Validation Loss: 0.038772076\n",
      "Epoch: 2214 cost = 0.028032293\n",
      "Validation Loss: 0.057788134\n",
      "Epoch: 2215 cost = 0.028030195\n",
      "Validation Loss: 0.06633765\n",
      "Epoch: 2216 cost = 0.028028044\n",
      "Validation Loss: 0.056617916\n",
      "Epoch: 2217 cost = 0.028025937\n",
      "Validation Loss: 0.05996219\n",
      "Epoch: 2218 cost = 0.028023873\n",
      "Validation Loss: 0.053477935\n",
      "Epoch: 2219 cost = 0.028021710\n",
      "Validation Loss: 0.07605978\n",
      "Epoch: 2220 cost = 0.028019600\n",
      "Validation Loss: 0.06753699\n",
      "Epoch: 2221 cost = 0.028017483\n",
      "Validation Loss: 0.034146823\n",
      "Epoch: 2222 cost = 0.028015311\n",
      "Validation Loss: 0.03499831\n",
      "Epoch: 2223 cost = 0.028013243\n",
      "Validation Loss: 0.03635913\n",
      "Epoch: 2224 cost = 0.028011209\n",
      "Validation Loss: 0.03864557\n",
      "Epoch: 2225 cost = 0.028009084\n",
      "Validation Loss: 0.043917716\n",
      "Epoch: 2226 cost = 0.028006942\n",
      "Validation Loss: 0.04446809\n",
      "Epoch: 2227 cost = 0.028004914\n",
      "Validation Loss: 0.038116377\n",
      "Epoch: 2228 cost = 0.028002790\n",
      "Validation Loss: 0.035262056\n",
      "Epoch: 2229 cost = 0.028000686\n",
      "Validation Loss: 0.04475895\n",
      "Epoch: 2230 cost = 0.027998575\n",
      "Validation Loss: 0.05483408\n",
      "Epoch: 2231 cost = 0.027996543\n",
      "Validation Loss: 0.04544361\n",
      "Epoch: 2232 cost = 0.027994456\n",
      "Validation Loss: 0.064052306\n",
      "Epoch: 2233 cost = 0.027992347\n",
      "Validation Loss: 0.051008813\n",
      "Epoch: 2234 cost = 0.027990267\n",
      "Validation Loss: 0.037759446\n",
      "Epoch: 2235 cost = 0.027988225\n",
      "Validation Loss: 0.042549744\n",
      "Epoch: 2236 cost = 0.027986124\n",
      "Validation Loss: 0.051422875\n",
      "Epoch: 2237 cost = 0.027984066\n",
      "Validation Loss: 0.036299918\n",
      "Epoch: 2238 cost = 0.027981954\n",
      "Validation Loss: 0.036213435\n",
      "Epoch: 2239 cost = 0.027979895\n",
      "Validation Loss: 0.04137988\n",
      "Epoch: 2240 cost = 0.027977871\n",
      "Validation Loss: 0.04200906\n",
      "Epoch: 2241 cost = 0.027975821\n",
      "Validation Loss: 0.04226604\n",
      "Epoch: 2242 cost = 0.027973781\n",
      "Validation Loss: 0.051279597\n",
      "Epoch: 2243 cost = 0.027971644\n",
      "Validation Loss: 0.08691764\n",
      "Epoch: 2244 cost = 0.027969612\n",
      "Validation Loss: 0.08554334\n",
      "Epoch: 2245 cost = 0.027967597\n",
      "Validation Loss: 0.090881184\n",
      "Epoch: 2246 cost = 0.027965501\n",
      "Validation Loss: 0.05588952\n",
      "Epoch: 2247 cost = 0.027963430\n",
      "Validation Loss: 0.03948909\n",
      "Epoch: 2248 cost = 0.027961443\n",
      "Validation Loss: 0.044209912\n",
      "Epoch: 2249 cost = 0.027959383\n",
      "Validation Loss: 0.046181664\n",
      "Epoch: 2250 cost = 0.027957338\n",
      "Validation Loss: 0.06296035\n",
      "Epoch: 2251 cost = 0.027955314\n",
      "Validation Loss: 0.056527633\n",
      "Epoch: 2252 cost = 0.027953268\n",
      "Validation Loss: 0.058631945\n",
      "Epoch: 2253 cost = 0.027951208\n",
      "Validation Loss: 0.057910644\n",
      "Epoch: 2254 cost = 0.027949195\n",
      "Validation Loss: 0.038637336\n",
      "Epoch: 2255 cost = 0.027947183\n",
      "Validation Loss: 0.03611079\n",
      "Epoch: 2256 cost = 0.027945192\n",
      "Validation Loss: 0.03679356\n",
      "Epoch: 2257 cost = 0.027943107\n",
      "Validation Loss: 0.035210002\n",
      "Epoch: 2258 cost = 0.027941081\n",
      "Validation Loss: 0.04281424\n",
      "Epoch: 2259 cost = 0.027939066\n",
      "Validation Loss: 0.043085877\n",
      "Epoch: 2260 cost = 0.027937065\n",
      "Validation Loss: 0.035552077\n",
      "Epoch: 2261 cost = 0.027935003\n",
      "Validation Loss: 0.03964883\n",
      "Epoch: 2262 cost = 0.027932962\n",
      "Validation Loss: 0.042359564\n",
      "Epoch: 2263 cost = 0.027930978\n",
      "Validation Loss: 0.04251499\n",
      "Epoch: 2264 cost = 0.027928947\n",
      "Validation Loss: 0.041985735\n",
      "Epoch: 2265 cost = 0.027926968\n",
      "Validation Loss: 0.040720515\n",
      "Epoch: 2266 cost = 0.027924944\n",
      "Validation Loss: 0.039479595\n",
      "Epoch: 2267 cost = 0.027922928\n",
      "Validation Loss: 0.038026225\n",
      "Epoch: 2268 cost = 0.027920963\n",
      "Validation Loss: 0.035851378\n",
      "Epoch: 2269 cost = 0.027918953\n",
      "Validation Loss: 0.041963704\n",
      "Epoch: 2270 cost = 0.027916952\n",
      "Validation Loss: 0.03781053\n",
      "Epoch: 2271 cost = 0.027914960\n",
      "Validation Loss: 0.03636419\n",
      "Epoch: 2272 cost = 0.027912969\n",
      "Validation Loss: 0.07456414\n",
      "Epoch: 2273 cost = 0.027910992\n",
      "Validation Loss: 0.08801005\n",
      "Epoch: 2274 cost = 0.027908945\n",
      "Validation Loss: 0.04431622\n",
      "Epoch: 2275 cost = 0.027907013\n",
      "Validation Loss: 0.05552939\n",
      "Epoch: 2276 cost = 0.027904968\n",
      "Validation Loss: 0.08140598\n",
      "Epoch: 2277 cost = 0.027902980\n",
      "Validation Loss: 0.066962905\n",
      "Epoch: 2278 cost = 0.027901025\n",
      "Validation Loss: 0.051831923\n",
      "Epoch: 2279 cost = 0.027899018\n",
      "Validation Loss: 0.038577758\n",
      "Epoch: 2280 cost = 0.027897051\n",
      "Validation Loss: 0.034768745\n",
      "Epoch: 2281 cost = 0.027895074\n",
      "Validation Loss: 0.040651735\n",
      "Epoch: 2282 cost = 0.027893092\n",
      "Validation Loss: 0.04117409\n",
      "Epoch: 2283 cost = 0.027891096\n",
      "Validation Loss: 0.036213063\n",
      "Epoch: 2284 cost = 0.027889135\n",
      "Validation Loss: 0.044060245\n",
      "Epoch: 2285 cost = 0.027887197\n",
      "Validation Loss: 0.066494614\n",
      "Epoch: 2286 cost = 0.027885175\n",
      "Validation Loss: 0.046764582\n",
      "Epoch: 2287 cost = 0.027883225\n",
      "Validation Loss: 0.047379397\n",
      "Epoch: 2288 cost = 0.027881237\n",
      "Validation Loss: 0.039043874\n",
      "Epoch: 2289 cost = 0.027879298\n",
      "Validation Loss: 0.038610447\n",
      "Epoch: 2290 cost = 0.027877339\n",
      "Validation Loss: 0.040768955\n",
      "Epoch: 2291 cost = 0.027875310\n",
      "Validation Loss: 0.036993496\n",
      "Epoch: 2292 cost = 0.027873403\n",
      "Validation Loss: 0.033592634\n",
      "Epoch: 2293 cost = 0.027871432\n",
      "Validation Loss: 0.04052736\n",
      "Epoch: 2294 cost = 0.027869557\n",
      "Validation Loss: 0.036508776\n",
      "Epoch: 2295 cost = 0.027867546\n",
      "Validation Loss: 0.036668587\n",
      "Epoch: 2296 cost = 0.027865560\n",
      "Validation Loss: 0.0385216\n",
      "Epoch: 2297 cost = 0.027863656\n",
      "Validation Loss: 0.038909998\n",
      "Epoch: 2298 cost = 0.027861680\n",
      "Validation Loss: 0.036709353\n",
      "Epoch: 2299 cost = 0.027859724\n",
      "Validation Loss: 0.04043194\n",
      "Epoch: 2300 cost = 0.027857843\n",
      "Validation Loss: 0.041322038\n",
      "Epoch: 2301 cost = 0.027855857\n",
      "Validation Loss: 0.03506268\n",
      "Epoch: 2302 cost = 0.027853926\n",
      "Validation Loss: 0.037247784\n",
      "Epoch: 2303 cost = 0.027852015\n",
      "Validation Loss: 0.04398107\n",
      "Epoch: 2304 cost = 0.027850012\n",
      "Validation Loss: 0.037289795\n",
      "Epoch: 2305 cost = 0.027848144\n",
      "Validation Loss: 0.039361093\n",
      "Epoch: 2306 cost = 0.027846084\n",
      "Validation Loss: 0.06458562\n",
      "Epoch: 2307 cost = 0.027844159\n",
      "Validation Loss: 0.07466781\n",
      "Epoch: 2308 cost = 0.027842332\n",
      "Validation Loss: 0.06807768\n",
      "Epoch: 2309 cost = 0.027840368\n",
      "Validation Loss: 0.052235737\n",
      "Epoch: 2310 cost = 0.027838386\n",
      "Validation Loss: 0.0360059\n",
      "Epoch: 2311 cost = 0.027836487\n",
      "Validation Loss: 0.04294447\n",
      "Epoch: 2312 cost = 0.027834552\n",
      "Validation Loss: 0.046221886\n",
      "Epoch: 2313 cost = 0.027832615\n",
      "Validation Loss: 0.06494926\n",
      "Epoch: 2314 cost = 0.027830711\n",
      "Validation Loss: 0.08396152\n",
      "Epoch: 2315 cost = 0.027828781\n",
      "Validation Loss: 0.0740587\n",
      "Epoch: 2316 cost = 0.027826889\n",
      "Validation Loss: 0.048418228\n",
      "Epoch: 2317 cost = 0.027824952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.045940388\n",
      "Epoch: 2318 cost = 0.027823047\n",
      "Validation Loss: 0.061159875\n",
      "Epoch: 2319 cost = 0.027821140\n",
      "Validation Loss: 0.118001014\n",
      "Epoch: 2320 cost = 0.027819234\n",
      "Validation Loss: 0.091495164\n",
      "Epoch: 2321 cost = 0.027817277\n",
      "Validation Loss: 0.036028143\n",
      "Epoch: 2322 cost = 0.027815418\n",
      "Validation Loss: 0.036119465\n",
      "Epoch: 2323 cost = 0.027813437\n",
      "Validation Loss: 0.03564664\n",
      "Epoch: 2324 cost = 0.027811593\n",
      "Validation Loss: 0.03934085\n",
      "Epoch: 2325 cost = 0.027809655\n",
      "Validation Loss: 0.0420066\n",
      "Epoch: 2326 cost = 0.027807813\n",
      "Validation Loss: 0.03801423\n",
      "Epoch: 2327 cost = 0.027805861\n",
      "Validation Loss: 0.041833796\n",
      "Epoch: 2328 cost = 0.027803971\n",
      "Validation Loss: 0.05469021\n",
      "Epoch: 2329 cost = 0.027802025\n",
      "Validation Loss: 0.04358868\n",
      "Epoch: 2330 cost = 0.027800128\n",
      "Validation Loss: 0.03850298\n",
      "Epoch: 2331 cost = 0.027798313\n",
      "Validation Loss: 0.04121819\n",
      "Epoch: 2332 cost = 0.027796377\n",
      "Validation Loss: 0.039322577\n",
      "Epoch: 2333 cost = 0.027794506\n",
      "Validation Loss: 0.034625858\n",
      "Epoch: 2334 cost = 0.027792604\n",
      "Validation Loss: 0.03482325\n",
      "Epoch: 2335 cost = 0.027790629\n",
      "Validation Loss: 0.04103834\n",
      "Epoch: 2336 cost = 0.027788806\n",
      "Validation Loss: 0.0408021\n",
      "Epoch: 2337 cost = 0.027786934\n",
      "Validation Loss: 0.03941559\n",
      "Epoch: 2338 cost = 0.027785031\n",
      "Validation Loss: 0.06273323\n",
      "Epoch: 2339 cost = 0.027783176\n",
      "Validation Loss: 0.056812756\n",
      "Epoch: 2340 cost = 0.027781216\n",
      "Validation Loss: 0.055836886\n",
      "Epoch: 2341 cost = 0.027779371\n",
      "Validation Loss: 0.050968785\n",
      "Epoch: 2342 cost = 0.027777468\n",
      "Validation Loss: 0.03592246\n",
      "Epoch: 2343 cost = 0.027775572\n",
      "Validation Loss: 0.036363725\n",
      "Epoch: 2344 cost = 0.027773749\n",
      "Validation Loss: 0.037032776\n",
      "Epoch: 2345 cost = 0.027771867\n",
      "Validation Loss: 0.04770142\n",
      "Epoch: 2346 cost = 0.027769969\n",
      "Validation Loss: 0.041874852\n",
      "Epoch: 2347 cost = 0.027768120\n",
      "Validation Loss: 0.062660106\n",
      "Epoch: 2348 cost = 0.027766236\n",
      "Validation Loss: 0.051366333\n",
      "Epoch: 2349 cost = 0.027764341\n",
      "Validation Loss: 0.043277603\n",
      "Epoch: 2350 cost = 0.027762496\n",
      "Validation Loss: 0.04476838\n",
      "Epoch: 2351 cost = 0.027760639\n",
      "Validation Loss: 0.04379081\n",
      "Epoch: 2352 cost = 0.027758726\n",
      "Validation Loss: 0.045141567\n",
      "Epoch: 2353 cost = 0.027756872\n",
      "Validation Loss: 0.050725237\n",
      "Epoch: 2354 cost = 0.027755036\n",
      "Validation Loss: 0.034084227\n",
      "Epoch: 2355 cost = 0.027753164\n",
      "Validation Loss: 0.035662986\n",
      "Epoch: 2356 cost = 0.027751300\n",
      "Validation Loss: 0.042603295\n",
      "Epoch: 2357 cost = 0.027749422\n",
      "Validation Loss: 0.061137665\n",
      "Epoch: 2358 cost = 0.027747547\n",
      "Validation Loss: 0.095603876\n",
      "Epoch: 2359 cost = 0.027745704\n",
      "Validation Loss: 0.16947591\n",
      "Epoch: 2360 cost = 0.027743855\n",
      "Validation Loss: 0.1347849\n",
      "Epoch: 2361 cost = 0.027742008\n",
      "Validation Loss: 0.10139358\n",
      "Epoch: 2362 cost = 0.027740182\n",
      "Validation Loss: 0.07355712\n",
      "Epoch: 2363 cost = 0.027738312\n",
      "Validation Loss: 0.052272666\n",
      "Epoch: 2364 cost = 0.027736484\n",
      "Validation Loss: 0.044915922\n",
      "Epoch: 2365 cost = 0.027734581\n",
      "Validation Loss: 0.036645155\n",
      "Epoch: 2366 cost = 0.027732741\n",
      "Validation Loss: 0.034483735\n",
      "Epoch: 2367 cost = 0.027730895\n",
      "Validation Loss: 0.035862453\n",
      "Epoch: 2368 cost = 0.027729010\n",
      "Validation Loss: 0.03537949\n",
      "Epoch: 2369 cost = 0.027727169\n",
      "Validation Loss: 0.064781465\n",
      "Epoch: 2370 cost = 0.027725379\n",
      "Validation Loss: 0.09426794\n",
      "Epoch: 2371 cost = 0.027723512\n",
      "Validation Loss: 0.079970375\n",
      "Epoch: 2372 cost = 0.027721704\n",
      "Validation Loss: 0.049897704\n",
      "Epoch: 2373 cost = 0.027719850\n",
      "Validation Loss: 0.04981492\n",
      "Epoch: 2374 cost = 0.027717976\n",
      "Validation Loss: 0.046279013\n",
      "Epoch: 2375 cost = 0.027716192\n",
      "Validation Loss: 0.041742932\n",
      "Epoch: 2376 cost = 0.027714238\n",
      "Validation Loss: 0.036426503\n",
      "Epoch: 2377 cost = 0.027712507\n",
      "Validation Loss: 0.03825284\n",
      "Epoch: 2378 cost = 0.027710627\n",
      "Validation Loss: 0.035068743\n",
      "Epoch: 2379 cost = 0.027708873\n",
      "Validation Loss: 0.042129934\n",
      "Epoch: 2380 cost = 0.027707026\n",
      "Validation Loss: 0.036107287\n",
      "Epoch: 2381 cost = 0.027705169\n",
      "Validation Loss: 0.042143077\n",
      "Epoch: 2382 cost = 0.027703318\n",
      "Validation Loss: 0.041754875\n",
      "Epoch: 2383 cost = 0.027701515\n",
      "Validation Loss: 0.038412046\n",
      "Epoch: 2384 cost = 0.027699683\n",
      "Validation Loss: 0.037151933\n",
      "Epoch: 2385 cost = 0.027697837\n",
      "Validation Loss: 0.05089272\n",
      "Epoch: 2386 cost = 0.027695994\n",
      "Validation Loss: 0.04211615\n",
      "Epoch: 2387 cost = 0.027694230\n",
      "Validation Loss: 0.032601602\n",
      "Epoch: 2388 cost = 0.027692369\n",
      "Validation Loss: 0.04304893\n",
      "Epoch: 2389 cost = 0.027690551\n",
      "Validation Loss: 0.035538543\n",
      "Epoch: 2390 cost = 0.027688760\n",
      "Validation Loss: 0.033595473\n",
      "Epoch: 2391 cost = 0.027686925\n",
      "Validation Loss: 0.033814166\n",
      "Epoch: 2392 cost = 0.027685107\n",
      "Validation Loss: 0.043870874\n",
      "Epoch: 2393 cost = 0.027683326\n",
      "Validation Loss: 0.03193406\n",
      "Epoch: 2394 cost = 0.027681454\n",
      "Validation Loss: 0.04361952\n",
      "Epoch: 2395 cost = 0.027679675\n",
      "Validation Loss: 0.036299955\n",
      "Epoch: 2396 cost = 0.027677884\n",
      "Validation Loss: 0.03191763\n",
      "Epoch: 2397 cost = 0.027676063\n",
      "Validation Loss: 0.03631668\n",
      "Epoch: 2398 cost = 0.027674239\n",
      "Validation Loss: 0.040009398\n",
      "Epoch: 2399 cost = 0.027672432\n",
      "Validation Loss: 0.041799445\n",
      "Epoch: 2400 cost = 0.027670606\n",
      "Validation Loss: 0.041179158\n",
      "Epoch: 2401 cost = 0.027668818\n",
      "Validation Loss: 0.11265663\n",
      "Epoch: 2402 cost = 0.027666991\n",
      "Validation Loss: 0.17214885\n",
      "Epoch: 2403 cost = 0.027665206\n",
      "Validation Loss: 0.08344684\n",
      "Epoch: 2404 cost = 0.027663404\n",
      "Validation Loss: 0.038311843\n",
      "Epoch: 2405 cost = 0.027661612\n",
      "Validation Loss: 0.06410032\n",
      "Epoch: 2406 cost = 0.027659777\n",
      "Validation Loss: 0.069411494\n",
      "Epoch: 2407 cost = 0.027657971\n",
      "Validation Loss: 0.032085985\n",
      "Epoch: 2408 cost = 0.027656194\n",
      "Validation Loss: 0.036233764\n",
      "Epoch: 2409 cost = 0.027654382\n",
      "Validation Loss: 0.034173768\n",
      "Epoch: 2410 cost = 0.027652655\n",
      "Validation Loss: 0.038117625\n",
      "Epoch: 2411 cost = 0.027650868\n",
      "Validation Loss: 0.043482397\n",
      "Epoch: 2412 cost = 0.027649019\n",
      "Validation Loss: 0.035167683\n",
      "Epoch: 2413 cost = 0.027647189\n",
      "Validation Loss: 0.036554635\n",
      "Epoch: 2414 cost = 0.027645456\n",
      "Validation Loss: 0.051628485\n",
      "Epoch: 2415 cost = 0.027643633\n",
      "Validation Loss: 0.056089625\n",
      "Epoch: 2416 cost = 0.027641890\n",
      "Validation Loss: 0.054375272\n",
      "Epoch: 2417 cost = 0.027640061\n",
      "Validation Loss: 0.058293026\n",
      "Epoch: 2418 cost = 0.027638238\n",
      "Validation Loss: 0.045544278\n",
      "Epoch: 2419 cost = 0.027636505\n",
      "Validation Loss: 0.067240894\n",
      "Epoch: 2420 cost = 0.027634731\n",
      "Validation Loss: 0.118927985\n",
      "Epoch: 2421 cost = 0.027632894\n",
      "Validation Loss: 0.08553943\n",
      "Epoch: 2422 cost = 0.027631185\n",
      "Validation Loss: 0.084169194\n",
      "Epoch: 2423 cost = 0.027629390\n",
      "Validation Loss: 0.044832945\n",
      "Epoch: 2424 cost = 0.027627616\n",
      "Validation Loss: 0.044355683\n",
      "Epoch: 2425 cost = 0.027625842\n",
      "Validation Loss: 0.035749316\n",
      "Epoch: 2426 cost = 0.027624017\n",
      "Validation Loss: 0.040185947\n",
      "Epoch: 2427 cost = 0.027622218\n",
      "Validation Loss: 0.04088444\n",
      "Epoch: 2428 cost = 0.027620441\n",
      "Validation Loss: 0.038151294\n",
      "Epoch: 2429 cost = 0.027618687\n",
      "Validation Loss: 0.036858894\n",
      "Epoch: 2430 cost = 0.027616932\n",
      "Validation Loss: 0.040100016\n",
      "Epoch: 2431 cost = 0.027615184\n",
      "Validation Loss: 0.043567\n",
      "Epoch: 2432 cost = 0.027613393\n",
      "Validation Loss: 0.04383601\n",
      "Epoch: 2433 cost = 0.027611634\n",
      "Validation Loss: 0.038414385\n",
      "Epoch: 2434 cost = 0.027609835\n",
      "Validation Loss: 0.03467954\n",
      "Epoch: 2435 cost = 0.027608092\n",
      "Validation Loss: 0.07354509\n",
      "Epoch: 2436 cost = 0.027606309\n",
      "Validation Loss: 0.06877574\n",
      "Epoch: 2437 cost = 0.027604526\n",
      "Validation Loss: 0.03989688\n",
      "Epoch: 2438 cost = 0.027602792\n",
      "Validation Loss: 0.04020592\n",
      "Epoch: 2439 cost = 0.027601019\n",
      "Validation Loss: 0.05467711\n",
      "Epoch: 2440 cost = 0.027599242\n",
      "Validation Loss: 0.10126602\n",
      "Epoch: 2441 cost = 0.027597515\n",
      "Validation Loss: 0.06621686\n",
      "Epoch: 2442 cost = 0.027595708\n",
      "Validation Loss: 0.038803272\n",
      "Epoch: 2443 cost = 0.027593981\n",
      "Validation Loss: 0.040538035\n",
      "Epoch: 2444 cost = 0.027592211\n",
      "Validation Loss: 0.05874184\n",
      "Epoch: 2445 cost = 0.027590425\n",
      "Validation Loss: 0.06237038\n",
      "Epoch: 2446 cost = 0.027588704\n",
      "Validation Loss: 0.07169345\n",
      "Epoch: 2447 cost = 0.027586951\n",
      "Validation Loss: 0.072793625\n",
      "Epoch: 2448 cost = 0.027585188\n",
      "Validation Loss: 0.0785617\n",
      "Epoch: 2449 cost = 0.027583447\n",
      "Validation Loss: 0.06258288\n",
      "Epoch: 2450 cost = 0.027581656\n",
      "Validation Loss: 0.052988723\n",
      "Epoch: 2451 cost = 0.027579890\n",
      "Validation Loss: 0.034738794\n",
      "Epoch: 2452 cost = 0.027578182\n",
      "Validation Loss: 0.036647245\n",
      "Epoch: 2453 cost = 0.027576412\n",
      "Validation Loss: 0.049560104\n",
      "Epoch: 2454 cost = 0.027574642\n",
      "Validation Loss: 0.053623803\n",
      "Epoch: 2455 cost = 0.027572960\n",
      "Validation Loss: 0.043942418\n",
      "Epoch: 2456 cost = 0.027571159\n",
      "Validation Loss: 0.05502897\n",
      "Epoch: 2457 cost = 0.027569425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.073897675\n",
      "Epoch: 2458 cost = 0.027567740\n",
      "Validation Loss: 0.077070564\n",
      "Epoch: 2459 cost = 0.027565962\n",
      "Validation Loss: 0.08772347\n",
      "Epoch: 2460 cost = 0.027564171\n",
      "Validation Loss: 0.043950345\n",
      "Epoch: 2461 cost = 0.027562428\n",
      "Validation Loss: 0.03913744\n",
      "Epoch: 2462 cost = 0.027560736\n",
      "Validation Loss: 0.03657558\n",
      "Epoch: 2463 cost = 0.027558990\n",
      "Validation Loss: 0.043334924\n",
      "Epoch: 2464 cost = 0.027557297\n",
      "Validation Loss: 0.05955091\n",
      "Epoch: 2465 cost = 0.027555486\n",
      "Validation Loss: 0.040673107\n",
      "Epoch: 2466 cost = 0.027553770\n",
      "Validation Loss: 0.054193422\n",
      "Epoch: 2467 cost = 0.027552072\n",
      "Validation Loss: 0.04117514\n",
      "Epoch: 2468 cost = 0.027550278\n",
      "Validation Loss: 0.037587885\n",
      "Epoch: 2469 cost = 0.027548551\n",
      "Validation Loss: 0.043039445\n",
      "Epoch: 2470 cost = 0.027546850\n",
      "Validation Loss: 0.085450865\n",
      "Epoch: 2471 cost = 0.027545122\n",
      "Validation Loss: 0.087052286\n",
      "Epoch: 2472 cost = 0.027543353\n",
      "Validation Loss: 0.04005002\n",
      "Epoch: 2473 cost = 0.027541650\n",
      "Validation Loss: 0.04597502\n",
      "Epoch: 2474 cost = 0.027539901\n",
      "Validation Loss: 0.051671855\n",
      "Epoch: 2475 cost = 0.027538205\n",
      "Validation Loss: 0.051533982\n",
      "Epoch: 2476 cost = 0.027536533\n",
      "Validation Loss: 0.044053618\n",
      "Epoch: 2477 cost = 0.027534780\n",
      "Validation Loss: 0.04090948\n",
      "Epoch: 2478 cost = 0.027533058\n",
      "Validation Loss: 0.04610957\n",
      "Epoch: 2479 cost = 0.027531287\n",
      "Validation Loss: 0.05516427\n",
      "Epoch: 2480 cost = 0.027529574\n",
      "Validation Loss: 0.056703016\n",
      "Epoch: 2481 cost = 0.027527861\n",
      "Validation Loss: 0.053585906\n",
      "Epoch: 2482 cost = 0.027526109\n",
      "Validation Loss: 0.065122046\n",
      "Epoch: 2483 cost = 0.027524450\n",
      "Validation Loss: 0.08008772\n",
      "Epoch: 2484 cost = 0.027522718\n",
      "Validation Loss: 0.08982056\n",
      "Epoch: 2485 cost = 0.027521015\n",
      "Validation Loss: 0.091286644\n",
      "Epoch: 2486 cost = 0.027519284\n",
      "Validation Loss: 0.12905647\n",
      "Epoch: 2487 cost = 0.027517578\n",
      "Validation Loss: 0.083915524\n",
      "Epoch: 2488 cost = 0.027515881\n",
      "Validation Loss: 0.051811635\n",
      "Epoch: 2489 cost = 0.027514154\n",
      "Validation Loss: 0.04453081\n",
      "Epoch: 2490 cost = 0.027512442\n",
      "Validation Loss: 0.052481163\n",
      "Epoch: 2491 cost = 0.027510725\n",
      "Validation Loss: 0.07859047\n",
      "Epoch: 2492 cost = 0.027509022\n",
      "Validation Loss: 0.047882855\n",
      "Epoch: 2493 cost = 0.027507282\n",
      "Validation Loss: 0.037552312\n",
      "Epoch: 2494 cost = 0.027505585\n",
      "Validation Loss: 0.05148818\n",
      "Epoch: 2495 cost = 0.027503900\n",
      "Validation Loss: 0.046562966\n",
      "Epoch: 2496 cost = 0.027502229\n",
      "Validation Loss: 0.04220846\n",
      "Epoch: 2497 cost = 0.027500527\n",
      "Validation Loss: 0.04709974\n",
      "Epoch: 2498 cost = 0.027498765\n",
      "Validation Loss: 0.040762395\n",
      "Epoch: 2499 cost = 0.027497050\n",
      "Validation Loss: 0.036720816\n",
      "Epoch: 2500 cost = 0.027495363\n",
      "Validation Loss: 0.054106634\n",
      "Epoch: 2501 cost = 0.027493703\n",
      "Validation Loss: 0.033765167\n",
      "Epoch: 2502 cost = 0.027491996\n",
      "Validation Loss: 0.036893997\n",
      "Epoch: 2503 cost = 0.027490315\n",
      "Validation Loss: 0.03928393\n",
      "Epoch: 2504 cost = 0.027488591\n",
      "Validation Loss: 0.053940345\n",
      "Epoch: 2505 cost = 0.027486893\n",
      "Validation Loss: 0.09541449\n",
      "Epoch: 2506 cost = 0.027485228\n",
      "Validation Loss: 0.09862668\n",
      "Epoch: 2507 cost = 0.027483469\n",
      "Validation Loss: 0.09371153\n",
      "Epoch: 2508 cost = 0.027481816\n",
      "Validation Loss: 0.11067612\n",
      "Epoch: 2509 cost = 0.027480157\n",
      "Validation Loss: 0.04334643\n",
      "Epoch: 2510 cost = 0.027478426\n",
      "Validation Loss: 0.037157077\n",
      "Epoch: 2511 cost = 0.027476792\n",
      "Validation Loss: 0.036844224\n",
      "Epoch: 2512 cost = 0.027475064\n",
      "Validation Loss: 0.039171938\n",
      "Epoch: 2513 cost = 0.027473386\n",
      "Validation Loss: 0.058395933\n",
      "Epoch: 2514 cost = 0.027471688\n",
      "Validation Loss: 0.060669128\n",
      "Epoch: 2515 cost = 0.027469951\n",
      "Validation Loss: 0.049783513\n",
      "Epoch: 2516 cost = 0.027468277\n",
      "Validation Loss: 0.10705135\n",
      "Epoch: 2517 cost = 0.027466651\n",
      "Validation Loss: 0.10495324\n",
      "Epoch: 2518 cost = 0.027464973\n",
      "Validation Loss: 0.056351453\n",
      "Epoch: 2519 cost = 0.027463265\n",
      "Validation Loss: 0.04125336\n",
      "Epoch: 2520 cost = 0.027461568\n",
      "Validation Loss: 0.04036506\n",
      "Epoch: 2521 cost = 0.027459923\n",
      "Validation Loss: 0.062838145\n",
      "Epoch: 2522 cost = 0.027458252\n",
      "Validation Loss: 0.0788384\n",
      "Epoch: 2523 cost = 0.027456521\n",
      "Validation Loss: 0.06432424\n",
      "Epoch: 2524 cost = 0.027454867\n",
      "Validation Loss: 0.12984695\n",
      "Epoch: 2525 cost = 0.027453175\n",
      "Validation Loss: 0.178208\n",
      "Epoch: 2526 cost = 0.027451563\n",
      "Validation Loss: 0.090356804\n",
      "Epoch: 2527 cost = 0.027449865\n",
      "Validation Loss: 0.06984247\n",
      "Epoch: 2528 cost = 0.027448226\n",
      "Validation Loss: 0.040767144\n",
      "Epoch: 2529 cost = 0.027446562\n",
      "Validation Loss: 0.039991405\n",
      "Epoch: 2530 cost = 0.027444839\n",
      "Validation Loss: 0.062456127\n",
      "Epoch: 2531 cost = 0.027443187\n",
      "Validation Loss: 0.053773537\n",
      "Epoch: 2532 cost = 0.027441539\n",
      "Validation Loss: 0.04990817\n",
      "Epoch: 2533 cost = 0.027439837\n",
      "Validation Loss: 0.07514786\n",
      "Epoch: 2534 cost = 0.027438249\n",
      "Validation Loss: 0.1624451\n",
      "Epoch: 2535 cost = 0.027436512\n",
      "Validation Loss: 0.0831319\n",
      "Epoch: 2536 cost = 0.027434794\n",
      "Validation Loss: 0.047633298\n",
      "Epoch: 2537 cost = 0.027433178\n",
      "Validation Loss: 0.046202704\n",
      "Epoch: 2538 cost = 0.027431502\n",
      "Validation Loss: 0.03848491\n",
      "Epoch: 2539 cost = 0.027429902\n",
      "Validation Loss: 0.03766488\n",
      "Epoch: 2540 cost = 0.027428212\n",
      "Validation Loss: 0.036619987\n",
      "Epoch: 2541 cost = 0.027426592\n",
      "Validation Loss: 0.03975422\n",
      "Epoch: 2542 cost = 0.027424899\n",
      "Validation Loss: 0.05177579\n",
      "Epoch: 2543 cost = 0.027423201\n",
      "Validation Loss: 0.068243995\n",
      "Epoch: 2544 cost = 0.027421591\n",
      "Validation Loss: 0.057998374\n",
      "Epoch: 2545 cost = 0.027419987\n",
      "Validation Loss: 0.056908518\n",
      "Epoch: 2546 cost = 0.027418361\n",
      "Validation Loss: 0.033792496\n",
      "Epoch: 2547 cost = 0.027416699\n",
      "Validation Loss: 0.038010683\n",
      "Epoch: 2548 cost = 0.027414961\n",
      "Validation Loss: 0.041279297\n",
      "Epoch: 2549 cost = 0.027413319\n",
      "Validation Loss: 0.047732696\n",
      "Epoch: 2550 cost = 0.027411725\n",
      "Validation Loss: 0.04853567\n",
      "Epoch: 2551 cost = 0.027410073\n",
      "Validation Loss: 0.04533896\n",
      "Epoch: 2552 cost = 0.027408411\n",
      "Validation Loss: 0.03447896\n",
      "Epoch: 2553 cost = 0.027406741\n",
      "Validation Loss: 0.083095826\n",
      "Epoch: 2554 cost = 0.027405166\n",
      "Validation Loss: 0.12299339\n",
      "Epoch: 2555 cost = 0.027403479\n",
      "Validation Loss: 0.08862625\n",
      "Epoch: 2556 cost = 0.027401852\n",
      "Validation Loss: 0.06551169\n",
      "Epoch: 2557 cost = 0.027400193\n",
      "Validation Loss: 0.04976285\n",
      "Epoch: 2558 cost = 0.027398508\n",
      "Validation Loss: 0.039745506\n",
      "Epoch: 2559 cost = 0.027396941\n",
      "Validation Loss: 0.046131164\n",
      "Epoch: 2560 cost = 0.027395286\n",
      "Validation Loss: 0.04398391\n",
      "Epoch: 2561 cost = 0.027393743\n",
      "Validation Loss: 0.03549085\n",
      "Epoch: 2562 cost = 0.027392051\n",
      "Validation Loss: 0.03818381\n",
      "Epoch: 2563 cost = 0.027390425\n",
      "Validation Loss: 0.044005144\n",
      "Epoch: 2564 cost = 0.027388820\n",
      "Validation Loss: 0.04580264\n",
      "Epoch: 2565 cost = 0.027387154\n",
      "Validation Loss: 0.043685183\n",
      "Epoch: 2566 cost = 0.027385523\n",
      "Validation Loss: 0.044656664\n",
      "Epoch: 2567 cost = 0.027383877\n",
      "Validation Loss: 0.0446959\n",
      "Epoch: 2568 cost = 0.027382346\n",
      "Validation Loss: 0.047521796\n",
      "Epoch: 2569 cost = 0.027380628\n",
      "Validation Loss: 0.052048672\n",
      "Epoch: 2570 cost = 0.027379022\n",
      "Validation Loss: 0.05365688\n",
      "Epoch: 2571 cost = 0.027377434\n",
      "Validation Loss: 0.04858338\n",
      "Epoch: 2572 cost = 0.027375725\n",
      "Validation Loss: 0.04613266\n",
      "Epoch: 2573 cost = 0.027374230\n",
      "Validation Loss: 0.031893816\n",
      "Epoch: 2574 cost = 0.027372520\n",
      "Validation Loss: 0.050673187\n",
      "Epoch: 2575 cost = 0.027370929\n",
      "Validation Loss: 0.034384537\n",
      "Epoch: 2576 cost = 0.027369359\n",
      "Validation Loss: 0.03838206\n",
      "Epoch: 2577 cost = 0.027367707\n",
      "Validation Loss: 0.042001866\n",
      "Epoch: 2578 cost = 0.027366115\n",
      "Validation Loss: 0.032400697\n",
      "Epoch: 2579 cost = 0.027364494\n",
      "Validation Loss: 0.03509078\n",
      "Epoch: 2580 cost = 0.027362879\n",
      "Validation Loss: 0.040100746\n",
      "Epoch: 2581 cost = 0.027361268\n",
      "Validation Loss: 0.044433415\n",
      "Epoch: 2582 cost = 0.027359672\n",
      "Validation Loss: 0.035675675\n",
      "Epoch: 2583 cost = 0.027358079\n",
      "Validation Loss: 0.058490742\n",
      "Epoch: 2584 cost = 0.027356463\n",
      "Validation Loss: 0.046921518\n",
      "Epoch: 2585 cost = 0.027354863\n",
      "Validation Loss: 0.04875163\n",
      "Epoch: 2586 cost = 0.027353223\n",
      "Validation Loss: 0.04759835\n",
      "Epoch: 2587 cost = 0.027351680\n",
      "Validation Loss: 0.03839628\n",
      "Epoch: 2588 cost = 0.027350040\n",
      "Validation Loss: 0.038471945\n",
      "Epoch: 2589 cost = 0.027348464\n",
      "Validation Loss: 0.037769467\n",
      "Epoch: 2590 cost = 0.027346857\n",
      "Validation Loss: 0.05338259\n",
      "Epoch: 2591 cost = 0.027345279\n",
      "Validation Loss: 0.0416429\n",
      "Epoch: 2592 cost = 0.027343694\n",
      "Validation Loss: 0.03205096\n",
      "Epoch: 2593 cost = 0.027342059\n",
      "Validation Loss: 0.031136442\n",
      "Epoch: 2594 cost = 0.027340504\n",
      "Validation Loss: 0.054127585\n",
      "Epoch: 2595 cost = 0.027338887\n",
      "Validation Loss: 0.039938644\n",
      "Epoch: 2596 cost = 0.027337318\n",
      "Validation Loss: 0.047073133\n",
      "Epoch: 2597 cost = 0.027335764\n",
      "Validation Loss: 0.04123618\n",
      "Epoch: 2598 cost = 0.027334171\n",
      "Validation Loss: 0.062749274\n",
      "Epoch: 2599 cost = 0.027332541\n",
      "Validation Loss: 0.050007805\n",
      "Epoch: 2600 cost = 0.027330984\n",
      "Validation Loss: 0.06278215\n",
      "Epoch: 2601 cost = 0.027329398\n",
      "Validation Loss: 0.081533395\n",
      "Epoch: 2602 cost = 0.027327768\n",
      "Validation Loss: 0.122022055\n",
      "Epoch: 2603 cost = 0.027326218\n",
      "Validation Loss: 0.12207883\n",
      "Epoch: 2604 cost = 0.027324639\n",
      "Validation Loss: 0.09363686\n",
      "Epoch: 2605 cost = 0.027323069\n",
      "Validation Loss: 0.06636235\n",
      "Epoch: 2606 cost = 0.027321555\n",
      "Validation Loss: 0.038257923\n",
      "Epoch: 2607 cost = 0.027319916\n",
      "Validation Loss: 0.051048942\n",
      "Epoch: 2608 cost = 0.027318376\n",
      "Validation Loss: 0.084720604\n",
      "Epoch: 2609 cost = 0.027316828\n",
      "Validation Loss: 0.08250201\n",
      "Epoch: 2610 cost = 0.027315211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.062201627\n",
      "Epoch: 2611 cost = 0.027313675\n",
      "Validation Loss: 0.043167587\n",
      "Epoch: 2612 cost = 0.027312127\n",
      "Validation Loss: 0.040109392\n",
      "Epoch: 2613 cost = 0.027310537\n",
      "Validation Loss: 0.041728016\n",
      "Epoch: 2614 cost = 0.027309005\n",
      "Validation Loss: 0.08121809\n",
      "Epoch: 2615 cost = 0.027307456\n",
      "Validation Loss: 0.06457626\n",
      "Epoch: 2616 cost = 0.027305902\n",
      "Validation Loss: 0.05509213\n",
      "Epoch: 2617 cost = 0.027304348\n",
      "Validation Loss: 0.03996908\n",
      "Epoch: 2618 cost = 0.027302763\n",
      "Validation Loss: 0.03612488\n",
      "Epoch: 2619 cost = 0.027301200\n",
      "Validation Loss: 0.042566705\n",
      "Epoch: 2620 cost = 0.027299650\n",
      "Validation Loss: 0.044119388\n",
      "Epoch: 2621 cost = 0.027298113\n",
      "Validation Loss: 0.042423118\n",
      "Epoch: 2622 cost = 0.027296580\n",
      "Validation Loss: 0.036424935\n",
      "Epoch: 2623 cost = 0.027295010\n",
      "Validation Loss: 0.039221935\n",
      "Epoch: 2624 cost = 0.027293473\n",
      "Validation Loss: 0.033980723\n",
      "Epoch: 2625 cost = 0.027291955\n",
      "Validation Loss: 0.034431707\n",
      "Epoch: 2626 cost = 0.027290349\n",
      "Validation Loss: 0.04602181\n",
      "Epoch: 2627 cost = 0.027288867\n",
      "Validation Loss: 0.042188633\n",
      "Epoch: 2628 cost = 0.027287324\n",
      "Validation Loss: 0.041607633\n",
      "Epoch: 2629 cost = 0.027285746\n",
      "Validation Loss: 0.03625436\n",
      "Epoch: 2630 cost = 0.027284232\n",
      "Validation Loss: 0.039565176\n",
      "Epoch: 2631 cost = 0.027282731\n",
      "Validation Loss: 0.03919689\n",
      "Epoch: 2632 cost = 0.027281153\n",
      "Validation Loss: 0.04088785\n",
      "Epoch: 2633 cost = 0.027279663\n",
      "Validation Loss: 0.036750507\n",
      "Epoch: 2634 cost = 0.027278111\n",
      "Validation Loss: 0.034184147\n",
      "Epoch: 2635 cost = 0.027276558\n",
      "Validation Loss: 0.03575473\n",
      "Epoch: 2636 cost = 0.027275056\n",
      "Validation Loss: 0.031186977\n",
      "Epoch: 2637 cost = 0.027273526\n",
      "Validation Loss: 0.03166478\n",
      "Epoch: 2638 cost = 0.027272017\n",
      "Validation Loss: 0.04562641\n",
      "Epoch: 2639 cost = 0.027270500\n",
      "Validation Loss: 0.031403095\n",
      "Epoch: 2640 cost = 0.027268997\n",
      "Validation Loss: 0.034217622\n",
      "Epoch: 2641 cost = 0.027267426\n",
      "Validation Loss: 0.03257311\n",
      "Epoch: 2642 cost = 0.027265904\n",
      "Validation Loss: 0.035228744\n",
      "Epoch: 2643 cost = 0.027264397\n",
      "Validation Loss: 0.034685485\n",
      "Epoch: 2644 cost = 0.027262913\n",
      "Validation Loss: 0.030581223\n",
      "Epoch: 2645 cost = 0.027261407\n",
      "Validation Loss: 0.04002139\n",
      "Epoch: 2646 cost = 0.027259881\n",
      "Validation Loss: 0.039318632\n",
      "Epoch: 2647 cost = 0.027258382\n",
      "Validation Loss: 0.037648343\n",
      "Epoch: 2648 cost = 0.027256884\n",
      "Validation Loss: 0.03856688\n",
      "Epoch: 2649 cost = 0.027255363\n",
      "Validation Loss: 0.039350316\n",
      "Epoch: 2650 cost = 0.027253897\n",
      "Validation Loss: 0.044594914\n",
      "Epoch: 2651 cost = 0.027252354\n",
      "Validation Loss: 0.039407346\n",
      "Epoch: 2652 cost = 0.027250881\n",
      "Validation Loss: 0.035088386\n",
      "Epoch: 2653 cost = 0.027249354\n",
      "Validation Loss: 0.036759797\n",
      "Epoch: 2654 cost = 0.027247879\n",
      "Validation Loss: 0.043979425\n",
      "Epoch: 2655 cost = 0.027246348\n",
      "Validation Loss: 0.03851258\n",
      "Epoch: 2656 cost = 0.027244883\n",
      "Validation Loss: 0.045288503\n",
      "Epoch: 2657 cost = 0.027243434\n",
      "Validation Loss: 0.039284445\n",
      "Epoch: 2658 cost = 0.027241919\n",
      "Validation Loss: 0.034736384\n",
      "Epoch: 2659 cost = 0.027240452\n",
      "Validation Loss: 0.035178486\n",
      "Epoch: 2660 cost = 0.027238903\n",
      "Validation Loss: 0.04344574\n",
      "Epoch: 2661 cost = 0.027237422\n",
      "Validation Loss: 0.0908909\n",
      "Epoch: 2662 cost = 0.027235938\n",
      "Validation Loss: 0.16085285\n",
      "Epoch: 2663 cost = 0.027234461\n",
      "Validation Loss: 0.12049629\n",
      "Epoch: 2664 cost = 0.027233013\n",
      "Validation Loss: 0.069792375\n",
      "Epoch: 2665 cost = 0.027231532\n",
      "Validation Loss: 0.05996456\n",
      "Epoch: 2666 cost = 0.027230046\n",
      "Validation Loss: 0.04725298\n",
      "Epoch: 2667 cost = 0.027228545\n",
      "Validation Loss: 0.034498498\n",
      "Epoch: 2668 cost = 0.027227103\n",
      "Validation Loss: 0.03648935\n",
      "Epoch: 2669 cost = 0.027225658\n",
      "Validation Loss: 0.04017756\n",
      "Epoch: 2670 cost = 0.027224176\n",
      "Validation Loss: 0.044599395\n",
      "Epoch: 2671 cost = 0.027222677\n",
      "Validation Loss: 0.046745192\n",
      "Epoch: 2672 cost = 0.027221253\n",
      "Validation Loss: 0.046207435\n",
      "Epoch: 2673 cost = 0.027219781\n",
      "Validation Loss: 0.042031035\n",
      "Epoch: 2674 cost = 0.027218295\n",
      "Validation Loss: 0.039233524\n",
      "Epoch: 2675 cost = 0.027216879\n",
      "Validation Loss: 0.032188617\n",
      "Epoch: 2676 cost = 0.027215329\n",
      "Validation Loss: 0.032561418\n",
      "Epoch: 2677 cost = 0.027213920\n",
      "Validation Loss: 0.040138397\n",
      "Epoch: 2678 cost = 0.027212445\n",
      "Validation Loss: 0.04197997\n",
      "Epoch: 2679 cost = 0.027211005\n",
      "Validation Loss: 0.038063783\n",
      "Epoch: 2680 cost = 0.027209547\n",
      "Validation Loss: 0.048978627\n",
      "Epoch: 2681 cost = 0.027208083\n",
      "Validation Loss: 0.07552792\n",
      "Epoch: 2682 cost = 0.027206675\n",
      "Validation Loss: 0.05035817\n",
      "Epoch: 2683 cost = 0.027205175\n",
      "Validation Loss: 0.04692721\n",
      "Epoch: 2684 cost = 0.027203773\n",
      "Validation Loss: 0.04257752\n",
      "Epoch: 2685 cost = 0.027202292\n",
      "Validation Loss: 0.07804149\n",
      "Epoch: 2686 cost = 0.027200875\n",
      "Validation Loss: 0.12843433\n",
      "Epoch: 2687 cost = 0.027199444\n",
      "Validation Loss: 0.15253289\n",
      "Epoch: 2688 cost = 0.027197995\n",
      "Validation Loss: 0.101386555\n",
      "Epoch: 2689 cost = 0.027196549\n",
      "Validation Loss: 0.05278483\n",
      "Epoch: 2690 cost = 0.027195147\n",
      "Validation Loss: 0.03796869\n",
      "Epoch: 2691 cost = 0.027193636\n",
      "Validation Loss: 0.03822575\n",
      "Epoch: 2692 cost = 0.027192255\n",
      "Validation Loss: 0.040401153\n",
      "Epoch: 2693 cost = 0.027190823\n",
      "Validation Loss: 0.041367017\n",
      "Epoch: 2694 cost = 0.027189372\n",
      "Validation Loss: 0.035308994\n",
      "Epoch: 2695 cost = 0.027187977\n",
      "Validation Loss: 0.031007828\n",
      "Epoch: 2696 cost = 0.027186526\n",
      "Validation Loss: 0.043831415\n",
      "Epoch: 2697 cost = 0.027185103\n",
      "Validation Loss: 0.04922966\n",
      "Epoch: 2698 cost = 0.027183718\n",
      "Validation Loss: 0.04020767\n",
      "Epoch: 2699 cost = 0.027182277\n",
      "Validation Loss: 0.040388115\n",
      "Epoch: 2700 cost = 0.027180849\n",
      "Validation Loss: 0.042220257\n",
      "Epoch: 2701 cost = 0.027179407\n",
      "Validation Loss: 0.036456008\n",
      "Epoch: 2702 cost = 0.027178025\n",
      "Validation Loss: 0.0364313\n",
      "Epoch: 2703 cost = 0.027176596\n",
      "Validation Loss: 0.036517337\n",
      "Epoch: 2704 cost = 0.027175181\n",
      "Validation Loss: 0.037893053\n",
      "Epoch: 2705 cost = 0.027173738\n",
      "Validation Loss: 0.03793253\n",
      "Epoch: 2706 cost = 0.027172358\n",
      "Validation Loss: 0.036514536\n",
      "Epoch: 2707 cost = 0.027170970\n",
      "Validation Loss: 0.041191775\n",
      "Epoch: 2708 cost = 0.027169551\n",
      "Validation Loss: 0.040611908\n",
      "Epoch: 2709 cost = 0.027168179\n",
      "Validation Loss: 0.03562742\n",
      "Epoch: 2710 cost = 0.027166713\n",
      "Validation Loss: 0.031370107\n",
      "Epoch: 2711 cost = 0.027165322\n",
      "Validation Loss: 0.05707794\n",
      "Epoch: 2712 cost = 0.027163919\n",
      "Validation Loss: 0.061189543\n",
      "Epoch: 2713 cost = 0.027162522\n",
      "Validation Loss: 0.053600345\n",
      "Epoch: 2714 cost = 0.027161160\n",
      "Validation Loss: 0.03919312\n",
      "Epoch: 2715 cost = 0.027159771\n",
      "Validation Loss: 0.04419697\n",
      "Epoch: 2716 cost = 0.027158347\n",
      "Validation Loss: 0.04602209\n",
      "Epoch: 2717 cost = 0.027156962\n",
      "Validation Loss: 0.040492088\n",
      "Epoch: 2718 cost = 0.027155570\n",
      "Validation Loss: 0.043771576\n",
      "Epoch: 2719 cost = 0.027154181\n",
      "Validation Loss: 0.039093893\n",
      "Epoch: 2720 cost = 0.027152808\n",
      "Validation Loss: 0.042381864\n",
      "Epoch: 2721 cost = 0.027151373\n",
      "Validation Loss: 0.06843894\n",
      "Epoch: 2722 cost = 0.027150050\n",
      "Validation Loss: 0.038290083\n",
      "Epoch: 2723 cost = 0.027148656\n",
      "Validation Loss: 0.031929776\n",
      "Epoch: 2724 cost = 0.027147262\n",
      "Validation Loss: 0.038866345\n",
      "Epoch: 2725 cost = 0.027145918\n",
      "Validation Loss: 0.041838203\n",
      "Epoch: 2726 cost = 0.027144472\n",
      "Validation Loss: 0.036762647\n",
      "Epoch: 2727 cost = 0.027143163\n",
      "Validation Loss: 0.040287998\n",
      "Epoch: 2728 cost = 0.027141746\n",
      "Validation Loss: 0.04616771\n",
      "Epoch: 2729 cost = 0.027140320\n",
      "Validation Loss: 0.059730403\n",
      "Epoch: 2730 cost = 0.027139032\n",
      "Validation Loss: 0.07052213\n",
      "Epoch: 2731 cost = 0.027137655\n",
      "Validation Loss: 0.06366074\n",
      "Epoch: 2732 cost = 0.027136310\n",
      "Validation Loss: 0.067752205\n",
      "Epoch: 2733 cost = 0.027134909\n",
      "Validation Loss: 0.041925054\n",
      "Epoch: 2734 cost = 0.027133571\n",
      "Validation Loss: 0.035647508\n",
      "Epoch: 2735 cost = 0.027132229\n",
      "Validation Loss: 0.03325641\n",
      "Epoch: 2736 cost = 0.027130878\n",
      "Validation Loss: 0.052023575\n",
      "Epoch: 2737 cost = 0.027129476\n",
      "Validation Loss: 0.07388502\n",
      "Epoch: 2738 cost = 0.027128093\n",
      "Validation Loss: 0.074707665\n",
      "Epoch: 2739 cost = 0.027126744\n",
      "Validation Loss: 0.06137408\n",
      "Epoch: 2740 cost = 0.027125369\n",
      "Validation Loss: 0.039125424\n",
      "Epoch: 2741 cost = 0.027124024\n",
      "Validation Loss: 0.046392947\n",
      "Epoch: 2742 cost = 0.027122664\n",
      "Validation Loss: 0.05501771\n",
      "Epoch: 2743 cost = 0.027121328\n",
      "Validation Loss: 0.038416952\n",
      "Epoch: 2744 cost = 0.027120026\n",
      "Validation Loss: 0.069120355\n",
      "Epoch: 2745 cost = 0.027118626\n",
      "Validation Loss: 0.070112295\n",
      "Epoch: 2746 cost = 0.027117327\n",
      "Validation Loss: 0.07989612\n",
      "Epoch: 2747 cost = 0.027115964\n",
      "Validation Loss: 0.080900416\n",
      "Epoch: 2748 cost = 0.027114598\n",
      "Validation Loss: 0.06986733\n",
      "Epoch: 2749 cost = 0.027113267\n",
      "Validation Loss: 0.06147658\n",
      "Epoch: 2750 cost = 0.027111903\n",
      "Validation Loss: 0.062263526\n",
      "Epoch: 2751 cost = 0.027110578\n",
      "Validation Loss: 0.054888602\n",
      "Epoch: 2752 cost = 0.027109294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.035982076\n",
      "Epoch: 2753 cost = 0.027107964\n",
      "Validation Loss: 0.0358137\n",
      "Epoch: 2754 cost = 0.027106595\n",
      "Validation Loss: 0.037576154\n",
      "Epoch: 2755 cost = 0.027105262\n",
      "Validation Loss: 0.036643293\n",
      "Epoch: 2756 cost = 0.027103985\n",
      "Validation Loss: 0.03593407\n",
      "Epoch: 2757 cost = 0.027102600\n",
      "Validation Loss: 0.03428303\n",
      "Epoch: 2758 cost = 0.027101318\n",
      "Validation Loss: 0.032450225\n",
      "Epoch: 2759 cost = 0.027099910\n",
      "Validation Loss: 0.04058711\n",
      "Epoch: 2760 cost = 0.027098626\n",
      "Validation Loss: 0.037760418\n",
      "Epoch: 2761 cost = 0.027097268\n",
      "Validation Loss: 0.036503084\n",
      "Epoch: 2762 cost = 0.027095989\n",
      "Validation Loss: 0.039997447\n",
      "Epoch: 2763 cost = 0.027094682\n",
      "Validation Loss: 0.03714003\n",
      "Epoch: 2764 cost = 0.027093345\n",
      "Validation Loss: 0.05000515\n",
      "Epoch: 2765 cost = 0.027092056\n",
      "Validation Loss: 0.056158453\n",
      "Epoch: 2766 cost = 0.027090709\n",
      "Validation Loss: 0.059994057\n",
      "Epoch: 2767 cost = 0.027089438\n",
      "Validation Loss: 0.076662\n",
      "Epoch: 2768 cost = 0.027088064\n",
      "Validation Loss: 0.050897457\n",
      "Epoch: 2769 cost = 0.027086760\n",
      "Validation Loss: 0.03391631\n",
      "Epoch: 2770 cost = 0.027085449\n",
      "Validation Loss: 0.0323448\n",
      "Epoch: 2771 cost = 0.027084120\n",
      "Validation Loss: 0.033740938\n",
      "Epoch: 2772 cost = 0.027082860\n",
      "Validation Loss: 0.036346313\n",
      "Epoch: 2773 cost = 0.027081541\n",
      "Validation Loss: 0.033147857\n",
      "Epoch: 2774 cost = 0.027080197\n",
      "Validation Loss: 0.033226177\n",
      "Epoch: 2775 cost = 0.027078955\n",
      "Validation Loss: 0.036014102\n",
      "Epoch: 2776 cost = 0.027077641\n",
      "Validation Loss: 0.03496256\n",
      "Epoch: 2777 cost = 0.027076331\n",
      "Validation Loss: 0.037248544\n",
      "Epoch: 2778 cost = 0.027075038\n",
      "Validation Loss: 0.037735667\n",
      "Epoch: 2779 cost = 0.027073747\n",
      "Validation Loss: 0.0356165\n",
      "Epoch: 2780 cost = 0.027072446\n",
      "Validation Loss: 0.04286951\n",
      "Epoch: 2781 cost = 0.027071135\n",
      "Validation Loss: 0.045371328\n",
      "Epoch: 2782 cost = 0.027069858\n",
      "Validation Loss: 0.036576774\n",
      "Epoch: 2783 cost = 0.027068605\n",
      "Validation Loss: 0.049496952\n",
      "Epoch: 2784 cost = 0.027067318\n",
      "Validation Loss: 0.06040311\n",
      "Epoch: 2785 cost = 0.027066009\n",
      "Validation Loss: 0.063820355\n",
      "Epoch: 2786 cost = 0.027064738\n",
      "Validation Loss: 0.07234169\n",
      "Epoch: 2787 cost = 0.027063433\n",
      "Validation Loss: 0.08484285\n",
      "Epoch: 2788 cost = 0.027062182\n",
      "Validation Loss: 0.053255994\n",
      "Epoch: 2789 cost = 0.027060854\n",
      "Validation Loss: 0.056026034\n",
      "Epoch: 2790 cost = 0.027059615\n",
      "Validation Loss: 0.042189777\n",
      "Epoch: 2791 cost = 0.027058323\n",
      "Validation Loss: 0.03317427\n",
      "Epoch: 2792 cost = 0.027057029\n",
      "Validation Loss: 0.035380524\n",
      "Epoch: 2793 cost = 0.027055737\n",
      "Validation Loss: 0.036297545\n",
      "Epoch: 2794 cost = 0.027054489\n",
      "Validation Loss: 0.05316702\n",
      "Epoch: 2795 cost = 0.027053189\n",
      "Validation Loss: 0.056247547\n",
      "Epoch: 2796 cost = 0.027051915\n",
      "Validation Loss: 0.06955159\n",
      "Epoch: 2797 cost = 0.027050690\n",
      "Validation Loss: 0.07101775\n",
      "Epoch: 2798 cost = 0.027049339\n",
      "Validation Loss: 0.08895191\n",
      "Epoch: 2799 cost = 0.027048103\n",
      "Validation Loss: 0.10477693\n",
      "Epoch: 2800 cost = 0.027046873\n",
      "Validation Loss: 0.08932245\n",
      "Epoch: 2801 cost = 0.027045607\n",
      "Validation Loss: 0.084692486\n",
      "Epoch: 2802 cost = 0.027044311\n",
      "Validation Loss: 0.10763368\n",
      "Epoch: 2803 cost = 0.027043062\n",
      "Validation Loss: 0.075014055\n",
      "Epoch: 2804 cost = 0.027041834\n",
      "Validation Loss: 0.05353833\n",
      "Epoch: 2805 cost = 0.027040537\n",
      "Validation Loss: 0.04247829\n",
      "Epoch: 2806 cost = 0.027039262\n",
      "Validation Loss: 0.036133826\n",
      "Epoch: 2807 cost = 0.027038023\n",
      "Validation Loss: 0.03751011\n",
      "Epoch: 2808 cost = 0.027036728\n",
      "Validation Loss: 0.03215588\n",
      "Epoch: 2809 cost = 0.027035563\n",
      "Validation Loss: 0.034387004\n",
      "Epoch: 2810 cost = 0.027034250\n",
      "Validation Loss: 0.03486231\n",
      "Epoch: 2811 cost = 0.027033001\n",
      "Validation Loss: 0.039219953\n",
      "Epoch: 2812 cost = 0.027031771\n",
      "Validation Loss: 0.03911157\n",
      "Epoch: 2813 cost = 0.027030524\n",
      "Validation Loss: 0.038646348\n",
      "Epoch: 2814 cost = 0.027029276\n",
      "Validation Loss: 0.039866902\n",
      "Epoch: 2815 cost = 0.027027988\n",
      "Validation Loss: 0.03854453\n",
      "Epoch: 2816 cost = 0.027026783\n",
      "Validation Loss: 0.039815098\n",
      "Epoch: 2817 cost = 0.027025511\n",
      "Validation Loss: 0.03470111\n",
      "Epoch: 2818 cost = 0.027024300\n",
      "Validation Loss: 0.036376733\n",
      "Epoch: 2819 cost = 0.027023058\n",
      "Validation Loss: 0.036027666\n",
      "Epoch: 2820 cost = 0.027021792\n",
      "Validation Loss: 0.037563894\n",
      "Epoch: 2821 cost = 0.027020557\n",
      "Validation Loss: 0.040395554\n",
      "Epoch: 2822 cost = 0.027019333\n",
      "Validation Loss: 0.03438488\n",
      "Epoch: 2823 cost = 0.027018087\n",
      "Validation Loss: 0.03844148\n",
      "Epoch: 2824 cost = 0.027016886\n",
      "Validation Loss: 0.034777198\n",
      "Epoch: 2825 cost = 0.027015635\n",
      "Validation Loss: 0.038651418\n",
      "Epoch: 2826 cost = 0.027014447\n",
      "Validation Loss: 0.03088894\n",
      "Epoch: 2827 cost = 0.027013126\n",
      "Validation Loss: 0.044808917\n",
      "Epoch: 2828 cost = 0.027011907\n",
      "Validation Loss: 0.053902082\n",
      "Epoch: 2829 cost = 0.027010673\n",
      "Validation Loss: 0.039197233\n",
      "Epoch: 2830 cost = 0.027009481\n",
      "Validation Loss: 0.036862552\n",
      "Epoch: 2831 cost = 0.027008282\n",
      "Validation Loss: 0.03541006\n",
      "Epoch: 2832 cost = 0.027007016\n",
      "Validation Loss: 0.034758087\n",
      "Epoch: 2833 cost = 0.027005791\n",
      "Validation Loss: 0.0383605\n",
      "Epoch: 2834 cost = 0.027004566\n",
      "Validation Loss: 0.039505687\n",
      "Epoch: 2835 cost = 0.027003351\n",
      "Validation Loss: 0.040278103\n",
      "Epoch: 2836 cost = 0.027002146\n",
      "Validation Loss: 0.041268095\n",
      "Epoch: 2837 cost = 0.027000903\n",
      "Validation Loss: 0.035572104\n",
      "Epoch: 2838 cost = 0.026999709\n",
      "Validation Loss: 0.033799928\n",
      "Epoch: 2839 cost = 0.026998543\n",
      "Validation Loss: 0.048844893\n",
      "Epoch: 2840 cost = 0.026997247\n",
      "Validation Loss: 0.06868034\n",
      "Epoch: 2841 cost = 0.026996035\n",
      "Validation Loss: 0.05617976\n",
      "Epoch: 2842 cost = 0.026994794\n",
      "Validation Loss: 0.04650955\n",
      "Epoch: 2843 cost = 0.026993629\n",
      "Validation Loss: 0.04598466\n",
      "Epoch: 2844 cost = 0.026992437\n",
      "Validation Loss: 0.0381203\n",
      "Epoch: 2845 cost = 0.026991168\n",
      "Validation Loss: 0.037632946\n",
      "Epoch: 2846 cost = 0.026990006\n",
      "Validation Loss: 0.033931557\n",
      "Epoch: 2847 cost = 0.026988813\n",
      "Validation Loss: 0.03476616\n",
      "Epoch: 2848 cost = 0.026987589\n",
      "Validation Loss: 0.03437699\n",
      "Epoch: 2849 cost = 0.026986406\n",
      "Validation Loss: 0.031983215\n",
      "Epoch: 2850 cost = 0.026985129\n",
      "Validation Loss: 0.0322576\n",
      "Epoch: 2851 cost = 0.026983960\n",
      "Validation Loss: 0.046734907\n",
      "Epoch: 2852 cost = 0.026982729\n",
      "Validation Loss: 0.062422115\n",
      "Epoch: 2853 cost = 0.026981514\n",
      "Validation Loss: 0.07197932\n",
      "Epoch: 2854 cost = 0.026980350\n",
      "Validation Loss: 0.091218635\n",
      "Epoch: 2855 cost = 0.026979199\n",
      "Validation Loss: 0.09263956\n",
      "Epoch: 2856 cost = 0.026977987\n",
      "Validation Loss: 0.060024943\n",
      "Epoch: 2857 cost = 0.026976777\n",
      "Validation Loss: 0.0405843\n",
      "Epoch: 2858 cost = 0.026975597\n",
      "Validation Loss: 0.03778889\n",
      "Epoch: 2859 cost = 0.026974432\n",
      "Validation Loss: 0.039838526\n",
      "Epoch: 2860 cost = 0.026973219\n",
      "Validation Loss: 0.03478486\n",
      "Epoch: 2861 cost = 0.026972048\n",
      "Validation Loss: 0.04069723\n",
      "Epoch: 2862 cost = 0.026970803\n",
      "Validation Loss: 0.042382233\n",
      "Epoch: 2863 cost = 0.026969630\n",
      "Validation Loss: 0.036794942\n",
      "Epoch: 2864 cost = 0.026968443\n",
      "Validation Loss: 0.053248324\n",
      "Epoch: 2865 cost = 0.026967293\n",
      "Validation Loss: 0.04360098\n",
      "Epoch: 2866 cost = 0.026966084\n",
      "Validation Loss: 0.04011345\n",
      "Epoch: 2867 cost = 0.026964875\n",
      "Validation Loss: 0.06873597\n",
      "Epoch: 2868 cost = 0.026963754\n",
      "Validation Loss: 0.06604859\n",
      "Epoch: 2869 cost = 0.026962524\n",
      "Validation Loss: 0.04708978\n",
      "Epoch: 2870 cost = 0.026961381\n",
      "Validation Loss: 0.03759709\n",
      "Epoch: 2871 cost = 0.026960174\n",
      "Validation Loss: 0.037126224\n",
      "Epoch: 2872 cost = 0.026959005\n",
      "Validation Loss: 0.03610177\n",
      "Epoch: 2873 cost = 0.026957799\n",
      "Validation Loss: 0.03861497\n",
      "Epoch: 2874 cost = 0.026956620\n",
      "Validation Loss: 0.03645178\n",
      "Epoch: 2875 cost = 0.026955458\n",
      "Validation Loss: 0.037183005\n",
      "Epoch: 2876 cost = 0.026954308\n",
      "Validation Loss: 0.03762003\n",
      "Epoch: 2877 cost = 0.026953134\n",
      "Validation Loss: 0.034927573\n",
      "Epoch: 2878 cost = 0.026951989\n",
      "Validation Loss: 0.036499165\n",
      "Epoch: 2879 cost = 0.026950770\n",
      "Validation Loss: 0.0376151\n",
      "Epoch: 2880 cost = 0.026949649\n",
      "Validation Loss: 0.03460714\n",
      "Epoch: 2881 cost = 0.026948398\n",
      "Validation Loss: 0.034987297\n",
      "Epoch: 2882 cost = 0.026947299\n",
      "Validation Loss: 0.034673564\n",
      "Epoch: 2883 cost = 0.026946138\n",
      "Validation Loss: 0.046547275\n",
      "Epoch: 2884 cost = 0.026944956\n",
      "Validation Loss: 0.08758231\n",
      "Epoch: 2885 cost = 0.026943776\n",
      "Validation Loss: 0.11053672\n",
      "Epoch: 2886 cost = 0.026942568\n",
      "Validation Loss: 0.119308814\n",
      "Epoch: 2887 cost = 0.026941449\n",
      "Validation Loss: 0.10964422\n",
      "Epoch: 2888 cost = 0.026940326\n",
      "Validation Loss: 0.13968356\n",
      "Epoch: 2889 cost = 0.026939137\n",
      "Validation Loss: 0.16391063\n",
      "Epoch: 2890 cost = 0.026937994\n",
      "Validation Loss: 0.09842091\n",
      "Epoch: 2891 cost = 0.026936837\n",
      "Validation Loss: 0.06021188\n",
      "Epoch: 2892 cost = 0.026935664\n",
      "Validation Loss: 0.03621979\n",
      "Epoch: 2893 cost = 0.026934557\n",
      "Validation Loss: 0.03993825\n",
      "Epoch: 2894 cost = 0.026933345\n",
      "Validation Loss: 0.036012806\n",
      "Epoch: 2895 cost = 0.026932199\n",
      "Validation Loss: 0.034932178\n",
      "Epoch: 2896 cost = 0.026931060\n",
      "Validation Loss: 0.034796774\n",
      "Epoch: 2897 cost = 0.026929872\n",
      "Validation Loss: 0.05762368\n",
      "Epoch: 2898 cost = 0.026928739\n",
      "Validation Loss: 0.14367343\n",
      "Epoch: 2899 cost = 0.026927543\n",
      "Validation Loss: 0.12427677\n",
      "Epoch: 2900 cost = 0.026926494\n",
      "Validation Loss: 0.07061563\n",
      "Epoch: 2901 cost = 0.026925301\n",
      "Validation Loss: 0.043287467\n",
      "Epoch: 2902 cost = 0.026924185\n",
      "Validation Loss: 0.03401034\n",
      "Epoch: 2903 cost = 0.026923062\n",
      "Validation Loss: 0.039858595\n",
      "Epoch: 2904 cost = 0.026921839\n",
      "Validation Loss: 0.043238904\n",
      "Epoch: 2905 cost = 0.026920750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.041966926\n",
      "Epoch: 2906 cost = 0.026919561\n",
      "Validation Loss: 0.039993674\n",
      "Epoch: 2907 cost = 0.026918423\n",
      "Validation Loss: 0.032405574\n",
      "Epoch: 2908 cost = 0.026917267\n",
      "Validation Loss: 0.03679438\n",
      "Epoch: 2909 cost = 0.026916190\n",
      "Validation Loss: 0.05253965\n",
      "Epoch: 2910 cost = 0.026915046\n",
      "Validation Loss: 0.036401972\n",
      "Epoch: 2911 cost = 0.026913902\n",
      "Validation Loss: 0.035317156\n",
      "Epoch: 2912 cost = 0.026912747\n",
      "Validation Loss: 0.03452012\n",
      "Epoch: 2913 cost = 0.026911596\n",
      "Validation Loss: 0.051103763\n",
      "Epoch: 2914 cost = 0.026910501\n",
      "Validation Loss: 0.039427184\n",
      "Epoch: 2915 cost = 0.026909374\n",
      "Validation Loss: 0.037596922\n",
      "Epoch: 2916 cost = 0.026908174\n",
      "Validation Loss: 0.04360965\n",
      "Epoch: 2917 cost = 0.026907086\n",
      "Validation Loss: 0.0418945\n",
      "Epoch: 2918 cost = 0.026905999\n",
      "Validation Loss: 0.045617174\n",
      "Epoch: 2919 cost = 0.026904828\n",
      "Validation Loss: 0.043551967\n",
      "Epoch: 2920 cost = 0.026903667\n",
      "Validation Loss: 0.045561053\n",
      "Epoch: 2921 cost = 0.026902545\n",
      "Validation Loss: 0.045448266\n",
      "Epoch: 2922 cost = 0.026901393\n",
      "Validation Loss: 0.04301739\n",
      "Epoch: 2923 cost = 0.026900277\n",
      "Validation Loss: 0.035461865\n",
      "Epoch: 2924 cost = 0.026899193\n",
      "Validation Loss: 0.032340012\n",
      "Epoch: 2925 cost = 0.026898025\n",
      "Validation Loss: 0.040178522\n",
      "Epoch: 2926 cost = 0.026896936\n",
      "Validation Loss: 0.037015535\n",
      "Epoch: 2927 cost = 0.026895810\n",
      "Validation Loss: 0.03503314\n",
      "Epoch: 2928 cost = 0.026894689\n",
      "Validation Loss: 0.035397127\n",
      "Epoch: 2929 cost = 0.026893545\n",
      "Validation Loss: 0.03510456\n",
      "Epoch: 2930 cost = 0.026892424\n",
      "Validation Loss: 0.039773468\n",
      "Epoch: 2931 cost = 0.026891323\n",
      "Validation Loss: 0.03737138\n",
      "Epoch: 2932 cost = 0.026890208\n",
      "Validation Loss: 0.035209294\n",
      "Epoch: 2933 cost = 0.026889090\n",
      "Validation Loss: 0.035977334\n",
      "Epoch: 2934 cost = 0.026887989\n",
      "Validation Loss: 0.051699005\n",
      "Epoch: 2935 cost = 0.026886833\n",
      "Validation Loss: 0.050986983\n",
      "Epoch: 2936 cost = 0.026885743\n",
      "Validation Loss: 0.03671867\n",
      "Epoch: 2937 cost = 0.026884627\n",
      "Validation Loss: 0.035249956\n",
      "Epoch: 2938 cost = 0.026883524\n",
      "Validation Loss: 0.033758853\n",
      "Epoch: 2939 cost = 0.026882429\n",
      "Validation Loss: 0.036937658\n",
      "Epoch: 2940 cost = 0.026881299\n",
      "Validation Loss: 0.04355973\n",
      "Epoch: 2941 cost = 0.026880170\n",
      "Validation Loss: 0.04292769\n",
      "Epoch: 2942 cost = 0.026879097\n",
      "Validation Loss: 0.03919457\n",
      "Epoch: 2943 cost = 0.026877952\n",
      "Validation Loss: 0.03833509\n",
      "Epoch: 2944 cost = 0.026876902\n",
      "Validation Loss: 0.035285823\n",
      "Epoch: 2945 cost = 0.026875789\n",
      "Validation Loss: 0.040211257\n",
      "Epoch: 2946 cost = 0.026874653\n",
      "Validation Loss: 0.04453643\n",
      "Epoch: 2947 cost = 0.026873532\n",
      "Validation Loss: 0.04622878\n",
      "Epoch: 2948 cost = 0.026872421\n",
      "Validation Loss: 0.045461763\n",
      "Epoch: 2949 cost = 0.026871307\n",
      "Validation Loss: 0.041604556\n",
      "Epoch: 2950 cost = 0.026870251\n",
      "Validation Loss: 0.038919214\n",
      "Epoch: 2951 cost = 0.026869144\n",
      "Validation Loss: 0.03890897\n",
      "Epoch: 2952 cost = 0.026868031\n",
      "Validation Loss: 0.03937374\n",
      "Epoch: 2953 cost = 0.026866948\n",
      "Validation Loss: 0.03466647\n",
      "Epoch: 2954 cost = 0.026865807\n",
      "Validation Loss: 0.039628703\n",
      "Epoch: 2955 cost = 0.026864764\n",
      "Validation Loss: 0.033052813\n",
      "Epoch: 2956 cost = 0.026863684\n",
      "Validation Loss: 0.040676963\n",
      "Epoch: 2957 cost = 0.026862546\n",
      "Validation Loss: 0.041658677\n",
      "Epoch: 2958 cost = 0.026861468\n",
      "Validation Loss: 0.045033857\n",
      "Epoch: 2959 cost = 0.026860372\n",
      "Validation Loss: 0.05191023\n",
      "Epoch: 2960 cost = 0.026859319\n",
      "Validation Loss: 0.05507624\n",
      "Epoch: 2961 cost = 0.026858132\n",
      "Validation Loss: 0.07782027\n",
      "Epoch: 2962 cost = 0.026857096\n",
      "Validation Loss: 0.07665536\n",
      "Epoch: 2963 cost = 0.026856007\n",
      "Validation Loss: 0.07236608\n",
      "Epoch: 2964 cost = 0.026854910\n",
      "Validation Loss: 0.048464414\n",
      "Epoch: 2965 cost = 0.026853821\n",
      "Validation Loss: 0.037739094\n",
      "Epoch: 2966 cost = 0.026852750\n",
      "Validation Loss: 0.03492889\n",
      "Epoch: 2967 cost = 0.026851642\n",
      "Validation Loss: 0.038666554\n",
      "Epoch: 2968 cost = 0.026850534\n",
      "Validation Loss: 0.032771207\n",
      "Epoch: 2969 cost = 0.026849439\n",
      "Validation Loss: 0.03394499\n",
      "Epoch: 2970 cost = 0.026848355\n",
      "Validation Loss: 0.038433064\n",
      "Epoch: 2971 cost = 0.026847267\n",
      "Validation Loss: 0.0376271\n",
      "Epoch: 2972 cost = 0.026846178\n",
      "Validation Loss: 0.044350684\n",
      "Epoch: 2973 cost = 0.026845156\n",
      "Validation Loss: 0.043083597\n",
      "Epoch: 2974 cost = 0.026844036\n",
      "Validation Loss: 0.035559908\n",
      "Epoch: 2975 cost = 0.026843000\n",
      "Validation Loss: 0.032497708\n",
      "Epoch: 2976 cost = 0.026841883\n",
      "Validation Loss: 0.0310977\n",
      "Epoch: 2977 cost = 0.026840842\n",
      "Validation Loss: 0.03864729\n",
      "Epoch: 2978 cost = 0.026839710\n",
      "Validation Loss: 0.039211463\n",
      "Epoch: 2979 cost = 0.026838609\n",
      "Validation Loss: 0.034437805\n",
      "Epoch: 2980 cost = 0.026837559\n",
      "Validation Loss: 0.035606224\n",
      "Epoch: 2981 cost = 0.026836478\n",
      "Validation Loss: 0.055916425\n",
      "Epoch: 2982 cost = 0.026835403\n",
      "Validation Loss: 0.03226915\n",
      "Epoch: 2983 cost = 0.026834336\n",
      "Validation Loss: 0.033721108\n",
      "Epoch: 2984 cost = 0.026833278\n",
      "Validation Loss: 0.03144861\n",
      "Epoch: 2985 cost = 0.026832189\n",
      "Validation Loss: 0.03687569\n",
      "Epoch: 2986 cost = 0.026831169\n",
      "Validation Loss: 0.044262342\n",
      "Epoch: 2987 cost = 0.026830026\n",
      "Validation Loss: 0.051310085\n",
      "Epoch: 2988 cost = 0.026829017\n",
      "Validation Loss: 0.04166344\n",
      "Epoch: 2989 cost = 0.026827896\n",
      "Validation Loss: 0.03631048\n",
      "Epoch: 2990 cost = 0.026826859\n",
      "Validation Loss: 0.032909043\n",
      "Epoch: 2991 cost = 0.026825776\n",
      "Validation Loss: 0.035568897\n",
      "Epoch: 2992 cost = 0.026824712\n",
      "Validation Loss: 0.051531717\n",
      "Epoch: 2993 cost = 0.026823616\n",
      "Validation Loss: 0.041010976\n",
      "Epoch: 2994 cost = 0.026822572\n",
      "Validation Loss: 0.043268703\n",
      "Epoch: 2995 cost = 0.026821502\n",
      "Validation Loss: 0.037073284\n",
      "Epoch: 2996 cost = 0.026820429\n",
      "Validation Loss: 0.038909387\n",
      "Epoch: 2997 cost = 0.026819401\n",
      "Validation Loss: 0.050227646\n",
      "Epoch: 2998 cost = 0.026818276\n",
      "Validation Loss: 0.07241087\n",
      "Epoch: 2999 cost = 0.026817216\n",
      "Validation Loss: 0.05788821\n",
      "Epoch: 3000 cost = 0.026816201\n",
      "Validation Loss: 0.05913284\n",
      "Epoch: 3001 cost = 0.026815110\n",
      "Validation Loss: 0.046222188\n",
      "Epoch: 3002 cost = 0.026814081\n",
      "Validation Loss: 0.057299074\n",
      "Epoch: 3003 cost = 0.026813008\n",
      "Validation Loss: 0.06364733\n",
      "Epoch: 3004 cost = 0.026811931\n",
      "Validation Loss: 0.05532978\n",
      "Epoch: 3005 cost = 0.026810861\n",
      "Validation Loss: 0.033961225\n",
      "Epoch: 3006 cost = 0.026809882\n",
      "Validation Loss: 0.036382824\n",
      "Epoch: 3007 cost = 0.026808761\n",
      "Validation Loss: 0.0342412\n",
      "Epoch: 3008 cost = 0.026807726\n",
      "Validation Loss: 0.032651443\n",
      "Epoch: 3009 cost = 0.026806650\n",
      "Validation Loss: 0.03271377\n",
      "Epoch: 3010 cost = 0.026805644\n",
      "Validation Loss: 0.034010485\n",
      "Epoch: 3011 cost = 0.026804598\n",
      "Validation Loss: 0.04647579\n",
      "Epoch: 3012 cost = 0.026803522\n",
      "Validation Loss: 0.036040682\n",
      "Epoch: 3013 cost = 0.026802483\n",
      "Validation Loss: 0.03252971\n",
      "Epoch: 3014 cost = 0.026801398\n",
      "Validation Loss: 0.033855256\n",
      "Epoch: 3015 cost = 0.026800372\n",
      "Validation Loss: 0.03776759\n",
      "Epoch: 3016 cost = 0.026799263\n",
      "Validation Loss: 0.036793828\n",
      "Epoch: 3017 cost = 0.026798234\n",
      "Validation Loss: 0.03198063\n",
      "Epoch: 3018 cost = 0.026797195\n",
      "Validation Loss: 0.030734561\n",
      "Epoch: 3019 cost = 0.026796118\n",
      "Validation Loss: 0.040633623\n",
      "Epoch: 3020 cost = 0.026795092\n",
      "Validation Loss: 0.05786688\n",
      "Epoch: 3021 cost = 0.026794061\n",
      "Validation Loss: 0.04918402\n",
      "Epoch: 3022 cost = 0.026793016\n",
      "Validation Loss: 0.03748654\n",
      "Epoch: 3023 cost = 0.026791971\n",
      "Validation Loss: 0.034988273\n",
      "Epoch: 3024 cost = 0.026790945\n",
      "Validation Loss: 0.0346794\n",
      "Epoch: 3025 cost = 0.026789874\n",
      "Validation Loss: 0.035442926\n",
      "Epoch: 3026 cost = 0.026788844\n",
      "Validation Loss: 0.0360914\n",
      "Epoch: 3027 cost = 0.026787814\n",
      "Validation Loss: 0.035575915\n",
      "Epoch: 3028 cost = 0.026786746\n",
      "Validation Loss: 0.03366662\n",
      "Epoch: 3029 cost = 0.026785711\n",
      "Validation Loss: 0.039309096\n",
      "Epoch: 3030 cost = 0.026784671\n",
      "Validation Loss: 0.04449156\n",
      "Epoch: 3031 cost = 0.026783654\n",
      "Validation Loss: 0.05925754\n",
      "Epoch: 3032 cost = 0.026782595\n",
      "Validation Loss: 0.07281985\n",
      "Epoch: 3033 cost = 0.026781522\n",
      "Validation Loss: 0.03904849\n",
      "Epoch: 3034 cost = 0.026780509\n",
      "Validation Loss: 0.038317017\n",
      "Epoch: 3035 cost = 0.026779470\n",
      "Validation Loss: 0.03948296\n",
      "Epoch: 3036 cost = 0.026778429\n",
      "Validation Loss: 0.040319268\n",
      "Epoch: 3037 cost = 0.026777416\n",
      "Validation Loss: 0.04564086\n",
      "Epoch: 3038 cost = 0.026776339\n",
      "Validation Loss: 0.047559537\n",
      "Epoch: 3039 cost = 0.026775319\n",
      "Validation Loss: 0.047222372\n",
      "Epoch: 3040 cost = 0.026774292\n",
      "Validation Loss: 0.039467104\n",
      "Epoch: 3041 cost = 0.026773313\n",
      "Validation Loss: 0.038881194\n",
      "Epoch: 3042 cost = 0.026772228\n",
      "Validation Loss: 0.04560495\n",
      "Epoch: 3043 cost = 0.026771191\n",
      "Validation Loss: 0.054960158\n",
      "Epoch: 3044 cost = 0.026770187\n",
      "Validation Loss: 0.043753803\n",
      "Epoch: 3045 cost = 0.026769158\n",
      "Validation Loss: 0.037254345\n",
      "Epoch: 3046 cost = 0.026768122\n",
      "Validation Loss: 0.043927517\n",
      "Epoch: 3047 cost = 0.026767092\n",
      "Validation Loss: 0.041968267\n",
      "Epoch: 3048 cost = 0.026766017\n",
      "Validation Loss: 0.033781942\n",
      "Epoch: 3049 cost = 0.026764994\n",
      "Validation Loss: 0.044238437\n",
      "Epoch: 3050 cost = 0.026763977\n",
      "Validation Loss: 0.040187493\n",
      "Epoch: 3051 cost = 0.026762951\n",
      "Validation Loss: 0.06487685\n",
      "Epoch: 3052 cost = 0.026761975\n",
      "Validation Loss: 0.077249095\n",
      "Epoch: 3053 cost = 0.026760960\n",
      "Validation Loss: 0.06975628\n",
      "Epoch: 3054 cost = 0.026759862\n",
      "Validation Loss: 0.06553785\n",
      "Epoch: 3055 cost = 0.026758860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04585837\n",
      "Epoch: 3056 cost = 0.026757838\n",
      "Validation Loss: 0.06459575\n",
      "Epoch: 3057 cost = 0.026756868\n",
      "Validation Loss: 0.06638739\n",
      "Epoch: 3058 cost = 0.026755819\n",
      "Validation Loss: 0.035345096\n",
      "Epoch: 3059 cost = 0.026754796\n",
      "Validation Loss: 0.040102005\n",
      "Epoch: 3060 cost = 0.026753745\n",
      "Validation Loss: 0.03992069\n",
      "Epoch: 3061 cost = 0.026752706\n",
      "Validation Loss: 0.04036402\n",
      "Epoch: 3062 cost = 0.026751756\n",
      "Validation Loss: 0.039719697\n",
      "Epoch: 3063 cost = 0.026750666\n",
      "Validation Loss: 0.037002955\n",
      "Epoch: 3064 cost = 0.026749702\n",
      "Validation Loss: 0.038111683\n",
      "Epoch: 3065 cost = 0.026748677\n",
      "Validation Loss: 0.043765347\n",
      "Epoch: 3066 cost = 0.026747646\n",
      "Validation Loss: 0.03723261\n",
      "Epoch: 3067 cost = 0.026746626\n",
      "Validation Loss: 0.032415055\n",
      "Epoch: 3068 cost = 0.026745641\n",
      "Validation Loss: 0.037198946\n",
      "Epoch: 3069 cost = 0.026744562\n",
      "Validation Loss: 0.03977476\n",
      "Epoch: 3070 cost = 0.026743607\n",
      "Validation Loss: 0.06300506\n",
      "Epoch: 3071 cost = 0.026742553\n",
      "Validation Loss: 0.081546515\n",
      "Epoch: 3072 cost = 0.026741544\n",
      "Validation Loss: 0.07472182\n",
      "Epoch: 3073 cost = 0.026740577\n",
      "Validation Loss: 0.037644535\n",
      "Epoch: 3074 cost = 0.026739554\n",
      "Validation Loss: 0.034925055\n",
      "Epoch: 3075 cost = 0.026738510\n",
      "Validation Loss: 0.037470125\n",
      "Epoch: 3076 cost = 0.026737540\n",
      "Validation Loss: 0.035858333\n",
      "Epoch: 3077 cost = 0.026736498\n",
      "Validation Loss: 0.038473114\n",
      "Epoch: 3078 cost = 0.026735479\n",
      "Validation Loss: 0.0378619\n",
      "Epoch: 3079 cost = 0.026734522\n",
      "Validation Loss: 0.037260495\n",
      "Epoch: 3080 cost = 0.026733468\n",
      "Validation Loss: 0.036829744\n",
      "Epoch: 3081 cost = 0.026732480\n",
      "Validation Loss: 0.03732825\n",
      "Epoch: 3082 cost = 0.026731422\n",
      "Validation Loss: 0.042405035\n",
      "Epoch: 3083 cost = 0.026730410\n",
      "Validation Loss: 0.04654212\n",
      "Epoch: 3084 cost = 0.026729458\n",
      "Validation Loss: 0.041666374\n",
      "Epoch: 3085 cost = 0.026728445\n",
      "Validation Loss: 0.035925176\n",
      "Epoch: 3086 cost = 0.026727425\n",
      "Validation Loss: 0.040208776\n",
      "Epoch: 3087 cost = 0.026726458\n",
      "Validation Loss: 0.04209696\n",
      "Epoch: 3088 cost = 0.026725414\n",
      "Validation Loss: 0.052713133\n",
      "Epoch: 3089 cost = 0.026724409\n",
      "Validation Loss: 0.046468016\n",
      "Epoch: 3090 cost = 0.026723439\n",
      "Validation Loss: 0.04144678\n",
      "Epoch: 3091 cost = 0.026722438\n",
      "Validation Loss: 0.056081187\n",
      "Epoch: 3092 cost = 0.026721461\n",
      "Validation Loss: 0.06001751\n",
      "Epoch: 3093 cost = 0.026720427\n",
      "Validation Loss: 0.0739695\n",
      "Epoch: 3094 cost = 0.026719416\n",
      "Validation Loss: 0.049755856\n",
      "Epoch: 3095 cost = 0.026718406\n",
      "Validation Loss: 0.051133886\n",
      "Epoch: 3096 cost = 0.026717420\n",
      "Validation Loss: 0.06132897\n",
      "Epoch: 3097 cost = 0.026716422\n",
      "Validation Loss: 0.048402093\n",
      "Epoch: 3098 cost = 0.026715441\n",
      "Validation Loss: 0.042608865\n",
      "Epoch: 3099 cost = 0.026714461\n",
      "Validation Loss: 0.032565705\n",
      "Epoch: 3100 cost = 0.026713470\n",
      "Validation Loss: 0.03112013\n",
      "Epoch: 3101 cost = 0.026712415\n",
      "Validation Loss: 0.029969165\n",
      "Epoch: 3102 cost = 0.026711438\n",
      "Validation Loss: 0.044705864\n",
      "Epoch: 3103 cost = 0.026710478\n",
      "Validation Loss: 0.05362845\n",
      "Epoch: 3104 cost = 0.026709458\n",
      "Validation Loss: 0.07385244\n",
      "Epoch: 3105 cost = 0.026708482\n",
      "Validation Loss: 0.07537045\n",
      "Epoch: 3106 cost = 0.026707488\n",
      "Validation Loss: 0.07449781\n",
      "Epoch: 3107 cost = 0.026706488\n",
      "Validation Loss: 0.056613524\n",
      "Epoch: 3108 cost = 0.026705481\n",
      "Validation Loss: 0.044471942\n",
      "Epoch: 3109 cost = 0.026704459\n",
      "Validation Loss: 0.03788815\n",
      "Epoch: 3110 cost = 0.026703476\n",
      "Validation Loss: 0.035362437\n",
      "Epoch: 3111 cost = 0.026702488\n",
      "Validation Loss: 0.03751\n",
      "Epoch: 3112 cost = 0.026701565\n",
      "Validation Loss: 0.036942616\n",
      "Epoch: 3113 cost = 0.026700549\n",
      "Validation Loss: 0.032479133\n",
      "Epoch: 3114 cost = 0.026699597\n",
      "Validation Loss: 0.032585427\n",
      "Epoch: 3115 cost = 0.026698554\n",
      "Validation Loss: 0.032869767\n",
      "Epoch: 3116 cost = 0.026697593\n",
      "Validation Loss: 0.032676995\n",
      "Epoch: 3117 cost = 0.026696534\n",
      "Validation Loss: 0.035294186\n",
      "Epoch: 3118 cost = 0.026695595\n",
      "Validation Loss: 0.036358915\n",
      "Epoch: 3119 cost = 0.026694582\n",
      "Validation Loss: 0.03828667\n",
      "Epoch: 3120 cost = 0.026693643\n",
      "Validation Loss: 0.038943484\n",
      "Epoch: 3121 cost = 0.026692639\n",
      "Validation Loss: 0.040124405\n",
      "Epoch: 3122 cost = 0.026691622\n",
      "Validation Loss: 0.08244325\n",
      "Epoch: 3123 cost = 0.026690652\n",
      "Validation Loss: 0.07905925\n",
      "Epoch: 3124 cost = 0.026689655\n",
      "Validation Loss: 0.06448364\n",
      "Epoch: 3125 cost = 0.026688713\n",
      "Validation Loss: 0.04796111\n",
      "Epoch: 3126 cost = 0.026687777\n",
      "Validation Loss: 0.059809744\n",
      "Epoch: 3127 cost = 0.026686770\n",
      "Validation Loss: 0.04770665\n",
      "Epoch: 3128 cost = 0.026685750\n",
      "Validation Loss: 0.037646882\n",
      "Epoch: 3129 cost = 0.026684773\n",
      "Validation Loss: 0.03661514\n",
      "Epoch: 3130 cost = 0.026683776\n",
      "Validation Loss: 0.040082756\n",
      "Epoch: 3131 cost = 0.026682811\n",
      "Validation Loss: 0.03609231\n",
      "Epoch: 3132 cost = 0.026681819\n",
      "Validation Loss: 0.033349734\n",
      "Epoch: 3133 cost = 0.026680864\n",
      "Validation Loss: 0.04056156\n",
      "Epoch: 3134 cost = 0.026679874\n",
      "Validation Loss: 0.042430308\n",
      "Epoch: 3135 cost = 0.026678895\n",
      "Validation Loss: 0.0360031\n",
      "Epoch: 3136 cost = 0.026677912\n",
      "Validation Loss: 0.037416738\n",
      "Epoch: 3137 cost = 0.026676951\n",
      "Validation Loss: 0.039322723\n",
      "Epoch: 3138 cost = 0.026675996\n",
      "Validation Loss: 0.047586266\n",
      "Epoch: 3139 cost = 0.026675035\n",
      "Validation Loss: 0.057264503\n",
      "Epoch: 3140 cost = 0.026674027\n",
      "Validation Loss: 0.032450616\n",
      "Epoch: 3141 cost = 0.026673101\n",
      "Validation Loss: 0.0357273\n",
      "Epoch: 3142 cost = 0.026672105\n",
      "Validation Loss: 0.030388389\n",
      "Epoch: 3143 cost = 0.026671129\n",
      "Validation Loss: 0.040093612\n",
      "Epoch: 3144 cost = 0.026670169\n",
      "Validation Loss: 0.040659126\n",
      "Epoch: 3145 cost = 0.026669189\n",
      "Validation Loss: 0.038502887\n",
      "Epoch: 3146 cost = 0.026668231\n",
      "Validation Loss: 0.039662443\n",
      "Epoch: 3147 cost = 0.026667233\n",
      "Validation Loss: 0.058295652\n",
      "Epoch: 3148 cost = 0.026666256\n",
      "Validation Loss: 0.056632116\n",
      "Epoch: 3149 cost = 0.026665330\n",
      "Validation Loss: 0.040058333\n",
      "Epoch: 3150 cost = 0.026664349\n",
      "Validation Loss: 0.03286722\n",
      "Epoch: 3151 cost = 0.026663344\n",
      "Validation Loss: 0.032475054\n",
      "Epoch: 3152 cost = 0.026662419\n",
      "Validation Loss: 0.04053509\n",
      "Epoch: 3153 cost = 0.026661414\n",
      "Validation Loss: 0.051378425\n",
      "Epoch: 3154 cost = 0.026660442\n",
      "Validation Loss: 0.052589275\n",
      "Epoch: 3155 cost = 0.026659495\n",
      "Validation Loss: 0.05603428\n",
      "Epoch: 3156 cost = 0.026658521\n",
      "Validation Loss: 0.058995437\n",
      "Epoch: 3157 cost = 0.026657534\n",
      "Validation Loss: 0.041781645\n",
      "Epoch: 3158 cost = 0.026656590\n",
      "Validation Loss: 0.03698446\n",
      "Epoch: 3159 cost = 0.026655596\n",
      "Validation Loss: 0.03569225\n",
      "Epoch: 3160 cost = 0.026654608\n",
      "Validation Loss: 0.05117\n",
      "Epoch: 3161 cost = 0.026653693\n",
      "Validation Loss: 0.043992683\n",
      "Epoch: 3162 cost = 0.026652732\n",
      "Validation Loss: 0.036874954\n",
      "Epoch: 3163 cost = 0.026651801\n",
      "Validation Loss: 0.037253544\n",
      "Epoch: 3164 cost = 0.026650833\n",
      "Validation Loss: 0.035464164\n",
      "Epoch: 3165 cost = 0.026649840\n",
      "Validation Loss: 0.033534877\n",
      "Epoch: 3166 cost = 0.026648918\n",
      "Validation Loss: 0.0370277\n",
      "Epoch: 3167 cost = 0.026647883\n",
      "Validation Loss: 0.045589454\n",
      "Epoch: 3168 cost = 0.026646969\n",
      "Validation Loss: 0.058431953\n",
      "Epoch: 3169 cost = 0.026645988\n",
      "Validation Loss: 0.05432122\n",
      "Epoch: 3170 cost = 0.026645075\n",
      "Validation Loss: 0.047050517\n",
      "Epoch: 3171 cost = 0.026644109\n",
      "Validation Loss: 0.031822823\n",
      "Epoch: 3172 cost = 0.026643152\n",
      "Validation Loss: 0.03777341\n",
      "Epoch: 3173 cost = 0.026642190\n",
      "Validation Loss: 0.045630015\n",
      "Epoch: 3174 cost = 0.026641194\n",
      "Validation Loss: 0.04538403\n",
      "Epoch: 3175 cost = 0.026640280\n",
      "Validation Loss: 0.045587614\n",
      "Epoch: 3176 cost = 0.026639286\n",
      "Validation Loss: 0.04435741\n",
      "Epoch: 3177 cost = 0.026638306\n",
      "Validation Loss: 0.04347313\n",
      "Epoch: 3178 cost = 0.026637379\n",
      "Validation Loss: 0.0383818\n",
      "Epoch: 3179 cost = 0.026636409\n",
      "Validation Loss: 0.034422413\n",
      "Epoch: 3180 cost = 0.026635531\n",
      "Validation Loss: 0.041974775\n",
      "Epoch: 3181 cost = 0.026634557\n",
      "Validation Loss: 0.056113385\n",
      "Epoch: 3182 cost = 0.026633563\n",
      "Validation Loss: 0.09729707\n",
      "Epoch: 3183 cost = 0.026632596\n",
      "Validation Loss: 0.09207908\n",
      "Epoch: 3184 cost = 0.026631676\n",
      "Validation Loss: 0.0465255\n",
      "Epoch: 3185 cost = 0.026630672\n",
      "Validation Loss: 0.030525504\n",
      "Epoch: 3186 cost = 0.026629832\n",
      "Validation Loss: 0.033026706\n",
      "Epoch: 3187 cost = 0.026628791\n",
      "Validation Loss: 0.03482013\n",
      "Epoch: 3188 cost = 0.026627861\n",
      "Validation Loss: 0.04032439\n",
      "Epoch: 3189 cost = 0.026626935\n",
      "Validation Loss: 0.044582687\n",
      "Epoch: 3190 cost = 0.026625962\n",
      "Validation Loss: 0.048491467\n",
      "Epoch: 3191 cost = 0.026625040\n",
      "Validation Loss: 0.064781554\n",
      "Epoch: 3192 cost = 0.026624063\n",
      "Validation Loss: 0.07377653\n",
      "Epoch: 3193 cost = 0.026623158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.08068425\n",
      "Epoch: 3194 cost = 0.026622155\n",
      "Validation Loss: 0.07041583\n",
      "Epoch: 3195 cost = 0.026621210\n",
      "Validation Loss: 0.06668782\n",
      "Epoch: 3196 cost = 0.026620303\n",
      "Validation Loss: 0.061612114\n",
      "Epoch: 3197 cost = 0.026619311\n",
      "Validation Loss: 0.054024447\n",
      "Epoch: 3198 cost = 0.026618346\n",
      "Validation Loss: 0.052967887\n",
      "Epoch: 3199 cost = 0.026617466\n",
      "Validation Loss: 0.036247123\n",
      "Epoch: 3200 cost = 0.026616542\n",
      "Validation Loss: 0.03859681\n",
      "Epoch: 3201 cost = 0.026615526\n",
      "Validation Loss: 0.039000932\n",
      "Epoch: 3202 cost = 0.026614608\n",
      "Validation Loss: 0.033647664\n",
      "Epoch: 3203 cost = 0.026613707\n",
      "Validation Loss: 0.0356919\n",
      "Epoch: 3204 cost = 0.026612758\n",
      "Validation Loss: 0.03962687\n",
      "Epoch: 3205 cost = 0.026611774\n",
      "Validation Loss: 0.037730645\n",
      "Epoch: 3206 cost = 0.026610841\n",
      "Validation Loss: 0.035394304\n",
      "Epoch: 3207 cost = 0.026609875\n",
      "Validation Loss: 0.047059085\n",
      "Epoch: 3208 cost = 0.026608972\n",
      "Validation Loss: 0.050759096\n",
      "Epoch: 3209 cost = 0.026608043\n",
      "Validation Loss: 0.059173502\n",
      "Epoch: 3210 cost = 0.026607065\n",
      "Validation Loss: 0.039155144\n",
      "Epoch: 3211 cost = 0.026606157\n",
      "Validation Loss: 0.039397284\n",
      "Epoch: 3212 cost = 0.026605219\n",
      "Validation Loss: 0.035055205\n",
      "Epoch: 3213 cost = 0.026604287\n",
      "Validation Loss: 0.034822654\n",
      "Epoch: 3214 cost = 0.026603328\n",
      "Validation Loss: 0.039545592\n",
      "Epoch: 3215 cost = 0.026602378\n",
      "Validation Loss: 0.03797607\n",
      "Epoch: 3216 cost = 0.026601480\n",
      "Validation Loss: 0.03799965\n",
      "Epoch: 3217 cost = 0.026600526\n",
      "Validation Loss: 0.034972798\n",
      "Epoch: 3218 cost = 0.026599564\n",
      "Validation Loss: 0.034893136\n",
      "Epoch: 3219 cost = 0.026598629\n",
      "Validation Loss: 0.031510603\n",
      "Epoch: 3220 cost = 0.026597708\n",
      "Validation Loss: 0.03143075\n",
      "Epoch: 3221 cost = 0.026596772\n",
      "Validation Loss: 0.04293322\n",
      "Epoch: 3222 cost = 0.026595862\n",
      "Validation Loss: 0.03888343\n",
      "Epoch: 3223 cost = 0.026594910\n",
      "Validation Loss: 0.0387628\n",
      "Epoch: 3224 cost = 0.026593996\n",
      "Validation Loss: 0.03678955\n",
      "Epoch: 3225 cost = 0.026593062\n",
      "Validation Loss: 0.030241817\n",
      "Epoch: 3226 cost = 0.026592147\n",
      "Validation Loss: 0.030970883\n",
      "Epoch: 3227 cost = 0.026591195\n",
      "Validation Loss: 0.034985892\n",
      "Epoch: 3228 cost = 0.026590234\n",
      "Validation Loss: 0.049731568\n",
      "Epoch: 3229 cost = 0.026589304\n",
      "Validation Loss: 0.07082936\n",
      "Epoch: 3230 cost = 0.026588418\n",
      "Validation Loss: 0.0707813\n",
      "Epoch: 3231 cost = 0.026587422\n",
      "Validation Loss: 0.0567402\n",
      "Epoch: 3232 cost = 0.026586521\n",
      "Validation Loss: 0.043398466\n",
      "Epoch: 3233 cost = 0.026585619\n",
      "Validation Loss: 0.038810067\n",
      "Epoch: 3234 cost = 0.026584653\n",
      "Validation Loss: 0.037053432\n",
      "Epoch: 3235 cost = 0.026583721\n",
      "Validation Loss: 0.03706862\n",
      "Epoch: 3236 cost = 0.026582791\n",
      "Validation Loss: 0.04023141\n",
      "Epoch: 3237 cost = 0.026581892\n",
      "Validation Loss: 0.03757919\n",
      "Epoch: 3238 cost = 0.026580956\n",
      "Validation Loss: 0.038508736\n",
      "Epoch: 3239 cost = 0.026580009\n",
      "Validation Loss: 0.04531485\n",
      "Epoch: 3240 cost = 0.026579128\n",
      "Validation Loss: 0.040340174\n",
      "Epoch: 3241 cost = 0.026578177\n",
      "Validation Loss: 0.04337954\n",
      "Epoch: 3242 cost = 0.026577272\n",
      "Validation Loss: 0.04152708\n",
      "Epoch: 3243 cost = 0.026576315\n",
      "Validation Loss: 0.0363388\n",
      "Epoch: 3244 cost = 0.026575375\n",
      "Validation Loss: 0.031132048\n",
      "Epoch: 3245 cost = 0.026574462\n",
      "Validation Loss: 0.03101827\n",
      "Epoch: 3246 cost = 0.026573560\n",
      "Validation Loss: 0.03697621\n",
      "Epoch: 3247 cost = 0.026572604\n",
      "Validation Loss: 0.040427905\n",
      "Epoch: 3248 cost = 0.026571728\n",
      "Validation Loss: 0.03758941\n",
      "Epoch: 3249 cost = 0.026570780\n",
      "Validation Loss: 0.040022336\n",
      "Epoch: 3250 cost = 0.026569867\n",
      "Validation Loss: 0.035012133\n",
      "Epoch: 3251 cost = 0.026568962\n",
      "Validation Loss: 0.0340079\n",
      "Epoch: 3252 cost = 0.026568017\n",
      "Validation Loss: 0.031279817\n",
      "Epoch: 3253 cost = 0.026567079\n",
      "Validation Loss: 0.031990837\n",
      "Epoch: 3254 cost = 0.026566173\n",
      "Validation Loss: 0.034582894\n",
      "Epoch: 3255 cost = 0.026565253\n",
      "Validation Loss: 0.032132857\n",
      "Epoch: 3256 cost = 0.026564337\n",
      "Validation Loss: 0.032896608\n",
      "Epoch: 3257 cost = 0.026563406\n",
      "Validation Loss: 0.03855473\n",
      "Epoch: 3258 cost = 0.026562503\n",
      "Validation Loss: 0.03687141\n",
      "Epoch: 3259 cost = 0.026561576\n",
      "Validation Loss: 0.03676013\n",
      "Epoch: 3260 cost = 0.026560634\n",
      "Validation Loss: 0.038405493\n",
      "Epoch: 3261 cost = 0.026559738\n",
      "Validation Loss: 0.034511708\n",
      "Epoch: 3262 cost = 0.026558827\n",
      "Validation Loss: 0.037705198\n",
      "Epoch: 3263 cost = 0.026557919\n",
      "Validation Loss: 0.035473187\n",
      "Epoch: 3264 cost = 0.026557000\n",
      "Validation Loss: 0.03493426\n",
      "Epoch: 3265 cost = 0.026556085\n",
      "Validation Loss: 0.038391836\n",
      "Epoch: 3266 cost = 0.026555155\n",
      "Validation Loss: 0.03590812\n",
      "Epoch: 3267 cost = 0.026554267\n",
      "Validation Loss: 0.03711388\n",
      "Epoch: 3268 cost = 0.026553327\n",
      "Validation Loss: 0.036095794\n",
      "Epoch: 3269 cost = 0.026552437\n",
      "Validation Loss: 0.060294013\n",
      "Epoch: 3270 cost = 0.026551524\n",
      "Validation Loss: 0.053452395\n",
      "Epoch: 3271 cost = 0.026550590\n",
      "Validation Loss: 0.045798395\n",
      "Epoch: 3272 cost = 0.026549705\n",
      "Validation Loss: 0.036296207\n",
      "Epoch: 3273 cost = 0.026548799\n",
      "Validation Loss: 0.03594015\n",
      "Epoch: 3274 cost = 0.026547818\n",
      "Validation Loss: 0.031968486\n",
      "Epoch: 3275 cost = 0.026546917\n",
      "Validation Loss: 0.03259028\n",
      "Epoch: 3276 cost = 0.026546038\n",
      "Validation Loss: 0.04190838\n",
      "Epoch: 3277 cost = 0.026545173\n",
      "Validation Loss: 0.070632495\n",
      "Epoch: 3278 cost = 0.026544178\n",
      "Validation Loss: 0.07234268\n",
      "Epoch: 3279 cost = 0.026543282\n",
      "Validation Loss: 0.05377719\n",
      "Epoch: 3280 cost = 0.026542391\n",
      "Validation Loss: 0.03968886\n",
      "Epoch: 3281 cost = 0.026541447\n",
      "Validation Loss: 0.033738125\n",
      "Epoch: 3282 cost = 0.026540582\n",
      "Validation Loss: 0.042164057\n",
      "Epoch: 3283 cost = 0.026539648\n",
      "Validation Loss: 0.03410205\n",
      "Epoch: 3284 cost = 0.026538777\n",
      "Validation Loss: 0.03598142\n",
      "Epoch: 3285 cost = 0.026537849\n",
      "Validation Loss: 0.038629543\n",
      "Epoch: 3286 cost = 0.026536975\n",
      "Validation Loss: 0.031010324\n",
      "Epoch: 3287 cost = 0.026536056\n",
      "Validation Loss: 0.038316473\n",
      "Epoch: 3288 cost = 0.026535121\n",
      "Validation Loss: 0.045226514\n",
      "Epoch: 3289 cost = 0.026534210\n",
      "Validation Loss: 0.0518279\n",
      "Epoch: 3290 cost = 0.026533296\n",
      "Validation Loss: 0.055196606\n",
      "Epoch: 3291 cost = 0.026532414\n",
      "Validation Loss: 0.04389276\n",
      "Epoch: 3292 cost = 0.026531531\n",
      "Validation Loss: 0.03778604\n",
      "Epoch: 3293 cost = 0.026530633\n",
      "Validation Loss: 0.036705397\n",
      "Epoch: 3294 cost = 0.026529701\n",
      "Validation Loss: 0.046060853\n",
      "Epoch: 3295 cost = 0.026528809\n",
      "Validation Loss: 0.07014165\n",
      "Epoch: 3296 cost = 0.026527895\n",
      "Validation Loss: 0.08008037\n",
      "Epoch: 3297 cost = 0.026526968\n",
      "Validation Loss: 0.0729011\n",
      "Epoch: 3298 cost = 0.026526076\n",
      "Validation Loss: 0.056248825\n",
      "Epoch: 3299 cost = 0.026525186\n",
      "Validation Loss: 0.044344153\n",
      "Epoch: 3300 cost = 0.026524236\n",
      "Validation Loss: 0.048830673\n",
      "Epoch: 3301 cost = 0.026523366\n",
      "Validation Loss: 0.043899294\n",
      "Epoch: 3302 cost = 0.026522496\n",
      "Validation Loss: 0.060065217\n",
      "Epoch: 3303 cost = 0.026521559\n",
      "Validation Loss: 0.07333113\n",
      "Epoch: 3304 cost = 0.026520670\n",
      "Validation Loss: 0.05927255\n",
      "Epoch: 3305 cost = 0.026519762\n",
      "Validation Loss: 0.075598665\n",
      "Epoch: 3306 cost = 0.026518899\n",
      "Validation Loss: 0.073136434\n",
      "Epoch: 3307 cost = 0.026517947\n",
      "Validation Loss: 0.048763685\n",
      "Epoch: 3308 cost = 0.026517108\n",
      "Validation Loss: 0.04820482\n",
      "Epoch: 3309 cost = 0.026516155\n",
      "Validation Loss: 0.049982302\n",
      "Epoch: 3310 cost = 0.026515293\n",
      "Validation Loss: 0.035466667\n",
      "Epoch: 3311 cost = 0.026514417\n",
      "Validation Loss: 0.035205014\n",
      "Epoch: 3312 cost = 0.026513472\n",
      "Validation Loss: 0.038143687\n",
      "Epoch: 3313 cost = 0.026512568\n",
      "Validation Loss: 0.04881052\n",
      "Epoch: 3314 cost = 0.026511689\n",
      "Validation Loss: 0.0668566\n",
      "Epoch: 3315 cost = 0.026510814\n",
      "Validation Loss: 0.06819491\n",
      "Epoch: 3316 cost = 0.026509933\n",
      "Validation Loss: 0.08823014\n",
      "Epoch: 3317 cost = 0.026509023\n",
      "Validation Loss: 0.0697198\n",
      "Epoch: 3318 cost = 0.026508137\n",
      "Validation Loss: 0.045429464\n",
      "Epoch: 3319 cost = 0.026507225\n",
      "Validation Loss: 0.048443746\n",
      "Epoch: 3320 cost = 0.026506343\n",
      "Validation Loss: 0.060476687\n",
      "Epoch: 3321 cost = 0.026505455\n",
      "Validation Loss: 0.043218005\n",
      "Epoch: 3322 cost = 0.026504526\n",
      "Validation Loss: 0.034636676\n",
      "Epoch: 3323 cost = 0.026503671\n",
      "Validation Loss: 0.0422289\n",
      "Epoch: 3324 cost = 0.026502763\n",
      "Validation Loss: 0.046384133\n",
      "Epoch: 3325 cost = 0.026501847\n",
      "Validation Loss: 0.041324805\n",
      "Epoch: 3326 cost = 0.026500996\n",
      "Validation Loss: 0.040562768\n",
      "Epoch: 3327 cost = 0.026500076\n",
      "Validation Loss: 0.036422636\n",
      "Epoch: 3328 cost = 0.026499162\n",
      "Validation Loss: 0.034358308\n",
      "Epoch: 3329 cost = 0.026498298\n",
      "Validation Loss: 0.03449143\n",
      "Epoch: 3330 cost = 0.026497420\n",
      "Validation Loss: 0.035897665\n",
      "Epoch: 3331 cost = 0.026496494\n",
      "Validation Loss: 0.04240243\n",
      "Epoch: 3332 cost = 0.026495600\n",
      "Validation Loss: 0.041381057\n",
      "Epoch: 3333 cost = 0.026494749\n",
      "Validation Loss: 0.039753057\n",
      "Epoch: 3334 cost = 0.026493868\n",
      "Validation Loss: 0.039710883\n",
      "Epoch: 3335 cost = 0.026492976\n",
      "Validation Loss: 0.039164703\n",
      "Epoch: 3336 cost = 0.026492129\n",
      "Validation Loss: 0.03656282\n",
      "Epoch: 3337 cost = 0.026491159\n",
      "Validation Loss: 0.034408867\n",
      "Epoch: 3338 cost = 0.026490277\n",
      "Validation Loss: 0.040652882\n",
      "Epoch: 3339 cost = 0.026489395\n",
      "Validation Loss: 0.035277944\n",
      "Epoch: 3340 cost = 0.026488548\n",
      "Validation Loss: 0.03378395\n",
      "Epoch: 3341 cost = 0.026487638\n",
      "Validation Loss: 0.03971127\n",
      "Epoch: 3342 cost = 0.026486752\n",
      "Validation Loss: 0.033990838\n",
      "Epoch: 3343 cost = 0.026485877\n",
      "Validation Loss: 0.03356757\n",
      "Epoch: 3344 cost = 0.026485001\n",
      "Validation Loss: 0.039751366\n",
      "Epoch: 3345 cost = 0.026484114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.035717234\n",
      "Epoch: 3346 cost = 0.026483232\n",
      "Validation Loss: 0.034481518\n",
      "Epoch: 3347 cost = 0.026482313\n",
      "Validation Loss: 0.030078916\n",
      "Epoch: 3348 cost = 0.026481465\n",
      "Validation Loss: 0.035205353\n",
      "Epoch: 3349 cost = 0.026480543\n",
      "Validation Loss: 0.042581562\n",
      "Epoch: 3350 cost = 0.026479706\n",
      "Validation Loss: 0.0429253\n",
      "Epoch: 3351 cost = 0.026478804\n",
      "Validation Loss: 0.04359792\n",
      "Epoch: 3352 cost = 0.026477915\n",
      "Validation Loss: 0.04494272\n",
      "Epoch: 3353 cost = 0.026476990\n",
      "Validation Loss: 0.039889675\n",
      "Epoch: 3354 cost = 0.026476132\n",
      "Validation Loss: 0.043862145\n",
      "Epoch: 3355 cost = 0.026475281\n",
      "Validation Loss: 0.03655342\n",
      "Epoch: 3356 cost = 0.026474359\n",
      "Validation Loss: 0.030977348\n",
      "Epoch: 3357 cost = 0.026473505\n",
      "Validation Loss: 0.029896151\n",
      "Epoch: 3358 cost = 0.026472614\n",
      "Validation Loss: 0.0560515\n",
      "Epoch: 3359 cost = 0.026471716\n",
      "Validation Loss: 0.04889774\n",
      "Epoch: 3360 cost = 0.026470888\n",
      "Validation Loss: 0.037669126\n",
      "Epoch: 3361 cost = 0.026470015\n",
      "Validation Loss: 0.034532357\n",
      "Epoch: 3362 cost = 0.026469130\n",
      "Validation Loss: 0.03389649\n",
      "Epoch: 3363 cost = 0.026468210\n",
      "Validation Loss: 0.032930553\n",
      "Epoch: 3364 cost = 0.026467354\n",
      "Validation Loss: 0.031678285\n",
      "Epoch: 3365 cost = 0.026466465\n",
      "Validation Loss: 0.04707601\n",
      "Epoch: 3366 cost = 0.026465594\n",
      "Validation Loss: 0.04237455\n",
      "Epoch: 3367 cost = 0.026464688\n",
      "Validation Loss: 0.047752295\n",
      "Epoch: 3368 cost = 0.026463860\n",
      "Validation Loss: 0.057334967\n",
      "Epoch: 3369 cost = 0.026462991\n",
      "Validation Loss: 0.044501223\n",
      "Epoch: 3370 cost = 0.026462063\n",
      "Validation Loss: 0.034857187\n",
      "Epoch: 3371 cost = 0.026461205\n",
      "Validation Loss: 0.037990835\n",
      "Epoch: 3372 cost = 0.026460324\n",
      "Validation Loss: 0.033239443\n",
      "Epoch: 3373 cost = 0.026459455\n",
      "Validation Loss: 0.03858747\n",
      "Epoch: 3374 cost = 0.026458594\n",
      "Validation Loss: 0.04173335\n",
      "Epoch: 3375 cost = 0.026457754\n",
      "Validation Loss: 0.03947549\n",
      "Epoch: 3376 cost = 0.026456852\n",
      "Validation Loss: 0.048427153\n",
      "Epoch: 3377 cost = 0.026455944\n",
      "Validation Loss: 0.04138798\n",
      "Epoch: 3378 cost = 0.026455139\n",
      "Validation Loss: 0.033496004\n",
      "Epoch: 3379 cost = 0.026454235\n",
      "Validation Loss: 0.030695604\n",
      "Epoch: 3380 cost = 0.026453418\n",
      "Validation Loss: 0.033324674\n",
      "Epoch: 3381 cost = 0.026452480\n",
      "Validation Loss: 0.038752336\n",
      "Epoch: 3382 cost = 0.026451650\n",
      "Validation Loss: 0.031118857\n",
      "Epoch: 3383 cost = 0.026450765\n",
      "Validation Loss: 0.0335311\n",
      "Epoch: 3384 cost = 0.026449873\n",
      "Validation Loss: 0.033932302\n",
      "Epoch: 3385 cost = 0.026449013\n",
      "Validation Loss: 0.04710108\n",
      "Epoch: 3386 cost = 0.026448129\n",
      "Validation Loss: 0.058137253\n",
      "Epoch: 3387 cost = 0.026447272\n",
      "Validation Loss: 0.06551554\n",
      "Epoch: 3388 cost = 0.026446440\n",
      "Validation Loss: 0.043813962\n",
      "Epoch: 3389 cost = 0.026445545\n",
      "Validation Loss: 0.03328183\n",
      "Epoch: 3390 cost = 0.026444637\n",
      "Validation Loss: 0.034248263\n",
      "Epoch: 3391 cost = 0.026443814\n",
      "Validation Loss: 0.03842063\n",
      "Epoch: 3392 cost = 0.026442932\n",
      "Validation Loss: 0.04071252\n",
      "Epoch: 3393 cost = 0.026442051\n",
      "Validation Loss: 0.035375886\n",
      "Epoch: 3394 cost = 0.026441174\n",
      "Validation Loss: 0.038022067\n",
      "Epoch: 3395 cost = 0.026440306\n",
      "Validation Loss: 0.043026634\n",
      "Epoch: 3396 cost = 0.026439433\n",
      "Validation Loss: 0.035163432\n",
      "Epoch: 3397 cost = 0.026438579\n",
      "Validation Loss: 0.02954109\n",
      "Epoch: 3398 cost = 0.026437733\n",
      "Validation Loss: 0.044887077\n",
      "Epoch: 3399 cost = 0.026436895\n",
      "Validation Loss: 0.059234668\n",
      "Epoch: 3400 cost = 0.026435996\n",
      "Validation Loss: 0.09499284\n",
      "Epoch: 3401 cost = 0.026435150\n",
      "Validation Loss: 0.08269883\n",
      "Epoch: 3402 cost = 0.026434270\n",
      "Validation Loss: 0.049956203\n",
      "Epoch: 3403 cost = 0.026433458\n",
      "Validation Loss: 0.041749783\n",
      "Epoch: 3404 cost = 0.026432553\n",
      "Validation Loss: 0.07093531\n",
      "Epoch: 3405 cost = 0.026431659\n",
      "Validation Loss: 0.07652349\n",
      "Epoch: 3406 cost = 0.026430776\n",
      "Validation Loss: 0.102489956\n",
      "Epoch: 3407 cost = 0.026429892\n",
      "Validation Loss: 0.05522445\n",
      "Epoch: 3408 cost = 0.026429083\n",
      "Validation Loss: 0.053377647\n",
      "Epoch: 3409 cost = 0.026428234\n",
      "Validation Loss: 0.073846705\n",
      "Epoch: 3410 cost = 0.026427344\n",
      "Validation Loss: 0.05357519\n",
      "Epoch: 3411 cost = 0.026426506\n",
      "Validation Loss: 0.037077077\n",
      "Epoch: 3412 cost = 0.026425630\n",
      "Validation Loss: 0.05527962\n",
      "Epoch: 3413 cost = 0.026424755\n",
      "Validation Loss: 0.06294859\n",
      "Epoch: 3414 cost = 0.026423914\n",
      "Validation Loss: 0.11692684\n",
      "Epoch: 3415 cost = 0.026423048\n",
      "Validation Loss: 0.13710767\n",
      "Epoch: 3416 cost = 0.026422173\n",
      "Validation Loss: 0.07047246\n",
      "Epoch: 3417 cost = 0.026421333\n",
      "Validation Loss: 0.051941533\n",
      "Epoch: 3418 cost = 0.026420481\n",
      "Validation Loss: 0.0647851\n",
      "Epoch: 3419 cost = 0.026419635\n",
      "Validation Loss: 0.071647085\n",
      "Epoch: 3420 cost = 0.026418735\n",
      "Validation Loss: 0.03814174\n",
      "Epoch: 3421 cost = 0.026417915\n",
      "Validation Loss: 0.034378886\n",
      "Epoch: 3422 cost = 0.026417050\n",
      "Validation Loss: 0.03646607\n",
      "Epoch: 3423 cost = 0.026416242\n",
      "Validation Loss: 0.04339081\n",
      "Epoch: 3424 cost = 0.026415337\n",
      "Validation Loss: 0.04247325\n",
      "Epoch: 3425 cost = 0.026414505\n",
      "Validation Loss: 0.037490644\n",
      "Epoch: 3426 cost = 0.026413654\n",
      "Validation Loss: 0.035959534\n",
      "Epoch: 3427 cost = 0.026412731\n",
      "Validation Loss: 0.033049352\n",
      "Epoch: 3428 cost = 0.026411924\n",
      "Validation Loss: 0.033287115\n",
      "Epoch: 3429 cost = 0.026411079\n",
      "Validation Loss: 0.039878998\n",
      "Epoch: 3430 cost = 0.026410185\n",
      "Validation Loss: 0.039006293\n",
      "Epoch: 3431 cost = 0.026409317\n",
      "Validation Loss: 0.045124482\n",
      "Epoch: 3432 cost = 0.026408455\n",
      "Validation Loss: 0.07151673\n",
      "Epoch: 3433 cost = 0.026407645\n",
      "Validation Loss: 0.09756513\n",
      "Epoch: 3434 cost = 0.026406767\n",
      "Validation Loss: 0.11484701\n",
      "Epoch: 3435 cost = 0.026405944\n",
      "Validation Loss: 0.055818114\n",
      "Epoch: 3436 cost = 0.026405064\n",
      "Validation Loss: 0.049935006\n",
      "Epoch: 3437 cost = 0.026404198\n",
      "Validation Loss: 0.058330223\n",
      "Epoch: 3438 cost = 0.026403387\n",
      "Validation Loss: 0.037522886\n",
      "Epoch: 3439 cost = 0.026402532\n",
      "Validation Loss: 0.033854187\n",
      "Epoch: 3440 cost = 0.026401633\n",
      "Validation Loss: 0.047563102\n",
      "Epoch: 3441 cost = 0.026400841\n",
      "Validation Loss: 0.040945493\n",
      "Epoch: 3442 cost = 0.026399976\n",
      "Validation Loss: 0.041961383\n",
      "Epoch: 3443 cost = 0.026399119\n",
      "Validation Loss: 0.054639127\n",
      "Epoch: 3444 cost = 0.026398263\n",
      "Validation Loss: 0.04452799\n",
      "Epoch: 3445 cost = 0.026397421\n",
      "Validation Loss: 0.036146563\n",
      "Epoch: 3446 cost = 0.026396579\n",
      "Validation Loss: 0.031923138\n",
      "Epoch: 3447 cost = 0.026395752\n",
      "Validation Loss: 0.03254707\n",
      "Epoch: 3448 cost = 0.026394887\n",
      "Validation Loss: 0.03813846\n",
      "Epoch: 3449 cost = 0.026394068\n",
      "Validation Loss: 0.03890233\n",
      "Epoch: 3450 cost = 0.026393212\n",
      "Validation Loss: 0.054120053\n",
      "Epoch: 3451 cost = 0.026392305\n",
      "Validation Loss: 0.07337929\n",
      "Epoch: 3452 cost = 0.026391489\n",
      "Validation Loss: 0.09354542\n",
      "Epoch: 3453 cost = 0.026390611\n",
      "Validation Loss: 0.09024032\n",
      "Epoch: 3454 cost = 0.026389797\n",
      "Validation Loss: 0.053223923\n",
      "Epoch: 3455 cost = 0.026388927\n",
      "Validation Loss: 0.048841175\n",
      "Epoch: 3456 cost = 0.026388069\n",
      "Validation Loss: 0.071484596\n",
      "Epoch: 3457 cost = 0.026387211\n",
      "Validation Loss: 0.117842026\n",
      "Epoch: 3458 cost = 0.026386426\n",
      "Validation Loss: 0.118263446\n",
      "Epoch: 3459 cost = 0.026385534\n",
      "Validation Loss: 0.07528904\n",
      "Epoch: 3460 cost = 0.026384724\n",
      "Validation Loss: 0.04136786\n",
      "Epoch: 3461 cost = 0.026383895\n",
      "Validation Loss: 0.034555405\n",
      "Epoch: 3462 cost = 0.026383042\n",
      "Validation Loss: 0.03343873\n",
      "Epoch: 3463 cost = 0.026382246\n",
      "Validation Loss: 0.033617985\n",
      "Epoch: 3464 cost = 0.026381350\n",
      "Validation Loss: 0.043411758\n",
      "Epoch: 3465 cost = 0.026380541\n",
      "Validation Loss: 0.06450449\n",
      "Epoch: 3466 cost = 0.026379670\n",
      "Validation Loss: 0.07259196\n",
      "Epoch: 3467 cost = 0.026378823\n",
      "Validation Loss: 0.035684004\n",
      "Epoch: 3468 cost = 0.026377954\n",
      "Validation Loss: 0.03898967\n",
      "Epoch: 3469 cost = 0.026377169\n",
      "Validation Loss: 0.04258671\n",
      "Epoch: 3470 cost = 0.026376316\n",
      "Validation Loss: 0.038998652\n",
      "Epoch: 3471 cost = 0.026375478\n",
      "Validation Loss: 0.034769565\n",
      "Epoch: 3472 cost = 0.026374650\n",
      "Validation Loss: 0.031444162\n",
      "Epoch: 3473 cost = 0.026373785\n",
      "Validation Loss: 0.03928094\n",
      "Epoch: 3474 cost = 0.026373001\n",
      "Validation Loss: 0.07494354\n",
      "Epoch: 3475 cost = 0.026372116\n",
      "Validation Loss: 0.06835135\n",
      "Epoch: 3476 cost = 0.026371303\n",
      "Validation Loss: 0.038873095\n",
      "Epoch: 3477 cost = 0.026370453\n",
      "Validation Loss: 0.032643735\n",
      "Epoch: 3478 cost = 0.026369574\n",
      "Validation Loss: 0.039474174\n",
      "Epoch: 3479 cost = 0.026368748\n",
      "Validation Loss: 0.042039115\n",
      "Epoch: 3480 cost = 0.026367882\n",
      "Validation Loss: 0.03788725\n",
      "Epoch: 3481 cost = 0.026367073\n",
      "Validation Loss: 0.03595564\n",
      "Epoch: 3482 cost = 0.026366239\n",
      "Validation Loss: 0.03405709\n",
      "Epoch: 3483 cost = 0.026365372\n",
      "Validation Loss: 0.053818397\n",
      "Epoch: 3484 cost = 0.026364600\n",
      "Validation Loss: 0.07508719\n",
      "Epoch: 3485 cost = 0.026363774\n",
      "Validation Loss: 0.10820263\n",
      "Epoch: 3486 cost = 0.026362928\n",
      "Validation Loss: 0.06385356\n",
      "Epoch: 3487 cost = 0.026362112\n",
      "Validation Loss: 0.04630203\n",
      "Epoch: 3488 cost = 0.026361245\n",
      "Validation Loss: 0.035233565\n",
      "Epoch: 3489 cost = 0.026360396\n",
      "Validation Loss: 0.039968766\n",
      "Epoch: 3490 cost = 0.026359562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.061987583\n",
      "Epoch: 3491 cost = 0.026358729\n",
      "Validation Loss: 0.06710423\n",
      "Epoch: 3492 cost = 0.026357906\n",
      "Validation Loss: 0.05584862\n",
      "Epoch: 3493 cost = 0.026357078\n",
      "Validation Loss: 0.033796657\n",
      "Epoch: 3494 cost = 0.026356258\n",
      "Validation Loss: 0.03901792\n",
      "Epoch: 3495 cost = 0.026355449\n",
      "Validation Loss: 0.03951604\n",
      "Epoch: 3496 cost = 0.026354572\n",
      "Validation Loss: 0.033855036\n",
      "Epoch: 3497 cost = 0.026353748\n",
      "Validation Loss: 0.03578849\n",
      "Epoch: 3498 cost = 0.026352932\n",
      "Validation Loss: 0.058433425\n",
      "Epoch: 3499 cost = 0.026352118\n",
      "Validation Loss: 0.09541979\n",
      "Epoch: 3500 cost = 0.026351264\n",
      "Validation Loss: 0.12942673\n",
      "Epoch: 3501 cost = 0.026350446\n",
      "Validation Loss: 0.10738884\n",
      "Epoch: 3502 cost = 0.026349612\n",
      "Validation Loss: 0.055589657\n",
      "Epoch: 3503 cost = 0.026348819\n",
      "Validation Loss: 0.03402921\n",
      "Epoch: 3504 cost = 0.026348001\n",
      "Validation Loss: 0.03742475\n",
      "Epoch: 3505 cost = 0.026347157\n",
      "Validation Loss: 0.035839453\n",
      "Epoch: 3506 cost = 0.026346330\n",
      "Validation Loss: 0.03455857\n",
      "Epoch: 3507 cost = 0.026345498\n",
      "Validation Loss: 0.048345096\n",
      "Epoch: 3508 cost = 0.026344674\n",
      "Validation Loss: 0.041330826\n",
      "Epoch: 3509 cost = 0.026343834\n",
      "Validation Loss: 0.053541474\n",
      "Epoch: 3510 cost = 0.026343008\n",
      "Validation Loss: 0.04608042\n",
      "Epoch: 3511 cost = 0.026342179\n",
      "Validation Loss: 0.05991209\n",
      "Epoch: 3512 cost = 0.026341340\n",
      "Validation Loss: 0.041329715\n",
      "Epoch: 3513 cost = 0.026340543\n",
      "Validation Loss: 0.03808045\n",
      "Epoch: 3514 cost = 0.026339698\n",
      "Validation Loss: 0.038400073\n",
      "Epoch: 3515 cost = 0.026338914\n",
      "Validation Loss: 0.039010745\n",
      "Epoch: 3516 cost = 0.026338095\n",
      "Validation Loss: 0.040792026\n",
      "Epoch: 3517 cost = 0.026337259\n",
      "Validation Loss: 0.036236115\n",
      "Epoch: 3518 cost = 0.026336456\n",
      "Validation Loss: 0.03435663\n",
      "Epoch: 3519 cost = 0.026335629\n",
      "Validation Loss: 0.03743564\n",
      "Epoch: 3520 cost = 0.026334802\n",
      "Validation Loss: 0.05467165\n",
      "Epoch: 3521 cost = 0.026333986\n",
      "Validation Loss: 0.046080045\n",
      "Epoch: 3522 cost = 0.026333126\n",
      "Validation Loss: 0.040141165\n",
      "Epoch: 3523 cost = 0.026332347\n",
      "Validation Loss: 0.0366638\n",
      "Epoch: 3524 cost = 0.026331561\n",
      "Validation Loss: 0.037202496\n",
      "Epoch: 3525 cost = 0.026330675\n",
      "Validation Loss: 0.03789453\n",
      "Epoch: 3526 cost = 0.026329876\n",
      "Validation Loss: 0.03484662\n",
      "Epoch: 3527 cost = 0.026329062\n",
      "Validation Loss: 0.03506564\n",
      "Epoch: 3528 cost = 0.026328272\n",
      "Validation Loss: 0.03440691\n",
      "Epoch: 3529 cost = 0.026327423\n",
      "Validation Loss: 0.035567537\n",
      "Epoch: 3530 cost = 0.026326580\n",
      "Validation Loss: 0.037669394\n",
      "Epoch: 3531 cost = 0.026325827\n",
      "Validation Loss: 0.039341196\n",
      "Epoch: 3532 cost = 0.026324986\n",
      "Validation Loss: 0.040746946\n",
      "Epoch: 3533 cost = 0.026324136\n",
      "Validation Loss: 0.034107897\n",
      "Epoch: 3534 cost = 0.026323391\n",
      "Validation Loss: 0.036790576\n",
      "Epoch: 3535 cost = 0.026322566\n",
      "Validation Loss: 0.052968286\n",
      "Epoch: 3536 cost = 0.026321709\n",
      "Validation Loss: 0.04952167\n",
      "Epoch: 3537 cost = 0.026320894\n",
      "Validation Loss: 0.04376794\n",
      "Epoch: 3538 cost = 0.026320136\n",
      "Validation Loss: 0.052129257\n",
      "Epoch: 3539 cost = 0.026319280\n",
      "Validation Loss: 0.0675862\n",
      "Epoch: 3540 cost = 0.026318464\n",
      "Validation Loss: 0.050946087\n",
      "Epoch: 3541 cost = 0.026317707\n",
      "Validation Loss: 0.03409324\n",
      "Epoch: 3542 cost = 0.026316881\n",
      "Validation Loss: 0.033574566\n",
      "Epoch: 3543 cost = 0.026316063\n",
      "Validation Loss: 0.034502346\n",
      "Epoch: 3544 cost = 0.026315286\n",
      "Validation Loss: 0.035161182\n",
      "Epoch: 3545 cost = 0.026314390\n",
      "Validation Loss: 0.041539464\n",
      "Epoch: 3546 cost = 0.026313598\n",
      "Validation Loss: 0.0846596\n",
      "Epoch: 3547 cost = 0.026312763\n",
      "Validation Loss: 0.05694065\n",
      "Epoch: 3548 cost = 0.026311970\n",
      "Validation Loss: 0.041155286\n",
      "Epoch: 3549 cost = 0.026311173\n",
      "Validation Loss: 0.031491153\n",
      "Epoch: 3550 cost = 0.026310390\n",
      "Validation Loss: 0.034916174\n",
      "Epoch: 3551 cost = 0.026309527\n",
      "Validation Loss: 0.03495069\n",
      "Epoch: 3552 cost = 0.026308740\n",
      "Validation Loss: 0.031723224\n",
      "Epoch: 3553 cost = 0.026307983\n",
      "Validation Loss: 0.03755987\n",
      "Epoch: 3554 cost = 0.026307149\n",
      "Validation Loss: 0.04075007\n",
      "Epoch: 3555 cost = 0.026306344\n",
      "Validation Loss: 0.039208923\n",
      "Epoch: 3556 cost = 0.026305566\n",
      "Validation Loss: 0.041757226\n",
      "Epoch: 3557 cost = 0.026304747\n",
      "Validation Loss: 0.035124734\n",
      "Epoch: 3558 cost = 0.026303974\n",
      "Validation Loss: 0.034914445\n",
      "Epoch: 3559 cost = 0.026303130\n",
      "Validation Loss: 0.03282984\n",
      "Epoch: 3560 cost = 0.026302326\n",
      "Validation Loss: 0.031499878\n",
      "Epoch: 3561 cost = 0.026301515\n",
      "Validation Loss: 0.039683476\n",
      "Epoch: 3562 cost = 0.026300725\n",
      "Validation Loss: 0.042198427\n",
      "Epoch: 3563 cost = 0.026299943\n",
      "Validation Loss: 0.04054224\n",
      "Epoch: 3564 cost = 0.026299139\n",
      "Validation Loss: 0.03637652\n",
      "Epoch: 3565 cost = 0.026298328\n",
      "Validation Loss: 0.03341298\n",
      "Epoch: 3566 cost = 0.026297497\n",
      "Validation Loss: 0.03920633\n",
      "Epoch: 3567 cost = 0.026296740\n",
      "Validation Loss: 0.03281567\n",
      "Epoch: 3568 cost = 0.026295903\n",
      "Validation Loss: 0.03429236\n",
      "Epoch: 3569 cost = 0.026295136\n",
      "Validation Loss: 0.031752557\n",
      "Epoch: 3570 cost = 0.026294350\n",
      "Validation Loss: 0.034032937\n",
      "Epoch: 3571 cost = 0.026293529\n",
      "Validation Loss: 0.03374244\n",
      "Epoch: 3572 cost = 0.026292728\n",
      "Validation Loss: 0.036746103\n",
      "Epoch: 3573 cost = 0.026291938\n",
      "Validation Loss: 0.054064404\n",
      "Epoch: 3574 cost = 0.026291128\n",
      "Validation Loss: 0.04763714\n",
      "Epoch: 3575 cost = 0.026290324\n",
      "Validation Loss: 0.07010143\n",
      "Epoch: 3576 cost = 0.026289528\n",
      "Validation Loss: 0.05151754\n",
      "Epoch: 3577 cost = 0.026288716\n",
      "Validation Loss: 0.072343834\n",
      "Epoch: 3578 cost = 0.026287927\n",
      "Validation Loss: 0.05608807\n",
      "Epoch: 3579 cost = 0.026287191\n",
      "Validation Loss: 0.046424404\n",
      "Epoch: 3580 cost = 0.026286365\n",
      "Validation Loss: 0.04548978\n",
      "Epoch: 3581 cost = 0.026285582\n",
      "Validation Loss: 0.07130948\n",
      "Epoch: 3582 cost = 0.026284785\n",
      "Validation Loss: 0.04155435\n",
      "Epoch: 3583 cost = 0.026283921\n",
      "Validation Loss: 0.03496281\n",
      "Epoch: 3584 cost = 0.026283216\n",
      "Validation Loss: 0.030980442\n",
      "Epoch: 3585 cost = 0.026282401\n",
      "Validation Loss: 0.040807646\n",
      "Epoch: 3586 cost = 0.026281602\n",
      "Validation Loss: 0.040302772\n",
      "Epoch: 3587 cost = 0.026280848\n",
      "Validation Loss: 0.041220028\n",
      "Epoch: 3588 cost = 0.026280034\n",
      "Validation Loss: 0.039559744\n",
      "Epoch: 3589 cost = 0.026279275\n",
      "Validation Loss: 0.043147985\n",
      "Epoch: 3590 cost = 0.026278442\n",
      "Validation Loss: 0.09957486\n",
      "Epoch: 3591 cost = 0.026277653\n",
      "Validation Loss: 0.11569556\n",
      "Epoch: 3592 cost = 0.026276855\n",
      "Validation Loss: 0.11899806\n",
      "Epoch: 3593 cost = 0.026276079\n",
      "Validation Loss: 0.121442646\n",
      "Epoch: 3594 cost = 0.026275315\n",
      "Validation Loss: 0.121441245\n",
      "Epoch: 3595 cost = 0.026274504\n",
      "Validation Loss: 0.094719455\n",
      "Epoch: 3596 cost = 0.026273725\n",
      "Validation Loss: 0.04621136\n",
      "Epoch: 3597 cost = 0.026272975\n",
      "Validation Loss: 0.034324378\n",
      "Epoch: 3598 cost = 0.026272153\n",
      "Validation Loss: 0.03308726\n",
      "Epoch: 3599 cost = 0.026271418\n",
      "Validation Loss: 0.0332112\n",
      "Epoch: 3600 cost = 0.026270576\n",
      "Validation Loss: 0.04302747\n",
      "Epoch: 3601 cost = 0.026269805\n",
      "Validation Loss: 0.064264\n",
      "Epoch: 3602 cost = 0.026269027\n",
      "Validation Loss: 0.07708964\n",
      "Epoch: 3603 cost = 0.026268223\n",
      "Validation Loss: 0.07536654\n",
      "Epoch: 3604 cost = 0.026267489\n",
      "Validation Loss: 0.065752774\n",
      "Epoch: 3605 cost = 0.026266698\n",
      "Validation Loss: 0.05762728\n",
      "Epoch: 3606 cost = 0.026265942\n",
      "Validation Loss: 0.053943295\n",
      "Epoch: 3607 cost = 0.026265136\n",
      "Validation Loss: 0.08138207\n",
      "Epoch: 3608 cost = 0.026264375\n",
      "Validation Loss: 0.114983134\n",
      "Epoch: 3609 cost = 0.026263590\n",
      "Validation Loss: 0.09670882\n",
      "Epoch: 3610 cost = 0.026262787\n",
      "Validation Loss: 0.07110579\n",
      "Epoch: 3611 cost = 0.026262046\n",
      "Validation Loss: 0.044388264\n",
      "Epoch: 3612 cost = 0.026261240\n",
      "Validation Loss: 0.04068477\n",
      "Epoch: 3613 cost = 0.026260484\n",
      "Validation Loss: 0.044577207\n",
      "Epoch: 3614 cost = 0.026259672\n",
      "Validation Loss: 0.044074684\n",
      "Epoch: 3615 cost = 0.026258907\n",
      "Validation Loss: 0.037122607\n",
      "Epoch: 3616 cost = 0.026258183\n",
      "Validation Loss: 0.03831793\n",
      "Epoch: 3617 cost = 0.026257404\n",
      "Validation Loss: 0.042125188\n",
      "Epoch: 3618 cost = 0.026256567\n",
      "Validation Loss: 0.046438165\n",
      "Epoch: 3619 cost = 0.026255810\n",
      "Validation Loss: 0.04047294\n",
      "Epoch: 3620 cost = 0.026255041\n",
      "Validation Loss: 0.032283314\n",
      "Epoch: 3621 cost = 0.026254247\n",
      "Validation Loss: 0.04822438\n",
      "Epoch: 3622 cost = 0.026253486\n",
      "Validation Loss: 0.046860494\n",
      "Epoch: 3623 cost = 0.026252705\n",
      "Validation Loss: 0.052080087\n",
      "Epoch: 3624 cost = 0.026251982\n",
      "Validation Loss: 0.052493844\n",
      "Epoch: 3625 cost = 0.026251212\n",
      "Validation Loss: 0.03813213\n",
      "Epoch: 3626 cost = 0.026250442\n",
      "Validation Loss: 0.040853985\n",
      "Epoch: 3627 cost = 0.026249634\n",
      "Validation Loss: 0.053131513\n",
      "Epoch: 3628 cost = 0.026248905\n",
      "Validation Loss: 0.078609526\n",
      "Epoch: 3629 cost = 0.026248141\n",
      "Validation Loss: 0.078940205\n",
      "Epoch: 3630 cost = 0.026247372\n",
      "Validation Loss: 0.03770355\n",
      "Epoch: 3631 cost = 0.026246608\n",
      "Validation Loss: 0.035317846\n",
      "Epoch: 3632 cost = 0.026245820\n",
      "Validation Loss: 0.041039128\n",
      "Epoch: 3633 cost = 0.026245094\n",
      "Validation Loss: 0.034048773\n",
      "Epoch: 3634 cost = 0.026244286\n",
      "Validation Loss: 0.032987732\n",
      "Epoch: 3635 cost = 0.026243529\n",
      "Validation Loss: 0.044044144\n",
      "Epoch: 3636 cost = 0.026242745\n",
      "Validation Loss: 0.11176751\n",
      "Epoch: 3637 cost = 0.026242025\n",
      "Validation Loss: 0.05416144\n",
      "Epoch: 3638 cost = 0.026241271\n",
      "Validation Loss: 0.036436576\n",
      "Epoch: 3639 cost = 0.026240440\n",
      "Validation Loss: 0.03643966\n",
      "Epoch: 3640 cost = 0.026239731\n",
      "Validation Loss: 0.032765817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3641 cost = 0.026238942\n",
      "Validation Loss: 0.04824981\n",
      "Epoch: 3642 cost = 0.026238212\n",
      "Validation Loss: 0.035474803\n",
      "Epoch: 3643 cost = 0.026237448\n",
      "Validation Loss: 0.03155105\n",
      "Epoch: 3644 cost = 0.026236726\n",
      "Validation Loss: 0.03521604\n",
      "Epoch: 3645 cost = 0.026235936\n",
      "Validation Loss: 0.035705473\n",
      "Epoch: 3646 cost = 0.026235197\n",
      "Validation Loss: 0.036874663\n",
      "Epoch: 3647 cost = 0.026234444\n",
      "Validation Loss: 0.037429992\n",
      "Epoch: 3648 cost = 0.026233651\n",
      "Validation Loss: 0.041090522\n",
      "Epoch: 3649 cost = 0.026232890\n",
      "Validation Loss: 0.037200835\n",
      "Epoch: 3650 cost = 0.026232142\n",
      "Validation Loss: 0.03610292\n",
      "Epoch: 3651 cost = 0.026231407\n",
      "Validation Loss: 0.037799127\n",
      "Epoch: 3652 cost = 0.026230606\n",
      "Validation Loss: 0.03840833\n",
      "Epoch: 3653 cost = 0.026229840\n",
      "Validation Loss: 0.035252873\n",
      "Epoch: 3654 cost = 0.026229114\n",
      "Validation Loss: 0.035474017\n",
      "Epoch: 3655 cost = 0.026228335\n",
      "Validation Loss: 0.0460709\n",
      "Epoch: 3656 cost = 0.026227646\n",
      "Validation Loss: 0.03307393\n",
      "Epoch: 3657 cost = 0.026226884\n",
      "Validation Loss: 0.04102465\n",
      "Epoch: 3658 cost = 0.026226106\n",
      "Validation Loss: 0.038406603\n",
      "Epoch: 3659 cost = 0.026225381\n",
      "Validation Loss: 0.03581933\n",
      "Epoch: 3660 cost = 0.026224599\n",
      "Validation Loss: 0.03340675\n",
      "Epoch: 3661 cost = 0.026223872\n",
      "Validation Loss: 0.029704968\n",
      "Epoch: 3662 cost = 0.026223102\n",
      "Validation Loss: 0.0343431\n",
      "Epoch: 3663 cost = 0.026222377\n",
      "Validation Loss: 0.04659894\n",
      "Epoch: 3664 cost = 0.026221638\n",
      "Validation Loss: 0.049214315\n",
      "Epoch: 3665 cost = 0.026220915\n",
      "Validation Loss: 0.035797533\n",
      "Epoch: 3666 cost = 0.026220152\n",
      "Validation Loss: 0.03129434\n",
      "Epoch: 3667 cost = 0.026219367\n",
      "Validation Loss: 0.03125698\n",
      "Epoch: 3668 cost = 0.026218618\n",
      "Validation Loss: 0.0301057\n",
      "Epoch: 3669 cost = 0.026217916\n",
      "Validation Loss: 0.03178568\n",
      "Epoch: 3670 cost = 0.026217153\n",
      "Validation Loss: 0.03213998\n",
      "Epoch: 3671 cost = 0.026216378\n",
      "Validation Loss: 0.034110304\n",
      "Epoch: 3672 cost = 0.026215655\n",
      "Validation Loss: 0.03711178\n",
      "Epoch: 3673 cost = 0.026214922\n",
      "Validation Loss: 0.03728792\n",
      "Epoch: 3674 cost = 0.026214153\n",
      "Validation Loss: 0.03299302\n",
      "Epoch: 3675 cost = 0.026213436\n",
      "Validation Loss: 0.039448235\n",
      "Epoch: 3676 cost = 0.026212716\n",
      "Validation Loss: 0.033635095\n",
      "Epoch: 3677 cost = 0.026211986\n",
      "Validation Loss: 0.034508888\n",
      "Epoch: 3678 cost = 0.026211230\n",
      "Validation Loss: 0.03621602\n",
      "Epoch: 3679 cost = 0.026210530\n",
      "Validation Loss: 0.039658837\n",
      "Epoch: 3680 cost = 0.026209779\n",
      "Validation Loss: 0.039718073\n",
      "Epoch: 3681 cost = 0.026209019\n",
      "Validation Loss: 0.03454619\n",
      "Epoch: 3682 cost = 0.026208287\n",
      "Validation Loss: 0.03655196\n",
      "Epoch: 3683 cost = 0.026207516\n",
      "Validation Loss: 0.036709294\n",
      "Epoch: 3684 cost = 0.026206761\n",
      "Validation Loss: 0.03906886\n",
      "Epoch: 3685 cost = 0.026206089\n",
      "Validation Loss: 0.06771922\n",
      "Epoch: 3686 cost = 0.026205305\n",
      "Validation Loss: 0.08279588\n",
      "Epoch: 3687 cost = 0.026204602\n",
      "Validation Loss: 0.04514106\n",
      "Epoch: 3688 cost = 0.026203884\n",
      "Validation Loss: 0.04764185\n",
      "Epoch: 3689 cost = 0.026203176\n",
      "Validation Loss: 0.04735025\n",
      "Epoch: 3690 cost = 0.026202419\n",
      "Validation Loss: 0.034788646\n",
      "Epoch: 3691 cost = 0.026201676\n",
      "Validation Loss: 0.036922283\n",
      "Epoch: 3692 cost = 0.026200926\n",
      "Validation Loss: 0.040896773\n",
      "Epoch: 3693 cost = 0.026200242\n",
      "Validation Loss: 0.0421154\n",
      "Epoch: 3694 cost = 0.026199497\n",
      "Validation Loss: 0.040434908\n",
      "Epoch: 3695 cost = 0.026198756\n",
      "Validation Loss: 0.056092132\n",
      "Epoch: 3696 cost = 0.026198025\n",
      "Validation Loss: 0.05431437\n",
      "Epoch: 3697 cost = 0.026197380\n",
      "Validation Loss: 0.040411312\n",
      "Epoch: 3698 cost = 0.026196572\n",
      "Validation Loss: 0.04367785\n",
      "Epoch: 3699 cost = 0.026195851\n",
      "Validation Loss: 0.044492505\n",
      "Epoch: 3700 cost = 0.026195098\n",
      "Validation Loss: 0.039603855\n",
      "Epoch: 3701 cost = 0.026194411\n",
      "Validation Loss: 0.031716432\n",
      "Epoch: 3702 cost = 0.026193681\n",
      "Validation Loss: 0.04631686\n",
      "Epoch: 3703 cost = 0.026193007\n",
      "Validation Loss: 0.059469108\n",
      "Epoch: 3704 cost = 0.026192283\n",
      "Validation Loss: 0.102093406\n",
      "Epoch: 3705 cost = 0.026191577\n",
      "Validation Loss: 0.05714277\n",
      "Epoch: 3706 cost = 0.026190798\n",
      "Validation Loss: 0.036326412\n",
      "Epoch: 3707 cost = 0.026190150\n",
      "Validation Loss: 0.036119655\n",
      "Epoch: 3708 cost = 0.026189401\n",
      "Validation Loss: 0.04113484\n",
      "Epoch: 3709 cost = 0.026188655\n",
      "Validation Loss: 0.040740285\n",
      "Epoch: 3710 cost = 0.026187949\n",
      "Validation Loss: 0.040697046\n",
      "Epoch: 3711 cost = 0.026187241\n",
      "Validation Loss: 0.040789634\n",
      "Epoch: 3712 cost = 0.026186502\n",
      "Validation Loss: 0.038870554\n",
      "Epoch: 3713 cost = 0.026185830\n",
      "Validation Loss: 0.039407507\n",
      "Epoch: 3714 cost = 0.026185049\n",
      "Validation Loss: 0.035082743\n",
      "Epoch: 3715 cost = 0.026184359\n",
      "Validation Loss: 0.03384744\n",
      "Epoch: 3716 cost = 0.026183632\n",
      "Validation Loss: 0.037470598\n",
      "Epoch: 3717 cost = 0.026182947\n",
      "Validation Loss: 0.031252317\n",
      "Epoch: 3718 cost = 0.026182187\n",
      "Validation Loss: 0.03349163\n",
      "Epoch: 3719 cost = 0.026181571\n",
      "Validation Loss: 0.036047183\n",
      "Epoch: 3720 cost = 0.026180763\n",
      "Validation Loss: 0.04125055\n",
      "Epoch: 3721 cost = 0.026180101\n",
      "Validation Loss: 0.0713904\n",
      "Epoch: 3722 cost = 0.026179391\n",
      "Validation Loss: 0.11107112\n",
      "Epoch: 3723 cost = 0.026178695\n",
      "Validation Loss: 0.079357654\n",
      "Epoch: 3724 cost = 0.026177979\n",
      "Validation Loss: 0.042947277\n",
      "Epoch: 3725 cost = 0.026177250\n",
      "Validation Loss: 0.04183997\n",
      "Epoch: 3726 cost = 0.026176561\n",
      "Validation Loss: 0.031233372\n",
      "Epoch: 3727 cost = 0.026175842\n",
      "Validation Loss: 0.035880387\n",
      "Epoch: 3728 cost = 0.026175136\n",
      "Validation Loss: 0.054317374\n",
      "Epoch: 3729 cost = 0.026174447\n",
      "Validation Loss: 0.07862214\n",
      "Epoch: 3730 cost = 0.026173758\n",
      "Validation Loss: 0.076696776\n",
      "Epoch: 3731 cost = 0.026173073\n",
      "Validation Loss: 0.057685617\n",
      "Epoch: 3732 cost = 0.026172376\n",
      "Validation Loss: 0.04002396\n",
      "Epoch: 3733 cost = 0.026171654\n",
      "Validation Loss: 0.042450443\n",
      "Epoch: 3734 cost = 0.026170927\n",
      "Validation Loss: 0.04173551\n",
      "Epoch: 3735 cost = 0.026170271\n",
      "Validation Loss: 0.045824323\n",
      "Epoch: 3736 cost = 0.026169571\n",
      "Validation Loss: 0.047615327\n",
      "Epoch: 3737 cost = 0.026168847\n",
      "Validation Loss: 0.040988024\n",
      "Epoch: 3738 cost = 0.026168131\n",
      "Validation Loss: 0.03598476\n",
      "Epoch: 3739 cost = 0.026167462\n",
      "Validation Loss: 0.032268465\n",
      "Epoch: 3740 cost = 0.026166787\n",
      "Validation Loss: 0.031617887\n",
      "Epoch: 3741 cost = 0.026166005\n",
      "Validation Loss: 0.032559194\n",
      "Epoch: 3742 cost = 0.026165346\n",
      "Validation Loss: 0.03251041\n",
      "Epoch: 3743 cost = 0.026164668\n",
      "Validation Loss: 0.037300598\n",
      "Epoch: 3744 cost = 0.026163946\n",
      "Validation Loss: 0.040262006\n",
      "Epoch: 3745 cost = 0.026163307\n",
      "Validation Loss: 0.038838055\n",
      "Epoch: 3746 cost = 0.026162568\n",
      "Validation Loss: 0.03127577\n",
      "Epoch: 3747 cost = 0.026161891\n",
      "Validation Loss: 0.051304787\n",
      "Epoch: 3748 cost = 0.026161166\n",
      "Validation Loss: 0.0697965\n",
      "Epoch: 3749 cost = 0.026160481\n",
      "Validation Loss: 0.06068258\n",
      "Epoch: 3750 cost = 0.026159841\n",
      "Validation Loss: 0.03964408\n",
      "Epoch: 3751 cost = 0.026159124\n",
      "Validation Loss: 0.033937983\n",
      "Epoch: 3752 cost = 0.026158409\n",
      "Validation Loss: 0.035981152\n",
      "Epoch: 3753 cost = 0.026157776\n",
      "Validation Loss: 0.04010944\n",
      "Epoch: 3754 cost = 0.026157038\n",
      "Validation Loss: 0.035807677\n",
      "Epoch: 3755 cost = 0.026156364\n",
      "Validation Loss: 0.037187953\n",
      "Epoch: 3756 cost = 0.026155692\n",
      "Validation Loss: 0.03697093\n",
      "Epoch: 3757 cost = 0.026155001\n",
      "Validation Loss: 0.03628611\n",
      "Epoch: 3758 cost = 0.026154345\n",
      "Validation Loss: 0.03277553\n",
      "Epoch: 3759 cost = 0.026153649\n",
      "Validation Loss: 0.036035024\n",
      "Epoch: 3760 cost = 0.026152991\n",
      "Validation Loss: 0.037277702\n",
      "Epoch: 3761 cost = 0.026152249\n",
      "Validation Loss: 0.045845274\n",
      "Epoch: 3762 cost = 0.026151579\n",
      "Validation Loss: 0.049341105\n",
      "Epoch: 3763 cost = 0.026150931\n",
      "Validation Loss: 0.06271033\n",
      "Epoch: 3764 cost = 0.026150231\n",
      "Validation Loss: 0.06464289\n",
      "Epoch: 3765 cost = 0.026149540\n",
      "Validation Loss: 0.044744406\n",
      "Epoch: 3766 cost = 0.026148897\n",
      "Validation Loss: 0.03263781\n",
      "Epoch: 3767 cost = 0.026148214\n",
      "Validation Loss: 0.03595124\n",
      "Epoch: 3768 cost = 0.026147499\n",
      "Validation Loss: 0.037478168\n",
      "Epoch: 3769 cost = 0.026146830\n",
      "Validation Loss: 0.039648246\n",
      "Epoch: 3770 cost = 0.026146178\n",
      "Validation Loss: 0.036763288\n",
      "Epoch: 3771 cost = 0.026145493\n",
      "Validation Loss: 0.033773556\n",
      "Epoch: 3772 cost = 0.026144831\n",
      "Validation Loss: 0.033644747\n",
      "Epoch: 3773 cost = 0.026144129\n",
      "Validation Loss: 0.029780911\n",
      "Epoch: 3774 cost = 0.026143455\n",
      "Validation Loss: 0.032114286\n",
      "Epoch: 3775 cost = 0.026142775\n",
      "Validation Loss: 0.037014835\n",
      "Epoch: 3776 cost = 0.026142126\n",
      "Validation Loss: 0.039856993\n",
      "Epoch: 3777 cost = 0.026141425\n",
      "Validation Loss: 0.039667998\n",
      "Epoch: 3778 cost = 0.026140750\n",
      "Validation Loss: 0.039183397\n",
      "Epoch: 3779 cost = 0.026140122\n",
      "Validation Loss: 0.037657943\n",
      "Epoch: 3780 cost = 0.026139449\n",
      "Validation Loss: 0.0350846\n",
      "Epoch: 3781 cost = 0.026138775\n",
      "Validation Loss: 0.034007147\n",
      "Epoch: 3782 cost = 0.026138132\n",
      "Validation Loss: 0.03974723\n",
      "Epoch: 3783 cost = 0.026137439\n",
      "Validation Loss: 0.04155654\n",
      "Epoch: 3784 cost = 0.026136778\n",
      "Validation Loss: 0.04639291\n",
      "Epoch: 3785 cost = 0.026136151\n",
      "Validation Loss: 0.033638943\n",
      "Epoch: 3786 cost = 0.026135483\n",
      "Validation Loss: 0.03249368\n",
      "Epoch: 3787 cost = 0.026134788\n",
      "Validation Loss: 0.03856306\n",
      "Epoch: 3788 cost = 0.026134172\n",
      "Validation Loss: 0.039092183\n",
      "Epoch: 3789 cost = 0.026133495\n",
      "Validation Loss: 0.029656054\n",
      "Epoch: 3790 cost = 0.026132809\n",
      "Validation Loss: 0.032445703\n",
      "Epoch: 3791 cost = 0.026132176\n",
      "Validation Loss: 0.032851975\n",
      "Epoch: 3792 cost = 0.026131515\n",
      "Validation Loss: 0.06129121\n",
      "Epoch: 3793 cost = 0.026130817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04941354\n",
      "Epoch: 3794 cost = 0.026130189\n",
      "Validation Loss: 0.03706809\n",
      "Epoch: 3795 cost = 0.026129507\n",
      "Validation Loss: 0.037370685\n",
      "Epoch: 3796 cost = 0.026128858\n",
      "Validation Loss: 0.05515763\n",
      "Epoch: 3797 cost = 0.026128202\n",
      "Validation Loss: 0.051352\n",
      "Epoch: 3798 cost = 0.026127530\n",
      "Validation Loss: 0.05270506\n",
      "Epoch: 3799 cost = 0.026126908\n",
      "Validation Loss: 0.06114639\n",
      "Epoch: 3800 cost = 0.026126212\n",
      "Validation Loss: 0.040874165\n",
      "Epoch: 3801 cost = 0.026125621\n",
      "Validation Loss: 0.034539387\n",
      "Epoch: 3802 cost = 0.026124912\n",
      "Validation Loss: 0.03158935\n",
      "Epoch: 3803 cost = 0.026124262\n",
      "Validation Loss: 0.038787592\n",
      "Epoch: 3804 cost = 0.026123641\n",
      "Validation Loss: 0.03228067\n",
      "Epoch: 3805 cost = 0.026122961\n",
      "Validation Loss: 0.03126877\n",
      "Epoch: 3806 cost = 0.026122279\n",
      "Validation Loss: 0.03585162\n",
      "Epoch: 3807 cost = 0.026121702\n",
      "Validation Loss: 0.03449402\n",
      "Epoch: 3808 cost = 0.026121024\n",
      "Validation Loss: 0.03864806\n",
      "Epoch: 3809 cost = 0.026120364\n",
      "Validation Loss: 0.03272562\n",
      "Epoch: 3810 cost = 0.026119768\n",
      "Validation Loss: 0.033858687\n",
      "Epoch: 3811 cost = 0.026119089\n",
      "Validation Loss: 0.033154577\n",
      "Epoch: 3812 cost = 0.026118435\n",
      "Validation Loss: 0.038167622\n",
      "Epoch: 3813 cost = 0.026117824\n",
      "Validation Loss: 0.038796805\n",
      "Epoch: 3814 cost = 0.026117118\n",
      "Validation Loss: 0.042215\n",
      "Epoch: 3815 cost = 0.026116471\n",
      "Validation Loss: 0.047153216\n",
      "Epoch: 3816 cost = 0.026115842\n",
      "Validation Loss: 0.038410075\n",
      "Epoch: 3817 cost = 0.026115210\n",
      "Validation Loss: 0.044654176\n",
      "Epoch: 3818 cost = 0.026114567\n",
      "Validation Loss: 0.06708192\n",
      "Epoch: 3819 cost = 0.026113937\n",
      "Validation Loss: 0.07160621\n",
      "Epoch: 3820 cost = 0.026113327\n",
      "Validation Loss: 0.039626196\n",
      "Epoch: 3821 cost = 0.026112643\n",
      "Validation Loss: 0.032055724\n",
      "Epoch: 3822 cost = 0.026112033\n",
      "Validation Loss: 0.03246173\n",
      "Epoch: 3823 cost = 0.026111410\n",
      "Validation Loss: 0.029671405\n",
      "Epoch: 3824 cost = 0.026110741\n",
      "Validation Loss: 0.029898014\n",
      "Epoch: 3825 cost = 0.026110084\n",
      "Validation Loss: 0.028054442\n",
      "Epoch: 3826 cost = 0.026109468\n",
      "Validation Loss: 0.04498203\n",
      "Epoch: 3827 cost = 0.026108807\n",
      "Validation Loss: 0.056407508\n",
      "Epoch: 3828 cost = 0.026108204\n",
      "Validation Loss: 0.043202806\n",
      "Epoch: 3829 cost = 0.026107550\n",
      "Validation Loss: 0.041616105\n",
      "Epoch: 3830 cost = 0.026106911\n",
      "Validation Loss: 0.03707766\n",
      "Epoch: 3831 cost = 0.026106289\n",
      "Validation Loss: 0.040369898\n",
      "Epoch: 3832 cost = 0.026105679\n",
      "Validation Loss: 0.04065021\n",
      "Epoch: 3833 cost = 0.026105102\n",
      "Validation Loss: 0.04371429\n",
      "Epoch: 3834 cost = 0.026104402\n",
      "Validation Loss: 0.044241983\n",
      "Epoch: 3835 cost = 0.026103787\n",
      "Validation Loss: 0.038441334\n",
      "Epoch: 3836 cost = 0.026103164\n",
      "Validation Loss: 0.039309494\n",
      "Epoch: 3837 cost = 0.026102524\n",
      "Validation Loss: 0.03819581\n",
      "Epoch: 3838 cost = 0.026101933\n",
      "Validation Loss: 0.032638784\n",
      "Epoch: 3839 cost = 0.026101310\n",
      "Validation Loss: 0.03132043\n",
      "Epoch: 3840 cost = 0.026100620\n",
      "Validation Loss: 0.02958628\n",
      "Epoch: 3841 cost = 0.026100017\n",
      "Validation Loss: 0.030180233\n",
      "Epoch: 3842 cost = 0.026099366\n",
      "Validation Loss: 0.034592494\n",
      "Epoch: 3843 cost = 0.026098794\n",
      "Validation Loss: 0.03617245\n",
      "Epoch: 3844 cost = 0.026098145\n",
      "Validation Loss: 0.03735721\n",
      "Epoch: 3845 cost = 0.026097519\n",
      "Validation Loss: 0.035210792\n",
      "Epoch: 3846 cost = 0.026096908\n",
      "Validation Loss: 0.033135127\n",
      "Epoch: 3847 cost = 0.026096284\n",
      "Validation Loss: 0.032401234\n",
      "Epoch: 3848 cost = 0.026095653\n",
      "Validation Loss: 0.033108536\n",
      "Epoch: 3849 cost = 0.026095011\n",
      "Validation Loss: 0.03546453\n",
      "Epoch: 3850 cost = 0.026094410\n",
      "Validation Loss: 0.033018027\n",
      "Epoch: 3851 cost = 0.026093827\n",
      "Validation Loss: 0.032978754\n",
      "Epoch: 3852 cost = 0.026093193\n",
      "Validation Loss: 0.03231449\n",
      "Epoch: 3853 cost = 0.026092560\n",
      "Validation Loss: 0.036195662\n",
      "Epoch: 3854 cost = 0.026091926\n",
      "Validation Loss: 0.039165318\n",
      "Epoch: 3855 cost = 0.026091320\n",
      "Validation Loss: 0.038826615\n",
      "Epoch: 3856 cost = 0.026090740\n",
      "Validation Loss: 0.03792496\n",
      "Epoch: 3857 cost = 0.026090102\n",
      "Validation Loss: 0.037198182\n",
      "Epoch: 3858 cost = 0.026089499\n",
      "Validation Loss: 0.037304163\n",
      "Epoch: 3859 cost = 0.026088918\n",
      "Validation Loss: 0.03697091\n",
      "Epoch: 3860 cost = 0.026088263\n",
      "Validation Loss: 0.03703657\n",
      "Epoch: 3861 cost = 0.026087660\n",
      "Validation Loss: 0.03678439\n",
      "Epoch: 3862 cost = 0.026087068\n",
      "Validation Loss: 0.034342106\n",
      "Epoch: 3863 cost = 0.026086468\n",
      "Validation Loss: 0.03398473\n",
      "Epoch: 3864 cost = 0.026085855\n",
      "Validation Loss: 0.030567471\n",
      "Epoch: 3865 cost = 0.026085279\n",
      "Validation Loss: 0.035214297\n",
      "Epoch: 3866 cost = 0.026084595\n",
      "Validation Loss: 0.0323127\n",
      "Epoch: 3867 cost = 0.026084070\n",
      "Validation Loss: 0.032326184\n",
      "Epoch: 3868 cost = 0.026083427\n",
      "Validation Loss: 0.032150097\n",
      "Epoch: 3869 cost = 0.026082807\n",
      "Validation Loss: 0.031003019\n",
      "Epoch: 3870 cost = 0.026082218\n",
      "Validation Loss: 0.03705992\n",
      "Epoch: 3871 cost = 0.026081577\n",
      "Validation Loss: 0.057753246\n",
      "Epoch: 3872 cost = 0.026080985\n",
      "Validation Loss: 0.06451388\n",
      "Epoch: 3873 cost = 0.026080384\n",
      "Validation Loss: 0.06718437\n",
      "Epoch: 3874 cost = 0.026079761\n",
      "Validation Loss: 0.05290355\n",
      "Epoch: 3875 cost = 0.026079196\n",
      "Validation Loss: 0.048341278\n",
      "Epoch: 3876 cost = 0.026078543\n",
      "Validation Loss: 0.060025465\n",
      "Epoch: 3877 cost = 0.026077941\n",
      "Validation Loss: 0.044867147\n",
      "Epoch: 3878 cost = 0.026077342\n",
      "Validation Loss: 0.03919891\n",
      "Epoch: 3879 cost = 0.026076778\n",
      "Validation Loss: 0.042463142\n",
      "Epoch: 3880 cost = 0.026076194\n",
      "Validation Loss: 0.04681159\n",
      "Epoch: 3881 cost = 0.026075573\n",
      "Validation Loss: 0.06351586\n",
      "Epoch: 3882 cost = 0.026074970\n",
      "Validation Loss: 0.070900775\n",
      "Epoch: 3883 cost = 0.026074407\n",
      "Validation Loss: 0.045617834\n",
      "Epoch: 3884 cost = 0.026073823\n",
      "Validation Loss: 0.04830409\n",
      "Epoch: 3885 cost = 0.026073220\n",
      "Validation Loss: 0.05246133\n",
      "Epoch: 3886 cost = 0.026072669\n",
      "Validation Loss: 0.047308873\n",
      "Epoch: 3887 cost = 0.026072011\n",
      "Validation Loss: 0.037226263\n",
      "Epoch: 3888 cost = 0.026071452\n",
      "Validation Loss: 0.04389064\n",
      "Epoch: 3889 cost = 0.026070860\n",
      "Validation Loss: 0.04846414\n",
      "Epoch: 3890 cost = 0.026070246\n",
      "Validation Loss: 0.076750614\n",
      "Epoch: 3891 cost = 0.026069724\n",
      "Validation Loss: 0.05729037\n",
      "Epoch: 3892 cost = 0.026069063\n",
      "Validation Loss: 0.05709241\n",
      "Epoch: 3893 cost = 0.026068444\n",
      "Validation Loss: 0.064572945\n",
      "Epoch: 3894 cost = 0.026067879\n",
      "Validation Loss: 0.062218\n",
      "Epoch: 3895 cost = 0.026067286\n",
      "Validation Loss: 0.0410267\n",
      "Epoch: 3896 cost = 0.026066696\n",
      "Validation Loss: 0.03237393\n",
      "Epoch: 3897 cost = 0.026066159\n",
      "Validation Loss: 0.03443357\n",
      "Epoch: 3898 cost = 0.026065564\n",
      "Validation Loss: 0.030599512\n",
      "Epoch: 3899 cost = 0.026065014\n",
      "Validation Loss: 0.039255764\n",
      "Epoch: 3900 cost = 0.026064331\n",
      "Validation Loss: 0.03819945\n",
      "Epoch: 3901 cost = 0.026063807\n",
      "Validation Loss: 0.03270721\n",
      "Epoch: 3902 cost = 0.026063193\n",
      "Validation Loss: 0.03259487\n",
      "Epoch: 3903 cost = 0.026062610\n",
      "Validation Loss: 0.03227344\n",
      "Epoch: 3904 cost = 0.026062023\n",
      "Validation Loss: 0.03210018\n",
      "Epoch: 3905 cost = 0.026061435\n",
      "Validation Loss: 0.0516391\n",
      "Epoch: 3906 cost = 0.026060896\n",
      "Validation Loss: 0.046609297\n",
      "Epoch: 3907 cost = 0.026060321\n",
      "Validation Loss: 0.049439177\n",
      "Epoch: 3908 cost = 0.026059759\n",
      "Validation Loss: 0.043637555\n",
      "Epoch: 3909 cost = 0.026059194\n",
      "Validation Loss: 0.031535912\n",
      "Epoch: 3910 cost = 0.026058554\n",
      "Validation Loss: 0.030094068\n",
      "Epoch: 3911 cost = 0.026058018\n",
      "Validation Loss: 0.032606296\n",
      "Epoch: 3912 cost = 0.026057355\n",
      "Validation Loss: 0.03415951\n",
      "Epoch: 3913 cost = 0.026056832\n",
      "Validation Loss: 0.036165416\n",
      "Epoch: 3914 cost = 0.026056249\n",
      "Validation Loss: 0.03594069\n",
      "Epoch: 3915 cost = 0.026055644\n",
      "Validation Loss: 0.034379914\n",
      "Epoch: 3916 cost = 0.026055101\n",
      "Validation Loss: 0.03505965\n",
      "Epoch: 3917 cost = 0.026054522\n",
      "Validation Loss: 0.033319388\n",
      "Epoch: 3918 cost = 0.026054008\n",
      "Validation Loss: 0.03521026\n",
      "Epoch: 3919 cost = 0.026053392\n",
      "Validation Loss: 0.03565235\n",
      "Epoch: 3920 cost = 0.026052869\n",
      "Validation Loss: 0.03631212\n",
      "Epoch: 3921 cost = 0.026052296\n",
      "Validation Loss: 0.03652163\n",
      "Epoch: 3922 cost = 0.026051685\n",
      "Validation Loss: 0.041611068\n",
      "Epoch: 3923 cost = 0.026051098\n",
      "Validation Loss: 0.038766064\n",
      "Epoch: 3924 cost = 0.026050530\n",
      "Validation Loss: 0.03461848\n",
      "Epoch: 3925 cost = 0.026050023\n",
      "Validation Loss: 0.0420473\n",
      "Epoch: 3926 cost = 0.026049404\n",
      "Validation Loss: 0.042563066\n",
      "Epoch: 3927 cost = 0.026048862\n",
      "Validation Loss: 0.032216515\n",
      "Epoch: 3928 cost = 0.026048280\n",
      "Validation Loss: 0.031185413\n",
      "Epoch: 3929 cost = 0.026047720\n",
      "Validation Loss: 0.031354796\n",
      "Epoch: 3930 cost = 0.026047216\n",
      "Validation Loss: 0.033026803\n",
      "Epoch: 3931 cost = 0.026046590\n",
      "Validation Loss: 0.036956\n",
      "Epoch: 3932 cost = 0.026046067\n",
      "Validation Loss: 0.042250954\n",
      "Epoch: 3933 cost = 0.026045461\n",
      "Validation Loss: 0.03769304\n",
      "Epoch: 3934 cost = 0.026044894\n",
      "Validation Loss: 0.053295076\n",
      "Epoch: 3935 cost = 0.026044358\n",
      "Validation Loss: 0.042981975\n",
      "Epoch: 3936 cost = 0.026043825\n",
      "Validation Loss: 0.040685702\n",
      "Epoch: 3937 cost = 0.026043248\n",
      "Validation Loss: 0.036319602\n",
      "Epoch: 3938 cost = 0.026042628\n",
      "Validation Loss: 0.035356387\n",
      "Epoch: 3939 cost = 0.026042104\n",
      "Validation Loss: 0.03466196\n",
      "Epoch: 3940 cost = 0.026041532\n",
      "Validation Loss: 0.030509071\n",
      "Epoch: 3941 cost = 0.026040961\n",
      "Validation Loss: 0.04733567\n",
      "Epoch: 3942 cost = 0.026040405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.102101654\n",
      "Epoch: 3943 cost = 0.026039887\n",
      "Validation Loss: 0.073768996\n",
      "Epoch: 3944 cost = 0.026039294\n",
      "Validation Loss: 0.06894997\n",
      "Epoch: 3945 cost = 0.026038752\n",
      "Validation Loss: 0.056375753\n",
      "Epoch: 3946 cost = 0.026038211\n",
      "Validation Loss: 0.048733216\n",
      "Epoch: 3947 cost = 0.026037588\n",
      "Validation Loss: 0.041658875\n",
      "Epoch: 3948 cost = 0.026037094\n",
      "Validation Loss: 0.03572863\n",
      "Epoch: 3949 cost = 0.026036561\n",
      "Validation Loss: 0.03454284\n",
      "Epoch: 3950 cost = 0.026035939\n",
      "Validation Loss: 0.03260439\n",
      "Epoch: 3951 cost = 0.026035428\n",
      "Validation Loss: 0.039247524\n",
      "Epoch: 3952 cost = 0.026034894\n",
      "Validation Loss: 0.03255379\n",
      "Epoch: 3953 cost = 0.026034356\n",
      "Validation Loss: 0.035427444\n",
      "Epoch: 3954 cost = 0.026033781\n",
      "Validation Loss: 0.033090003\n",
      "Epoch: 3955 cost = 0.026033212\n",
      "Validation Loss: 0.040037386\n",
      "Epoch: 3956 cost = 0.026032677\n",
      "Validation Loss: 0.037608523\n",
      "Epoch: 3957 cost = 0.026032148\n",
      "Validation Loss: 0.043769132\n",
      "Epoch: 3958 cost = 0.026031622\n",
      "Validation Loss: 0.034510776\n",
      "Epoch: 3959 cost = 0.026031079\n",
      "Validation Loss: 0.03255083\n",
      "Epoch: 3960 cost = 0.026030445\n",
      "Validation Loss: 0.034756925\n",
      "Epoch: 3961 cost = 0.026029936\n",
      "Validation Loss: 0.032491572\n",
      "Epoch: 3962 cost = 0.026029415\n",
      "Validation Loss: 0.030631121\n",
      "Epoch: 3963 cost = 0.026028874\n",
      "Validation Loss: 0.03854635\n",
      "Epoch: 3964 cost = 0.026028293\n",
      "Validation Loss: 0.05246549\n",
      "Epoch: 3965 cost = 0.026027794\n",
      "Validation Loss: 0.032876313\n",
      "Epoch: 3966 cost = 0.026027226\n",
      "Validation Loss: 0.034554474\n",
      "Epoch: 3967 cost = 0.026026710\n",
      "Validation Loss: 0.029229354\n",
      "Epoch: 3968 cost = 0.026026230\n",
      "Validation Loss: 0.035566315\n",
      "Epoch: 3969 cost = 0.026025629\n",
      "Validation Loss: 0.032523204\n",
      "Epoch: 3970 cost = 0.026025106\n",
      "Validation Loss: 0.03296449\n",
      "Epoch: 3971 cost = 0.026024500\n",
      "Validation Loss: 0.042499866\n",
      "Epoch: 3972 cost = 0.026023959\n",
      "Validation Loss: 0.09042922\n",
      "Epoch: 3973 cost = 0.026023485\n",
      "Validation Loss: 0.08911673\n",
      "Epoch: 3974 cost = 0.026022937\n",
      "Validation Loss: 0.04986068\n",
      "Epoch: 3975 cost = 0.026022375\n",
      "Validation Loss: 0.03735259\n",
      "Epoch: 3976 cost = 0.026021854\n",
      "Validation Loss: 0.0337881\n",
      "Epoch: 3977 cost = 0.026021300\n",
      "Validation Loss: 0.046441372\n",
      "Epoch: 3978 cost = 0.026020771\n",
      "Validation Loss: 0.047434624\n",
      "Epoch: 3979 cost = 0.026020240\n",
      "Validation Loss: 0.05591178\n",
      "Epoch: 3980 cost = 0.026019767\n",
      "Validation Loss: 0.037943147\n",
      "Epoch: 3981 cost = 0.026019163\n",
      "Validation Loss: 0.038957495\n",
      "Epoch: 3982 cost = 0.026018644\n",
      "Validation Loss: 0.038482547\n",
      "Epoch: 3983 cost = 0.026018099\n",
      "Validation Loss: 0.04089293\n",
      "Epoch: 3984 cost = 0.026017543\n",
      "Validation Loss: 0.03388307\n",
      "Epoch: 3985 cost = 0.026017055\n",
      "Validation Loss: 0.035652366\n",
      "Epoch: 3986 cost = 0.026016518\n",
      "Validation Loss: 0.049722686\n",
      "Epoch: 3987 cost = 0.026015987\n",
      "Validation Loss: 0.034552105\n",
      "Epoch: 3988 cost = 0.026015448\n",
      "Validation Loss: 0.04744499\n",
      "Epoch: 3989 cost = 0.026014914\n",
      "Validation Loss: 0.061035104\n",
      "Epoch: 3990 cost = 0.026014384\n",
      "Validation Loss: 0.05032737\n",
      "Epoch: 3991 cost = 0.026013827\n",
      "Validation Loss: 0.048831087\n",
      "Epoch: 3992 cost = 0.026013284\n",
      "Validation Loss: 0.08761265\n",
      "Epoch: 3993 cost = 0.026012804\n",
      "Validation Loss: 0.11005187\n",
      "Epoch: 3994 cost = 0.026012298\n",
      "Validation Loss: 0.07415022\n",
      "Epoch: 3995 cost = 0.026011784\n",
      "Validation Loss: 0.081172004\n",
      "Epoch: 3996 cost = 0.026011257\n",
      "Validation Loss: 0.05391887\n",
      "Epoch: 3997 cost = 0.026010714\n",
      "Validation Loss: 0.03521978\n",
      "Epoch: 3998 cost = 0.026010152\n",
      "Validation Loss: 0.03610537\n",
      "Epoch: 3999 cost = 0.026009642\n",
      "Validation Loss: 0.03943755\n",
      "Epoch: 4000 cost = 0.026009174\n",
      "Validation Loss: 0.039300736\n",
      "Epoch: 4001 cost = 0.026008634\n",
      "Validation Loss: 0.041804906\n",
      "Epoch: 4002 cost = 0.026008072\n",
      "Validation Loss: 0.03879227\n",
      "Epoch: 4003 cost = 0.026007575\n",
      "Validation Loss: 0.035335228\n",
      "Epoch: 4004 cost = 0.026007017\n",
      "Validation Loss: 0.03750772\n",
      "Epoch: 4005 cost = 0.026006568\n",
      "Validation Loss: 0.038981114\n",
      "Epoch: 4006 cost = 0.026006008\n",
      "Validation Loss: 0.051536094\n",
      "Epoch: 4007 cost = 0.026005520\n",
      "Validation Loss: 0.034392245\n",
      "Epoch: 4008 cost = 0.026005003\n",
      "Validation Loss: 0.041764215\n",
      "Epoch: 4009 cost = 0.026004476\n",
      "Validation Loss: 0.037379015\n",
      "Epoch: 4010 cost = 0.026003942\n",
      "Validation Loss: 0.04411839\n",
      "Epoch: 4011 cost = 0.026003468\n",
      "Validation Loss: 0.05934002\n",
      "Epoch: 4012 cost = 0.026002956\n",
      "Validation Loss: 0.06470151\n",
      "Epoch: 4013 cost = 0.026002408\n",
      "Validation Loss: 0.05630185\n",
      "Epoch: 4014 cost = 0.026001866\n",
      "Validation Loss: 0.08365522\n",
      "Epoch: 4015 cost = 0.026001395\n",
      "Validation Loss: 0.05780232\n",
      "Epoch: 4016 cost = 0.026000867\n",
      "Validation Loss: 0.046077907\n",
      "Epoch: 4017 cost = 0.026000294\n",
      "Validation Loss: 0.045558672\n",
      "Epoch: 4018 cost = 0.025999823\n",
      "Validation Loss: 0.059199754\n",
      "Epoch: 4019 cost = 0.025999305\n",
      "Validation Loss: 0.06580355\n",
      "Epoch: 4020 cost = 0.025998795\n",
      "Validation Loss: 0.047156617\n",
      "Epoch: 4021 cost = 0.025998294\n",
      "Validation Loss: 0.046985134\n",
      "Epoch: 4022 cost = 0.025997761\n",
      "Validation Loss: 0.050531555\n",
      "Epoch: 4023 cost = 0.025997327\n",
      "Validation Loss: 0.037516844\n",
      "Epoch: 4024 cost = 0.025996773\n",
      "Validation Loss: 0.035468888\n",
      "Epoch: 4025 cost = 0.025996247\n",
      "Validation Loss: 0.036582343\n",
      "Epoch: 4026 cost = 0.025995754\n",
      "Validation Loss: 0.03294241\n",
      "Epoch: 4027 cost = 0.025995246\n",
      "Validation Loss: 0.037228625\n",
      "Epoch: 4028 cost = 0.025994775\n",
      "Validation Loss: 0.033744264\n",
      "Epoch: 4029 cost = 0.025994273\n",
      "Validation Loss: 0.036022637\n",
      "Epoch: 4030 cost = 0.025993757\n",
      "Validation Loss: 0.03436602\n",
      "Epoch: 4031 cost = 0.025993163\n",
      "Validation Loss: 0.031008027\n",
      "Epoch: 4032 cost = 0.025992706\n",
      "Validation Loss: 0.03390773\n",
      "Epoch: 4033 cost = 0.025992218\n",
      "Validation Loss: 0.050553538\n",
      "Epoch: 4034 cost = 0.025991653\n",
      "Validation Loss: 0.050818823\n",
      "Epoch: 4035 cost = 0.025991161\n",
      "Validation Loss: 0.03539884\n",
      "Epoch: 4036 cost = 0.025990699\n",
      "Validation Loss: 0.03790344\n",
      "Epoch: 4037 cost = 0.025990173\n",
      "Validation Loss: 0.038789716\n",
      "Epoch: 4038 cost = 0.025989702\n",
      "Validation Loss: 0.043082416\n",
      "Epoch: 4039 cost = 0.025989212\n",
      "Validation Loss: 0.04004385\n",
      "Epoch: 4040 cost = 0.025988726\n",
      "Validation Loss: 0.03464468\n",
      "Epoch: 4041 cost = 0.025988220\n",
      "Validation Loss: 0.03218237\n",
      "Epoch: 4042 cost = 0.025987652\n",
      "Validation Loss: 0.035186738\n",
      "Epoch: 4043 cost = 0.025987185\n",
      "Validation Loss: 0.039075475\n",
      "Epoch: 4044 cost = 0.025986667\n",
      "Validation Loss: 0.046110775\n",
      "Epoch: 4045 cost = 0.025986214\n",
      "Validation Loss: 0.06913847\n",
      "Epoch: 4046 cost = 0.025985662\n",
      "Validation Loss: 0.06762722\n",
      "Epoch: 4047 cost = 0.025985225\n",
      "Validation Loss: 0.05795311\n",
      "Epoch: 4048 cost = 0.025984697\n",
      "Validation Loss: 0.03654215\n",
      "Epoch: 4049 cost = 0.025984190\n",
      "Validation Loss: 0.033105735\n",
      "Epoch: 4050 cost = 0.025983711\n",
      "Validation Loss: 0.03061216\n",
      "Epoch: 4051 cost = 0.025983232\n",
      "Validation Loss: 0.036017127\n",
      "Epoch: 4052 cost = 0.025982704\n",
      "Validation Loss: 0.040224176\n",
      "Epoch: 4053 cost = 0.025982216\n",
      "Validation Loss: 0.040357217\n",
      "Epoch: 4054 cost = 0.025981750\n",
      "Validation Loss: 0.034148365\n",
      "Epoch: 4055 cost = 0.025981227\n",
      "Validation Loss: 0.034682173\n",
      "Epoch: 4056 cost = 0.025980714\n",
      "Validation Loss: 0.03633098\n",
      "Epoch: 4057 cost = 0.025980255\n",
      "Validation Loss: 0.037116066\n",
      "Epoch: 4058 cost = 0.025979741\n",
      "Validation Loss: 0.086935185\n",
      "Epoch: 4059 cost = 0.025979294\n",
      "Validation Loss: 0.06651931\n",
      "Epoch: 4060 cost = 0.025978816\n",
      "Validation Loss: 0.032353137\n",
      "Epoch: 4061 cost = 0.025978295\n",
      "Validation Loss: 0.037598472\n",
      "Epoch: 4062 cost = 0.025977812\n",
      "Validation Loss: 0.03815098\n",
      "Epoch: 4063 cost = 0.025977332\n",
      "Validation Loss: 0.034618434\n",
      "Epoch: 4064 cost = 0.025976818\n",
      "Validation Loss: 0.03107761\n",
      "Epoch: 4065 cost = 0.025976364\n",
      "Validation Loss: 0.03263481\n",
      "Epoch: 4066 cost = 0.025975862\n",
      "Validation Loss: 0.034842856\n",
      "Epoch: 4067 cost = 0.025975345\n",
      "Validation Loss: 0.03139039\n",
      "Epoch: 4068 cost = 0.025974895\n",
      "Validation Loss: 0.037458245\n",
      "Epoch: 4069 cost = 0.025974434\n",
      "Validation Loss: 0.060977712\n",
      "Epoch: 4070 cost = 0.025973898\n",
      "Validation Loss: 0.040844455\n",
      "Epoch: 4071 cost = 0.025973405\n",
      "Validation Loss: 0.039854687\n",
      "Epoch: 4072 cost = 0.025972938\n",
      "Validation Loss: 0.038307615\n",
      "Epoch: 4073 cost = 0.025972486\n",
      "Validation Loss: 0.03671245\n",
      "Epoch: 4074 cost = 0.025971988\n",
      "Validation Loss: 0.041214146\n",
      "Epoch: 4075 cost = 0.025971458\n",
      "Validation Loss: 0.039499063\n",
      "Epoch: 4076 cost = 0.025971045\n",
      "Validation Loss: 0.03588621\n",
      "Epoch: 4077 cost = 0.025970527\n",
      "Validation Loss: 0.036779366\n",
      "Epoch: 4078 cost = 0.025970039\n",
      "Validation Loss: 0.03472364\n",
      "Epoch: 4079 cost = 0.025969595\n",
      "Validation Loss: 0.0367295\n",
      "Epoch: 4080 cost = 0.025969053\n",
      "Validation Loss: 0.05181486\n",
      "Epoch: 4081 cost = 0.025968625\n",
      "Validation Loss: 0.041974787\n",
      "Epoch: 4082 cost = 0.025968193\n",
      "Validation Loss: 0.04321391\n",
      "Epoch: 4083 cost = 0.025967656\n",
      "Validation Loss: 0.036501564\n",
      "Epoch: 4084 cost = 0.025967168\n",
      "Validation Loss: 0.03495771\n",
      "Epoch: 4085 cost = 0.025966705\n",
      "Validation Loss: 0.03353594\n",
      "Epoch: 4086 cost = 0.025966181\n",
      "Validation Loss: 0.03852666\n",
      "Epoch: 4087 cost = 0.025965723\n",
      "Validation Loss: 0.0521569\n",
      "Epoch: 4088 cost = 0.025965257\n",
      "Validation Loss: 0.045075584\n",
      "Epoch: 4089 cost = 0.025964742\n",
      "Validation Loss: 0.03792189\n",
      "Epoch: 4090 cost = 0.025964278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.039406035\n",
      "Epoch: 4091 cost = 0.025963822\n",
      "Validation Loss: 0.035155904\n",
      "Epoch: 4092 cost = 0.025963351\n",
      "Validation Loss: 0.046229895\n",
      "Epoch: 4093 cost = 0.025962839\n",
      "Validation Loss: 0.036804628\n",
      "Epoch: 4094 cost = 0.025962359\n",
      "Validation Loss: 0.031915136\n",
      "Epoch: 4095 cost = 0.025961899\n",
      "Validation Loss: 0.03612842\n",
      "Epoch: 4096 cost = 0.025961426\n",
      "Validation Loss: 0.031023001\n",
      "Epoch: 4097 cost = 0.025960954\n",
      "Validation Loss: 0.04522252\n",
      "Epoch: 4098 cost = 0.025960477\n",
      "Validation Loss: 0.046154156\n",
      "Epoch: 4099 cost = 0.025960049\n",
      "Validation Loss: 0.03842892\n",
      "Epoch: 4100 cost = 0.025959514\n",
      "Validation Loss: 0.029937718\n",
      "Epoch: 4101 cost = 0.025959084\n",
      "Validation Loss: 0.029767033\n",
      "Epoch: 4102 cost = 0.025958563\n",
      "Validation Loss: 0.04766981\n",
      "Epoch: 4103 cost = 0.025958109\n",
      "Validation Loss: 0.040436927\n",
      "Epoch: 4104 cost = 0.025957694\n",
      "Validation Loss: 0.03662512\n",
      "Epoch: 4105 cost = 0.025957213\n",
      "Validation Loss: 0.03358376\n",
      "Epoch: 4106 cost = 0.025956661\n",
      "Validation Loss: 0.03726311\n",
      "Epoch: 4107 cost = 0.025956306\n",
      "Validation Loss: 0.038665894\n",
      "Epoch: 4108 cost = 0.025955759\n",
      "Validation Loss: 0.03863863\n",
      "Epoch: 4109 cost = 0.025955341\n",
      "Validation Loss: 0.03920749\n",
      "Epoch: 4110 cost = 0.025954847\n",
      "Validation Loss: 0.03935041\n",
      "Epoch: 4111 cost = 0.025954408\n",
      "Validation Loss: 0.037659593\n",
      "Epoch: 4112 cost = 0.025953926\n",
      "Validation Loss: 0.036563884\n",
      "Epoch: 4113 cost = 0.025953485\n",
      "Validation Loss: 0.03338199\n",
      "Epoch: 4114 cost = 0.025952995\n",
      "Validation Loss: 0.03079875\n",
      "Epoch: 4115 cost = 0.025952527\n",
      "Validation Loss: 0.033906627\n",
      "Epoch: 4116 cost = 0.025952008\n",
      "Validation Loss: 0.031457268\n",
      "Epoch: 4117 cost = 0.025951639\n",
      "Validation Loss: 0.035350498\n",
      "Epoch: 4118 cost = 0.025951145\n",
      "Validation Loss: 0.032843255\n",
      "Epoch: 4119 cost = 0.025950746\n",
      "Validation Loss: 0.03075572\n",
      "Epoch: 4120 cost = 0.025950177\n",
      "Validation Loss: 0.03215174\n",
      "Epoch: 4121 cost = 0.025949771\n",
      "Validation Loss: 0.032042973\n",
      "Epoch: 4122 cost = 0.025949306\n",
      "Validation Loss: 0.03388965\n",
      "Epoch: 4123 cost = 0.025948855\n",
      "Validation Loss: 0.03151252\n",
      "Epoch: 4124 cost = 0.025948385\n",
      "Validation Loss: 0.036503445\n",
      "Epoch: 4125 cost = 0.025947935\n",
      "Validation Loss: 0.034084544\n",
      "Epoch: 4126 cost = 0.025947450\n",
      "Validation Loss: 0.03251126\n",
      "Epoch: 4127 cost = 0.025946994\n",
      "Validation Loss: 0.032995034\n",
      "Epoch: 4128 cost = 0.025946576\n",
      "Validation Loss: 0.03343081\n",
      "Epoch: 4129 cost = 0.025946091\n",
      "Validation Loss: 0.034089617\n",
      "Epoch: 4130 cost = 0.025945657\n",
      "Validation Loss: 0.03291272\n",
      "Epoch: 4131 cost = 0.025945133\n",
      "Validation Loss: 0.033671837\n",
      "Epoch: 4132 cost = 0.025944700\n",
      "Validation Loss: 0.034636576\n",
      "Epoch: 4133 cost = 0.025944260\n",
      "Validation Loss: 0.049506668\n",
      "Epoch: 4134 cost = 0.025943786\n",
      "Validation Loss: 0.034984533\n",
      "Epoch: 4135 cost = 0.025943385\n",
      "Validation Loss: 0.035726186\n",
      "Epoch: 4136 cost = 0.025942847\n",
      "Validation Loss: 0.03689144\n",
      "Epoch: 4137 cost = 0.025942425\n",
      "Validation Loss: 0.037818782\n",
      "Epoch: 4138 cost = 0.025941963\n",
      "Validation Loss: 0.035360307\n",
      "Epoch: 4139 cost = 0.025941523\n",
      "Validation Loss: 0.034106664\n",
      "Epoch: 4140 cost = 0.025941089\n",
      "Validation Loss: 0.03411642\n",
      "Epoch: 4141 cost = 0.025940627\n",
      "Validation Loss: 0.033421066\n",
      "Epoch: 4142 cost = 0.025940123\n",
      "Validation Loss: 0.043968912\n",
      "Epoch: 4143 cost = 0.025939676\n",
      "Validation Loss: 0.057764724\n",
      "Epoch: 4144 cost = 0.025939239\n",
      "Validation Loss: 0.049479835\n",
      "Epoch: 4145 cost = 0.025938775\n",
      "Validation Loss: 0.030737977\n",
      "Epoch: 4146 cost = 0.025938345\n",
      "Validation Loss: 0.034118935\n",
      "Epoch: 4147 cost = 0.025937904\n",
      "Validation Loss: 0.03727109\n",
      "Epoch: 4148 cost = 0.025937426\n",
      "Validation Loss: 0.037371032\n",
      "Epoch: 4149 cost = 0.025937003\n",
      "Validation Loss: 0.040227946\n",
      "Epoch: 4150 cost = 0.025936537\n",
      "Validation Loss: 0.05090697\n",
      "Epoch: 4151 cost = 0.025936113\n",
      "Validation Loss: 0.037749283\n",
      "Epoch: 4152 cost = 0.025935633\n",
      "Validation Loss: 0.039157074\n",
      "Epoch: 4153 cost = 0.025935189\n",
      "Validation Loss: 0.037026133\n",
      "Epoch: 4154 cost = 0.025934722\n",
      "Validation Loss: 0.035169113\n",
      "Epoch: 4155 cost = 0.025934292\n",
      "Validation Loss: 0.03741099\n",
      "Epoch: 4156 cost = 0.025933835\n",
      "Validation Loss: 0.032630697\n",
      "Epoch: 4157 cost = 0.025933398\n",
      "Validation Loss: 0.029837541\n",
      "Epoch: 4158 cost = 0.025932951\n",
      "Validation Loss: 0.034568597\n",
      "Epoch: 4159 cost = 0.025932474\n",
      "Validation Loss: 0.035499237\n",
      "Epoch: 4160 cost = 0.025932039\n",
      "Validation Loss: 0.03505065\n",
      "Epoch: 4161 cost = 0.025931654\n",
      "Validation Loss: 0.035378605\n",
      "Epoch: 4162 cost = 0.025931132\n",
      "Validation Loss: 0.035357047\n",
      "Epoch: 4163 cost = 0.025930725\n",
      "Validation Loss: 0.038894195\n",
      "Epoch: 4164 cost = 0.025930278\n",
      "Validation Loss: 0.034286615\n",
      "Epoch: 4165 cost = 0.025929827\n",
      "Validation Loss: 0.03614343\n",
      "Epoch: 4166 cost = 0.025929432\n",
      "Validation Loss: 0.037849456\n",
      "Epoch: 4167 cost = 0.025928937\n",
      "Validation Loss: 0.033728156\n",
      "Epoch: 4168 cost = 0.025928557\n",
      "Validation Loss: 0.034787435\n",
      "Epoch: 4169 cost = 0.025928101\n",
      "Validation Loss: 0.034583464\n",
      "Epoch: 4170 cost = 0.025927594\n",
      "Validation Loss: 0.031821836\n",
      "Epoch: 4171 cost = 0.025927221\n",
      "Validation Loss: 0.033205796\n",
      "Epoch: 4172 cost = 0.025926749\n",
      "Validation Loss: 0.03334159\n",
      "Epoch: 4173 cost = 0.025926339\n",
      "Validation Loss: 0.029224172\n",
      "Epoch: 4174 cost = 0.025925873\n",
      "Validation Loss: 0.031246927\n",
      "Epoch: 4175 cost = 0.025925430\n",
      "Validation Loss: 0.032012686\n",
      "Epoch: 4176 cost = 0.025924993\n",
      "Validation Loss: 0.03082821\n",
      "Epoch: 4177 cost = 0.025924508\n",
      "Validation Loss: 0.038817093\n",
      "Epoch: 4178 cost = 0.025924129\n",
      "Validation Loss: 0.029783929\n",
      "Epoch: 4179 cost = 0.025923734\n",
      "Validation Loss: 0.03977033\n",
      "Epoch: 4180 cost = 0.025923226\n",
      "Validation Loss: 0.03508397\n",
      "Epoch: 4181 cost = 0.025922851\n",
      "Validation Loss: 0.031271078\n",
      "Epoch: 4182 cost = 0.025922388\n",
      "Validation Loss: 0.032435555\n",
      "Epoch: 4183 cost = 0.025921951\n",
      "Validation Loss: 0.037584998\n",
      "Epoch: 4184 cost = 0.025921488\n",
      "Validation Loss: 0.05846261\n",
      "Epoch: 4185 cost = 0.025921034\n",
      "Validation Loss: 0.121175036\n",
      "Epoch: 4186 cost = 0.025920616\n",
      "Validation Loss: 0.086210884\n",
      "Epoch: 4187 cost = 0.025920227\n",
      "Validation Loss: 0.03184573\n",
      "Epoch: 4188 cost = 0.025919842\n",
      "Validation Loss: 0.034801066\n",
      "Epoch: 4189 cost = 0.025919280\n",
      "Validation Loss: 0.03530767\n",
      "Epoch: 4190 cost = 0.025918936\n",
      "Validation Loss: 0.042728588\n",
      "Epoch: 4191 cost = 0.025918466\n",
      "Validation Loss: 0.040441733\n",
      "Epoch: 4192 cost = 0.025918015\n",
      "Validation Loss: 0.033836927\n",
      "Epoch: 4193 cost = 0.025917586\n",
      "Validation Loss: 0.033008207\n",
      "Epoch: 4194 cost = 0.025917155\n",
      "Validation Loss: 0.050668422\n",
      "Epoch: 4195 cost = 0.025916725\n",
      "Validation Loss: 0.058229875\n",
      "Epoch: 4196 cost = 0.025916268\n",
      "Validation Loss: 0.042245217\n",
      "Epoch: 4197 cost = 0.025915834\n",
      "Validation Loss: 0.046801303\n",
      "Epoch: 4198 cost = 0.025915384\n",
      "Validation Loss: 0.07265061\n",
      "Epoch: 4199 cost = 0.025915012\n",
      "Validation Loss: 0.0438621\n",
      "Epoch: 4200 cost = 0.025914569\n",
      "Validation Loss: 0.034910154\n",
      "Epoch: 4201 cost = 0.025914108\n",
      "Validation Loss: 0.03724288\n",
      "Epoch: 4202 cost = 0.025913712\n",
      "Validation Loss: 0.035874162\n",
      "Epoch: 4203 cost = 0.025913316\n",
      "Validation Loss: 0.03847475\n",
      "Epoch: 4204 cost = 0.025912819\n",
      "Validation Loss: 0.036939662\n",
      "Epoch: 4205 cost = 0.025912423\n",
      "Validation Loss: 0.031188725\n",
      "Epoch: 4206 cost = 0.025911974\n",
      "Validation Loss: 0.03148825\n",
      "Epoch: 4207 cost = 0.025911569\n",
      "Validation Loss: 0.038920876\n",
      "Epoch: 4208 cost = 0.025911099\n",
      "Validation Loss: 0.042079248\n",
      "Epoch: 4209 cost = 0.025910714\n",
      "Validation Loss: 0.043534905\n",
      "Epoch: 4210 cost = 0.025910273\n",
      "Validation Loss: 0.042557415\n",
      "Epoch: 4211 cost = 0.025909855\n",
      "Validation Loss: 0.03259373\n",
      "Epoch: 4212 cost = 0.025909454\n",
      "Validation Loss: 0.04606793\n",
      "Epoch: 4213 cost = 0.025909044\n",
      "Validation Loss: 0.04546105\n",
      "Epoch: 4214 cost = 0.025908600\n",
      "Validation Loss: 0.05176384\n",
      "Epoch: 4215 cost = 0.025908128\n",
      "Validation Loss: 0.04432923\n",
      "Epoch: 4216 cost = 0.025907690\n",
      "Validation Loss: 0.038676757\n",
      "Epoch: 4217 cost = 0.025907295\n",
      "Validation Loss: 0.04270368\n",
      "Epoch: 4218 cost = 0.025906887\n",
      "Validation Loss: 0.04018163\n",
      "Epoch: 4219 cost = 0.025906449\n",
      "Validation Loss: 0.04944395\n",
      "Epoch: 4220 cost = 0.025906013\n",
      "Validation Loss: 0.04569774\n",
      "Epoch: 4221 cost = 0.025905625\n",
      "Validation Loss: 0.037780803\n",
      "Epoch: 4222 cost = 0.025905165\n",
      "Validation Loss: 0.031836577\n",
      "Epoch: 4223 cost = 0.025904738\n",
      "Validation Loss: 0.030723553\n",
      "Epoch: 4224 cost = 0.025904354\n",
      "Validation Loss: 0.033355482\n",
      "Epoch: 4225 cost = 0.025903976\n",
      "Validation Loss: 0.04016843\n",
      "Epoch: 4226 cost = 0.025903497\n",
      "Validation Loss: 0.036433496\n",
      "Epoch: 4227 cost = 0.025903120\n",
      "Validation Loss: 0.033230245\n",
      "Epoch: 4228 cost = 0.025902669\n",
      "Validation Loss: 0.040656246\n",
      "Epoch: 4229 cost = 0.025902218\n",
      "Validation Loss: 0.061700672\n",
      "Epoch: 4230 cost = 0.025901864\n",
      "Validation Loss: 0.06264501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4231 cost = 0.025901414\n",
      "Validation Loss: 0.04784592\n",
      "Epoch: 4232 cost = 0.025900990\n",
      "Validation Loss: 0.03996324\n",
      "Epoch: 4233 cost = 0.025900594\n",
      "Validation Loss: 0.033053223\n",
      "Epoch: 4234 cost = 0.025900153\n",
      "Validation Loss: 0.03144883\n",
      "Epoch: 4235 cost = 0.025899738\n",
      "Validation Loss: 0.035406306\n",
      "Epoch: 4236 cost = 0.025899334\n",
      "Validation Loss: 0.03441859\n",
      "Epoch: 4237 cost = 0.025898967\n",
      "Validation Loss: 0.03916594\n",
      "Epoch: 4238 cost = 0.025898475\n",
      "Validation Loss: 0.036432594\n",
      "Epoch: 4239 cost = 0.025898082\n",
      "Validation Loss: 0.04452768\n",
      "Epoch: 4240 cost = 0.025897653\n",
      "Validation Loss: 0.03353945\n",
      "Epoch: 4241 cost = 0.025897299\n",
      "Validation Loss: 0.035228536\n",
      "Epoch: 4242 cost = 0.025896774\n",
      "Validation Loss: 0.035964582\n",
      "Epoch: 4243 cost = 0.025896436\n",
      "Validation Loss: 0.033057023\n",
      "Epoch: 4244 cost = 0.025895975\n",
      "Validation Loss: 0.05662143\n",
      "Epoch: 4245 cost = 0.025895550\n",
      "Validation Loss: 0.07584016\n",
      "Epoch: 4246 cost = 0.025895149\n",
      "Validation Loss: 0.077720575\n",
      "Epoch: 4247 cost = 0.025894791\n",
      "Validation Loss: 0.07586336\n",
      "Epoch: 4248 cost = 0.025894332\n",
      "Validation Loss: 0.059309874\n",
      "Epoch: 4249 cost = 0.025893919\n",
      "Validation Loss: 0.054339632\n",
      "Epoch: 4250 cost = 0.025893531\n",
      "Validation Loss: 0.061337348\n",
      "Epoch: 4251 cost = 0.025893150\n",
      "Validation Loss: 0.048682734\n",
      "Epoch: 4252 cost = 0.025892671\n",
      "Validation Loss: 0.035255887\n",
      "Epoch: 4253 cost = 0.025892252\n",
      "Validation Loss: 0.034561574\n",
      "Epoch: 4254 cost = 0.025891867\n",
      "Validation Loss: 0.03839751\n",
      "Epoch: 4255 cost = 0.025891465\n",
      "Validation Loss: 0.039477613\n",
      "Epoch: 4256 cost = 0.025891063\n",
      "Validation Loss: 0.036619235\n",
      "Epoch: 4257 cost = 0.025890636\n",
      "Validation Loss: 0.03276\n",
      "Epoch: 4258 cost = 0.025890273\n",
      "Validation Loss: 0.032016646\n",
      "Epoch: 4259 cost = 0.025889816\n",
      "Validation Loss: 0.031511433\n",
      "Epoch: 4260 cost = 0.025889435\n",
      "Validation Loss: 0.034083027\n",
      "Epoch: 4261 cost = 0.025889011\n",
      "Validation Loss: 0.03309008\n",
      "Epoch: 4262 cost = 0.025888595\n",
      "Validation Loss: 0.037365794\n",
      "Epoch: 4263 cost = 0.025888183\n",
      "Validation Loss: 0.03606534\n",
      "Epoch: 4264 cost = 0.025887792\n",
      "Validation Loss: 0.0585246\n",
      "Epoch: 4265 cost = 0.025887367\n",
      "Validation Loss: 0.04847799\n",
      "Epoch: 4266 cost = 0.025886974\n",
      "Validation Loss: 0.036809847\n",
      "Epoch: 4267 cost = 0.025886579\n",
      "Validation Loss: 0.042533487\n",
      "Epoch: 4268 cost = 0.025886138\n",
      "Validation Loss: 0.06051857\n",
      "Epoch: 4269 cost = 0.025885788\n",
      "Validation Loss: 0.04221384\n",
      "Epoch: 4270 cost = 0.025885359\n",
      "Validation Loss: 0.032514486\n",
      "Epoch: 4271 cost = 0.025884978\n",
      "Validation Loss: 0.030891674\n",
      "Epoch: 4272 cost = 0.025884523\n",
      "Validation Loss: 0.029081995\n",
      "Epoch: 4273 cost = 0.025884135\n",
      "Validation Loss: 0.0339998\n",
      "Epoch: 4274 cost = 0.025883773\n",
      "Validation Loss: 0.031410422\n",
      "Epoch: 4275 cost = 0.025883324\n",
      "Validation Loss: 0.03285188\n",
      "Epoch: 4276 cost = 0.025882881\n",
      "Validation Loss: 0.03720207\n",
      "Epoch: 4277 cost = 0.025882562\n",
      "Validation Loss: 0.038558986\n",
      "Epoch: 4278 cost = 0.025882130\n",
      "Validation Loss: 0.03876832\n",
      "Epoch: 4279 cost = 0.025881731\n",
      "Validation Loss: 0.034422804\n",
      "Epoch: 4280 cost = 0.025881317\n",
      "Validation Loss: 0.036670983\n",
      "Epoch: 4281 cost = 0.025880925\n",
      "Validation Loss: 0.02940146\n",
      "Epoch: 4282 cost = 0.025880544\n",
      "Validation Loss: 0.033212803\n",
      "Epoch: 4283 cost = 0.025880118\n",
      "Validation Loss: 0.029712338\n",
      "Epoch: 4284 cost = 0.025879757\n",
      "Validation Loss: 0.03707338\n",
      "Epoch: 4285 cost = 0.025879315\n",
      "Validation Loss: 0.038636327\n",
      "Epoch: 4286 cost = 0.025878950\n",
      "Validation Loss: 0.038007535\n",
      "Epoch: 4287 cost = 0.025878533\n",
      "Validation Loss: 0.044620547\n",
      "Epoch: 4288 cost = 0.025878117\n",
      "Validation Loss: 0.034975175\n",
      "Epoch: 4289 cost = 0.025877673\n",
      "Validation Loss: 0.032443143\n",
      "Epoch: 4290 cost = 0.025877312\n",
      "Validation Loss: 0.033457257\n",
      "Epoch: 4291 cost = 0.025876908\n",
      "Validation Loss: 0.033715665\n",
      "Epoch: 4292 cost = 0.025876495\n",
      "Validation Loss: 0.03434358\n",
      "Epoch: 4293 cost = 0.025876095\n",
      "Validation Loss: 0.033257872\n",
      "Epoch: 4294 cost = 0.025875738\n",
      "Validation Loss: 0.038104005\n",
      "Epoch: 4295 cost = 0.025875385\n",
      "Validation Loss: 0.037313282\n",
      "Epoch: 4296 cost = 0.025874893\n",
      "Validation Loss: 0.03564968\n",
      "Epoch: 4297 cost = 0.025874542\n",
      "Validation Loss: 0.033018254\n",
      "Epoch: 4298 cost = 0.025874177\n",
      "Validation Loss: 0.03215028\n",
      "Epoch: 4299 cost = 0.025873753\n",
      "Validation Loss: 0.035179596\n",
      "Epoch: 4300 cost = 0.025873337\n",
      "Validation Loss: 0.041166436\n",
      "Epoch: 4301 cost = 0.025872919\n",
      "Validation Loss: 0.039640844\n",
      "Epoch: 4302 cost = 0.025872581\n",
      "Validation Loss: 0.03867262\n",
      "Epoch: 4303 cost = 0.025872204\n",
      "Validation Loss: 0.034774043\n",
      "Epoch: 4304 cost = 0.025871761\n",
      "Validation Loss: 0.03495826\n",
      "Epoch: 4305 cost = 0.025871363\n",
      "Validation Loss: 0.036186222\n",
      "Epoch: 4306 cost = 0.025871002\n",
      "Validation Loss: 0.03729029\n",
      "Epoch: 4307 cost = 0.025870556\n",
      "Validation Loss: 0.034954596\n",
      "Epoch: 4308 cost = 0.025870208\n",
      "Validation Loss: 0.034993295\n",
      "Epoch: 4309 cost = 0.025869837\n",
      "Validation Loss: 0.030409237\n",
      "Epoch: 4310 cost = 0.025869413\n",
      "Validation Loss: 0.028109834\n",
      "Epoch: 4311 cost = 0.025869020\n",
      "Validation Loss: 0.031030362\n",
      "Epoch: 4312 cost = 0.025868657\n",
      "Validation Loss: 0.03517376\n",
      "Epoch: 4313 cost = 0.025868231\n",
      "Validation Loss: 0.033982277\n",
      "Epoch: 4314 cost = 0.025867838\n",
      "Validation Loss: 0.037201785\n",
      "Epoch: 4315 cost = 0.025867440\n",
      "Validation Loss: 0.037828635\n",
      "Epoch: 4316 cost = 0.025867067\n",
      "Validation Loss: 0.037655663\n",
      "Epoch: 4317 cost = 0.025866651\n",
      "Validation Loss: 0.0349225\n",
      "Epoch: 4318 cost = 0.025866262\n",
      "Validation Loss: 0.031872652\n",
      "Epoch: 4319 cost = 0.025865865\n",
      "Validation Loss: 0.031388953\n",
      "Epoch: 4320 cost = 0.025865517\n",
      "Validation Loss: 0.035269555\n",
      "Epoch: 4321 cost = 0.025865120\n",
      "Validation Loss: 0.039320666\n",
      "Epoch: 4322 cost = 0.025864712\n",
      "Validation Loss: 0.04068142\n",
      "Epoch: 4323 cost = 0.025864363\n",
      "Validation Loss: 0.03218008\n",
      "Epoch: 4324 cost = 0.025863969\n",
      "Validation Loss: 0.028618645\n",
      "Epoch: 4325 cost = 0.025863526\n",
      "Validation Loss: 0.03173195\n",
      "Epoch: 4326 cost = 0.025863153\n",
      "Validation Loss: 0.034586094\n",
      "Epoch: 4327 cost = 0.025862793\n",
      "Validation Loss: 0.036837053\n",
      "Epoch: 4328 cost = 0.025862408\n",
      "Validation Loss: 0.036947824\n",
      "Epoch: 4329 cost = 0.025861972\n",
      "Validation Loss: 0.031282824\n",
      "Epoch: 4330 cost = 0.025861640\n",
      "Validation Loss: 0.032826617\n",
      "Epoch: 4331 cost = 0.025861255\n",
      "Validation Loss: 0.031081093\n",
      "Epoch: 4332 cost = 0.025860813\n",
      "Validation Loss: 0.030655513\n",
      "Epoch: 4333 cost = 0.025860460\n",
      "Validation Loss: 0.040749714\n",
      "Epoch: 4334 cost = 0.025860087\n",
      "Validation Loss: 0.038063455\n",
      "Epoch: 4335 cost = 0.025859655\n",
      "Validation Loss: 0.050430622\n",
      "Epoch: 4336 cost = 0.025859301\n",
      "Validation Loss: 0.058900144\n",
      "Epoch: 4337 cost = 0.025858873\n",
      "Validation Loss: 0.05635207\n",
      "Epoch: 4338 cost = 0.025858509\n",
      "Validation Loss: 0.04387656\n",
      "Epoch: 4339 cost = 0.025858184\n",
      "Validation Loss: 0.028436668\n",
      "Epoch: 4340 cost = 0.025857758\n",
      "Validation Loss: 0.02931391\n",
      "Epoch: 4341 cost = 0.025857388\n",
      "Validation Loss: 0.03153695\n",
      "Epoch: 4342 cost = 0.025857008\n",
      "Validation Loss: 0.033295963\n",
      "Epoch: 4343 cost = 0.025856630\n",
      "Validation Loss: 0.033035595\n",
      "Epoch: 4344 cost = 0.025856261\n",
      "Validation Loss: 0.03484444\n",
      "Epoch: 4345 cost = 0.025855849\n",
      "Validation Loss: 0.03814102\n",
      "Epoch: 4346 cost = 0.025855488\n",
      "Validation Loss: 0.056743056\n",
      "Epoch: 4347 cost = 0.025855072\n",
      "Validation Loss: 0.054101206\n",
      "Epoch: 4348 cost = 0.025854701\n",
      "Validation Loss: 0.058766812\n",
      "Epoch: 4349 cost = 0.025854280\n",
      "Validation Loss: 0.063475564\n",
      "Epoch: 4350 cost = 0.025853976\n",
      "Validation Loss: 0.035087\n",
      "Epoch: 4351 cost = 0.025853562\n",
      "Validation Loss: 0.030591127\n",
      "Epoch: 4352 cost = 0.025853202\n",
      "Validation Loss: 0.031776156\n",
      "Epoch: 4353 cost = 0.025852775\n",
      "Validation Loss: 0.039479934\n",
      "Epoch: 4354 cost = 0.025852441\n",
      "Validation Loss: 0.03659192\n",
      "Epoch: 4355 cost = 0.025852037\n",
      "Validation Loss: 0.03699314\n",
      "Epoch: 4356 cost = 0.025851679\n",
      "Validation Loss: 0.034143195\n",
      "Epoch: 4357 cost = 0.025851292\n",
      "Validation Loss: 0.03243779\n",
      "Epoch: 4358 cost = 0.025850926\n",
      "Validation Loss: 0.034608237\n",
      "Epoch: 4359 cost = 0.025850551\n",
      "Validation Loss: 0.034086674\n",
      "Epoch: 4360 cost = 0.025850136\n",
      "Validation Loss: 0.030417155\n",
      "Epoch: 4361 cost = 0.025849756\n",
      "Validation Loss: 0.031347405\n",
      "Epoch: 4362 cost = 0.025849382\n",
      "Validation Loss: 0.031242121\n",
      "Epoch: 4363 cost = 0.025849000\n",
      "Validation Loss: 0.032390743\n",
      "Epoch: 4364 cost = 0.025848636\n",
      "Validation Loss: 0.030579945\n",
      "Epoch: 4365 cost = 0.025848281\n",
      "Validation Loss: 0.033335544\n",
      "Epoch: 4366 cost = 0.025847917\n",
      "Validation Loss: 0.036054898\n",
      "Epoch: 4367 cost = 0.025847528\n",
      "Validation Loss: 0.037401702\n",
      "Epoch: 4368 cost = 0.025847136\n",
      "Validation Loss: 0.041431222\n",
      "Epoch: 4369 cost = 0.025846805\n",
      "Validation Loss: 0.039236788\n",
      "Epoch: 4370 cost = 0.025846376\n",
      "Validation Loss: 0.034400743\n",
      "Epoch: 4371 cost = 0.025846068\n",
      "Validation Loss: 0.032717694\n",
      "Epoch: 4372 cost = 0.025845659\n",
      "Validation Loss: 0.03307739\n",
      "Epoch: 4373 cost = 0.025845267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.032921206\n",
      "Epoch: 4374 cost = 0.025844889\n",
      "Validation Loss: 0.033148736\n",
      "Epoch: 4375 cost = 0.025844553\n",
      "Validation Loss: 0.032928955\n",
      "Epoch: 4376 cost = 0.025844153\n",
      "Validation Loss: 0.037331995\n",
      "Epoch: 4377 cost = 0.025843781\n",
      "Validation Loss: 0.040223982\n",
      "Epoch: 4378 cost = 0.025843425\n",
      "Validation Loss: 0.04065429\n",
      "Epoch: 4379 cost = 0.025843021\n",
      "Validation Loss: 0.033728156\n",
      "Epoch: 4380 cost = 0.025842632\n",
      "Validation Loss: 0.036775157\n",
      "Epoch: 4381 cost = 0.025842278\n",
      "Validation Loss: 0.032001633\n",
      "Epoch: 4382 cost = 0.025841891\n",
      "Validation Loss: 0.0337992\n",
      "Epoch: 4383 cost = 0.025841569\n",
      "Validation Loss: 0.036199972\n",
      "Epoch: 4384 cost = 0.025841187\n",
      "Validation Loss: 0.03033897\n",
      "Epoch: 4385 cost = 0.025840808\n",
      "Validation Loss: 0.03249267\n",
      "Epoch: 4386 cost = 0.025840420\n",
      "Validation Loss: 0.03181469\n",
      "Epoch: 4387 cost = 0.025840045\n",
      "Validation Loss: 0.040889934\n",
      "Epoch: 4388 cost = 0.025839703\n",
      "Validation Loss: 0.03707829\n",
      "Epoch: 4389 cost = 0.025839316\n",
      "Validation Loss: 0.041688766\n",
      "Epoch: 4390 cost = 0.025838961\n",
      "Validation Loss: 0.039588206\n",
      "Epoch: 4391 cost = 0.025838589\n",
      "Validation Loss: 0.056485336\n",
      "Epoch: 4392 cost = 0.025838200\n",
      "Validation Loss: 0.059967957\n",
      "Epoch: 4393 cost = 0.025837851\n",
      "Validation Loss: 0.052896157\n",
      "Epoch: 4394 cost = 0.025837491\n",
      "Validation Loss: 0.04956357\n",
      "Epoch: 4395 cost = 0.025837068\n",
      "Validation Loss: 0.035879258\n",
      "Epoch: 4396 cost = 0.025836715\n",
      "Validation Loss: 0.033938345\n",
      "Epoch: 4397 cost = 0.025836354\n",
      "Validation Loss: 0.033195615\n",
      "Epoch: 4398 cost = 0.025835966\n",
      "Validation Loss: 0.03383149\n",
      "Epoch: 4399 cost = 0.025835655\n",
      "Validation Loss: 0.036576103\n",
      "Epoch: 4400 cost = 0.025835291\n",
      "Validation Loss: 0.0343457\n",
      "Epoch: 4401 cost = 0.025834864\n",
      "Validation Loss: 0.03068366\n",
      "Epoch: 4402 cost = 0.025834489\n",
      "Validation Loss: 0.03120296\n",
      "Epoch: 4403 cost = 0.025834186\n",
      "Validation Loss: 0.03448582\n",
      "Epoch: 4404 cost = 0.025833806\n",
      "Validation Loss: 0.05008745\n",
      "Epoch: 4405 cost = 0.025833406\n",
      "Validation Loss: 0.057300773\n",
      "Epoch: 4406 cost = 0.025833098\n",
      "Validation Loss: 0.03569768\n",
      "Epoch: 4407 cost = 0.025832679\n",
      "Validation Loss: 0.03238236\n",
      "Epoch: 4408 cost = 0.025832351\n",
      "Validation Loss: 0.031753596\n",
      "Epoch: 4409 cost = 0.025831960\n",
      "Validation Loss: 0.03569644\n",
      "Epoch: 4410 cost = 0.025831548\n",
      "Validation Loss: 0.03633564\n",
      "Epoch: 4411 cost = 0.025831257\n",
      "Validation Loss: 0.0323199\n",
      "Epoch: 4412 cost = 0.025830913\n",
      "Validation Loss: 0.033592936\n",
      "Epoch: 4413 cost = 0.025830517\n",
      "Validation Loss: 0.03459532\n",
      "Epoch: 4414 cost = 0.025830160\n",
      "Validation Loss: 0.033186354\n",
      "Epoch: 4415 cost = 0.025829759\n",
      "Validation Loss: 0.032005917\n",
      "Epoch: 4416 cost = 0.025829410\n",
      "Validation Loss: 0.0340718\n",
      "Epoch: 4417 cost = 0.025829054\n",
      "Validation Loss: 0.03386367\n",
      "Epoch: 4418 cost = 0.025828689\n",
      "Validation Loss: 0.034766536\n",
      "Epoch: 4419 cost = 0.025828354\n",
      "Validation Loss: 0.03299155\n",
      "Epoch: 4420 cost = 0.025827987\n",
      "Validation Loss: 0.031618025\n",
      "Epoch: 4421 cost = 0.025827614\n",
      "Validation Loss: 0.03553391\n",
      "Epoch: 4422 cost = 0.025827308\n",
      "Validation Loss: 0.038713742\n",
      "Epoch: 4423 cost = 0.025826909\n",
      "Validation Loss: 0.052176617\n",
      "Epoch: 4424 cost = 0.025826519\n",
      "Validation Loss: 0.03641753\n",
      "Epoch: 4425 cost = 0.025826174\n",
      "Validation Loss: 0.039575506\n",
      "Epoch: 4426 cost = 0.025825820\n",
      "Validation Loss: 0.04133824\n",
      "Epoch: 4427 cost = 0.025825390\n",
      "Validation Loss: 0.03110255\n",
      "Epoch: 4428 cost = 0.025825079\n",
      "Validation Loss: 0.029759191\n",
      "Epoch: 4429 cost = 0.025824708\n",
      "Validation Loss: 0.037418064\n",
      "Epoch: 4430 cost = 0.025824355\n",
      "Validation Loss: 0.03373096\n",
      "Epoch: 4431 cost = 0.025824031\n",
      "Validation Loss: 0.03501064\n",
      "Epoch: 4432 cost = 0.025823630\n",
      "Validation Loss: 0.031648137\n",
      "Epoch: 4433 cost = 0.025823288\n",
      "Validation Loss: 0.0485265\n",
      "Epoch: 4434 cost = 0.025822935\n",
      "Validation Loss: 0.03740767\n",
      "Epoch: 4435 cost = 0.025822545\n",
      "Validation Loss: 0.037393954\n",
      "Epoch: 4436 cost = 0.025822195\n",
      "Validation Loss: 0.030842671\n",
      "Epoch: 4437 cost = 0.025821859\n",
      "Validation Loss: 0.031330146\n",
      "Epoch: 4438 cost = 0.025821478\n",
      "Validation Loss: 0.03193157\n",
      "Epoch: 4439 cost = 0.025821145\n",
      "Validation Loss: 0.034891848\n",
      "Epoch: 4440 cost = 0.025820789\n",
      "Validation Loss: 0.032112986\n",
      "Epoch: 4441 cost = 0.025820412\n",
      "Validation Loss: 0.034719586\n",
      "Epoch: 4442 cost = 0.025820027\n",
      "Validation Loss: 0.045046363\n",
      "Epoch: 4443 cost = 0.025819697\n",
      "Validation Loss: 0.054608874\n",
      "Epoch: 4444 cost = 0.025819364\n",
      "Validation Loss: 0.03463208\n",
      "Epoch: 4445 cost = 0.025819038\n",
      "Validation Loss: 0.04559304\n",
      "Epoch: 4446 cost = 0.025818613\n",
      "Validation Loss: 0.04796532\n",
      "Epoch: 4447 cost = 0.025818281\n",
      "Validation Loss: 0.03668644\n",
      "Epoch: 4448 cost = 0.025817911\n",
      "Validation Loss: 0.030823873\n",
      "Epoch: 4449 cost = 0.025817615\n",
      "Validation Loss: 0.03273602\n",
      "Epoch: 4450 cost = 0.025817188\n",
      "Validation Loss: 0.03967228\n",
      "Epoch: 4451 cost = 0.025816865\n",
      "Validation Loss: 0.054978095\n",
      "Epoch: 4452 cost = 0.025816570\n",
      "Validation Loss: 0.100371316\n",
      "Epoch: 4453 cost = 0.025816195\n",
      "Validation Loss: 0.10505455\n",
      "Epoch: 4454 cost = 0.025815827\n",
      "Validation Loss: 0.049519937\n",
      "Epoch: 4455 cost = 0.025815436\n",
      "Validation Loss: 0.05174164\n",
      "Epoch: 4456 cost = 0.025815076\n",
      "Validation Loss: 0.053125117\n",
      "Epoch: 4457 cost = 0.025814795\n",
      "Validation Loss: 0.036649927\n",
      "Epoch: 4458 cost = 0.025814446\n",
      "Validation Loss: 0.032305032\n",
      "Epoch: 4459 cost = 0.025814098\n",
      "Validation Loss: 0.03394352\n",
      "Epoch: 4460 cost = 0.025813672\n",
      "Validation Loss: 0.035923745\n",
      "Epoch: 4461 cost = 0.025813377\n",
      "Validation Loss: 0.035895903\n",
      "Epoch: 4462 cost = 0.025813008\n",
      "Validation Loss: 0.030318666\n",
      "Epoch: 4463 cost = 0.025812657\n",
      "Validation Loss: 0.03609915\n",
      "Epoch: 4464 cost = 0.025812298\n",
      "Validation Loss: 0.03556416\n",
      "Epoch: 4465 cost = 0.025811944\n",
      "Validation Loss: 0.038459416\n",
      "Epoch: 4466 cost = 0.025811592\n",
      "Validation Loss: 0.03060527\n",
      "Epoch: 4467 cost = 0.025811223\n",
      "Validation Loss: 0.04317644\n",
      "Epoch: 4468 cost = 0.025810897\n",
      "Validation Loss: 0.07429302\n",
      "Epoch: 4469 cost = 0.025810514\n",
      "Validation Loss: 0.074240156\n",
      "Epoch: 4470 cost = 0.025810194\n",
      "Validation Loss: 0.039009407\n",
      "Epoch: 4471 cost = 0.025809844\n",
      "Validation Loss: 0.036463227\n",
      "Epoch: 4472 cost = 0.025809435\n",
      "Validation Loss: 0.04770937\n",
      "Epoch: 4473 cost = 0.025809122\n",
      "Validation Loss: 0.039926253\n",
      "Epoch: 4474 cost = 0.025808821\n",
      "Validation Loss: 0.035946093\n",
      "Epoch: 4475 cost = 0.025808476\n",
      "Validation Loss: 0.03435512\n",
      "Epoch: 4476 cost = 0.025808095\n",
      "Validation Loss: 0.031924807\n",
      "Epoch: 4477 cost = 0.025807719\n",
      "Validation Loss: 0.03168727\n",
      "Epoch: 4478 cost = 0.025807429\n",
      "Validation Loss: 0.033891164\n",
      "Epoch: 4479 cost = 0.025807051\n",
      "Validation Loss: 0.035430446\n",
      "Epoch: 4480 cost = 0.025806739\n",
      "Validation Loss: 0.033399653\n",
      "Epoch: 4481 cost = 0.025806350\n",
      "Validation Loss: 0.03430225\n",
      "Epoch: 4482 cost = 0.025806003\n",
      "Validation Loss: 0.031703\n",
      "Epoch: 4483 cost = 0.025805701\n",
      "Validation Loss: 0.03204191\n",
      "Epoch: 4484 cost = 0.025805320\n",
      "Validation Loss: 0.03987346\n",
      "Epoch: 4485 cost = 0.025804925\n",
      "Validation Loss: 0.07583708\n",
      "Epoch: 4486 cost = 0.025804631\n",
      "Validation Loss: 0.072250694\n",
      "Epoch: 4487 cost = 0.025804287\n",
      "Validation Loss: 0.07616087\n",
      "Epoch: 4488 cost = 0.025803923\n",
      "Validation Loss: 0.0354128\n",
      "Epoch: 4489 cost = 0.025803603\n",
      "Validation Loss: 0.04059186\n",
      "Epoch: 4490 cost = 0.025803203\n",
      "Validation Loss: 0.035729036\n",
      "Epoch: 4491 cost = 0.025802931\n",
      "Validation Loss: 0.030536737\n",
      "Epoch: 4492 cost = 0.025802544\n",
      "Validation Loss: 0.032180782\n",
      "Epoch: 4493 cost = 0.025802167\n",
      "Validation Loss: 0.030227581\n",
      "Epoch: 4494 cost = 0.025801882\n",
      "Validation Loss: 0.041828573\n",
      "Epoch: 4495 cost = 0.025801496\n",
      "Validation Loss: 0.038516585\n",
      "Epoch: 4496 cost = 0.025801153\n",
      "Validation Loss: 0.042890135\n",
      "Epoch: 4497 cost = 0.025800854\n",
      "Validation Loss: 0.042739477\n",
      "Epoch: 4498 cost = 0.025800486\n",
      "Validation Loss: 0.03327995\n",
      "Epoch: 4499 cost = 0.025800136\n",
      "Validation Loss: 0.03660944\n",
      "Epoch: 4500 cost = 0.025799811\n",
      "Validation Loss: 0.038228408\n",
      "Epoch: 4501 cost = 0.025799448\n",
      "Validation Loss: 0.039285794\n",
      "Epoch: 4502 cost = 0.025799095\n",
      "Validation Loss: 0.056382377\n",
      "Epoch: 4503 cost = 0.025798795\n",
      "Validation Loss: 0.059487175\n",
      "Epoch: 4504 cost = 0.025798404\n",
      "Validation Loss: 0.03680012\n",
      "Epoch: 4505 cost = 0.025798174\n",
      "Validation Loss: 0.033126406\n",
      "Epoch: 4506 cost = 0.025797753\n",
      "Validation Loss: 0.03376809\n",
      "Epoch: 4507 cost = 0.025797420\n",
      "Validation Loss: 0.036037415\n",
      "Epoch: 4508 cost = 0.025797075\n",
      "Validation Loss: 0.040580567\n",
      "Epoch: 4509 cost = 0.025796703\n",
      "Validation Loss: 0.037238616\n",
      "Epoch: 4510 cost = 0.025796375\n",
      "Validation Loss: 0.03404588\n",
      "Epoch: 4511 cost = 0.025796036\n",
      "Validation Loss: 0.030653888\n",
      "Epoch: 4512 cost = 0.025795716\n",
      "Validation Loss: 0.042888112\n",
      "Epoch: 4513 cost = 0.025795393\n",
      "Validation Loss: 0.054575026\n",
      "Epoch: 4514 cost = 0.025795020\n",
      "Validation Loss: 0.06443989\n",
      "Epoch: 4515 cost = 0.025794677\n",
      "Validation Loss: 0.072820656\n",
      "Epoch: 4516 cost = 0.025794357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.067619145\n",
      "Epoch: 4517 cost = 0.025794060\n",
      "Validation Loss: 0.061465126\n",
      "Epoch: 4518 cost = 0.025793677\n",
      "Validation Loss: 0.05733314\n",
      "Epoch: 4519 cost = 0.025793307\n",
      "Validation Loss: 0.04125661\n",
      "Epoch: 4520 cost = 0.025793028\n",
      "Validation Loss: 0.03972413\n",
      "Epoch: 4521 cost = 0.025792658\n",
      "Validation Loss: 0.063018665\n",
      "Epoch: 4522 cost = 0.025792281\n",
      "Validation Loss: 0.05328435\n",
      "Epoch: 4523 cost = 0.025791972\n",
      "Validation Loss: 0.075515226\n",
      "Epoch: 4524 cost = 0.025791662\n",
      "Validation Loss: 0.05886096\n",
      "Epoch: 4525 cost = 0.025791275\n",
      "Validation Loss: 0.045392267\n",
      "Epoch: 4526 cost = 0.025790990\n",
      "Validation Loss: 0.03161478\n",
      "Epoch: 4527 cost = 0.025790657\n",
      "Validation Loss: 0.03516045\n",
      "Epoch: 4528 cost = 0.025790288\n",
      "Validation Loss: 0.040730443\n",
      "Epoch: 4529 cost = 0.025789996\n",
      "Validation Loss: 0.038817596\n",
      "Epoch: 4530 cost = 0.025789618\n",
      "Validation Loss: 0.037158713\n",
      "Epoch: 4531 cost = 0.025789291\n",
      "Validation Loss: 0.043075692\n",
      "Epoch: 4532 cost = 0.025788979\n",
      "Validation Loss: 0.047168996\n",
      "Epoch: 4533 cost = 0.025788645\n",
      "Validation Loss: 0.041616037\n",
      "Epoch: 4534 cost = 0.025788315\n",
      "Validation Loss: 0.03895874\n",
      "Epoch: 4535 cost = 0.025787946\n",
      "Validation Loss: 0.038418166\n",
      "Epoch: 4536 cost = 0.025787629\n",
      "Validation Loss: 0.037650272\n",
      "Epoch: 4537 cost = 0.025787245\n",
      "Validation Loss: 0.035591748\n",
      "Epoch: 4538 cost = 0.025786949\n",
      "Validation Loss: 0.033026047\n",
      "Epoch: 4539 cost = 0.025786638\n",
      "Validation Loss: 0.03506812\n",
      "Epoch: 4540 cost = 0.025786273\n",
      "Validation Loss: 0.043660488\n",
      "Epoch: 4541 cost = 0.025785944\n",
      "Validation Loss: 0.04379823\n",
      "Epoch: 4542 cost = 0.025785639\n",
      "Validation Loss: 0.040860906\n",
      "Epoch: 4543 cost = 0.025785263\n",
      "Validation Loss: 0.052553136\n",
      "Epoch: 4544 cost = 0.025784951\n",
      "Validation Loss: 0.056210652\n",
      "Epoch: 4545 cost = 0.025784620\n",
      "Validation Loss: 0.045668576\n",
      "Epoch: 4546 cost = 0.025784296\n",
      "Validation Loss: 0.03791626\n",
      "Epoch: 4547 cost = 0.025783941\n",
      "Validation Loss: 0.030485312\n",
      "Epoch: 4548 cost = 0.025783585\n",
      "Validation Loss: 0.034699064\n",
      "Epoch: 4549 cost = 0.025783302\n",
      "Validation Loss: 0.032989416\n",
      "Epoch: 4550 cost = 0.025782933\n",
      "Validation Loss: 0.03607987\n",
      "Epoch: 4551 cost = 0.025782597\n",
      "Validation Loss: 0.030689677\n",
      "Epoch: 4552 cost = 0.025782272\n",
      "Validation Loss: 0.03662084\n",
      "Epoch: 4553 cost = 0.025781911\n",
      "Validation Loss: 0.039293453\n",
      "Epoch: 4554 cost = 0.025781648\n",
      "Validation Loss: 0.036509044\n",
      "Epoch: 4555 cost = 0.025781288\n",
      "Validation Loss: 0.038774103\n",
      "Epoch: 4556 cost = 0.025780961\n",
      "Validation Loss: 0.03471117\n",
      "Epoch: 4557 cost = 0.025780584\n",
      "Validation Loss: 0.04363768\n",
      "Epoch: 4558 cost = 0.025780308\n",
      "Validation Loss: 0.061349366\n",
      "Epoch: 4559 cost = 0.025779949\n",
      "Validation Loss: 0.038448635\n",
      "Epoch: 4560 cost = 0.025779617\n",
      "Validation Loss: 0.040853262\n",
      "Epoch: 4561 cost = 0.025779345\n",
      "Validation Loss: 0.031636503\n",
      "Epoch: 4562 cost = 0.025779000\n",
      "Validation Loss: 0.032192033\n",
      "Epoch: 4563 cost = 0.025778644\n",
      "Validation Loss: 0.033096135\n",
      "Epoch: 4564 cost = 0.025778314\n",
      "Validation Loss: 0.035110116\n",
      "Epoch: 4565 cost = 0.025777988\n",
      "Validation Loss: 0.031141797\n",
      "Epoch: 4566 cost = 0.025777619\n",
      "Validation Loss: 0.031032942\n",
      "Epoch: 4567 cost = 0.025777327\n",
      "Validation Loss: 0.03172995\n",
      "Epoch: 4568 cost = 0.025776983\n",
      "Validation Loss: 0.03046503\n",
      "Epoch: 4569 cost = 0.025776666\n",
      "Validation Loss: 0.030112045\n",
      "Epoch: 4570 cost = 0.025776341\n",
      "Validation Loss: 0.06050686\n",
      "Epoch: 4571 cost = 0.025776006\n",
      "Validation Loss: 0.044028886\n",
      "Epoch: 4572 cost = 0.025775740\n",
      "Validation Loss: 0.039810818\n",
      "Epoch: 4573 cost = 0.025775345\n",
      "Validation Loss: 0.03460498\n",
      "Epoch: 4574 cost = 0.025775039\n",
      "Validation Loss: 0.034094486\n",
      "Epoch: 4575 cost = 0.025774743\n",
      "Validation Loss: 0.030597296\n",
      "Epoch: 4576 cost = 0.025774358\n",
      "Validation Loss: 0.033079635\n",
      "Epoch: 4577 cost = 0.025774025\n",
      "Validation Loss: 0.032022826\n",
      "Epoch: 4578 cost = 0.025773737\n",
      "Validation Loss: 0.031232448\n",
      "Epoch: 4579 cost = 0.025773396\n",
      "Validation Loss: 0.03327642\n",
      "Epoch: 4580 cost = 0.025773064\n",
      "Validation Loss: 0.039191287\n",
      "Epoch: 4581 cost = 0.025772796\n",
      "Validation Loss: 0.038783852\n",
      "Epoch: 4582 cost = 0.025772418\n",
      "Validation Loss: 0.04011568\n",
      "Epoch: 4583 cost = 0.025772084\n",
      "Validation Loss: 0.04094933\n",
      "Epoch: 4584 cost = 0.025771813\n",
      "Validation Loss: 0.035060264\n",
      "Epoch: 4585 cost = 0.025771435\n",
      "Validation Loss: 0.034285262\n",
      "Epoch: 4586 cost = 0.025771108\n",
      "Validation Loss: 0.033879176\n",
      "Epoch: 4587 cost = 0.025770783\n",
      "Validation Loss: 0.037402622\n",
      "Epoch: 4588 cost = 0.025770492\n",
      "Validation Loss: 0.036780827\n",
      "Epoch: 4589 cost = 0.025770170\n",
      "Validation Loss: 0.041765604\n",
      "Epoch: 4590 cost = 0.025769866\n",
      "Validation Loss: 0.03159783\n",
      "Epoch: 4591 cost = 0.025769519\n",
      "Validation Loss: 0.031188672\n",
      "Epoch: 4592 cost = 0.025769228\n",
      "Validation Loss: 0.02876387\n",
      "Epoch: 4593 cost = 0.025768835\n",
      "Validation Loss: 0.036264777\n",
      "Epoch: 4594 cost = 0.025768521\n",
      "Validation Loss: 0.03555808\n",
      "Epoch: 4595 cost = 0.025768240\n",
      "Validation Loss: 0.02911288\n",
      "Epoch: 4596 cost = 0.025767905\n",
      "Validation Loss: 0.03400087\n",
      "Epoch: 4597 cost = 0.025767595\n",
      "Validation Loss: 0.036121413\n",
      "Epoch: 4598 cost = 0.025767200\n",
      "Validation Loss: 0.03677348\n",
      "Epoch: 4599 cost = 0.025766936\n",
      "Validation Loss: 0.03660385\n",
      "Epoch: 4600 cost = 0.025766628\n",
      "Validation Loss: 0.033864956\n",
      "Epoch: 4601 cost = 0.025766266\n",
      "Validation Loss: 0.03404083\n",
      "Epoch: 4602 cost = 0.025765945\n",
      "Validation Loss: 0.032480113\n",
      "Epoch: 4603 cost = 0.025765597\n",
      "Validation Loss: 0.03545147\n",
      "Epoch: 4604 cost = 0.025765351\n",
      "Validation Loss: 0.04981608\n",
      "Epoch: 4605 cost = 0.025764961\n",
      "Validation Loss: 0.055613566\n",
      "Epoch: 4606 cost = 0.025764631\n",
      "Validation Loss: 0.042552438\n",
      "Epoch: 4607 cost = 0.025764386\n",
      "Validation Loss: 0.037055075\n",
      "Epoch: 4608 cost = 0.025764070\n",
      "Validation Loss: 0.03311232\n",
      "Epoch: 4609 cost = 0.025763696\n",
      "Validation Loss: 0.036689095\n",
      "Epoch: 4610 cost = 0.025763433\n",
      "Validation Loss: 0.0404232\n",
      "Epoch: 4611 cost = 0.025763073\n",
      "Validation Loss: 0.038512684\n",
      "Epoch: 4612 cost = 0.025762744\n",
      "Validation Loss: 0.03660898\n",
      "Epoch: 4613 cost = 0.025762434\n",
      "Validation Loss: 0.03376818\n",
      "Epoch: 4614 cost = 0.025762117\n",
      "Validation Loss: 0.03526455\n",
      "Epoch: 4615 cost = 0.025761788\n",
      "Validation Loss: 0.036217425\n",
      "Epoch: 4616 cost = 0.025761491\n",
      "Validation Loss: 0.034166094\n",
      "Epoch: 4617 cost = 0.025761151\n",
      "Validation Loss: 0.031349126\n",
      "Epoch: 4618 cost = 0.025760829\n",
      "Validation Loss: 0.031166049\n",
      "Epoch: 4619 cost = 0.025760501\n",
      "Validation Loss: 0.032341078\n",
      "Epoch: 4620 cost = 0.025760202\n",
      "Validation Loss: 0.030117279\n",
      "Epoch: 4621 cost = 0.025759903\n",
      "Validation Loss: 0.040899444\n",
      "Epoch: 4622 cost = 0.025759587\n",
      "Validation Loss: 0.056993444\n",
      "Epoch: 4623 cost = 0.025759241\n",
      "Validation Loss: 0.054192655\n",
      "Epoch: 4624 cost = 0.025758907\n",
      "Validation Loss: 0.052442223\n",
      "Epoch: 4625 cost = 0.025758644\n",
      "Validation Loss: 0.054352853\n",
      "Epoch: 4626 cost = 0.025758322\n",
      "Validation Loss: 0.030967707\n",
      "Epoch: 4627 cost = 0.025758012\n",
      "Validation Loss: 0.034303844\n",
      "Epoch: 4628 cost = 0.025757672\n",
      "Validation Loss: 0.031477552\n",
      "Epoch: 4629 cost = 0.025757372\n",
      "Validation Loss: 0.033086374\n",
      "Epoch: 4630 cost = 0.025757025\n",
      "Validation Loss: 0.03515813\n",
      "Epoch: 4631 cost = 0.025756689\n",
      "Validation Loss: 0.03019382\n",
      "Epoch: 4632 cost = 0.025756426\n",
      "Validation Loss: 0.04970888\n",
      "Epoch: 4633 cost = 0.025756103\n",
      "Validation Loss: 0.08793919\n",
      "Epoch: 4634 cost = 0.025755809\n",
      "Validation Loss: 0.056057442\n",
      "Epoch: 4635 cost = 0.025755437\n",
      "Validation Loss: 0.055064686\n",
      "Epoch: 4636 cost = 0.025755181\n",
      "Validation Loss: 0.035704292\n",
      "Epoch: 4637 cost = 0.025754831\n",
      "Validation Loss: 0.034114834\n",
      "Epoch: 4638 cost = 0.025754514\n",
      "Validation Loss: 0.044360828\n",
      "Epoch: 4639 cost = 0.025754248\n",
      "Validation Loss: 0.04709277\n",
      "Epoch: 4640 cost = 0.025753928\n",
      "Validation Loss: 0.0454467\n",
      "Epoch: 4641 cost = 0.025753561\n",
      "Validation Loss: 0.037649956\n",
      "Epoch: 4642 cost = 0.025753308\n",
      "Validation Loss: 0.035921518\n",
      "Epoch: 4643 cost = 0.025752979\n",
      "Validation Loss: 0.036864057\n",
      "Epoch: 4644 cost = 0.025752617\n",
      "Validation Loss: 0.031769745\n",
      "Epoch: 4645 cost = 0.025752361\n",
      "Validation Loss: 0.031161387\n",
      "Epoch: 4646 cost = 0.025752072\n",
      "Validation Loss: 0.032225337\n",
      "Epoch: 4647 cost = 0.025751685\n",
      "Validation Loss: 0.037295174\n",
      "Epoch: 4648 cost = 0.025751448\n",
      "Validation Loss: 0.034192365\n",
      "Epoch: 4649 cost = 0.025751110\n",
      "Validation Loss: 0.034142602\n",
      "Epoch: 4650 cost = 0.025750761\n",
      "Validation Loss: 0.04495186\n",
      "Epoch: 4651 cost = 0.025750496\n",
      "Validation Loss: 0.06103384\n",
      "Epoch: 4652 cost = 0.025750203\n",
      "Validation Loss: 0.07860817\n",
      "Epoch: 4653 cost = 0.025749821\n",
      "Validation Loss: 0.04730195\n",
      "Epoch: 4654 cost = 0.025749557\n",
      "Validation Loss: 0.033592474\n",
      "Epoch: 4655 cost = 0.025749294\n",
      "Validation Loss: 0.034153424\n",
      "Epoch: 4656 cost = 0.025748924\n",
      "Validation Loss: 0.03969024\n",
      "Epoch: 4657 cost = 0.025748667\n",
      "Validation Loss: 0.03449613\n",
      "Epoch: 4658 cost = 0.025748304\n",
      "Validation Loss: 0.034912698\n",
      "Epoch: 4659 cost = 0.025748068\n",
      "Validation Loss: 0.037543703\n",
      "Epoch: 4660 cost = 0.025747707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03980103\n",
      "Epoch: 4661 cost = 0.025747353\n",
      "Validation Loss: 0.03676546\n",
      "Epoch: 4662 cost = 0.025747130\n",
      "Validation Loss: 0.038810495\n",
      "Epoch: 4663 cost = 0.025746796\n",
      "Validation Loss: 0.051281303\n",
      "Epoch: 4664 cost = 0.025746520\n",
      "Validation Loss: 0.073111705\n",
      "Epoch: 4665 cost = 0.025746180\n",
      "Validation Loss: 0.0660823\n",
      "Epoch: 4666 cost = 0.025745900\n",
      "Validation Loss: 0.058851197\n",
      "Epoch: 4667 cost = 0.025745587\n",
      "Validation Loss: 0.06137714\n",
      "Epoch: 4668 cost = 0.025745306\n",
      "Validation Loss: 0.052876845\n",
      "Epoch: 4669 cost = 0.025744975\n",
      "Validation Loss: 0.035220787\n",
      "Epoch: 4670 cost = 0.025744693\n",
      "Validation Loss: 0.033215486\n",
      "Epoch: 4671 cost = 0.025744379\n",
      "Validation Loss: 0.037169125\n",
      "Epoch: 4672 cost = 0.025744059\n",
      "Validation Loss: 0.037510097\n",
      "Epoch: 4673 cost = 0.025743835\n",
      "Validation Loss: 0.042206973\n",
      "Epoch: 4674 cost = 0.025743490\n",
      "Validation Loss: 0.041631542\n",
      "Epoch: 4675 cost = 0.025743182\n",
      "Validation Loss: 0.041677304\n",
      "Epoch: 4676 cost = 0.025742911\n",
      "Validation Loss: 0.03666253\n",
      "Epoch: 4677 cost = 0.025742574\n",
      "Validation Loss: 0.03325756\n",
      "Epoch: 4678 cost = 0.025742334\n",
      "Validation Loss: 0.02981776\n",
      "Epoch: 4679 cost = 0.025742040\n",
      "Validation Loss: 0.035104826\n",
      "Epoch: 4680 cost = 0.025741703\n",
      "Validation Loss: 0.035254452\n",
      "Epoch: 4681 cost = 0.025741409\n",
      "Validation Loss: 0.030895801\n",
      "Epoch: 4682 cost = 0.025741114\n",
      "Validation Loss: 0.031527534\n",
      "Epoch: 4683 cost = 0.025740870\n",
      "Validation Loss: 0.032623757\n",
      "Epoch: 4684 cost = 0.025740592\n",
      "Validation Loss: 0.030590931\n",
      "Epoch: 4685 cost = 0.025740272\n",
      "Validation Loss: 0.031672157\n",
      "Epoch: 4686 cost = 0.025740009\n",
      "Validation Loss: 0.033359375\n",
      "Epoch: 4687 cost = 0.025739681\n",
      "Validation Loss: 0.037704915\n",
      "Epoch: 4688 cost = 0.025739473\n",
      "Validation Loss: 0.044852562\n",
      "Epoch: 4689 cost = 0.025739166\n",
      "Validation Loss: 0.049094733\n",
      "Epoch: 4690 cost = 0.025738883\n",
      "Validation Loss: 0.045591403\n",
      "Epoch: 4691 cost = 0.025738604\n",
      "Validation Loss: 0.035411086\n",
      "Epoch: 4692 cost = 0.025738361\n",
      "Validation Loss: 0.035134114\n",
      "Epoch: 4693 cost = 0.025738097\n",
      "Validation Loss: 0.033505302\n",
      "Epoch: 4694 cost = 0.025737830\n",
      "Validation Loss: 0.029756652\n",
      "Epoch: 4695 cost = 0.025737602\n",
      "Validation Loss: 0.03599917\n",
      "Epoch: 4696 cost = 0.025737313\n",
      "Validation Loss: 0.03197318\n",
      "Epoch: 4697 cost = 0.025737065\n",
      "Validation Loss: 0.035728846\n",
      "Epoch: 4698 cost = 0.025736806\n",
      "Validation Loss: 0.03407467\n",
      "Epoch: 4699 cost = 0.025736632\n",
      "Validation Loss: 0.031644307\n",
      "Epoch: 4700 cost = 0.025736377\n",
      "Validation Loss: 0.043524195\n",
      "Epoch: 4701 cost = 0.025736154\n",
      "Validation Loss: 0.039426446\n",
      "Epoch: 4702 cost = 0.025735965\n",
      "Validation Loss: 0.029741202\n",
      "Epoch: 4703 cost = 0.025735725\n",
      "Validation Loss: 0.031141713\n",
      "Epoch: 4704 cost = 0.025735585\n",
      "Validation Loss: 0.034574296\n",
      "Epoch: 4705 cost = 0.025735448\n",
      "Validation Loss: 0.036905658\n",
      "Epoch: 4706 cost = 0.025735331\n",
      "Validation Loss: 0.03996405\n",
      "Epoch: 4707 cost = 0.025735234\n",
      "Validation Loss: 0.042419184\n",
      "Epoch: 4708 cost = 0.025735139\n",
      "Validation Loss: 0.039689712\n",
      "Epoch: 4709 cost = 0.025735154\n",
      "Validation Loss: 0.035670254\n",
      "Epoch: 4710 cost = 0.025735244\n",
      "Validation Loss: 0.032497503\n",
      "Epoch: 4711 cost = 0.025735291\n",
      "Validation Loss: 0.033316378\n",
      "Epoch: 4712 cost = 0.025735524\n",
      "Validation Loss: 0.04095619\n",
      "Epoch: 4713 cost = 0.025735870\n",
      "Validation Loss: 0.04233285\n",
      "Epoch: 4714 cost = 0.025736429\n",
      "Validation Loss: 0.04028138\n",
      "Epoch: 4715 cost = 0.025737241\n",
      "Validation Loss: 0.040303342\n",
      "Epoch: 4716 cost = 0.025738432\n",
      "Validation Loss: 0.039180648\n",
      "Epoch: 4717 cost = 0.025740198\n",
      "Validation Loss: 0.03633623\n",
      "Epoch: 4718 cost = 0.025742896\n",
      "Validation Loss: 0.032132097\n",
      "Epoch: 4719 cost = 0.025746889\n",
      "Validation Loss: 0.030925265\n",
      "Epoch: 4720 cost = 0.025752899\n",
      "Validation Loss: 0.033052333\n",
      "Epoch: 4721 cost = 0.025761556\n",
      "Validation Loss: 0.049196582\n",
      "Epoch: 4722 cost = 0.025772710\n",
      "Validation Loss: 0.049636897\n",
      "Epoch: 4723 cost = 0.025783473\n",
      "Validation Loss: 0.042515405\n",
      "Epoch: 4724 cost = 0.025787815\n",
      "Validation Loss: 0.04536439\n",
      "Epoch: 4725 cost = 0.025781457\n",
      "Validation Loss: 0.04743753\n",
      "Epoch: 4726 cost = 0.025766408\n",
      "Validation Loss: 0.036823362\n",
      "Epoch: 4727 cost = 0.025749465\n",
      "Validation Loss: 0.035239395\n",
      "Epoch: 4728 cost = 0.025737061\n",
      "Validation Loss: 0.03588935\n",
      "Epoch: 4729 cost = 0.025731156\n",
      "Validation Loss: 0.03872139\n",
      "Epoch: 4730 cost = 0.025729614\n",
      "Validation Loss: 0.04024679\n",
      "Epoch: 4731 cost = 0.025729814\n",
      "Validation Loss: 0.042891882\n",
      "Epoch: 4732 cost = 0.025729689\n",
      "Validation Loss: 0.037600562\n",
      "Epoch: 4733 cost = 0.025728559\n",
      "Validation Loss: 0.035106365\n",
      "Epoch: 4734 cost = 0.025726753\n",
      "Validation Loss: 0.039309677\n",
      "Epoch: 4735 cost = 0.025725007\n",
      "Validation Loss: 0.053291917\n",
      "Epoch: 4736 cost = 0.025723516\n",
      "Validation Loss: 0.03785636\n",
      "Epoch: 4737 cost = 0.025722361\n",
      "Validation Loss: 0.032014627\n",
      "Epoch: 4738 cost = 0.025721497\n",
      "Validation Loss: 0.033968188\n",
      "Epoch: 4739 cost = 0.025720948\n",
      "Validation Loss: 0.033425488\n",
      "Epoch: 4740 cost = 0.025720623\n",
      "Validation Loss: 0.033401832\n",
      "Epoch: 4741 cost = 0.025720352\n",
      "Validation Loss: 0.034311943\n",
      "Epoch: 4742 cost = 0.025720089\n",
      "Validation Loss: 0.03223717\n",
      "Epoch: 4743 cost = 0.025719879\n",
      "Validation Loss: 0.036218118\n",
      "Epoch: 4744 cost = 0.025719596\n",
      "Validation Loss: 0.03911738\n",
      "Epoch: 4745 cost = 0.025719334\n",
      "Validation Loss: 0.039021008\n",
      "Epoch: 4746 cost = 0.025719062\n",
      "Validation Loss: 0.027883401\n",
      "Epoch: 4747 cost = 0.025718805\n",
      "Validation Loss: 0.039973665\n",
      "Epoch: 4748 cost = 0.025718508\n",
      "Validation Loss: 0.041918147\n",
      "Epoch: 4749 cost = 0.025718240\n",
      "Validation Loss: 0.033496134\n",
      "Epoch: 4750 cost = 0.025717922\n",
      "Validation Loss: 0.041328393\n",
      "Epoch: 4751 cost = 0.025717624\n",
      "Validation Loss: 0.041796282\n",
      "Epoch: 4752 cost = 0.025717308\n",
      "Validation Loss: 0.038768057\n",
      "Epoch: 4753 cost = 0.025717028\n",
      "Validation Loss: 0.032257963\n",
      "Epoch: 4754 cost = 0.025716716\n",
      "Validation Loss: 0.03085371\n",
      "Epoch: 4755 cost = 0.025716447\n",
      "Validation Loss: 0.031282164\n",
      "Epoch: 4756 cost = 0.025716112\n",
      "Validation Loss: 0.034438998\n",
      "Epoch: 4757 cost = 0.025715838\n",
      "Validation Loss: 0.03564713\n",
      "Epoch: 4758 cost = 0.025715488\n",
      "Validation Loss: 0.03110458\n",
      "Epoch: 4759 cost = 0.025715236\n",
      "Validation Loss: 0.032840017\n",
      "Epoch: 4760 cost = 0.025714926\n",
      "Validation Loss: 0.030927464\n",
      "Epoch: 4761 cost = 0.025714624\n",
      "Validation Loss: 0.028831081\n",
      "Epoch: 4762 cost = 0.025714357\n",
      "Validation Loss: 0.033088736\n",
      "Epoch: 4763 cost = 0.025714066\n",
      "Validation Loss: 0.035959385\n",
      "Epoch: 4764 cost = 0.025713754\n",
      "Validation Loss: 0.031546235\n",
      "Epoch: 4765 cost = 0.025713493\n",
      "Validation Loss: 0.031760026\n",
      "Epoch: 4766 cost = 0.025713196\n",
      "Validation Loss: 0.031796522\n",
      "Epoch: 4767 cost = 0.025712879\n",
      "Validation Loss: 0.031548303\n",
      "Epoch: 4768 cost = 0.025712608\n",
      "Validation Loss: 0.0321725\n",
      "Epoch: 4769 cost = 0.025712334\n",
      "Validation Loss: 0.036055926\n",
      "Epoch: 4770 cost = 0.025712064\n",
      "Validation Loss: 0.03472528\n",
      "Epoch: 4771 cost = 0.025711742\n",
      "Validation Loss: 0.034805138\n",
      "Epoch: 4772 cost = 0.025711452\n",
      "Validation Loss: 0.033719175\n",
      "Epoch: 4773 cost = 0.025711206\n",
      "Validation Loss: 0.034899514\n",
      "Epoch: 4774 cost = 0.025710945\n",
      "Validation Loss: 0.031756114\n",
      "Epoch: 4775 cost = 0.025710604\n",
      "Validation Loss: 0.051101957\n",
      "Epoch: 4776 cost = 0.025710358\n",
      "Validation Loss: 0.044627286\n",
      "Epoch: 4777 cost = 0.025710031\n",
      "Validation Loss: 0.03764586\n",
      "Epoch: 4778 cost = 0.025709790\n",
      "Validation Loss: 0.03267999\n",
      "Epoch: 4779 cost = 0.025709461\n",
      "Validation Loss: 0.03161369\n",
      "Epoch: 4780 cost = 0.025709197\n",
      "Validation Loss: 0.032182496\n",
      "Epoch: 4781 cost = 0.025708908\n",
      "Validation Loss: 0.03238947\n",
      "Epoch: 4782 cost = 0.025708603\n",
      "Validation Loss: 0.03200656\n",
      "Epoch: 4783 cost = 0.025708322\n",
      "Validation Loss: 0.031241419\n",
      "Epoch: 4784 cost = 0.025708028\n",
      "Validation Loss: 0.029965011\n",
      "Epoch: 4785 cost = 0.025707767\n",
      "Validation Loss: 0.031354576\n",
      "Epoch: 4786 cost = 0.025707473\n",
      "Validation Loss: 0.032505933\n",
      "Epoch: 4787 cost = 0.025707213\n",
      "Validation Loss: 0.031049123\n",
      "Epoch: 4788 cost = 0.025706887\n",
      "Validation Loss: 0.036973733\n",
      "Epoch: 4789 cost = 0.025706632\n",
      "Validation Loss: 0.031814065\n",
      "Epoch: 4790 cost = 0.025706341\n",
      "Validation Loss: 0.030025447\n",
      "Epoch: 4791 cost = 0.025706031\n",
      "Validation Loss: 0.03350624\n",
      "Epoch: 4792 cost = 0.025705782\n",
      "Validation Loss: 0.032602843\n",
      "Epoch: 4793 cost = 0.025705486\n",
      "Validation Loss: 0.032209296\n",
      "Epoch: 4794 cost = 0.025705255\n",
      "Validation Loss: 0.031039527\n",
      "Epoch: 4795 cost = 0.025704941\n",
      "Validation Loss: 0.036518827\n",
      "Epoch: 4796 cost = 0.025704619\n",
      "Validation Loss: 0.03810549\n",
      "Epoch: 4797 cost = 0.025704406\n",
      "Validation Loss: 0.031983577\n",
      "Epoch: 4798 cost = 0.025704100\n",
      "Validation Loss: 0.032976493\n",
      "Epoch: 4799 cost = 0.025703819\n",
      "Validation Loss: 0.033684168\n",
      "Epoch: 4800 cost = 0.025703516\n",
      "Validation Loss: 0.035945613\n",
      "Epoch: 4801 cost = 0.025703234\n",
      "Validation Loss: 0.029903768\n",
      "Epoch: 4802 cost = 0.025703009\n",
      "Validation Loss: 0.031604126\n",
      "Epoch: 4803 cost = 0.025702681\n",
      "Validation Loss: 0.032606293\n",
      "Epoch: 4804 cost = 0.025702371\n",
      "Validation Loss: 0.05532284\n",
      "Epoch: 4805 cost = 0.025702174\n",
      "Validation Loss: 0.048592865\n",
      "Epoch: 4806 cost = 0.025701855\n",
      "Validation Loss: 0.038639158\n",
      "Epoch: 4807 cost = 0.025701562\n",
      "Validation Loss: 0.031791158\n",
      "Epoch: 4808 cost = 0.025701278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.031354666\n",
      "Epoch: 4809 cost = 0.025701035\n",
      "Validation Loss: 0.0325366\n",
      "Epoch: 4810 cost = 0.025700715\n",
      "Validation Loss: 0.03396839\n",
      "Epoch: 4811 cost = 0.025700422\n",
      "Validation Loss: 0.035454873\n",
      "Epoch: 4812 cost = 0.025700159\n",
      "Validation Loss: 0.033352952\n",
      "Epoch: 4813 cost = 0.025699887\n",
      "Validation Loss: 0.03148126\n",
      "Epoch: 4814 cost = 0.025699596\n",
      "Validation Loss: 0.03362192\n",
      "Epoch: 4815 cost = 0.025699294\n",
      "Validation Loss: 0.03322642\n",
      "Epoch: 4816 cost = 0.025699008\n",
      "Validation Loss: 0.031090552\n",
      "Epoch: 4817 cost = 0.025698744\n",
      "Validation Loss: 0.029092768\n",
      "Epoch: 4818 cost = 0.025698432\n",
      "Validation Loss: 0.0298952\n",
      "Epoch: 4819 cost = 0.025698222\n",
      "Validation Loss: 0.03209471\n",
      "Epoch: 4820 cost = 0.025697878\n",
      "Validation Loss: 0.03435915\n",
      "Epoch: 4821 cost = 0.025697596\n",
      "Validation Loss: 0.032456942\n",
      "Epoch: 4822 cost = 0.025697362\n",
      "Validation Loss: 0.031812042\n",
      "Epoch: 4823 cost = 0.025697055\n",
      "Validation Loss: 0.029467853\n",
      "Epoch: 4824 cost = 0.025696802\n",
      "Validation Loss: 0.034414213\n",
      "Epoch: 4825 cost = 0.025696509\n",
      "Validation Loss: 0.031342696\n",
      "Epoch: 4826 cost = 0.025696218\n",
      "Validation Loss: 0.036263477\n",
      "Epoch: 4827 cost = 0.025695950\n",
      "Validation Loss: 0.03869732\n",
      "Epoch: 4828 cost = 0.025695686\n",
      "Validation Loss: 0.039670438\n",
      "Epoch: 4829 cost = 0.025695376\n",
      "Validation Loss: 0.03483076\n",
      "Epoch: 4830 cost = 0.025695112\n",
      "Validation Loss: 0.031091569\n",
      "Epoch: 4831 cost = 0.025694835\n",
      "Validation Loss: 0.032434747\n",
      "Epoch: 4832 cost = 0.025694542\n",
      "Validation Loss: 0.030440599\n",
      "Epoch: 4833 cost = 0.025694305\n",
      "Validation Loss: 0.030577917\n",
      "Epoch: 4834 cost = 0.025694008\n",
      "Validation Loss: 0.03195665\n",
      "Epoch: 4835 cost = 0.025693704\n",
      "Validation Loss: 0.034220155\n",
      "Epoch: 4836 cost = 0.025693448\n",
      "Validation Loss: 0.033031445\n",
      "Epoch: 4837 cost = 0.025693199\n",
      "Validation Loss: 0.034015696\n",
      "Epoch: 4838 cost = 0.025692896\n",
      "Validation Loss: 0.035452027\n",
      "Epoch: 4839 cost = 0.025692585\n",
      "Validation Loss: 0.043670245\n",
      "Epoch: 4840 cost = 0.025692330\n",
      "Validation Loss: 0.054717697\n",
      "Epoch: 4841 cost = 0.025692064\n",
      "Validation Loss: 0.043131206\n",
      "Epoch: 4842 cost = 0.025691743\n",
      "Validation Loss: 0.037054446\n",
      "Epoch: 4843 cost = 0.025691480\n",
      "Validation Loss: 0.038465373\n",
      "Epoch: 4844 cost = 0.025691213\n",
      "Validation Loss: 0.048780452\n",
      "Epoch: 4845 cost = 0.025690931\n",
      "Validation Loss: 0.05654738\n",
      "Epoch: 4846 cost = 0.025690673\n",
      "Validation Loss: 0.044452764\n",
      "Epoch: 4847 cost = 0.025690403\n",
      "Validation Loss: 0.037815586\n",
      "Epoch: 4848 cost = 0.025690084\n",
      "Validation Loss: 0.045163833\n",
      "Epoch: 4849 cost = 0.025689842\n",
      "Validation Loss: 0.040944614\n",
      "Epoch: 4850 cost = 0.025689555\n",
      "Validation Loss: 0.030464357\n",
      "Epoch: 4851 cost = 0.025689268\n",
      "Validation Loss: 0.034994405\n",
      "Epoch: 4852 cost = 0.025688996\n",
      "Validation Loss: 0.035912722\n",
      "Epoch: 4853 cost = 0.025688692\n",
      "Validation Loss: 0.03873581\n",
      "Epoch: 4854 cost = 0.025688441\n",
      "Validation Loss: 0.057534054\n",
      "Epoch: 4855 cost = 0.025688173\n",
      "Validation Loss: 0.047131512\n",
      "Epoch: 4856 cost = 0.025687835\n",
      "Validation Loss: 0.038819984\n",
      "Epoch: 4857 cost = 0.025687570\n",
      "Validation Loss: 0.046301086\n",
      "Epoch: 4858 cost = 0.025687312\n",
      "Validation Loss: 0.085601725\n",
      "Epoch: 4859 cost = 0.025686976\n",
      "Validation Loss: 0.05598761\n",
      "Epoch: 4860 cost = 0.025686756\n",
      "Validation Loss: 0.051226676\n",
      "Epoch: 4861 cost = 0.025686437\n",
      "Validation Loss: 0.042125236\n",
      "Epoch: 4862 cost = 0.025686218\n",
      "Validation Loss: 0.033148613\n",
      "Epoch: 4863 cost = 0.025685910\n",
      "Validation Loss: 0.034097563\n",
      "Epoch: 4864 cost = 0.025685622\n",
      "Validation Loss: 0.036095176\n",
      "Epoch: 4865 cost = 0.025685340\n",
      "Validation Loss: 0.041766323\n",
      "Epoch: 4866 cost = 0.025685097\n",
      "Validation Loss: 0.04090549\n",
      "Epoch: 4867 cost = 0.025684802\n",
      "Validation Loss: 0.038290657\n",
      "Epoch: 4868 cost = 0.025684522\n",
      "Validation Loss: 0.03538005\n",
      "Epoch: 4869 cost = 0.025684234\n",
      "Validation Loss: 0.03119406\n",
      "Epoch: 4870 cost = 0.025683965\n",
      "Validation Loss: 0.033552464\n",
      "Epoch: 4871 cost = 0.025683695\n",
      "Validation Loss: 0.034198854\n",
      "Epoch: 4872 cost = 0.025683372\n",
      "Validation Loss: 0.03259249\n",
      "Epoch: 4873 cost = 0.025683096\n",
      "Validation Loss: 0.037217475\n",
      "Epoch: 4874 cost = 0.025682809\n",
      "Validation Loss: 0.03730916\n",
      "Epoch: 4875 cost = 0.025682560\n",
      "Validation Loss: 0.033664364\n",
      "Epoch: 4876 cost = 0.025682274\n",
      "Validation Loss: 0.0328325\n",
      "Epoch: 4877 cost = 0.025681981\n",
      "Validation Loss: 0.03012823\n",
      "Epoch: 4878 cost = 0.025681707\n",
      "Validation Loss: 0.037031706\n",
      "Epoch: 4879 cost = 0.025681390\n",
      "Validation Loss: 0.033258367\n",
      "Epoch: 4880 cost = 0.025681151\n",
      "Validation Loss: 0.037055057\n",
      "Epoch: 4881 cost = 0.025680802\n",
      "Validation Loss: 0.03528482\n",
      "Epoch: 4882 cost = 0.025680541\n",
      "Validation Loss: 0.0325474\n",
      "Epoch: 4883 cost = 0.025680273\n",
      "Validation Loss: 0.037503164\n",
      "Epoch: 4884 cost = 0.025679995\n",
      "Validation Loss: 0.045979682\n",
      "Epoch: 4885 cost = 0.025679682\n",
      "Validation Loss: 0.04381101\n",
      "Epoch: 4886 cost = 0.025679447\n",
      "Validation Loss: 0.056502346\n",
      "Epoch: 4887 cost = 0.025679150\n",
      "Validation Loss: 0.058181554\n",
      "Epoch: 4888 cost = 0.025678876\n",
      "Validation Loss: 0.04912981\n",
      "Epoch: 4889 cost = 0.025678636\n",
      "Validation Loss: 0.04771627\n",
      "Epoch: 4890 cost = 0.025678310\n",
      "Validation Loss: 0.050671525\n",
      "Epoch: 4891 cost = 0.025677947\n",
      "Validation Loss: 0.06819672\n",
      "Epoch: 4892 cost = 0.025677731\n",
      "Validation Loss: 0.04723282\n",
      "Epoch: 4893 cost = 0.025677436\n",
      "Validation Loss: 0.03267713\n",
      "Epoch: 4894 cost = 0.025677142\n",
      "Validation Loss: 0.041939337\n",
      "Epoch: 4895 cost = 0.025676874\n",
      "Validation Loss: 0.057311572\n",
      "Epoch: 4896 cost = 0.025676595\n",
      "Validation Loss: 0.04770005\n",
      "Epoch: 4897 cost = 0.025676376\n",
      "Validation Loss: 0.03722577\n",
      "Epoch: 4898 cost = 0.025676046\n",
      "Validation Loss: 0.037724264\n",
      "Epoch: 4899 cost = 0.025675757\n",
      "Validation Loss: 0.034126516\n",
      "Epoch: 4900 cost = 0.025675514\n",
      "Validation Loss: 0.036273524\n",
      "Epoch: 4901 cost = 0.025675179\n",
      "Validation Loss: 0.03213292\n",
      "Epoch: 4902 cost = 0.025674937\n",
      "Validation Loss: 0.02989076\n",
      "Epoch: 4903 cost = 0.025674643\n",
      "Validation Loss: 0.030820822\n",
      "Epoch: 4904 cost = 0.025674337\n",
      "Validation Loss: 0.039116573\n",
      "Epoch: 4905 cost = 0.025674089\n",
      "Validation Loss: 0.034711562\n",
      "Epoch: 4906 cost = 0.025673757\n",
      "Validation Loss: 0.036461793\n",
      "Epoch: 4907 cost = 0.025673478\n",
      "Validation Loss: 0.034705054\n",
      "Epoch: 4908 cost = 0.025673191\n",
      "Validation Loss: 0.03977315\n",
      "Epoch: 4909 cost = 0.025672962\n",
      "Validation Loss: 0.03729773\n",
      "Epoch: 4910 cost = 0.025672653\n",
      "Validation Loss: 0.03446778\n",
      "Epoch: 4911 cost = 0.025672385\n",
      "Validation Loss: 0.034012325\n",
      "Epoch: 4912 cost = 0.025672071\n",
      "Validation Loss: 0.030276654\n",
      "Epoch: 4913 cost = 0.025671768\n",
      "Validation Loss: 0.029004887\n",
      "Epoch: 4914 cost = 0.025671533\n",
      "Validation Loss: 0.030631078\n",
      "Epoch: 4915 cost = 0.025671241\n",
      "Validation Loss: 0.030880038\n",
      "Epoch: 4916 cost = 0.025670972\n",
      "Validation Loss: 0.030918024\n",
      "Epoch: 4917 cost = 0.025670668\n",
      "Validation Loss: 0.028840251\n",
      "Epoch: 4918 cost = 0.025670371\n",
      "Validation Loss: 0.029569104\n",
      "Epoch: 4919 cost = 0.025670065\n",
      "Validation Loss: 0.03591765\n",
      "Epoch: 4920 cost = 0.025669841\n",
      "Validation Loss: 0.03431404\n",
      "Epoch: 4921 cost = 0.025669517\n",
      "Validation Loss: 0.034557853\n",
      "Epoch: 4922 cost = 0.025669249\n",
      "Validation Loss: 0.03623945\n",
      "Epoch: 4923 cost = 0.025668950\n",
      "Validation Loss: 0.031630818\n",
      "Epoch: 4924 cost = 0.025668660\n",
      "Validation Loss: 0.03502674\n",
      "Epoch: 4925 cost = 0.025668358\n",
      "Validation Loss: 0.069246516\n",
      "Epoch: 4926 cost = 0.025668147\n",
      "Validation Loss: 0.047524083\n",
      "Epoch: 4927 cost = 0.025667862\n",
      "Validation Loss: 0.02847647\n",
      "Epoch: 4928 cost = 0.025667570\n",
      "Validation Loss: 0.029001804\n",
      "Epoch: 4929 cost = 0.025667269\n",
      "Validation Loss: 0.035509814\n",
      "Epoch: 4930 cost = 0.025666999\n",
      "Validation Loss: 0.03872386\n",
      "Epoch: 4931 cost = 0.025666751\n",
      "Validation Loss: 0.03605384\n",
      "Epoch: 4932 cost = 0.025666433\n",
      "Validation Loss: 0.037723787\n",
      "Epoch: 4933 cost = 0.025666085\n",
      "Validation Loss: 0.031292897\n",
      "Epoch: 4934 cost = 0.025665876\n",
      "Validation Loss: 0.03175857\n",
      "Epoch: 4935 cost = 0.025665590\n",
      "Validation Loss: 0.031239444\n",
      "Epoch: 4936 cost = 0.025665276\n",
      "Validation Loss: 0.037177093\n",
      "Epoch: 4937 cost = 0.025665043\n",
      "Validation Loss: 0.039908547\n",
      "Epoch: 4938 cost = 0.025664729\n",
      "Validation Loss: 0.031592447\n",
      "Epoch: 4939 cost = 0.025664460\n",
      "Validation Loss: 0.030947715\n",
      "Epoch: 4940 cost = 0.025664133\n",
      "Validation Loss: 0.03851574\n",
      "Epoch: 4941 cost = 0.025663902\n",
      "Validation Loss: 0.056926247\n",
      "Epoch: 4942 cost = 0.025663598\n",
      "Validation Loss: 0.05203698\n",
      "Epoch: 4943 cost = 0.025663369\n",
      "Validation Loss: 0.04190359\n",
      "Epoch: 4944 cost = 0.025663090\n",
      "Validation Loss: 0.03653112\n",
      "Epoch: 4945 cost = 0.025662740\n",
      "Validation Loss: 0.038726747\n",
      "Epoch: 4946 cost = 0.025662512\n",
      "Validation Loss: 0.045144033\n",
      "Epoch: 4947 cost = 0.025662204\n",
      "Validation Loss: 0.061155487\n",
      "Epoch: 4948 cost = 0.025661909\n",
      "Validation Loss: 0.05102256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4949 cost = 0.025661662\n",
      "Validation Loss: 0.045727447\n",
      "Epoch: 4950 cost = 0.025661345\n",
      "Validation Loss: 0.035009094\n",
      "Epoch: 4951 cost = 0.025661090\n",
      "Validation Loss: 0.032567747\n",
      "Epoch: 4952 cost = 0.025660848\n",
      "Validation Loss: 0.035573073\n",
      "Epoch: 4953 cost = 0.025660504\n",
      "Validation Loss: 0.035532095\n",
      "Epoch: 4954 cost = 0.025660236\n",
      "Validation Loss: 0.03710632\n",
      "Epoch: 4955 cost = 0.025659948\n",
      "Validation Loss: 0.039207585\n",
      "Epoch: 4956 cost = 0.025659653\n",
      "Validation Loss: 0.03518027\n",
      "Epoch: 4957 cost = 0.025659388\n",
      "Validation Loss: 0.03187885\n",
      "Epoch: 4958 cost = 0.025659108\n",
      "Validation Loss: 0.036987577\n",
      "Epoch: 4959 cost = 0.025658814\n",
      "Validation Loss: 0.032920342\n",
      "Epoch: 4960 cost = 0.025658572\n",
      "Validation Loss: 0.037252046\n",
      "Epoch: 4961 cost = 0.025658301\n",
      "Validation Loss: 0.039110024\n",
      "Epoch: 4962 cost = 0.025657991\n",
      "Validation Loss: 0.034507435\n",
      "Epoch: 4963 cost = 0.025657697\n",
      "Validation Loss: 0.0392993\n",
      "Epoch: 4964 cost = 0.025657396\n",
      "Validation Loss: 0.039733857\n",
      "Epoch: 4965 cost = 0.025657117\n",
      "Validation Loss: 0.03872227\n",
      "Epoch: 4966 cost = 0.025656800\n",
      "Validation Loss: 0.039360177\n",
      "Epoch: 4967 cost = 0.025656545\n",
      "Validation Loss: 0.03884733\n",
      "Epoch: 4968 cost = 0.025656255\n",
      "Validation Loss: 0.033436224\n",
      "Epoch: 4969 cost = 0.025655958\n",
      "Validation Loss: 0.031376995\n",
      "Epoch: 4970 cost = 0.025655696\n",
      "Validation Loss: 0.03267525\n",
      "Epoch: 4971 cost = 0.025655379\n",
      "Validation Loss: 0.040339377\n",
      "Epoch: 4972 cost = 0.025655083\n",
      "Validation Loss: 0.040479578\n",
      "Epoch: 4973 cost = 0.025654844\n",
      "Validation Loss: 0.03101166\n",
      "Epoch: 4974 cost = 0.025654569\n",
      "Validation Loss: 0.032380097\n",
      "Epoch: 4975 cost = 0.025654261\n",
      "Validation Loss: 0.035225756\n",
      "Epoch: 4976 cost = 0.025654007\n",
      "Validation Loss: 0.03321381\n",
      "Epoch: 4977 cost = 0.025653677\n",
      "Validation Loss: 0.033568256\n",
      "Epoch: 4978 cost = 0.025653321\n",
      "Validation Loss: 0.04132042\n",
      "Epoch: 4979 cost = 0.025653124\n",
      "Validation Loss: 0.036158014\n",
      "Epoch: 4980 cost = 0.025652815\n",
      "Validation Loss: 0.031792812\n",
      "Epoch: 4981 cost = 0.025652510\n",
      "Validation Loss: 0.033345565\n",
      "Epoch: 4982 cost = 0.025652205\n",
      "Validation Loss: 0.03567387\n",
      "Epoch: 4983 cost = 0.025651964\n",
      "Validation Loss: 0.03444237\n",
      "Epoch: 4984 cost = 0.025651610\n",
      "Validation Loss: 0.030961031\n",
      "Epoch: 4985 cost = 0.025651349\n",
      "Validation Loss: 0.027774975\n",
      "Epoch: 4986 cost = 0.025651067\n",
      "Validation Loss: 0.035030715\n",
      "Epoch: 4987 cost = 0.025650753\n",
      "Validation Loss: 0.03123206\n",
      "Epoch: 4988 cost = 0.025650490\n",
      "Validation Loss: 0.036279097\n",
      "Epoch: 4989 cost = 0.025650185\n",
      "Validation Loss: 0.040808484\n",
      "Epoch: 4990 cost = 0.025649872\n",
      "Validation Loss: 0.036670968\n",
      "Epoch: 4991 cost = 0.025649597\n",
      "Validation Loss: 0.03646812\n",
      "Epoch: 4992 cost = 0.025649309\n",
      "Validation Loss: 0.032546226\n",
      "Epoch: 4993 cost = 0.025649015\n",
      "Validation Loss: 0.031116087\n",
      "Epoch: 4994 cost = 0.025648704\n",
      "Validation Loss: 0.031267796\n",
      "Epoch: 4995 cost = 0.025648432\n",
      "Validation Loss: 0.03995022\n",
      "Epoch: 4996 cost = 0.025648147\n",
      "Validation Loss: 0.04103269\n",
      "Epoch: 4997 cost = 0.025647873\n",
      "Validation Loss: 0.029919356\n",
      "Epoch: 4998 cost = 0.025647590\n",
      "Validation Loss: 0.03359118\n",
      "Epoch: 4999 cost = 0.025647280\n",
      "Validation Loss: 0.0332586\n",
      "Epoch: 5000 cost = 0.025647026\n",
      "Validation Loss: 0.034368873\n",
      "Optimization Finished!\n",
      "Test Loss: 0.034480486\n"
     ]
    }
   ],
   "source": [
    "#we store the variables here\n",
    "log_files_path = 'C:/Users/yy2895/Desktop/st19-15-19/tmp/model.ckpt'\n",
    "def layer_batch_normalization(x, n_out, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - n_out: integer, depth of input maps - number of sample in the batch \n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - batch-normalized maps   \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    beta_init = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_init)\n",
    "    \n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_init)\n",
    "\n",
    "    #tf.nn.moment: https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "    #calculate mean and variance of x\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "    \n",
    "    #tf.train.ExponentialMovingAverage:\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
    "    #Maintains moving averages of variables by employing an exponential decay.\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    \n",
    "    def mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "        \n",
    "    #tf.cond: https://www.tensorflow.org/api_docs/python/tf/cond\n",
    "    #Return true_fn() if the predicate pred is true else false_fn()\n",
    "    mean, var = tf.cond(phase_train, mean_var_with_update, lambda: (ema_mean, ema_var))\n",
    "    \n",
    "    \n",
    "    #Here, we changesd the shape of x into [[[x1]],[[x2] ],....]\n",
    "\n",
    "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var, beta, gamma, 1e-3, True)\n",
    "    \n",
    "    return tf.reshape(normed, [-1, n_out])\n",
    "\n",
    "def layer(x, weight_shape, bias_shape, phase_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape the the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize weights\n",
    "    weight_init = tf.random_normal_initializer(stddev=(1.0/weight_shape[0])**0.5)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    \n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "\n",
    "    logits = tf.matmul(x, W) + b\n",
    "    \n",
    "    #apply the non-linear function after the batch normalization\n",
    "    return tf.nn.sigmoid(layer_batch_normalization(logits, weight_shape[1], phase_train))\n",
    "def encoder(x, n_code, phase_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the network encoder part\n",
    "    input:\n",
    "        - x: input vector of the encoder\n",
    "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder)\n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector: reduced dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope(\"code\"):\n",
    "            output = layer(x, [19, n_code], [n_code], phase_train)\n",
    "\n",
    "\n",
    "    return output\n",
    "\n",
    "def decoder(x, n_code, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network encoder part\n",
    "    input:\n",
    "        - x: input vector of the decoder - reduced dimension vector\n",
    "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder) \n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector: reconstructed dimension of the initial vector\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        \n",
    "   \n",
    "        with tf.variable_scope(\"output\"):\n",
    "            output = layer(x, [ n_code, 19], [19], phase_train)\n",
    "\n",
    "    return output\n",
    "def loss(output, x):\n",
    "    \"\"\"\n",
    "    Compute the loss of the auto-encoder\n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the decoder\n",
    "        - x: true value of the sample batch - this is the input of the encoder\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"training\"):\n",
    "        \n",
    "        l2 = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x)), 1))\n",
    "        train_loss = tf.reduce_mean(l2)\n",
    "        train_summary_op = tf.summary.scalar(\"train_cost\", train_loss)\n",
    "        return train_loss, train_summary_op\n",
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op\n",
    "def evaluate(output, x):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        -output: prediction vector of the network for the validation set\n",
    "        -x: true value for the validation set\n",
    "    output:\n",
    "        - val_loss: loss of the autoencoder\n",
    "        - in_image_op: input image \n",
    "        - out_image_op:reconstructed image \n",
    "        - val_summary_op: summary of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"validation\"):\n",
    "        \n",
    "        #in_image_op = image_summary(\"input_image\", x)\n",
    "        \n",
    "        #out_image_op = image_summary(\"output_image\", output)\n",
    "        \n",
    "        l2_norm = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x, name=\"val_diff\")), 1))\n",
    "        \n",
    "        val_loss = tf.reduce_mean(l2_norm)\n",
    "        \n",
    "        val_summary_op = tf.summary.scalar(\"val_cost\", val_loss)\n",
    "        \n",
    "        #return val_loss, in_image_op, out_image_op, val_summary_op\n",
    "        return val_loss,  val_summary_op\n",
    "\"\"\"\n",
    "def image_summary(label, tensor):\n",
    "    #tf.summary.image: https://www.tensorflow.org/api_docs/python/tf/summary/image\n",
    "    #Outputs a Summary protocol buffer with images.\n",
    "\n",
    "    tensor_reshaped = tf.reshape(tensor, [-1, 19, 1, 1])\n",
    "    return tf.summary.image(label, tensor_reshaped)\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    print('we begin')\n",
    "\n",
    "    #if a python file, please use the 4 lines bellow and comment the \"n_code = '2'\"\n",
    "    #parser = argparse.ArgumentParser(description='Autoencoder')\n",
    "    #parser.add_argument('n_code', nargs=1, type=str)\n",
    "    #args = parser.parse_args(['--help'])\n",
    "    #n_code = args.n_code[0]\n",
    "    \n",
    "    #if a jupyter file, please comment the 4 above and use the one bellow\n",
    "    n_code = '15'\n",
    "    \n",
    "    #feel free to change with your own \n",
    "    #log_files_path = r'C:\\Users\\yy2895\\Desktop\\pys'\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.variable_scope(\"autoencoder_model\"):\n",
    "\n",
    "            #the input variables are first define as placeholder \n",
    "            # a placeholder is a variable/data which will be assigned later \n",
    "            # image vector & label, phase_train is a boolean \n",
    "            x = tf.placeholder(\"float\", [None, 19]) # MNIST data image of shape 28*28=784\n",
    "            \n",
    "            phase_train = tf.placeholder(tf.bool)\n",
    "            \n",
    "            #define the encoder \n",
    "            code = encoder(x, int(n_code), phase_train)\n",
    "            \n",
    "            #define the decoder\n",
    "            output = decoder(code, int(n_code), phase_train)\n",
    "            \n",
    "            #compute the loss \n",
    "            cost, train_summary_op = loss(output, x)\n",
    "\n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "            train_op = training(cost, global_step)\n",
    "\n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            #eval_op, in_image_op, out_image_op, val_summary_op = evaluate(output, x)\n",
    "            eval_op, val_summary_op = evaluate(output, x)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "\n",
    "            #save and restore variables to and from checkpoints.\n",
    "            #saver = tf.train.Saver(max_to_keep=200)\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "\n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            #train_writer = tf.summary.FileWriter(log_files_path+'mnist_autoencoder_hidden_' + n_code + '_logs/', graph=sess.graph)\n",
    "\n",
    "            #val_writer   = tf.summary.FileWriter(log_files_path+'mnist_autoencoder_hidden_' + n_code + '_logs/', graph=sess.graph)\n",
    "\n",
    "            #initialization of the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "\n",
    "            sess.run(init_op)\n",
    "            currentmin=10000000000\n",
    "            currentmin_index=-1\n",
    "            error_path=[]\n",
    "            togive2=[]\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                #total_batch = int(numberofsamples/batch_size)\n",
    "                \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "                    \n",
    "                    minibatch_x= trainset[i]\n",
    "                    \n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    _, new_cost, train_summary = sess.run([train_op, cost, train_summary_op], feed_dict={x: minibatch_x, phase_train: True})\n",
    "                    \n",
    "                    #train_writer.add_summary(train_summary, sess.run(global_step))\n",
    "                    \n",
    "                    # Compute average loss\n",
    "                    avg_cost += new_cost/total_batch\n",
    "                    \n",
    "                \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:0.9f}\".format(avg_cost))\n",
    "\n",
    "                    #the accuracy is evaluated using the validation dataset\n",
    "                    #train_writer.add_summary(train_summary, sess.run(global_step))\n",
    "\n",
    "                    #validation_loss, in_image, out_image, val_summary = sess.run([eval_op, in_image_op, out_image_op, val_summary_op], feed_dict={x: validationset, phase_train: False})\n",
    "                    validation_loss,  val_summary = sess.run([eval_op, val_summary_op], feed_dict={x: validationset, phase_train: False})\n",
    "                    #val_writer.add_summary(in_image, sess.run(global_step))\n",
    "                    #val_writer.add_summary(out_image, sess.run(global_step))\n",
    "                    #val_writer.add_summary(val_summary, sess.run(global_step))\n",
    "                    print(\"Validation Loss:\", validation_loss)\n",
    "                    error_path.append(validation_loss)\n",
    "                    \n",
    "                    if validation_loss<currentmin:\n",
    "                        currentmin=validation_loss\n",
    "                        currentmin_index=epoch\n",
    "                        saver.save(sess, 'C:/Users/yy2895/Desktop/st19-15-19/tmp/model.ckpt')\n",
    "                        togive8=[]\n",
    "                        for i in range(len(d)):\n",
    "                            any_image = d[i].reshape(-1,19)\n",
    "                            output_any_image = sess.run(code,feed_dict={x:any_image,phase_train: False})\n",
    "                            togive8.append(output_any_image)\n",
    "                            \n",
    "                        togive2=togive8\n",
    "                    #save to use later\n",
    "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "                    #saver.save(sess, 'C:/Users/yy2895/Desktop/st19-14-19/tmp/model.ckpt')\n",
    "                    \n",
    "\n",
    "            print(\"Optimization Finished!\")\n",
    "\n",
    "            test_loss = sess.run(eval_op, feed_dict={x: testset, phase_train: False})\n",
    "            #nps_loss = sess.run(eval_op, feed_dict={x: mnist.validation.images, phase_train: False})\n",
    "            print(\"Test Loss:\", test_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027774975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.01276377, 0.8053072 , 0.42155513, 0.5055225 , 0.7092401 ,\n",
       "         0.94296   , 0.283776  , 0.4910083 , 0.9192298 , 0.95906043,\n",
       "         0.04284439, 0.6582974 , 0.386457  , 0.8570693 , 0.50587106]],\n",
       "       dtype=float32),\n",
       " array([[0.00948077, 0.8023985 , 0.44545788, 0.52687234, 0.71887267,\n",
       "         0.9568662 , 0.2899333 , 0.50239754, 0.929103  , 0.97104275,\n",
       "         0.03338652, 0.6911974 , 0.4010063 , 0.8324401 , 0.525347  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01390988, 0.7622969 , 0.42391008, 0.46666253, 0.7324156 ,\n",
       "         0.94664097, 0.4167286 , 0.5462175 , 0.9072104 , 0.95939344,\n",
       "         0.03864054, 0.62672895, 0.49858832, 0.8072751 , 0.56141484]],\n",
       "       dtype=float32),\n",
       " array([[0.01081361, 0.7978565 , 0.412372  , 0.47122818, 0.73125196,\n",
       "         0.9564731 , 0.4608774 , 0.5401551 , 0.93310535, 0.9689599 ,\n",
       "         0.03153424, 0.45797515, 0.5257955 , 0.8137742 , 0.54287237]],\n",
       "       dtype=float32),\n",
       " array([[0.01727001, 0.78246176, 0.37758967, 0.4010683 , 0.7333381 ,\n",
       "         0.94064623, 0.6035381 , 0.5598097 , 0.9281637 , 0.9520658 ,\n",
       "         0.03861342, 0.2889561 , 0.6314596 , 0.80992645, 0.55416703]],\n",
       "       dtype=float32),\n",
       " array([[0.01462001, 0.77609086, 0.4069197 , 0.42690197, 0.7384723 ,\n",
       "         0.94745123, 0.5046363 , 0.5652738 , 0.9270402 , 0.9593709 ,\n",
       "         0.03479324, 0.4679951 , 0.593661  , 0.79270655, 0.5658388 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01709144, 0.7774832 , 0.38879982, 0.42682913, 0.7381827 ,\n",
       "         0.9427432 , 0.6274919 , 0.5727398 , 0.91272646, 0.9525453 ,\n",
       "         0.03675772, 0.30606934, 0.6405095 , 0.7856476 , 0.56849825]],\n",
       "       dtype=float32),\n",
       " array([[0.01331819, 0.7807876 , 0.3937413 , 0.38155112, 0.7460286 ,\n",
       "         0.95078987, 0.61235577, 0.5848653 , 0.92855126, 0.9631067 ,\n",
       "         0.02995978, 0.37661767, 0.63516086, 0.7694848 , 0.5761877 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01614715, 0.7578967 , 0.3868168 , 0.3893174 , 0.7403047 ,\n",
       "         0.94272006, 0.5665978 , 0.5773283 , 0.9190216 , 0.95472693,\n",
       "         0.03752566, 0.44966617, 0.6156251 , 0.786314  , 0.5830769 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01376856, 0.7921404 , 0.39042377, 0.41007218, 0.7422021 ,\n",
       "         0.94992703, 0.53548247, 0.5785314 , 0.9304795 , 0.9619215 ,\n",
       "         0.03134433, 0.4847464 , 0.6321756 , 0.77471125, 0.5690368 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02783313, 0.748485  , 0.3615661 , 0.29410037, 0.7567987 ,\n",
       "         0.9250873 , 0.77830696, 0.6290413 , 0.9229352 , 0.931252  ,\n",
       "         0.03919141, 0.24554543, 0.7852037 , 0.7417524 , 0.60107785]],\n",
       "       dtype=float32),\n",
       " array([[0.04692927, 0.72669524, 0.346867  , 0.26314443, 0.7551633 ,\n",
       "         0.8944849 , 0.85440403, 0.63709605, 0.90098673, 0.8876604 ,\n",
       "         0.04813997, 0.06937836, 0.82343584, 0.7459661 , 0.6123236 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06333183, 0.68820775, 0.34861973, 0.27330044, 0.75206417,\n",
       "         0.872261  , 0.85874486, 0.6415986 , 0.8759306 , 0.85193807,\n",
       "         0.06129847, 0.08495051, 0.8272046 , 0.74227124, 0.63104934]],\n",
       "       dtype=float32),\n",
       " array([[0.07072753, 0.6783489 , 0.34038365, 0.2626428 , 0.75731456,\n",
       "         0.86879504, 0.86947215, 0.6636317 , 0.8791412 , 0.842025  ,\n",
       "         0.06229461, 0.05520446, 0.8489926 , 0.7337666 , 0.6439814 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08231664, 0.6946942 , 0.3214195 , 0.21770124, 0.7575542 ,\n",
       "         0.85651976, 0.93756723, 0.6789447 , 0.91162485, 0.824018  ,\n",
       "         0.06330386, 0.01840726, 0.899024  , 0.7285523 , 0.6433569 ]],\n",
       "       dtype=float32),\n",
       " array([[0.13228491, 0.6688389 , 0.31613854, 0.19564481, 0.7549358 ,\n",
       "         0.80240804, 0.94071734, 0.6800667 , 0.88439906, 0.734835  ,\n",
       "         0.07792834, 0.0105023 , 0.90508926, 0.7343814 , 0.651051  ]],\n",
       "       dtype=float32),\n",
       " array([[0.04617698, 0.69497937, 0.35917088, 0.24202587, 0.7536229 ,\n",
       "         0.8868081 , 0.83791715, 0.66200566, 0.914477  , 0.88469315,\n",
       "         0.05341271, 0.13093919, 0.8048999 , 0.72989905, 0.64759964]],\n",
       "       dtype=float32),\n",
       " array([[0.09349954, 0.63687825, 0.3270814 , 0.1869619 , 0.7588987 ,\n",
       "         0.819965  , 0.82491016, 0.682548  , 0.86231434, 0.78667176,\n",
       "         0.07907466, 0.20186293, 0.8133881 , 0.7359511 , 0.66141707]],\n",
       "       dtype=float32),\n",
       " array([[0.03886756, 0.6606327 , 0.34429646, 0.20138402, 0.7659451 ,\n",
       "         0.89570194, 0.76773167, 0.68349665, 0.8993715 , 0.90111494,\n",
       "         0.05060952, 0.41100335, 0.7610515 , 0.7169498 , 0.66445416]],\n",
       "       dtype=float32),\n",
       " array([[0.07163341, 0.667922  , 0.31576797, 0.1783764 , 0.76483905,\n",
       "         0.85806096, 0.8569186 , 0.6936755 , 0.90519327, 0.8414736 ,\n",
       "         0.06158719, 0.13447297, 0.8516064 , 0.72295994, 0.66000706]],\n",
       "       dtype=float32),\n",
       " array([[0.14670648, 0.6424343 , 0.31816784, 0.17168646, 0.76172525,\n",
       "         0.78670686, 0.90089816, 0.69741696, 0.88617855, 0.71920407,\n",
       "         0.08403059, 0.06412236, 0.8968691 , 0.71474487, 0.66782147]],\n",
       "       dtype=float32),\n",
       " array([[0.12863497, 0.63418704, 0.32305157, 0.1682807 , 0.76171184,\n",
       "         0.7924263 , 0.8382018 , 0.69436413, 0.8791823 , 0.7397141 ,\n",
       "         0.08277565, 0.16580641, 0.86093366, 0.7200321 , 0.66999614]],\n",
       "       dtype=float32),\n",
       " array([[0.05862429, 0.6368659 , 0.31567925, 0.16240495, 0.76966727,\n",
       "         0.8683133 , 0.8021332 , 0.70015657, 0.88130283, 0.8622619 ,\n",
       "         0.05504364, 0.16873743, 0.79534376, 0.7187965 , 0.67929465]],\n",
       "       dtype=float32),\n",
       " array([[0.02846989, 0.65486556, 0.3302164 , 0.18765584, 0.77248937,\n",
       "         0.91421753, 0.67221177, 0.6917044 , 0.8837907 , 0.9259733 ,\n",
       "         0.03886539, 0.40159974, 0.705086  , 0.71026254, 0.6791366 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06694564, 0.6113143 , 0.2896912 , 0.1481236 , 0.77829385,\n",
       "         0.87681496, 0.922543  , 0.7356937 , 0.913961  , 0.8610366 ,\n",
       "         0.05835881, 0.02320203, 0.8827823 , 0.71480125, 0.7006293 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09813753, 0.62678295, 0.32522368, 0.1571525 , 0.7664843 ,\n",
       "         0.8254062 , 0.8988019 , 0.7018929 , 0.8792245 , 0.7918545 ,\n",
       "         0.06625288, 0.05475618, 0.85992926, 0.706331  , 0.68432456]],\n",
       "       dtype=float32),\n",
       " array([[0.03551522, 0.6615272 , 0.35762239, 0.18896288, 0.7668057 ,\n",
       "         0.89895064, 0.76383847, 0.6847958 , 0.90336686, 0.908812  ,\n",
       "         0.04265314, 0.34087655, 0.7541393 , 0.6981948 , 0.6781889 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06128233, 0.65241486, 0.32150066, 0.1535405 , 0.76856756,\n",
       "         0.868208  , 0.9160779 , 0.7086039 , 0.91677773, 0.8609374 ,\n",
       "         0.05388168, 0.0533084 , 0.86000013, 0.70644116, 0.68232584]],\n",
       "       dtype=float32),\n",
       " array([[0.11289016, 0.64373285, 0.3166217 , 0.17297442, 0.76461816,\n",
       "         0.82347906, 0.9243898 , 0.7085654 , 0.89273417, 0.7770902 ,\n",
       "         0.06838796, 0.02652365, 0.89475   , 0.70228624, 0.684226  ]],\n",
       "       dtype=float32),\n",
       " array([[0.06443474, 0.6407206 , 0.3133026 , 0.16260535, 0.770826  ,\n",
       "         0.8689948 , 0.86065245, 0.7109563 , 0.89170253, 0.85778296,\n",
       "         0.05167705, 0.06543358, 0.83967066, 0.70261294, 0.6906021 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07218406, 0.65364987, 0.3275908 , 0.19097313, 0.7654839 ,\n",
       "         0.85725886, 0.81462353, 0.70069253, 0.88831943, 0.84085095,\n",
       "         0.05980614, 0.24160066, 0.83222544, 0.6986714 , 0.68016815]],\n",
       "       dtype=float32),\n",
       " array([[0.06298814, 0.63816905, 0.3296318 , 0.17138672, 0.76660156,\n",
       "         0.8603823 , 0.81898123, 0.701081  , 0.89196926, 0.8527172 ,\n",
       "         0.05942574, 0.22028407, 0.803221  , 0.71296966, 0.68431187]],\n",
       "       dtype=float32),\n",
       " array([[0.05972587, 0.6196779 , 0.3221832 , 0.15219861, 0.77064073,\n",
       "         0.8627367 , 0.8473518 , 0.70412856, 0.87031305, 0.8569087 ,\n",
       "         0.05463224, 0.11319256, 0.787243  , 0.713344  , 0.69207895]],\n",
       "       dtype=float32),\n",
       " array([[0.03303065, 0.6396314 , 0.3333804 , 0.15876932, 0.7778315 ,\n",
       "         0.90688586, 0.72447413, 0.70789444, 0.9027379 , 0.91861075,\n",
       "         0.03951939, 0.45084432, 0.755571  , 0.69164026, 0.6927475 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02175269, 0.67240655, 0.35044548, 0.21812442, 0.77286756,\n",
       "         0.9274176 , 0.56725115, 0.68562496, 0.89064485, 0.94195706,\n",
       "         0.0344929 , 0.75837237, 0.67359984, 0.6924414 , 0.678107  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02764509, 0.69168645, 0.34195685, 0.24071965, 0.76956284,\n",
       "         0.9216324 , 0.7098377 , 0.68375206, 0.89466166, 0.93031764,\n",
       "         0.03801657, 0.49814758, 0.750067  , 0.69425714, 0.6683079 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01950538, 0.68568987, 0.35108498, 0.2374243 , 0.7720954 ,\n",
       "         0.93547654, 0.68053395, 0.679531  , 0.90010965, 0.9481895 ,\n",
       "         0.03206378, 0.4090023 , 0.7041156 , 0.7002025 , 0.6737248 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03117186, 0.66371375, 0.34798738, 0.21497764, 0.7720607 ,\n",
       "         0.91546977, 0.75694823, 0.68574774, 0.89434266, 0.9230133 ,\n",
       "         0.0386495 , 0.23610324, 0.7575162 , 0.70181006, 0.679808  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01730229, 0.69877285, 0.3567171 , 0.25932118, 0.771798  ,\n",
       "         0.94177854, 0.6593634 , 0.68070555, 0.9175814 , 0.9544983 ,\n",
       "         0.03186252, 0.58970326, 0.71763766, 0.6963048 , 0.66917574]],\n",
       "       dtype=float32),\n",
       " array([[0.0120824 , 0.6930261 , 0.35480368, 0.25258118, 0.77739483,\n",
       "         0.95407045, 0.68331426, 0.68091774, 0.89907825, 0.9670751 ,\n",
       "         0.02421927, 0.44931296, 0.68050945, 0.684306  , 0.6764375 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0185067 , 0.6718668 , 0.33720618, 0.20121998, 0.77873015,\n",
       "         0.9390389 , 0.7652627 , 0.6896829 , 0.8999262 , 0.95181656,\n",
       "         0.02893232, 0.19717418, 0.7265469 , 0.70062107, 0.68040335]],\n",
       "       dtype=float32),\n",
       " array([[0.04357088, 0.66672814, 0.3376934 , 0.20104547, 0.77356493,\n",
       "         0.9043324 , 0.87551606, 0.6933244 , 0.9041234 , 0.9026863 ,\n",
       "         0.04111541, 0.05686185, 0.84014386, 0.6960636 , 0.6789691 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03292786, 0.65787697, 0.34602198, 0.19715667, 0.7765247 ,\n",
       "         0.91607153, 0.83277184, 0.6939251 , 0.9006697 , 0.9219136 ,\n",
       "         0.03726975, 0.15407282, 0.80052906, 0.6889136 , 0.68332475]],\n",
       "       dtype=float32),\n",
       " array([[0.01829344, 0.7144085 , 0.3636224 , 0.24713637, 0.7716385 ,\n",
       "         0.94267327, 0.835065  , 0.6774202 , 0.9286604 , 0.9537409 ,\n",
       "         0.02790294, 0.14754723, 0.7915986 , 0.68685406, 0.6652732 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01649367, 0.7222564 , 0.36013877, 0.29246184, 0.7647889 ,\n",
       "         0.9441861 , 0.72336686, 0.6566902 , 0.9071646 , 0.95577025,\n",
       "         0.02935743, 0.34740952, 0.7202838 , 0.70281345, 0.65524286]],\n",
       "       dtype=float32),\n",
       " array([[0.00547607, 0.7580854 , 0.36469877, 0.28887576, 0.77335614,\n",
       "         0.9713416 , 0.52731067, 0.65998846, 0.9450385 , 0.9840395 ,\n",
       "         0.01786223, 0.83245385, 0.63163036, 0.698046  , 0.6448887 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0076095 , 0.73642844, 0.35972604, 0.2591625 , 0.7798718 ,\n",
       "         0.96513736, 0.49511975, 0.6682335 , 0.92307615, 0.97882   ,\n",
       "         0.01915668, 0.87220365, 0.6328028 , 0.6876524 , 0.65015763]],\n",
       "       dtype=float32),\n",
       " array([[0.01870944, 0.735255  , 0.3589956 , 0.22372328, 0.7764832 ,\n",
       "         0.9439943 , 0.8243674 , 0.6691942 , 0.9300079 , 0.95536596,\n",
       "         0.02388735, 0.2160496 , 0.8128734 , 0.67823505, 0.6478545 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00531401, 0.7716801 , 0.40560403, 0.30798283, 0.77425575,\n",
       "         0.9730549 , 0.5965057 , 0.64149225, 0.9464981 , 0.9849183 ,\n",
       "         0.01460931, 0.7081168 , 0.66308755, 0.67816657, 0.6352418 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01044214, 0.739558  , 0.38427675, 0.3109121 , 0.76554465,\n",
       "         0.95778316, 0.5749377 , 0.6255619 , 0.9136135 , 0.9710378 ,\n",
       "         0.02259811, 0.6215705 , 0.6439223 , 0.7175893 , 0.633673  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01478805, 0.739106  , 0.3551298 , 0.24183366, 0.7783022 ,\n",
       "         0.95356745, 0.76538473, 0.66740483, 0.93476886, 0.96491706,\n",
       "         0.02191128, 0.25420827, 0.79353136, 0.69018877, 0.6446008 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02055567, 0.71920514, 0.34941772, 0.25178993, 0.77532923,\n",
       "         0.94272006, 0.8217261 , 0.6665837 , 0.9087611 , 0.95080143,\n",
       "         0.02656203, 0.08543546, 0.7934097 , 0.70087165, 0.65099263]],\n",
       "       dtype=float32),\n",
       " array([[0.0054824 , 0.79567   , 0.4110723 , 0.36470333, 0.75225246,\n",
       "         0.96836144, 0.4804946 , 0.5935856 , 0.95578986, 0.9822844 ,\n",
       "         0.01998742, 0.60119283, 0.56257176, 0.7598359 , 0.5989446 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00441299, 0.77788186, 0.38747585, 0.27875525, 0.7775321 ,\n",
       "         0.977028  , 0.68639964, 0.63781315, 0.94670147, 0.9877564 ,\n",
       "         0.01174403, 0.38397956, 0.68653345, 0.6807061 , 0.6310391 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00462244, 0.7943505 , 0.45702395, 0.38709748, 0.7475623 ,\n",
       "         0.96796656, 0.3071238 , 0.55878896, 0.9481624 , 0.9835382 ,\n",
       "         0.02002284, 0.93442583, 0.43580118, 0.76291937, 0.5833713 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00528182, 0.8058759 , 0.37249896, 0.29376626, 0.7762615 ,\n",
       "         0.9770776 , 0.846572  , 0.64660317, 0.96821725, 0.9866807 ,\n",
       "         0.01311915, 0.13065219, 0.8122015 , 0.68703973, 0.6139578 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01862218, 0.7398678 , 0.34601006, 0.21722537, 0.7947967 ,\n",
       "         0.9604706 , 0.9651863 , 0.70593673, 0.950219  , 0.9654468 ,\n",
       "         0.01647704, 0.00891486, 0.9367304 , 0.59636974, 0.66959596]],\n",
       "       dtype=float32),\n",
       " array([[0.0181852 , 0.6749006 , 0.37748903, 0.21389379, 0.7997341 ,\n",
       "         0.9560785 , 0.91533065, 0.71634024, 0.9259444 , 0.9627792 ,\n",
       "         0.02006721, 0.1271022 , 0.8851069 , 0.59075934, 0.69149274]],\n",
       "       dtype=float32),\n",
       " array([[0.0164245 , 0.6623954 , 0.37176794, 0.2233502 , 0.7940352 ,\n",
       "         0.9557966 , 0.82343966, 0.69557726, 0.9016084 , 0.96434927,\n",
       "         0.02092218, 0.36995375, 0.82400215, 0.6176474 , 0.6871744 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01027171, 0.6575697 , 0.3559521 , 0.22698018, 0.79949397,\n",
       "         0.9692041 , 0.8280297 , 0.69873184, 0.88382494, 0.97753006,\n",
       "         0.01492384, 0.20229919, 0.8025453 , 0.60656184, 0.6976597 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0147057 , 0.6998585 , 0.31723654, 0.19691727, 0.80676585,\n",
       "         0.96704125, 0.9505533 , 0.7354595 , 0.92034584, 0.97216606,\n",
       "         0.01430218, 0.00880701, 0.91205   , 0.59457505, 0.692378  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02757291, 0.6713072 , 0.3369745 , 0.21746144, 0.7950496 ,\n",
       "         0.9470593 , 0.95399916, 0.7184186 , 0.90354407, 0.94765735,\n",
       "         0.02380321, 0.03935675, 0.91720206, 0.5926914 , 0.6923122 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00160931, 0.7906439 , 0.41882494, 0.3123299 , 0.7794334 ,\n",
       "         0.98812044, 0.57847255, 0.64283043, 0.9790866 , 0.9953387 ,\n",
       "         0.00891105, 0.8186604 , 0.6599903 , 0.67471135, 0.6343839 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01609081, 0.71591216, 0.35527948, 0.26433185, 0.7681815 ,\n",
       "         0.9472859 , 0.8227521 , 0.65217584, 0.9320915 , 0.9585261 ,\n",
       "         0.03259404, 0.32052645, 0.7657031 , 0.7339071 , 0.6345263 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01465558, 0.7006499 , 0.37725803, 0.2701726 , 0.79733497,\n",
       "         0.9641872 , 0.85283154, 0.6949936 , 0.89144415, 0.97022724,\n",
       "         0.0160097 , 0.24159646, 0.85411644, 0.5907942 , 0.6742477 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00257229, 0.7438503 , 0.42585894, 0.33178842, 0.80410236,\n",
       "         0.98898274, 0.70368224, 0.6796041 , 0.9411055 , 0.9944147 ,\n",
       "         0.00606716, 0.604843  , 0.78424335, 0.54746574, 0.67668957]],\n",
       "       dtype=float32),\n",
       " array([[0.00509835, 0.75743234, 0.4322998 , 0.3303823 , 0.79688793,\n",
       "         0.9814502 , 0.7228136 , 0.6716225 , 0.939901  , 0.98874205,\n",
       "         0.00954708, 0.6259695 , 0.79967815, 0.5881366 , 0.6500514 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00264306, 0.7962317 , 0.49157953, 0.40186065, 0.7620184 ,\n",
       "         0.98102194, 0.29482543, 0.5724354 , 0.96372926, 0.991606  ,\n",
       "         0.01275548, 0.981189  , 0.4968357 , 0.7194682 , 0.58754146]],\n",
       "       dtype=float32),\n",
       " array([[0.00198315, 0.78538734, 0.529041  , 0.48196408, 0.7315928 ,\n",
       "         0.9774704 , 0.06612331, 0.47367254, 0.94342864, 0.9911919 ,\n",
       "         0.01803271, 0.993519  , 0.16171068, 0.83162683, 0.547825  ]],\n",
       "       dtype=float32),\n",
       " array([[0.00162017, 0.7828802 , 0.51796395, 0.4254013 , 0.76877666,\n",
       "         0.9861752 , 0.13725561, 0.52960515, 0.92226887, 0.99451435,\n",
       "         0.00807288, 0.977216  , 0.30188617, 0.733067  , 0.5787034 ]],\n",
       "       dtype=float32),\n",
       " array([[2.8611417e-04, 7.9993570e-01, 5.6370544e-01, 4.5286667e-01,\n",
       "         7.9682595e-01, 9.9675107e-01, 1.7713465e-01, 5.6453025e-01,\n",
       "         9.7117651e-01, 9.9917513e-01, 2.5035511e-03, 9.8952174e-01,\n",
       "         4.0776905e-01, 6.2676382e-01, 6.0745317e-01]], dtype=float32),\n",
       " array([[2.5136693e-04, 8.4513295e-01, 5.9295160e-01, 5.3307945e-01,\n",
       "         7.9345793e-01, 9.9750727e-01, 4.0005288e-01, 5.3445083e-01,\n",
       "         9.7551131e-01, 9.9935549e-01, 1.7718002e-03, 9.8719203e-01,\n",
       "         5.9491974e-01, 5.4714996e-01, 5.8050829e-01]], dtype=float32),\n",
       " array([[0.00176743, 0.77765596, 0.44903305, 0.31844857, 0.81076765,\n",
       "         0.99275255, 0.8795755 , 0.6483265 , 0.9729541 , 0.99666566,\n",
       "         0.00457417, 0.3535812 , 0.87276363, 0.5699058 , 0.6301439 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00200329, 0.7754809 , 0.39082646, 0.3043798 , 0.8081945 ,\n",
       "         0.99166894, 0.91789365, 0.6548712 , 0.94964916, 0.99577326,\n",
       "         0.00462686, 0.01007126, 0.83270687, 0.6246404 , 0.6347829 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00106064, 0.79656154, 0.41853312, 0.3496486 , 0.814776  ,\n",
       "         0.9949528 , 0.8802269 , 0.6726647 , 0.9655258 , 0.9977932 ,\n",
       "         0.0032473 , 0.03065025, 0.83046496, 0.5930682 , 0.63360095]],\n",
       "       dtype=float32),\n",
       " array([[0.00167735, 0.790073  , 0.36983222, 0.32101172, 0.8055397 ,\n",
       "         0.99304813, 0.9379031 , 0.6642764 , 0.9570812 , 0.9965687 ,\n",
       "         0.00430282, 0.00880668, 0.86363655, 0.61330295, 0.6331349 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00322115, 0.7353572 , 0.32793868, 0.22816901, 0.8134784 ,\n",
       "         0.9891866 , 0.9670058 , 0.7044454 , 0.936516  , 0.9936393 ,\n",
       "         0.00575822, 0.00213195, 0.8875839 , 0.60712564, 0.6679357 ]],\n",
       "       dtype=float32),\n",
       " array([[1.3038739e-02, 7.0440936e-01, 2.9261154e-01, 2.0357320e-01,\n",
       "         8.1634867e-01, 9.7581965e-01, 9.9315453e-01, 7.4519151e-01,\n",
       "         8.9762121e-01, 9.7747028e-01, 1.1086638e-02, 2.4877195e-04,\n",
       "         9.5053554e-01, 5.8561873e-01, 6.7845654e-01]], dtype=float32),\n",
       " array([[0.01784958, 0.6556492 , 0.3755575 , 0.20696968, 0.80857974,\n",
       "         0.9612093 , 0.9597057 , 0.71739936, 0.8549984 , 0.96491474,\n",
       "         0.01499693, 0.03489452, 0.88875574, 0.5700681 , 0.6843514 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01479672, 0.73364896, 0.38319662, 0.30395672, 0.7797954 ,\n",
       "         0.9638401 , 0.94825685, 0.6693073 , 0.93955016, 0.9694192 ,\n",
       "         0.02060258, 0.16520523, 0.90150785, 0.63202953, 0.6371656 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03242361, 0.7679314 , 0.31434682, 0.3513589 , 0.77107614,\n",
       "         0.94983894, 0.9790389 , 0.67693126, 0.92777616, 0.94187456,\n",
       "         0.02902099, 0.00886914, 0.949907  , 0.66136515, 0.6174318 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02166602, 0.7399743 , 0.34453264, 0.33736336, 0.7751232 ,\n",
       "         0.95687103, 0.82146716, 0.65986854, 0.91061723, 0.9586652 ,\n",
       "         0.02273022, 0.15603192, 0.8736102 , 0.6768047 , 0.62796533]],\n",
       "       dtype=float32),\n",
       " array([[0.04123682, 0.7165517 , 0.33467293, 0.3227789 , 0.77535814,\n",
       "         0.93699753, 0.8037146 , 0.6687257 , 0.89392155, 0.92839175,\n",
       "         0.03165116, 0.22659396, 0.8950132 , 0.6779236 , 0.6333955 ]],\n",
       "       dtype=float32),\n",
       " array([[0.20203573, 0.74179953, 0.27426437, 0.25660393, 0.7693933 ,\n",
       "         0.85463965, 0.99359775, 0.7192413 , 0.95176   , 0.75042164,\n",
       "         0.07313283, 0.00687083, 0.9894031 , 0.64107907, 0.6262258 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04809223, 0.6921642 , 0.34945494, 0.27769598, 0.7804232 ,\n",
       "         0.9301823 , 0.97132313, 0.69885415, 0.8940111 , 0.9158194 ,\n",
       "         0.02975899, 0.01305061, 0.94217736, 0.5979192 , 0.67341226]],\n",
       "       dtype=float32),\n",
       " array([[0.07172555, 0.6694439 , 0.2961508 , 0.23285596, 0.78088224,\n",
       "         0.90925395, 0.982896  , 0.7244864 , 0.8749023 , 0.8778941 ,\n",
       "         0.03837951, 0.00229862, 0.95164984, 0.6211173 , 0.6873357 ]],\n",
       "       dtype=float32),\n",
       " array([[3.3732963e-01, 6.2848526e-01, 2.2924961e-01, 1.5387498e-01,\n",
       "         7.7932894e-01, 7.7089161e-01, 9.8994243e-01, 7.6071620e-01,\n",
       "         8.7138253e-01, 5.9569150e-01, 8.3139896e-02, 8.4681017e-04,\n",
       "         9.8418045e-01, 6.3278908e-01, 6.9664687e-01]], dtype=float32),\n",
       " array([[0.23395771, 0.5919952 , 0.25272217, 0.17238545, 0.7770216 ,\n",
       "         0.80101436, 0.9868194 , 0.7556014 , 0.81410885, 0.66823   ,\n",
       "         0.07564016, 0.00098995, 0.966615  , 0.6371255 , 0.7141857 ]],\n",
       "       dtype=float32),\n",
       " array([[2.9856166e-01, 6.2550575e-01, 2.2776397e-01, 1.4633133e-01,\n",
       "         7.7134937e-01, 7.5742930e-01, 9.9610174e-01, 7.6940703e-01,\n",
       "         8.8317555e-01, 5.9122252e-01, 9.8261058e-02, 2.0056538e-04,\n",
       "         9.8166335e-01, 6.4952350e-01, 7.0672643e-01]], dtype=float32),\n",
       " array([[0.08946462, 0.61221445, 0.32127413, 0.15484059, 0.7707563 ,\n",
       "         0.8493963 , 0.9602078 , 0.7409575 , 0.8995163 , 0.8195038 ,\n",
       "         0.05965071, 0.03957892, 0.91367656, 0.6312386 , 0.7152584 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04257052, 0.6486688 , 0.34560102, 0.18886124, 0.76870483,\n",
       "         0.8989382 , 0.89559436, 0.71837705, 0.8998927 , 0.9003126 ,\n",
       "         0.04238041, 0.2594771 , 0.84928   , 0.6353216 , 0.69832206]],\n",
       "       dtype=float32),\n",
       " array([[0.23742346, 0.58452076, 0.29388037, 0.1537856 , 0.7642928 ,\n",
       "         0.7290971 , 0.9469199 , 0.7335601 , 0.8210661 , 0.6093771 ,\n",
       "         0.10891357, 0.17862259, 0.92489165, 0.6537182 , 0.6994478 ]],\n",
       "       dtype=float32),\n",
       " array([[0.12038229, 0.59294677, 0.30659592, 0.14255992, 0.77197737,\n",
       "         0.8165209 , 0.8285109 , 0.7306946 , 0.87413824, 0.7746528 ,\n",
       "         0.07069436, 0.33304733, 0.8765093 , 0.6689743 , 0.7045938 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09323088, 0.62041825, 0.3143534 , 0.1713421 , 0.7696983 ,\n",
       "         0.8436136 , 0.75885284, 0.7128883 , 0.8642232 , 0.8158395 ,\n",
       "         0.06217401, 0.51834875, 0.8477262 , 0.67526275, 0.6897037 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04970152, 0.64552504, 0.3534858 , 0.18522899, 0.76924175,\n",
       "         0.88448834, 0.3994968 , 0.68921006, 0.89202183, 0.8902697 ,\n",
       "         0.04626467, 0.95952326, 0.74469703, 0.6794126 , 0.6750126 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01723347, 0.71836764, 0.308262  , 0.1439353 , 0.7782567 ,\n",
       "         0.94279647, 0.8088566 , 0.71559066, 0.9598491 , 0.959191  ,\n",
       "         0.02467372, 0.21140839, 0.8329678 , 0.68669915, 0.66987944]],\n",
       "       dtype=float32),\n",
       " array([[0.01570014, 0.67292833, 0.3388741 , 0.1994589 , 0.77800494,\n",
       "         0.94570875, 0.63632655, 0.695413  , 0.90081334, 0.9595474 ,\n",
       "         0.02390717, 0.30987608, 0.70111954, 0.6848292 , 0.6849622 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00837419, 0.6550564 , 0.3801731 , 0.22076714, 0.7796637 ,\n",
       "         0.9594031 , 0.31371537, 0.6732572 , 0.87351406, 0.97543633,\n",
       "         0.01835842, 0.79903626, 0.49051872, 0.6890231 , 0.68806595]],\n",
       "       dtype=float32),\n",
       " array([[0.00919695, 0.6731297 , 0.36703345, 0.18475834, 0.7796877 ,\n",
       "         0.95578057, 0.5355552 , 0.6753343 , 0.8913338 , 0.9729546 ,\n",
       "         0.01840315, 0.5753056 , 0.57160527, 0.6875392 , 0.67798686]],\n",
       "       dtype=float32),\n",
       " array([[0.00323133, 0.71489716, 0.42419842, 0.2510439 , 0.7782243 ,\n",
       "         0.97722715, 0.46505243, 0.65197074, 0.9285536 , 0.9894392 ,\n",
       "         0.01165674, 0.76948184, 0.48961014, 0.676593  , 0.66551316]],\n",
       "       dtype=float32),\n",
       " array([[4.7329997e-04, 7.8384179e-01, 4.7493652e-01, 3.2010752e-01,\n",
       "         7.7746660e-01, 9.9289167e-01, 1.9320208e-01, 6.0061264e-01,\n",
       "         9.5468140e-01, 9.9811721e-01, 4.2017568e-03, 8.8123685e-01,\n",
       "         2.5734529e-01, 6.9504011e-01, 6.3687813e-01]], dtype=float32),\n",
       " array([[0.0045953 , 0.76732606, 0.43237546, 0.32228455, 0.7665136 ,\n",
       "         0.97361404, 0.45416847, 0.6119878 , 0.9324286 , 0.98607916,\n",
       "         0.01327563, 0.77202535, 0.557663  , 0.6956797 , 0.6219393 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04215277, 0.7190555 , 0.32088223, 0.21836784, 0.76853055,\n",
       "         0.91337883, 0.9100898 , 0.67925036, 0.9283361 , 0.91065836,\n",
       "         0.03978088, 0.04098795, 0.88150984, 0.7111961 , 0.6411349 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06023202, 0.65098596, 0.31963181, 0.1767381 , 0.7717157 ,\n",
       "         0.8786529 , 0.9337384 , 0.69006306, 0.8641085 , 0.86422706,\n",
       "         0.04929503, 0.02676141, 0.84888184, 0.702199  , 0.66860986]],\n",
       "       dtype=float32),\n",
       " array([[0.09570003, 0.6388265 , 0.28810135, 0.15945563, 0.7727152 ,\n",
       "         0.85278714, 0.9431219 , 0.71577334, 0.88998085, 0.8162044 ,\n",
       "         0.06082771, 0.01247374, 0.9027393 , 0.70670915, 0.68175334]],\n",
       "       dtype=float32),\n",
       " array([[3.3436355e-01, 5.4122746e-01, 2.0148715e-01, 1.1326090e-01,\n",
       "         7.6878929e-01, 7.0052254e-01, 9.8683029e-01, 7.4915934e-01,\n",
       "         8.0400491e-01, 5.2165633e-01, 1.3289359e-01, 3.1710885e-04,\n",
       "         9.5270991e-01, 7.4776423e-01, 7.0858228e-01]], dtype=float32),\n",
       " array([[0.02669267, 0.6896926 , 0.3221267 , 0.1468692 , 0.7845492 ,\n",
       "         0.9286534 , 0.91638917, 0.73764455, 0.9449905 , 0.93820465,\n",
       "         0.02949807, 0.03854532, 0.86824906, 0.66952133, 0.68426687]],\n",
       "       dtype=float32),\n",
       " array([[0.07627902, 0.6319733 , 0.3163983 , 0.18028234, 0.7595468 ,\n",
       "         0.8501631 , 0.8669283 , 0.6878688 , 0.86401397, 0.83029413,\n",
       "         0.06337085, 0.12780659, 0.8254367 , 0.711087  , 0.68018395]],\n",
       "       dtype=float32),\n",
       " array([[0.18334325, 0.6263025 , 0.29245573, 0.15513834, 0.7603282 ,\n",
       "         0.7677386 , 0.96935004, 0.7167165 , 0.88387805, 0.6774576 ,\n",
       "         0.09701689, 0.03234881, 0.93276876, 0.6874497 , 0.6831747 ]],\n",
       "       dtype=float32),\n",
       " array([[0.12347897, 0.6292703 , 0.35557714, 0.19149102, 0.76499593,\n",
       "         0.8116702 , 0.9592793 , 0.71289885, 0.8754333 , 0.7550609 ,\n",
       "         0.07760039, 0.18131837, 0.911444  , 0.6332257 , 0.68884194]],\n",
       "       dtype=float32),\n",
       " array([[0.21162827, 0.6437863 , 0.29233268, 0.18968126, 0.7516238 ,\n",
       "         0.7631626 , 0.97217065, 0.7103075 , 0.9145754 , 0.65647614,\n",
       "         0.11160832, 0.04461599, 0.9535892 , 0.6821021 , 0.68017274]],\n",
       "       dtype=float32),\n",
       " array([[0.6661193 , 0.600944  , 0.2469666 , 0.17635721, 0.7379186 ,\n",
       "         0.49661142, 0.9800363 , 0.71419364, 0.8722939 , 0.24634837,\n",
       "         0.24694957, 0.00974607, 0.979786  , 0.70981747, 0.6828505 ]],\n",
       "       dtype=float32),\n",
       " array([[0.33795547, 0.63630927, 0.2642514 , 0.18994968, 0.76595867,\n",
       "         0.7193147 , 0.97388226, 0.7524766 , 0.8619022 , 0.53735363,\n",
       "         0.11059156, 0.0038929 , 0.96735907, 0.6550058 , 0.69917214]],\n",
       "       dtype=float32),\n",
       " array([[0.18871278, 0.61549556, 0.2920986 , 0.15983303, 0.7733784 ,\n",
       "         0.7782636 , 0.9320596 , 0.7483809 , 0.84311616, 0.68203336,\n",
       "         0.07699546, 0.01870747, 0.92342126, 0.64776117, 0.7114782 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06414302, 0.6209475 , 0.32545754, 0.16444016, 0.77098364,\n",
       "         0.8636109 , 0.7922964 , 0.72006166, 0.8795372 , 0.8547952 ,\n",
       "         0.05340028, 0.17192057, 0.8117029 , 0.674095  , 0.70810825]],\n",
       "       dtype=float32),\n",
       " array([[0.05066891, 0.64301807, 0.32780677, 0.17185341, 0.7721693 ,\n",
       "         0.87819546, 0.90535337, 0.7283752 , 0.87450695, 0.87410086,\n",
       "         0.04922416, 0.09522429, 0.8245301 , 0.6529305 , 0.7043614 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03762604, 0.6181852 , 0.35133952, 0.18338974, 0.7689545 ,\n",
       "         0.88817024, 0.7429137 , 0.70652765, 0.86103183, 0.8968512 ,\n",
       "         0.04800893, 0.3915907 , 0.70450836, 0.673967  , 0.707887  ]],\n",
       "       dtype=float32),\n",
       " array([[0.08622796, 0.6218822 , 0.33030072, 0.15213911, 0.7653522 ,\n",
       "         0.8261358 , 0.8858045 , 0.718628  , 0.89748955, 0.80534816,\n",
       "         0.06961071, 0.11612159, 0.8467803 , 0.676224  , 0.7054021 ]],\n",
       "       dtype=float32),\n",
       " array([[0.2824768 , 0.5866142 , 0.28472874, 0.14083254, 0.7601408 ,\n",
       "         0.6742663 , 0.9206049 , 0.72738296, 0.8410632 , 0.5389922 ,\n",
       "         0.13112706, 0.07572731, 0.91305023, 0.68341076, 0.7051896 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07465869, 0.6294334 , 0.33325556, 0.18430707, 0.76446027,\n",
       "         0.84549415, 0.7797806 , 0.7099388 , 0.8808259 , 0.829427  ,\n",
       "         0.06460636, 0.2958439 , 0.8114012 , 0.67598236, 0.7019974 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04673284, 0.63751024, 0.32541996, 0.16760938, 0.7705218 ,\n",
       "         0.8820801 , 0.71197194, 0.7065794 , 0.8688317 , 0.8853542 ,\n",
       "         0.04449487, 0.19914049, 0.7521128 , 0.6844077 , 0.70188975]],\n",
       "       dtype=float32),\n",
       " array([[0.04213199, 0.6270193 , 0.30851465, 0.15546255, 0.7758445 ,\n",
       "         0.89034605, 0.69039994, 0.7203772 , 0.8823531 , 0.89703256,\n",
       "         0.04695016, 0.4201318 , 0.7537632 , 0.6881872 , 0.7032628 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02037465, 0.6249141 , 0.3298838 , 0.1706355 , 0.7811526 ,\n",
       "         0.9274465 , 0.57663   , 0.71168536, 0.8668217 , 0.9436414 ,\n",
       "         0.03235292, 0.5118331 , 0.63487995, 0.6864636 , 0.7071808 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02243761, 0.5556721 , 0.34681076, 0.1383912 , 0.7878547 ,\n",
       "         0.9139289 , 0.5461413 , 0.7186857 , 0.8197185 , 0.9338345 ,\n",
       "         0.03776411, 0.8016157 , 0.5503133 , 0.68024725, 0.72379476]],\n",
       "       dtype=float32),\n",
       " array([[0.03119627, 0.5608231 , 0.3129177 , 0.11411817, 0.792867  ,\n",
       "         0.90330386, 0.6781335 , 0.7337353 , 0.8290731 , 0.9178557 ,\n",
       "         0.03860655, 0.47627616, 0.66053057, 0.6816352 , 0.72247666]],\n",
       "       dtype=float32),\n",
       " array([[0.0264242 , 0.62199974, 0.3271947 , 0.16553862, 0.7776626 ,\n",
       "         0.91481984, 0.6942706 , 0.7008025 , 0.8714117 , 0.92903674,\n",
       "         0.03896764, 0.49194166, 0.684947  , 0.6963164 , 0.69786376]],\n",
       "       dtype=float32),\n",
       " array([[0.04342571, 0.64568913, 0.3198175 , 0.18497579, 0.77750075,\n",
       "         0.9023955 , 0.81718105, 0.71190345, 0.8896229 , 0.9018971 ,\n",
       "         0.04208899, 0.09613291, 0.8164828 , 0.68599105, 0.69539434]],\n",
       "       dtype=float32),\n",
       " array([[0.08051678, 0.6386648 , 0.316858  , 0.18559745, 0.76774055,\n",
       "         0.85897243, 0.8943307 , 0.70238656, 0.8871644 , 0.83325857,\n",
       "         0.0584343 , 0.02945293, 0.8664132 , 0.70083195, 0.69109946]],\n",
       "       dtype=float32),\n",
       " array([[0.13445008, 0.6486204 , 0.3012392 , 0.18350312, 0.7655645 ,\n",
       "         0.8231195 , 0.96668744, 0.72136366, 0.91186965, 0.7587418 ,\n",
       "         0.0755711 , 0.00610713, 0.93596625, 0.6881603 , 0.691988  ]],\n",
       "       dtype=float32),\n",
       " array([[0.05784956, 0.66097206, 0.34720558, 0.21052785, 0.7648364 ,\n",
       "         0.87823856, 0.90879554, 0.6936712 , 0.88713807, 0.86662656,\n",
       "         0.04879177, 0.02994917, 0.84364223, 0.68351424, 0.68901515]],\n",
       "       dtype=float32),\n",
       " array([[0.08685526, 0.6389368 , 0.32324907, 0.16843146, 0.7665121 ,\n",
       "         0.8412258 , 0.9349741 , 0.7101168 , 0.8800092 , 0.8121882 ,\n",
       "         0.0601314 , 0.02230307, 0.8711702 , 0.68440896, 0.69645905]],\n",
       "       dtype=float32),\n",
       " array([[0.04224555, 0.67803746, 0.34199056, 0.22158478, 0.76414675,\n",
       "         0.8968384 , 0.87442434, 0.7004262 , 0.9123544 , 0.89682275,\n",
       "         0.04814516, 0.11746188, 0.8280938 , 0.6842511 , 0.6857015 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04175775, 0.67599374, 0.34292793, 0.2398615 , 0.7636525 ,\n",
       "         0.897069  , 0.83535564, 0.6908973 , 0.8809128 , 0.895947  ,\n",
       "         0.04680719, 0.15107363, 0.79408765, 0.6838375 , 0.6835905 ]],\n",
       "       dtype=float32),\n",
       " array([[0.031596  , 0.6840463 , 0.35863906, 0.24706899, 0.76611996,\n",
       "         0.9135197 , 0.7497483 , 0.68572855, 0.90120536, 0.9203024 ,\n",
       "         0.04107415, 0.40680006, 0.7696089 , 0.6819866 , 0.6786712 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01780269, 0.71134317, 0.38209575, 0.30111656, 0.7655559 ,\n",
       "         0.93961346, 0.61663115, 0.66829544, 0.9097265 , 0.9519893 ,\n",
       "         0.03203661, 0.7344548 , 0.7052355 , 0.67983854, 0.6658241 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01634835, 0.71666056, 0.40093452, 0.3411483 , 0.7642466 ,\n",
       "         0.9436111 , 0.503601  , 0.6505784 , 0.8936547 , 0.9557634 ,\n",
       "         0.02960818, 0.8487303 , 0.6606705 , 0.67908317, 0.658593  ]],\n",
       "       dtype=float32),\n",
       " array([[0.00641346, 0.7455137 , 0.42255536, 0.3504583 , 0.7683001 ,\n",
       "         0.9674732 , 0.32895136, 0.63801426, 0.929155  , 0.98101693,\n",
       "         0.01892823, 0.9480204 , 0.558585  , 0.6846451 , 0.64786774]],\n",
       "       dtype=float32),\n",
       " array([[0.00480537, 0.7840338 , 0.4087645 , 0.3654977 , 0.76918644,\n",
       "         0.97471607, 0.3470377 , 0.6279966 , 0.93685573, 0.98612845,\n",
       "         0.01395228, 0.8535355 , 0.5806938 , 0.68870175, 0.62962544]],\n",
       "       dtype=float32),\n",
       " array([[0.00900622, 0.7388702 , 0.38870326, 0.3046213 , 0.77065504,\n",
       "         0.9619745 , 0.479034  , 0.6377022 , 0.9201099 , 0.9752914 ,\n",
       "         0.01986915, 0.71031886, 0.63188905, 0.70059174, 0.6443815 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00155688, 0.7771252 , 0.43361264, 0.3528145 , 0.7817316 ,\n",
       "         0.9877099 , 0.3010774 , 0.62899405, 0.9488524 , 0.995103  ,\n",
       "         0.00766529, 0.81954855, 0.45995188, 0.68936837, 0.63988703]],\n",
       "       dtype=float32),\n",
       " array([[0.00372499, 0.74826974, 0.3985781 , 0.28043386, 0.7819482 ,\n",
       "         0.9783854 , 0.58611935, 0.6440495 , 0.93421805, 0.9889958 ,\n",
       "         0.01181085, 0.45590124, 0.5868206 , 0.6955879 , 0.6455205 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00320239, 0.7508894 , 0.41029483, 0.33045232, 0.7827328 ,\n",
       "         0.9816399 , 0.58768547, 0.6417858 , 0.92586446, 0.9905753 ,\n",
       "         0.01056028, 0.33454952, 0.5783055 , 0.68597037, 0.64863276]],\n",
       "       dtype=float32),\n",
       " array([[0.0054544 , 0.7386561 , 0.38703004, 0.30511862, 0.7774407 ,\n",
       "         0.974464  , 0.7039686 , 0.64221555, 0.9277767 , 0.9848838 ,\n",
       "         0.01473035, 0.2501905 , 0.6627444 , 0.6984801 , 0.6474851 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01107388, 0.7214377 , 0.38134444, 0.27285543, 0.7801579 ,\n",
       "         0.9607084 , 0.7972312 , 0.65869784, 0.91171664, 0.9714614 ,\n",
       "         0.01955699, 0.16630964, 0.7410449 , 0.6825665 , 0.6528437 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01745725, 0.692992  , 0.3665543 , 0.24873377, 0.7801201 ,\n",
       "         0.9475449 , 0.82535493, 0.667817  , 0.8911231 , 0.9568223 ,\n",
       "         0.0247657 , 0.1248433 , 0.7634191 , 0.68567204, 0.66261345]],\n",
       "       dtype=float32),\n",
       " array([[0.04291082, 0.69474256, 0.33853665, 0.19936927, 0.77894574,\n",
       "         0.91276747, 0.9529125 , 0.6947467 , 0.91612816, 0.90855694,\n",
       "         0.03707084, 0.0209342 , 0.8939887 , 0.677414  , 0.66261804]],\n",
       "       dtype=float32),\n",
       " array([[0.02911102, 0.6863066 , 0.36433032, 0.21780962, 0.78138953,\n",
       "         0.92843056, 0.8941818 , 0.6929425 , 0.9094747 , 0.93292314,\n",
       "         0.03151958, 0.08503262, 0.83763266, 0.67270213, 0.6687129 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01459706, 0.7095807 , 0.37889698, 0.25116804, 0.780788  ,\n",
       "         0.9516972 , 0.7846244 , 0.6791039 , 0.9141242 , 0.9628976 ,\n",
       "         0.02316038, 0.26469913, 0.75639254, 0.6746117 , 0.6619946 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01953964, 0.71021146, 0.38119504, 0.25280046, 0.78217006,\n",
       "         0.9417147 , 0.8349577 , 0.6850223 , 0.89151406, 0.95069087,\n",
       "         0.02644208, 0.3437212 , 0.7797206 , 0.6550467 , 0.6578404 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0348231 , 0.69631076, 0.35880074, 0.23202516, 0.7777806 ,\n",
       "         0.92004645, 0.85581887, 0.6842931 , 0.8968088 , 0.92146224,\n",
       "         0.03441632, 0.15292215, 0.83300066, 0.67466015, 0.6603344 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03184151, 0.71450055, 0.3475752 , 0.26044175, 0.77106386,\n",
       "         0.92785615, 0.89886045, 0.6731455 , 0.9088981 , 0.92844886,\n",
       "         0.03345872, 0.04618819, 0.8530796 , 0.69102186, 0.6533186 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05141935, 0.721857  , 0.3504612 , 0.25741228, 0.7736768 ,\n",
       "         0.9081865 , 0.91936964, 0.69122505, 0.91692424, 0.896459  ,\n",
       "         0.03993834, 0.06300131, 0.901694  , 0.6662756 , 0.65175873]],\n",
       "       dtype=float32),\n",
       " array([[0.12832136, 0.6832163 , 0.32741886, 0.24617453, 0.75737935,\n",
       "         0.8376532 , 0.9589677 , 0.6755957 , 0.90441173, 0.772895  ,\n",
       "         0.07128781, 0.01018812, 0.93264776, 0.7044185 , 0.6574891 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14640677, 0.65397   , 0.32548892, 0.22996494, 0.7616226 ,\n",
       "         0.8189336 , 0.9433545 , 0.6877185 , 0.8770148 , 0.7426412 ,\n",
       "         0.07661523, 0.01722026, 0.9206389 , 0.6974764 , 0.67134714]],\n",
       "       dtype=float32),\n",
       " array([[0.01950182, 0.73395807, 0.3521187 , 0.2720476 , 0.7687235 ,\n",
       "         0.9438095 , 0.7646064 , 0.675147  , 0.93944436, 0.9534479 ,\n",
       "         0.02882435, 0.19136454, 0.8077688 , 0.6960791 , 0.65576106]],\n",
       "       dtype=float32),\n",
       " array([[0.02995213, 0.6859747 , 0.3368596 , 0.23061402, 0.7717946 ,\n",
       "         0.92102194, 0.74782336, 0.6803719 , 0.88766795, 0.92755634,\n",
       "         0.03702828, 0.35055047, 0.7699469 , 0.69639534, 0.66614777]],\n",
       "       dtype=float32),\n",
       " array([[0.03700171, 0.70119584, 0.30901027, 0.2382201 , 0.75998557,\n",
       "         0.9106942 , 0.8119126 , 0.66600144, 0.9115627 , 0.91344076,\n",
       "         0.04756958, 0.2854685 , 0.81546956, 0.7260286 , 0.6517013 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02610903, 0.663153  , 0.348873  , 0.2273433 , 0.7681405 ,\n",
       "         0.9220364 , 0.72730964, 0.66469777, 0.8829731 , 0.93244064,\n",
       "         0.03867164, 0.46057293, 0.71775866, 0.7105713 , 0.6694595 ]],\n",
       "       dtype=float32),\n",
       " array([[0.009217  , 0.71504587, 0.3722548 , 0.24911983, 0.77546346,\n",
       "         0.95897543, 0.48065478, 0.6620401 , 0.92586076, 0.9741965 ,\n",
       "         0.02234451, 0.88133574, 0.62517935, 0.69935733, 0.6549312 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01041825, 0.7122016 , 0.3495282 , 0.2540439 , 0.780023  ,\n",
       "         0.95942384, 0.54619384, 0.66787374, 0.89747316, 0.9722829 ,\n",
       "         0.02124291, 0.7238687 , 0.6507647 , 0.6968359 , 0.6544299 ]],\n",
       "       dtype=float32),\n",
       " array([[0.008873  , 0.70982707, 0.3721351 , 0.245491  , 0.7850839 ,\n",
       "         0.96375   , 0.52112824, 0.66817313, 0.9068381 , 0.97658926,\n",
       "         0.01793525, 0.71626306, 0.64447105, 0.6838822 , 0.6579915 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00602043, 0.7500437 , 0.3921952 , 0.28824556, 0.7776599 ,\n",
       "         0.9712876 , 0.42382094, 0.6360706 , 0.9228871 , 0.98348373,\n",
       "         0.01420837, 0.75382906, 0.6052623 , 0.6887028 , 0.6384869 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00347369, 0.7501564 , 0.42577577, 0.3212204 , 0.78471047,\n",
       "         0.980942  , 0.39597812, 0.64126325, 0.93583626, 0.99037766,\n",
       "         0.01055217, 0.7767767 , 0.57635814, 0.67350596, 0.6452172 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00838218, 0.7221696 , 0.38993046, 0.22492677, 0.7875463 ,\n",
       "         0.9656461 , 0.720153  , 0.6637418 , 0.92506564, 0.978217  ,\n",
       "         0.01563103, 0.38347965, 0.7115876 , 0.67251486, 0.65078163]],\n",
       "       dtype=float32),\n",
       " array([[0.0060541 , 0.73603725, 0.39470258, 0.27444363, 0.7819003 ,\n",
       "         0.9728829 , 0.71451306, 0.6461361 , 0.9245086 , 0.9836939 ,\n",
       "         0.01346375, 0.20997377, 0.6796985 , 0.6851583 , 0.64728963]],\n",
       "       dtype=float32),\n",
       " array([[0.00824369, 0.7288791 , 0.38442653, 0.28262067, 0.7732485 ,\n",
       "         0.9666355 , 0.67231697, 0.63055176, 0.92377573, 0.97834194,\n",
       "         0.01728282, 0.2739881 , 0.6852019 , 0.7080599 , 0.64225084]],\n",
       "       dtype=float32),\n",
       " array([[0.00619071, 0.76743937, 0.41744176, 0.36318776, 0.7742961 ,\n",
       "         0.9738602 , 0.6136455 , 0.62374043, 0.91712075, 0.983566  ,\n",
       "         0.01325569, 0.3801795 , 0.6719125 , 0.6765022 , 0.628686  ]],\n",
       "       dtype=float32),\n",
       " array([[0.00255024, 0.7825096 , 0.44726244, 0.40667775, 0.77657574,\n",
       "         0.9849413 , 0.5639195 , 0.6180883 , 0.9402962 , 0.9925884 ,\n",
       "         0.00946999, 0.6123892 , 0.60036   , 0.67115444, 0.6256337 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0029588 , 0.77699375, 0.43635666, 0.43663782, 0.77537787,\n",
       "         0.9843987 , 0.59205365, 0.61197925, 0.9223309 , 0.99165946,\n",
       "         0.00994711, 0.44318363, 0.6091159 , 0.67648154, 0.62533975]],\n",
       "       dtype=float32),\n",
       " array([[0.00585637, 0.775243  , 0.4373187 , 0.43774238, 0.77113795,\n",
       "         0.9766684 , 0.73374957, 0.6177955 , 0.92957205, 0.98478967,\n",
       "         0.01451373, 0.36669856, 0.72574675, 0.6697004 , 0.6220987 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00579773, 0.7763556 , 0.43429992, 0.4278516 , 0.7732645 ,\n",
       "         0.977399  , 0.675022  , 0.62177676, 0.93706626, 0.9854592 ,\n",
       "         0.01410809, 0.5087953 , 0.7324935 , 0.66921526, 0.6203052 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00807087, 0.75891185, 0.4152264 , 0.37255305, 0.7757286 ,\n",
       "         0.97164536, 0.78081304, 0.6343738 , 0.93010306, 0.98015296,\n",
       "         0.01660914, 0.33913115, 0.7692662 , 0.6702057 , 0.6263682 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00896659, 0.7516798 , 0.40637684, 0.37562555, 0.7763663 ,\n",
       "         0.9708007 , 0.7187494 , 0.63339674, 0.9179754 , 0.9787638 ,\n",
       "         0.01625482, 0.26423043, 0.7569813 , 0.67799395, 0.63026834]],\n",
       "       dtype=float32),\n",
       " array([[0.02414511, 0.7671425 , 0.33428138, 0.31135052, 0.7716302 ,\n",
       "         0.9512288 , 0.94662356, 0.6645287 , 0.94439507, 0.9522022 ,\n",
       "         0.02597059, 0.0114013 , 0.915703  , 0.69049436, 0.62512004]],\n",
       "       dtype=float32),\n",
       " array([[0.06889232, 0.7087295 , 0.31965277, 0.28291065, 0.76838726,\n",
       "         0.90290874, 0.9519247 , 0.67502475, 0.8998193 , 0.8746187 ,\n",
       "         0.04662567, 0.01088651, 0.92561895, 0.6933008 , 0.64489675]],\n",
       "       dtype=float32),\n",
       " array([[0.08006607, 0.7061425 , 0.31999394, 0.25075325, 0.7654014 ,\n",
       "         0.8868552 , 0.9791551 , 0.69009316, 0.9257171 , 0.8523758 ,\n",
       "         0.05509959, 0.00515085, 0.9445284 , 0.68718505, 0.6528309 ]],\n",
       "       dtype=float32),\n",
       " array([[0.13252872, 0.67810756, 0.31261113, 0.26115942, 0.75979793,\n",
       "         0.8425891 , 0.9869589 , 0.6944493 , 0.8864332 , 0.7647537 ,\n",
       "         0.07505236, 0.00235103, 0.9498556 , 0.68363893, 0.6640671 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14135903, 0.6965415 , 0.32409754, 0.28329045, 0.7510014 ,\n",
       "         0.8293057 , 0.98345494, 0.6841366 , 0.8986967 , 0.74586016,\n",
       "         0.08117909, 0.0034388 , 0.9477267 , 0.6893542 , 0.6572613 ]],\n",
       "       dtype=float32),\n",
       " array([[0.28855646, 0.6424663 , 0.26081538, 0.18397507, 0.7565496 ,\n",
       "         0.7342941 , 0.9897238 , 0.7242402 , 0.8991872 , 0.57466096,\n",
       "         0.12519087, 0.00125127, 0.96820146, 0.7103558 , 0.6778713 ]],\n",
       "       dtype=float32),\n",
       " array([[0.5065224 , 0.6725149 , 0.26770678, 0.20346709, 0.73701453,\n",
       "         0.58916616, 0.99261135, 0.70710236, 0.9116697 , 0.35643506,\n",
       "         0.2008385 , 0.00250941, 0.9806434 , 0.7049235 , 0.65872765]],\n",
       "       dtype=float32),\n",
       " array([[0.41431567, 0.6675945 , 0.2911596 , 0.24236244, 0.73480946,\n",
       "         0.6284163 , 0.98197466, 0.694606  , 0.883276  , 0.41938427,\n",
       "         0.18021196, 0.00939705, 0.9647441 , 0.6991374 , 0.6641553 ]],\n",
       "       dtype=float32),\n",
       " array([[0.21751413, 0.6593052 , 0.3332343 , 0.26314422, 0.74073917,\n",
       "         0.73416185, 0.95249474, 0.6898599 , 0.8824852 , 0.6121077 ,\n",
       "         0.13122   , 0.07943153, 0.92406553, 0.687942  , 0.6730728 ]],\n",
       "       dtype=float32),\n",
       " array([[0.5344535 , 0.6508549 , 0.23672454, 0.17064399, 0.73907465,\n",
       "         0.5650932 , 0.9861428 , 0.7307309 , 0.9287273 , 0.33831596,\n",
       "         0.23202729, 0.00643467, 0.97975916, 0.7240403 , 0.67427814]],\n",
       "       dtype=float32),\n",
       " array([[0.45750576, 0.6081318 , 0.2678659 , 0.19376267, 0.7413685 ,\n",
       "         0.5870944 , 0.9579064 , 0.71639174, 0.85847545, 0.37821716,\n",
       "         0.20459345, 0.02904039, 0.9509673 , 0.7163033 , 0.68893516]],\n",
       "       dtype=float32),\n",
       " array([[0.40775347, 0.63186526, 0.26346493, 0.18074188, 0.74119824,\n",
       "         0.614225  , 0.9394416 , 0.7167033 , 0.89695555, 0.42905918,\n",
       "         0.18708214, 0.05051548, 0.95021194, 0.72169733, 0.6832989 ]],\n",
       "       dtype=float32),\n",
       " array([[0.328566  , 0.5808247 , 0.27678138, 0.13590972, 0.7542307 ,\n",
       "         0.63408786, 0.9230721 , 0.7288044 , 0.8552491 , 0.48527324,\n",
       "         0.15404814, 0.06742875, 0.9152532 , 0.7089186 , 0.70573   ]],\n",
       "       dtype=float32),\n",
       " array([[0.20984428, 0.56761515, 0.28527784, 0.129322  , 0.7624017 ,\n",
       "         0.7142239 , 0.8870921 , 0.73499864, 0.8572228 , 0.6196839 ,\n",
       "         0.11853   , 0.11778394, 0.8783183 , 0.7058233 , 0.7149844 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0337944 , 0.64404017, 0.333962  , 0.1829115 , 0.76878744,\n",
       "         0.900623  , 0.70804757, 0.7159913 , 0.9089838 , 0.91164684,\n",
       "         0.04521664, 0.31449   , 0.7394914 , 0.694892  , 0.7046852 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04874493, 0.6213436 , 0.35499582, 0.18230209, 0.76721096,\n",
       "         0.8711176 , 0.60633594, 0.70248073, 0.87798506, 0.8765842 ,\n",
       "         0.05359617, 0.6296683 , 0.7089763 , 0.69096935, 0.70309   ]],\n",
       "       dtype=float32),\n",
       " array([[0.06167393, 0.6212638 , 0.31815693, 0.1493539 , 0.77106905,\n",
       "         0.8582418 , 0.77514255, 0.71885425, 0.89337975, 0.85523254,\n",
       "         0.05870611, 0.30533865, 0.79223484, 0.6971    , 0.70258474]],\n",
       "       dtype=float32),\n",
       " array([[0.09039648, 0.6085499 , 0.3195029 , 0.1126275 , 0.77247804,\n",
       "         0.81500155, 0.8877883 , 0.72321355, 0.89772606, 0.798122  ,\n",
       "         0.06562155, 0.10706777, 0.84057826, 0.6902153 , 0.7053194 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09993333, 0.5387206 , 0.30757013, 0.08425312, 0.78261906,\n",
       "         0.7956049 , 0.7739395 , 0.7362245 , 0.8479412 , 0.77959216,\n",
       "         0.06552131, 0.19644482, 0.7735133 , 0.6951626 , 0.72790647]],\n",
       "       dtype=float32),\n",
       " array([[0.0786525 , 0.5623326 , 0.31202185, 0.0879031 , 0.7834716 ,\n",
       "         0.82112163, 0.7750865 , 0.73623973, 0.86318874, 0.81752294,\n",
       "         0.0580758 , 0.2653831 , 0.76720464, 0.6889553 , 0.72174525]],\n",
       "       dtype=float32),\n",
       " array([[0.04374428, 0.59385943, 0.32009712, 0.12027597, 0.7842257 ,\n",
       "         0.88122696, 0.6834186 , 0.7304909 , 0.875875  , 0.8915409 ,\n",
       "         0.04457595, 0.3795916 , 0.72503823, 0.68880546, 0.71596855]],\n",
       "       dtype=float32),\n",
       " array([[0.04362539, 0.58012223, 0.28007704, 0.0983424 , 0.77857   ,\n",
       "         0.87608117, 0.68215656, 0.7141695 , 0.868176  , 0.8899445 ,\n",
       "         0.04667661, 0.1956609 , 0.6943604 , 0.7332393 , 0.7125641 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05767624, 0.61561334, 0.3010766 , 0.08728402, 0.78726125,\n",
       "         0.8647878 , 0.8999757 , 0.73919475, 0.9050588 , 0.86837333,\n",
       "         0.04226505, 0.03415941, 0.837772  , 0.6857839 , 0.70976454]],\n",
       "       dtype=float32),\n",
       " array([[0.09290915, 0.5702062 , 0.31635442, 0.09189286, 0.781266  ,\n",
       "         0.8089553 , 0.88928515, 0.72998285, 0.8680772 , 0.79238385,\n",
       "         0.06308032, 0.11105906, 0.82104415, 0.6861608 , 0.7157074 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02882067, 0.64490986, 0.37218225, 0.16644402, 0.7739515 ,\n",
       "         0.90192175, 0.73153687, 0.6928993 , 0.88524014, 0.918585  ,\n",
       "         0.03724959, 0.3970937 , 0.6852763 , 0.67883945, 0.6963685 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04406998, 0.62720805, 0.31869882, 0.14279507, 0.77860504,\n",
       "         0.8858237 , 0.81582594, 0.71602756, 0.8826496 , 0.89122677,\n",
       "         0.04504731, 0.14878686, 0.7731875 , 0.69414777, 0.70202667]],\n",
       "       dtype=float32),\n",
       " array([[0.08119591, 0.64654136, 0.3060226 , 0.16817518, 0.77055055,\n",
       "         0.8527582 , 0.8589733 , 0.7118599 , 0.8969853 , 0.8309616 ,\n",
       "         0.06050977, 0.08466537, 0.8603688 , 0.7005345 , 0.691342  ]],\n",
       "       dtype=float32),\n",
       " array([[0.075342  , 0.64661247, 0.33340117, 0.18193325, 0.76852185,\n",
       "         0.8527647 , 0.799424  , 0.6973917 , 0.8811756 , 0.83616287,\n",
       "         0.05716575, 0.20523565, 0.82472736, 0.6914174 , 0.68891317]],\n",
       "       dtype=float32),\n",
       " array([[0.01581709, 0.6906028 , 0.37132773, 0.21225601, 0.7757528 ,\n",
       "         0.93984854, 0.61085045, 0.68855155, 0.92546415, 0.95668966,\n",
       "         0.02790649, 0.62620294, 0.6891633 , 0.68317556, 0.68255687]],\n",
       "       dtype=float32),\n",
       " array([[0.01676315, 0.6897646 , 0.3678033 , 0.21409601, 0.7754628 ,\n",
       "         0.9364885 , 0.6946989 , 0.6841236 , 0.9043056 , 0.9527216 ,\n",
       "         0.02877698, 0.5338363 , 0.6842251 , 0.68056804, 0.6788972 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01280811, 0.70067835, 0.38227823, 0.24913175, 0.7755421 ,\n",
       "         0.94877434, 0.6815609 , 0.6752764 , 0.90617347, 0.9634811 ,\n",
       "         0.02431419, 0.41057292, 0.668148  , 0.67900676, 0.6771983 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02355783, 0.66792494, 0.33854148, 0.20236482, 0.77611005,\n",
       "         0.9263135 , 0.6452954 , 0.6840218 , 0.89404464, 0.9392896 ,\n",
       "         0.03395499, 0.4222344 , 0.70526314, 0.7037001 , 0.681405  ]],\n",
       "       dtype=float32),\n",
       " array([[0.05087981, 0.64265174, 0.33676952, 0.15225194, 0.7816837 ,\n",
       "         0.88587534, 0.7929567 , 0.7028137 , 0.8921054 , 0.8862879 ,\n",
       "         0.04239424, 0.18678126, 0.8097799 , 0.68646246, 0.6885333 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02660996, 0.64913076, 0.3720979 , 0.19452256, 0.78508145,\n",
       "         0.922351  , 0.74547774, 0.70065993, 0.8829264 , 0.9328256 ,\n",
       "         0.03241068, 0.35022888, 0.73728985, 0.66795015, 0.6920851 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01555927, 0.6629889 , 0.33862504, 0.16852993, 0.7871603 ,\n",
       "         0.9427245 , 0.7266575 , 0.69905436, 0.8990619 , 0.9581329 ,\n",
       "         0.02489072, 0.2216574 , 0.69329363, 0.6909637 , 0.6897905 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0302857 , 0.65356433, 0.34216678, 0.16742584, 0.7823581 ,\n",
       "         0.91818935, 0.83032507, 0.70020473, 0.9105932 , 0.9275152 ,\n",
       "         0.03426635, 0.09347852, 0.7943064 , 0.69271016, 0.68962157]],\n",
       "       dtype=float32),\n",
       " array([[0.03648254, 0.68149924, 0.351908  , 0.2262603 , 0.77291757,\n",
       "         0.91350096, 0.82716143, 0.68200696, 0.90466017, 0.9157052 ,\n",
       "         0.0378245 , 0.0825849 , 0.8147641 , 0.69382316, 0.6762042 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04487535, 0.640667  , 0.32737213, 0.18048276, 0.7769201 ,\n",
       "         0.89557916, 0.8678109 , 0.6982409 , 0.8853401 , 0.8945594 ,\n",
       "         0.04696663, 0.10256396, 0.810029  , 0.70099944, 0.68714005]],\n",
       "       dtype=float32),\n",
       " array([[0.07199562, 0.6490637 , 0.31232792, 0.14372389, 0.7751399 ,\n",
       "         0.8629309 , 0.93102086, 0.70570797, 0.9136468 , 0.84806186,\n",
       "         0.05416575, 0.02399259, 0.8813819 , 0.703426  , 0.6849294 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06055071, 0.6393577 , 0.33888802, 0.16849546, 0.7747143 ,\n",
       "         0.8701547 , 0.88282764, 0.69593954, 0.87673503, 0.8611502 ,\n",
       "         0.05042849, 0.08170109, 0.82438445, 0.689223  , 0.68868506]],\n",
       "       dtype=float32),\n",
       " array([[0.0727557 , 0.6753965 , 0.31951213, 0.15975721, 0.7789225 ,\n",
       "         0.8658864 , 0.9221032 , 0.7145669 , 0.8962295 , 0.8475802 ,\n",
       "         0.04773808, 0.03425917, 0.8841106 , 0.67074984, 0.6820936 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04777534, 0.70875275, 0.32090598, 0.21537234, 0.7645417 ,\n",
       "         0.89512056, 0.86703885, 0.6830681 , 0.9219819 , 0.89221317,\n",
       "         0.04628287, 0.07668451, 0.85546297, 0.7018695 , 0.66637486]],\n",
       "       dtype=float32),\n",
       " array([[0.07169424, 0.6784787 , 0.31026655, 0.18253937, 0.77146655,\n",
       "         0.86536336, 0.9043298 , 0.7071092 , 0.9051333 , 0.84710467,\n",
       "         0.05669473, 0.06852909, 0.8778068 , 0.6869048 , 0.6795998 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04541894, 0.65903735, 0.32227796, 0.19941229, 0.7732448 ,\n",
       "         0.8946696 , 0.8347238 , 0.7028219 , 0.89836204, 0.89325976,\n",
       "         0.05045356, 0.19513014, 0.8164436 , 0.69392234, 0.68726414]],\n",
       "       dtype=float32),\n",
       " array([[0.03436913, 0.66115797, 0.33969414, 0.19284181, 0.77434057,\n",
       "         0.9045656 , 0.7145842 , 0.69101727, 0.895781  , 0.913744  ,\n",
       "         0.04345763, 0.4971978 , 0.75125843, 0.69160837, 0.6841947 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01280242, 0.70714915, 0.37891224, 0.25386083, 0.77807885,\n",
       "         0.94937295, 0.58682954, 0.67929256, 0.91495615, 0.96425015,\n",
       "         0.02573249, 0.7223577 , 0.670103  , 0.67255807, 0.67350477]],\n",
       "       dtype=float32),\n",
       " array([[0.01889184, 0.6942385 , 0.3736929 , 0.27827772, 0.7751926 ,\n",
       "         0.93876636, 0.61156684, 0.6747917 , 0.8963857 , 0.9504057 ,\n",
       "         0.03241317, 0.72032803, 0.70223373, 0.67792374, 0.6720666 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01122339, 0.70104533, 0.37133196, 0.2977859 , 0.77632856,\n",
       "         0.9566401 , 0.49767494, 0.665475  , 0.9060706 , 0.9694625 ,\n",
       "         0.02544717, 0.73625046, 0.63815343, 0.69408333, 0.6705704 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02151804, 0.681902  , 0.35335433, 0.21843135, 0.78269655,\n",
       "         0.93616027, 0.7155335 , 0.6903372 , 0.9141332 , 0.9474829 ,\n",
       "         0.03161592, 0.46698633, 0.76229554, 0.68271106, 0.676638  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02165506, 0.6925803 , 0.36452302, 0.260402  , 0.77747345,\n",
       "         0.93748415, 0.6889882 , 0.67160904, 0.8943134 , 0.94674206,\n",
       "         0.02978854, 0.32257745, 0.74346733, 0.6838155 , 0.67172045]],\n",
       "       dtype=float32),\n",
       " array([[0.009298  , 0.734913  , 0.4004813 , 0.29486048, 0.7767739 ,\n",
       "         0.96129334, 0.67873806, 0.6569389 , 0.92244464, 0.9740684 ,\n",
       "         0.01944171, 0.36198792, 0.6875877 , 0.66936445, 0.66189015]],\n",
       "       dtype=float32),\n",
       " array([[0.00453895, 0.73522055, 0.36514026, 0.29671305, 0.785384  ,\n",
       "         0.9757781 , 0.5130699 , 0.6741377 , 0.92410374, 0.9866024 ,\n",
       "         0.01520785, 0.57016736, 0.5882344 , 0.6840804 , 0.6678574 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00585278, 0.6936385 , 0.3680758 , 0.24220203, 0.7902234 ,\n",
       "         0.96960497, 0.5409556 , 0.6800608 , 0.8997396 , 0.9824629 ,\n",
       "         0.01712767, 0.6253251 , 0.5619922 , 0.68142515, 0.6792465 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0109393 , 0.71379286, 0.37319976, 0.25574547, 0.7860275 ,\n",
       "         0.95952094, 0.7696063 , 0.6865881 , 0.926037  , 0.9713339 ,\n",
       "         0.02181631, 0.27734837, 0.74372196, 0.6689171 , 0.6708347 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01022075, 0.70440423, 0.3891101 , 0.28251818, 0.7777055 ,\n",
       "         0.958733  , 0.71653694, 0.65964085, 0.9136874 , 0.9714442 ,\n",
       "         0.0232817 , 0.43955857, 0.68138367, 0.6840975 , 0.66665334]],\n",
       "       dtype=float32),\n",
       " array([[0.01625799, 0.70640296, 0.37132606, 0.27202278, 0.7792282 ,\n",
       "         0.9489119 , 0.7967301 , 0.6736484 , 0.9127133 , 0.9589673 ,\n",
       "         0.02706826, 0.24874404, 0.7678097 , 0.6779414 , 0.66583765]],\n",
       "       dtype=float32),\n",
       " array([[0.03421507, 0.6919312 , 0.38116342, 0.27743927, 0.77235   ,\n",
       "         0.9207314 , 0.883187  , 0.66821116, 0.9008914 , 0.9205184 ,\n",
       "         0.03799452, 0.08553814, 0.8338615 , 0.6758114 , 0.6666938 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08017261, 0.68264127, 0.3581338 , 0.23072383, 0.7734519 ,\n",
       "         0.8781687 , 0.94822705, 0.6913894 , 0.9169447 , 0.84777826,\n",
       "         0.05062623, 0.01128056, 0.9192631 , 0.6743304 , 0.67191225]],\n",
       "       dtype=float32),\n",
       " array([[0.0923558 , 0.6590812 , 0.3276101 , 0.2222318 , 0.76912117,\n",
       "         0.85997087, 0.929474  , 0.6873442 , 0.88560385, 0.8206377 ,\n",
       "         0.06084226, 0.01671881, 0.89739627, 0.69643545, 0.6768418 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04319956, 0.68835926, 0.3375145 , 0.24982096, 0.77383935,\n",
       "         0.9117071 , 0.8924478 , 0.69356894, 0.90797347, 0.9056779 ,\n",
       "         0.04337489, 0.05213522, 0.86320543, 0.6865703 , 0.67415136]],\n",
       "       dtype=float32),\n",
       " array([[0.05565897, 0.6640615 , 0.31830573, 0.21793723, 0.7698055 ,\n",
       "         0.8904093 , 0.9054611 , 0.68849266, 0.89202315, 0.8780785 ,\n",
       "         0.05296308, 0.04893817, 0.85766435, 0.7049864 , 0.67685676]],\n",
       "       dtype=float32),\n",
       " array([[0.03776908, 0.67795527, 0.35288706, 0.23842764, 0.7735861 ,\n",
       "         0.91197157, 0.8757731 , 0.6882661 , 0.9006911 , 0.91176367,\n",
       "         0.04218842, 0.11870598, 0.82931185, 0.6841924 , 0.67629284]],\n",
       "       dtype=float32),\n",
       " array([[0.02808019, 0.6922048 , 0.34109837, 0.26333177, 0.77527595,\n",
       "         0.9308778 , 0.85271865, 0.6925207 , 0.90903234, 0.93430626,\n",
       "         0.03654204, 0.09927043, 0.82284945, 0.6890319 , 0.6757606 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04525867, 0.6710636 , 0.363958  , 0.26144165, 0.7735165 ,\n",
       "         0.9025716 , 0.8291299 , 0.68784404, 0.8847331 , 0.8969669 ,\n",
       "         0.04753122, 0.3107602 , 0.82321274, 0.6716523 , 0.6768724 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03302418, 0.7142202 , 0.3706106 , 0.3199657 , 0.7661488 ,\n",
       "         0.9228494 , 0.8012671 , 0.6697073 , 0.91348535, 0.92365044,\n",
       "         0.04161063, 0.33832586, 0.8257991 , 0.6798    , 0.6605231 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03460352, 0.6960547 , 0.35155657, 0.27648112, 0.7672538 ,\n",
       "         0.9183272 , 0.805657  , 0.6696442 , 0.90613115, 0.919707  ,\n",
       "         0.04200605, 0.21321747, 0.8147822 , 0.69524735, 0.66639555]],\n",
       "       dtype=float32),\n",
       " array([[0.03505792, 0.69542694, 0.3568495 , 0.31062517, 0.7688123 ,\n",
       "         0.9216208 , 0.7534376 , 0.6726534 , 0.89496803, 0.92073745,\n",
       "         0.04166045, 0.2938995 , 0.80844796, 0.68837625, 0.6678055 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01162357, 0.7170535 , 0.3714659 , 0.28364533, 0.7780953 ,\n",
       "         0.9571569 , 0.61294943, 0.67415   , 0.9237543 , 0.9694745 ,\n",
       "         0.02397703, 0.57325256, 0.70153654, 0.68778205, 0.6653743 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00861927, 0.72376955, 0.36811993, 0.30841956, 0.77448726,\n",
       "         0.9628125 , 0.50146997, 0.6549452 , 0.911274  , 0.97567016,\n",
       "         0.02264494, 0.7866171 , 0.6184359 , 0.70010024, 0.6565502 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00423235, 0.7268791 , 0.37612015, 0.26009458, 0.786926  ,\n",
       "         0.97434086, 0.4032648 , 0.66377246, 0.9108354 , 0.9868067 ,\n",
       "         0.01447531, 0.8604433 , 0.5037162 , 0.6874346 , 0.6610431 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00633273, 0.7137884 , 0.36962733, 0.25888643, 0.7865287 ,\n",
       "         0.96895313, 0.53947103, 0.66938066, 0.9080174 , 0.9816465 ,\n",
       "         0.01743636, 0.696858  , 0.5897297 , 0.68907654, 0.6638678 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01146753, 0.70984024, 0.37049013, 0.24649797, 0.78315204,\n",
       "         0.9560799 , 0.62576085, 0.6648159 , 0.90329075, 0.9693494 ,\n",
       "         0.02159311, 0.5555653 , 0.67265916, 0.6869675 , 0.6593404 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00362646, 0.7431727 , 0.40106672, 0.3094044 , 0.78499097,\n",
       "         0.9787633 , 0.45712712, 0.65417093, 0.93296826, 0.989198  ,\n",
       "         0.01332087, 0.82932705, 0.5589428 , 0.68193775, 0.6532459 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00525345, 0.7294292 , 0.38356802, 0.29488087, 0.78567076,\n",
       "         0.9738548 , 0.5237193 , 0.6548281 , 0.9070493 , 0.9849244 ,\n",
       "         0.01495244, 0.66104645, 0.5863164 , 0.68433416, 0.6547335 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00757763, 0.71801466, 0.37043634, 0.26628017, 0.7880122 ,\n",
       "         0.9694874 , 0.6772386 , 0.66743624, 0.9159733 , 0.98029053,\n",
       "         0.01657464, 0.33606508, 0.6903691 , 0.68388385, 0.6600314 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01291894, 0.70779943, 0.3462617 , 0.21636349, 0.78920287,\n",
       "         0.95859045, 0.82238925, 0.68428344, 0.9264611 , 0.9693173 ,\n",
       "         0.02044563, 0.11669634, 0.79131824, 0.6843847 , 0.6642494 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0189891 , 0.7011965 , 0.366301  , 0.23117855, 0.78291315,\n",
       "         0.94464254, 0.8239004 , 0.66859555, 0.9006266 , 0.9542367 ,\n",
       "         0.02446866, 0.15108381, 0.7844995 , 0.67612845, 0.66081905]],\n",
       "       dtype=float32),\n",
       " array([[0.02609196, 0.6745208 , 0.36232194, 0.22677952, 0.78287446,\n",
       "         0.9342643 , 0.88294643, 0.6824161 , 0.8998028 , 0.9397665 ,\n",
       "         0.03078884, 0.09337578, 0.822923  , 0.67555887, 0.67268574]],\n",
       "       dtype=float32),\n",
       " array([[0.02023283, 0.68810934, 0.35114416, 0.21512367, 0.7834553 ,\n",
       "         0.942993  , 0.8800243 , 0.6843167 , 0.9124329 , 0.95168257,\n",
       "         0.026841  , 0.06280853, 0.8111748 , 0.68602973, 0.6700307 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03735735, 0.6750553 , 0.3466671 , 0.23132303, 0.77932245,\n",
       "         0.92201495, 0.90037256, 0.6865898 , 0.9019225 , 0.91986674,\n",
       "         0.03642945, 0.04305785, 0.85918444, 0.68531644, 0.67216164]],\n",
       "       dtype=float32),\n",
       " array([[0.01283072, 0.72187454, 0.3583499 , 0.28089377, 0.78115976,\n",
       "         0.9594361 , 0.7764687 , 0.6787683 , 0.92962015, 0.9690887 ,\n",
       "         0.02319773, 0.2703651 , 0.7865945 , 0.6810435 , 0.6602132 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01308963, 0.7300741 , 0.37289575, 0.31022415, 0.777742  ,\n",
       "         0.95674676, 0.7509868 , 0.6654299 , 0.9084048 , 0.9666587 ,\n",
       "         0.02422056, 0.48893324, 0.7521318 , 0.6719774 , 0.65103173]],\n",
       "       dtype=float32),\n",
       " array([[0.00790759, 0.7430407 , 0.40112   , 0.34757346, 0.77683246,\n",
       "         0.9679327 , 0.6519698 , 0.6503697 , 0.9208494 , 0.97863984,\n",
       "         0.01937231, 0.6890657 , 0.69170594, 0.67106885, 0.6462782 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00965521, 0.7475779 , 0.38018325, 0.3350045 , 0.77235776,\n",
       "         0.9641352 , 0.6624548 , 0.6394856 , 0.92167425, 0.9749257 ,\n",
       "         0.02105247, 0.6019687 , 0.71743923, 0.68816376, 0.6379148 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01562433, 0.7270059 , 0.3834908 , 0.34362254, 0.7767608 ,\n",
       "         0.9555377 , 0.6975907 , 0.6548766 , 0.9052443 , 0.963201  ,\n",
       "         0.02483299, 0.46956712, 0.76954603, 0.67365015, 0.6483481 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01333545, 0.7227108 , 0.36675507, 0.3108795 , 0.78191954,\n",
       "         0.9603716 , 0.74497664, 0.66712654, 0.90977305, 0.9685866 ,\n",
       "         0.02204455, 0.28258553, 0.7750025 , 0.6770648 , 0.6537159 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01824852, 0.72735053, 0.3581894 , 0.2743806 , 0.7832293 ,\n",
       "         0.9537053 , 0.8694907 , 0.68194646, 0.93062013, 0.9601574 ,\n",
       "         0.02369546, 0.07634371, 0.8531993 , 0.669777  , 0.6561792 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0279597 , 0.69196063, 0.36235234, 0.2649398 , 0.7777343 ,\n",
       "         0.9354172 , 0.87013286, 0.67245597, 0.9013206 , 0.9380855 ,\n",
       "         0.0309144 , 0.07335213, 0.83677346, 0.6796302 , 0.66455287]],\n",
       "       dtype=float32),\n",
       " array([[0.04671044, 0.7025582 , 0.33558246, 0.22026446, 0.7768146 ,\n",
       "         0.9154663 , 0.9533908 , 0.6927641 , 0.92955303, 0.9073132 ,\n",
       "         0.03697465, 0.00790982, 0.91431683, 0.6805525 , 0.665399  ]],\n",
       "       dtype=float32),\n",
       " array([[0.07529747, 0.672371  , 0.33014527, 0.21106301, 0.77057016,\n",
       "         0.87929696, 0.96216094, 0.6911586 , 0.9064029 , 0.851868  ,\n",
       "         0.05171933, 0.00754667, 0.91481596, 0.68849033, 0.6724819 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06682301, 0.6730668 , 0.33873028, 0.22077131, 0.7703083 ,\n",
       "         0.8830164 , 0.9381798 , 0.6894478 , 0.8920607 , 0.86180824,\n",
       "         0.04902863, 0.01920658, 0.8892445 , 0.68307966, 0.67399913]],\n",
       "       dtype=float32),\n",
       " array([[0.12041555, 0.64497334, 0.3027836 , 0.17639709, 0.76610935,\n",
       "         0.82824314, 0.96293926, 0.6999021 , 0.89236724, 0.7732231 ,\n",
       "         0.07252262, 0.00983422, 0.91876656, 0.70281965, 0.67974234]],\n",
       "       dtype=float32),\n",
       " array([[0.13810737, 0.6451648 , 0.30597886, 0.16043589, 0.7697954 ,\n",
       "         0.80975497, 0.95634186, 0.7112852 , 0.8928774 , 0.7471088 ,\n",
       "         0.07473262, 0.02129552, 0.92228043, 0.6870788 , 0.68154806]],\n",
       "       dtype=float32),\n",
       " array([[0.12205915, 0.6341544 , 0.30824006, 0.15867637, 0.7712268 ,\n",
       "         0.8188473 , 0.9422204 , 0.714001  , 0.88845736, 0.76722246,\n",
       "         0.07276471, 0.0352773 , 0.90636164, 0.6885109 , 0.68739146]],\n",
       "       dtype=float32),\n",
       " array([[0.18931963, 0.6563984 , 0.29569456, 0.15917304, 0.76435846,\n",
       "         0.7693956 , 0.9611493 , 0.7158173 , 0.91174656, 0.6791947 ,\n",
       "         0.09450547, 0.02949137, 0.9408432 , 0.69182736, 0.67675424]],\n",
       "       dtype=float32),\n",
       " array([[0.20127255, 0.621566  , 0.29228735, 0.15348941, 0.76680017,\n",
       "         0.75468165, 0.9364698 , 0.7205037 , 0.883784  , 0.6580455 ,\n",
       "         0.10086271, 0.05230343, 0.9225655 , 0.6962237 , 0.68958765]],\n",
       "       dtype=float32),\n",
       " array([[0.18916973, 0.60834277, 0.28520918, 0.12997904, 0.77033246,\n",
       "         0.7532519 , 0.9229617 , 0.72518235, 0.8752971 , 0.6678737 ,\n",
       "         0.09572405, 0.06174463, 0.90802026, 0.69962454, 0.69481176]],\n",
       "       dtype=float32),\n",
       " array([[0.14051133, 0.635491  , 0.2982312 , 0.14943112, 0.7680815 ,\n",
       "         0.79323083, 0.8758154 , 0.71357644, 0.8879535 , 0.73696476,\n",
       "         0.07973648, 0.11281904, 0.88902754, 0.698656  , 0.6875831 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07805737, 0.6425207 , 0.3212329 , 0.16674626, 0.7699415 ,\n",
       "         0.8487751 , 0.81552607, 0.7045959 , 0.8874271 , 0.8313336 ,\n",
       "         0.05990058, 0.1936297 , 0.8330258 , 0.6968426 , 0.6885567 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07344389, 0.6701476 , 0.32381314, 0.18056646, 0.7674266 ,\n",
       "         0.85931075, 0.8676035 , 0.7017615 , 0.91057444, 0.84306955,\n",
       "         0.05710356, 0.10432306, 0.86363816, 0.6945574 , 0.68100536]],\n",
       "       dtype=float32),\n",
       " array([[0.05491363, 0.64341116, 0.34724414, 0.18171261, 0.7705848 ,\n",
       "         0.87197983, 0.7808722 , 0.6960458 , 0.8861122 , 0.86946076,\n",
       "         0.05178239, 0.25908917, 0.78621066, 0.6901938 , 0.6910672 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06007894, 0.65284777, 0.3406201 , 0.17743605, 0.7699663 ,\n",
       "         0.8674323 , 0.8365644 , 0.69932395, 0.8988924 , 0.86108136,\n",
       "         0.05342845, 0.14878897, 0.8208053 , 0.6895716 , 0.6892062 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06791919, 0.6397762 , 0.33523542, 0.16230023, 0.77168465,\n",
       "         0.8556604 , 0.83561003, 0.7020387 , 0.8868823 , 0.8454341 ,\n",
       "         0.05537094, 0.15311219, 0.81898016, 0.6892392 , 0.6922542 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03963906, 0.67805403, 0.35016245, 0.1886614 , 0.7697964 ,\n",
       "         0.894592  , 0.7663777 , 0.68654716, 0.9006484 , 0.9015494 ,\n",
       "         0.04063028, 0.19830641, 0.775226  , 0.6878227 , 0.6818399 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03061465, 0.67607665, 0.3472517 , 0.18316416, 0.77380216,\n",
       "         0.91047   , 0.74661744, 0.6909477 , 0.90628654, 0.922139  ,\n",
       "         0.0359548 , 0.22888897, 0.75658053, 0.6896273 , 0.68402183]],\n",
       "       dtype=float32),\n",
       " array([[0.04037836, 0.6768775 , 0.34184968, 0.18081251, 0.7728825 ,\n",
       "         0.89871734, 0.81191826, 0.6944276 , 0.91331327, 0.90434426,\n",
       "         0.04056166, 0.15775141, 0.80940455, 0.69025135, 0.68161774]],\n",
       "       dtype=float32),\n",
       " array([[0.03108427, 0.64005226, 0.3428259 , 0.1595821 , 0.78011894,\n",
       "         0.90825826, 0.7563268 , 0.7007769 , 0.88858765, 0.92048216,\n",
       "         0.03669913, 0.25550067, 0.7351863 , 0.69072264, 0.6951844 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01852612, 0.66657025, 0.363645  , 0.18511117, 0.77960676,\n",
       "         0.9318024 , 0.66337943, 0.6885314 , 0.90250665, 0.9489225 ,\n",
       "         0.02951326, 0.53556913, 0.67790365, 0.68475324, 0.6863147 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02306853, 0.66357267, 0.352518  , 0.17661224, 0.78105575,\n",
       "         0.9260489 , 0.73759043, 0.6955515 , 0.909426  , 0.9405863 ,\n",
       "         0.03185593, 0.35196227, 0.73777694, 0.68576187, 0.68732715]],\n",
       "       dtype=float32),\n",
       " array([[0.03205842, 0.64988184, 0.3432356 , 0.17055616, 0.78121567,\n",
       "         0.9117442 , 0.7799274 , 0.6985162 , 0.89553165, 0.9214399 ,\n",
       "         0.0366677 , 0.24437347, 0.7677032 , 0.6867219 , 0.6895741 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02126858, 0.67580366, 0.34737462, 0.20441118, 0.7806665 ,\n",
       "         0.9342814 , 0.72652173, 0.69317377, 0.91062003, 0.94656324,\n",
       "         0.0306565 , 0.30958784, 0.7483067 , 0.6881729 , 0.6831858 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00659825, 0.702722  , 0.36457318, 0.2391598 , 0.7849607 ,\n",
       "         0.9664589 , 0.47889608, 0.684135  , 0.9241196 , 0.98061794,\n",
       "         0.01943741, 0.8197092 , 0.58485365, 0.6893842 , 0.6766942 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00879379, 0.70239925, 0.3579282 , 0.25647426, 0.78329223,\n",
       "         0.9614813 , 0.5407602 , 0.679214  , 0.9036391 , 0.9750779 ,\n",
       "         0.02171883, 0.7293093 , 0.61694086, 0.68851286, 0.6724625 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00875588, 0.7106832 , 0.36041483, 0.25927904, 0.78300506,\n",
       "         0.96307933, 0.67559505, 0.67978853, 0.9180659 , 0.97571373,\n",
       "         0.02099731, 0.44575945, 0.6743909 , 0.68642074, 0.6711277 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01799583, 0.69152457, 0.37548414, 0.24996561, 0.7786017 ,\n",
       "         0.94338906, 0.75196606, 0.67135084, 0.90490794, 0.95440996,\n",
       "         0.02702023, 0.23734914, 0.74293274, 0.68386996, 0.6722324 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03940534, 0.6929699 , 0.38434783, 0.2521423 , 0.77114207,\n",
       "         0.9138153 , 0.88702935, 0.6685389 , 0.9158939 , 0.91264   ,\n",
       "         0.03695129, 0.0541893 , 0.85374814, 0.6780477 , 0.66846454]],\n",
       "       dtype=float32),\n",
       " array([[0.04380103, 0.69457954, 0.38237938, 0.26172507, 0.7688591 ,\n",
       "         0.9077874 , 0.8936411 , 0.66613555, 0.9057709 , 0.9028764 ,\n",
       "         0.03902416, 0.04978147, 0.85502315, 0.6771999 , 0.6670124 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0304623 , 0.6920805 , 0.3599967 , 0.24189293, 0.77471375,\n",
       "         0.92616266, 0.8845798 , 0.67912686, 0.90660757, 0.9293424 ,\n",
       "         0.03262416, 0.03680698, 0.832166  , 0.6828639 , 0.6743655 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02661855, 0.69595504, 0.3581453 , 0.26485306, 0.77406776,\n",
       "         0.93220115, 0.84634614, 0.67945737, 0.90462035, 0.9370103 ,\n",
       "         0.03271626, 0.0821818 , 0.81189525, 0.683968  , 0.6733996 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02849617, 0.7152239 , 0.35367364, 0.27578726, 0.77134943,\n",
       "         0.93017876, 0.86006516, 0.67865396, 0.91629165, 0.93378633,\n",
       "         0.03453945, 0.09894413, 0.8362712 , 0.68080956, 0.6651579 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02473454, 0.7146571 , 0.37391344, 0.29035085, 0.7699435 ,\n",
       "         0.9333904 , 0.85727525, 0.6712371 , 0.9137758 , 0.9393541 ,\n",
       "         0.03364179, 0.15645504, 0.8143699 , 0.6751094 , 0.6643013 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01764669, 0.7068421 , 0.38231158, 0.29252425, 0.7726345 ,\n",
       "         0.94318765, 0.75493157, 0.6685543 , 0.9083135 , 0.95374763,\n",
       "         0.03027471, 0.4216631 , 0.7443581 , 0.6771005 , 0.6669738 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00811375, 0.7579531 , 0.39747593, 0.32394868, 0.7723828 ,\n",
       "         0.96513224, 0.6475348 , 0.65249014, 0.9396215 , 0.97751963,\n",
       "         0.01984726, 0.64156634, 0.70194906, 0.6758609 , 0.6473569 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01230263, 0.7369166 , 0.38153636, 0.3431349 , 0.7727141 ,\n",
       "         0.9566258 , 0.5665338 , 0.6513699 , 0.9033908 , 0.96760833,\n",
       "         0.02462433, 0.746089  , 0.6887961 , 0.68137664, 0.6486922 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01381528, 0.7150518 , 0.36712623, 0.3024168 , 0.7787553 ,\n",
       "         0.95495147, 0.629257  , 0.6665696 , 0.90590894, 0.9653568 ,\n",
       "         0.02530852, 0.58691394, 0.72043145, 0.6844772 , 0.65938854]],\n",
       "       dtype=float32),\n",
       " array([[0.01849428, 0.7081044 , 0.36503094, 0.29986164, 0.77786547,\n",
       "         0.94795316, 0.7434081 , 0.67199016, 0.9105716 , 0.9559273 ,\n",
       "         0.02915207, 0.35815424, 0.778104  , 0.6833935 , 0.6623883 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01900206, 0.7106404 , 0.37432745, 0.2822481 , 0.77960527,\n",
       "         0.94604695, 0.79147834, 0.67254496, 0.90499395, 0.95406705,\n",
       "         0.02653308, 0.18175554, 0.78365237, 0.67238486, 0.664432  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02262716, 0.696553  , 0.35046217, 0.2406825 , 0.77935785,\n",
       "         0.93942314, 0.85464823, 0.67975056, 0.90957665, 0.94652766,\n",
       "         0.02887542, 0.06316898, 0.8108226 , 0.68685895, 0.6704126 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03258184, 0.68050015, 0.33397534, 0.19904198, 0.78108954,\n",
       "         0.9236758 , 0.8941893 , 0.69351506, 0.91186416, 0.9269805 ,\n",
       "         0.03356009, 0.03262763, 0.8463399 , 0.6892675 , 0.67666405]],\n",
       "       dtype=float32),\n",
       " array([[0.03347275, 0.6770029 , 0.34940538, 0.22549604, 0.7771728 ,\n",
       "         0.9210308 , 0.87181515, 0.685233  , 0.90057564, 0.92325217,\n",
       "         0.0356602 , 0.05641559, 0.8280189 , 0.6859974 , 0.67726487]],\n",
       "       dtype=float32),\n",
       " array([[0.03745739, 0.6733133 , 0.34368196, 0.20405354, 0.7776971 ,\n",
       "         0.91278636, 0.88128924, 0.6920997 , 0.9061445 , 0.91448814,\n",
       "         0.03864839, 0.07268812, 0.8371726 , 0.68539184, 0.67811257]],\n",
       "       dtype=float32),\n",
       " array([[0.04411973, 0.6744527 , 0.34160298, 0.18630709, 0.77546555,\n",
       "         0.899149  , 0.89795774, 0.6885054 , 0.90252876, 0.89864707,\n",
       "         0.04138219, 0.0683346 , 0.8424779 , 0.68632656, 0.6745226 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0642526 , 0.6761903 , 0.3302927 , 0.17946303, 0.77204067,\n",
       "         0.8749678 , 0.9246954 , 0.69166005, 0.9072898 , 0.8618504 ,\n",
       "         0.05024245, 0.04524581, 0.8780407 , 0.6889193 , 0.6723999 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06851308, 0.6771838 , 0.33065626, 0.20199102, 0.76742446,\n",
       "         0.87065077, 0.89742506, 0.6841829 , 0.9028195 , 0.85381806,\n",
       "         0.0550881 , 0.0830956 , 0.8698702 , 0.6948545 , 0.67028   ]],\n",
       "       dtype=float32),\n",
       " array([[0.08446048, 0.65080386, 0.31703648, 0.17594111, 0.7745658 ,\n",
       "         0.85443807, 0.8771112 , 0.7028889 , 0.88522714, 0.82847387,\n",
       "         0.05968472, 0.12519367, 0.86974096, 0.6900122 , 0.6804864 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06420083, 0.64025545, 0.3102292 , 0.15591823, 0.7822787 ,\n",
       "         0.8759972 , 0.8555883 , 0.7168416 , 0.8910644 , 0.8649726 ,\n",
       "         0.05132181, 0.16031913, 0.8527348 , 0.6870525 , 0.68865603]],\n",
       "       dtype=float32),\n",
       " array([[0.05726529, 0.6517479 , 0.32175577, 0.1657671 , 0.7810258 ,\n",
       "         0.8828695 , 0.84602326, 0.71002305, 0.89128757, 0.8759496 ,\n",
       "         0.04743676, 0.15837799, 0.8420485 , 0.68276566, 0.6858123 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03210012, 0.68138635, 0.34159473, 0.20094739, 0.7772636 ,\n",
       "         0.917134  , 0.787527  , 0.6931302 , 0.91493607, 0.9244741 ,\n",
       "         0.03734473, 0.257632  , 0.80462575, 0.6876383 , 0.6770374 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0179944 , 0.7022806 , 0.36661974, 0.2450324 , 0.77597886,\n",
       "         0.94071174, 0.6858511 , 0.6778951 , 0.9181318 , 0.9536011 ,\n",
       "         0.02963324, 0.5516323 , 0.7372359 , 0.6821948 , 0.6695695 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01317474, 0.7039647 , 0.3713852 , 0.27978322, 0.7770739 ,\n",
       "         0.95223796, 0.62957543, 0.67284673, 0.907572  , 0.96475875,\n",
       "         0.02620055, 0.6179296 , 0.6903949 , 0.6822545 , 0.6695496 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01763538, 0.68928266, 0.3577246 , 0.24781221, 0.7802027 ,\n",
       "         0.94518834, 0.75724536, 0.6871982 , 0.91699934, 0.9560471 ,\n",
       "         0.02957107, 0.3555687 , 0.76236564, 0.6840111 , 0.6759426 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01802289, 0.7015975 , 0.37044224, 0.27113804, 0.7770685 ,\n",
       "         0.9450381 , 0.72211564, 0.6721503 , 0.9073829 , 0.95522517,\n",
       "         0.02749092, 0.32879394, 0.75160605, 0.6805082 , 0.6694447 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01110028, 0.7292804 , 0.37560758, 0.28546748, 0.7775355 ,\n",
       "         0.95840615, 0.67199093, 0.66612434, 0.9203418 , 0.97066855,\n",
       "         0.02180332, 0.49672645, 0.716065  , 0.6734272 , 0.66106707]],\n",
       "       dtype=float32),\n",
       " array([[0.00392178, 0.75971943, 0.38466606, 0.32593262, 0.779426  ,\n",
       "         0.97747916, 0.45617196, 0.6555697 , 0.9373098 , 0.98827934,\n",
       "         0.01458388, 0.8551557 , 0.5812808 , 0.6815459 , 0.65038407]],\n",
       "       dtype=float32),\n",
       " array([[0.00376794, 0.7475064 , 0.38252962, 0.33232674, 0.7783692 ,\n",
       "         0.9771755 , 0.37884805, 0.64299244, 0.9138256 , 0.9882387 ,\n",
       "         0.01485846, 0.9071633 , 0.50399876, 0.691863  , 0.6489834 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00857329, 0.7136453 , 0.36500058, 0.27467024, 0.78208363,\n",
       "         0.9647826 , 0.6116273 , 0.66568065, 0.917158  , 0.97694826,\n",
       "         0.02069152, 0.612308  , 0.667084  , 0.6920849 , 0.6613188 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01762063, 0.6969006 , 0.36027318, 0.23254207, 0.7806186 ,\n",
       "         0.9458605 , 0.78611565, 0.6715473 , 0.91773486, 0.95694363,\n",
       "         0.02692676, 0.25428498, 0.77342796, 0.68917423, 0.6644607 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02696675, 0.66492367, 0.35501242, 0.2132935 , 0.7815208 ,\n",
       "         0.9286122 , 0.8106394 , 0.6785524 , 0.89190775, 0.9360777 ,\n",
       "         0.03308864, 0.21716136, 0.7828906 , 0.6887135 , 0.6733673 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03422841, 0.67529577, 0.3644488 , 0.22543406, 0.77572   ,\n",
       "         0.9188485 , 0.8697447 , 0.67205346, 0.90370566, 0.92171746,\n",
       "         0.03660349, 0.1056873 , 0.8270015 , 0.68663436, 0.66962415]],\n",
       "       dtype=float32),\n",
       " array([[0.04184472, 0.6579108 , 0.34890515, 0.21564412, 0.7795827 ,\n",
       "         0.9124057 , 0.880883  , 0.6888778 , 0.893659  , 0.9094395 ,\n",
       "         0.03913255, 0.06238701, 0.8449628 , 0.6856523 , 0.67953116]],\n",
       "       dtype=float32),\n",
       " array([[0.04236693, 0.66829187, 0.35613257, 0.2278512 , 0.7798934 ,\n",
       "         0.9138239 , 0.9009061 , 0.69401824, 0.8963548 , 0.90902585,\n",
       "         0.03776024, 0.03998215, 0.8595472 , 0.6741184 , 0.67997205]],\n",
       "       dtype=float32),\n",
       " array([[0.03426423, 0.6917104 , 0.35733983, 0.25164196, 0.77731186,\n",
       "         0.92417836, 0.8878868 , 0.68877745, 0.9038286 , 0.9237371 ,\n",
       "         0.03476563, 0.05238022, 0.85043895, 0.67299837, 0.67295134]],\n",
       "       dtype=float32),\n",
       " array([[0.04684785, 0.70254713, 0.36594048, 0.25743788, 0.7693455 ,\n",
       "         0.90660816, 0.9373421 , 0.68116117, 0.91909593, 0.89834017,\n",
       "         0.04245115, 0.02949606, 0.8882354 , 0.6727044 , 0.6665501 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0576489 , 0.6828564 , 0.35017753, 0.22901963, 0.77064747,\n",
       "         0.8897936 , 0.9303393 , 0.68734854, 0.90008426, 0.8755204 ,\n",
       "         0.0474173 , 0.03482675, 0.8791438 , 0.6778699 , 0.6724135 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03420036, 0.7002777 , 0.3574604 , 0.25843433, 0.7726779 ,\n",
       "         0.92071444, 0.8927676 , 0.6877594 , 0.91167265, 0.9210344 ,\n",
       "         0.03759836, 0.06765612, 0.84863865, 0.67426014, 0.6719594 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05334654, 0.69236475, 0.3456494 , 0.24731593, 0.77416956,\n",
       "         0.8997784 , 0.8979164 , 0.6994079 , 0.905693  , 0.8876301 ,\n",
       "         0.04551587, 0.06967992, 0.87911636, 0.6693307 , 0.67396736]],\n",
       "       dtype=float32),\n",
       " array([[0.04038301, 0.7217187 , 0.36535373, 0.31450126, 0.7668556 ,\n",
       "         0.9157698 , 0.8570088 , 0.67827326, 0.90956944, 0.9104346 ,\n",
       "         0.04125253, 0.13250227, 0.8576101 , 0.66977555, 0.66130036]],\n",
       "       dtype=float32),\n",
       " array([[0.02597382, 0.7315391 , 0.3676257 , 0.3193768 , 0.7656975 ,\n",
       "         0.93395185, 0.8112966 , 0.66825366, 0.923976  , 0.9385821 ,\n",
       "         0.034877  , 0.19326353, 0.824785  , 0.6809521 , 0.6578528 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02521146, 0.7183961 , 0.36638305, 0.2940683 , 0.7692599 ,\n",
       "         0.93334955, 0.8058922 , 0.6739571 , 0.9198948 , 0.9395058 ,\n",
       "         0.03459764, 0.23483299, 0.81168485, 0.67983955, 0.66282547]],\n",
       "       dtype=float32),\n",
       " array([[0.01848308, 0.71971166, 0.3796738 , 0.316209  , 0.7693374 ,\n",
       "         0.94397104, 0.72641444, 0.66557795, 0.91966367, 0.9534141 ,\n",
       "         0.03087729, 0.41740572, 0.76484156, 0.68126523, 0.6621692 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00921082, 0.7632203 , 0.3900281 , 0.36831787, 0.76582974,\n",
       "         0.9635961 , 0.6528264 , 0.6444215 , 0.9350188 , 0.9749117 ,\n",
       "         0.02206263, 0.5511539 , 0.7141023 , 0.685123  , 0.64368033]],\n",
       "       dtype=float32),\n",
       " array([[0.00755112, 0.73940307, 0.38223162, 0.33717346, 0.7743491 ,\n",
       "         0.96655065, 0.50455403, 0.6520407 , 0.9114661 , 0.9785735 ,\n",
       "         0.01996439, 0.77660465, 0.6204871 , 0.68528616, 0.65334314]],\n",
       "       dtype=float32),\n",
       " array([[0.00331971, 0.7734978 , 0.39296794, 0.35695112, 0.7764821 ,\n",
       "         0.9797151 , 0.38630617, 0.639283  , 0.93172044, 0.9898403 ,\n",
       "         0.01303943, 0.88518125, 0.5387005 , 0.68481565, 0.63990784]],\n",
       "       dtype=float32),\n",
       " array([[0.00843215, 0.7408527 , 0.3556347 , 0.2812393 , 0.7807919 ,\n",
       "         0.96640754, 0.6780232 , 0.667884  , 0.9290244 , 0.97784823,\n",
       "         0.0193785 , 0.464002  , 0.71502423, 0.6882092 , 0.65184736]],\n",
       "       dtype=float32),\n",
       " array([[0.00387856, 0.76586443, 0.40701213, 0.3474504 , 0.7767484 ,\n",
       "         0.9783312 , 0.50324184, 0.6385159 , 0.9401456 , 0.9886093 ,\n",
       "         0.01354725, 0.7610131 , 0.59994763, 0.68228555, 0.6419446 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00464546, 0.7533011 , 0.39410064, 0.3252943 , 0.779456  ,\n",
       "         0.9761787 , 0.5668853 , 0.64248013, 0.9282166 , 0.9866899 ,\n",
       "         0.01424292, 0.62013507, 0.6177835 , 0.68558484, 0.64457494]],\n",
       "       dtype=float32),\n",
       " array([[0.00821782, 0.72418773, 0.3747127 , 0.28674158, 0.7820734 ,\n",
       "         0.9669446 , 0.6691956 , 0.6551367 , 0.9090971 , 0.9781039 ,\n",
       "         0.01803726, 0.41196263, 0.6791    , 0.6874257 , 0.6530791 ]],\n",
       "       dtype=float32),\n",
       " array([[0.009558  , 0.710176  , 0.37176308, 0.24606627, 0.78454787,\n",
       "         0.9630549 , 0.70205605, 0.66097164, 0.9130587 , 0.97506565,\n",
       "         0.01850863, 0.28635642, 0.69724023, 0.6901252 , 0.6591401 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01923392, 0.68562376, 0.32773355, 0.19009194, 0.7882406 ,\n",
       "         0.94616926, 0.869413  , 0.6912488 , 0.91507614, 0.9555071 ,\n",
       "         0.02527701, 0.05845797, 0.81447005, 0.6946503 , 0.66938525]],\n",
       "       dtype=float32),\n",
       " array([[0.03211904, 0.6662993 , 0.3455921 , 0.20926031, 0.78267825,\n",
       "         0.92528605, 0.8728238 , 0.68600494, 0.89609313, 0.92834204,\n",
       "         0.03418514, 0.09325638, 0.8294621 , 0.68702966, 0.6723807 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04509681, 0.6725424 , 0.32555875, 0.19439563, 0.78080505,\n",
       "         0.9133643 , 0.9520861 , 0.7006703 , 0.9172828 , 0.9069774 ,\n",
       "         0.03883675, 0.008953  , 0.8973501 , 0.6893013 , 0.67634386]],\n",
       "       dtype=float32),\n",
       " array([[0.07036487, 0.6559114 , 0.33624345, 0.21073338, 0.77462626,\n",
       "         0.8823163 , 0.94836587, 0.6935488 , 0.8878326 , 0.8578497 ,\n",
       "         0.05061401, 0.01434608, 0.895197  , 0.6860107 , 0.6777552 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08259075, 0.66138804, 0.3310378 , 0.2204807 , 0.77191967,\n",
       "         0.87367755, 0.9432867 , 0.6962009 , 0.8954085 , 0.8407835 ,\n",
       "         0.05505121, 0.01372124, 0.90668803, 0.68882054, 0.67766184]],\n",
       "       dtype=float32),\n",
       " array([[0.05682481, 0.6804685 , 0.3453534 , 0.25138092, 0.7694608 ,\n",
       "         0.89698094, 0.9331389 , 0.68997157, 0.905918  , 0.8809855 ,\n",
       "         0.04924675, 0.03318436, 0.88923293, 0.68356484, 0.672511  ]],\n",
       "       dtype=float32),\n",
       " array([[0.0823392 , 0.671715  , 0.33823636, 0.25425637, 0.76734567,\n",
       "         0.8716233 , 0.9218266 , 0.6921892 , 0.89409286, 0.8380238 ,\n",
       "         0.06122554, 0.05854927, 0.89837337, 0.68423796, 0.6722107 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07003277, 0.677802  , 0.33516562, 0.22500482, 0.76922965,\n",
       "         0.8789161 , 0.9330881 , 0.69642514, 0.90904313, 0.85650516,\n",
       "         0.05510113, 0.03810311, 0.89669156, 0.6842547 , 0.67419934]],\n",
       "       dtype=float32),\n",
       " array([[0.11068641, 0.66412616, 0.3378453 , 0.2557583 , 0.7639789 ,\n",
       "         0.84231925, 0.9127348 , 0.6922138 , 0.8828777 , 0.7895364 ,\n",
       "         0.07363549, 0.09187938, 0.9007893 , 0.68338674, 0.67352015]],\n",
       "       dtype=float32),\n",
       " array([[0.07660037, 0.68156296, 0.3460617 , 0.27529344, 0.7634718 ,\n",
       "         0.87223244, 0.87718886, 0.6849897 , 0.88994604, 0.8432777 ,\n",
       "         0.06046865, 0.1202121 , 0.876525  , 0.6831707 , 0.6709414 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04304497, 0.6942364 , 0.35476917, 0.2675681 , 0.7670483 ,\n",
       "         0.906683  , 0.82463115, 0.68427396, 0.9138584 , 0.9034119 ,\n",
       "         0.04661704, 0.25198403, 0.8415397 , 0.6837019 , 0.66939974]],\n",
       "       dtype=float32),\n",
       " array([[0.03355969, 0.6941564 , 0.35416418, 0.2882594 , 0.76871324,\n",
       "         0.9211142 , 0.76246125, 0.67799854, 0.89641887, 0.9222579 ,\n",
       "         0.04009677, 0.2718583 , 0.8019875 , 0.68786716, 0.66938424]],\n",
       "       dtype=float32),\n",
       " array([[0.03646125, 0.6886434 , 0.35154602, 0.25130376, 0.7710035 ,\n",
       "         0.9163659 , 0.8357177 , 0.6866988 , 0.9147561 , 0.9172166 ,\n",
       "         0.04104525, 0.14314455, 0.83364916, 0.68818325, 0.67355573]],\n",
       "       dtype=float32),\n",
       " array([[0.03952814, 0.6695182 , 0.3574268 , 0.23935682, 0.77192414,\n",
       "         0.90767115, 0.78028226, 0.6828082 , 0.8927905 , 0.9083449 ,\n",
       "         0.04271647, 0.26232874, 0.79885554, 0.6872636 , 0.6771988 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03532223, 0.65685475, 0.3691456 , 0.24091582, 0.7726659 ,\n",
       "         0.9115452 , 0.8039618 , 0.6820243 , 0.88582146, 0.9144058 ,\n",
       "         0.04157302, 0.21926333, 0.7807516 , 0.68328625, 0.6836717 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01262434, 0.6817238 , 0.34167045, 0.2064139 , 0.78423214,\n",
       "         0.9518086 , 0.70816547, 0.70048493, 0.9236601 , 0.966081  ,\n",
       "         0.02619996, 0.43860993, 0.70990574, 0.69063014, 0.68317205]],\n",
       "       dtype=float32),\n",
       " array([[0.01551616, 0.68293864, 0.33091995, 0.1969716 , 0.78121454,\n",
       "         0.943727  , 0.654098  , 0.6864398 , 0.901447  , 0.9585726 ,\n",
       "         0.02714489, 0.4391608 , 0.6861947 , 0.7012166 , 0.6756417 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03318852, 0.66920274, 0.34697723, 0.1835598 , 0.7798269 ,\n",
       "         0.9151105 , 0.8037284 , 0.6909913 , 0.906367  , 0.9224369 ,\n",
       "         0.03522671, 0.17597096, 0.80066055, 0.68768764, 0.67783725]],\n",
       "       dtype=float32),\n",
       " array([[0.03512739, 0.6457713 , 0.34705472, 0.15945138, 0.78412235,\n",
       "         0.9094665 , 0.8028991 , 0.69731414, 0.892017  , 0.91727304,\n",
       "         0.03485814, 0.16770987, 0.78519005, 0.6847897 , 0.6861601 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01856855, 0.691418  , 0.36889768, 0.2123752 , 0.77706724,\n",
       "         0.93754995, 0.7519238 , 0.67452085, 0.9141026 , 0.95145625,\n",
       "         0.02806062, 0.3247286 , 0.7370249 , 0.6865083 , 0.670595  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02189313, 0.69234115, 0.35560736, 0.1809418 , 0.7790218 ,\n",
       "         0.9313158 , 0.8025589 , 0.68015915, 0.9196856 , 0.94511926,\n",
       "         0.02823899, 0.2282633 , 0.77453285, 0.68765724, 0.6685986 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02392538, 0.66781753, 0.3343897 , 0.18731958, 0.78031695,\n",
       "         0.9299998 , 0.7735278 , 0.6857131 , 0.89743024, 0.94112027,\n",
       "         0.03113073, 0.20359987, 0.75704765, 0.7000439 , 0.67717606]],\n",
       "       dtype=float32),\n",
       " array([[0.01323792, 0.7096945 , 0.33906144, 0.22233415, 0.78117347,\n",
       "         0.95185935, 0.67759866, 0.6807321 , 0.91244364, 0.9653547 ,\n",
       "         0.0238824 , 0.46423975, 0.71182686, 0.69295305, 0.66422933]],\n",
       "       dtype=float32),\n",
       " array([[0.01516433, 0.6940859 , 0.3432266 , 0.20973143, 0.785296  ,\n",
       "         0.947793  , 0.6799128 , 0.6889474 , 0.9030834 , 0.9610789 ,\n",
       "         0.02485617, 0.49853694, 0.7162589 , 0.6843115 , 0.6702622 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02295312, 0.68611586, 0.36326197, 0.236237  , 0.7772175 ,\n",
       "         0.93446445, 0.795796  , 0.6752876 , 0.90112185, 0.9436284 ,\n",
       "         0.03102755, 0.25737718, 0.7729268 , 0.68575084, 0.668959  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02621108, 0.6814379 , 0.35964996, 0.23462753, 0.77791995,\n",
       "         0.93100137, 0.82724404, 0.6791332 , 0.89681476, 0.93765944,\n",
       "         0.03177631, 0.15475297, 0.7938881 , 0.6849415 , 0.6714696 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03416425, 0.6879442 , 0.37295705, 0.25246492, 0.7719461 ,\n",
       "         0.92031795, 0.8517257 , 0.66845256, 0.9012619 , 0.9220895 ,\n",
       "         0.03503347, 0.09291656, 0.8237692 , 0.68483776, 0.6673599 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03087251, 0.70978785, 0.36704493, 0.27831158, 0.76971155,\n",
       "         0.9265559 , 0.823995  , 0.66521525, 0.9062175 , 0.9293674 ,\n",
       "         0.03397829, 0.14243905, 0.82160634, 0.6862314 , 0.65857744]],\n",
       "       dtype=float32),\n",
       " array([[0.0314488 , 0.70572555, 0.3642955 , 0.27397862, 0.7700279 ,\n",
       "         0.92610294, 0.85405076, 0.6681803 , 0.9057968 , 0.9280636 ,\n",
       "         0.03446214, 0.09316869, 0.82934004, 0.6877164 , 0.66091126]],\n",
       "       dtype=float32),\n",
       " array([[0.00959688, 0.7669285 , 0.37755424, 0.31709576, 0.7692624 ,\n",
       "         0.96187645, 0.6918176 , 0.64543486, 0.92593354, 0.973905  ,\n",
       "         0.01935006, 0.39055672, 0.71483624, 0.6849632 , 0.63881993]],\n",
       "       dtype=float32),\n",
       " array([[0.01342199, 0.7339529 , 0.358789  , 0.2686648 , 0.7749612 ,\n",
       "         0.95306927, 0.7310224 , 0.6643197 , 0.9145123 , 0.96508217,\n",
       "         0.02325819, 0.36510593, 0.737407  , 0.68644106, 0.6523272 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03811463, 0.68702495, 0.3653011 , 0.2606624 , 0.77234334,\n",
       "         0.91916007, 0.89027005, 0.67841274, 0.91208935, 0.9170361 ,\n",
       "         0.03884517, 0.0840752 , 0.8579346 , 0.68417734, 0.66758245]],\n",
       "       dtype=float32),\n",
       " array([[0.04948666, 0.66343254, 0.3731829 , 0.25097337, 0.7715412 ,\n",
       "         0.9027992 , 0.88658077, 0.6762749 , 0.8931147 , 0.8939501 ,\n",
       "         0.04357081, 0.0809244 , 0.8526068 , 0.6836531 , 0.6740262 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04839851, 0.6591688 , 0.3569872 , 0.23705724, 0.774116  ,\n",
       "         0.9043335 , 0.8833087 , 0.6857231 , 0.8927094 , 0.8964095 ,\n",
       "         0.04359576, 0.07616661, 0.8520561 , 0.68557274, 0.6781541 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07118362, 0.62191087, 0.33256903, 0.19890556, 0.7787034 ,\n",
       "         0.880884  , 0.90306044, 0.70716155, 0.8854442 , 0.85882425,\n",
       "         0.05453091, 0.05902221, 0.87591225, 0.69030154, 0.69128305]],\n",
       "       dtype=float32),\n",
       " array([[0.05348463, 0.6496241 , 0.3345405 , 0.19687432, 0.7784188 ,\n",
       "         0.8966661 , 0.88619685, 0.70131797, 0.89476126, 0.88761866,\n",
       "         0.04481328, 0.06097761, 0.85891414, 0.6887826 , 0.6841377 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04526785, 0.6554633 , 0.34932092, 0.22181039, 0.7754517 ,\n",
       "         0.9042094 , 0.85898125, 0.69222546, 0.89116466, 0.89991885,\n",
       "         0.04368992, 0.11705101, 0.8335201 , 0.6869894 , 0.6817039 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03601804, 0.65845567, 0.346183  , 0.21570691, 0.77802426,\n",
       "         0.91491693, 0.83429986, 0.6954629 , 0.8930711 , 0.9171033 ,\n",
       "         0.03956677, 0.17207289, 0.81118757, 0.68533504, 0.6826903 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02159453, 0.67860925, 0.35346612, 0.23883915, 0.77760094,\n",
       "         0.93753713, 0.80274224, 0.6892461 , 0.9115383 , 0.9469792 ,\n",
       "         0.03280882, 0.30957964, 0.78259593, 0.68243885, 0.6784193 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03426539, 0.6975397 , 0.3488315 , 0.22366658, 0.77319485,\n",
       "         0.91773176, 0.8632033 , 0.68550706, 0.9208238 , 0.92154604,\n",
       "         0.0378459 , 0.13959892, 0.84076726, 0.6863839 , 0.66681695]],\n",
       "       dtype=float32),\n",
       " array([[0.05216147, 0.6576292 , 0.3397953 , 0.21590574, 0.7725025 ,\n",
       "         0.894533  , 0.85978013, 0.6886836 , 0.8955529 , 0.88679826,\n",
       "         0.04824093, 0.11842608, 0.8428256 , 0.6957666 , 0.6781794 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04331745, 0.70269734, 0.35803798, 0.2480268 , 0.76910007,\n",
       "         0.9059703 , 0.8415672 , 0.67462933, 0.90208447, 0.9031319 ,\n",
       "         0.03994299, 0.13192548, 0.8391795 , 0.6819224 , 0.66271925]],\n",
       "       dtype=float32),\n",
       " array([[0.03572127, 0.7071469 , 0.35197714, 0.22940418, 0.7726498 ,\n",
       "         0.9161792 , 0.8525554 , 0.6822329 , 0.91319627, 0.91881216,\n",
       "         0.03535199, 0.1145026 , 0.83967716, 0.6793293 , 0.66473454]],\n",
       "       dtype=float32),\n",
       " array([[0.03907349, 0.6788941 , 0.34351495, 0.20211649, 0.7750649 ,\n",
       "         0.90879476, 0.8481118 , 0.6889761 , 0.9052884 , 0.9109197 ,\n",
       "         0.03842349, 0.11065755, 0.82808495, 0.687422  , 0.6748371 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03959432, 0.6773978 , 0.3401939 , 0.20435871, 0.7747679 ,\n",
       "         0.9088398 , 0.8622795 , 0.6903961 , 0.903712  , 0.90979517,\n",
       "         0.03871528, 0.07364871, 0.8322524 , 0.68878275, 0.67711705]],\n",
       "       dtype=float32),\n",
       " array([[0.02125884, 0.7023764 , 0.35206655, 0.22005051, 0.7757563 ,\n",
       "         0.9343229 , 0.76979345, 0.6835568 , 0.9178373 , 0.94622743,\n",
       "         0.03040031, 0.2884106 , 0.7699849 , 0.6852546 , 0.6696261 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02989985, 0.67748505, 0.3386507 , 0.18783136, 0.7779766 ,\n",
       "         0.91925275, 0.8182039 , 0.69317776, 0.91273475, 0.92819697,\n",
       "         0.03563294, 0.19434156, 0.80018866, 0.689903  , 0.6769654 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03770768, 0.6641652 , 0.34515172, 0.19452372, 0.77633905,\n",
       "         0.90721464, 0.83776367, 0.6900468 , 0.8962304 , 0.91099936,\n",
       "         0.03994912, 0.16509266, 0.8063448 , 0.6875294 , 0.6793107 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01767379, 0.7121944 , 0.3557375 , 0.23912583, 0.7746364 ,\n",
       "         0.9416662 , 0.7281055 , 0.6766913 , 0.92102486, 0.95441043,\n",
       "         0.02860108, 0.3895978 , 0.74972564, 0.688786  , 0.6646667 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03188876, 0.69614935, 0.3460618 , 0.22650053, 0.7716404 ,\n",
       "         0.91908294, 0.8076778 , 0.6780472 , 0.9138562 , 0.92509115,\n",
       "         0.0372899 , 0.20930718, 0.8099939 , 0.6952967 , 0.665761  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01554883, 0.7280197 , 0.35500303, 0.25654763, 0.77704483,\n",
       "         0.94930226, 0.756413  , 0.6817954 , 0.92725384, 0.96079445,\n",
       "         0.0256035 , 0.31649828, 0.77180386, 0.6822058 , 0.6607148 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00491174, 0.77081245, 0.3677512 , 0.28337505, 0.7767421 ,\n",
       "         0.9727386 , 0.507753  , 0.65721965, 0.9401298 , 0.9853516 ,\n",
       "         0.01538724, 0.8066277 , 0.61301565, 0.6868063 , 0.6427238 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00200256, 0.78285855, 0.3705115 , 0.31532267, 0.7815782 ,\n",
       "         0.9841031 , 0.29487664, 0.65072554, 0.9404662 , 0.99338526,\n",
       "         0.01089356, 0.96480685, 0.4615592 , 0.6888177 , 0.6382845 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0047961 , 0.7228915 , 0.35413373, 0.24230097, 0.7883508 ,\n",
       "         0.9735692 , 0.44154716, 0.6689248 , 0.9115367 , 0.98586696,\n",
       "         0.01508433, 0.8502916 , 0.5486948 , 0.69290507, 0.65827006]],\n",
       "       dtype=float32),\n",
       " array([[0.00519061, 0.73759073, 0.3855515 , 0.3010774 , 0.7819405 ,\n",
       "         0.97385603, 0.53025717, 0.650085  , 0.9186997 , 0.9851216 ,\n",
       "         0.01539622, 0.7523204 , 0.600107  , 0.6867856 , 0.64918554]],\n",
       "       dtype=float32),\n",
       " array([[0.00646381, 0.74306315, 0.3955533 , 0.3133603 , 0.7788371 ,\n",
       "         0.97074515, 0.5728835 , 0.6425266 , 0.92270994, 0.9822114 ,\n",
       "         0.0165331 , 0.6959241 , 0.64502794, 0.68455374, 0.64369404]],\n",
       "       dtype=float32),\n",
       " array([[0.005545  , 0.7551295 , 0.40414187, 0.3478567 , 0.77541625,\n",
       "         0.974337  , 0.57765394, 0.631547  , 0.93207234, 0.9847888 ,\n",
       "         0.01547595, 0.63667315, 0.65112126, 0.6891903 , 0.63794744]],\n",
       "       dtype=float32),\n",
       " array([[0.00558217, 0.7604911 , 0.40424904, 0.3543301 , 0.7776635 ,\n",
       "         0.9755136 , 0.6635797 , 0.6401741 , 0.9347612 , 0.98509514,\n",
       "         0.014722  , 0.45072085, 0.6924678 , 0.680517  , 0.63869673]],\n",
       "       dtype=float32),\n",
       " array([[0.00767593, 0.73436403, 0.3700879 , 0.3141164 , 0.7819823 ,\n",
       "         0.9714262 , 0.7447983 , 0.65617704, 0.9212396 , 0.98065335,\n",
       "         0.01683618, 0.1776017 , 0.72898275, 0.6932561 , 0.6495784 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01410621, 0.7258065 , 0.35994035, 0.28814784, 0.7775431 ,\n",
       "         0.95791036, 0.83304083, 0.65808547, 0.92063016, 0.96652055,\n",
       "         0.0226192 , 0.0940569 , 0.7963181 , 0.6960746 , 0.6493352 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01710982, 0.71124387, 0.3641343 , 0.28258327, 0.7786919 ,\n",
       "         0.9520451 , 0.844754  , 0.6645236 , 0.9064536 , 0.9595587 ,\n",
       "         0.0247518 , 0.10552163, 0.79906064, 0.6870302 , 0.65532726]],\n",
       "       dtype=float32),\n",
       " array([[0.00494634, 0.7668002 , 0.40920857, 0.33967128, 0.7749295 ,\n",
       "         0.9761569 , 0.7360163 , 0.63746065, 0.9457078 , 0.98621076,\n",
       "         0.01452015, 0.40333384, 0.70006925, 0.6823111 , 0.63539475]],\n",
       "       dtype=float32),\n",
       " array([[0.00599779, 0.7637317 , 0.37665325, 0.309033  , 0.77826434,\n",
       "         0.97354704, 0.72722167, 0.64610845, 0.9319491 , 0.98384494,\n",
       "         0.01499675, 0.36978385, 0.70810103, 0.68578166, 0.63413477]],\n",
       "       dtype=float32),\n",
       " array([[0.00941962, 0.7350041 , 0.37512654, 0.3332735 , 0.7788026 ,\n",
       "         0.96754843, 0.76005965, 0.65506   , 0.9157872 , 0.9764864 ,\n",
       "         0.01953888, 0.29780114, 0.74742174, 0.68595815, 0.64523035]],\n",
       "       dtype=float32),\n",
       " array([[0.01871004, 0.7464836 , 0.36975423, 0.33771676, 0.7734282 ,\n",
       "         0.95311767, 0.84054005, 0.65627396, 0.92620856, 0.9585041 ,\n",
       "         0.02618296, 0.17305389, 0.8420266 , 0.6818301 , 0.63652116]],\n",
       "       dtype=float32),\n",
       " array([[0.02068548, 0.7238709 , 0.38143963, 0.33670527, 0.77317977,\n",
       "         0.94770706, 0.8192648 , 0.6551606 , 0.90954053, 0.9527732 ,\n",
       "         0.02894352, 0.27936092, 0.81733316, 0.6783213 , 0.64460856]],\n",
       "       dtype=float32),\n",
       " array([[0.02874915, 0.72097236, 0.3688626 , 0.3136242 , 0.7715544 ,\n",
       "         0.936472  , 0.88265336, 0.66490746, 0.91612965, 0.9372981 ,\n",
       "         0.03366468, 0.12793112, 0.8595204 , 0.679271  , 0.6478122 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02351429, 0.7226933 , 0.35696605, 0.31676137, 0.77327055,\n",
       "         0.9454913 , 0.8837111 , 0.66828954, 0.91411436, 0.9481192 ,\n",
       "         0.02944136, 0.06120511, 0.85122824, 0.68536407, 0.6514511 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04987002, 0.7054296 , 0.34814826, 0.28175116, 0.77255887,\n",
       "         0.9167767 , 0.93715745, 0.6837895 , 0.91646737, 0.9031358 ,\n",
       "         0.03979184, 0.01472715, 0.9091505 , 0.68174356, 0.6593808 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07034477, 0.67842793, 0.3470183 , 0.2459531 , 0.7733332 ,\n",
       "         0.89116395, 0.9333958 , 0.6886794 , 0.89069164, 0.8653327 ,\n",
       "         0.04558807, 0.01759731, 0.9037658 , 0.6778736 , 0.66817725]],\n",
       "       dtype=float32),\n",
       " array([[0.08309635, 0.66780084, 0.34182972, 0.23523064, 0.7696559 ,\n",
       "         0.8759673 , 0.9572851 , 0.692107  , 0.8950235 , 0.84109795,\n",
       "         0.0537503 , 0.01189917, 0.91522247, 0.6828628 , 0.6717555 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07178468, 0.66789144, 0.33892533, 0.23321632, 0.7669074 ,\n",
       "         0.8803634 , 0.94491804, 0.6884499 , 0.8975333 , 0.8546246 ,\n",
       "         0.05346547, 0.01740625, 0.89714175, 0.6918634 , 0.67322475]],\n",
       "       dtype=float32),\n",
       " array([[0.08144847, 0.653198  , 0.32969746, 0.21210696, 0.7673546 ,\n",
       "         0.8656552 , 0.93575567, 0.69268566, 0.88630956, 0.83511114,\n",
       "         0.05864805, 0.02893406, 0.8894044 , 0.6942909 , 0.6772691 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05321553, 0.70149106, 0.33836678, 0.25888184, 0.7673431 ,\n",
       "         0.90195006, 0.9113352 , 0.69050384, 0.9116218 , 0.88904697,\n",
       "         0.04559654, 0.04618739, 0.8872221 , 0.6838526 , 0.66507065]],\n",
       "       dtype=float32),\n",
       " array([[0.06377322, 0.6761098 , 0.3349129 , 0.21843468, 0.77233213,\n",
       "         0.8863358 , 0.9142618 , 0.7015565 , 0.89847904, 0.8685548 ,\n",
       "         0.0488259 , 0.05310236, 0.8848012 , 0.6781058 , 0.67459494]],\n",
       "       dtype=float32),\n",
       " array([[0.04855808, 0.68151546, 0.32720405, 0.18512724, 0.77970666,\n",
       "         0.90120685, 0.8975765 , 0.7138897 , 0.91109544, 0.8963818 ,\n",
       "         0.04032287, 0.06744045, 0.8731634 , 0.6731764 , 0.6770325 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06296058, 0.6418419 , 0.32332087, 0.15945977, 0.7789247 ,\n",
       "         0.876023  , 0.8780534 , 0.7108049 , 0.8874706 , 0.86512995,\n",
       "         0.04860983, 0.09971613, 0.8509986 , 0.6858379 , 0.6855314 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08689248, 0.6417293 , 0.30643573, 0.1650766 , 0.77274114,\n",
       "         0.8551649 , 0.8931008 , 0.70535904, 0.8933514 , 0.82804847,\n",
       "         0.05922626, 0.05878055, 0.8791294 , 0.7043771 , 0.6816416 ]],\n",
       "       dtype=float32),\n",
       " array([[0.10680167, 0.6247975 , 0.3260542 , 0.16434456, 0.76849365,\n",
       "         0.8261002 , 0.8641666 , 0.6951392 , 0.88075185, 0.7890343 ,\n",
       "         0.06791527, 0.1208351 , 0.8640427 , 0.70308614, 0.6837892 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09834164, 0.63550967, 0.31861982, 0.17681278, 0.7669411 ,\n",
       "         0.83825326, 0.8682027 , 0.6951913 , 0.88764787, 0.80429024,\n",
       "         0.0665632 , 0.08662341, 0.8675996 , 0.7081141 , 0.6823466 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08392563, 0.62352306, 0.32093737, 0.15815538, 0.7691388 ,\n",
       "         0.84425455, 0.8438163 , 0.6951647 , 0.88260335, 0.8231602 ,\n",
       "         0.06195018, 0.12647061, 0.83746314, 0.710727  , 0.6864391 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1174844 , 0.6145822 , 0.30516544, 0.1313136 , 0.7696203 ,\n",
       "         0.8124111 , 0.908406  , 0.7065732 , 0.89803964, 0.7723528 ,\n",
       "         0.07146788, 0.04348007, 0.88352466, 0.71485007, 0.6898743 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09702249, 0.6139841 , 0.3201183 , 0.15416835, 0.7687154 ,\n",
       "         0.82928175, 0.88837445, 0.7006215 , 0.87594616, 0.79815173,\n",
       "         0.06712519, 0.07287408, 0.852686  , 0.70585346, 0.6921376 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07052502, 0.6554861 , 0.32997543, 0.18054861, 0.7643661 ,\n",
       "         0.858236  , 0.8564088 , 0.68793523, 0.89679635, 0.8445131 ,\n",
       "         0.0573845 , 0.12209141, 0.83947724, 0.7036512 , 0.67978805]],\n",
       "       dtype=float32),\n",
       " array([[0.05853835, 0.65302277, 0.33405578, 0.1591073 , 0.7729572 ,\n",
       "         0.8702067 , 0.8542301 , 0.7015815 , 0.89215237, 0.8656976 ,\n",
       "         0.04831951, 0.12882267, 0.824175  , 0.68704027, 0.68592596]],\n",
       "       dtype=float32),\n",
       " array([[0.07695963, 0.62813413, 0.30522832, 0.1244141 , 0.77838063,\n",
       "         0.847766  , 0.87098634, 0.720974  , 0.8920825 , 0.834438  ,\n",
       "         0.05593019, 0.11514115, 0.8475666 , 0.69356173, 0.6938561 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06038647, 0.6370783 , 0.31910792, 0.1416564 , 0.7762032 ,\n",
       "         0.86488867, 0.8238381 , 0.7098369 , 0.8860097 , 0.86113006,\n",
       "         0.05069201, 0.16883774, 0.80862623, 0.69456893, 0.69133127]],\n",
       "       dtype=float32),\n",
       " array([[0.06099697, 0.625225  , 0.3146525 , 0.13208297, 0.7781246 ,\n",
       "         0.8618502 , 0.7992528 , 0.71487474, 0.8879312 , 0.85970664,\n",
       "         0.05330713, 0.26836565, 0.79924375, 0.6993347 , 0.6936927 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06795409, 0.6305657 , 0.3140717 , 0.13681552, 0.7768467 ,\n",
       "         0.856059  , 0.8349317 , 0.71443444, 0.89034474, 0.8479527 ,\n",
       "         0.0554965 , 0.17817889, 0.8225667 , 0.6976461 , 0.6924469 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06406259, 0.6347065 , 0.31938368, 0.13470343, 0.77706367,\n",
       "         0.8606352 , 0.8466481 , 0.71197796, 0.89354473, 0.8553314 ,\n",
       "         0.05165135, 0.13898808, 0.8238378 , 0.69397587, 0.6925292 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05252466, 0.6385079 , 0.3277932 , 0.1577451 , 0.77649295,\n",
       "         0.8793707 , 0.8089523 , 0.7060549 , 0.8893501 , 0.8785743 ,\n",
       "         0.04784971, 0.18943402, 0.8019297 , 0.6943821 , 0.691438  ]],\n",
       "       dtype=float32),\n",
       " array([[0.0372659 , 0.6710838 , 0.3408709 , 0.18112567, 0.77342   ,\n",
       "         0.9013023 , 0.77466595, 0.6953396 , 0.9070249 , 0.90913975,\n",
       "         0.04077872, 0.2768112 , 0.7838749 , 0.69190603, 0.68159574]],\n",
       "       dtype=float32),\n",
       " array([[0.03662931, 0.66650903, 0.3356268 , 0.18822558, 0.77465576,\n",
       "         0.9053038 , 0.7972811 , 0.7005284 , 0.9073316 , 0.9116897 ,\n",
       "         0.04179599, 0.23244394, 0.7939515 , 0.69269925, 0.68458515]],\n",
       "       dtype=float32),\n",
       " array([[0.03695881, 0.6625705 , 0.34262016, 0.19056967, 0.7745059 ,\n",
       "         0.9050752 , 0.81473774, 0.69671905, 0.9011922 , 0.9107236 ,\n",
       "         0.04051524, 0.16775146, 0.7927225 , 0.69067997, 0.68616176]],\n",
       "       dtype=float32),\n",
       " array([[0.02846518, 0.6816172 , 0.361092  , 0.23096462, 0.77113926,\n",
       "         0.9194413 , 0.7536614 , 0.682075  , 0.90043825, 0.92838025,\n",
       "         0.03623994, 0.30077848, 0.75877976, 0.6884112 , 0.67811096]],\n",
       "       dtype=float32),\n",
       " array([[0.02280267, 0.7090497 , 0.37532762, 0.25840694, 0.768324  ,\n",
       "         0.930648  , 0.7491207 , 0.67103446, 0.91673476, 0.94164515,\n",
       "         0.03217145, 0.3337246 , 0.7614187 , 0.6850769 , 0.66768914]],\n",
       "       dtype=float32),\n",
       " array([[0.02149846, 0.69336647, 0.3634119 , 0.24181598, 0.772794  ,\n",
       "         0.93274164, 0.73695236, 0.6797553 , 0.9090699 , 0.9443824 ,\n",
       "         0.03226779, 0.36767945, 0.7440446 , 0.68718153, 0.6741794 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02728459, 0.6699286 , 0.34780738, 0.20283332, 0.77739966,\n",
       "         0.9226605 , 0.77425104, 0.69039845, 0.8993943 , 0.93237334,\n",
       "         0.03435313, 0.23482065, 0.76460934, 0.68931943, 0.6821969 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02664366, 0.6761815 , 0.3567382 , 0.2268604 , 0.77546155,\n",
       "         0.92568   , 0.76683855, 0.6852846 , 0.90183777, 0.9344301 ,\n",
       "         0.03447518, 0.2542528 , 0.7680694 , 0.6878992 , 0.6795712 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02032257, 0.68985105, 0.36320165, 0.2398813 , 0.77675897,\n",
       "         0.9372559 , 0.7300426 , 0.6818258 , 0.9052865 , 0.94857466,\n",
       "         0.02986914, 0.3840467 , 0.74889314, 0.6772195 , 0.6766149 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0280555 , 0.6778678 , 0.36103097, 0.22854628, 0.7747691 ,\n",
       "         0.92409587, 0.81281376, 0.68355525, 0.9073672 , 0.9316001 ,\n",
       "         0.0354784 , 0.17679943, 0.7886063 , 0.68767995, 0.6778993 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03961779, 0.6689286 , 0.36848003, 0.2356281 , 0.77126694,\n",
       "         0.9088298 , 0.8594331 , 0.6794134 , 0.9021338 , 0.90850705,\n",
       "         0.04068799, 0.07891483, 0.8218065 , 0.69036436, 0.6786857 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0385673 , 0.6728038 , 0.36414823, 0.23318857, 0.7716767 ,\n",
       "         0.9103356 , 0.84822726, 0.67998964, 0.9023716 , 0.91094005,\n",
       "         0.03964657, 0.08714029, 0.81880283, 0.6909238 , 0.67761534]],\n",
       "       dtype=float32),\n",
       " array([[0.02453507, 0.7044267 , 0.3627267 , 0.24909982, 0.7718016 ,\n",
       "         0.9302993 , 0.7874828 , 0.6744602 , 0.91283345, 0.9392757 ,\n",
       "         0.03263998, 0.22925599, 0.7823694 , 0.6878538 , 0.66684216]],\n",
       "       dtype=float32),\n",
       " array([[0.02259935, 0.7033189 , 0.356501  , 0.24645667, 0.77350277,\n",
       "         0.9340756 , 0.7958755 , 0.67898834, 0.91395897, 0.94364756,\n",
       "         0.03203119, 0.22515887, 0.7808227 , 0.68843555, 0.6684451 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02837504, 0.6917712 , 0.36013898, 0.24912962, 0.77243143,\n",
       "         0.925298  , 0.8329365 , 0.67827237, 0.9044873 , 0.93108535,\n",
       "         0.03520724, 0.12972488, 0.7989472 , 0.6871411 , 0.6723911 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03412632, 0.6860394 , 0.35938674, 0.24509357, 0.7720742 ,\n",
       "         0.91620207, 0.82072955, 0.6782505 , 0.897679  , 0.91910875,\n",
       "         0.03826138, 0.15566725, 0.8039011 , 0.6862055 , 0.6727038 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02753789, 0.7085964 , 0.35444888, 0.2516071 , 0.771471  ,\n",
       "         0.9262774 , 0.8091902 , 0.6764126 , 0.9109869 , 0.9330559 ,\n",
       "         0.03468278, 0.18619674, 0.7999687 , 0.6870196 , 0.66511667]],\n",
       "       dtype=float32),\n",
       " array([[0.03993825, 0.70442563, 0.35697538, 0.24536732, 0.7691789 ,\n",
       "         0.9090504 , 0.86349225, 0.6779434 , 0.91367   , 0.90858674,\n",
       "         0.04074822, 0.11335929, 0.8427792 , 0.68389714, 0.6652333 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03490769, 0.7029498 , 0.35707387, 0.25219595, 0.7691567 ,\n",
       "         0.91504675, 0.8344323 , 0.6738919 , 0.90316296, 0.9173256 ,\n",
       "         0.03804006, 0.1250256 , 0.8149166 , 0.68780005, 0.66574675]],\n",
       "       dtype=float32),\n",
       " array([[0.01254227, 0.76428324, 0.37309512, 0.29485023, 0.7675069 ,\n",
       "         0.95340335, 0.71701515, 0.65613216, 0.9388673 , 0.9664125 ,\n",
       "         0.02337356, 0.36708707, 0.7508728 , 0.6849709 , 0.6448491 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01673645, 0.73213845, 0.35573316, 0.27009693, 0.7725129 ,\n",
       "         0.9450005 , 0.7124314 , 0.67013305, 0.9188475 , 0.95683634,\n",
       "         0.02768163, 0.4227206 , 0.75051415, 0.68670887, 0.6564349 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02577005, 0.7012229 , 0.35967663, 0.25974154, 0.7731094 ,\n",
       "         0.9304465 , 0.80261385, 0.67690647, 0.9084218 , 0.9374916 ,\n",
       "         0.03413075, 0.22973442, 0.7935247 , 0.68560207, 0.6673949 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02201109, 0.71129936, 0.36517885, 0.2769828 , 0.77060175,\n",
       "         0.9366529 , 0.7851561 , 0.66805315, 0.91268563, 0.94532937,\n",
       "         0.03195839, 0.24966496, 0.7798266 , 0.6885921 , 0.662835  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01782006, 0.7211639 , 0.3655971 , 0.26539454, 0.77349657,\n",
       "         0.9437031 , 0.762711  , 0.67203695, 0.924203  , 0.95497364,\n",
       "         0.02844498, 0.33689243, 0.77089965, 0.6850237 , 0.66091365]],\n",
       "       dtype=float32),\n",
       " array([[0.0356521 , 0.6783176 , 0.35010657, 0.21399374, 0.776709  ,\n",
       "         0.91448957, 0.8233027 , 0.6862709 , 0.9044088 , 0.9181579 ,\n",
       "         0.03793375, 0.18695956, 0.81605947, 0.6867546 , 0.673729  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02621393, 0.6963436 , 0.3546402 , 0.24424374, 0.7751149 ,\n",
       "         0.9302282 , 0.81000155, 0.67839235, 0.9046658 , 0.9371069 ,\n",
       "         0.03253962, 0.15808037, 0.7951448 , 0.6871267 , 0.66944504]],\n",
       "       dtype=float32),\n",
       " array([[0.00520091, 0.771316  , 0.37258276, 0.30622536, 0.775493  ,\n",
       "         0.97321236, 0.5700615 , 0.656688  , 0.94437337, 0.9849855 ,\n",
       "         0.01582658, 0.6742307 , 0.6512204 , 0.6877483 , 0.64441043]],\n",
       "       dtype=float32),\n",
       " array([[0.00786831, 0.7309866 , 0.3514519 , 0.2547831 , 0.781712  ,\n",
       "         0.96456623, 0.5596314 , 0.6700924 , 0.9158444 , 0.9779448 ,\n",
       "         0.01927472, 0.71987784, 0.6385525 , 0.69100994, 0.6568291 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01745813, 0.7053572 , 0.3485399 , 0.22036086, 0.7814778 ,\n",
       "         0.9449607 , 0.7871199 , 0.6813923 , 0.9175629 , 0.9567095 ,\n",
       "         0.02654016, 0.28851363, 0.7730233 , 0.68621874, 0.66430235]],\n",
       "       dtype=float32),\n",
       " array([[0.00760476, 0.7254183 , 0.36728114, 0.25339097, 0.78201324,\n",
       "         0.96534115, 0.6281187 , 0.6677884 , 0.9256347 , 0.978617  ,\n",
       "         0.01909246, 0.6363916 , 0.65711737, 0.6876308 , 0.65912753]],\n",
       "       dtype=float32),\n",
       " array([[0.01304343, 0.7022738 , 0.35250756, 0.23969424, 0.78283334,\n",
       "         0.9545695 , 0.7363625 , 0.6795443 , 0.9166492 , 0.96666414,\n",
       "         0.02417449, 0.3716031 , 0.7344817 , 0.6905636 , 0.66657007]],\n",
       "       dtype=float32),\n",
       " array([[0.004763  , 0.7596455 , 0.37207508, 0.27837613, 0.7843751 ,\n",
       "         0.97512007, 0.55107224, 0.66696936, 0.9423363 , 0.9865131 ,\n",
       "         0.01475446, 0.8069773 , 0.64355487, 0.68054694, 0.64594346]],\n",
       "       dtype=float32),\n",
       " array([[0.00513196, 0.74948233, 0.36312193, 0.28210118, 0.78205687,\n",
       "         0.97350216, 0.4718884 , 0.65333647, 0.9217309 , 0.98531485,\n",
       "         0.01543777, 0.85778034, 0.5924808 , 0.6940154 , 0.6426611 ]],\n",
       "       dtype=float32),\n",
       " array([[6.3129939e-04, 8.5908294e-01, 3.8065618e-01, 3.3155498e-01,\n",
       "         7.8155071e-01, 9.9346417e-01, 4.8973066e-01, 6.3603032e-01,\n",
       "         9.8697960e-01, 9.9805200e-01, 5.2993274e-03, 8.3791262e-01,\n",
       "         6.1645305e-01, 6.9404405e-01, 5.9754229e-01]], dtype=float32),\n",
       " array([[0.00156864, 0.80758846, 0.4409455 , 0.40538645, 0.7765554 ,\n",
       "         0.9881243 , 0.35832605, 0.5990624 , 0.9493233 , 0.9951468 ,\n",
       "         0.00776871, 0.9003849 , 0.5062413 , 0.68227595, 0.611458  ]],\n",
       "       dtype=float32),\n",
       " array([[0.00721571, 0.7606498 , 0.39561063, 0.32363406, 0.78026   ,\n",
       "         0.9728851 , 0.7988819 , 0.64673656, 0.95018697, 0.9823178 ,\n",
       "         0.01667067, 0.33116874, 0.78424704, 0.68172455, 0.6328909 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01114941, 0.7100844 , 0.38856232, 0.29726478, 0.78190976,\n",
       "         0.9630237 , 0.7663908 , 0.6473925 , 0.9071529 , 0.9726261 ,\n",
       "         0.01994175, 0.25668833, 0.74004966, 0.6886154 , 0.65102977]],\n",
       "       dtype=float32),\n",
       " array([[0.01727315, 0.6906249 , 0.36154372, 0.25825745, 0.7858257 ,\n",
       "         0.9531704 , 0.8330222 , 0.6700413 , 0.89638054, 0.9605542 ,\n",
       "         0.02325213, 0.09757725, 0.792948  , 0.68760914, 0.661973  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01717862, 0.7030963 , 0.37701425, 0.29630044, 0.7842933 ,\n",
       "         0.95475996, 0.8385162 , 0.67122895, 0.898765  , 0.96095073,\n",
       "         0.02328287, 0.11967353, 0.80520344, 0.673942  , 0.6595683 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00818652, 0.7491695 , 0.36563185, 0.33120355, 0.77847135,\n",
       "         0.9718317 , 0.78678197, 0.6525904 , 0.9311267 , 0.9802664 ,\n",
       "         0.0167424 , 0.11830302, 0.7719842 , 0.6955581 , 0.6424525 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00811687, 0.74254686, 0.35776153, 0.31908584, 0.778176  ,\n",
       "         0.9712118 , 0.8268889 , 0.6534328 , 0.92469984, 0.9798293 ,\n",
       "         0.01732756, 0.08548054, 0.766247  , 0.6997572 , 0.64407945]],\n",
       "       dtype=float32),\n",
       " array([[0.0072657 , 0.75743043, 0.42283964, 0.39380398, 0.7749841 ,\n",
       "         0.9727748 , 0.7403321 , 0.63545114, 0.92843807, 0.981516  ,\n",
       "         0.01642807, 0.38801333, 0.7372543 , 0.6727101 , 0.6353156 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00759435, 0.7569671 , 0.4186761 , 0.40502465, 0.7683497 ,\n",
       "         0.97035146, 0.74417657, 0.6181744 , 0.9184023 , 0.9796779 ,\n",
       "         0.01847851, 0.45680645, 0.7125799 , 0.68294865, 0.6286912 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00375962, 0.79292893, 0.45890173, 0.43488115, 0.76928025,\n",
       "         0.9803129 , 0.5915691 , 0.600806  , 0.9452645 , 0.9892848 ,\n",
       "         0.01283424, 0.8471    , 0.65207994, 0.66881263, 0.610284  ]],\n",
       "       dtype=float32),\n",
       " array([[0.00714004, 0.74448436, 0.39845675, 0.35326302, 0.78037554,\n",
       "         0.9732423 , 0.66074604, 0.64068764, 0.9274578 , 0.9823042 ,\n",
       "         0.01688422, 0.58561915, 0.7223416 , 0.682816  , 0.63469595]],\n",
       "       dtype=float32),\n",
       " array([[0.01156805, 0.74127054, 0.39955434, 0.40357843, 0.77651477,\n",
       "         0.9667321 , 0.6845852 , 0.63294506, 0.9036267 , 0.9734634 ,\n",
       "         0.0202441 , 0.45916528, 0.76188236, 0.68211025, 0.6303806 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01196405, 0.7692216 , 0.38433105, 0.37304613, 0.7746538 ,\n",
       "         0.96592706, 0.726623  , 0.63657033, 0.9315037 , 0.97335243,\n",
       "         0.01944738, 0.3600467 , 0.807674  , 0.6826075 , 0.6196464 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00792126, 0.7307895 , 0.40779424, 0.37717786, 0.77993   ,\n",
       "         0.97314274, 0.7311285 , 0.6367496 , 0.91660434, 0.98097664,\n",
       "         0.01678141, 0.2901483 , 0.73921376, 0.6849438 , 0.64049274]],\n",
       "       dtype=float32),\n",
       " array([[0.01609252, 0.74645144, 0.37494886, 0.35051548, 0.775822  ,\n",
       "         0.96036184, 0.90329444, 0.65441906, 0.93141246, 0.965176  ,\n",
       "         0.02313796, 0.0515034 , 0.8635546 , 0.6813818 , 0.6357307 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0127498 , 0.72068316, 0.3694603 , 0.3318128 , 0.77881813,\n",
       "         0.9639656 , 0.8772596 , 0.6571701 , 0.9069499 , 0.9703251 ,\n",
       "         0.02042199, 0.03655583, 0.80754477, 0.687684  , 0.65132576]],\n",
       "       dtype=float32),\n",
       " array([[0.01369566, 0.7228442 , 0.36731422, 0.3159137 , 0.7748121 ,\n",
       "         0.9603394 , 0.84808433, 0.6515958 , 0.9162912 , 0.9678183 ,\n",
       "         0.02248678, 0.0839578 , 0.80090106, 0.69637996, 0.6459934 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02819271, 0.71693677, 0.34041873, 0.28419173, 0.7768272 ,\n",
       "         0.9418587 , 0.92917645, 0.67949474, 0.9171769 , 0.941487  ,\n",
       "         0.03047896, 0.02403218, 0.885346  , 0.68613625, 0.6512121 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04764816, 0.69899327, 0.34678835, 0.3028012 , 0.76811135,\n",
       "         0.9169397 , 0.95067275, 0.67079294, 0.89148027, 0.9025248 ,\n",
       "         0.04211095, 0.01763921, 0.8969463 , 0.6867706 , 0.6537116 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01745388, 0.73941404, 0.38336086, 0.31143105, 0.7698043 ,\n",
       "         0.95104235, 0.84121007, 0.6580923 , 0.9365631 , 0.959185  ,\n",
       "         0.02651271, 0.2506068 , 0.82906914, 0.6802515 , 0.64109105]],\n",
       "       dtype=float32),\n",
       " array([[0.01886542, 0.72966003, 0.37149265, 0.3592259 , 0.7629648 ,\n",
       "         0.94828737, 0.7733774 , 0.6407184 , 0.90744907, 0.95476836,\n",
       "         0.03087858, 0.4071439 , 0.7854739 , 0.69851923, 0.6373411 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02741804, 0.72541994, 0.3516573 , 0.2809733 , 0.7754847 ,\n",
       "         0.936607  , 0.83889455, 0.67573625, 0.90552247, 0.93956214,\n",
       "         0.03096213, 0.24426806, 0.84215623, 0.67416906, 0.64498013]],\n",
       "       dtype=float32),\n",
       " array([[0.0270019 , 0.72133327, 0.3508049 , 0.28597987, 0.77168655,\n",
       "         0.9376536 , 0.86388284, 0.6675185 , 0.9137125 , 0.9404733 ,\n",
       "         0.03191496, 0.14507805, 0.84843683, 0.6870139 , 0.6453771 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07248752, 0.6829055 , 0.33109972, 0.22393182, 0.77447355,\n",
       "         0.8897514 , 0.920307  , 0.69442254, 0.9136273 , 0.86624306,\n",
       "         0.04914822, 0.0506918 , 0.9134767 , 0.6841074 , 0.6606613 ]],\n",
       "       dtype=float32),\n",
       " array([[0.12705731, 0.6250364 , 0.32604605, 0.18826126, 0.7740031 ,\n",
       "         0.8344553 , 0.926639  , 0.70106214, 0.8719101 , 0.7764255 ,\n",
       "         0.06760719, 0.04712427, 0.9104621 , 0.6881305 , 0.6775669 ]],\n",
       "       dtype=float32),\n",
       " array([[0.11707373, 0.65058297, 0.35153675, 0.23913775, 0.76649874,\n",
       "         0.84269166, 0.93289804, 0.6895655 , 0.8816051 , 0.7863889 ,\n",
       "         0.06777368, 0.04594134, 0.91170996, 0.6788291 , 0.67201537]],\n",
       "       dtype=float32),\n",
       " array([[0.11391937, 0.64947253, 0.32763264, 0.21085334, 0.76300144,\n",
       "         0.8390401 , 0.9375453 , 0.6912043 , 0.9004858 , 0.7885404 ,\n",
       "         0.0706201 , 0.0234314 , 0.9117209 , 0.7009078 , 0.6755811 ]],\n",
       "       dtype=float32),\n",
       " array([[0.13680433, 0.6478128 , 0.3380645 , 0.23705718, 0.75863427,\n",
       "         0.81801707, 0.9247717 , 0.6867286 , 0.8738411 , 0.7490239 ,\n",
       "         0.07692856, 0.02842814, 0.9046157 , 0.69361013, 0.67705715]],\n",
       "       dtype=float32),\n",
       " array([[0.10677457, 0.64792234, 0.321756  , 0.19513169, 0.7721346 ,\n",
       "         0.8437695 , 0.9546444 , 0.7203848 , 0.87684274, 0.7937884 ,\n",
       "         0.06242478, 0.01135373, 0.91100335, 0.67120755, 0.68876046]],\n",
       "       dtype=float32),\n",
       " array([[0.0923827 , 0.63384485, 0.3090155 , 0.17529681, 0.76927245,\n",
       "         0.84651834, 0.9439652 , 0.7114625 , 0.8726817 , 0.80962646,\n",
       "         0.06294871, 0.01541528, 0.88558525, 0.6933243 , 0.69058514]],\n",
       "       dtype=float32),\n",
       " array([[0.07128697, 0.6484454 , 0.3146949 , 0.1808922 , 0.76798916,\n",
       "         0.86700016, 0.9333133 , 0.71173966, 0.9026804 , 0.84682435,\n",
       "         0.05784485, 0.02463131, 0.8799399 , 0.69450676, 0.6896667 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05996218, 0.6625402 , 0.31145868, 0.18263057, 0.7719938 ,\n",
       "         0.8814713 , 0.90563506, 0.71658003, 0.9052653 , 0.86937696,\n",
       "         0.05204536, 0.05905527, 0.8696105 , 0.6885381 , 0.684869  ]],\n",
       "       dtype=float32),\n",
       " array([[0.04582558, 0.661987  , 0.3373807 , 0.19059211, 0.7785309 ,\n",
       "         0.8964794 , 0.80487776, 0.71520364, 0.88600355, 0.8950093 ,\n",
       "         0.04226707, 0.23168512, 0.8158252 , 0.667734  , 0.6866625 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0244242 , 0.6700639 , 0.34622175, 0.18036562, 0.7817474 ,\n",
       "         0.92490965, 0.6927285 , 0.7063633 , 0.90067416, 0.9379998 ,\n",
       "         0.03160902, 0.48448926, 0.7403211 , 0.67311674, 0.68377054]],\n",
       "       dtype=float32),\n",
       " array([[0.03381788, 0.68069917, 0.34926856, 0.2234361 , 0.7711444 ,\n",
       "         0.91041297, 0.6690637 , 0.6847087 , 0.89338183, 0.9176194 ,\n",
       "         0.04081203, 0.6349955 , 0.75902295, 0.6844736 , 0.67028236]],\n",
       "       dtype=float32),\n",
       " array([[0.03151875, 0.65031356, 0.3357403 , 0.20875086, 0.76989794,\n",
       "         0.9112911 , 0.58574027, 0.6766114 , 0.8833128 , 0.9213686 ,\n",
       "         0.04306676, 0.6821041 , 0.70487887, 0.712043  , 0.67683   ]],\n",
       "       dtype=float32),\n",
       " array([[0.00670821, 0.7377004 , 0.37112418, 0.26262543, 0.7711805 ,\n",
       "         0.9653764 , 0.42362145, 0.65443724, 0.9402248 , 0.9803469 ,\n",
       "         0.01970568, 0.8890457 , 0.60019135, 0.70020205, 0.6515952 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00742797, 0.7104844 , 0.36558995, 0.25964618, 0.7764507 ,\n",
       "         0.96481764, 0.4202143 , 0.6564463 , 0.9124601 , 0.9788735 ,\n",
       "         0.01945941, 0.8539857 , 0.58196414, 0.6969203 , 0.66029704]],\n",
       "       dtype=float32),\n",
       " array([[0.0047596 , 0.74469584, 0.40058059, 0.31748998, 0.7706302 ,\n",
       "         0.972758  , 0.40633732, 0.62905407, 0.9229976 , 0.9853402 ,\n",
       "         0.01568909, 0.8187173 , 0.5323747 , 0.6971658 , 0.644732  ]],\n",
       "       dtype=float32),\n",
       " array([[0.0067483 , 0.69793165, 0.38307983, 0.2701583 , 0.77919924,\n",
       "         0.96762085, 0.5101091 , 0.65277445, 0.9073067 , 0.98051125,\n",
       "         0.01836485, 0.64081085, 0.57693285, 0.69963896, 0.6637227 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0073578 , 0.70659107, 0.38937297, 0.24898176, 0.7826486 ,\n",
       "         0.9663236 , 0.64183176, 0.661105  , 0.91878873, 0.979294  ,\n",
       "         0.01758161, 0.46351412, 0.6417562 , 0.6850246 , 0.66223747]],\n",
       "       dtype=float32),\n",
       " array([[0.01373351, 0.71657026, 0.34404263, 0.2339435 , 0.78062147,\n",
       "         0.95598686, 0.8715242 , 0.6820831 , 0.9319264 , 0.96628356,\n",
       "         0.02272459, 0.04892923, 0.806049  , 0.69159806, 0.66191524]],\n",
       "       dtype=float32),\n",
       " array([[0.03076732, 0.6806765 , 0.33210987, 0.22515363, 0.775823  ,\n",
       "         0.9269172 , 0.9074371 , 0.6843804 , 0.8968984 , 0.92900246,\n",
       "         0.03438025, 0.02631077, 0.83649194, 0.6947515 , 0.67097354]],\n",
       "       dtype=float32),\n",
       " array([[0.05443338, 0.6407876 , 0.31005427, 0.17261818, 0.7809419 ,\n",
       "         0.8957883 , 0.9267756 , 0.70994174, 0.88300395, 0.88486576,\n",
       "         0.04422598, 0.01720054, 0.8676004 , 0.6939699 , 0.68626297]],\n",
       "       dtype=float32),\n",
       " array([[0.0704184 , 0.6274166 , 0.2990713 , 0.15582682, 0.7783964 ,\n",
       "         0.8755134 , 0.9306446 , 0.7130262 , 0.8824146 , 0.8559481 ,\n",
       "         0.05144525, 0.01603782, 0.8777419 , 0.70155275, 0.689709  ]],\n",
       "       dtype=float32),\n",
       " array([[0.09973094, 0.6557854 , 0.30379593, 0.16387059, 0.77405936,\n",
       "         0.8506599 , 0.9678182 , 0.7192705 , 0.9036285 , 0.80950946,\n",
       "         0.05974168, 0.00636703, 0.9243112 , 0.68473506, 0.68303126]],\n",
       "       dtype=float32),\n",
       " array([[0.11034892, 0.63735396, 0.3100529 , 0.16234028, 0.7713348 ,\n",
       "         0.8316551 , 0.958057  , 0.7147377 , 0.88312495, 0.7839885 ,\n",
       "         0.06606732, 0.012035  , 0.9076592 , 0.68641305, 0.68779707]],\n",
       "       dtype=float32),\n",
       " array([[0.12853177, 0.6487338 , 0.31965178, 0.19725505, 0.75879234,\n",
       "         0.8096432 , 0.94134516, 0.6968536 , 0.8944165 , 0.7500657 ,\n",
       "         0.08434094, 0.03975307, 0.9046513 , 0.698789  , 0.6785305 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05780353, 0.7002065 , 0.3574145 , 0.25517347, 0.7598381 ,\n",
       "         0.8834592 , 0.88033164, 0.68291265, 0.92213404, 0.87157685,\n",
       "         0.05564645, 0.18364556, 0.8693236 , 0.6825409 , 0.66399515]],\n",
       "       dtype=float32),\n",
       " array([[0.08687125, 0.66276765, 0.34327766, 0.23388481, 0.763346  ,\n",
       "         0.85074544, 0.8660462 , 0.6926077 , 0.8840282 , 0.8183718 ,\n",
       "         0.06804285, 0.2272631 , 0.8648886 , 0.68315375, 0.6739615 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07987741, 0.6898924 , 0.33252174, 0.24176034, 0.76277596,\n",
       "         0.86628217, 0.8801443 , 0.6945975 , 0.91340345, 0.83898616,\n",
       "         0.06224108, 0.12985925, 0.89046997, 0.68705297, 0.6677049 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06023477, 0.6928261 , 0.36238912, 0.27294675, 0.76203996,\n",
       "         0.8842607 , 0.7990944 , 0.68020004, 0.9078341 , 0.8704693 ,\n",
       "         0.0540929 , 0.31912774, 0.8505716 , 0.68155956, 0.6657602 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08433995, 0.6854265 , 0.340205  , 0.2400911 , 0.7633902 ,\n",
       "         0.8620635 , 0.879259  , 0.6932411 , 0.91247064, 0.83219516,\n",
       "         0.06206064, 0.11447643, 0.8914101 , 0.684952  , 0.669744  ]],\n",
       "       dtype=float32),\n",
       " array([[0.0783272 , 0.6582546 , 0.35436913, 0.22675988, 0.76448137,\n",
       "         0.8590254 , 0.87164074, 0.6896193 , 0.88878495, 0.83361983,\n",
       "         0.05959995, 0.09629931, 0.85774475, 0.68456703, 0.6808905 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08590887, 0.6385101 , 0.3239846 , 0.18583077, 0.7698859 ,\n",
       "         0.8533115 , 0.9070023 , 0.7079533 , 0.8856229 , 0.82313377,\n",
       "         0.05941176, 0.02427467, 0.8728767 , 0.6928316 , 0.6928748 ]],\n",
       "       dtype=float32),\n",
       " array([[0.072571  , 0.6435229 , 0.33445367, 0.18504319, 0.76875776,\n",
       "         0.8603796 , 0.8798159 , 0.70105386, 0.88315976, 0.841307  ,\n",
       "         0.05470922, 0.04367251, 0.8451772 , 0.6910606 , 0.6913595 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0539623 , 0.6421871 , 0.33928886, 0.19094798, 0.7699412 ,\n",
       "         0.8786847 , 0.8184561 , 0.7003449 , 0.8834187 , 0.8734816 ,\n",
       "         0.05088148, 0.13233966, 0.80104476, 0.69246626, 0.69240785]],\n",
       "       dtype=float32),\n",
       " array([[0.03163218, 0.6632407 , 0.33685747, 0.17550196, 0.7736228 ,\n",
       "         0.9087217 , 0.845184  , 0.7033488 , 0.9087697 , 0.91859746,\n",
       "         0.0396028 , 0.12700188, 0.7837275 , 0.6895371 , 0.6891993 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03183986, 0.65285563, 0.34291053, 0.18108837, 0.77430964,\n",
       "         0.90694165, 0.7871141 , 0.70091486, 0.89732414, 0.9174221 ,\n",
       "         0.04121909, 0.29391763, 0.7543987 , 0.6875845 , 0.6902821 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06004125, 0.6435451 , 0.33389255, 0.16537686, 0.7725362 ,\n",
       "         0.87086076, 0.88130796, 0.70873934, 0.9064273 , 0.86375517,\n",
       "         0.0535016 , 0.0911997 , 0.8427084 , 0.6886424 , 0.6922164 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09809565, 0.62144035, 0.32789293, 0.1618802 , 0.77094036,\n",
       "         0.8247022 , 0.8553384 , 0.7074928 , 0.8692162 , 0.7926701 ,\n",
       "         0.06926759, 0.18679766, 0.8433417 , 0.68723327, 0.69244015]],\n",
       "       dtype=float32),\n",
       " array([[0.09002391, 0.6162179 , 0.315419  , 0.1427537 , 0.7748342 ,\n",
       "         0.8331685 , 0.84098226, 0.7139792 , 0.8724553 , 0.80907583,\n",
       "         0.06350139, 0.15727624, 0.836319  , 0.69283694, 0.6961366 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06435849, 0.6167259 , 0.3145024 , 0.14095357, 0.77771497,\n",
       "         0.8611465 , 0.8131457 , 0.71514404, 0.87475663, 0.8538693 ,\n",
       "         0.05400623, 0.16851847, 0.803885  , 0.694993  , 0.6992524 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05265411, 0.6393256 , 0.3036102 , 0.14161281, 0.7792904 ,\n",
       "         0.88067806, 0.80150926, 0.71909785, 0.8992811 , 0.8806672 ,\n",
       "         0.04855476, 0.18285878, 0.81570005, 0.6963676 , 0.6940625 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04835432, 0.62348986, 0.31898144, 0.14736205, 0.7800811 ,\n",
       "         0.88549227, 0.8079658 , 0.71247256, 0.88112175, 0.8869074 ,\n",
       "         0.04593832, 0.15494794, 0.79050773, 0.6947892 , 0.6981887 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03043438, 0.65569675, 0.34674996, 0.17850353, 0.7759795 ,\n",
       "         0.9098042 , 0.737635  , 0.69641286, 0.89921635, 0.9218074 ,\n",
       "         0.0388259 , 0.38749704, 0.7424478 , 0.68846625, 0.68804616]],\n",
       "       dtype=float32),\n",
       " array([[0.00651468, 0.71499455, 0.36267543, 0.21730064, 0.7800647 ,\n",
       "         0.96395385, 0.5241782 , 0.68235475, 0.93270344, 0.97992116,\n",
       "         0.0194443 , 0.8164482 , 0.5869458 , 0.68845963, 0.67248696]],\n",
       "       dtype=float32),\n",
       " array([[0.00593609, 0.7119763 , 0.36175075, 0.23388079, 0.7811665 ,\n",
       "         0.9655825 , 0.39981663, 0.67183185, 0.90418375, 0.9811298 ,\n",
       "         0.01861624, 0.9212357 , 0.50649095, 0.69024104, 0.6672766 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00827901, 0.692956  , 0.36626405, 0.24534424, 0.7820262 ,\n",
       "         0.960936  , 0.4222696 , 0.6706432 , 0.89319813, 0.9758179 ,\n",
       "         0.02085917, 0.8665827 , 0.5530414 , 0.69297206, 0.67081964]],\n",
       "       dtype=float32),\n",
       " array([[0.00916043, 0.7047289 , 0.36730784, 0.26429078, 0.78063583,\n",
       "         0.960971  , 0.52442396, 0.66921455, 0.90652674, 0.9744752 ,\n",
       "         0.02174142, 0.7624025 , 0.6228741 , 0.6916157 , 0.665007  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01431823, 0.7104163 , 0.3691637 , 0.25690046, 0.7781379 ,\n",
       "         0.9511357 , 0.6722749 , 0.6687286 , 0.91874766, 0.9635106 ,\n",
       "         0.02500615, 0.48790884, 0.72695243, 0.6887326 , 0.6607787 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01240829, 0.6985101 , 0.37572682, 0.25169367, 0.77952826,\n",
       "         0.95405674, 0.6792286 , 0.66656506, 0.9083877 , 0.96703064,\n",
       "         0.02306956, 0.4157018 , 0.69212127, 0.68770003, 0.6669051 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00783178, 0.7177633 , 0.36068872, 0.23180906, 0.78380525,\n",
       "         0.9657678 , 0.6720317 , 0.67160726, 0.9267629 , 0.97865295,\n",
       "         0.01766903, 0.3618335 , 0.6784438 , 0.691856  , 0.6626673 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0075253 , 0.7096664 , 0.36422408, 0.24848662, 0.78356487,\n",
       "         0.96678233, 0.62628305, 0.66569936, 0.9094065 , 0.97920406,\n",
       "         0.01740055, 0.40391657, 0.63963526, 0.6946037 , 0.6635257 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00787865, 0.7132329 , 0.3735206 , 0.27479738, 0.7821193 ,\n",
       "         0.9674778 , 0.6780062 , 0.66362774, 0.91465265, 0.97884434,\n",
       "         0.01796189, 0.3353283 , 0.674821  , 0.6908378 , 0.66221744]],\n",
       "       dtype=float32),\n",
       " array([[0.00573301, 0.737914  , 0.38277856, 0.2806811 , 0.7811294 ,\n",
       "         0.9724392 , 0.659594  , 0.6538875 , 0.9263948 , 0.983841  ,\n",
       "         0.01546069, 0.50402594, 0.6528857 , 0.6860723 , 0.6495808 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00663117, 0.73685557, 0.39331743, 0.29922694, 0.77887213,\n",
       "         0.97008395, 0.6813106 , 0.6483673 , 0.9233478 , 0.9815517 ,\n",
       "         0.01688924, 0.5209314 , 0.6687651 , 0.6827975 , 0.6474584 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00759986, 0.73117226, 0.40507933, 0.3313742 , 0.7770335 ,\n",
       "         0.9683773 , 0.677387  , 0.64391243, 0.9169372 , 0.979257  ,\n",
       "         0.01852071, 0.5440749 , 0.6769851 , 0.67993575, 0.6483291 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01524567, 0.7464296 , 0.3658709 , 0.32377633, 0.7748795 ,\n",
       "         0.957209  , 0.84690344, 0.6617335 , 0.9310432 , 0.9645828 ,\n",
       "         0.0244403 , 0.15222324, 0.8285094 , 0.68177676, 0.6417048 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01538388, 0.7210083 , 0.37344798, 0.3218527 , 0.7768448 ,\n",
       "         0.9561658 , 0.7769075 , 0.6610769 , 0.9138435 , 0.9637757 ,\n",
       "         0.02476446, 0.23974761, 0.78724784, 0.68450105, 0.6517315 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01639218, 0.728659  , 0.36451784, 0.29971024, 0.7761947 ,\n",
       "         0.95323956, 0.77388614, 0.65935934, 0.91333467, 0.9613788 ,\n",
       "         0.0245419 , 0.22435036, 0.7886722 , 0.6880938 , 0.64646685]],\n",
       "       dtype=float32),\n",
       " array([[0.03533042, 0.7241918 , 0.3356068 , 0.24797948, 0.77562344,\n",
       "         0.9303261 , 0.9404871 , 0.68417877, 0.9348225 , 0.9282246 ,\n",
       "         0.03365373, 0.01868353, 0.90565103, 0.6855274 , 0.65168935]],\n",
       "       dtype=float32),\n",
       " array([[0.06178058, 0.67351335, 0.3462644 , 0.23107865, 0.7734694 ,\n",
       "         0.8954092 , 0.9416518 , 0.6832224 , 0.8938037 , 0.87629616,\n",
       "         0.04457412, 0.01507178, 0.8955006 , 0.6842663 , 0.6684824 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07985029, 0.6709546 , 0.33645603, 0.22535466, 0.77088976,\n",
       "         0.87895584, 0.9618945 , 0.69291055, 0.90251267, 0.84658784,\n",
       "         0.05197261, 0.00633104, 0.9183895 , 0.6851101 , 0.67321783]],\n",
       "       dtype=float32),\n",
       " array([[0.08089866, 0.6659164 , 0.33621877, 0.22945398, 0.7686625 ,\n",
       "         0.8738492 , 0.9476045 , 0.69247013, 0.8972158 , 0.8414803 ,\n",
       "         0.05600025, 0.01705454, 0.9065798 , 0.6884844 , 0.67348444]],\n",
       "       dtype=float32),\n",
       " array([[0.08924098, 0.66711146, 0.33139026, 0.23062003, 0.76708454,\n",
       "         0.8657068 , 0.94670767, 0.6943223 , 0.8943913 , 0.8275146 ,\n",
       "         0.05924419, 0.01672286, 0.90955967, 0.68828493, 0.674267  ]],\n",
       "       dtype=float32),\n",
       " array([[0.11471238, 0.65977556, 0.33874285, 0.23215163, 0.7622282 ,\n",
       "         0.83718693, 0.9376498 , 0.68860227, 0.8906349 , 0.7834643 ,\n",
       "         0.07172063, 0.04090682, 0.9095604 , 0.68846506, 0.67290425]],\n",
       "       dtype=float32),\n",
       " array([[0.12017368, 0.6500901 , 0.3313502 , 0.21421273, 0.7671094 ,\n",
       "         0.83122486, 0.9198132 , 0.7006258 , 0.8802002 , 0.7757647 ,\n",
       "         0.07118854, 0.06064148, 0.9033105 , 0.682939  , 0.6789657 ]],\n",
       "       dtype=float32),\n",
       " array([[0.13110179, 0.67200184, 0.3323672 , 0.21903661, 0.76055026,\n",
       "         0.81673265, 0.9331881 , 0.6929872 , 0.8976177 , 0.75511134,\n",
       "         0.07749566, 0.05978234, 0.91424876, 0.6841504 , 0.67019475]],\n",
       "       dtype=float32),\n",
       " array([[0.10618543, 0.67217296, 0.33889702, 0.21326782, 0.7655358 ,\n",
       "         0.83451694, 0.91779274, 0.7005239 , 0.8928884 , 0.78968483,\n",
       "         0.06770199, 0.07937993, 0.89740855, 0.6732225 , 0.67528945]],\n",
       "       dtype=float32),\n",
       " array([[0.10765308, 0.6398617 , 0.30414915, 0.17251419, 0.7675656 ,\n",
       "         0.8290644 , 0.8980331 , 0.70848286, 0.8900639 , 0.7875909 ,\n",
       "         0.07216652, 0.06326138, 0.883184  , 0.7033036 , 0.6858896 ]],\n",
       "       dtype=float32),\n",
       " array([[0.10664015, 0.64159805, 0.31163743, 0.18044454, 0.7690261 ,\n",
       "         0.8305289 , 0.87379533, 0.7092903 , 0.8803709 , 0.789099  ,\n",
       "         0.06980278, 0.09352286, 0.87476444, 0.69475126, 0.6863281 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07115187, 0.6604382 , 0.33130628, 0.18340743, 0.77390546,\n",
       "         0.8654309 , 0.8471401 , 0.7099851 , 0.890421  , 0.8485111 ,\n",
       "         0.05221507, 0.11512867, 0.8524989 , 0.67892724, 0.685586  ]],\n",
       "       dtype=float32),\n",
       " array([[0.07395726, 0.64724106, 0.32198963, 0.16720824, 0.7725753 ,\n",
       "         0.8599044 , 0.89868605, 0.7145412 , 0.90559345, 0.84221977,\n",
       "         0.0577862 , 0.06502151, 0.86853623, 0.6895847 , 0.6909125 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05620981, 0.6606756 , 0.35090312, 0.19774069, 0.76914406,\n",
       "         0.87606865, 0.8457438 , 0.6970924 , 0.89644754, 0.86955404,\n",
       "         0.05056537, 0.13399674, 0.8241646 , 0.6812463 , 0.68690515]],\n",
       "       dtype=float32),\n",
       " array([[0.0388325 , 0.66802025, 0.3533444 , 0.21345615, 0.7682826 ,\n",
       "         0.89929646, 0.79586244, 0.68792236, 0.9000861 , 0.90361106,\n",
       "         0.04467374, 0.20916009, 0.782447  , 0.6899101 , 0.6836289 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0309096 , 0.6707731 , 0.34891796, 0.2003223 , 0.7735725 ,\n",
       "         0.9116131 , 0.74324095, 0.6949275 , 0.9022008 , 0.9214544 ,\n",
       "         0.03892442, 0.3271546 , 0.7574403 , 0.6855088 , 0.6846883 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04918154, 0.66689646, 0.32886055, 0.17471221, 0.7731293 ,\n",
       "         0.8885332 , 0.8560138 , 0.704683  , 0.9165593 , 0.88774425,\n",
       "         0.04690077, 0.09510731, 0.8394808 , 0.691717  , 0.6854362 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04736181, 0.6473507 , 0.33848464, 0.18602784, 0.7730323 ,\n",
       "         0.8885141 , 0.80713415, 0.6967142 , 0.88747746, 0.88809353,\n",
       "         0.04661195, 0.15695603, 0.79576445, 0.69107777, 0.6900762 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04604457, 0.65714705, 0.32092738, 0.1695658 , 0.7725339 ,\n",
       "         0.88959986, 0.81809115, 0.69885004, 0.9067232 , 0.89199334,\n",
       "         0.04733509, 0.15581723, 0.8111055 , 0.7006458 , 0.68578583]],\n",
       "       dtype=float32),\n",
       " array([[0.03735774, 0.65972024, 0.33628526, 0.19302629, 0.7713532 ,\n",
       "         0.90205264, 0.7809875 , 0.6870045 , 0.89337975, 0.90799785,\n",
       "         0.0429658 , 0.20738338, 0.7725178 , 0.69909805, 0.683439  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02853648, 0.67444813, 0.33861598, 0.18614969, 0.7748772 ,\n",
       "         0.9179687 , 0.7909519 , 0.692512  , 0.91585517, 0.92898643,\n",
       "         0.03645574, 0.21078807, 0.78208125, 0.6912129 , 0.68286884]],\n",
       "       dtype=float32),\n",
       " array([[0.03149263, 0.6727916 , 0.33804396, 0.20224197, 0.77210635,\n",
       "         0.91270036, 0.7522498 , 0.6840171 , 0.8992852 , 0.921377  ,\n",
       "         0.03895192, 0.21861725, 0.761604  , 0.69941765, 0.67984957]],\n",
       "       dtype=float32),\n",
       " array([[0.02226938, 0.6732721 , 0.3322614 , 0.1920811 , 0.77728486,\n",
       "         0.9288358 , 0.7110878 , 0.69091266, 0.90819335, 0.94232696,\n",
       "         0.03381377, 0.34739068, 0.73157567, 0.70030886, 0.68122596]],\n",
       "       dtype=float32),\n",
       " array([[0.04760377, 0.6700533 , 0.33223635, 0.18454736, 0.7729242 ,\n",
       "         0.8957636 , 0.88352287, 0.6950048 , 0.9200441 , 0.8939695 ,\n",
       "         0.04534294, 0.06032936, 0.85429883, 0.69640094, 0.68010014]],\n",
       "       dtype=float32),\n",
       " array([[0.05157183, 0.6579894 , 0.35269347, 0.21904993, 0.7662603 ,\n",
       "         0.8872852 , 0.86176914, 0.674591  , 0.8897043 , 0.88079214,\n",
       "         0.04908805, 0.07673933, 0.8212627 , 0.6975709 , 0.68026006]],\n",
       "       dtype=float32),\n",
       " array([[0.03592591, 0.6796175 , 0.35268137, 0.24158472, 0.76823   ,\n",
       "         0.91255075, 0.8220832 , 0.67581964, 0.9041095 , 0.9149143 ,\n",
       "         0.04097923, 0.11337847, 0.807221  , 0.6951913 , 0.6762549 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04147727, 0.6807808 , 0.36038825, 0.25162545, 0.76753294,\n",
       "         0.90489846, 0.8333259 , 0.67738223, 0.90167356, 0.9033862 ,\n",
       "         0.04441918, 0.13723049, 0.82014894, 0.68681365, 0.6758402 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04141334, 0.65503085, 0.34726632, 0.2169923 , 0.7770506 ,\n",
       "         0.90538585, 0.82348955, 0.6980309 , 0.8874765 , 0.9044358 ,\n",
       "         0.04302079, 0.15229122, 0.81015927, 0.68110096, 0.68803155]],\n",
       "       dtype=float32),\n",
       " array([[0.02866027, 0.6919453 , 0.3494587 , 0.23379803, 0.7708736 ,\n",
       "         0.92206866, 0.818069  , 0.6812534 , 0.91312903, 0.92948985,\n",
       "         0.03730873, 0.16660026, 0.796885  , 0.6905549 , 0.67421037]],\n",
       "       dtype=float32),\n",
       " array([[0.03923548, 0.6944148 , 0.35813338, 0.2343889 , 0.7693259 ,\n",
       "         0.9071737 , 0.8556127 , 0.6794756 , 0.90915453, 0.9080695 ,\n",
       "         0.04064552, 0.10977393, 0.82977855, 0.6820569 , 0.671723  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02809837, 0.7045162 , 0.3567471 , 0.25420508, 0.76866686,\n",
       "         0.92274183, 0.8020221 , 0.67392015, 0.90783423, 0.929797  ,\n",
       "         0.03646118, 0.1856708 , 0.78811085, 0.68674135, 0.66884375]],\n",
       "       dtype=float32),\n",
       " array([[0.02584313, 0.72521144, 0.36142394, 0.27994257, 0.7663242 ,\n",
       "         0.9284806 , 0.823046  , 0.66849977, 0.9145655 , 0.93535817,\n",
       "         0.03448302, 0.16039953, 0.80131555, 0.68399215, 0.6604786 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03262917, 0.6934544 , 0.3636001 , 0.24963148, 0.7731837 ,\n",
       "         0.91794026, 0.8045025 , 0.68431765, 0.9023515 , 0.92200094,\n",
       "         0.03740464, 0.20759167, 0.8032517 , 0.67537755, 0.674177  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01357081, 0.73881894, 0.37556654, 0.28714857, 0.77128524,\n",
       "         0.951031  , 0.70267814, 0.667991  , 0.930375  , 0.9638041 ,\n",
       "         0.02544824, 0.46338204, 0.73930675, 0.67935973, 0.6580588 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02392908, 0.71375805, 0.36675307, 0.26350647, 0.7739152 ,\n",
       "         0.93274325, 0.77915984, 0.6795427 , 0.91375387, 0.9411543 ,\n",
       "         0.03220282, 0.296419  , 0.7904045 , 0.67397374, 0.6659099 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0228586 , 0.69986665, 0.37122446, 0.25631157, 0.7726256 ,\n",
       "         0.93273497, 0.76585263, 0.6733962 , 0.9136599 , 0.942634  ,\n",
       "         0.03273214, 0.3111903 , 0.77019626, 0.6833454 , 0.6695145 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02958328, 0.6711603 , 0.361689  , 0.25490358, 0.7740677 ,\n",
       "         0.9226527 , 0.772616  , 0.6794554 , 0.8867949 , 0.92785835,\n",
       "         0.03808745, 0.27561495, 0.76925886, 0.6865424 , 0.6783474 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03178973, 0.6886638 , 0.36667567, 0.2551415 , 0.77168375,\n",
       "         0.92060286, 0.80737156, 0.67467177, 0.90547544, 0.92478377,\n",
       "         0.03754495, 0.1950879 , 0.8034771 , 0.6852537 , 0.67140627]],\n",
       "       dtype=float32),\n",
       " array([[0.02204182, 0.6883255 , 0.3661246 , 0.2377174 , 0.7777489 ,\n",
       "         0.9338565 , 0.74026793, 0.68027395, 0.8999084 , 0.94441205,\n",
       "         0.03074197, 0.34231475, 0.74935126, 0.67979646, 0.67414814]],\n",
       "       dtype=float32),\n",
       " array([[0.01663116, 0.70047295, 0.34736997, 0.22383435, 0.78119165,\n",
       "         0.94511724, 0.7548616 , 0.6874672 , 0.9113718 , 0.9573579 ,\n",
       "         0.02649507, 0.28681782, 0.747789  , 0.6842854 , 0.6720468 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01864335, 0.70195866, 0.36939892, 0.25708076, 0.77674025,\n",
       "         0.941752  , 0.7558692 , 0.67592174, 0.908614  , 0.9525363 ,\n",
       "         0.02854401, 0.29744068, 0.7536771 , 0.67984474, 0.6696563 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01849382, 0.68142784, 0.36344752, 0.23649009, 0.7799907 ,\n",
       "         0.94047105, 0.71670985, 0.6800188 , 0.89469975, 0.95216316,\n",
       "         0.02880429, 0.35530022, 0.720699  , 0.68431574, 0.6764365 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02093917, 0.7008006 , 0.37076998, 0.25004947, 0.77619547,\n",
       "         0.9382568 , 0.8035042 , 0.67650163, 0.91654015, 0.94807225,\n",
       "         0.0301758 , 0.23823135, 0.7836499 , 0.680587  , 0.6679775 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03183749, 0.6779676 , 0.36998117, 0.23311889, 0.77635   ,\n",
       "         0.92104816, 0.8333931 , 0.6789836 , 0.903053  , 0.92545754,\n",
       "         0.0354728 , 0.14209221, 0.8093136 , 0.6808283 , 0.6743492 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02738735, 0.689838  , 0.3650157 , 0.22316666, 0.7767062 ,\n",
       "         0.92637557, 0.8312385 , 0.6787017 , 0.91087234, 0.9341596 ,\n",
       "         0.03250034, 0.1398186 , 0.80261517, 0.681359  , 0.67135257]],\n",
       "       dtype=float32),\n",
       " array([[0.06611772, 0.6922274 , 0.35090217, 0.20919397, 0.7721106 ,\n",
       "         0.88479847, 0.93155974, 0.68781185, 0.922006  , 0.8677277 ,\n",
       "         0.04559532, 0.02115394, 0.903961  , 0.67821085, 0.66898394]],\n",
       "       dtype=float32),\n",
       " array([[0.06205919, 0.66621035, 0.34000823, 0.18224292, 0.77614945,\n",
       "         0.88093174, 0.9003394 , 0.6927595 , 0.89240664, 0.86856735,\n",
       "         0.04441617, 0.04112812, 0.8651039 , 0.6810804 , 0.67879415]],\n",
       "       dtype=float32),\n",
       " array([[0.04392874, 0.6613456 , 0.32983437, 0.1920775 , 0.778948  ,\n",
       "         0.90309566, 0.8703769 , 0.7026365 , 0.8944676 , 0.90131325,\n",
       "         0.04187985, 0.0850912 , 0.835824  , 0.6852832 , 0.6848852 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02434587, 0.6966164 , 0.33908665, 0.21102758, 0.77821064,\n",
       "         0.93105954, 0.8262224 , 0.69389665, 0.91648805, 0.94064707,\n",
       "         0.03187935, 0.17493498, 0.80136496, 0.68369955, 0.6746699 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02557238, 0.68631417, 0.331187  , 0.19727606, 0.7801658 ,\n",
       "         0.9276027 , 0.80963546, 0.69807863, 0.9083985 , 0.93747395,\n",
       "         0.03320291, 0.23221004, 0.79029286, 0.6852394 , 0.6771515 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02253721, 0.6837512 , 0.33666438, 0.20751895, 0.7806141 ,\n",
       "         0.93314743, 0.78117234, 0.6961653 , 0.9072204 , 0.94396144,\n",
       "         0.03218683, 0.32041955, 0.7713631 , 0.6858871 , 0.6775125 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01593901, 0.70098716, 0.35919136, 0.23356171, 0.7785234 ,\n",
       "         0.9440699 , 0.6706922 , 0.6812949 , 0.915897  , 0.9579884 ,\n",
       "         0.02856725, 0.66057235, 0.71756333, 0.6848993 , 0.6681896 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01682888, 0.6899929 , 0.36326903, 0.24689385, 0.7788176 ,\n",
       "         0.94304353, 0.63202524, 0.67653155, 0.89969254, 0.95596826,\n",
       "         0.02937047, 0.6953966 , 0.6966004 , 0.68836576, 0.669098  ]],\n",
       "       dtype=float32),\n",
       " array([[0.00649134, 0.7497878 , 0.37754864, 0.298473  , 0.77744544,\n",
       "         0.96873003, 0.5096738 , 0.6576047 , 0.9316888 , 0.98147756,\n",
       "         0.01843847, 0.8550742 , 0.6309627 , 0.68688685, 0.6473652 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00799226, 0.7184477 , 0.36132878, 0.27469182, 0.7831572 ,\n",
       "         0.9654146 , 0.4861418 , 0.6656241 , 0.904028  , 0.97802246,\n",
       "         0.01948278, 0.8056815 , 0.61534345, 0.69121754, 0.658426  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01103066, 0.72638667, 0.35811606, 0.2543732 , 0.78231406,\n",
       "         0.9595966 , 0.66708624, 0.6707108 , 0.9257679 , 0.9718765 ,\n",
       "         0.0213543 , 0.50181794, 0.7251903 , 0.68860054, 0.65565723]],\n",
       "       dtype=float32),\n",
       " array([[0.01405196, 0.70304567, 0.35517564, 0.25418672, 0.7824634 ,\n",
       "         0.9531416 , 0.6918405 , 0.6737879 , 0.90573835, 0.96454906,\n",
       "         0.02450837, 0.42050833, 0.72418606, 0.69020003, 0.66366726]],\n",
       "       dtype=float32),\n",
       " array([[0.00982722, 0.70186865, 0.34994254, 0.22598514, 0.7864008 ,\n",
       "         0.96121675, 0.71790135, 0.67944914, 0.9149227 , 0.97392005,\n",
       "         0.02034141, 0.34378538, 0.6992649 , 0.6907057 , 0.6682542 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00556632, 0.730325  , 0.3695079 , 0.26835644, 0.7837105 ,\n",
       "         0.9726766 , 0.61778355, 0.66361135, 0.92736816, 0.9842807 ,\n",
       "         0.01580127, 0.5452408 , 0.63608086, 0.6918228 , 0.6576714 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01103443, 0.70785713, 0.34316394, 0.23655662, 0.7854359 ,\n",
       "         0.96114177, 0.7951468 , 0.6819528 , 0.91967857, 0.9722096 ,\n",
       "         0.02079418, 0.15762   , 0.75156534, 0.6937851 , 0.6660203 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01381257, 0.67948014, 0.35672215, 0.24562345, 0.785669  ,\n",
       "         0.9547216 , 0.7631881 , 0.683974  , 0.9023201 , 0.9653847 ,\n",
       "         0.02488546, 0.3244632 , 0.7358794 , 0.68846494, 0.6735276 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01175428, 0.7162869 , 0.3611535 , 0.2618335 , 0.77981305,\n",
       "         0.9580364 , 0.7448201 , 0.6681055 , 0.91725373, 0.96973443,\n",
       "         0.02247684, 0.36859873, 0.7331995 , 0.690065  , 0.6577564 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01241031, 0.7230181 , 0.36501867, 0.2746515 , 0.7767616 ,\n",
       "         0.95646954, 0.7471864 , 0.65975314, 0.91425115, 0.9679726 ,\n",
       "         0.02319854, 0.40744594, 0.7351468 , 0.6908129 , 0.65160424]],\n",
       "       dtype=float32),\n",
       " array([[0.02998006, 0.71887124, 0.35283282, 0.24732946, 0.7763002 ,\n",
       "         0.93390155, 0.92354876, 0.6779337 , 0.9307314 , 0.9359456 ,\n",
       "         0.0310137 , 0.03472168, 0.88217676, 0.6836688 , 0.6546227 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07890662, 0.6838659 , 0.36025834, 0.2365674 , 0.7682875 ,\n",
       "         0.8793305 , 0.93833804, 0.6696752 , 0.90803766, 0.85103846,\n",
       "         0.04842778, 0.01790344, 0.91091955, 0.68705934, 0.66094357]],\n",
       "       dtype=float32),\n",
       " array([[0.098373  , 0.6551384 , 0.34621495, 0.2112925 , 0.7741681 ,\n",
       "         0.8608164 , 0.9350618 , 0.69143933, 0.88947356, 0.8196126 ,\n",
       "         0.0549493 , 0.02108514, 0.9113263 , 0.67896587, 0.6754587 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0687727 , 0.65879315, 0.34252182, 0.20579782, 0.7785207 ,\n",
       "         0.8847951 , 0.91782254, 0.699133  , 0.88552636, 0.8635527 ,\n",
       "         0.04596205, 0.03139939, 0.8867886 , 0.6747809 , 0.6795387 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03962774, 0.7251175 , 0.3641587 , 0.2566392 , 0.76768845,\n",
       "         0.91398317, 0.9057649 , 0.6675805 , 0.91263485, 0.91181135,\n",
       "         0.03495917, 0.04358907, 0.8668185 , 0.67477787, 0.65477365]],\n",
       "       dtype=float32),\n",
       " array([[0.04047894, 0.69050807, 0.33491236, 0.22828887, 0.77404606,\n",
       "         0.9135954 , 0.8939708 , 0.6897697 , 0.9029405 , 0.91092634,\n",
       "         0.03836692, 0.04681919, 0.85657305, 0.68598974, 0.6717717 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05096297, 0.68969345, 0.34685093, 0.2583532 , 0.7671393 ,\n",
       "         0.8993923 , 0.88426954, 0.67930216, 0.89845246, 0.889466  ,\n",
       "         0.04675172, 0.09231663, 0.8600228 , 0.686314  , 0.66799915]],\n",
       "       dtype=float32),\n",
       " array([[0.05469472, 0.6919276 , 0.3554674 , 0.25566915, 0.77109796,\n",
       "         0.8957832 , 0.88819325, 0.69013774, 0.8971069 , 0.8832375 ,\n",
       "         0.04618338, 0.11112771, 0.8690875 , 0.6685273 , 0.6704108 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04921798, 0.6857142 , 0.3596138 , 0.26141298, 0.7676864 ,\n",
       "         0.8974269 , 0.8716675 , 0.68182343, 0.89468586, 0.8891141 ,\n",
       "         0.04759694, 0.14258187, 0.84473574, 0.67785764, 0.67176986]],\n",
       "       dtype=float32),\n",
       " array([[0.05061203, 0.6822499 , 0.34394392, 0.24203366, 0.7700116 ,\n",
       "         0.896572  , 0.85083115, 0.6890117 , 0.8984869 , 0.8885343 ,\n",
       "         0.04761651, 0.14214782, 0.8454787 , 0.68572736, 0.67354506]],\n",
       "       dtype=float32),\n",
       " array([[0.03695231, 0.7005972 , 0.35281304, 0.2697701 , 0.7684266 ,\n",
       "         0.9150816 , 0.80260557, 0.67982095, 0.90600157, 0.91530067,\n",
       "         0.04086867, 0.2073929 , 0.82133794, 0.6880429 , 0.6671806 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04426806, 0.70102274, 0.34331465, 0.25579473, 0.7688442 ,\n",
       "         0.9062497 , 0.8251962 , 0.6838427 , 0.9068383 , 0.9022654 ,\n",
       "         0.04370277, 0.17353426, 0.8426769 , 0.68795055, 0.665829  ]],\n",
       "       dtype=float32),\n",
       " array([[0.03459456, 0.68568945, 0.35415214, 0.23653957, 0.77170444,\n",
       "         0.9144992 , 0.8014298 , 0.6805658 , 0.8984769 , 0.9181667 ,\n",
       "         0.03856358, 0.20839588, 0.79962593, 0.6882001 , 0.67181885]],\n",
       "       dtype=float32),\n",
       " array([[0.03357948, 0.6660729 , 0.3558937 , 0.22083099, 0.77414066,\n",
       "         0.9142374 , 0.8047442 , 0.6865573 , 0.8986904 , 0.91942686,\n",
       "         0.03944461, 0.21627499, 0.78855044, 0.69069386, 0.68011206]],\n",
       "       dtype=float32),\n",
       " array([[0.04267631, 0.64954704, 0.34585044, 0.18875773, 0.7769225 ,\n",
       "         0.90105957, 0.84055614, 0.6951414 , 0.89658326, 0.9021503 ,\n",
       "         0.0422006 , 0.13617294, 0.81395864, 0.69100857, 0.6855993 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05691732, 0.60724676, 0.332113  , 0.16754985, 0.7814992 ,\n",
       "         0.88439584, 0.85875297, 0.7117739 , 0.88121367, 0.8764377 ,\n",
       "         0.05017943, 0.1113644 , 0.82815427, 0.69301003, 0.7003097 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04026447, 0.64771855, 0.33869064, 0.19607644, 0.7779768 ,\n",
       "         0.9063304 , 0.82809186, 0.6987869 , 0.89165545, 0.90757054,\n",
       "         0.04162002, 0.13438624, 0.8080774 , 0.6916703 , 0.68830246]],\n",
       "       dtype=float32),\n",
       " array([[0.03425992, 0.64965785, 0.34279966, 0.20030867, 0.7791794 ,\n",
       "         0.91424626, 0.8113028 , 0.7000572 , 0.89566064, 0.91911376,\n",
       "         0.03968851, 0.18926707, 0.7932911 , 0.6890116 , 0.6889693 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0309709 , 0.65907556, 0.35060397, 0.20913078, 0.7784077 ,\n",
       "         0.9187443 , 0.79687315, 0.69348645, 0.89301854, 0.9253428 ,\n",
       "         0.03686881, 0.21350698, 0.78013605, 0.68540156, 0.6853669 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0325323 , 0.64861584, 0.34773782, 0.19362988, 0.7790644 ,\n",
       "         0.91396   , 0.79707456, 0.6945648 , 0.89206165, 0.9210648 ,\n",
       "         0.03882865, 0.2460862 , 0.7753668 , 0.6881849 , 0.6874416 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02678987, 0.6620342 , 0.35211933, 0.21607798, 0.77806324,\n",
       "         0.9243037 , 0.76145136, 0.6899906 , 0.8962828 , 0.9334097 ,\n",
       "         0.0364088 , 0.32359198, 0.7576156 , 0.68851   , 0.6833381 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02491072, 0.66197205, 0.34266594, 0.2073445 , 0.7806265 ,\n",
       "         0.9288279 , 0.7681375 , 0.6944475 , 0.8989319 , 0.93863064,\n",
       "         0.03462372, 0.318831  , 0.764563  , 0.68518066, 0.68503624]],\n",
       "       dtype=float32),\n",
       " array([[0.03448645, 0.70006144, 0.34897646, 0.2105325 , 0.77416426,\n",
       "         0.9162286 , 0.8577295 , 0.6850948 , 0.92412615, 0.9210367 ,\n",
       "         0.03633694, 0.10919738, 0.84065664, 0.68586814, 0.66808033]],\n",
       "       dtype=float32),\n",
       " array([[0.0295473 , 0.70040756, 0.35552225, 0.2168849 , 0.77397436,\n",
       "         0.9218074 , 0.81966376, 0.6778409 , 0.9145019 , 0.9295081 ,\n",
       "         0.03313852, 0.148279  , 0.8081948 , 0.6849657 , 0.6677004 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03363678, 0.70088863, 0.35740346, 0.22725758, 0.7722993 ,\n",
       "         0.91811687, 0.84661907, 0.6775034 , 0.91532713, 0.9224454 ,\n",
       "         0.03484806, 0.10337397, 0.82962376, 0.68518484, 0.6672028 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02751007, 0.7103681 , 0.36858025, 0.2620984 , 0.7701211 ,\n",
       "         0.92791146, 0.81940114, 0.6687922 , 0.91049796, 0.934189  ,\n",
       "         0.03238944, 0.14896071, 0.8062372 , 0.68262404, 0.66390085]],\n",
       "       dtype=float32),\n",
       " array([[0.01747971, 0.7278106 , 0.36582312, 0.2717369 , 0.77166533,\n",
       "         0.9449255 , 0.78584844, 0.6690507 , 0.9238082 , 0.9557968 ,\n",
       "         0.02708123, 0.23069637, 0.7778253 , 0.6840155 , 0.6598967 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01648714, 0.71112424, 0.3573408 , 0.25943553, 0.7753206 ,\n",
       "         0.946186  , 0.75672305, 0.675391  , 0.9125707 , 0.9575512 ,\n",
       "         0.02724579, 0.29014346, 0.74977934, 0.68669695, 0.6666451 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02297531, 0.6988812 , 0.3557645 , 0.24349429, 0.7755793 ,\n",
       "         0.9351812 , 0.8023508 , 0.67808616, 0.9079155 , 0.94391716,\n",
       "         0.03067013, 0.18771085, 0.78558964, 0.68617463, 0.6691348 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03332745, 0.6933886 , 0.36006713, 0.23683836, 0.773633  ,\n",
       "         0.91993386, 0.8563546 , 0.68008035, 0.91296744, 0.92332244,\n",
       "         0.03623825, 0.1178438 , 0.8319811 , 0.68151766, 0.67014015]],\n",
       "       dtype=float32),\n",
       " array([[0.03170693, 0.69371253, 0.36912784, 0.2553533 , 0.77172554,\n",
       "         0.9204848 , 0.8216776 , 0.67293763, 0.9030521 , 0.9246104 ,\n",
       "         0.03653616, 0.18328142, 0.80702233, 0.6794787 , 0.6692313 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03350594, 0.70221734, 0.35967466, 0.24982294, 0.7717095 ,\n",
       "         0.9201251 , 0.8493774 , 0.6775431 , 0.9140964 , 0.9229001 ,\n",
       "         0.03646034, 0.10970109, 0.83342105, 0.6815104 , 0.6678604 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03698305, 0.69941634, 0.3546619 , 0.2374898 , 0.77136666,\n",
       "         0.91288024, 0.84222674, 0.67623657, 0.90423805, 0.91436654,\n",
       "         0.0376465 , 0.10778788, 0.8253943 , 0.6851237 , 0.6667911 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02031227, 0.7134074 , 0.3546121 , 0.24807334, 0.7746028 ,\n",
       "         0.93855894, 0.765473  , 0.6785472 , 0.9212724 , 0.9492136 ,\n",
       "         0.03038   , 0.2797668 , 0.7781783 , 0.68551123, 0.6656258 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01498344, 0.7110033 , 0.35393932, 0.23439804, 0.7772776 ,\n",
       "         0.9460149 , 0.68977755, 0.6757019 , 0.91461587, 0.9599662 ,\n",
       "         0.02680386, 0.49581343, 0.71557087, 0.6876886 , 0.66515696]],\n",
       "       dtype=float32),\n",
       " array([[0.01815507, 0.71063316, 0.3660924 , 0.25223038, 0.7760977 ,\n",
       "         0.9419026 , 0.7527877 , 0.67350453, 0.91291004, 0.95338416,\n",
       "         0.02830637, 0.3306479 , 0.75484395, 0.67985475, 0.66537845]],\n",
       "       dtype=float32),\n",
       " array([[0.02451216, 0.6850369 , 0.3562769 , 0.23084109, 0.7770025 ,\n",
       "         0.9299769 , 0.78174543, 0.68069065, 0.9051542 , 0.93929094,\n",
       "         0.03400593, 0.2991671 , 0.77279663, 0.68608665, 0.67250097]],\n",
       "       dtype=float32),\n",
       " array([[0.02299607, 0.6969151 , 0.3538345 , 0.23140398, 0.7769445 ,\n",
       "         0.9329412 , 0.7739173 , 0.6788901 , 0.9090681 , 0.9429918 ,\n",
       "         0.0319671 , 0.30399716, 0.77440643, 0.6844888 , 0.66826844]],\n",
       "       dtype=float32),\n",
       " array([[0.03162499, 0.6911549 , 0.36082932, 0.2371877 , 0.7745973 ,\n",
       "         0.9210568 , 0.81017876, 0.67632216, 0.90572053, 0.92594665,\n",
       "         0.03572167, 0.18582138, 0.8082828 , 0.68294823, 0.6690682 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03154682, 0.68973976, 0.3531954 , 0.23832822, 0.7762505 ,\n",
       "         0.9233292 , 0.83800477, 0.6831394 , 0.9039228 , 0.92692715,\n",
       "         0.03530983, 0.12044387, 0.8195651 , 0.6819647 , 0.67188495]],\n",
       "       dtype=float32),\n",
       " array([[0.00877855, 0.74672467, 0.36098364, 0.26279876, 0.7792121 ,\n",
       "         0.96365076, 0.6941656 , 0.6738622 , 0.9402302 , 0.9763654 ,\n",
       "         0.01972184, 0.42678893, 0.72539145, 0.68203527, 0.6559429 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01219836, 0.7063317 , 0.33693513, 0.23020487, 0.78260535,\n",
       "         0.9544241 , 0.6817894 , 0.68351525, 0.91166353, 0.9675931 ,\n",
       "         0.02430604, 0.45451608, 0.704196  , 0.6922411 , 0.6681057 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03274111, 0.70010525, 0.36185506, 0.22370103, 0.77601695,\n",
       "         0.9221561 , 0.88734365, 0.6820844 , 0.9252037 , 0.92596984,\n",
       "         0.03445505, 0.06775202, 0.85290396, 0.67901045, 0.66723245]],\n",
       "       dtype=float32),\n",
       " array([[0.03449847, 0.67053413, 0.36309636, 0.2303392 , 0.775358  ,\n",
       "         0.9162461 , 0.8436258 , 0.6777523 , 0.8931274 , 0.91891974,\n",
       "         0.03768993, 0.12027647, 0.8067873 , 0.68485886, 0.67574745]],\n",
       "       dtype=float32),\n",
       " array([[0.02753511, 0.68545556, 0.34840575, 0.21713321, 0.77761215,\n",
       "         0.9272138 , 0.8422715 , 0.6850146 , 0.9110259 , 0.93449247,\n",
       "         0.03376402, 0.1351143 , 0.8092665 , 0.6871418 , 0.67305386]],\n",
       "       dtype=float32),\n",
       " array([[0.03458758, 0.674591  , 0.3431344 , 0.20953052, 0.7799353 ,\n",
       "         0.9183745 , 0.8507271 , 0.6939284 , 0.90144455, 0.92131835,\n",
       "         0.03638946, 0.11551563, 0.8258504 , 0.68258494, 0.6775041 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03968879, 0.67893153, 0.34495604, 0.21861356, 0.7775932 ,\n",
       "         0.9132866 , 0.8767468 , 0.69388264, 0.9064003 , 0.91232336,\n",
       "         0.03879993, 0.07879834, 0.84852475, 0.6816672 , 0.6763112 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04365497, 0.6686991 , 0.3338394 , 0.1998772 , 0.77919227,\n",
       "         0.90677226, 0.8769528 , 0.6996949 , 0.9000128 , 0.90429485,\n",
       "         0.04039498, 0.07329271, 0.84812033, 0.6834758 , 0.6807004 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0327087 , 0.6801533 , 0.33891892, 0.21857043, 0.77712435,\n",
       "         0.9202375 , 0.8438651 , 0.69251716, 0.90433276, 0.9241283 ,\n",
       "         0.03690052, 0.1175823 , 0.8202166 , 0.68568516, 0.6778899 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03164485, 0.68177086, 0.33673158, 0.20555711, 0.7780203 ,\n",
       "         0.91981256, 0.8522425 , 0.694462  , 0.90597504, 0.9253782 ,\n",
       "         0.03658806, 0.15245649, 0.8181686 , 0.68418795, 0.6759886 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03851007, 0.6753763 , 0.32595235, 0.19160594, 0.77658606,\n",
       "         0.91009444, 0.86590457, 0.6953749 , 0.9106307 , 0.9126501 ,\n",
       "         0.04049378, 0.11636711, 0.8371133 , 0.69363874, 0.67644733]],\n",
       "       dtype=float32),\n",
       " array([[0.04136306, 0.6569693 , 0.3078512 , 0.17623022, 0.7798995 ,\n",
       "         0.90782267, 0.86532485, 0.7032321 , 0.89599156, 0.90802574,\n",
       "         0.04054178, 0.0641785 , 0.8332621 , 0.7013851 , 0.68434936]],\n",
       "       dtype=float32),\n",
       " array([[0.03653914, 0.6781836 , 0.32039866, 0.19490032, 0.78082913,\n",
       "         0.9154304 , 0.84239703, 0.7033413 , 0.9009809 , 0.9177464 ,\n",
       "         0.03743808, 0.12142501, 0.83016497, 0.6874709 , 0.67791945]],\n",
       "       dtype=float32),\n",
       " array([[0.04348668, 0.6468877 , 0.32476273, 0.18961424, 0.7823259 ,\n",
       "         0.905772  , 0.8497315 , 0.7111036 , 0.8967681 , 0.904191  ,\n",
       "         0.04399661, 0.14974776, 0.8343922 , 0.68684614, 0.6892401 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04278884, 0.638515  , 0.32844815, 0.18171751, 0.779527  ,\n",
       "         0.90183496, 0.8309367 , 0.7028955 , 0.8971223 , 0.90286916,\n",
       "         0.04562993, 0.19307427, 0.8147537 , 0.6954107 , 0.6896198 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04478344, 0.6422195 , 0.33625665, 0.19455759, 0.77880687,\n",
       "         0.90043944, 0.8275044 , 0.7002443 , 0.89021736, 0.8990473 ,\n",
       "         0.04533056, 0.17496741, 0.8158413 , 0.6899807 , 0.68886393]],\n",
       "       dtype=float32),\n",
       " array([[0.01610695, 0.6829359 , 0.33953008, 0.22333607, 0.77850944,\n",
       "         0.9451284 , 0.6836459 , 0.6912632 , 0.93199486, 0.95875067,\n",
       "         0.03240281, 0.6101266 , 0.73915565, 0.70123434, 0.6774078 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01030297, 0.68659186, 0.331002  , 0.21668263, 0.7841062 ,\n",
       "         0.9565711 , 0.56286657, 0.69003093, 0.9155624 , 0.9714466 ,\n",
       "         0.02593795, 0.80075455, 0.64585173, 0.700454  , 0.6753307 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00809861, 0.6909339 , 0.34053317, 0.21947692, 0.7873262 ,\n",
       "         0.96231866, 0.5288962 , 0.68787026, 0.91322845, 0.97687805,\n",
       "         0.0224732 , 0.84724915, 0.61094934, 0.69370985, 0.67385423]],\n",
       "       dtype=float32),\n",
       " array([[0.01153951, 0.7134259 , 0.359043  , 0.22660975, 0.7822917 ,\n",
       "         0.9543654 , 0.63969946, 0.67152876, 0.91482306, 0.96885216,\n",
       "         0.0224916 , 0.61827415, 0.685539  , 0.68515533, 0.6612556 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02232737, 0.66284686, 0.3556833 , 0.21359877, 0.7844586 ,\n",
       "         0.93505484, 0.74239004, 0.6877855 , 0.8966611 , 0.94535846,\n",
       "         0.0316817 , 0.38611785, 0.7511695 , 0.6850998 , 0.67907625]],\n",
       "       dtype=float32),\n",
       " array([[0.00977886, 0.6986125 , 0.3678234 , 0.23992689, 0.7859313 ,\n",
       "         0.9606095 , 0.65617615, 0.68288666, 0.92674434, 0.97384363,\n",
       "         0.02243976, 0.6427092 , 0.69329953, 0.68192345, 0.6711505 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00926304, 0.69726044, 0.34788916, 0.24235407, 0.78683937,\n",
       "         0.96264356, 0.65341306, 0.68240005, 0.90815264, 0.975009  ,\n",
       "         0.02130301, 0.49148852, 0.6708168 , 0.69064444, 0.67111725]],\n",
       "       dtype=float32),\n",
       " array([[0.01591788, 0.7341937 , 0.35319787, 0.2504753 , 0.7774901 ,\n",
       "         0.9509631 , 0.82863444, 0.6703937 , 0.93044156, 0.9613275 ,\n",
       "         0.02375979, 0.1066661 , 0.8045936 , 0.6860074 , 0.65444666]],\n",
       "       dtype=float32),\n",
       " array([[0.01366829, 0.7262084 , 0.3562617 , 0.23688608, 0.78123814,\n",
       "         0.9537692 , 0.7784307 , 0.67255944, 0.9228588 , 0.96558225,\n",
       "         0.02169609, 0.17292763, 0.7658371 , 0.6821739 , 0.6585553 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00951597, 0.73739654, 0.3771199 , 0.27583346, 0.7779612 ,\n",
       "         0.96202934, 0.7366438 , 0.6612941 , 0.92923784, 0.9743595 ,\n",
       "         0.02026214, 0.38547698, 0.7241617 , 0.67915434, 0.6533825 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01341222, 0.73765707, 0.3826676 , 0.29113233, 0.7737978 ,\n",
       "         0.9540005 , 0.7906151 , 0.6555079 , 0.9219457 , 0.96523964,\n",
       "         0.02335401, 0.27642187, 0.76216537, 0.67683274, 0.6500403 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01555376, 0.7147587 , 0.36689794, 0.26718256, 0.77680516,\n",
       "         0.9499764 , 0.8102    , 0.66499144, 0.90799195, 0.9603357 ,\n",
       "         0.02491319, 0.17531207, 0.763418  , 0.68263775, 0.65989894]],\n",
       "       dtype=float32),\n",
       " array([[0.00776237, 0.76114404, 0.36651722, 0.3050229 , 0.77692544,\n",
       "         0.96801656, 0.67561793, 0.6577896 , 0.93484896, 0.9792802 ,\n",
       "         0.01833557, 0.5126104 , 0.71882874, 0.68309915, 0.6419658 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01352666, 0.7326729 , 0.36359757, 0.2924435 , 0.77782273,\n",
       "         0.9554554 , 0.6883591 , 0.66437054, 0.9155482 , 0.96617305,\n",
       "         0.02421392, 0.5468087 , 0.7472066 , 0.6801914 , 0.64989054]],\n",
       "       dtype=float32),\n",
       " array([[0.01119791, 0.744872  , 0.3679292 , 0.31111407, 0.7764436 ,\n",
       "         0.960344  , 0.7029933 , 0.65884054, 0.92025715, 0.97111183,\n",
       "         0.02256572, 0.5380066 , 0.7396436 , 0.6796686 , 0.6444992 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00482204, 0.7807829 , 0.37541482, 0.3300926 , 0.7768381 ,\n",
       "         0.9762457 , 0.6466358 , 0.64878374, 0.9461599 , 0.9865102 ,\n",
       "         0.01508115, 0.6230893 , 0.6896859 , 0.68246204, 0.6322771 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00331916, 0.7844781 , 0.41446182, 0.36827508, 0.7745365 ,\n",
       "         0.9804441 , 0.46589938, 0.62203044, 0.94315785, 0.99015206,\n",
       "         0.01239509, 0.8419107 , 0.5894904 , 0.6816423 , 0.62643343]],\n",
       "       dtype=float32),\n",
       " array([[0.01040032, 0.74383384, 0.39118707, 0.33641398, 0.776518  ,\n",
       "         0.96402633, 0.6867332 , 0.64452523, 0.9220924 , 0.9739666 ,\n",
       "         0.02063017, 0.5060308 , 0.7401079 , 0.6797854 , 0.63984936]],\n",
       "       dtype=float32),\n",
       " array([[0.01382133, 0.74249965, 0.38678327, 0.33918193, 0.77448386,\n",
       "         0.95842004, 0.78570074, 0.6433398 , 0.91428185, 0.9665745 ,\n",
       "         0.02235385, 0.20155233, 0.7820481 , 0.6802753 , 0.64001507]],\n",
       "       dtype=float32),\n",
       " array([[0.01718189, 0.7277    , 0.3827773 , 0.3115897 , 0.7750437 ,\n",
       "         0.95238554, 0.84416527, 0.65393025, 0.92063594, 0.9596949 ,\n",
       "         0.02489408, 0.10236669, 0.81405884, 0.6807224 , 0.64958405]],\n",
       "       dtype=float32),\n",
       " array([[0.02351118, 0.7028624 , 0.37830654, 0.30448687, 0.774697  ,\n",
       "         0.9412975 , 0.830362  , 0.65735877, 0.8936475 , 0.94558823,\n",
       "         0.02922178, 0.10850801, 0.8048316 , 0.6816508 , 0.6579182 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02552104, 0.72010916, 0.36455604, 0.30493006, 0.77298445,\n",
       "         0.9405622 , 0.8923849 , 0.6665173 , 0.9134803 , 0.9429354 ,\n",
       "         0.03058802, 0.05469927, 0.85187083, 0.680693  , 0.6536775 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03079564, 0.7157626 , 0.35624498, 0.29211932, 0.7720076 ,\n",
       "         0.93454576, 0.9259621 , 0.6709681 , 0.91152287, 0.9331825 ,\n",
       "         0.03155718, 0.01381895, 0.87375635, 0.6827272 , 0.65902036]],\n",
       "       dtype=float32),\n",
       " array([[0.04248725, 0.7039783 , 0.37189943, 0.3019684 , 0.7674377 ,\n",
       "         0.91792375, 0.92445713, 0.6661861 , 0.90122414, 0.9093239 ,\n",
       "         0.03799245, 0.02002988, 0.87702215, 0.6788454 , 0.66119266]],\n",
       "       dtype=float32),\n",
       " array([[0.0615152 , 0.68022144, 0.35752746, 0.2694252 , 0.76951915,\n",
       "         0.89633304, 0.9280637 , 0.68156093, 0.8949106 , 0.8758282 ,\n",
       "         0.04748273, 0.0288193 , 0.89187795, 0.6788971 , 0.6686519 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06671774, 0.6741975 , 0.35914275, 0.24225168, 0.76904815,\n",
       "         0.884571  , 0.9357419 , 0.68498516, 0.9001766 , 0.8630987 ,\n",
       "         0.05115305, 0.03961628, 0.89286757, 0.67665464, 0.6702955 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08559468, 0.6697428 , 0.34787887, 0.228209  , 0.76886916,\n",
       "         0.86727434, 0.9400369 , 0.6905931 , 0.897088  , 0.8332198 ,\n",
       "         0.05560129, 0.02406957, 0.9056484 , 0.6789837 , 0.6730803 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08346339, 0.6724805 , 0.3487923 , 0.25379983, 0.76734686,\n",
       "         0.86988616, 0.9185334 , 0.68872327, 0.88476694, 0.8356023 ,\n",
       "         0.05660323, 0.04582645, 0.89474756, 0.6751554 , 0.6732251 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09900548, 0.69332516, 0.34251183, 0.26828262, 0.76395947,\n",
       "         0.86000973, 0.9155525 , 0.68946403, 0.9010651 , 0.81541634,\n",
       "         0.06174926, 0.05167233, 0.91355366, 0.6758726 , 0.6654361 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08482978, 0.67864645, 0.33614993, 0.24168552, 0.76492864,\n",
       "         0.8644811 , 0.8976089 , 0.68816346, 0.89285237, 0.8320593 ,\n",
       "         0.05909659, 0.07331248, 0.8900477 , 0.68379277, 0.6707864 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07346385, 0.675386  , 0.33597213, 0.24135917, 0.76527363,\n",
       "         0.87382334, 0.88433087, 0.6882141 , 0.89452654, 0.84956336,\n",
       "         0.05681494, 0.08746567, 0.8768202 , 0.6878548 , 0.6732229 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05241577, 0.68879753, 0.35115525, 0.26677966, 0.76278144,\n",
       "         0.8941438 , 0.85449797, 0.6767128 , 0.8991014 , 0.8839476 ,\n",
       "         0.04928541, 0.11074675, 0.84684896, 0.6892096 , 0.67022985]],\n",
       "       dtype=float32),\n",
       " array([[0.0434703 , 0.689374  , 0.3438006 , 0.24678384, 0.76781017,\n",
       "         0.9051347 , 0.8452332 , 0.68645746, 0.9061118 , 0.90186906,\n",
       "         0.04430392, 0.12429103, 0.83932596, 0.6872873 , 0.6729802 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03181002, 0.6869068 , 0.35390747, 0.2373501 , 0.77259517,\n",
       "         0.91896415, 0.81499577, 0.69073826, 0.9112937 , 0.924011  ,\n",
       "         0.03857762, 0.21339095, 0.81019074, 0.67912906, 0.6768857 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02597295, 0.68969434, 0.36068353, 0.25954017, 0.76961315,\n",
       "         0.92680895, 0.74850327, 0.67748606, 0.90613663, 0.9351225 ,\n",
       "         0.03683184, 0.35559332, 0.76741254, 0.687213  , 0.67308867]],\n",
       "       dtype=float32),\n",
       " array([[0.01337006, 0.71842587, 0.3583704 , 0.2724298 , 0.77196324,\n",
       "         0.9501203 , 0.6361883 , 0.67081475, 0.9158248 , 0.9635713 ,\n",
       "         0.02694798, 0.58844674, 0.6969108 , 0.6881834 , 0.6641289 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01428364, 0.7027763 , 0.35426125, 0.2401386 , 0.7783076 ,\n",
       "         0.9477912 , 0.6423466 , 0.6813846 , 0.90814763, 0.96164155,\n",
       "         0.02667299, 0.6154498 , 0.69621164, 0.68289495, 0.66960955]],\n",
       "       dtype=float32),\n",
       " array([[0.01205891, 0.71029645, 0.35475224, 0.24927096, 0.7776936 ,\n",
       "         0.9528963 , 0.62134737, 0.67670596, 0.9132417 , 0.96696836,\n",
       "         0.0251479 , 0.64378226, 0.6798993 , 0.6871281 , 0.6661868 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01798481, 0.69570714, 0.35544172, 0.23554656, 0.774682  ,\n",
       "         0.93958455, 0.68325204, 0.6703915 , 0.90333265, 0.9527165 ,\n",
       "         0.02949853, 0.45753896, 0.7116566 , 0.69533676, 0.6663723 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00835426, 0.72246134, 0.34788534, 0.22950093, 0.7815081 ,\n",
       "         0.96249   , 0.61998117, 0.67937636, 0.9301992 , 0.9766574 ,\n",
       "         0.0205249 , 0.6451473 , 0.66899306, 0.69151455, 0.66226023]],\n",
       "       dtype=float32),\n",
       " array([[0.01500326, 0.68293417, 0.3452124 , 0.19819833, 0.78309584,\n",
       "         0.9456975 , 0.6797757 , 0.68237853, 0.9003022 , 0.96024555,\n",
       "         0.02537946, 0.4391185 , 0.6929966 , 0.69276255, 0.67261714]],\n",
       "       dtype=float32),\n",
       " array([[0.02687467, 0.68720555, 0.34606472, 0.20181565, 0.7788089 ,\n",
       "         0.9291533 , 0.85653216, 0.6867516 , 0.9188037 , 0.93708336,\n",
       "         0.0314923 , 0.08288027, 0.820904  , 0.6884656 , 0.6722556 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04266609, 0.655816  , 0.34985065, 0.19510746, 0.77829266,\n",
       "         0.9056252 , 0.87837726, 0.69032574, 0.892178  , 0.90430653,\n",
       "         0.03890544, 0.05626786, 0.83309543, 0.68443036, 0.6818395 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04072525, 0.6443052 , 0.35378808, 0.21125367, 0.77735794,\n",
       "         0.9079582 , 0.8639338 , 0.692343  , 0.887932  , 0.90690076,\n",
       "         0.04154466, 0.08616358, 0.81885445, 0.68560576, 0.6870854 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0503822 , 0.66781455, 0.34183747, 0.19398695, 0.77505493,\n",
       "         0.89765507, 0.9202913 , 0.6946629 , 0.907892  , 0.8909343 ,\n",
       "         0.04228644, 0.02570575, 0.8705859 , 0.6844222 , 0.67997575]],\n",
       "       dtype=float32),\n",
       " array([[0.06497537, 0.66406786, 0.34200343, 0.1943889 , 0.7730726 ,\n",
       "         0.88046783, 0.9261878 , 0.69647706, 0.90410024, 0.8641724 ,\n",
       "         0.04813735, 0.0243139 , 0.8833188 , 0.681682  , 0.68103826]],\n",
       "       dtype=float32),\n",
       " array([[0.07965328, 0.65454257, 0.34417292, 0.19702265, 0.77022845,\n",
       "         0.8609864 , 0.9109866 , 0.6938153 , 0.89193296, 0.83553547,\n",
       "         0.055678  , 0.04500275, 0.87738603, 0.682538  , 0.6819846 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08320431, 0.6428195 , 0.33481243, 0.18182649, 0.77403754,\n",
       "         0.8557902 , 0.8980252 , 0.70511067, 0.88505614, 0.82915455,\n",
       "         0.05740091, 0.06593066, 0.87215215, 0.68008924, 0.68768966]],\n",
       "       dtype=float32),\n",
       " array([[0.06574104, 0.65848637, 0.33557832, 0.18417656, 0.77372664,\n",
       "         0.8726171 , 0.89405966, 0.70396227, 0.8993832 , 0.85835385,\n",
       "         0.05233793, 0.08671071, 0.8641892 , 0.6800064 , 0.68385977]],\n",
       "       dtype=float32),\n",
       " array([[0.04650617, 0.67827773, 0.339973  , 0.20547572, 0.77249515,\n",
       "         0.8958194 , 0.85451376, 0.6959189 , 0.9031082 , 0.89349556,\n",
       "         0.04493062, 0.14634989, 0.8359115 , 0.6814299 , 0.67762625]],\n",
       "       dtype=float32),\n",
       " array([[0.02848643, 0.69664145, 0.34965116, 0.23271203, 0.77232635,\n",
       "         0.9227543 , 0.7934652 , 0.6868972 , 0.91261774, 0.93031925,\n",
       "         0.03616777, 0.23410487, 0.79564935, 0.6838658 , 0.67280596]],\n",
       "       dtype=float32),\n",
       " array([[0.02367503, 0.70083773, 0.35112602, 0.23741056, 0.7744545 ,\n",
       "         0.9316509 , 0.7266747 , 0.6856184 , 0.9170786 , 0.9418293 ,\n",
       "         0.03354663, 0.45074758, 0.7754893 , 0.6851376 , 0.66884774]],\n",
       "       dtype=float32),\n",
       " array([[0.02403336, 0.70592576, 0.36117828, 0.24963257, 0.77322686,\n",
       "         0.93237007, 0.75896525, 0.678106  , 0.91730464, 0.9416117 ,\n",
       "         0.03274671, 0.37931958, 0.78662556, 0.683759  , 0.66455114]],\n",
       "       dtype=float32),\n",
       " array([[0.02209939, 0.6961421 , 0.3620159 , 0.24012284, 0.77494234,\n",
       "         0.9335786 , 0.7187288 , 0.67521113, 0.9043588 , 0.9445067 ,\n",
       "         0.03114025, 0.4245955 , 0.749579  , 0.6854345 , 0.6677157 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0284648 , 0.6872954 , 0.36051056, 0.22755654, 0.7749931 ,\n",
       "         0.92405754, 0.7824499 , 0.67925787, 0.90701914, 0.93184185,\n",
       "         0.03409148, 0.25111735, 0.7887007 , 0.68534636, 0.67112005]],\n",
       "       dtype=float32),\n",
       " array([[0.01524859, 0.70455694, 0.3533589 , 0.2335978 , 0.77875173,\n",
       "         0.94781977, 0.7019923 , 0.6821233 , 0.92125946, 0.96083933,\n",
       "         0.02635916, 0.44455108, 0.7364648 , 0.6888762 , 0.6682935 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01597776, 0.69908917, 0.33641034, 0.21794063, 0.7792655 ,\n",
       "         0.94642323, 0.73194844, 0.68486005, 0.9182463 , 0.9593209 ,\n",
       "         0.02704047, 0.32966626, 0.74354345, 0.69754666, 0.66965425]],\n",
       "       dtype=float32),\n",
       " array([[0.0110909 , 0.6991724 , 0.33924943, 0.2196473 , 0.78209424,\n",
       "         0.9565848 , 0.6875972 , 0.6834207 , 0.916331  , 0.9702545 ,\n",
       "         0.02279142, 0.39774868, 0.69336647, 0.6984057 , 0.67111796]],\n",
       "       dtype=float32),\n",
       " array([[0.00840618, 0.7092812 , 0.34828237, 0.22721297, 0.7823718 ,\n",
       "         0.9622501 , 0.6181252 , 0.67550254, 0.9158301 , 0.9763139 ,\n",
       "         0.02015993, 0.58007777, 0.64265186, 0.6971142 , 0.66574943]],\n",
       "       dtype=float32),\n",
       " array([[0.00868125, 0.7044182 , 0.34686586, 0.21439265, 0.7841519 ,\n",
       "         0.96078247, 0.61300427, 0.67565143, 0.90873027, 0.9754041 ,\n",
       "         0.02018049, 0.6401609 , 0.6337747 , 0.6939897 , 0.6652959 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01607035, 0.6905184 , 0.3551879 , 0.20672455, 0.7822706 ,\n",
       "         0.94494843, 0.7547373 , 0.6794953 , 0.90990597, 0.95849615,\n",
       "         0.02601073, 0.38659778, 0.7342392 , 0.6878709 , 0.6676364 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02282424, 0.6796903 , 0.35181132, 0.21039867, 0.781026  ,\n",
       "         0.93506056, 0.8132708 , 0.68169284, 0.90196323, 0.94468135,\n",
       "         0.02955748, 0.1816687 , 0.78017646, 0.6875933 , 0.671504  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01669091, 0.7061932 , 0.36122027, 0.24742946, 0.778031  ,\n",
       "         0.94645154, 0.7397305 , 0.671121  , 0.9103303 , 0.9579021 ,\n",
       "         0.02639948, 0.36251083, 0.74803257, 0.6872883 , 0.66138417]],\n",
       "       dtype=float32),\n",
       " array([[0.01002888, 0.71611077, 0.33995226, 0.23782934, 0.784265  ,\n",
       "         0.96145815, 0.65604067, 0.68229353, 0.9227771 , 0.97394776,\n",
       "         0.02141474, 0.55631953, 0.70797354, 0.69341695, 0.6608695 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01066734, 0.7211745 , 0.35278556, 0.26437783, 0.78069353,\n",
       "         0.9602018 , 0.6812632 , 0.668821  , 0.9093215 , 0.9720133 ,\n",
       "         0.02147733, 0.4733893 , 0.70412976, 0.69041425, 0.6556643 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01174574, 0.72746277, 0.36325592, 0.28032202, 0.7783162 ,\n",
       "         0.95929337, 0.7387236 , 0.66388094, 0.91764903, 0.97017866,\n",
       "         0.02173967, 0.31534877, 0.74288523, 0.6874058 , 0.6532812 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01487468, 0.7105194 , 0.3756631 , 0.2857769 , 0.7765885 ,\n",
       "         0.95272195, 0.7815285 , 0.6636969 , 0.9136482 , 0.96276236,\n",
       "         0.02537136, 0.2742838 , 0.76114017, 0.68456   , 0.65904325]],\n",
       "       dtype=float32),\n",
       " array([[0.0282911 , 0.69142675, 0.37252727, 0.2701627 , 0.77483374,\n",
       "         0.93086064, 0.83750236, 0.6687219 , 0.90088505, 0.93466103,\n",
       "         0.03380204, 0.16841342, 0.81423604, 0.6819969 , 0.6628833 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0376096 , 0.708883  , 0.36192894, 0.26434162, 0.7698653 ,\n",
       "         0.92114836, 0.91376185, 0.66667145, 0.9150075 , 0.91847324,\n",
       "         0.03557471, 0.0282317 , 0.8711978 , 0.6863924 , 0.65731645]],\n",
       "       dtype=float32),\n",
       " array([[0.01431118, 0.73788106, 0.36726806, 0.2921796 , 0.7730645 ,\n",
       "         0.9553108 , 0.8129058 , 0.6654217 , 0.939603  , 0.96512616,\n",
       "         0.02464685, 0.16698791, 0.80464333, 0.6882157 , 0.6517666 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01372011, 0.7295334 , 0.36085463, 0.30693576, 0.77500325,\n",
       "         0.95556957, 0.72571003, 0.6651408 , 0.9125521 , 0.96538335,\n",
       "         0.02488574, 0.35118836, 0.7507039 , 0.6858939 , 0.6531126 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00946553, 0.7412368 , 0.38187343, 0.34433246, 0.77469635,\n",
       "         0.9642704 , 0.6696917 , 0.65708536, 0.91789144, 0.9747346 ,\n",
       "         0.02175664, 0.5367699 , 0.70820165, 0.6795859 , 0.649118  ]],\n",
       "       dtype=float32),\n",
       " array([[0.00682271, 0.7448481 , 0.39107853, 0.35327974, 0.77397704,\n",
       "         0.96994215, 0.61874807, 0.64562935, 0.9199742 , 0.98080176,\n",
       "         0.01924951, 0.6807123 , 0.657429  , 0.68350613, 0.64508045]],\n",
       "       dtype=float32),\n",
       " array([[0.00861564, 0.73687947, 0.40229583, 0.34900916, 0.7731843 ,\n",
       "         0.96546704, 0.648196  , 0.63941747, 0.9131574 , 0.9764489 ,\n",
       "         0.02049516, 0.61448205, 0.6780767 , 0.680315  , 0.6448614 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01022908, 0.73367524, 0.40045455, 0.3406446 , 0.77378345,\n",
       "         0.96241814, 0.6574176 , 0.6394551 , 0.91053045, 0.973104  ,\n",
       "         0.02128475, 0.5835932 , 0.7006611 , 0.68020356, 0.64338255]],\n",
       "       dtype=float32),\n",
       " array([[0.01924378, 0.71383077, 0.3873139 , 0.30173743, 0.7755562 ,\n",
       "         0.9469573 , 0.75593066, 0.65561444, 0.9133832 , 0.9549244 ,\n",
       "         0.02790213, 0.41578603, 0.7885567 , 0.67910373, 0.6493238 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01161022, 0.73633474, 0.38593435, 0.31658265, 0.77618957,\n",
       "         0.9619421 , 0.7352131 , 0.6504467 , 0.9272886 , 0.97168005,\n",
       "         0.02110326, 0.3446241 , 0.76529986, 0.68362087, 0.643575  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01251623, 0.7331893 , 0.38862187, 0.32552803, 0.7745554 ,\n",
       "         0.9597606 , 0.7078622 , 0.6437298 , 0.91435903, 0.96929526,\n",
       "         0.02150414, 0.3322344 , 0.74804455, 0.68574023, 0.64302933]],\n",
       "       dtype=float32),\n",
       " array([[0.01809679, 0.72563225, 0.3722413 , 0.30246708, 0.7750462 ,\n",
       "         0.95183647, 0.86424756, 0.66168976, 0.9253639 , 0.9585114 ,\n",
       "         0.02590048, 0.09162161, 0.83123994, 0.68452877, 0.649215  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01145173, 0.7341833 , 0.37932563, 0.29696685, 0.7754585 ,\n",
       "         0.96173173, 0.8085651 , 0.6554837 , 0.93195057, 0.97169465,\n",
       "         0.02077244, 0.16058719, 0.78013736, 0.6879189 , 0.64779335]],\n",
       "       dtype=float32),\n",
       " array([[0.01152282, 0.7267081 , 0.37732095, 0.3058724 , 0.77330124,\n",
       "         0.9609468 , 0.80709577, 0.64830214, 0.919358  , 0.9708227 ,\n",
       "         0.02162452, 0.15718974, 0.7590484 , 0.6941734 , 0.64783317]],\n",
       "       dtype=float32),\n",
       " array([[0.01704591, 0.7287152 , 0.38517058, 0.28437492, 0.7771789 ,\n",
       "         0.95063525, 0.8416982 , 0.6603845 , 0.9121555 , 0.95903397,\n",
       "         0.0231925 , 0.14246288, 0.8026601 , 0.6700648 , 0.6478056 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0268321 , 0.6986521 , 0.346791  , 0.2459453 , 0.7780138 ,\n",
       "         0.9367247 , 0.8905494 , 0.67855954, 0.9086262 , 0.94030476,\n",
       "         0.0305579 , 0.0606203 , 0.84567446, 0.6863175 , 0.6596187 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04982011, 0.6983592 , 0.3480088 , 0.23797664, 0.7748106 ,\n",
       "         0.91131055, 0.9438674 , 0.68651485, 0.91655064, 0.90035343,\n",
       "         0.03883504, 0.01651268, 0.9052483 , 0.67752826, 0.6607737 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05840608, 0.6896325 , 0.3709381 , 0.2736319 , 0.7694364 ,\n",
       "         0.9002315 , 0.9147653 , 0.67537546, 0.90171194, 0.88292503,\n",
       "         0.04386687, 0.0411005 , 0.89055616, 0.6744017 , 0.6619338 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03363229, 0.72993445, 0.34370542, 0.270312  , 0.7690863 ,\n",
       "         0.92783695, 0.91260225, 0.6779138 , 0.92769337, 0.9273287 ,\n",
       "         0.03481762, 0.047067  , 0.8824317 , 0.68287665, 0.65048605]],\n",
       "       dtype=float32),\n",
       " array([[0.02967056, 0.70738065, 0.34967595, 0.27187058, 0.7714366 ,\n",
       "         0.93081903, 0.8604585 , 0.67842895, 0.9123171 , 0.9331399 ,\n",
       "         0.0348433 , 0.12510353, 0.84165466, 0.68547606, 0.6590773 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0377937 , 0.68937576, 0.3436823 , 0.23878443, 0.77313274,\n",
       "         0.91909695, 0.87969166, 0.6853532 , 0.9102054 , 0.91790557,\n",
       "         0.03792742, 0.07509726, 0.8560143 , 0.6881836 , 0.66625464]],\n",
       "       dtype=float32),\n",
       " array([[0.09605484, 0.6697072 , 0.34554693, 0.22629029, 0.76807404,\n",
       "         0.8623135 , 0.9453417 , 0.69031215, 0.90325105, 0.82158893,\n",
       "         0.05762853, 0.02083597, 0.91843   , 0.68144643, 0.66897845]],\n",
       "       dtype=float32),\n",
       " array([[0.13423586, 0.66010773, 0.35976797, 0.22657396, 0.76356196,\n",
       "         0.826452  , 0.9483118 , 0.68456656, 0.8934793 , 0.760962  ,\n",
       "         0.06741168, 0.01917368, 0.92417836, 0.67638105, 0.6710923 ]],\n",
       "       dtype=float32),\n",
       " array([[0.12094287, 0.6546372 , 0.3449111 , 0.20580268, 0.7656445 ,\n",
       "         0.83294165, 0.9528769 , 0.6952162 , 0.8975423 , 0.77698255,\n",
       "         0.06517782, 0.01231151, 0.92012805, 0.6808851 , 0.6787734 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17497936, 0.65544707, 0.31380078, 0.19193609, 0.765621  ,\n",
       "         0.7995654 , 0.9685533 , 0.7156885 , 0.90899533, 0.70968133,\n",
       "         0.08095738, 0.00575428, 0.9466261 , 0.68442297, 0.68225133]],\n",
       "       dtype=float32),\n",
       " array([[0.13584775, 0.6556532 , 0.32190928, 0.22092094, 0.7635489 ,\n",
       "         0.82131135, 0.93938863, 0.7069624 , 0.881972  , 0.75241494,\n",
       "         0.07340151, 0.01449165, 0.9159954 , 0.68516207, 0.68449503]],\n",
       "       dtype=float32),\n",
       " array([[0.09754243, 0.65243226, 0.32180074, 0.19657332, 0.76783293,\n",
       "         0.8439505 , 0.9129813 , 0.7108175 , 0.8888646 , 0.80552137,\n",
       "         0.06452882, 0.04635336, 0.8888829 , 0.68462193, 0.6868913 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09169028, 0.6596113 , 0.32151824, 0.18456544, 0.76899725,\n",
       "         0.84648466, 0.921263  , 0.7160901 , 0.90099174, 0.8139065 ,\n",
       "         0.06220937, 0.04396494, 0.8921292 , 0.6804982 , 0.6875806 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07204699, 0.64906156, 0.32626912, 0.1805266 , 0.7669213 ,\n",
       "         0.8570701 , 0.88598865, 0.7079538 , 0.90157026, 0.84070027,\n",
       "         0.06137779, 0.12251798, 0.85425127, 0.69093883, 0.68895257]],\n",
       "       dtype=float32),\n",
       " array([[0.04595628, 0.6607131 , 0.3449249 , 0.18379992, 0.7678815 ,\n",
       "         0.8847295 , 0.78584415, 0.6996281 , 0.91376704, 0.88902664,\n",
       "         0.05038625, 0.4365334 , 0.7995551 , 0.68966484, 0.68448013]],\n",
       "       dtype=float32),\n",
       " array([[0.04089658, 0.666604  , 0.34585518, 0.20438293, 0.7675967 ,\n",
       "         0.89504063, 0.71825767, 0.68596095, 0.8949307 , 0.9003242 ,\n",
       "         0.04598054, 0.50954825, 0.7673711 , 0.69389504, 0.6778897 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04234646, 0.6673746 , 0.33935088, 0.18781306, 0.77426726,\n",
       "         0.8963224 , 0.74640614, 0.70066243, 0.900945  , 0.90040165,\n",
       "         0.0438497 , 0.42411774, 0.7940709 , 0.68344843, 0.6812005 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02376443, 0.68864894, 0.3559606 , 0.21331091, 0.77488005,\n",
       "         0.92644835, 0.6666413 , 0.6882703 , 0.9101253 , 0.93935066,\n",
       "         0.03307427, 0.5578017 , 0.7383785 , 0.6827388 , 0.6749636 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02511431, 0.66500664, 0.34778422, 0.18507087, 0.7782841 ,\n",
       "         0.9206492 , 0.60886425, 0.6885539 , 0.8896664 , 0.93512154,\n",
       "         0.03351574, 0.6370687 , 0.6978119 , 0.6889455 , 0.6801803 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01343577, 0.68640506, 0.349007  , 0.19368094, 0.78111225,\n",
       "         0.94600075, 0.57933134, 0.6874103 , 0.912265  , 0.96290344,\n",
       "         0.02538452, 0.6874645 , 0.65736246, 0.6905704 , 0.67629135]],\n",
       "       dtype=float32),\n",
       " array([[0.01710753, 0.69121605, 0.33462065, 0.18911712, 0.7817477 ,\n",
       "         0.9421515 , 0.7653674 , 0.6965133 , 0.91815585, 0.9559875 ,\n",
       "         0.02638745, 0.20668365, 0.7497932 , 0.6902945 , 0.6778536 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02092913, 0.6582657 , 0.3358242 , 0.183329  , 0.7799347 ,\n",
       "         0.93199474, 0.7256917 , 0.6884863 , 0.8886689 , 0.94547087,\n",
       "         0.02971365, 0.202366  , 0.708929  , 0.7003042 , 0.6858995 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03095863, 0.6770438 , 0.33347237, 0.17875873, 0.776309  ,\n",
       "         0.91737366, 0.8506916 , 0.6932602 , 0.9149866 , 0.92585146,\n",
       "         0.03454519, 0.0697425 , 0.81043047, 0.6946112 , 0.6801589 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04005343, 0.6470802 , 0.3314263 , 0.179789  , 0.7764038 ,\n",
       "         0.90323246, 0.8718467 , 0.69857246, 0.88941854, 0.9051991 ,\n",
       "         0.0409812 , 0.05953452, 0.81033117, 0.6939663 , 0.6895328 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02587435, 0.66244495, 0.3482305 , 0.19944504, 0.77465004,\n",
       "         0.9228462 , 0.82836133, 0.68928045, 0.9010223 , 0.93330044,\n",
       "         0.03522268, 0.13132823, 0.76342165, 0.6928552 , 0.6859193 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02318212, 0.6829617 , 0.3505953 , 0.23117453, 0.77215344,\n",
       "         0.92978156, 0.8019685 , 0.6811277 , 0.8977199 , 0.93974286,\n",
       "         0.03319632, 0.14807846, 0.7546285 , 0.6914873 , 0.678374  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01346506, 0.7062408 , 0.35575062, 0.24094823, 0.7751786 ,\n",
       "         0.94916314, 0.68901074, 0.68166035, 0.9270612 , 0.9634088 ,\n",
       "         0.02794466, 0.57290924, 0.7146829 , 0.6907396 , 0.66896594]],\n",
       "       dtype=float32),\n",
       " array([[0.012276  , 0.72442025, 0.35908568, 0.25884545, 0.77388203,\n",
       "         0.9520722 , 0.6169908 , 0.66618997, 0.91465926, 0.966203  ,\n",
       "         0.02495953, 0.6595529 , 0.6817641 , 0.69102234, 0.65657747]],\n",
       "       dtype=float32),\n",
       " array([[0.01012223, 0.723814  , 0.36539087, 0.24500977, 0.7760466 ,\n",
       "         0.95545095, 0.5559171 , 0.6620815 , 0.918817  , 0.9710173 ,\n",
       "         0.02347844, 0.8265106 , 0.6406577 , 0.6926373 , 0.6529361 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01025536, 0.7369486 , 0.37118357, 0.26714283, 0.7743528 ,\n",
       "         0.95781237, 0.57344615, 0.6570514 , 0.9337462 , 0.9720249 ,\n",
       "         0.0232783 , 0.7654236 , 0.68074197, 0.69935906, 0.64527947]],\n",
       "       dtype=float32),\n",
       " array([[0.00443297, 0.7578446 , 0.40252993, 0.32361552, 0.7740341 ,\n",
       "         0.97466046, 0.40888724, 0.63275075, 0.93715686, 0.9866203 ,\n",
       "         0.01576457, 0.91091764, 0.55927193, 0.6970607 , 0.6358167 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00576295, 0.7711509 , 0.39739874, 0.34320617, 0.7730551 ,\n",
       "         0.97263676, 0.48311645, 0.6274912 , 0.9323106 , 0.9839461 ,\n",
       "         0.01581114, 0.8031544 , 0.63426596, 0.689156  , 0.62710905]],\n",
       "       dtype=float32),\n",
       " array([[0.00132093, 0.78407943, 0.44156966, 0.38881567, 0.77915597,\n",
       "         0.98952943, 0.37512317, 0.61643386, 0.9643681 , 0.99594516,\n",
       "         0.00830673, 0.89654964, 0.5182913 , 0.6918687 , 0.62914485]],\n",
       "       dtype=float32),\n",
       " array([[0.00163809, 0.7937217 , 0.44718385, 0.4181442 , 0.7766266 ,\n",
       "         0.98855585, 0.4271886 , 0.60030365, 0.9558281 , 0.9951539 ,\n",
       "         0.00841783, 0.837758  , 0.55274755, 0.6865921 , 0.61632776]],\n",
       "       dtype=float32),\n",
       " array([[4.2166171e-04, 7.8983063e-01, 5.1324445e-01, 4.6404171e-01,\n",
       "         7.8118020e-01, 9.9498051e-01, 2.2728075e-01, 5.7550365e-01,\n",
       "         9.7250980e-01, 9.9858320e-01, 4.9835439e-03, 9.7339475e-01,\n",
       "         3.6898550e-01, 6.9450849e-01, 6.1776787e-01]], dtype=float32),\n",
       " array([[0.00153824, 0.77168757, 0.4431934 , 0.38474867, 0.7861087 ,\n",
       "         0.9900547 , 0.61088693, 0.61308503, 0.9631445 , 0.995773  ,\n",
       "         0.00827156, 0.65145284, 0.6273488 , 0.69086874, 0.62158024]],\n",
       "       dtype=float32),\n",
       " array([[8.8410499e-04, 8.0325699e-01, 5.0423634e-01, 5.0159395e-01,\n",
       "         7.7758837e-01, 9.9287874e-01, 4.1361129e-01, 5.5575818e-01,\n",
       "         9.5433503e-01, 9.9733317e-01, 5.6276359e-03, 8.0076492e-01,\n",
       "         4.9149382e-01, 6.8480599e-01, 5.9844798e-01]], dtype=float32),\n",
       " array([[0.00379642, 0.77117443, 0.42003953, 0.3734738 , 0.78378296,\n",
       "         0.98376334, 0.7841964 , 0.62182766, 0.9535321 , 0.9907747 ,\n",
       "         0.01117474, 0.2285955 , 0.7574444 , 0.6846177 , 0.6193919 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00802293, 0.75755554, 0.38761568, 0.35582152, 0.7833242 ,\n",
       "         0.97482   , 0.8260952 , 0.6183797 , 0.9011481 , 0.9815694 ,\n",
       "         0.01317237, 0.05078741, 0.77732784, 0.6864038 , 0.6187397 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01757277, 0.7253641 , 0.3478589 , 0.27964365, 0.7856559 ,\n",
       "         0.9587523 , 0.92590266, 0.6593878 , 0.90554386, 0.9629226 ,\n",
       "         0.02085484, 0.01636589, 0.86267227, 0.68572474, 0.63797826]],\n",
       "       dtype=float32),\n",
       " array([[0.01354894, 0.7434604 , 0.32019642, 0.27671784, 0.7854531 ,\n",
       "         0.96618026, 0.9406111 , 0.6685018 , 0.9135889 , 0.9710169 ,\n",
       "         0.01715332, 0.00310803, 0.8682493 , 0.69382685, 0.6403193 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0241516 , 0.7133809 , 0.34922743, 0.26873925, 0.7792001 ,\n",
       "         0.9453598 , 0.94019735, 0.66813886, 0.9015782 , 0.94733256,\n",
       "         0.02682096, 0.01799504, 0.869017  , 0.68147576, 0.6472987 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00822138, 0.7545539 , 0.346286  , 0.29615423, 0.78240615,\n",
       "         0.97384745, 0.9172219 , 0.6764338 , 0.95419556, 0.98123175,\n",
       "         0.01696986, 0.02676605, 0.8567339 , 0.6886788 , 0.6412598 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0096868 , 0.7474033 , 0.41365427, 0.34876317, 0.7711549 ,\n",
       "         0.96492654, 0.840034  , 0.6288412 , 0.9142003 , 0.9744621 ,\n",
       "         0.01984107, 0.3333686 , 0.7576379 , 0.67156565, 0.6269872 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02021722, 0.75131327, 0.39217773, 0.37316954, 0.7697899 ,\n",
       "         0.95118135, 0.8063902 , 0.6343827 , 0.90251625, 0.9551001 ,\n",
       "         0.02568492, 0.30955344, 0.82638943, 0.6723581 , 0.62071437]],\n",
       "       dtype=float32),\n",
       " array([[0.04843361, 0.7334064 , 0.3645886 , 0.3072856 , 0.76984876,\n",
       "         0.9175356 , 0.943811  , 0.6651061 , 0.9183179 , 0.90485424,\n",
       "         0.04156173, 0.09925474, 0.9160435 , 0.6653712 , 0.62899923]],\n",
       "       dtype=float32),\n",
       " array([[0.19129881, 0.7161005 , 0.32240018, 0.30920306, 0.76369977,\n",
       "         0.8285382 , 0.9572875 , 0.6799079 , 0.88689965, 0.71978813,\n",
       "         0.07573935, 0.02509162, 0.9602518 , 0.6723016 , 0.6316146 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05950997, 0.72768897, 0.36922362, 0.31890672, 0.7639337 ,\n",
       "         0.9047952 , 0.909253  , 0.6621189 , 0.9144725 , 0.88539505,\n",
       "         0.04404925, 0.07276518, 0.9077026 , 0.67317724, 0.6383243 ]],\n",
       "       dtype=float32),\n",
       " array([[0.10684152, 0.72802204, 0.28496268, 0.25780717, 0.76886207,\n",
       "         0.87978595, 0.95917565, 0.70657605, 0.9283993 , 0.8287598 ,\n",
       "         0.05695762, 0.00733438, 0.9563751 , 0.6902625 , 0.64502394]],\n",
       "       dtype=float32),\n",
       " array([[0.1382299 , 0.6775828 , 0.28337216, 0.20880856, 0.77032894,\n",
       "         0.8473207 , 0.9782702 , 0.7188788 , 0.90448207, 0.774191  ,\n",
       "         0.0653901 , 0.001352  , 0.9544318 , 0.6924969 , 0.6710832 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14577171, 0.6558683 , 0.28692302, 0.18647562, 0.7692102 ,\n",
       "         0.82725734, 0.9698859 , 0.7191851 , 0.8850838 , 0.75146157,\n",
       "         0.0683302 , 0.00235524, 0.93996316, 0.69272685, 0.68061996]],\n",
       "       dtype=float32),\n",
       " array([[0.13621604, 0.6459963 , 0.32091132, 0.18670447, 0.76307195,\n",
       "         0.8089772 , 0.9629589 , 0.70673776, 0.87409323, 0.741569  ,\n",
       "         0.07396836, 0.01098983, 0.9149289 , 0.68349177, 0.6823903 ]],\n",
       "       dtype=float32),\n",
       " array([[0.11438306, 0.6426794 , 0.33156613, 0.18981925, 0.7621815 ,\n",
       "         0.81880045, 0.94162   , 0.7059093 , 0.880199  , 0.76863706,\n",
       "         0.07371185, 0.04517981, 0.89255714, 0.6825188 , 0.6840818 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04657749, 0.66265357, 0.33763766, 0.19835041, 0.7660222 ,\n",
       "         0.8896619 , 0.88350755, 0.70100135, 0.90180063, 0.88792694,\n",
       "         0.04942265, 0.13459182, 0.82710403, 0.68813205, 0.6818307 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07651439, 0.6689412 , 0.32915598, 0.20257224, 0.7612532 ,\n",
       "         0.8543518 , 0.7683924 , 0.6906877 , 0.89791095, 0.8370398 ,\n",
       "         0.06326558, 0.5405683 , 0.83904386, 0.6973604 , 0.6667475 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15830761, 0.65074366, 0.3076697 , 0.18532062, 0.7643468 ,\n",
       "         0.7954678 , 0.8924372 , 0.71325934, 0.89266294, 0.7230934 ,\n",
       "         0.08496022, 0.14326821, 0.912667  , 0.6911927 , 0.675365  ]],\n",
       "       dtype=float32),\n",
       " array([[0.11275273, 0.63134223, 0.33830813, 0.16988875, 0.7725134 ,\n",
       "         0.8199584 , 0.8477815 , 0.71363485, 0.8654407 , 0.77773505,\n",
       "         0.06632535, 0.27986845, 0.8642566 , 0.6712996 , 0.68495035]],\n",
       "       dtype=float32),\n",
       " array([[0.02572632, 0.6706316 , 0.3539168 , 0.19092213, 0.77351886,\n",
       "         0.9202785 , 0.671129  , 0.69257563, 0.90954185, 0.9341892 ,\n",
       "         0.03478984, 0.6044629 , 0.7319367 , 0.68977326, 0.6769511 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02590819, 0.6535269 , 0.3241106 , 0.14878   , 0.77835196,\n",
       "         0.9165232 , 0.59423864, 0.69547904, 0.89037544, 0.9333918 ,\n",
       "         0.03312638, 0.6216175 , 0.68887645, 0.70438117, 0.6797225 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04189066, 0.6551994 , 0.30808082, 0.16954766, 0.7762236 ,\n",
       "         0.90119636, 0.749559  , 0.7018446 , 0.8803625 , 0.9042973 ,\n",
       "         0.04020097, 0.21085909, 0.7858782 , 0.70458764, 0.679948  ]],\n",
       "       dtype=float32),\n",
       " array([[0.04433142, 0.6529747 , 0.29767612, 0.13174525, 0.7802317 ,\n",
       "         0.8977199 , 0.8484061 , 0.7172487 , 0.9157772 , 0.90223855,\n",
       "         0.0396651 , 0.07719204, 0.8373462 , 0.7044626 , 0.6858633 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05704277, 0.62584877, 0.30787876, 0.14299251, 0.77615535,\n",
       "         0.87717897, 0.8865499 , 0.7121398 , 0.8793824 , 0.8713838 ,\n",
       "         0.04657236, 0.03353919, 0.82640254, 0.70311946, 0.6954442 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07818491, 0.62131375, 0.33280265, 0.15181653, 0.76930916,\n",
       "         0.842585  , 0.88787466, 0.7013025 , 0.86613613, 0.8245454 ,\n",
       "         0.05707948, 0.07290959, 0.8263897 , 0.6935124 , 0.6929115 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04419079, 0.6398695 , 0.3351331 , 0.17069928, 0.76992744,\n",
       "         0.8884005 , 0.8717249 , 0.70391285, 0.8954656 , 0.8910862 ,\n",
       "         0.04691421, 0.10131727, 0.7999085 , 0.69571126, 0.69311076]],\n",
       "       dtype=float32),\n",
       " array([[0.05109434, 0.6372073 , 0.31628418, 0.16586104, 0.7718911 ,\n",
       "         0.8847666 , 0.86428314, 0.70873183, 0.88336813, 0.8813107 ,\n",
       "         0.04620491, 0.045929  , 0.8133182 , 0.70241904, 0.69544214]],\n",
       "       dtype=float32),\n",
       " array([[0.02543001, 0.68455887, 0.33835664, 0.19926316, 0.77085817,\n",
       "         0.92382985, 0.75588346, 0.69621396, 0.92256534, 0.9359599 ,\n",
       "         0.03528035, 0.3153433 , 0.7722536 , 0.6959438 , 0.6781982 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00822386, 0.7359532 , 0.3651731 , 0.21554546, 0.7736569 ,\n",
       "         0.95874363, 0.55484676, 0.67454433, 0.94151706, 0.9757666 ,\n",
       "         0.02054187, 0.8539916 , 0.64621377, 0.68756163, 0.65493953]],\n",
       "       dtype=float32),\n",
       " array([[0.01495931, 0.67308235, 0.36525124, 0.20200418, 0.7709809 ,\n",
       "         0.93728155, 0.48261347, 0.6562099 , 0.88530785, 0.95656747,\n",
       "         0.02868713, 0.8895207 , 0.58163804, 0.7064131 , 0.664828  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02300074, 0.6675573 , 0.35377043, 0.177198  , 0.7808985 ,\n",
       "         0.92760456, 0.7172513 , 0.6904209 , 0.9056519 , 0.94192976,\n",
       "         0.03124117, 0.5640425 , 0.7383686 , 0.68567294, 0.6742078 ]],\n",
       "       dtype=float32),\n",
       " array([[0.041582  , 0.6843317 , 0.35207126, 0.20150864, 0.777843  ,\n",
       "         0.907948  , 0.82812774, 0.69432086, 0.9081917 , 0.90876853,\n",
       "         0.03720028, 0.19576208, 0.8390447 , 0.67514807, 0.66972905]],\n",
       "       dtype=float32),\n",
       " array([[0.027238  , 0.685973  , 0.35848078, 0.23612468, 0.7718992 ,\n",
       "         0.9267729 , 0.69199395, 0.67410827, 0.91182095, 0.93552923,\n",
       "         0.03447229, 0.43928406, 0.7709911 , 0.6960363 , 0.66656893]],\n",
       "       dtype=float32),\n",
       " array([[0.02167309, 0.69749594, 0.33132613, 0.20834829, 0.7773778 ,\n",
       "         0.9380705 , 0.7708154 , 0.6877024 , 0.91854614, 0.9484762 ,\n",
       "         0.02848149, 0.16289476, 0.787764  , 0.6987027 , 0.6681661 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00938467, 0.7009522 , 0.34619173, 0.23649232, 0.7803809 ,\n",
       "         0.9624405 , 0.683546  , 0.67805314, 0.9126501 , 0.9748336 ,\n",
       "         0.01947831, 0.2352637 , 0.68153495, 0.6993905 , 0.6709095 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00363637, 0.7449474 , 0.38652006, 0.30273804, 0.7734735 ,\n",
       "         0.978293  , 0.5081683 , 0.63901144, 0.93463135, 0.9889979 ,\n",
       "         0.01303274, 0.56695753, 0.55845505, 0.7069235 , 0.64951944]],\n",
       "       dtype=float32),\n",
       " array([[0.00671267, 0.72004366, 0.34916583, 0.25598532, 0.7780078 ,\n",
       "         0.9703627 , 0.7689333 , 0.67024124, 0.93957835, 0.98178816,\n",
       "         0.018589  , 0.2377092 , 0.7122276 , 0.7072727 , 0.6592723 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02024929, 0.6729354 , 0.34190258, 0.23718512, 0.77853584,\n",
       "         0.943224  , 0.8867486 , 0.6856829 , 0.9028743 , 0.9508125 ,\n",
       "         0.03083509, 0.08858111, 0.8014907 , 0.6958631 , 0.6725154 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03236759, 0.6946122 , 0.3377252 , 0.22572534, 0.77324116,\n",
       "         0.92414397, 0.92124915, 0.6814991 , 0.90781057, 0.9260026 ,\n",
       "         0.03469265, 0.03323646, 0.8529589 , 0.69135714, 0.6638602 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0397157 , 0.6894049 , 0.34979513, 0.22497882, 0.7758874 ,\n",
       "         0.91455597, 0.8844982 , 0.68605256, 0.8908312 , 0.9123241 ,\n",
       "         0.03441224, 0.04912916, 0.846465  , 0.6767526 , 0.6678635 ]],\n",
       "       dtype=float32),\n",
       " array([[0.08280554, 0.6788022 , 0.32533985, 0.1883683 , 0.7824046 ,\n",
       "         0.87889653, 0.95781994, 0.72872424, 0.9136617 , 0.8478758 ,\n",
       "         0.04665653, 0.00862388, 0.93054754, 0.6568678 , 0.68118423]],\n",
       "       dtype=float32),\n",
       " array([[0.12667295, 0.64517856, 0.35867897, 0.21490155, 0.7737202 ,\n",
       "         0.82819206, 0.9432533 , 0.7122499 , 0.85465676, 0.76439476,\n",
       "         0.06222968, 0.02260786, 0.9085359 , 0.6483443 , 0.6877091 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1211585 , 0.6535921 , 0.34777036, 0.19983682, 0.7661949 ,\n",
       "         0.821943  , 0.9390042 , 0.7045446 , 0.8864093 , 0.7670997 ,\n",
       "         0.06707796, 0.02526616, 0.9050783 , 0.6700093 , 0.68507975]],\n",
       "       dtype=float32),\n",
       " array([[0.10272765, 0.62873167, 0.32251117, 0.17139031, 0.7688744 ,\n",
       "         0.82881767, 0.9359925 , 0.71373534, 0.8692164 , 0.78712225,\n",
       "         0.0670532 , 0.02771403, 0.8792241 , 0.6831368 , 0.69486654]],\n",
       "       dtype=float32),\n",
       " array([[0.16618602, 0.63058025, 0.30306312, 0.17088848, 0.76542026,\n",
       "         0.78111464, 0.96015376, 0.7224449 , 0.87803054, 0.69688165,\n",
       "         0.09090956, 0.02007285, 0.9209662 , 0.6856693 , 0.6917359 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1137263 , 0.6480574 , 0.29488584, 0.19443423, 0.75755584,\n",
       "         0.82288975, 0.9333761 , 0.7055627 , 0.8948692 , 0.77226734,\n",
       "         0.0815189 , 0.02721021, 0.89564604, 0.7121791 , 0.6861815 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14960138, 0.6693869 , 0.3087908 , 0.19999659, 0.75878555,\n",
       "         0.79680675, 0.9320988 , 0.71580786, 0.9157419 , 0.7268248 ,\n",
       "         0.09060437, 0.06555939, 0.92353076, 0.68937624, 0.6802303 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09372546, 0.6764175 , 0.34518555, 0.2370842 , 0.7663247 ,\n",
       "         0.8469383 , 0.8605852 , 0.70958745, 0.8880672 , 0.80953884,\n",
       "         0.06365708, 0.16373867, 0.87778234, 0.6637007 , 0.68169993]],\n",
       "       dtype=float32),\n",
       " array([[0.07991771, 0.67820287, 0.3535978 , 0.25128353, 0.76252997,\n",
       "         0.85455394, 0.8464977 , 0.7011088 , 0.8859885 , 0.8266326 ,\n",
       "         0.06313726, 0.22798629, 0.8552669 , 0.66728616, 0.6807812 ]],\n",
       "       dtype=float32),\n",
       " array([[0.11607395, 0.65986323, 0.31579584, 0.21255054, 0.7596028 ,\n",
       "         0.8199686 , 0.87105805, 0.7034359 , 0.8892989 , 0.7703388 ,\n",
       "         0.07760875, 0.08993442, 0.8803795 , 0.6961183 , 0.6845412 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14907575, 0.6259739 , 0.32069746, 0.19482598, 0.7586568 ,\n",
       "         0.78221864, 0.8797271 , 0.70442414, 0.8721634 , 0.7130485 ,\n",
       "         0.09205934, 0.08961947, 0.87642694, 0.69865584, 0.694608  ]],\n",
       "       dtype=float32),\n",
       " array([[0.09400143, 0.64362234, 0.31221363, 0.19218788, 0.7594896 ,\n",
       "         0.8330235 , 0.827225  , 0.69952905, 0.8967956 , 0.80228436,\n",
       "         0.07393219, 0.13175225, 0.84972143, 0.71150774, 0.68973553]],\n",
       "       dtype=float32),\n",
       " array([[0.05763587, 0.63658315, 0.33299223, 0.16433086, 0.76760465,\n",
       "         0.86262774, 0.7922826 , 0.7017439 , 0.891088  , 0.8609309 ,\n",
       "         0.05545549, 0.22319566, 0.7846881 , 0.698574  , 0.6955015 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09233234, 0.67481714, 0.30423424, 0.15670632, 0.7653605 ,\n",
       "         0.84014505, 0.9366163 , 0.7189922 , 0.93405885, 0.812669  ,\n",
       "         0.06314828, 0.01361847, 0.9083707 , 0.6966785 , 0.6897248 ]],\n",
       "       dtype=float32),\n",
       " array([[0.11507878, 0.6119638 , 0.3172714 , 0.17000447, 0.7648944 ,\n",
       "         0.803719  , 0.89612275, 0.71274626, 0.8527901 , 0.7560206 ,\n",
       "         0.07734363, 0.04258792, 0.8475064 , 0.6941098 , 0.7060971 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04392092, 0.6528423 , 0.34857768, 0.20548114, 0.76453644,\n",
       "         0.88515586, 0.74862474, 0.6972853 , 0.903798  , 0.8891863 ,\n",
       "         0.05206446, 0.31519696, 0.7647683 , 0.6967484 , 0.69488376]],\n",
       "       dtype=float32),\n",
       " array([[0.0116944 , 0.69535816, 0.3873894 , 0.23192185, 0.7664635 ,\n",
       "         0.94278866, 0.494488  , 0.6683679 , 0.9195462 , 0.9631287 ,\n",
       "         0.02824509, 0.85605764, 0.5760095 , 0.69279313, 0.67836034]],\n",
       "       dtype=float32),\n",
       " array([[0.02543583, 0.6677368 , 0.3351587 , 0.2071786 , 0.77308017,\n",
       "         0.9206671 , 0.6853544 , 0.69453245, 0.8939999 , 0.93298787,\n",
       "         0.03818819, 0.47868925, 0.7156735 , 0.69802874, 0.68525726]],\n",
       "       dtype=float32),\n",
       " array([[0.0318126 , 0.6603755 , 0.33297306, 0.17606387, 0.77534556,\n",
       "         0.90890217, 0.7554684 , 0.6972826 , 0.9013354 , 0.9197739 ,\n",
       "         0.03916094, 0.2642268 , 0.7551055 , 0.6984406 , 0.6873629 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04143293, 0.6294401 , 0.3464914 , 0.17159   , 0.77666694,\n",
       "         0.89018184, 0.6371594 , 0.69546473, 0.88114125, 0.89836   ,\n",
       "         0.04614904, 0.6453811 , 0.72564596, 0.6938777 , 0.6920725 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04381145, 0.63350576, 0.34686512, 0.18371803, 0.77557176,\n",
       "         0.8895307 , 0.72846967, 0.6961072 , 0.88048357, 0.89369315,\n",
       "         0.0484184 , 0.5206128 , 0.7559098 , 0.69071347, 0.6904657 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03778631, 0.6511593 , 0.33767068, 0.18825415, 0.775837  ,\n",
       "         0.90397066, 0.8180845 , 0.69778275, 0.89313966, 0.9086496 ,\n",
       "         0.04183598, 0.14625156, 0.78709984, 0.69368273, 0.6903256 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00575889, 0.7202729 , 0.35447222, 0.22388893, 0.7806519 ,\n",
       "         0.9693533 , 0.5832275 , 0.6807198 , 0.9435669 , 0.98308486,\n",
       "         0.01684551, 0.41260743, 0.62412107, 0.7026211 , 0.6756031 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01386896, 0.68146974, 0.3356572 , 0.20976835, 0.78210014,\n",
       "         0.94805866, 0.5604942 , 0.6852482 , 0.89214617, 0.96274143,\n",
       "         0.02518003, 0.5485518 , 0.64866287, 0.7005461 , 0.67855877]],\n",
       "       dtype=float32),\n",
       " array([[0.02547631, 0.6703602 , 0.34990457, 0.2165225 , 0.778109  ,\n",
       "         0.927778  , 0.7783676 , 0.6886285 , 0.90303993, 0.9372497 ,\n",
       "         0.03483861, 0.27402171, 0.7681355 , 0.6905675 , 0.68052536]],\n",
       "       dtype=float32),\n",
       " array([[0.01349954, 0.6648268 , 0.37775204, 0.22918086, 0.7782919 ,\n",
       "         0.9461905 , 0.72393674, 0.6718936 , 0.8878823 , 0.9610767 ,\n",
       "         0.02683584, 0.4133007 , 0.6479618 , 0.6895236 , 0.68281436]],\n",
       "       dtype=float32),\n",
       " array([[0.01426021, 0.67925954, 0.37572694, 0.23909576, 0.7770216 ,\n",
       "         0.9462624 , 0.7200476 , 0.6695144 , 0.89696443, 0.9603294 ,\n",
       "         0.02669247, 0.38751945, 0.6748348 , 0.69119954, 0.6767573 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01214399, 0.7025871 , 0.38299474, 0.26547566, 0.77651024,\n",
       "         0.9526965 , 0.57948345, 0.66148335, 0.90743864, 0.96677476,\n",
       "         0.02430182, 0.7052923 , 0.6558273 , 0.6876638 , 0.66572237]],\n",
       "       dtype=float32),\n",
       " array([[0.0075001 , 0.74616635, 0.35125172, 0.29339394, 0.77949387,\n",
       "         0.9682929 , 0.5853121 , 0.6661336 , 0.9237704 , 0.97975177,\n",
       "         0.01864623, 0.6314028 , 0.6756997 , 0.69152844, 0.650307  ]],\n",
       "       dtype=float32),\n",
       " array([[0.00822333, 0.71328336, 0.36194426, 0.2734635 , 0.78265464,\n",
       "         0.9649727 , 0.5266967 , 0.66118085, 0.8941545 , 0.9773186 ,\n",
       "         0.01923543, 0.70686954, 0.6159726 , 0.6923124 , 0.65905   ]],\n",
       "       dtype=float32),\n",
       " array([[0.00315647, 0.7437705 , 0.40187097, 0.312759  , 0.78233737,\n",
       "         0.979984  , 0.36709216, 0.640302  , 0.93019664, 0.99037313,\n",
       "         0.01277581, 0.91775334, 0.5089947 , 0.6900756 , 0.64807504]],\n",
       "       dtype=float32),\n",
       " array([[0.00519309, 0.72450846, 0.40106648, 0.30570865, 0.78227127,\n",
       "         0.97330487, 0.49182764, 0.63793314, 0.90239793, 0.98482054,\n",
       "         0.01554744, 0.8477726 , 0.5602714 , 0.68568915, 0.6479719 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00312247, 0.73922014, 0.43447405, 0.3408806 , 0.7816521 ,\n",
       "         0.9807945 , 0.40127864, 0.6196848 , 0.9229275 , 0.9905856 ,\n",
       "         0.01209099, 0.91326416, 0.50839466, 0.68627065, 0.6402576 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00410813, 0.71232814, 0.3993688 , 0.3510523 , 0.78090316,\n",
       "         0.97958267, 0.48364702, 0.6215363 , 0.9056778 , 0.98860514,\n",
       "         0.01408911, 0.6849832 , 0.5556262 , 0.710725  , 0.6482673 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00796509, 0.7662131 , 0.38261878, 0.34584147, 0.78325224,\n",
       "         0.97399634, 0.81309205, 0.65162337, 0.9430128 , 0.9817504 ,\n",
       "         0.01569146, 0.15665443, 0.8108578 , 0.67826545, 0.6317062 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01091116, 0.730851  , 0.37915027, 0.3060969 , 0.7861583 ,\n",
       "         0.96652067, 0.80535537, 0.6546304 , 0.904517  , 0.9744557 ,\n",
       "         0.01685506, 0.09184938, 0.7763655 , 0.67687565, 0.6468818 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02069987, 0.7650534 , 0.33561447, 0.27296618, 0.7760886 ,\n",
       "         0.95303255, 0.95983297, 0.6721202 , 0.9548158 , 0.95719606,\n",
       "         0.02431956, 0.00529967, 0.9148059 , 0.6914442 , 0.63664055]],\n",
       "       dtype=float32),\n",
       " array([[0.03806772, 0.70512325, 0.33941033, 0.2820786 , 0.77647936,\n",
       "         0.92922825, 0.9554293 , 0.681064  , 0.8948612 , 0.921098  ,\n",
       "         0.03351856, 0.00482505, 0.89487076, 0.6813488 , 0.6627278 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04187134, 0.70643383, 0.33729848, 0.28289828, 0.769258  ,\n",
       "         0.92172194, 0.9503647 , 0.6750661 , 0.90510803, 0.9123968 ,\n",
       "         0.0379866 , 0.00642813, 0.8937118 , 0.6933383 , 0.6616866 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07225341, 0.6941238 , 0.3103978 , 0.23355323, 0.7700291 ,\n",
       "         0.8904845 , 0.9698723 , 0.6967301 , 0.9098131 , 0.86173785,\n",
       "         0.05008671, 0.00382196, 0.9277033 , 0.69294566, 0.6667766 ]],\n",
       "       dtype=float32),\n",
       " array([[0.10577609, 0.6616904 , 0.32269886, 0.20992827, 0.77163434,\n",
       "         0.85181046, 0.9556449 , 0.7036104 , 0.8832118 , 0.80276924,\n",
       "         0.06155863, 0.01478858, 0.9184657 , 0.6803677 , 0.6762803 ]],\n",
       "       dtype=float32),\n",
       " array([[0.10509233, 0.67960507, 0.32009268, 0.22653884, 0.7643515 ,\n",
       "         0.84998345, 0.9605798 , 0.69704926, 0.90288013, 0.8010697 ,\n",
       "         0.06744234, 0.01769765, 0.9247752 , 0.6877084 , 0.66891944]],\n",
       "       dtype=float32),\n",
       " array([[0.06796741, 0.6980455 , 0.37532115, 0.28071883, 0.7614786 ,\n",
       "         0.87786543, 0.89551914, 0.6772168 , 0.91230005, 0.8568741 ,\n",
       "         0.05780438, 0.2432861 , 0.88412535, 0.66956615, 0.6604027 ]],\n",
       "       dtype=float32),\n",
       " array([[0.10789381, 0.6788375 , 0.33260724, 0.24783184, 0.76210123,\n",
       "         0.8450772 , 0.9075813 , 0.68908125, 0.9005938 , 0.7973125 ,\n",
       "         0.07217189, 0.12042563, 0.90741825, 0.6882975 , 0.6655079 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07396664, 0.6917496 , 0.34881   , 0.26339254, 0.7668939 ,\n",
       "         0.8782358 , 0.8713925 , 0.69060946, 0.908758  , 0.8533692 ,\n",
       "         0.05729639, 0.22203757, 0.8904976 , 0.6761893 , 0.66400623]],\n",
       "       dtype=float32),\n",
       " array([[0.04663082, 0.71163946, 0.364803  , 0.29345247, 0.7666193 ,\n",
       "         0.90827185, 0.7536597 , 0.6754266 , 0.91639274, 0.9024801 ,\n",
       "         0.04405349, 0.42259327, 0.85135686, 0.68034786, 0.65662444]],\n",
       "       dtype=float32),\n",
       " array([[0.02175991, 0.703438  , 0.38460898, 0.28571773, 0.7711317 ,\n",
       "         0.93572134, 0.59287566, 0.65988743, 0.89521205, 0.945899  ,\n",
       "         0.03062169, 0.70616657, 0.7214451 , 0.6819647 , 0.6591695 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0214426 , 0.7000838 , 0.3775205 , 0.28431916, 0.77340704,\n",
       "         0.9375544 , 0.61886954, 0.663816  , 0.89203775, 0.9471406 ,\n",
       "         0.03074368, 0.67264503, 0.72755986, 0.6826434 , 0.66027606]],\n",
       "       dtype=float32),\n",
       " array([[0.00907152, 0.7284686 , 0.38486812, 0.28839746, 0.7749958 ,\n",
       "         0.96180993, 0.6100452 , 0.6509986 , 0.9086594 , 0.9747137 ,\n",
       "         0.01914382, 0.48076957, 0.6491309 , 0.6871465 , 0.6557417 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00739583, 0.7110169 , 0.38505465, 0.27294055, 0.7799471 ,\n",
       "         0.9654928 , 0.51274973, 0.6599773 , 0.91346025, 0.97890776,\n",
       "         0.01904136, 0.7776846 , 0.6016288 , 0.6881699 , 0.66250056]],\n",
       "       dtype=float32),\n",
       " array([[0.01530742, 0.7202048 , 0.3493644 , 0.2460415 , 0.779054  ,\n",
       "         0.9524121 , 0.8189133 , 0.68250644, 0.9344204 , 0.963051  ,\n",
       "         0.02474953, 0.14438011, 0.80122334, 0.6889393 , 0.66218483]],\n",
       "       dtype=float32),\n",
       " array([[0.02455308, 0.6672595 , 0.34969556, 0.2172745 , 0.77998954,\n",
       "         0.9327083 , 0.8473911 , 0.686757  , 0.89412314, 0.94046307,\n",
       "         0.03137587, 0.10010884, 0.786179  , 0.68884623, 0.6789212 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03483839, 0.6570206 , 0.33599925, 0.19089802, 0.7800564 ,\n",
       "         0.9174394 , 0.8749819 , 0.6930956 , 0.8878965 , 0.9202786 ,\n",
       "         0.03435102, 0.03882325, 0.81749237, 0.6926449 , 0.6832686 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05423633, 0.62828153, 0.33092797, 0.17687465, 0.77926147,\n",
       "         0.89179593, 0.91645896, 0.7048879 , 0.88134766, 0.88243824,\n",
       "         0.04501878, 0.02431904, 0.85139513, 0.6925405 , 0.69292885]],\n",
       "       dtype=float32),\n",
       " array([[0.07085391, 0.6234598 , 0.32305175, 0.16590375, 0.7817264 ,\n",
       "         0.87524337, 0.92996675, 0.71732706, 0.872459  , 0.8542804 ,\n",
       "         0.04897859, 0.01876922, 0.8743125 , 0.6819627 , 0.69643176]],\n",
       "       dtype=float32),\n",
       " array([[0.0467848 , 0.6359992 , 0.34655112, 0.18436399, 0.77342004,\n",
       "         0.89241385, 0.8636682 , 0.6922518 , 0.8934495 , 0.89160705,\n",
       "         0.04713124, 0.14704877, 0.8152283 , 0.6951076 , 0.68678606]],\n",
       "       dtype=float32),\n",
       " array([[0.07133368, 0.627769  , 0.32427636, 0.16304174, 0.776322  ,\n",
       "         0.8661649 , 0.8925386 , 0.70690006, 0.88507855, 0.84961814,\n",
       "         0.05512132, 0.09501389, 0.8566029 , 0.69272214, 0.6888828 ]],\n",
       "       dtype=float32),\n",
       " array([[0.07458607, 0.62726283, 0.33455613, 0.17931862, 0.7744113 ,\n",
       "         0.8624445 , 0.86038953, 0.6994435 , 0.8719419 , 0.84297085,\n",
       "         0.05658762, 0.16626361, 0.8444176 , 0.6878004 , 0.68758446]],\n",
       "       dtype=float32),\n",
       " array([[0.08226183, 0.67971766, 0.32997826, 0.19325605, 0.77066237,\n",
       "         0.8625736 , 0.9283527 , 0.7033946 , 0.915868  , 0.8362355 ,\n",
       "         0.05705767, 0.05618186, 0.90430254, 0.6806888 , 0.67280966]],\n",
       "       dtype=float32),\n",
       " array([[0.07859675, 0.6605015 , 0.3366025 , 0.20114848, 0.7708007 ,\n",
       "         0.86144763, 0.86476654, 0.6962415 , 0.88591146, 0.8377858 ,\n",
       "         0.05586474, 0.12387387, 0.8631715 , 0.68416965, 0.67864174]],\n",
       "       dtype=float32),\n",
       " array([[0.05966256, 0.69165426, 0.34539133, 0.23346442, 0.7670155 ,\n",
       "         0.8849955 , 0.8684397 , 0.6881325 , 0.9056979 , 0.87230146,\n",
       "         0.04891925, 0.11301654, 0.8642667 , 0.6833303 , 0.66996056]],\n",
       "       dtype=float32),\n",
       " array([[0.07024086, 0.67476326, 0.3410154 , 0.2337313 , 0.7678552 ,\n",
       "         0.87430733, 0.8445578 , 0.6902078 , 0.8868909 , 0.853801  ,\n",
       "         0.05329174, 0.14067416, 0.8580363 , 0.68568146, 0.6743889 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04189987, 0.66948014, 0.341205  , 0.21736826, 0.7720922 ,\n",
       "         0.9036788 , 0.8252812 , 0.6908046 , 0.8890934 , 0.9029772 ,\n",
       "         0.04145242, 0.10897683, 0.8096005 , 0.69181776, 0.68132424]],\n",
       "       dtype=float32),\n",
       " array([[0.04813823, 0.6844587 , 0.34943053, 0.22423357, 0.7687453 ,\n",
       "         0.89661133, 0.86193955, 0.6871642 , 0.9058932 , 0.8920958 ,\n",
       "         0.04366805, 0.08150183, 0.8429988 , 0.6876786 , 0.675593  ]],\n",
       "       dtype=float32),\n",
       " array([[0.04326557, 0.6752317 , 0.34971738, 0.22185788, 0.76976657,\n",
       "         0.9003909 , 0.85775596, 0.68667024, 0.8930194 , 0.89878273,\n",
       "         0.04234801, 0.09244987, 0.8196954 , 0.6879784 , 0.6788139 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03676017, 0.67732775, 0.35990387, 0.22552936, 0.76990545,\n",
       "         0.907592  , 0.81980646, 0.6822197 , 0.8988884 , 0.9112528 ,\n",
       "         0.04009216, 0.16301633, 0.7968666 , 0.6869319 , 0.67789304]],\n",
       "       dtype=float32),\n",
       " array([[0.02975137, 0.6771377 , 0.35459402, 0.2098119 , 0.7727107 ,\n",
       "         0.9166095 , 0.7961686 , 0.68749094, 0.9087309 , 0.925756  ,\n",
       "         0.03736767, 0.2503804 , 0.77785844, 0.6898815 , 0.67888534]],\n",
       "       dtype=float32),\n",
       " array([[0.04110731, 0.6820108 , 0.3542581 , 0.22792132, 0.77015454,\n",
       "         0.90437686, 0.8115441 , 0.6842093 , 0.9031326 , 0.9049877 ,\n",
       "         0.04167939, 0.17169605, 0.8150205 , 0.6886213 , 0.6751297 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04504902, 0.6734513 , 0.34706023, 0.20175253, 0.7722514 ,\n",
       "         0.89670175, 0.83958066, 0.69121826, 0.9062415 , 0.8965933 ,\n",
       "         0.04359065, 0.14047532, 0.82594883, 0.6880382 , 0.67891353]],\n",
       "       dtype=float32),\n",
       " array([[0.06293952, 0.6590478 , 0.34133416, 0.18844536, 0.7719496 ,\n",
       "         0.87262964, 0.84678125, 0.692179  , 0.8872743 , 0.86148673,\n",
       "         0.04971703, 0.11190457, 0.8349143 , 0.68872774, 0.6813725 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04882044, 0.643796  , 0.3401943 , 0.17013344, 0.7760003 ,\n",
       "         0.88555056, 0.82637024, 0.69696516, 0.8841195 , 0.8854706 ,\n",
       "         0.04504505, 0.15161446, 0.79895973, 0.68971914, 0.688842  ]],\n",
       "       dtype=float32),\n",
       " array([[0.0431191 , 0.65416   , 0.33917984, 0.1765627 , 0.77609265,\n",
       "         0.8954848 , 0.8303562 , 0.6986032 , 0.89805   , 0.8982328 ,\n",
       "         0.04318573, 0.1488704 , 0.80536735, 0.6897289 , 0.6873214 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03384329, 0.6633079 , 0.33697575, 0.18915674, 0.77608204,\n",
       "         0.9095521 , 0.7848221 , 0.6948359 , 0.89666945, 0.91704893,\n",
       "         0.03930964, 0.21540228, 0.7757589 , 0.6926889 , 0.68469954]],\n",
       "       dtype=float32),\n",
       " array([[0.03789815, 0.677599  , 0.32758576, 0.17646658, 0.77716154,\n",
       "         0.90647906, 0.8478749 , 0.70233417, 0.9157421 , 0.91167504,\n",
       "         0.03949202, 0.1164195 , 0.8271492 , 0.6890204 , 0.6814452 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02941466, 0.69029623, 0.34341648, 0.20842907, 0.77426887,\n",
       "         0.9198408 , 0.8090385 , 0.6899961 , 0.916168  , 0.92830646,\n",
       "         0.03596589, 0.17438927, 0.79912645, 0.68848187, 0.6767145 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02658024, 0.6803305 , 0.34300488, 0.21821825, 0.7737638 ,\n",
       "         0.92281336, 0.76583266, 0.6832645 , 0.8975316 , 0.9324321 ,\n",
       "         0.03615933, 0.2630525 , 0.7559648 , 0.6941407 , 0.6769413 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01855794, 0.6961102 , 0.3385376 , 0.22907236, 0.77612025,\n",
       "         0.9394907 , 0.7518632 , 0.68642795, 0.91245157, 0.9516138 ,\n",
       "         0.03095525, 0.28956884, 0.7453348 , 0.694598  , 0.67451024]],\n",
       "       dtype=float32),\n",
       " array([[0.01860869, 0.7069389 , 0.34815106, 0.25056478, 0.7728426 ,\n",
       "         0.94048977, 0.7359912 , 0.67408717, 0.91307986, 0.9519454 ,\n",
       "         0.03020885, 0.2708035 , 0.7452408 , 0.69819796, 0.6675294 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02676938, 0.7050034 , 0.34853274, 0.24104752, 0.77346116,\n",
       "         0.92892987, 0.81108385, 0.67994964, 0.91674316, 0.9360591 ,\n",
       "         0.03364447, 0.14062113, 0.80647224, 0.6913462 , 0.667772  ]],\n",
       "       dtype=float32),\n",
       " array([[0.03190544, 0.6804941 , 0.36006406, 0.23098738, 0.7747565 ,\n",
       "         0.91823214, 0.78669006, 0.6784278 , 0.8951155 , 0.9235761 ,\n",
       "         0.03626643, 0.1984794 , 0.7854775 , 0.68668973, 0.6741148 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04609544, 0.6848788 , 0.36120126, 0.22852951, 0.7695864 ,\n",
       "         0.9015085 , 0.88082415, 0.67742974, 0.91539556, 0.8979516 ,\n",
       "         0.0426623 , 0.06261105, 0.8533751 , 0.6895379 , 0.6719175 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04790976, 0.6523076 , 0.35244995, 0.2113907 , 0.7728945 ,\n",
       "         0.8952117 , 0.8504176 , 0.68426406, 0.8893143 , 0.89113337,\n",
       "         0.04561096, 0.10129929, 0.81963396, 0.6931354 , 0.6831008 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03985287, 0.6735815 , 0.34485453, 0.2222335 , 0.7716027 ,\n",
       "         0.9073263 , 0.84063077, 0.68366116, 0.90457976, 0.9079763 ,\n",
       "         0.0425309 , 0.10599741, 0.82045543, 0.69611573, 0.6779641 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03868775, 0.67699665, 0.34048858, 0.21956235, 0.7719479 ,\n",
       "         0.9077748 , 0.83551306, 0.6838194 , 0.8985506 , 0.9092854 ,\n",
       "         0.04177977, 0.12289927, 0.8121863 , 0.69518256, 0.6763766 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03601561, 0.6817305 , 0.34518072, 0.22257315, 0.7726407 ,\n",
       "         0.91073185, 0.81928927, 0.68429196, 0.9000332 , 0.91424584,\n",
       "         0.04064735, 0.18228741, 0.80385286, 0.69030064, 0.6750629 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02170436, 0.6882166 , 0.3505146 , 0.22289419, 0.77556384,\n",
       "         0.9321761 , 0.7653437 , 0.68308747, 0.90953207, 0.9439587 ,\n",
       "         0.03304244, 0.32036644, 0.75132716, 0.69195026, 0.674653  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02912219, 0.67854685, 0.35545865, 0.22054525, 0.77690905,\n",
       "         0.9202395 , 0.7835067 , 0.6876568 , 0.8995798 , 0.9282432 ,\n",
       "         0.0370367 , 0.33715877, 0.77622265, 0.68297374, 0.6765035 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02458374, 0.6929395 , 0.35737938, 0.2373622 , 0.77651846,\n",
       "         0.9294331 , 0.7593339 , 0.6834414 , 0.903882  , 0.9388184 ,\n",
       "         0.03352491, 0.35997728, 0.7677426 , 0.6824741 , 0.6718408 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02068166, 0.70422524, 0.36529768, 0.25056973, 0.7761381 ,\n",
       "         0.93716466, 0.73805875, 0.6781491 , 0.9124308 , 0.94796044,\n",
       "         0.03073272, 0.42338026, 0.7602942 , 0.6816497 , 0.66724205]],\n",
       "       dtype=float32),\n",
       " array([[0.0267767 , 0.70205593, 0.3521513 , 0.2373163 , 0.77722585,\n",
       "         0.9296555 , 0.79326826, 0.6859755 , 0.9159296 , 0.93705434,\n",
       "         0.03325831, 0.24928424, 0.8074105 , 0.681894  , 0.6686658 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03369933, 0.6719868 , 0.35905606, 0.22059073, 0.77824455,\n",
       "         0.9171539 , 0.80263245, 0.6851049 , 0.8929613 , 0.9214499 ,\n",
       "         0.03609288, 0.2051685 , 0.798319  , 0.6798806 , 0.67793435]],\n",
       "       dtype=float32),\n",
       " array([[0.02930018, 0.67993176, 0.36788425, 0.22427033, 0.77971613,\n",
       "         0.924238  , 0.8116191 , 0.6869554 , 0.90118223, 0.93062127,\n",
       "         0.03289225, 0.17801462, 0.7983288 , 0.67338604, 0.6778196 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02017027, 0.68824327, 0.37026942, 0.25005654, 0.7768225 ,\n",
       "         0.93852043, 0.7572995 , 0.674975  , 0.9010805 , 0.9489363 ,\n",
       "         0.02949517, 0.27402222, 0.74903387, 0.681645  , 0.6746914 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01960108, 0.70146394, 0.3619969 , 0.2543208 , 0.77713543,\n",
       "         0.9416242 , 0.7972393 , 0.6792649 , 0.9118036 , 0.9512931 ,\n",
       "         0.02874579, 0.18334256, 0.7777359 , 0.68073124, 0.6717979 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02605186, 0.6845329 , 0.37461832, 0.2560874 , 0.7750637 ,\n",
       "         0.92900926, 0.7997609 , 0.6744334 , 0.8971516 , 0.93606853,\n",
       "         0.03358871, 0.21735   , 0.7784728 , 0.6787667 , 0.6740753 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02043428, 0.7009327 , 0.3648243 , 0.2494948 , 0.77647954,\n",
       "         0.9391242 , 0.7932267 , 0.6788569 , 0.9180623 , 0.94924283,\n",
       "         0.03031141, 0.24158837, 0.78071225, 0.6826795 , 0.67013216]],\n",
       "       dtype=float32),\n",
       " array([[0.02908173, 0.6822704 , 0.35944274, 0.23873259, 0.7749321 ,\n",
       "         0.9239455 , 0.8069071 , 0.6770648 , 0.8996603 , 0.93007916,\n",
       "         0.03571566, 0.19611989, 0.7903242 , 0.6869505 , 0.6731492 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02040852, 0.71507895, 0.37311384, 0.2663967 , 0.77487487,\n",
       "         0.9398272 , 0.79449815, 0.67227155, 0.9164425 , 0.9493637 ,\n",
       "         0.02914113, 0.25437498, 0.78519446, 0.67680675, 0.66315186]],\n",
       "       dtype=float32),\n",
       " array([[0.02478475, 0.69452757, 0.3534223 , 0.23567526, 0.77700967,\n",
       "         0.9322619 , 0.8076823 , 0.68006843, 0.90799284, 0.94030833,\n",
       "         0.03194822, 0.17760284, 0.7924517 , 0.68737   , 0.669867  ]],\n",
       "       dtype=float32),\n",
       " array([[0.02416185, 0.6856471 , 0.35195205, 0.23604934, 0.7776027 ,\n",
       "         0.93287706, 0.77373856, 0.68006593, 0.90259665, 0.9414473 ,\n",
       "         0.03260436, 0.26736555, 0.7747402 , 0.69061875, 0.6716141 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0165002 , 0.70170933, 0.35283542, 0.23755698, 0.78214175,\n",
       "         0.9466004 , 0.7268271 , 0.6847433 , 0.90919477, 0.9582612 ,\n",
       "         0.02668044, 0.40479422, 0.7448073 , 0.68214947, 0.6688299 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00529985, 0.7421558 , 0.35117286, 0.25207737, 0.78409785,\n",
       "         0.971882  , 0.54791045, 0.6737457 , 0.93435144, 0.9845179 ,\n",
       "         0.01690672, 0.8062188 , 0.61944824, 0.69057566, 0.6551651 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00786819, 0.72131044, 0.3455218 , 0.24863103, 0.78448683,\n",
       "         0.9649121 , 0.5807354 , 0.67501885, 0.9135078 , 0.97804105,\n",
       "         0.02007546, 0.74156004, 0.6415314 , 0.69185704, 0.6596501 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01527255, 0.7089664 , 0.3508006 , 0.24171688, 0.78174996,\n",
       "         0.9507889 , 0.76771355, 0.67804414, 0.91825795, 0.9620225 ,\n",
       "         0.02546283, 0.291594  , 0.7636319 , 0.6884265 , 0.6632005 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02641631, 0.6967015 , 0.37064096, 0.2626824 , 0.7759133 ,\n",
       "         0.9330024 , 0.8126725 , 0.66798174, 0.90452397, 0.93867606,\n",
       "         0.03177125, 0.18614042, 0.8042462 , 0.6851598 , 0.6628634 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02454498, 0.6877789 , 0.36320817, 0.2526951 , 0.7778159 ,\n",
       "         0.93521374, 0.80182475, 0.6732034 , 0.9000827 , 0.94202834,\n",
       "         0.03125353, 0.18908654, 0.78926826, 0.6877471 , 0.6678896 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04384425, 0.7045552 , 0.3630604 , 0.24280591, 0.7724563 ,\n",
       "         0.91448975, 0.93030214, 0.6782713 , 0.9293288 , 0.9093076 ,\n",
       "         0.03741229, 0.02124787, 0.8941979 , 0.6830717 , 0.6630616 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04354074, 0.69563085, 0.35796666, 0.24914859, 0.7716981 ,\n",
       "         0.9131415 , 0.9128354 , 0.67506087, 0.90716654, 0.9071541 ,\n",
       "         0.03688697, 0.01978916, 0.8707892 , 0.6875481 , 0.6668796 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04385776, 0.6883133 , 0.347005  , 0.23000121, 0.77310824,\n",
       "         0.9092162 , 0.90513486, 0.6836114 , 0.90532905, 0.9044887 ,\n",
       "         0.03910076, 0.031074  , 0.8618695 , 0.6891574 , 0.6708472 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04680689, 0.68803245, 0.34372768, 0.21527877, 0.77273154,\n",
       "         0.8997955 , 0.87497514, 0.6825479 , 0.8952652 , 0.8955071 ,\n",
       "         0.04099807, 0.07104289, 0.84288496, 0.6879389 , 0.66889995]],\n",
       "       dtype=float32),\n",
       " array([[0.04269933, 0.67841756, 0.337394  , 0.20832174, 0.7748784 ,\n",
       "         0.9043744 , 0.8918173 , 0.69457877, 0.9046692 , 0.9026975 ,\n",
       "         0.04286923, 0.07991641, 0.8450435 , 0.6877876 , 0.67605007]],\n",
       "       dtype=float32),\n",
       " array([[0.03552231, 0.68186736, 0.3329776 , 0.21059948, 0.7761156 ,\n",
       "         0.9138618 , 0.8591986 , 0.6959243 , 0.9060756 , 0.9168529 ,\n",
       "         0.04003536, 0.12992203, 0.82488805, 0.6896555 , 0.67593277]],\n",
       "       dtype=float32),\n",
       " array([[0.03763072, 0.6739702 , 0.34473443, 0.21672276, 0.7752378 ,\n",
       "         0.9083147 , 0.79607856, 0.6896528 , 0.8948152 , 0.91130567,\n",
       "         0.04195489, 0.2994845 , 0.79851943, 0.68766904, 0.675679  ]],\n",
       "       dtype=float32),\n",
       " array([[0.03059176, 0.70016366, 0.34568876, 0.24560243, 0.774295  ,\n",
       "         0.92289305, 0.77505285, 0.6863279 , 0.9112268 , 0.92826   ,\n",
       "         0.03804651, 0.3719186 , 0.80705756, 0.6851239 , 0.6666615 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02835159, 0.69760257, 0.35045186, 0.2513599 , 0.77461505,\n",
       "         0.9259141 , 0.76801586, 0.68365407, 0.907704  , 0.9323027 ,\n",
       "         0.03723986, 0.39845523, 0.7945244 , 0.6845725 , 0.6672247 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03389878, 0.69565076, 0.34330615, 0.23407042, 0.7755492 ,\n",
       "         0.9200508 , 0.831748  , 0.69054615, 0.91840535, 0.9232456 ,\n",
       "         0.03854277, 0.17210488, 0.83497214, 0.6860616 , 0.67069507]],\n",
       "       dtype=float32),\n",
       " array([[0.03603536, 0.67972076, 0.35792544, 0.23854192, 0.7740196 ,\n",
       "         0.9139768 , 0.80040616, 0.68112516, 0.8975335 , 0.91629446,\n",
       "         0.03944402, 0.22474068, 0.80514497, 0.68509334, 0.67338   ]],\n",
       "       dtype=float32),\n",
       " array([[0.02241413, 0.70587754, 0.3554459 , 0.2520631 , 0.7750141 ,\n",
       "         0.93587315, 0.7589765 , 0.67953163, 0.9167562 , 0.94526374,\n",
       "         0.03185144, 0.3118764 , 0.782654  , 0.68553936, 0.6671433 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01363689, 0.7098186 , 0.35871837, 0.25557253, 0.7767937 ,\n",
       "         0.9506798 , 0.6983366 , 0.6741378 , 0.9148722 , 0.96362156,\n",
       "         0.0258446 , 0.41822362, 0.7138202 , 0.6889479 , 0.66741246]],\n",
       "       dtype=float32),\n",
       " array([[0.01865713, 0.6968182 , 0.35397956, 0.24354157, 0.77840424,\n",
       "         0.94307786, 0.77074844, 0.67975235, 0.9073158 , 0.9534949 ,\n",
       "         0.0278817 , 0.21667653, 0.7630803 , 0.68437445, 0.67249334]],\n",
       "       dtype=float32),\n",
       " array([[0.02759985, 0.69406384, 0.35920477, 0.24728437, 0.77296937,\n",
       "         0.9292929 , 0.8528435 , 0.6763182 , 0.9181466 , 0.93505716,\n",
       "         0.03420405, 0.08455419, 0.8197242 , 0.69268394, 0.67024463]],\n",
       "       dtype=float32),\n",
       " array([[0.02194397, 0.69753605, 0.35543647, 0.2427224 , 0.77449256,\n",
       "         0.9364376 , 0.8066973 , 0.674507  , 0.91341454, 0.94583565,\n",
       "         0.03098938, 0.16108349, 0.78204286, 0.69398504, 0.66840667]],\n",
       "       dtype=float32),\n",
       " array([[0.00997272, 0.72546387, 0.3520956 , 0.2657222 , 0.7761725 ,\n",
       "         0.959496  , 0.6947217 , 0.6691035 , 0.9244079 , 0.972516  ,\n",
       "         0.02316312, 0.4643576 , 0.69663405, 0.69739884, 0.6596967 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0101793 , 0.71069145, 0.34653684, 0.2522443 , 0.78122413,\n",
       "         0.9588709 , 0.6460709 , 0.6758334 , 0.9060407 , 0.97195697,\n",
       "         0.02289039, 0.5802174 , 0.66705704, 0.6938133 , 0.6643831 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00664701, 0.7271615 , 0.35527614, 0.25587866, 0.78349847,\n",
       "         0.9678352 , 0.53367084, 0.67300636, 0.9232676 , 0.9809738 ,\n",
       "         0.01888974, 0.79882175, 0.61981696, 0.69142014, 0.65885735]],\n",
       "       dtype=float32),\n",
       " array([[0.00339223, 0.7579127 , 0.36470398, 0.2706004 , 0.78612363,\n",
       "         0.9787602 , 0.4152877 , 0.66104937, 0.93572354, 0.98973113,\n",
       "         0.01316744, 0.9150748 , 0.55013335, 0.6880667 , 0.64494526]],\n",
       "       dtype=float32),\n",
       " array([[0.00655168, 0.732483  , 0.36549327, 0.27337945, 0.78411454,\n",
       "         0.96989506, 0.5654401 , 0.6605185 , 0.919079  , 0.9818559 ,\n",
       "         0.01755392, 0.74858916, 0.63752264, 0.69018227, 0.64986265]],\n",
       "       dtype=float32),\n",
       " array([[0.01213334, 0.71874624, 0.36437082, 0.27252394, 0.77817154,\n",
       "         0.95767754, 0.73133606, 0.6569455 , 0.921518  , 0.9691654 ,\n",
       "         0.02368046, 0.40648177, 0.7380566 , 0.6962601 , 0.65200436]],\n",
       "       dtype=float32),\n",
       " array([[0.00920492, 0.7265551 , 0.3803106 , 0.29988876, 0.77802527,\n",
       "         0.96457213, 0.6763262 , 0.64883745, 0.9210868 , 0.9758512 ,\n",
       "         0.02031731, 0.47784057, 0.70127654, 0.69275045, 0.6498936 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00925151, 0.7253869 , 0.38398096, 0.29512852, 0.7816909 ,\n",
       "         0.96500754, 0.6723321 , 0.655401  , 0.915579  , 0.9760048 ,\n",
       "         0.01917055, 0.45614713, 0.7027828 , 0.6828693 , 0.6523333 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01507054, 0.7289201 , 0.36262196, 0.28607196, 0.7802634 ,\n",
       "         0.9566392 , 0.84324485, 0.67044544, 0.9279453 , 0.9648655 ,\n",
       "         0.0233617 , 0.10394692, 0.8166874 , 0.6839671 , 0.653358  ]],\n",
       "       dtype=float32),\n",
       " array([[0.01733072, 0.71434677, 0.36073786, 0.29064283, 0.7775306 ,\n",
       "         0.951661  , 0.8442705 , 0.66369814, 0.90509474, 0.95879227,\n",
       "         0.02507467, 0.07756753, 0.7986022 , 0.68839425, 0.6572911 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0114779 , 0.73958105, 0.3756604 , 0.31996095, 0.7732102 ,\n",
       "         0.96155655, 0.80591863, 0.6508269 , 0.92749316, 0.9711802 ,\n",
       "         0.02177027, 0.15793863, 0.7741495 , 0.6889669 , 0.64817345]],\n",
       "       dtype=float32),\n",
       " array([[0.01573775, 0.7237029 , 0.39099687, 0.3288308 , 0.77222455,\n",
       "         0.9523666 , 0.80089855, 0.64994633, 0.90900606, 0.9608726 ,\n",
       "         0.02570867, 0.23449273, 0.77371794, 0.67816067, 0.6521077 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01251854, 0.7370734 , 0.3731996 , 0.319642  , 0.77469385,\n",
       "         0.95905507, 0.8106923 , 0.66108173, 0.9236696 , 0.96844894,\n",
       "         0.0237533 , 0.25212747, 0.7797368 , 0.6799577 , 0.64946294]],\n",
       "       dtype=float32),\n",
       " array([[0.01661637, 0.72182137, 0.37059125, 0.306583  , 0.7753458 ,\n",
       "         0.95133173, 0.81220615, 0.6607062 , 0.90608233, 0.9593474 ,\n",
       "         0.02611779, 0.20331429, 0.78372365, 0.6816985 , 0.6525459 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03914532, 0.71235895, 0.37237024, 0.2844263 , 0.77165234,\n",
       "         0.9218184 , 0.8914307 , 0.66796905, 0.91806555, 0.91792256,\n",
       "         0.03685689, 0.07368679, 0.8755665 , 0.67782116, 0.6535895 ]],\n",
       "       dtype=float32),\n",
       " array([[0.09018639, 0.68800974, 0.36552313, 0.2597419 , 0.7692725 ,\n",
       "         0.8744388 , 0.9433163 , 0.6775615 , 0.90576184, 0.83580804,\n",
       "         0.05230008, 0.02112086, 0.92304003, 0.6728659 , 0.66004896]],\n",
       "       dtype=float32),\n",
       " array([[0.08496037, 0.6745125 , 0.3623908 , 0.25107038, 0.7699132 ,\n",
       "         0.8751092 , 0.9399614 , 0.6810593 , 0.8956551 , 0.8396491 ,\n",
       "         0.05202037, 0.01889208, 0.9114127 , 0.67470676, 0.66826284]],\n",
       "       dtype=float32),\n",
       " array([[0.05130113, 0.68665296, 0.3623824 , 0.2744743 , 0.7663406 ,\n",
       "         0.9026485 , 0.8878062 , 0.66904914, 0.89987415, 0.891049  ,\n",
       "         0.04502591, 0.05062757, 0.8638343 , 0.6907616 , 0.6651648 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06000756, 0.6938411 , 0.35265112, 0.25088754, 0.7694933 ,\n",
       "         0.8960003 , 0.9209182 , 0.685284  , 0.9156132 , 0.8792842 ,\n",
       "         0.04637337, 0.03062862, 0.8971703 , 0.6823794 , 0.66608876]],\n",
       "       dtype=float32),\n",
       " array([[0.04372992, 0.6913615 , 0.35273623, 0.24100697, 0.774098  ,\n",
       "         0.90972996, 0.8869226 , 0.6894187 , 0.90305656, 0.90471333,\n",
       "         0.0397798 , 0.07250674, 0.8599844 , 0.67531466, 0.66952205]],\n",
       "       dtype=float32),\n",
       " array([[0.02806157, 0.70093745, 0.34603408, 0.2509213 , 0.7700873 ,\n",
       "         0.9278764 , 0.8395066 , 0.6751035 , 0.91120064, 0.93329805,\n",
       "         0.03527216, 0.12234361, 0.8134495 , 0.6954053 , 0.66459876]],\n",
       "       dtype=float32),\n",
       " array([[0.01260399, 0.7288136 , 0.35390353, 0.27617654, 0.7725874 ,\n",
       "         0.9543825 , 0.72843426, 0.6693419 , 0.92711234, 0.9665962 ,\n",
       "         0.02595177, 0.44521758, 0.7378264 , 0.6944584 , 0.65528226]],\n",
       "       dtype=float32),\n",
       " array([[0.01303156, 0.71785086, 0.36705512, 0.2835905 , 0.77682424,\n",
       "         0.9532335 , 0.6611172 , 0.67025644, 0.90391326, 0.9652461 ,\n",
       "         0.02533488, 0.63356304, 0.7017714 , 0.68117535, 0.6579905 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01012013, 0.73620033, 0.36977044, 0.28472486, 0.77648914,\n",
       "         0.96018934, 0.619555  , 0.66356677, 0.9248482 , 0.97290367,\n",
       "         0.02210669, 0.7047823 , 0.6976005 , 0.68495506, 0.6497146 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01065334, 0.7324796 , 0.37306634, 0.28054178, 0.77826893,\n",
       "         0.95962733, 0.59483176, 0.6624024 , 0.9219815 , 0.97217   ,\n",
       "         0.02172266, 0.73832166, 0.6999501 , 0.6825779 , 0.6490545 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01498705, 0.7089014 , 0.37350887, 0.27058902, 0.7785312 ,\n",
       "         0.95093226, 0.64432967, 0.66254365, 0.9047438 , 0.9624112 ,\n",
       "         0.02492935, 0.6051504 , 0.71967405, 0.6849508 , 0.655501  ]],\n",
       "       dtype=float32),\n",
       " array([[0.0129321 , 0.71094406, 0.36443433, 0.2612593 , 0.7763391 ,\n",
       "         0.95449954, 0.6668055 , 0.65636414, 0.9157267 , 0.9668796 ,\n",
       "         0.02419497, 0.5280697 , 0.7139884 , 0.69887394, 0.6533285 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00870921, 0.7122812 , 0.3586837 , 0.25181207, 0.77930635,\n",
       "         0.9640209 , 0.62026304, 0.6551469 , 0.91805136, 0.97670335,\n",
       "         0.0197882 , 0.52195114, 0.6647127 , 0.70658886, 0.65393513]],\n",
       "       dtype=float32),\n",
       " array([[0.00700514, 0.72589725, 0.37968984, 0.27785647, 0.7789532 ,\n",
       "         0.96892065, 0.60788405, 0.6461324 , 0.9199978 , 0.98087823,\n",
       "         0.01712846, 0.55543697, 0.6476116 , 0.69814026, 0.6485362 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00670194, 0.7363875 , 0.39121455, 0.30157983, 0.7789167 ,\n",
       "         0.97084415, 0.6462064 , 0.64371884, 0.92220986, 0.9819031 ,\n",
       "         0.01622385, 0.49500534, 0.6676791 , 0.6896347 , 0.6446728 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00454987, 0.7451284 , 0.39933217, 0.30202076, 0.77917635,\n",
       "         0.97634447, 0.61090326, 0.6346846 , 0.92969334, 0.9870122 ,\n",
       "         0.01372493, 0.60798424, 0.6214304 , 0.6917487 , 0.639481  ]],\n",
       "       dtype=float32),\n",
       " array([[0.00454133, 0.7450887 , 0.4071658 , 0.31626773, 0.7792017 ,\n",
       "         0.97666866, 0.583744  , 0.63034475, 0.92716616, 0.98711467,\n",
       "         0.01375086, 0.67369825, 0.6151779 , 0.68918204, 0.6373826 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00939567, 0.7315635 , 0.38104877, 0.29603308, 0.78032315,\n",
       "         0.96647793, 0.7686361 , 0.65143245, 0.924897  , 0.9765633 ,\n",
       "         0.01885781, 0.29780075, 0.75044805, 0.6869546 , 0.64316845]],\n",
       "       dtype=float32),\n",
       " array([[0.0156086 , 0.72541255, 0.36765814, 0.27875084, 0.7800014 ,\n",
       "         0.95596355, 0.8365748 , 0.66012186, 0.9199402 , 0.9641008 ,\n",
       "         0.02254258, 0.14600188, 0.8120578 , 0.68507123, 0.6444657 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0154145 , 0.72532046, 0.35392922, 0.2575372 , 0.78143495,\n",
       "         0.95628506, 0.8531157 , 0.66966057, 0.92726874, 0.96483207,\n",
       "         0.02228602, 0.11131848, 0.82387704, 0.6868968 , 0.64750063]],\n",
       "       dtype=float32),\n",
       " array([[0.0220576 , 0.70906043, 0.3537174 , 0.25731164, 0.77942264,\n",
       "         0.9452057 , 0.8640932 , 0.67052376, 0.90937954, 0.9509088 ,\n",
       "         0.02634108, 0.08609588, 0.8319675 , 0.6863964 , 0.6527862 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02747557, 0.68789554, 0.33817056, 0.23611227, 0.78149676,\n",
       "         0.9377287 , 0.8904021 , 0.6842768 , 0.90049076, 0.9404227 ,\n",
       "         0.02988693, 0.0537513 , 0.84660804, 0.68895775, 0.6625967 ]],\n",
       "       dtype=float32),\n",
       " array([[0.03752574, 0.6942027 , 0.3415489 , 0.2373283 , 0.7763601 ,\n",
       "         0.9242315 , 0.9212662 , 0.68354154, 0.9117475 , 0.9215269 ,\n",
       "         0.03528031, 0.03442422, 0.8785995 , 0.68830913, 0.6600286 ]],\n",
       "       dtype=float32),\n",
       " array([[0.02610967, 0.7100918 , 0.3569765 , 0.272692  , 0.7718102 ,\n",
       "         0.9373271 , 0.87776953, 0.6702016 , 0.9201605 , 0.94140893,\n",
       "         0.03192664, 0.09624055, 0.8449659 , 0.6911981 , 0.65413475]],\n",
       "       dtype=float32),\n",
       " array([[0.02441387, 0.73099667, 0.36030322, 0.2918781 , 0.76961654,\n",
       "         0.9392768 , 0.8691694 , 0.66570854, 0.9207304 , 0.9440987 ,\n",
       "         0.03086093, 0.14395268, 0.8424207 , 0.684269  , 0.6451116 ]],\n",
       "       dtype=float32),\n",
       " array([[0.00989448, 0.7565136 , 0.3735694 , 0.31786945, 0.7717634 ,\n",
       "         0.96341383, 0.74423563, 0.6569964 , 0.93811476, 0.97435975,\n",
       "         0.02176451, 0.5323216 , 0.759258  , 0.6839912 , 0.6370109 ]],\n",
       "       dtype=float32),\n",
       " array([[0.01357447, 0.73100215, 0.35338435, 0.2975755 , 0.7733125 ,\n",
       "         0.9553964 , 0.6872681 , 0.65874934, 0.9114228 , 0.9658585 ,\n",
       "         0.02530485, 0.5632503 , 0.7392998 , 0.69513786, 0.64262724]],\n",
       "       dtype=float32),\n",
       " array([[0.02575879, 0.7126997 , 0.3529252 , 0.28837702, 0.7739289 ,\n",
       "         0.9381879 , 0.7936263 , 0.66877216, 0.9040264 , 0.94227797,\n",
       "         0.03222319, 0.30064055, 0.81787556, 0.6882694 , 0.6484333 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04906325, 0.7173114 , 0.3586422 , 0.2630925 , 0.77404815,\n",
       "         0.9137084 , 0.917103  , 0.68546015, 0.92594385, 0.9038315 ,\n",
       "         0.03904931, 0.06080401, 0.9063262 , 0.6685928 , 0.6513454 ]],\n",
       "       dtype=float32),\n",
       " array([[0.05566482, 0.688236  , 0.3601161 , 0.24926817, 0.77032626,\n",
       "         0.9005854 , 0.91022867, 0.67692655, 0.90432966, 0.8868621 ,\n",
       "         0.04249004, 0.03889643, 0.8844173 , 0.68186873, 0.6620796 ]],\n",
       "       dtype=float32),\n",
       " array([[0.0705193 , 0.6681493 , 0.33741283, 0.21195039, 0.7728815 ,\n",
       "         0.8839802 , 0.9302742 , 0.6950401 , 0.9023648 , 0.86162186,\n",
       "         0.04868552, 0.02450021, 0.89856035, 0.68619955, 0.67153275]],\n",
       "       dtype=float32),\n",
       " array([[0.03966675, 0.68673444, 0.33415046, 0.21611762, 0.7743279 ,\n",
       "         0.9178392 , 0.9105675 , 0.6954534 , 0.9219905 , 0.9157346 ,\n",
       "         0.03689882, 0.0229995 , 0.87539834, 0.69288164, 0.671883  ]],\n",
       "       dtype=float32),\n",
       " array([[0.05752411, 0.66840297, 0.31928226, 0.19747132, 0.77363074,\n",
       "         0.89454335, 0.9289587 , 0.7023375 , 0.9024815 , 0.881264  ,\n",
       "         0.04508903, 0.01815723, 0.8857667 , 0.692853  , 0.6767888 ]],\n",
       "       dtype=float32),\n",
       " array([[0.04793849, 0.66969204, 0.3353422 , 0.20671727, 0.772417  ,\n",
       "         0.9005534 , 0.89247054, 0.69441664, 0.9007463 , 0.89488864,\n",
       "         0.04300971, 0.0505607 , 0.8543585 , 0.69084257, 0.6759575 ]],\n",
       "       dtype=float32),\n",
       " array([[0.06380986, 0.6607484 , 0.35104993, 0.20497106, 0.76795644,\n",
       "         0.87644273, 0.9195794 , 0.6919435 , 0.9002223 , 0.8613302 ,\n",
       "         0.0521942 , 0.05579153, 0.8689968 , 0.6843445 , 0.6772145 ]],\n",
       "       dtype=float32),\n",
       " array([[0.11604986, 0.6489442 , 0.3340239 , 0.18072428, 0.7669321 ,\n",
       "         0.8251167 , 0.94018006, 0.70031554, 0.8879903 , 0.7756457 ,\n",
       "         0.06657812, 0.02789021, 0.9026063 , 0.6844673 , 0.679117  ]],\n",
       "       dtype=float32),\n",
       " array([[0.1288088 , 0.6215405 , 0.3286158 , 0.16355334, 0.7696467 ,\n",
       "         0.8104841 , 0.9308708 , 0.7106764 , 0.8813537 , 0.7551158 ,\n",
       "         0.07277002, 0.04078935, 0.8975126 , 0.68587184, 0.68995374]],\n",
       "       dtype=float32),\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "togive2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('C:/Users/yy2895/Desktop/update_stresult19-15-19.csv', 'w',newline='') as myfile:\n",
    "     wr = csv.writer(myfile)\n",
    "     for i in range(len(togive2)):\n",
    "        wr.writerow(list(togive2[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
