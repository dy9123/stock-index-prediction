{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "df=pd.read_csv('C:/Users/yy2895/Desktop/RawData.csv')\n",
    "d = df.values\n",
    "ntotal=len(df)\n",
    "\n",
    "\n",
    "d = normalize(d, axis=0, norm='l2')\n",
    "\n",
    "\n",
    "resultu = []\n",
    "np.random.rand(4)\n",
    "# Return 100 results (for instance)\n",
    "for i in range(ntotal):\n",
    "    \n",
    "    res = random.random()\n",
    "    if res < 0.1:\n",
    "        resultu.append(1)\n",
    "    elif res < 0.2 and res>=0.1:\n",
    "        resultu.append(2)\n",
    "    elif res < 0.3 and res>=0.2:\n",
    "        resultu.append(3)\n",
    "    elif res < 0.4 and res>=0.3:\n",
    "        resultu.append(4)\n",
    "    elif res < 0.5 and res>=0.4:\n",
    "        resultu.append(5)\n",
    "    elif res < 0.6 and res>=0.5:\n",
    "        resultu.append(6)\n",
    "    elif res < 0.7 and res>=0.6:\n",
    "        resultu.append(7)\n",
    "    elif res < 0.8 and res>=0.7:\n",
    "        resultu.append(8)\n",
    "    else:\n",
    "        resultu.append(9)\n",
    "resultu=np.array(resultu)\n",
    "trainset=[]\n",
    "for i in range(1,8):\n",
    "    toinsert=d[resultu==i].astype(np.float32)\n",
    "    trainset.append(toinsert)\n",
    "validationset=d[resultu==8].astype(np.float32)\n",
    "testset=d[resultu==9].astype(np.float32)\n",
    "\n",
    "\n",
    "#x = data\n",
    "\n",
    "# Following Hinton-Salakhutdinov Architecture\n",
    "\n",
    "# 3 hidden layers for encoder\n",
    "n_encoder_h_1 = 14\n",
    "n_encoder_h_2 = 9\n",
    "\n",
    "\n",
    "\n",
    "#n_encoder_h_5 = 10\n",
    "\n",
    "\n",
    "# 3 hidden layers for decoder\n",
    "#n_decoder_h_1 = 10\n",
    "n_decoder_h_1 = 14\n",
    "n_decoder_h_2 = 19\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.005\n",
    "\n",
    "#batch_size = 7\n",
    "display_step = 1\n",
    "\n",
    "total_batch=7\n",
    "training_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we begin\n",
      "Epoch: 0001 cost = 2.267292806\n",
      "Validation Loss: 2.7203662\n",
      "Epoch: 0002 cost = 2.252367122\n",
      "Validation Loss: 2.4011958\n",
      "Epoch: 0003 cost = 2.237690415\n",
      "Validation Loss: 2.3864565\n",
      "Epoch: 0004 cost = 2.222809928\n",
      "Validation Loss: 2.3749034\n",
      "Epoch: 0005 cost = 2.206821578\n",
      "Validation Loss: 2.3756406\n",
      "Epoch: 0006 cost = 2.189512730\n",
      "Validation Loss: 2.4179192\n",
      "Epoch: 0007 cost = 2.170483317\n",
      "Validation Loss: 2.4199295\n",
      "Epoch: 0008 cost = 2.149913618\n",
      "Validation Loss: 2.4094696\n",
      "Epoch: 0009 cost = 2.128934281\n",
      "Validation Loss: 2.3933074\n",
      "Epoch: 0010 cost = 2.108378513\n",
      "Validation Loss: 2.3756807\n",
      "Epoch: 0011 cost = 2.088259833\n",
      "Validation Loss: 2.3347232\n",
      "Epoch: 0012 cost = 2.068148715\n",
      "Validation Loss: 2.1176355\n",
      "Epoch: 0013 cost = 2.047423261\n",
      "Validation Loss: 2.0661752\n",
      "Epoch: 0014 cost = 2.026686668\n",
      "Validation Loss: 1.9976523\n",
      "Epoch: 0015 cost = 2.008111630\n",
      "Validation Loss: 1.9580992\n",
      "Epoch: 0016 cost = 1.992551804\n",
      "Validation Loss: 1.934895\n",
      "Epoch: 0017 cost = 1.979146532\n",
      "Validation Loss: 1.9245093\n",
      "Epoch: 0018 cost = 1.967087814\n",
      "Validation Loss: 1.920761\n",
      "Epoch: 0019 cost = 1.955852798\n",
      "Validation Loss: 1.9053462\n",
      "Epoch: 0020 cost = 1.945096357\n",
      "Validation Loss: 1.9112304\n",
      "Epoch: 0021 cost = 1.934595227\n",
      "Validation Loss: 1.9939295\n",
      "Epoch: 0022 cost = 1.924206768\n",
      "Validation Loss: 1.9993687\n",
      "Epoch: 0023 cost = 1.913839511\n",
      "Validation Loss: 2.0012348\n",
      "Epoch: 0024 cost = 1.903435571\n",
      "Validation Loss: 2.001521\n",
      "Epoch: 0025 cost = 1.892960940\n",
      "Validation Loss: 1.9868686\n",
      "Epoch: 0026 cost = 1.882400615\n",
      "Validation Loss: 1.9897312\n",
      "Epoch: 0027 cost = 1.871757848\n",
      "Validation Loss: 2.0057952\n",
      "Epoch: 0028 cost = 1.861051066\n",
      "Validation Loss: 1.9852705\n",
      "Epoch: 0029 cost = 1.850314549\n",
      "Validation Loss: 1.9733379\n",
      "Epoch: 0030 cost = 1.839591111\n",
      "Validation Loss: 1.9530239\n",
      "Epoch: 0031 cost = 1.828925014\n",
      "Validation Loss: 1.9043502\n",
      "Epoch: 0032 cost = 1.818351558\n",
      "Validation Loss: 1.7231878\n",
      "Epoch: 0033 cost = 1.807891335\n",
      "Validation Loss: 1.7257261\n",
      "Epoch: 0034 cost = 1.797548294\n",
      "Validation Loss: 1.8221123\n",
      "Epoch: 0035 cost = 1.787318860\n",
      "Validation Loss: 1.8277229\n",
      "Epoch: 0036 cost = 1.777199796\n",
      "Validation Loss: 1.8082377\n",
      "Epoch: 0037 cost = 1.767191751\n",
      "Validation Loss: 1.803656\n",
      "Epoch: 0038 cost = 1.757298606\n",
      "Validation Loss: 1.7880045\n",
      "Epoch: 0039 cost = 1.747525300\n",
      "Validation Loss: 1.7657337\n",
      "Epoch: 0040 cost = 1.737874780\n",
      "Validation Loss: 1.7061261\n",
      "Epoch: 0041 cost = 1.728349039\n",
      "Validation Loss: 1.4746794\n",
      "Epoch: 0042 cost = 1.718946763\n",
      "Validation Loss: 1.5000287\n",
      "Epoch: 0043 cost = 1.709664975\n",
      "Validation Loss: 1.6139379\n",
      "Epoch: 0044 cost = 1.700498479\n",
      "Validation Loss: 1.673581\n",
      "Epoch: 0045 cost = 1.691441979\n",
      "Validation Loss: 1.7139757\n",
      "Epoch: 0046 cost = 1.682489753\n",
      "Validation Loss: 1.720758\n",
      "Epoch: 0047 cost = 1.673636879\n",
      "Validation Loss: 1.6591685\n",
      "Epoch: 0048 cost = 1.664878471\n",
      "Validation Loss: 1.5988281\n",
      "Epoch: 0049 cost = 1.656210865\n",
      "Validation Loss: 1.5608078\n",
      "Epoch: 0050 cost = 1.647630692\n",
      "Validation Loss: 1.5767516\n",
      "Epoch: 0051 cost = 1.639135190\n",
      "Validation Loss: 1.6145035\n",
      "Epoch: 0052 cost = 1.630721995\n",
      "Validation Loss: 1.5983504\n",
      "Epoch: 0053 cost = 1.622388942\n",
      "Validation Loss: 1.579193\n",
      "Epoch: 0054 cost = 1.614134414\n",
      "Validation Loss: 1.5219867\n",
      "Epoch: 0055 cost = 1.605955447\n",
      "Validation Loss: 1.5421352\n",
      "Epoch: 0056 cost = 1.597850442\n",
      "Validation Loss: 1.5617654\n",
      "Epoch: 0057 cost = 1.589816860\n",
      "Validation Loss: 1.5335003\n",
      "Epoch: 0058 cost = 1.581852470\n",
      "Validation Loss: 1.5603421\n",
      "Epoch: 0059 cost = 1.573954463\n",
      "Validation Loss: 1.578683\n",
      "Epoch: 0060 cost = 1.566120573\n",
      "Validation Loss: 1.5870486\n",
      "Epoch: 0061 cost = 1.558348060\n",
      "Validation Loss: 1.5656761\n",
      "Epoch: 0062 cost = 1.550634520\n",
      "Validation Loss: 1.5360373\n",
      "Epoch: 0063 cost = 1.542977708\n",
      "Validation Loss: 1.5412849\n",
      "Epoch: 0064 cost = 1.535375306\n",
      "Validation Loss: 1.5433512\n",
      "Epoch: 0065 cost = 1.527825543\n",
      "Validation Loss: 1.511794\n",
      "Epoch: 0066 cost = 1.520326206\n",
      "Validation Loss: 1.4753336\n",
      "Epoch: 0067 cost = 1.512875591\n",
      "Validation Loss: 1.4367406\n",
      "Epoch: 0068 cost = 1.505472711\n",
      "Validation Loss: 1.2606542\n",
      "Epoch: 0069 cost = 1.498115642\n",
      "Validation Loss: 1.257494\n",
      "Epoch: 0070 cost = 1.490803599\n",
      "Validation Loss: 1.2772382\n",
      "Epoch: 0071 cost = 1.483535613\n",
      "Validation Loss: 1.3903148\n",
      "Epoch: 0072 cost = 1.476310134\n",
      "Validation Loss: 1.4351221\n",
      "Epoch: 0073 cost = 1.469127110\n",
      "Validation Loss: 1.4541893\n",
      "Epoch: 0074 cost = 1.461985230\n",
      "Validation Loss: 1.424171\n",
      "Epoch: 0075 cost = 1.454884171\n",
      "Validation Loss: 1.4090315\n",
      "Epoch: 0076 cost = 1.447823014\n",
      "Validation Loss: 1.3878608\n",
      "Epoch: 0077 cost = 1.440801638\n",
      "Validation Loss: 1.3444498\n",
      "Epoch: 0078 cost = 1.433819073\n",
      "Validation Loss: 1.3306295\n",
      "Epoch: 0079 cost = 1.426875131\n",
      "Validation Loss: 1.3082551\n",
      "Epoch: 0080 cost = 1.419969610\n",
      "Validation Loss: 1.3212332\n",
      "Epoch: 0081 cost = 1.413101622\n",
      "Validation Loss: 1.365276\n",
      "Epoch: 0082 cost = 1.406271066\n",
      "Validation Loss: 1.3648669\n",
      "Epoch: 0083 cost = 1.399477652\n",
      "Validation Loss: 1.3894588\n",
      "Epoch: 0084 cost = 1.392721091\n",
      "Validation Loss: 1.3664542\n",
      "Epoch: 0085 cost = 1.386000940\n",
      "Validation Loss: 1.3340528\n",
      "Epoch: 0086 cost = 1.379317045\n",
      "Validation Loss: 1.2839376\n",
      "Epoch: 0087 cost = 1.372668896\n",
      "Validation Loss: 1.3038613\n",
      "Epoch: 0088 cost = 1.366056255\n",
      "Validation Loss: 1.3159015\n",
      "Epoch: 0089 cost = 1.359479189\n",
      "Validation Loss: 1.3117027\n",
      "Epoch: 0090 cost = 1.352937324\n",
      "Validation Loss: 1.2500976\n",
      "Epoch: 0091 cost = 1.346430370\n",
      "Validation Loss: 1.0986775\n",
      "Epoch: 0092 cost = 1.339957970\n",
      "Validation Loss: 1.0947142\n",
      "Epoch: 0093 cost = 1.333520208\n",
      "Validation Loss: 1.1060005\n",
      "Epoch: 0094 cost = 1.327116558\n",
      "Validation Loss: 1.2290293\n",
      "Epoch: 0095 cost = 1.320747154\n",
      "Validation Loss: 1.3434703\n",
      "Epoch: 0096 cost = 1.314411334\n",
      "Validation Loss: 1.3949754\n",
      "Epoch: 0097 cost = 1.308109488\n",
      "Validation Loss: 1.3752754\n",
      "Epoch: 0098 cost = 1.301841072\n",
      "Validation Loss: 1.3525137\n",
      "Epoch: 0099 cost = 1.295605745\n",
      "Validation Loss: 1.3243291\n",
      "Epoch: 0100 cost = 1.289403541\n",
      "Validation Loss: 1.2567725\n",
      "Epoch: 0101 cost = 1.283234222\n",
      "Validation Loss: 1.2476693\n",
      "Epoch: 0102 cost = 1.277097634\n",
      "Validation Loss: 1.2537243\n",
      "Epoch: 0103 cost = 1.270993761\n",
      "Validation Loss: 1.2359346\n",
      "Epoch: 0104 cost = 1.264922227\n",
      "Validation Loss: 1.2428244\n",
      "Epoch: 0105 cost = 1.258882829\n",
      "Validation Loss: 1.2298062\n",
      "Epoch: 0106 cost = 1.252875532\n",
      "Validation Loss: 1.2377014\n",
      "Epoch: 0107 cost = 1.246900065\n",
      "Validation Loss: 1.2482328\n",
      "Epoch: 0108 cost = 1.240956068\n",
      "Validation Loss: 1.220308\n",
      "Epoch: 0109 cost = 1.235043866\n",
      "Validation Loss: 1.2236179\n",
      "Epoch: 0110 cost = 1.229162948\n",
      "Validation Loss: 1.1898494\n",
      "Epoch: 0111 cost = 1.223313263\n",
      "Validation Loss: 1.1967431\n",
      "Epoch: 0112 cost = 1.217494522\n",
      "Validation Loss: 1.187775\n",
      "Epoch: 0113 cost = 1.211706468\n",
      "Validation Loss: 1.1824106\n",
      "Epoch: 0114 cost = 1.205949528\n",
      "Validation Loss: 1.172748\n",
      "Epoch: 0115 cost = 1.200222714\n",
      "Validation Loss: 1.1535709\n",
      "Epoch: 0116 cost = 1.194526536\n",
      "Validation Loss: 1.1960503\n",
      "Epoch: 0117 cost = 1.188860331\n",
      "Validation Loss: 1.2124567\n",
      "Epoch: 0118 cost = 1.183224406\n",
      "Validation Loss: 1.1644495\n",
      "Epoch: 0119 cost = 1.177618112\n",
      "Validation Loss: 1.1352112\n",
      "Epoch: 0120 cost = 1.172041518\n",
      "Validation Loss: 1.0755423\n",
      "Epoch: 0121 cost = 1.166494540\n",
      "Validation Loss: 0.89873147\n",
      "Epoch: 0122 cost = 1.160976768\n",
      "Validation Loss: 0.97484636\n",
      "Epoch: 0123 cost = 1.155488508\n",
      "Validation Loss: 1.0287985\n",
      "Epoch: 0124 cost = 1.150029012\n",
      "Validation Loss: 1.0502886\n",
      "Epoch: 0125 cost = 1.144598416\n",
      "Validation Loss: 1.0715228\n",
      "Epoch: 0126 cost = 1.139196668\n",
      "Validation Loss: 1.0820314\n",
      "Epoch: 0127 cost = 1.133823293\n",
      "Validation Loss: 1.0800248\n",
      "Epoch: 0128 cost = 1.128478459\n",
      "Validation Loss: 1.0654845\n",
      "Epoch: 0129 cost = 1.123161810\n",
      "Validation Loss: 1.0593228\n",
      "Epoch: 0130 cost = 1.117873005\n",
      "Validation Loss: 1.1281848\n",
      "Epoch: 0131 cost = 1.112612367\n",
      "Validation Loss: 1.1519308\n",
      "Epoch: 0132 cost = 1.107379198\n",
      "Validation Loss: 1.144695\n",
      "Epoch: 0133 cost = 1.102173771\n",
      "Validation Loss: 1.1216056\n",
      "Epoch: 0134 cost = 1.096995626\n",
      "Validation Loss: 1.1055534\n",
      "Epoch: 0135 cost = 1.091844797\n",
      "Validation Loss: 1.0945982\n",
      "Epoch: 0136 cost = 1.086720960\n",
      "Validation Loss: 1.0777366\n",
      "Epoch: 0137 cost = 1.081623997\n",
      "Validation Loss: 1.0870821\n",
      "Epoch: 0138 cost = 1.076554026\n",
      "Validation Loss: 1.0945365\n",
      "Epoch: 0139 cost = 1.071510298\n",
      "Validation Loss: 1.0812184\n",
      "Epoch: 0140 cost = 1.066493205\n",
      "Validation Loss: 1.1200176\n",
      "Epoch: 0141 cost = 1.061502303\n",
      "Validation Loss: 1.1244439\n",
      "Epoch: 0142 cost = 1.056537543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.0956283\n",
      "Epoch: 0143 cost = 1.051598838\n",
      "Validation Loss: 1.1225846\n",
      "Epoch: 0144 cost = 1.046685866\n",
      "Validation Loss: 1.0921907\n",
      "Epoch: 0145 cost = 1.041798592\n",
      "Validation Loss: 1.0041512\n",
      "Epoch: 0146 cost = 1.036936743\n",
      "Validation Loss: 0.9792394\n",
      "Epoch: 0147 cost = 1.032100303\n",
      "Validation Loss: 1.017008\n",
      "Epoch: 0148 cost = 1.027289118\n",
      "Validation Loss: 1.0292032\n",
      "Epoch: 0149 cost = 1.022502967\n",
      "Validation Loss: 1.0588467\n",
      "Epoch: 0150 cost = 1.017741680\n",
      "Validation Loss: 1.0235628\n",
      "Epoch: 0151 cost = 1.013005478\n",
      "Validation Loss: 0.9723004\n",
      "Epoch: 0152 cost = 1.008293637\n",
      "Validation Loss: 0.94863105\n",
      "Epoch: 0153 cost = 1.003606021\n",
      "Validation Loss: 0.9651555\n",
      "Epoch: 0154 cost = 0.998943065\n",
      "Validation Loss: 0.95006496\n",
      "Epoch: 0155 cost = 0.994304197\n",
      "Validation Loss: 0.96968436\n",
      "Epoch: 0156 cost = 0.989689572\n",
      "Validation Loss: 0.9450514\n",
      "Epoch: 0157 cost = 0.985098575\n",
      "Validation Loss: 0.9717028\n",
      "Epoch: 0158 cost = 0.980531607\n",
      "Validation Loss: 0.9999402\n",
      "Epoch: 0159 cost = 0.975988167\n",
      "Validation Loss: 0.9974925\n",
      "Epoch: 0160 cost = 0.971468304\n",
      "Validation Loss: 0.99479276\n",
      "Epoch: 0161 cost = 0.966971823\n",
      "Validation Loss: 0.9188827\n",
      "Epoch: 0162 cost = 0.962498495\n",
      "Validation Loss: 0.93607235\n",
      "Epoch: 0163 cost = 0.958048361\n",
      "Validation Loss: 0.9488792\n",
      "Epoch: 0164 cost = 0.953621422\n",
      "Validation Loss: 0.9264598\n",
      "Epoch: 0165 cost = 0.949217243\n",
      "Validation Loss: 0.9192197\n",
      "Epoch: 0166 cost = 0.944835884\n",
      "Validation Loss: 0.9573055\n",
      "Epoch: 0167 cost = 0.940477099\n",
      "Validation Loss: 0.9440137\n",
      "Epoch: 0168 cost = 0.936140920\n",
      "Validation Loss: 0.9590918\n",
      "Epoch: 0169 cost = 0.931827094\n",
      "Validation Loss: 0.9635284\n",
      "Epoch: 0170 cost = 0.927535474\n",
      "Validation Loss: 0.9250545\n",
      "Epoch: 0171 cost = 0.923266266\n",
      "Validation Loss: 0.893097\n",
      "Epoch: 0172 cost = 0.919019060\n",
      "Validation Loss: 0.79554987\n",
      "Epoch: 0173 cost = 0.914793738\n",
      "Validation Loss: 0.79641414\n",
      "Epoch: 0174 cost = 0.910590376\n",
      "Validation Loss: 0.80364287\n",
      "Epoch: 0175 cost = 0.906408676\n",
      "Validation Loss: 0.83305943\n",
      "Epoch: 0176 cost = 0.902248757\n",
      "Validation Loss: 0.8693556\n",
      "Epoch: 0177 cost = 0.898110288\n",
      "Validation Loss: 0.88350993\n",
      "Epoch: 0178 cost = 0.893993301\n",
      "Validation Loss: 0.8753639\n",
      "Epoch: 0179 cost = 0.889897619\n",
      "Validation Loss: 0.8819377\n",
      "Epoch: 0180 cost = 0.885823335\n",
      "Validation Loss: 0.8843201\n",
      "Epoch: 0181 cost = 0.881770023\n",
      "Validation Loss: 0.8925324\n",
      "Epoch: 0182 cost = 0.877737965\n",
      "Validation Loss: 0.90126646\n",
      "Epoch: 0183 cost = 0.873726845\n",
      "Validation Loss: 0.86340517\n",
      "Epoch: 0184 cost = 0.869736663\n",
      "Validation Loss: 0.8484724\n",
      "Epoch: 0185 cost = 0.865767317\n",
      "Validation Loss: 0.8395007\n",
      "Epoch: 0186 cost = 0.861818612\n",
      "Validation Loss: 0.8771322\n",
      "Epoch: 0187 cost = 0.857890674\n",
      "Validation Loss: 0.86389965\n",
      "Epoch: 0188 cost = 0.853983343\n",
      "Validation Loss: 0.8301769\n",
      "Epoch: 0189 cost = 0.850096464\n",
      "Validation Loss: 0.861071\n",
      "Epoch: 0190 cost = 0.846229945\n",
      "Validation Loss: 0.8698675\n",
      "Epoch: 0191 cost = 0.842384015\n",
      "Validation Loss: 0.83218294\n",
      "Epoch: 0192 cost = 0.838558308\n",
      "Validation Loss: 0.80615914\n",
      "Epoch: 0193 cost = 0.834752773\n",
      "Validation Loss: 0.79878265\n",
      "Epoch: 0194 cost = 0.830967511\n",
      "Validation Loss: 0.7863973\n",
      "Epoch: 0195 cost = 0.827202329\n",
      "Validation Loss: 0.7451151\n",
      "Epoch: 0196 cost = 0.823457318\n",
      "Validation Loss: 0.7293637\n",
      "Epoch: 0197 cost = 0.819732266\n",
      "Validation Loss: 0.7378843\n",
      "Epoch: 0198 cost = 0.816027284\n",
      "Validation Loss: 0.77784365\n",
      "Epoch: 0199 cost = 0.812342158\n",
      "Validation Loss: 0.79231554\n",
      "Epoch: 0200 cost = 0.808677018\n",
      "Validation Loss: 0.8061248\n",
      "Epoch: 0201 cost = 0.805031836\n",
      "Validation Loss: 0.77761286\n",
      "Epoch: 0202 cost = 0.801406298\n",
      "Validation Loss: 0.7706203\n",
      "Epoch: 0203 cost = 0.797800635\n",
      "Validation Loss: 0.78322035\n",
      "Epoch: 0204 cost = 0.794214802\n",
      "Validation Loss: 0.774566\n",
      "Epoch: 0205 cost = 0.790648733\n",
      "Validation Loss: 0.78265893\n",
      "Epoch: 0206 cost = 0.787102308\n",
      "Validation Loss: 0.7954977\n",
      "Epoch: 0207 cost = 0.783575731\n",
      "Validation Loss: 0.7816135\n",
      "Epoch: 0208 cost = 0.780068687\n",
      "Validation Loss: 0.77228\n",
      "Epoch: 0209 cost = 0.776581398\n",
      "Validation Loss: 0.7942201\n",
      "Epoch: 0210 cost = 0.773113659\n",
      "Validation Loss: 0.7745202\n",
      "Epoch: 0211 cost = 0.769665778\n",
      "Validation Loss: 0.7688129\n",
      "Epoch: 0212 cost = 0.766237497\n",
      "Validation Loss: 0.76096874\n",
      "Epoch: 0213 cost = 0.762828682\n",
      "Validation Loss: 0.7434612\n",
      "Epoch: 0214 cost = 0.759439519\n",
      "Validation Loss: 0.74777585\n",
      "Epoch: 0215 cost = 0.756069916\n",
      "Validation Loss: 0.75290686\n",
      "Epoch: 0216 cost = 0.752719964\n",
      "Validation Loss: 0.73444724\n",
      "Epoch: 0217 cost = 0.749389546\n",
      "Validation Loss: 0.74722916\n",
      "Epoch: 0218 cost = 0.746078806\n",
      "Validation Loss: 0.7423242\n",
      "Epoch: 0219 cost = 0.742787446\n",
      "Validation Loss: 0.7368684\n",
      "Epoch: 0220 cost = 0.739515620\n",
      "Validation Loss: 0.7101804\n",
      "Epoch: 0221 cost = 0.736263369\n",
      "Validation Loss: 0.65557384\n",
      "Epoch: 0222 cost = 0.733030472\n",
      "Validation Loss: 0.65756696\n",
      "Epoch: 0223 cost = 0.729817135\n",
      "Validation Loss: 0.6804111\n",
      "Epoch: 0224 cost = 0.726623118\n",
      "Validation Loss: 0.71631604\n",
      "Epoch: 0225 cost = 0.723448379\n",
      "Validation Loss: 0.71873105\n",
      "Epoch: 0226 cost = 0.720293122\n",
      "Validation Loss: 0.6976033\n",
      "Epoch: 0227 cost = 0.717157262\n",
      "Validation Loss: 0.6948671\n",
      "Epoch: 0228 cost = 0.714040450\n",
      "Validation Loss: 0.71078384\n",
      "Epoch: 0229 cost = 0.710942975\n",
      "Validation Loss: 0.71473163\n",
      "Epoch: 0230 cost = 0.707864591\n",
      "Validation Loss: 0.72191083\n",
      "Epoch: 0231 cost = 0.704805238\n",
      "Validation Loss: 0.7253092\n",
      "Epoch: 0232 cost = 0.701764984\n",
      "Validation Loss: 0.7214284\n",
      "Epoch: 0233 cost = 0.698743769\n",
      "Validation Loss: 0.70436496\n",
      "Epoch: 0234 cost = 0.695741211\n",
      "Validation Loss: 0.6832953\n",
      "Epoch: 0235 cost = 0.692757734\n",
      "Validation Loss: 0.6696042\n",
      "Epoch: 0236 cost = 0.689792693\n",
      "Validation Loss: 0.67522955\n",
      "Epoch: 0237 cost = 0.686846461\n",
      "Validation Loss: 0.6829846\n",
      "Epoch: 0238 cost = 0.683918663\n",
      "Validation Loss: 0.6948278\n",
      "Epoch: 0239 cost = 0.681009480\n",
      "Validation Loss: 0.69814277\n",
      "Epoch: 0240 cost = 0.678118595\n",
      "Validation Loss: 0.68971044\n",
      "Epoch: 0241 cost = 0.675246034\n",
      "Validation Loss: 0.6937172\n",
      "Epoch: 0242 cost = 0.672391525\n",
      "Validation Loss: 0.6670971\n",
      "Epoch: 0243 cost = 0.669554991\n",
      "Validation Loss: 0.6823824\n",
      "Epoch: 0244 cost = 0.666736569\n",
      "Validation Loss: 0.6779278\n",
      "Epoch: 0245 cost = 0.663935832\n",
      "Validation Loss: 0.658816\n",
      "Epoch: 0246 cost = 0.661152848\n",
      "Validation Loss: 0.647899\n",
      "Epoch: 0247 cost = 0.658387440\n",
      "Validation Loss: 0.5994756\n",
      "Epoch: 0248 cost = 0.655639580\n",
      "Validation Loss: 0.63521487\n",
      "Epoch: 0249 cost = 0.652909151\n",
      "Validation Loss: 0.65091\n",
      "Epoch: 0250 cost = 0.650195820\n",
      "Validation Loss: 0.638999\n",
      "Epoch: 0251 cost = 0.647499723\n",
      "Validation Loss: 0.645796\n",
      "Epoch: 0252 cost = 0.644820682\n",
      "Validation Loss: 0.631555\n",
      "Epoch: 0253 cost = 0.642158474\n",
      "Validation Loss: 0.6188268\n",
      "Epoch: 0254 cost = 0.639512973\n",
      "Validation Loss: 0.6159329\n",
      "Epoch: 0255 cost = 0.636884264\n",
      "Validation Loss: 0.60693187\n",
      "Epoch: 0256 cost = 0.634272107\n",
      "Validation Loss: 0.6205956\n",
      "Epoch: 0257 cost = 0.631676427\n",
      "Validation Loss: 0.62576663\n",
      "Epoch: 0258 cost = 0.629096976\n",
      "Validation Loss: 0.63662183\n",
      "Epoch: 0259 cost = 0.626533815\n",
      "Validation Loss: 0.6288749\n",
      "Epoch: 0260 cost = 0.623986704\n",
      "Validation Loss: 0.62307954\n",
      "Epoch: 0261 cost = 0.621455627\n",
      "Validation Loss: 0.5966839\n",
      "Epoch: 0262 cost = 0.618940379\n",
      "Validation Loss: 0.59205514\n",
      "Epoch: 0263 cost = 0.616441054\n",
      "Validation Loss: 0.6197213\n",
      "Epoch: 0264 cost = 0.613957320\n",
      "Validation Loss: 0.62552077\n",
      "Epoch: 0265 cost = 0.611489151\n",
      "Validation Loss: 0.6139455\n",
      "Epoch: 0266 cost = 0.609036531\n",
      "Validation Loss: 0.6034364\n",
      "Epoch: 0267 cost = 0.606599237\n",
      "Validation Loss: 0.59354484\n",
      "Epoch: 0268 cost = 0.604177109\n",
      "Validation Loss: 0.6009729\n",
      "Epoch: 0269 cost = 0.601770384\n",
      "Validation Loss: 0.60744756\n",
      "Epoch: 0270 cost = 0.599378594\n",
      "Validation Loss: 0.6123245\n",
      "Epoch: 0271 cost = 0.597001834\n",
      "Validation Loss: 0.6272014\n",
      "Epoch: 0272 cost = 0.594640034\n",
      "Validation Loss: 0.62240124\n",
      "Epoch: 0273 cost = 0.592293050\n",
      "Validation Loss: 0.61135674\n",
      "Epoch: 0274 cost = 0.589960805\n",
      "Validation Loss: 0.583703\n",
      "Epoch: 0275 cost = 0.587643070\n",
      "Validation Loss: 0.57308334\n",
      "Epoch: 0276 cost = 0.585340066\n",
      "Validation Loss: 0.5770856\n",
      "Epoch: 0277 cost = 0.583051375\n",
      "Validation Loss: 0.5770535\n",
      "Epoch: 0278 cost = 0.580777134\n",
      "Validation Loss: 0.5835969\n",
      "Epoch: 0279 cost = 0.578517190\n",
      "Validation Loss: 0.57496893\n",
      "Epoch: 0280 cost = 0.576271474\n",
      "Validation Loss: 0.57350105\n",
      "Epoch: 0281 cost = 0.574039911\n",
      "Validation Loss: 0.5761316\n",
      "Epoch: 0282 cost = 0.571822294\n",
      "Validation Loss: 0.57936275\n",
      "Epoch: 0283 cost = 0.569618591\n",
      "Validation Loss: 0.5734569\n",
      "Epoch: 0284 cost = 0.567428938\n",
      "Validation Loss: 0.5901091\n",
      "Epoch: 0285 cost = 0.565252909\n",
      "Validation Loss: 0.57687914\n",
      "Epoch: 0286 cost = 0.563090665\n",
      "Validation Loss: 0.5804151\n",
      "Epoch: 0287 cost = 0.560942011\n",
      "Validation Loss: 0.55157024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0288 cost = 0.558806854\n",
      "Validation Loss: 0.56392866\n",
      "Epoch: 0289 cost = 0.556685226\n",
      "Validation Loss: 0.55533737\n",
      "Epoch: 0290 cost = 0.554576933\n",
      "Validation Loss: 0.55889654\n",
      "Epoch: 0291 cost = 0.552481949\n",
      "Validation Loss: 0.5490822\n",
      "Epoch: 0292 cost = 0.550400053\n",
      "Validation Loss: 0.54847056\n",
      "Epoch: 0293 cost = 0.548331397\n",
      "Validation Loss: 0.55026275\n",
      "Epoch: 0294 cost = 0.546275667\n",
      "Validation Loss: 0.52801126\n",
      "Epoch: 0295 cost = 0.544232862\n",
      "Validation Loss: 0.542902\n",
      "Epoch: 0296 cost = 0.542202950\n",
      "Validation Loss: 0.5387671\n",
      "Epoch: 0297 cost = 0.540185775\n",
      "Validation Loss: 0.5390473\n",
      "Epoch: 0298 cost = 0.538181279\n",
      "Validation Loss: 0.53766036\n",
      "Epoch: 0299 cost = 0.536189428\n",
      "Validation Loss: 0.5384074\n",
      "Epoch: 0300 cost = 0.534210069\n",
      "Validation Loss: 0.53909206\n",
      "Epoch: 0301 cost = 0.532243133\n",
      "Validation Loss: 0.55161387\n",
      "Epoch: 0302 cost = 0.530288458\n",
      "Validation Loss: 0.540133\n",
      "Epoch: 0303 cost = 0.528345977\n",
      "Validation Loss: 0.5378961\n",
      "Epoch: 0304 cost = 0.526415757\n",
      "Validation Loss: 0.5337454\n",
      "Epoch: 0305 cost = 0.524497560\n",
      "Validation Loss: 0.53469396\n",
      "Epoch: 0306 cost = 0.522591327\n",
      "Validation Loss: 0.5465225\n",
      "Epoch: 0307 cost = 0.520697015\n",
      "Validation Loss: 0.54409355\n",
      "Epoch: 0308 cost = 0.518814500\n",
      "Validation Loss: 0.5392827\n",
      "Epoch: 0309 cost = 0.516943714\n",
      "Validation Loss: 0.51346415\n",
      "Epoch: 0310 cost = 0.515084586\n",
      "Validation Loss: 0.5106141\n",
      "Epoch: 0311 cost = 0.513236961\n",
      "Validation Loss: 0.52058154\n",
      "Epoch: 0312 cost = 0.511400832\n",
      "Validation Loss: 0.50569946\n",
      "Epoch: 0313 cost = 0.509576078\n",
      "Validation Loss: 0.49060097\n",
      "Epoch: 0314 cost = 0.507762513\n",
      "Validation Loss: 0.50061315\n",
      "Epoch: 0315 cost = 0.505960277\n",
      "Validation Loss: 0.49129742\n",
      "Epoch: 0316 cost = 0.504169221\n",
      "Validation Loss: 0.49419782\n",
      "Epoch: 0317 cost = 0.502388929\n",
      "Validation Loss: 0.50201887\n",
      "Epoch: 0318 cost = 0.500619850\n",
      "Validation Loss: 0.5147793\n",
      "Epoch: 0319 cost = 0.498861530\n",
      "Validation Loss: 0.5294471\n",
      "Epoch: 0320 cost = 0.497113964\n",
      "Validation Loss: 0.5312075\n",
      "Epoch: 0321 cost = 0.495377226\n",
      "Validation Loss: 0.51694995\n",
      "Epoch: 0322 cost = 0.493650935\n",
      "Validation Loss: 0.5080393\n",
      "Epoch: 0323 cost = 0.491935355\n",
      "Validation Loss: 0.5055753\n",
      "Epoch: 0324 cost = 0.490230169\n",
      "Validation Loss: 0.514782\n",
      "Epoch: 0325 cost = 0.488535276\n",
      "Validation Loss: 0.50876045\n",
      "Epoch: 0326 cost = 0.486850785\n",
      "Validation Loss: 0.50703436\n",
      "Epoch: 0327 cost = 0.485176414\n",
      "Validation Loss: 0.512886\n",
      "Epoch: 0328 cost = 0.483512261\n",
      "Validation Loss: 0.50759846\n",
      "Epoch: 0329 cost = 0.481858151\n",
      "Validation Loss: 0.47713178\n",
      "Epoch: 0330 cost = 0.480213898\n",
      "Validation Loss: 0.48804227\n",
      "Epoch: 0331 cost = 0.478579666\n",
      "Validation Loss: 0.48325086\n",
      "Epoch: 0332 cost = 0.476955278\n",
      "Validation Loss: 0.47241625\n",
      "Epoch: 0333 cost = 0.475340566\n",
      "Validation Loss: 0.47499943\n",
      "Epoch: 0334 cost = 0.473735477\n",
      "Validation Loss: 0.47883138\n",
      "Epoch: 0335 cost = 0.472140001\n",
      "Validation Loss: 0.4743946\n",
      "Epoch: 0336 cost = 0.470554105\n",
      "Validation Loss: 0.48184168\n",
      "Epoch: 0337 cost = 0.468977507\n",
      "Validation Loss: 0.4837299\n",
      "Epoch: 0338 cost = 0.467410326\n",
      "Validation Loss: 0.45672178\n",
      "Epoch: 0339 cost = 0.465852452\n",
      "Validation Loss: 0.4726333\n",
      "Epoch: 0340 cost = 0.464303638\n",
      "Validation Loss: 0.44619608\n",
      "Epoch: 0341 cost = 0.462764038\n",
      "Validation Loss: 0.45301595\n",
      "Epoch: 0342 cost = 0.461233492\n",
      "Validation Loss: 0.43935078\n",
      "Epoch: 0343 cost = 0.459711914\n",
      "Validation Loss: 0.45734194\n",
      "Epoch: 0344 cost = 0.458199280\n",
      "Validation Loss: 0.44299117\n",
      "Epoch: 0345 cost = 0.456695382\n",
      "Validation Loss: 0.44218683\n",
      "Epoch: 0346 cost = 0.455200289\n",
      "Validation Loss: 0.44092315\n",
      "Epoch: 0347 cost = 0.453713843\n",
      "Validation Loss: 0.43593317\n",
      "Epoch: 0348 cost = 0.452236027\n",
      "Validation Loss: 0.45762485\n",
      "Epoch: 0349 cost = 0.450766768\n",
      "Validation Loss: 0.4517372\n",
      "Epoch: 0350 cost = 0.449305879\n",
      "Validation Loss: 0.4459489\n",
      "Epoch: 0351 cost = 0.447853574\n",
      "Validation Loss: 0.4413206\n",
      "Epoch: 0352 cost = 0.446409370\n",
      "Validation Loss: 0.45247537\n",
      "Epoch: 0353 cost = 0.444973648\n",
      "Validation Loss: 0.44333854\n",
      "Epoch: 0354 cost = 0.443545925\n",
      "Validation Loss: 0.43692875\n",
      "Epoch: 0355 cost = 0.442126474\n",
      "Validation Loss: 0.42667642\n",
      "Epoch: 0356 cost = 0.440715092\n",
      "Validation Loss: 0.4378493\n",
      "Epoch: 0357 cost = 0.439311709\n",
      "Validation Loss: 0.42477903\n",
      "Epoch: 0358 cost = 0.437916245\n",
      "Validation Loss: 0.44671655\n",
      "Epoch: 0359 cost = 0.436528700\n",
      "Validation Loss: 0.44009927\n",
      "Epoch: 0360 cost = 0.435148997\n",
      "Validation Loss: 0.42876476\n",
      "Epoch: 0361 cost = 0.433777145\n",
      "Validation Loss: 0.43039736\n",
      "Epoch: 0362 cost = 0.432412948\n",
      "Validation Loss: 0.42908955\n",
      "Epoch: 0363 cost = 0.431056410\n",
      "Validation Loss: 0.42128026\n",
      "Epoch: 0364 cost = 0.429707617\n",
      "Validation Loss: 0.44072926\n",
      "Epoch: 0365 cost = 0.428366397\n",
      "Validation Loss: 0.42178157\n",
      "Epoch: 0366 cost = 0.427032722\n",
      "Validation Loss: 0.40867132\n",
      "Epoch: 0367 cost = 0.425706591\n",
      "Validation Loss: 0.43933287\n",
      "Epoch: 0368 cost = 0.424387936\n",
      "Validation Loss: 0.41256005\n",
      "Epoch: 0369 cost = 0.423076672\n",
      "Validation Loss: 0.40855357\n",
      "Epoch: 0370 cost = 0.421772897\n",
      "Validation Loss: 0.42784068\n",
      "Epoch: 0371 cost = 0.420476475\n",
      "Validation Loss: 0.41778067\n",
      "Epoch: 0372 cost = 0.419187341\n",
      "Validation Loss: 0.42373493\n",
      "Epoch: 0373 cost = 0.417905527\n",
      "Validation Loss: 0.41259113\n",
      "Epoch: 0374 cost = 0.416631039\n",
      "Validation Loss: 0.4064663\n",
      "Epoch: 0375 cost = 0.415363801\n",
      "Validation Loss: 0.44528657\n",
      "Epoch: 0376 cost = 0.414103810\n",
      "Validation Loss: 0.44065133\n",
      "Epoch: 0377 cost = 0.412850916\n",
      "Validation Loss: 0.4241182\n",
      "Epoch: 0378 cost = 0.411605209\n",
      "Validation Loss: 0.41529375\n",
      "Epoch: 0379 cost = 0.410366629\n",
      "Validation Loss: 0.41293767\n",
      "Epoch: 0380 cost = 0.409135150\n",
      "Validation Loss: 0.41564777\n",
      "Epoch: 0381 cost = 0.407910743\n",
      "Validation Loss: 0.42345783\n",
      "Epoch: 0382 cost = 0.406693275\n",
      "Validation Loss: 0.4255023\n",
      "Epoch: 0383 cost = 0.405482807\n",
      "Validation Loss: 0.41043958\n",
      "Epoch: 0384 cost = 0.404279262\n",
      "Validation Loss: 0.3940086\n",
      "Epoch: 0385 cost = 0.403082771\n",
      "Validation Loss: 0.41538167\n",
      "Epoch: 0386 cost = 0.401893130\n",
      "Validation Loss: 0.4278475\n",
      "Epoch: 0387 cost = 0.400710234\n",
      "Validation Loss: 0.42032662\n",
      "Epoch: 0388 cost = 0.399534204\n",
      "Validation Loss: 0.40783587\n",
      "Epoch: 0389 cost = 0.398364991\n",
      "Validation Loss: 0.39965168\n",
      "Epoch: 0390 cost = 0.397202436\n",
      "Validation Loss: 0.39327595\n",
      "Epoch: 0391 cost = 0.396046562\n",
      "Validation Loss: 0.42585054\n",
      "Epoch: 0392 cost = 0.394897376\n",
      "Validation Loss: 0.41028517\n",
      "Epoch: 0393 cost = 0.393754768\n",
      "Validation Loss: 0.3995689\n",
      "Epoch: 0394 cost = 0.392618733\n",
      "Validation Loss: 0.39136928\n",
      "Epoch: 0395 cost = 0.391489238\n",
      "Validation Loss: 0.39737582\n",
      "Epoch: 0396 cost = 0.390366239\n",
      "Validation Loss: 0.37888145\n",
      "Epoch: 0397 cost = 0.389249687\n",
      "Validation Loss: 0.39818338\n",
      "Epoch: 0398 cost = 0.388139491\n",
      "Validation Loss: 0.39456192\n",
      "Epoch: 0399 cost = 0.387035770\n",
      "Validation Loss: 0.38815802\n",
      "Epoch: 0400 cost = 0.385938334\n",
      "Validation Loss: 0.3954138\n",
      "Epoch: 0401 cost = 0.384847092\n",
      "Validation Loss: 0.39272362\n",
      "Epoch: 0402 cost = 0.383762223\n",
      "Validation Loss: 0.38247985\n",
      "Epoch: 0403 cost = 0.382683469\n",
      "Validation Loss: 0.3898849\n",
      "Epoch: 0404 cost = 0.381610909\n",
      "Validation Loss: 0.3948608\n",
      "Epoch: 0405 cost = 0.380544475\n",
      "Validation Loss: 0.39073294\n",
      "Epoch: 0406 cost = 0.379484100\n",
      "Validation Loss: 0.38096285\n",
      "Epoch: 0407 cost = 0.378429745\n",
      "Validation Loss: 0.3647094\n",
      "Epoch: 0408 cost = 0.377381397\n",
      "Validation Loss: 0.39106736\n",
      "Epoch: 0409 cost = 0.376338984\n",
      "Validation Loss: 0.39218128\n",
      "Epoch: 0410 cost = 0.375302528\n",
      "Validation Loss: 0.3902188\n",
      "Epoch: 0411 cost = 0.374271976\n",
      "Validation Loss: 0.38965935\n",
      "Epoch: 0412 cost = 0.373247193\n",
      "Validation Loss: 0.38118264\n",
      "Epoch: 0413 cost = 0.372228231\n",
      "Validation Loss: 0.382888\n",
      "Epoch: 0414 cost = 0.371215080\n",
      "Validation Loss: 0.3800996\n",
      "Epoch: 0415 cost = 0.370207561\n",
      "Validation Loss: 0.37958223\n",
      "Epoch: 0416 cost = 0.369205752\n",
      "Validation Loss: 0.37292892\n",
      "Epoch: 0417 cost = 0.368209575\n",
      "Validation Loss: 0.37805513\n",
      "Epoch: 0418 cost = 0.367219022\n",
      "Validation Loss: 0.38268965\n",
      "Epoch: 0419 cost = 0.366234051\n",
      "Validation Loss: 0.3856069\n",
      "Epoch: 0420 cost = 0.365254589\n",
      "Validation Loss: 0.38000512\n",
      "Epoch: 0421 cost = 0.364280628\n",
      "Validation Loss: 0.37082145\n",
      "Epoch: 0422 cost = 0.363312083\n",
      "Validation Loss: 0.36052924\n",
      "Epoch: 0423 cost = 0.362348961\n",
      "Validation Loss: 0.36227623\n",
      "Epoch: 0424 cost = 0.361391221\n",
      "Validation Loss: 0.3524468\n",
      "Epoch: 0425 cost = 0.360438832\n",
      "Validation Loss: 0.35356873\n",
      "Epoch: 0426 cost = 0.359491753\n",
      "Validation Loss: 0.3420777\n",
      "Epoch: 0427 cost = 0.358549953\n",
      "Validation Loss: 0.38855824\n",
      "Epoch: 0428 cost = 0.357613359\n",
      "Validation Loss: 0.3629575\n",
      "Epoch: 0429 cost = 0.356682011\n",
      "Validation Loss: 0.34829828\n",
      "Epoch: 0430 cost = 0.355755806\n",
      "Validation Loss: 0.34441996\n",
      "Epoch: 0431 cost = 0.354834795\n",
      "Validation Loss: 0.3404011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0432 cost = 0.353918833\n",
      "Validation Loss: 0.3660995\n",
      "Epoch: 0433 cost = 0.353007951\n",
      "Validation Loss: 0.35688862\n",
      "Epoch: 0434 cost = 0.352102058\n",
      "Validation Loss: 0.3534528\n",
      "Epoch: 0435 cost = 0.351201249\n",
      "Validation Loss: 0.34163556\n",
      "Epoch: 0436 cost = 0.350305306\n",
      "Validation Loss: 0.3344875\n",
      "Epoch: 0437 cost = 0.349414404\n",
      "Validation Loss: 0.3521777\n",
      "Epoch: 0438 cost = 0.348528351\n",
      "Validation Loss: 0.35241723\n",
      "Epoch: 0439 cost = 0.347647203\n",
      "Validation Loss: 0.35319898\n",
      "Epoch: 0440 cost = 0.346770857\n",
      "Validation Loss: 0.33797717\n",
      "Epoch: 0441 cost = 0.345899343\n",
      "Validation Loss: 0.32867715\n",
      "Epoch: 0442 cost = 0.345032654\n",
      "Validation Loss: 0.3400057\n",
      "Epoch: 0443 cost = 0.344170707\n",
      "Validation Loss: 0.33287618\n",
      "Epoch: 0444 cost = 0.343313473\n",
      "Validation Loss: 0.3428501\n",
      "Epoch: 0445 cost = 0.342460960\n",
      "Validation Loss: 0.33782902\n",
      "Epoch: 0446 cost = 0.341613114\n",
      "Validation Loss: 0.33777487\n",
      "Epoch: 0447 cost = 0.340769849\n",
      "Validation Loss: 0.32205483\n",
      "Epoch: 0448 cost = 0.339931271\n",
      "Validation Loss: 0.34723157\n",
      "Epoch: 0449 cost = 0.339097257\n",
      "Validation Loss: 0.35486192\n",
      "Epoch: 0450 cost = 0.338267739\n",
      "Validation Loss: 0.3563238\n",
      "Epoch: 0451 cost = 0.337442811\n",
      "Validation Loss: 0.34339517\n",
      "Epoch: 0452 cost = 0.336622306\n",
      "Validation Loss: 0.33903635\n",
      "Epoch: 0453 cost = 0.335806348\n",
      "Validation Loss: 0.34588644\n",
      "Epoch: 0454 cost = 0.334994853\n",
      "Validation Loss: 0.33854923\n",
      "Epoch: 0455 cost = 0.334187712\n",
      "Validation Loss: 0.33438182\n",
      "Epoch: 0456 cost = 0.333384969\n",
      "Validation Loss: 0.3280336\n",
      "Epoch: 0457 cost = 0.332586629\n",
      "Validation Loss: 0.32640088\n",
      "Epoch: 0458 cost = 0.331792636\n",
      "Validation Loss: 0.32858002\n",
      "Epoch: 0459 cost = 0.331002959\n",
      "Validation Loss: 0.31751126\n",
      "Epoch: 0460 cost = 0.330217583\n",
      "Validation Loss: 0.34103695\n",
      "Epoch: 0461 cost = 0.329436494\n",
      "Validation Loss: 0.33542112\n",
      "Epoch: 0462 cost = 0.328659624\n",
      "Validation Loss: 0.325199\n",
      "Epoch: 0463 cost = 0.327886943\n",
      "Validation Loss: 0.31952387\n",
      "Epoch: 0464 cost = 0.327118482\n",
      "Validation Loss: 0.31243852\n",
      "Epoch: 0465 cost = 0.326354227\n",
      "Validation Loss: 0.33015308\n",
      "Epoch: 0466 cost = 0.325594119\n",
      "Validation Loss: 0.31622517\n",
      "Epoch: 0467 cost = 0.324838119\n",
      "Validation Loss: 0.31198552\n",
      "Epoch: 0468 cost = 0.324086194\n",
      "Validation Loss: 0.34101307\n",
      "Epoch: 0469 cost = 0.323338411\n",
      "Validation Loss: 0.34588528\n",
      "Epoch: 0470 cost = 0.322594609\n",
      "Validation Loss: 0.33864638\n",
      "Epoch: 0471 cost = 0.321854911\n",
      "Validation Loss: 0.3358998\n",
      "Epoch: 0472 cost = 0.321119257\n",
      "Validation Loss: 0.32676274\n",
      "Epoch: 0473 cost = 0.320387529\n",
      "Validation Loss: 0.32187125\n",
      "Epoch: 0474 cost = 0.319659821\n",
      "Validation Loss: 0.33073184\n",
      "Epoch: 0475 cost = 0.318936037\n",
      "Validation Loss: 0.32747948\n",
      "Epoch: 0476 cost = 0.318216132\n",
      "Validation Loss: 0.32093185\n",
      "Epoch: 0477 cost = 0.317500234\n",
      "Validation Loss: 0.3232923\n",
      "Epoch: 0478 cost = 0.316788180\n",
      "Validation Loss: 0.32010546\n",
      "Epoch: 0479 cost = 0.316079983\n",
      "Validation Loss: 0.3195922\n",
      "Epoch: 0480 cost = 0.315375669\n",
      "Validation Loss: 0.3264614\n",
      "Epoch: 0481 cost = 0.314675186\n",
      "Validation Loss: 0.3298314\n",
      "Epoch: 0482 cost = 0.313978455\n",
      "Validation Loss: 0.32654345\n",
      "Epoch: 0483 cost = 0.313285559\n",
      "Validation Loss: 0.32564187\n",
      "Epoch: 0484 cost = 0.312596453\n",
      "Validation Loss: 0.32671443\n",
      "Epoch: 0485 cost = 0.311911064\n",
      "Validation Loss: 0.31413975\n",
      "Epoch: 0486 cost = 0.311229429\n",
      "Validation Loss: 0.29170185\n",
      "Epoch: 0487 cost = 0.310551528\n",
      "Validation Loss: 0.30613655\n",
      "Epoch: 0488 cost = 0.309877336\n",
      "Validation Loss: 0.3077768\n",
      "Epoch: 0489 cost = 0.309206792\n",
      "Validation Loss: 0.30022267\n",
      "Epoch: 0490 cost = 0.308539906\n",
      "Validation Loss: 0.29376423\n",
      "Epoch: 0491 cost = 0.307876702\n",
      "Validation Loss: 0.29419768\n",
      "Epoch: 0492 cost = 0.307217066\n",
      "Validation Loss: 0.30349046\n",
      "Epoch: 0493 cost = 0.306561070\n",
      "Validation Loss: 0.30823058\n",
      "Epoch: 0494 cost = 0.305908676\n",
      "Validation Loss: 0.3075245\n",
      "Epoch: 0495 cost = 0.305259828\n",
      "Validation Loss: 0.3126053\n",
      "Epoch: 0496 cost = 0.304614527\n",
      "Validation Loss: 0.31269526\n",
      "Epoch: 0497 cost = 0.303972811\n",
      "Validation Loss: 0.3035258\n",
      "Epoch: 0498 cost = 0.303334568\n",
      "Validation Loss: 0.29566598\n",
      "Epoch: 0499 cost = 0.302699864\n",
      "Validation Loss: 0.2938593\n",
      "Epoch: 0500 cost = 0.302068685\n",
      "Validation Loss: 0.29331857\n",
      "Epoch: 0501 cost = 0.301440967\n",
      "Validation Loss: 0.29552177\n",
      "Epoch: 0502 cost = 0.300816659\n",
      "Validation Loss: 0.29706696\n",
      "Epoch: 0503 cost = 0.300195826\n",
      "Validation Loss: 0.30361938\n",
      "Epoch: 0504 cost = 0.299578445\n",
      "Validation Loss: 0.30103797\n",
      "Epoch: 0505 cost = 0.298964441\n",
      "Validation Loss: 0.32381108\n",
      "Epoch: 0506 cost = 0.298353817\n",
      "Validation Loss: 0.3456091\n",
      "Epoch: 0507 cost = 0.297746584\n",
      "Validation Loss: 0.3325975\n",
      "Epoch: 0508 cost = 0.297142714\n",
      "Validation Loss: 0.304074\n",
      "Epoch: 0509 cost = 0.296542236\n",
      "Validation Loss: 0.28548068\n",
      "Epoch: 0510 cost = 0.295945091\n",
      "Validation Loss: 0.3106221\n",
      "Epoch: 0511 cost = 0.295351220\n",
      "Validation Loss: 0.31845164\n",
      "Epoch: 0512 cost = 0.294760704\n",
      "Validation Loss: 0.30411708\n",
      "Epoch: 0513 cost = 0.294173456\n",
      "Validation Loss: 0.28803846\n",
      "Epoch: 0514 cost = 0.293589517\n",
      "Validation Loss: 0.2877824\n",
      "Epoch: 0515 cost = 0.293008813\n",
      "Validation Loss: 0.28741935\n",
      "Epoch: 0516 cost = 0.292431376\n",
      "Validation Loss: 0.2777595\n",
      "Epoch: 0517 cost = 0.291857164\n",
      "Validation Loss: 0.3045733\n",
      "Epoch: 0518 cost = 0.291286247\n",
      "Validation Loss: 0.2954012\n",
      "Epoch: 0519 cost = 0.290718411\n",
      "Validation Loss: 0.2906691\n",
      "Epoch: 0520 cost = 0.290153838\n",
      "Validation Loss: 0.29186597\n",
      "Epoch: 0521 cost = 0.289592479\n",
      "Validation Loss: 0.3085083\n",
      "Epoch: 0522 cost = 0.289034218\n",
      "Validation Loss: 0.31082284\n",
      "Epoch: 0523 cost = 0.288479209\n",
      "Validation Loss: 0.3075695\n",
      "Epoch: 0524 cost = 0.287927264\n",
      "Validation Loss: 0.2989491\n",
      "Epoch: 0525 cost = 0.287378481\n",
      "Validation Loss: 0.29473802\n",
      "Epoch: 0526 cost = 0.286832835\n",
      "Validation Loss: 0.28920445\n",
      "Epoch: 0527 cost = 0.286290224\n",
      "Validation Loss: 0.28100368\n",
      "Epoch: 0528 cost = 0.285750751\n",
      "Validation Loss: 0.27079296\n",
      "Epoch: 0529 cost = 0.285214375\n",
      "Validation Loss: 0.29140547\n",
      "Epoch: 0530 cost = 0.284681078\n",
      "Validation Loss: 0.28854364\n",
      "Epoch: 0531 cost = 0.284150781\n",
      "Validation Loss: 0.28591588\n",
      "Epoch: 0532 cost = 0.283623559\n",
      "Validation Loss: 0.28914714\n",
      "Epoch: 0533 cost = 0.283099370\n",
      "Validation Loss: 0.28125468\n",
      "Epoch: 0534 cost = 0.282578177\n",
      "Validation Loss: 0.27828386\n",
      "Epoch: 0535 cost = 0.282060006\n",
      "Validation Loss: 0.2734686\n",
      "Epoch: 0536 cost = 0.281544826\n",
      "Validation Loss: 0.26941472\n",
      "Epoch: 0537 cost = 0.281032637\n",
      "Validation Loss: 0.28556496\n",
      "Epoch: 0538 cost = 0.280523415\n",
      "Validation Loss: 0.26790923\n",
      "Epoch: 0539 cost = 0.280017150\n",
      "Validation Loss: 0.29343095\n",
      "Epoch: 0540 cost = 0.279513834\n",
      "Validation Loss: 0.26830325\n",
      "Epoch: 0541 cost = 0.279013451\n",
      "Validation Loss: 0.27963737\n",
      "Epoch: 0542 cost = 0.278515999\n",
      "Validation Loss: 0.27977088\n",
      "Epoch: 0543 cost = 0.278021440\n",
      "Validation Loss: 0.27312735\n",
      "Epoch: 0544 cost = 0.277529814\n",
      "Validation Loss: 0.27441046\n",
      "Epoch: 0545 cost = 0.277041065\n",
      "Validation Loss: 0.2783001\n",
      "Epoch: 0546 cost = 0.276555198\n",
      "Validation Loss: 0.2837286\n",
      "Epoch: 0547 cost = 0.276072172\n",
      "Validation Loss: 0.29199868\n",
      "Epoch: 0548 cost = 0.275592067\n",
      "Validation Loss: 0.27882972\n",
      "Epoch: 0549 cost = 0.275114726\n",
      "Validation Loss: 0.2726197\n",
      "Epoch: 0550 cost = 0.274640237\n",
      "Validation Loss: 0.27130157\n",
      "Epoch: 0551 cost = 0.274168559\n",
      "Validation Loss: 0.25702465\n",
      "Epoch: 0552 cost = 0.273699735\n",
      "Validation Loss: 0.28352487\n",
      "Epoch: 0553 cost = 0.273233720\n",
      "Validation Loss: 0.2647649\n",
      "Epoch: 0554 cost = 0.272770447\n",
      "Validation Loss: 0.2620376\n",
      "Epoch: 0555 cost = 0.272309993\n",
      "Validation Loss: 0.2657454\n",
      "Epoch: 0556 cost = 0.271852283\n",
      "Validation Loss: 0.26090637\n",
      "Epoch: 0557 cost = 0.271397331\n",
      "Validation Loss: 0.25413105\n",
      "Epoch: 0558 cost = 0.270945096\n",
      "Validation Loss: 0.26406184\n",
      "Epoch: 0559 cost = 0.270495666\n",
      "Validation Loss: 0.2530681\n",
      "Epoch: 0560 cost = 0.270048914\n",
      "Validation Loss: 0.2652192\n",
      "Epoch: 0561 cost = 0.269604872\n",
      "Validation Loss: 0.27013358\n",
      "Epoch: 0562 cost = 0.269163587\n",
      "Validation Loss: 0.27452552\n",
      "Epoch: 0563 cost = 0.268724931\n",
      "Validation Loss: 0.2611574\n",
      "Epoch: 0564 cost = 0.268288944\n",
      "Validation Loss: 0.27174175\n",
      "Epoch: 0565 cost = 0.267855659\n",
      "Validation Loss: 0.2551981\n",
      "Epoch: 0566 cost = 0.267425039\n",
      "Validation Loss: 0.25982314\n",
      "Epoch: 0567 cost = 0.266997065\n",
      "Validation Loss: 0.2687541\n",
      "Epoch: 0568 cost = 0.266571707\n",
      "Validation Loss: 0.2615294\n",
      "Epoch: 0569 cost = 0.266148997\n",
      "Validation Loss: 0.26819903\n",
      "Epoch: 0570 cost = 0.265728919\n",
      "Validation Loss: 0.2551754\n",
      "Epoch: 0571 cost = 0.265311448\n",
      "Validation Loss: 0.24974266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0572 cost = 0.264896544\n",
      "Validation Loss: 0.27045295\n",
      "Epoch: 0573 cost = 0.264484239\n",
      "Validation Loss: 0.26950997\n",
      "Epoch: 0574 cost = 0.264074521\n",
      "Validation Loss: 0.25878075\n",
      "Epoch: 0575 cost = 0.263667392\n",
      "Validation Loss: 0.24898328\n",
      "Epoch: 0576 cost = 0.263262798\n",
      "Validation Loss: 0.27740887\n",
      "Epoch: 0577 cost = 0.262860781\n",
      "Validation Loss: 0.26201716\n",
      "Epoch: 0578 cost = 0.262461247\n",
      "Validation Loss: 0.25991854\n",
      "Epoch: 0579 cost = 0.262064267\n",
      "Validation Loss: 0.25793156\n",
      "Epoch: 0580 cost = 0.261669802\n",
      "Validation Loss: 0.25392112\n",
      "Epoch: 0581 cost = 0.261277852\n",
      "Validation Loss: 0.25437757\n",
      "Epoch: 0582 cost = 0.260888389\n",
      "Validation Loss: 0.25808856\n",
      "Epoch: 0583 cost = 0.260501423\n",
      "Validation Loss: 0.2554072\n",
      "Epoch: 0584 cost = 0.260116926\n",
      "Validation Loss: 0.24443929\n",
      "Epoch: 0585 cost = 0.259734901\n",
      "Validation Loss: 0.26553452\n",
      "Epoch: 0586 cost = 0.259355343\n",
      "Validation Loss: 0.26039565\n",
      "Epoch: 0587 cost = 0.258978209\n",
      "Validation Loss: 0.2645198\n",
      "Epoch: 0588 cost = 0.258603552\n",
      "Validation Loss: 0.26623473\n",
      "Epoch: 0589 cost = 0.258231301\n",
      "Validation Loss: 0.2471495\n",
      "Epoch: 0590 cost = 0.257861487\n",
      "Validation Loss: 0.23789133\n",
      "Epoch: 0591 cost = 0.257494069\n",
      "Validation Loss: 0.24466765\n",
      "Epoch: 0592 cost = 0.257129094\n",
      "Validation Loss: 0.2618621\n",
      "Epoch: 0593 cost = 0.256766470\n",
      "Validation Loss: 0.27668452\n",
      "Epoch: 0594 cost = 0.256406218\n",
      "Validation Loss: 0.27226928\n",
      "Epoch: 0595 cost = 0.256048356\n",
      "Validation Loss: 0.25366572\n",
      "Epoch: 0596 cost = 0.255692859\n",
      "Validation Loss: 0.24251749\n",
      "Epoch: 0597 cost = 0.255339695\n",
      "Validation Loss: 0.24058521\n",
      "Epoch: 0598 cost = 0.254988913\n",
      "Validation Loss: 0.2319912\n",
      "Epoch: 0599 cost = 0.254640437\n",
      "Validation Loss: 0.2661667\n",
      "Epoch: 0600 cost = 0.254294272\n",
      "Validation Loss: 0.24204351\n",
      "Epoch: 0601 cost = 0.253950468\n",
      "Validation Loss: 0.24328634\n",
      "Epoch: 0602 cost = 0.253608940\n",
      "Validation Loss: 0.25720617\n",
      "Epoch: 0603 cost = 0.253269685\n",
      "Validation Loss: 0.24211603\n",
      "Epoch: 0604 cost = 0.252932783\n",
      "Validation Loss: 0.23283005\n",
      "Epoch: 0605 cost = 0.252598130\n",
      "Validation Loss: 0.24132577\n",
      "Epoch: 0606 cost = 0.252265739\n",
      "Validation Loss: 0.25119126\n",
      "Epoch: 0607 cost = 0.251935567\n",
      "Validation Loss: 0.25164422\n",
      "Epoch: 0608 cost = 0.251607701\n",
      "Validation Loss: 0.24642265\n",
      "Epoch: 0609 cost = 0.251282049\n",
      "Validation Loss: 0.23987144\n",
      "Epoch: 0610 cost = 0.250958611\n",
      "Validation Loss: 0.23948045\n",
      "Epoch: 0611 cost = 0.250637429\n",
      "Validation Loss: 0.24540497\n",
      "Epoch: 0612 cost = 0.250318457\n",
      "Validation Loss: 0.24528736\n",
      "Epoch: 0613 cost = 0.250001699\n",
      "Validation Loss: 0.23763202\n",
      "Epoch: 0614 cost = 0.249687167\n",
      "Validation Loss: 0.24182084\n",
      "Epoch: 0615 cost = 0.249374747\n",
      "Validation Loss: 0.25669792\n",
      "Epoch: 0616 cost = 0.249064539\n",
      "Validation Loss: 0.27209583\n",
      "Epoch: 0617 cost = 0.248756456\n",
      "Validation Loss: 0.27555144\n",
      "Epoch: 0618 cost = 0.248450550\n",
      "Validation Loss: 0.26260138\n",
      "Epoch: 0619 cost = 0.248146811\n",
      "Validation Loss: 0.2502664\n",
      "Epoch: 0620 cost = 0.247845198\n",
      "Validation Loss: 0.23180129\n",
      "Epoch: 0621 cost = 0.247545751\n",
      "Validation Loss: 0.23124887\n",
      "Epoch: 0622 cost = 0.247248375\n",
      "Validation Loss: 0.24454217\n",
      "Epoch: 0623 cost = 0.246953143\n",
      "Validation Loss: 0.23238495\n",
      "Epoch: 0624 cost = 0.246660003\n",
      "Validation Loss: 0.24511911\n",
      "Epoch: 0625 cost = 0.246368911\n",
      "Validation Loss: 0.2364554\n",
      "Epoch: 0626 cost = 0.246079922\n",
      "Validation Loss: 0.23721984\n",
      "Epoch: 0627 cost = 0.245793057\n",
      "Validation Loss: 0.23469675\n",
      "Epoch: 0628 cost = 0.245508192\n",
      "Validation Loss: 0.24121688\n",
      "Epoch: 0629 cost = 0.245225451\n",
      "Validation Loss: 0.24726857\n",
      "Epoch: 0630 cost = 0.244944700\n",
      "Validation Loss: 0.25330517\n",
      "Epoch: 0631 cost = 0.244665980\n",
      "Validation Loss: 0.2504763\n",
      "Epoch: 0632 cost = 0.244389319\n",
      "Validation Loss: 0.24511135\n",
      "Epoch: 0633 cost = 0.244114627\n",
      "Validation Loss: 0.23459917\n",
      "Epoch: 0634 cost = 0.243841982\n",
      "Validation Loss: 0.23126987\n",
      "Epoch: 0635 cost = 0.243571337\n",
      "Validation Loss: 0.23177624\n",
      "Epoch: 0636 cost = 0.243302643\n",
      "Validation Loss: 0.23382877\n",
      "Epoch: 0637 cost = 0.243035957\n",
      "Validation Loss: 0.23306383\n",
      "Epoch: 0638 cost = 0.242771276\n",
      "Validation Loss: 0.23831059\n",
      "Epoch: 0639 cost = 0.242508499\n",
      "Validation Loss: 0.2348675\n",
      "Epoch: 0640 cost = 0.242247686\n",
      "Validation Loss: 0.24437568\n",
      "Epoch: 0641 cost = 0.241988819\n",
      "Validation Loss: 0.25024658\n",
      "Epoch: 0642 cost = 0.241731884\n",
      "Validation Loss: 0.24716902\n",
      "Epoch: 0643 cost = 0.241476874\n",
      "Validation Loss: 0.23005779\n",
      "Epoch: 0644 cost = 0.241223767\n",
      "Validation Loss: 0.24021468\n",
      "Epoch: 0645 cost = 0.240972598\n",
      "Validation Loss: 0.24331468\n",
      "Epoch: 0646 cost = 0.240723261\n",
      "Validation Loss: 0.23691557\n",
      "Epoch: 0647 cost = 0.240475821\n",
      "Validation Loss: 0.24110784\n",
      "Epoch: 0648 cost = 0.240230288\n",
      "Validation Loss: 0.2442857\n",
      "Epoch: 0649 cost = 0.239986581\n",
      "Validation Loss: 0.23836184\n",
      "Epoch: 0650 cost = 0.239744778\n",
      "Validation Loss: 0.2481275\n",
      "Epoch: 0651 cost = 0.239504769\n",
      "Validation Loss: 0.251667\n",
      "Epoch: 0652 cost = 0.239266643\n",
      "Validation Loss: 0.23807934\n",
      "Epoch: 0653 cost = 0.239030287\n",
      "Validation Loss: 0.22182621\n",
      "Epoch: 0654 cost = 0.238795776\n",
      "Validation Loss: 0.24406967\n",
      "Epoch: 0655 cost = 0.238563057\n",
      "Validation Loss: 0.24136984\n",
      "Epoch: 0656 cost = 0.238332137\n",
      "Validation Loss: 0.2395923\n",
      "Epoch: 0657 cost = 0.238103002\n",
      "Validation Loss: 0.23763832\n",
      "Epoch: 0658 cost = 0.237875657\n",
      "Validation Loss: 0.25319612\n",
      "Epoch: 0659 cost = 0.237650071\n",
      "Validation Loss: 0.24498436\n",
      "Epoch: 0660 cost = 0.237426230\n",
      "Validation Loss: 0.22279449\n",
      "Epoch: 0661 cost = 0.237204141\n",
      "Validation Loss: 0.22666068\n",
      "Epoch: 0662 cost = 0.236983782\n",
      "Validation Loss: 0.22554247\n",
      "Epoch: 0663 cost = 0.236765159\n",
      "Validation Loss: 0.23573425\n",
      "Epoch: 0664 cost = 0.236548268\n",
      "Validation Loss: 0.23549671\n",
      "Epoch: 0665 cost = 0.236333042\n",
      "Validation Loss: 0.24103224\n",
      "Epoch: 0666 cost = 0.236119560\n",
      "Validation Loss: 0.23359327\n",
      "Epoch: 0667 cost = 0.235907697\n",
      "Validation Loss: 0.23075242\n",
      "Epoch: 0668 cost = 0.235697570\n",
      "Validation Loss: 0.23047855\n",
      "Epoch: 0669 cost = 0.235489073\n",
      "Validation Loss: 0.23330295\n",
      "Epoch: 0670 cost = 0.235282221\n",
      "Validation Loss: 0.23929355\n",
      "Epoch: 0671 cost = 0.235077068\n",
      "Validation Loss: 0.23592834\n",
      "Epoch: 0672 cost = 0.234873516\n",
      "Validation Loss: 0.22921175\n",
      "Epoch: 0673 cost = 0.234671591\n",
      "Validation Loss: 0.22872233\n",
      "Epoch: 0674 cost = 0.234471272\n",
      "Validation Loss: 0.2299643\n",
      "Epoch: 0675 cost = 0.234272561\n",
      "Validation Loss: 0.2298421\n",
      "Epoch: 0676 cost = 0.234075463\n",
      "Validation Loss: 0.23076949\n",
      "Epoch: 0677 cost = 0.233879934\n",
      "Validation Loss: 0.2275347\n",
      "Epoch: 0678 cost = 0.233685964\n",
      "Validation Loss: 0.22912683\n",
      "Epoch: 0679 cost = 0.233493579\n",
      "Validation Loss: 0.23333491\n",
      "Epoch: 0680 cost = 0.233302740\n",
      "Validation Loss: 0.23437344\n",
      "Epoch: 0681 cost = 0.233113406\n",
      "Validation Loss: 0.22830278\n",
      "Epoch: 0682 cost = 0.232925656\n",
      "Validation Loss: 0.23567748\n",
      "Epoch: 0683 cost = 0.232739380\n",
      "Validation Loss: 0.23100482\n",
      "Epoch: 0684 cost = 0.232554646\n",
      "Validation Loss: 0.22953351\n",
      "Epoch: 0685 cost = 0.232371424\n",
      "Validation Loss: 0.22509299\n",
      "Epoch: 0686 cost = 0.232189664\n",
      "Validation Loss: 0.21823463\n",
      "Epoch: 0687 cost = 0.232009432\n",
      "Validation Loss: 0.22853768\n",
      "Epoch: 0688 cost = 0.231830625\n",
      "Validation Loss: 0.21649265\n",
      "Epoch: 0689 cost = 0.231653245\n",
      "Validation Loss: 0.2381552\n",
      "Epoch: 0690 cost = 0.231477414\n",
      "Validation Loss: 0.2282903\n",
      "Epoch: 0691 cost = 0.231302926\n",
      "Validation Loss: 0.22442937\n",
      "Epoch: 0692 cost = 0.231129923\n",
      "Validation Loss: 0.22391611\n",
      "Epoch: 0693 cost = 0.230958287\n",
      "Validation Loss: 0.21955898\n",
      "Epoch: 0694 cost = 0.230788127\n",
      "Validation Loss: 0.22140811\n",
      "Epoch: 0695 cost = 0.230619343\n",
      "Validation Loss: 0.21777222\n",
      "Epoch: 0696 cost = 0.230451933\n",
      "Validation Loss: 0.21760696\n",
      "Epoch: 0697 cost = 0.230285911\n",
      "Validation Loss: 0.22999083\n",
      "Epoch: 0698 cost = 0.230121255\n",
      "Validation Loss: 0.24220407\n",
      "Epoch: 0699 cost = 0.229957911\n",
      "Validation Loss: 0.23950043\n",
      "Epoch: 0700 cost = 0.229796012\n",
      "Validation Loss: 0.23612872\n",
      "Epoch: 0701 cost = 0.229635392\n",
      "Validation Loss: 0.24030632\n",
      "Epoch: 0702 cost = 0.229476099\n",
      "Validation Loss: 0.24402712\n",
      "Epoch: 0703 cost = 0.229318146\n",
      "Validation Loss: 0.25244787\n",
      "Epoch: 0704 cost = 0.229161475\n",
      "Validation Loss: 0.24346027\n",
      "Epoch: 0705 cost = 0.229006090\n",
      "Validation Loss: 0.2329419\n",
      "Epoch: 0706 cost = 0.228852044\n",
      "Validation Loss: 0.23099443\n",
      "Epoch: 0707 cost = 0.228699235\n",
      "Validation Loss: 0.22065328\n",
      "Epoch: 0708 cost = 0.228547748\n",
      "Validation Loss: 0.21888289\n",
      "Epoch: 0709 cost = 0.228397457\n",
      "Validation Loss: 0.22771814\n",
      "Epoch: 0710 cost = 0.228248443\n",
      "Validation Loss: 0.22126785\n",
      "Epoch: 0711 cost = 0.228100657\n",
      "Validation Loss: 0.2168345\n",
      "Epoch: 0712 cost = 0.227954107\n",
      "Validation Loss: 0.21644177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0713 cost = 0.227808761\n",
      "Validation Loss: 0.22965649\n",
      "Epoch: 0714 cost = 0.227664671\n",
      "Validation Loss: 0.22002734\n",
      "Epoch: 0715 cost = 0.227521741\n",
      "Validation Loss: 0.21829727\n",
      "Epoch: 0716 cost = 0.227380010\n",
      "Validation Loss: 0.21949622\n",
      "Epoch: 0717 cost = 0.227239473\n",
      "Validation Loss: 0.22108863\n",
      "Epoch: 0718 cost = 0.227100070\n",
      "Validation Loss: 0.22338107\n",
      "Epoch: 0719 cost = 0.226961866\n",
      "Validation Loss: 0.2317049\n",
      "Epoch: 0720 cost = 0.226824788\n",
      "Validation Loss: 0.22046438\n",
      "Epoch: 0721 cost = 0.226688883\n",
      "Validation Loss: 0.21982084\n",
      "Epoch: 0722 cost = 0.226554072\n",
      "Validation Loss: 0.21644153\n",
      "Epoch: 0723 cost = 0.226420428\n",
      "Validation Loss: 0.23245835\n",
      "Epoch: 0724 cost = 0.226287874\n",
      "Validation Loss: 0.2232938\n",
      "Epoch: 0725 cost = 0.226156465\n",
      "Validation Loss: 0.21687111\n",
      "Epoch: 0726 cost = 0.226026099\n",
      "Validation Loss: 0.21750309\n",
      "Epoch: 0727 cost = 0.225896835\n",
      "Validation Loss: 0.21768431\n",
      "Epoch: 0728 cost = 0.225768683\n",
      "Validation Loss: 0.21608496\n",
      "Epoch: 0729 cost = 0.225641591\n",
      "Validation Loss: 0.22959405\n",
      "Epoch: 0730 cost = 0.225515566\n",
      "Validation Loss: 0.22170785\n",
      "Epoch: 0731 cost = 0.225390590\n",
      "Validation Loss: 0.21710783\n",
      "Epoch: 0732 cost = 0.225266608\n",
      "Validation Loss: 0.21826723\n",
      "Epoch: 0733 cost = 0.225143703\n",
      "Validation Loss: 0.21710914\n",
      "Epoch: 0734 cost = 0.225021822\n",
      "Validation Loss: 0.22015582\n",
      "Epoch: 0735 cost = 0.224900959\n",
      "Validation Loss: 0.22072789\n",
      "Epoch: 0736 cost = 0.224781104\n",
      "Validation Loss: 0.21414146\n",
      "Epoch: 0737 cost = 0.224662227\n",
      "Validation Loss: 0.22982903\n",
      "Epoch: 0738 cost = 0.224544400\n",
      "Validation Loss: 0.22655168\n",
      "Epoch: 0739 cost = 0.224427487\n",
      "Validation Loss: 0.21983375\n",
      "Epoch: 0740 cost = 0.224311605\n",
      "Validation Loss: 0.227378\n",
      "Epoch: 0741 cost = 0.224196664\n",
      "Validation Loss: 0.21662188\n",
      "Epoch: 0742 cost = 0.224082657\n",
      "Validation Loss: 0.21500038\n",
      "Epoch: 0743 cost = 0.223969630\n",
      "Validation Loss: 0.21022281\n",
      "Epoch: 0744 cost = 0.223857535\n",
      "Validation Loss: 0.23162024\n",
      "Epoch: 0745 cost = 0.223746374\n",
      "Validation Loss: 0.22130527\n",
      "Epoch: 0746 cost = 0.223636138\n",
      "Validation Loss: 0.22176579\n",
      "Epoch: 0747 cost = 0.223526842\n",
      "Validation Loss: 0.22300275\n",
      "Epoch: 0748 cost = 0.223418442\n",
      "Validation Loss: 0.2284691\n",
      "Epoch: 0749 cost = 0.223310905\n",
      "Validation Loss: 0.21973822\n",
      "Epoch: 0750 cost = 0.223204323\n",
      "Validation Loss: 0.21662347\n",
      "Epoch: 0751 cost = 0.223098578\n",
      "Validation Loss: 0.22034901\n",
      "Epoch: 0752 cost = 0.222993714\n",
      "Validation Loss: 0.219182\n",
      "Epoch: 0753 cost = 0.222889766\n",
      "Validation Loss: 0.21824174\n",
      "Epoch: 0754 cost = 0.222786618\n",
      "Validation Loss: 0.21373849\n",
      "Epoch: 0755 cost = 0.222684337\n",
      "Validation Loss: 0.21002987\n",
      "Epoch: 0756 cost = 0.222582896\n",
      "Validation Loss: 0.22916883\n",
      "Epoch: 0757 cost = 0.222482330\n",
      "Validation Loss: 0.22016531\n",
      "Epoch: 0758 cost = 0.222382563\n",
      "Validation Loss: 0.2173136\n",
      "Epoch: 0759 cost = 0.222283642\n",
      "Validation Loss: 0.21243174\n",
      "Epoch: 0760 cost = 0.222185507\n",
      "Validation Loss: 0.2129486\n",
      "Epoch: 0761 cost = 0.222088199\n",
      "Validation Loss: 0.21224391\n",
      "Epoch: 0762 cost = 0.221991716\n",
      "Validation Loss: 0.21490793\n",
      "Epoch: 0763 cost = 0.221895995\n",
      "Validation Loss: 0.21565627\n",
      "Epoch: 0764 cost = 0.221801092\n",
      "Validation Loss: 0.21151407\n",
      "Epoch: 0765 cost = 0.221706925\n",
      "Validation Loss: 0.20898157\n",
      "Epoch: 0766 cost = 0.221613569\n",
      "Validation Loss: 0.22614773\n",
      "Epoch: 0767 cost = 0.221520948\n",
      "Validation Loss: 0.22116914\n",
      "Epoch: 0768 cost = 0.221429093\n",
      "Validation Loss: 0.21527603\n",
      "Epoch: 0769 cost = 0.221337974\n",
      "Validation Loss: 0.21202312\n",
      "Epoch: 0770 cost = 0.221247616\n",
      "Validation Loss: 0.2094751\n",
      "Epoch: 0771 cost = 0.221157991\n",
      "Validation Loss: 0.21015571\n",
      "Epoch: 0772 cost = 0.221069095\n",
      "Validation Loss: 0.2071913\n",
      "Epoch: 0773 cost = 0.220980915\n",
      "Validation Loss: 0.22658314\n",
      "Epoch: 0774 cost = 0.220893449\n",
      "Validation Loss: 0.21912707\n",
      "Epoch: 0775 cost = 0.220806701\n",
      "Validation Loss: 0.21763393\n",
      "Epoch: 0776 cost = 0.220720632\n",
      "Validation Loss: 0.21449041\n",
      "Epoch: 0777 cost = 0.220635261\n",
      "Validation Loss: 0.21215971\n",
      "Epoch: 0778 cost = 0.220550575\n",
      "Validation Loss: 0.20689972\n",
      "Epoch: 0779 cost = 0.220466578\n",
      "Validation Loss: 0.22761703\n",
      "Epoch: 0780 cost = 0.220383248\n",
      "Validation Loss: 0.22096682\n",
      "Epoch: 0781 cost = 0.220300600\n",
      "Validation Loss: 0.21419857\n",
      "Epoch: 0782 cost = 0.220218599\n",
      "Validation Loss: 0.21456125\n",
      "Epoch: 0783 cost = 0.220137217\n",
      "Validation Loss: 0.20982288\n",
      "Epoch: 0784 cost = 0.220056508\n",
      "Validation Loss: 0.210387\n",
      "Epoch: 0785 cost = 0.219976421\n",
      "Validation Loss: 0.2077918\n",
      "Epoch: 0786 cost = 0.219896945\n",
      "Validation Loss: 0.20614335\n",
      "Epoch: 0787 cost = 0.219818113\n",
      "Validation Loss: 0.22893497\n",
      "Epoch: 0788 cost = 0.219739856\n",
      "Validation Loss: 0.21895908\n",
      "Epoch: 0789 cost = 0.219662228\n",
      "Validation Loss: 0.2129991\n",
      "Epoch: 0790 cost = 0.219585172\n",
      "Validation Loss: 0.21552491\n",
      "Epoch: 0791 cost = 0.219508708\n",
      "Validation Loss: 0.21316153\n",
      "Epoch: 0792 cost = 0.219432805\n",
      "Validation Loss: 0.2098298\n",
      "Epoch: 0793 cost = 0.219357452\n",
      "Validation Loss: 0.21056919\n",
      "Epoch: 0794 cost = 0.219282680\n",
      "Validation Loss: 0.21295248\n",
      "Epoch: 0795 cost = 0.219208398\n",
      "Validation Loss: 0.20721175\n",
      "Epoch: 0796 cost = 0.219134659\n",
      "Validation Loss: 0.20464066\n",
      "Epoch: 0797 cost = 0.219061413\n",
      "Validation Loss: 0.22519301\n",
      "Epoch: 0798 cost = 0.218988670\n",
      "Validation Loss: 0.21221745\n",
      "Epoch: 0799 cost = 0.218916359\n",
      "Validation Loss: 0.20999898\n",
      "Epoch: 0800 cost = 0.218844465\n",
      "Validation Loss: 0.21354976\n",
      "Epoch: 0801 cost = 0.218772978\n",
      "Validation Loss: 0.21374714\n",
      "Epoch: 0802 cost = 0.218701891\n",
      "Validation Loss: 0.2099465\n",
      "Epoch: 0803 cost = 0.218631110\n",
      "Validation Loss: 0.21022822\n",
      "Epoch: 0804 cost = 0.218560591\n",
      "Validation Loss: 0.21004802\n",
      "Epoch: 0805 cost = 0.218490279\n",
      "Validation Loss: 0.20982881\n",
      "Epoch: 0806 cost = 0.218420054\n",
      "Validation Loss: 0.21267103\n",
      "Epoch: 0807 cost = 0.218349857\n",
      "Validation Loss: 0.2130735\n",
      "Epoch: 0808 cost = 0.218279515\n",
      "Validation Loss: 0.21527706\n",
      "Epoch: 0809 cost = 0.218208852\n",
      "Validation Loss: 0.21223785\n",
      "Epoch: 0810 cost = 0.218137692\n",
      "Validation Loss: 0.20736423\n",
      "Epoch: 0811 cost = 0.218065734\n",
      "Validation Loss: 0.20808172\n",
      "Epoch: 0812 cost = 0.217992780\n",
      "Validation Loss: 0.20862907\n",
      "Epoch: 0813 cost = 0.217918473\n",
      "Validation Loss: 0.2083929\n",
      "Epoch: 0814 cost = 0.217842541\n",
      "Validation Loss: 0.21308096\n",
      "Epoch: 0815 cost = 0.217764539\n",
      "Validation Loss: 0.21571071\n",
      "Epoch: 0816 cost = 0.217683909\n",
      "Validation Loss: 0.2207311\n",
      "Epoch: 0817 cost = 0.217599209\n",
      "Validation Loss: 0.21671046\n",
      "Epoch: 0818 cost = 0.217507169\n",
      "Validation Loss: 0.2119064\n",
      "Epoch: 0819 cost = 0.217400149\n",
      "Validation Loss: 0.20346978\n",
      "Epoch: 0820 cost = 0.217258281\n",
      "Validation Loss: 0.21592446\n",
      "Epoch: 0821 cost = 0.217025461\n",
      "Validation Loss: 0.2041199\n",
      "Epoch: 0822 cost = 0.216544626\n",
      "Validation Loss: 0.20044914\n",
      "Epoch: 0823 cost = 0.215827410\n",
      "Validation Loss: 0.20965612\n",
      "Epoch: 0824 cost = 0.215509327\n",
      "Validation Loss: 0.2025114\n",
      "Epoch: 0825 cost = 0.215315978\n",
      "Validation Loss: 0.20283845\n",
      "Epoch: 0826 cost = 0.215145656\n",
      "Validation Loss: 0.20164803\n",
      "Epoch: 0827 cost = 0.215014683\n",
      "Validation Loss: 0.20161867\n",
      "Epoch: 0828 cost = 0.214916212\n",
      "Validation Loss: 0.20528343\n",
      "Epoch: 0829 cost = 0.214820319\n",
      "Validation Loss: 0.20713116\n",
      "Epoch: 0830 cost = 0.214727087\n",
      "Validation Loss: 0.20901237\n",
      "Epoch: 0831 cost = 0.214642416\n",
      "Validation Loss: 0.20461449\n",
      "Epoch: 0832 cost = 0.214560102\n",
      "Validation Loss: 0.20156083\n",
      "Epoch: 0833 cost = 0.214473716\n",
      "Validation Loss: 0.20002861\n",
      "Epoch: 0834 cost = 0.214383181\n",
      "Validation Loss: 0.20838644\n",
      "Epoch: 0835 cost = 0.214287626\n",
      "Validation Loss: 0.20517012\n",
      "Epoch: 0836 cost = 0.214180597\n",
      "Validation Loss: 0.20722476\n",
      "Epoch: 0837 cost = 0.214049616\n",
      "Validation Loss: 0.20606217\n",
      "Epoch: 0838 cost = 0.213863941\n",
      "Validation Loss: 0.20713353\n",
      "Epoch: 0839 cost = 0.213518234\n",
      "Validation Loss: 0.20115575\n",
      "Epoch: 0840 cost = 0.212496907\n",
      "Validation Loss: 0.19815215\n",
      "Epoch: 0841 cost = 0.208586267\n",
      "Validation Loss: 0.20110373\n",
      "Epoch: 0842 cost = 0.201763198\n",
      "Validation Loss: 0.19846816\n",
      "Epoch: 0843 cost = 0.198683221\n",
      "Validation Loss: 0.20147677\n",
      "Epoch: 0844 cost = 0.197275851\n",
      "Validation Loss: 0.19940943\n",
      "Epoch: 0845 cost = 0.196247471\n",
      "Validation Loss: 0.20026071\n",
      "Epoch: 0846 cost = 0.195660408\n",
      "Validation Loss: 0.20088747\n",
      "Epoch: 0847 cost = 0.195352803\n",
      "Validation Loss: 0.19993465\n",
      "Epoch: 0848 cost = 0.195049342\n",
      "Validation Loss: 0.19865166\n",
      "Epoch: 0849 cost = 0.194772243\n",
      "Validation Loss: 0.19903284\n",
      "Epoch: 0850 cost = 0.194542420\n",
      "Validation Loss: 0.20054753\n",
      "Epoch: 0851 cost = 0.194314705\n",
      "Validation Loss: 0.20159143\n",
      "Epoch: 0852 cost = 0.194054673\n",
      "Validation Loss: 0.20384969\n",
      "Epoch: 0853 cost = 0.193770560\n",
      "Validation Loss: 0.20028043\n",
      "Epoch: 0854 cost = 0.193473025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.19802704\n",
      "Epoch: 0855 cost = 0.193169413\n",
      "Validation Loss: 0.20096077\n",
      "Epoch: 0856 cost = 0.192878758\n",
      "Validation Loss: 0.20021312\n",
      "Epoch: 0857 cost = 0.192621811\n",
      "Validation Loss: 0.19972025\n",
      "Epoch: 0858 cost = 0.192402540\n",
      "Validation Loss: 0.19847421\n",
      "Epoch: 0859 cost = 0.192211250\n",
      "Validation Loss: 0.19927076\n",
      "Epoch: 0860 cost = 0.192038325\n",
      "Validation Loss: 0.19906269\n",
      "Epoch: 0861 cost = 0.191878852\n",
      "Validation Loss: 0.19805558\n",
      "Epoch: 0862 cost = 0.191730721\n",
      "Validation Loss: 0.19908336\n",
      "Epoch: 0863 cost = 0.191592978\n",
      "Validation Loss: 0.20187856\n",
      "Epoch: 0864 cost = 0.191464409\n",
      "Validation Loss: 0.19835429\n",
      "Epoch: 0865 cost = 0.191343366\n",
      "Validation Loss: 0.19726984\n",
      "Epoch: 0866 cost = 0.191228186\n",
      "Validation Loss: 0.20079708\n",
      "Epoch: 0867 cost = 0.191117387\n",
      "Validation Loss: 0.20040904\n",
      "Epoch: 0868 cost = 0.191009682\n",
      "Validation Loss: 0.19970024\n",
      "Epoch: 0869 cost = 0.190903593\n",
      "Validation Loss: 0.19812517\n",
      "Epoch: 0870 cost = 0.190797647\n",
      "Validation Loss: 0.20034847\n",
      "Epoch: 0871 cost = 0.190689740\n",
      "Validation Loss: 0.1986552\n",
      "Epoch: 0872 cost = 0.190576592\n",
      "Validation Loss: 0.19878182\n",
      "Epoch: 0873 cost = 0.190451890\n",
      "Validation Loss: 0.19815373\n",
      "Epoch: 0874 cost = 0.190302413\n",
      "Validation Loss: 0.1969571\n",
      "Epoch: 0875 cost = 0.190096095\n",
      "Validation Loss: 0.20026268\n",
      "Epoch: 0876 cost = 0.189753776\n",
      "Validation Loss: 0.2007291\n",
      "Epoch: 0877 cost = 0.189073898\n",
      "Validation Loss: 0.19732058\n",
      "Epoch: 0878 cost = 0.187630997\n",
      "Validation Loss: 0.19739419\n",
      "Epoch: 0879 cost = 0.185667479\n",
      "Validation Loss: 0.19753876\n",
      "Epoch: 0880 cost = 0.184315493\n",
      "Validation Loss: 0.19703406\n",
      "Epoch: 0881 cost = 0.183550537\n",
      "Validation Loss: 0.1955366\n",
      "Epoch: 0882 cost = 0.182909682\n",
      "Validation Loss: 0.20150284\n",
      "Epoch: 0883 cost = 0.182259487\n",
      "Validation Loss: 0.19766226\n",
      "Epoch: 0884 cost = 0.181564236\n",
      "Validation Loss: 0.19759442\n",
      "Epoch: 0885 cost = 0.180764045\n",
      "Validation Loss: 0.196148\n",
      "Epoch: 0886 cost = 0.179849598\n",
      "Validation Loss: 0.19335742\n",
      "Epoch: 0887 cost = 0.178905999\n",
      "Validation Loss: 0.1988641\n",
      "Epoch: 0888 cost = 0.178044500\n",
      "Validation Loss: 0.19018376\n",
      "Epoch: 0889 cost = 0.177292501\n",
      "Validation Loss: 0.19826645\n",
      "Epoch: 0890 cost = 0.176608012\n",
      "Validation Loss: 0.19226427\n",
      "Epoch: 0891 cost = 0.175946159\n",
      "Validation Loss: 0.19544628\n",
      "Epoch: 0892 cost = 0.175270107\n",
      "Validation Loss: 0.20731679\n",
      "Epoch: 0893 cost = 0.174532913\n",
      "Validation Loss: 0.19412044\n",
      "Epoch: 0894 cost = 0.173641294\n",
      "Validation Loss: 0.1907259\n",
      "Epoch: 0895 cost = 0.172449903\n",
      "Validation Loss: 0.18939918\n",
      "Epoch: 0896 cost = 0.170927845\n",
      "Validation Loss: 0.21220209\n",
      "Epoch: 0897 cost = 0.169203979\n",
      "Validation Loss: 0.1934525\n",
      "Epoch: 0898 cost = 0.167198043\n",
      "Validation Loss: 0.18575916\n",
      "Epoch: 0899 cost = 0.165524461\n",
      "Validation Loss: 0.19096795\n",
      "Epoch: 0900 cost = 0.164289583\n",
      "Validation Loss: 0.17547365\n",
      "Epoch: 0901 cost = 0.163240463\n",
      "Validation Loss: 0.24455142\n",
      "Epoch: 0902 cost = 0.162337513\n",
      "Validation Loss: 0.24653694\n",
      "Epoch: 0903 cost = 0.161531163\n",
      "Validation Loss: 0.19777763\n",
      "Epoch: 0904 cost = 0.160804549\n",
      "Validation Loss: 0.2132066\n",
      "Epoch: 0905 cost = 0.160129059\n",
      "Validation Loss: 0.21794988\n",
      "Epoch: 0906 cost = 0.159423125\n",
      "Validation Loss: 0.23336256\n",
      "Epoch: 0907 cost = 0.158543118\n",
      "Validation Loss: 0.2048647\n",
      "Epoch: 0908 cost = 0.157256512\n",
      "Validation Loss: 0.20649393\n",
      "Epoch: 0909 cost = 0.155454954\n",
      "Validation Loss: 0.21979368\n",
      "Epoch: 0910 cost = 0.153923889\n",
      "Validation Loss: 0.16407365\n",
      "Epoch: 0911 cost = 0.153061279\n",
      "Validation Loss: 0.20056577\n",
      "Epoch: 0912 cost = 0.152179557\n",
      "Validation Loss: 0.1782395\n",
      "Epoch: 0913 cost = 0.151395454\n",
      "Validation Loss: 0.16665955\n",
      "Epoch: 0914 cost = 0.150712744\n",
      "Validation Loss: 0.13858959\n",
      "Epoch: 0915 cost = 0.150112136\n",
      "Validation Loss: 0.16596667\n",
      "Epoch: 0916 cost = 0.149596204\n",
      "Validation Loss: 0.14761698\n",
      "Epoch: 0917 cost = 0.149139212\n",
      "Validation Loss: 0.15316811\n",
      "Epoch: 0918 cost = 0.148733228\n",
      "Validation Loss: 0.18642321\n",
      "Epoch: 0919 cost = 0.148376888\n",
      "Validation Loss: 0.20780668\n",
      "Epoch: 0920 cost = 0.148055565\n",
      "Validation Loss: 0.17973657\n",
      "Epoch: 0921 cost = 0.147752946\n",
      "Validation Loss: 0.20318414\n",
      "Epoch: 0922 cost = 0.147465855\n",
      "Validation Loss: 0.15881535\n",
      "Epoch: 0923 cost = 0.147196068\n",
      "Validation Loss: 0.13442075\n",
      "Epoch: 0924 cost = 0.146945197\n",
      "Validation Loss: 0.15017878\n",
      "Epoch: 0925 cost = 0.146709119\n",
      "Validation Loss: 0.1325813\n",
      "Epoch: 0926 cost = 0.146486222\n",
      "Validation Loss: 0.15946668\n",
      "Epoch: 0927 cost = 0.146274119\n",
      "Validation Loss: 0.14286238\n",
      "Epoch: 0928 cost = 0.146072119\n",
      "Validation Loss: 0.13076964\n",
      "Epoch: 0929 cost = 0.145879225\n",
      "Validation Loss: 0.15472126\n",
      "Epoch: 0930 cost = 0.145694819\n",
      "Validation Loss: 0.13885786\n",
      "Epoch: 0931 cost = 0.145517897\n",
      "Validation Loss: 0.15342957\n",
      "Epoch: 0932 cost = 0.145348011\n",
      "Validation Loss: 0.20510997\n",
      "Epoch: 0933 cost = 0.145184551\n",
      "Validation Loss: 0.16469748\n",
      "Epoch: 0934 cost = 0.145027038\n",
      "Validation Loss: 0.16010918\n",
      "Epoch: 0935 cost = 0.144875058\n",
      "Validation Loss: 0.21899432\n",
      "Epoch: 0936 cost = 0.144728235\n",
      "Validation Loss: 0.1540196\n",
      "Epoch: 0937 cost = 0.144586248\n",
      "Validation Loss: 0.14867046\n",
      "Epoch: 0938 cost = 0.144448674\n",
      "Validation Loss: 0.1315946\n",
      "Epoch: 0939 cost = 0.144315456\n",
      "Validation Loss: 0.13745557\n",
      "Epoch: 0940 cost = 0.144186172\n",
      "Validation Loss: 0.12920007\n",
      "Epoch: 0941 cost = 0.144060629\n",
      "Validation Loss: 0.16396241\n",
      "Epoch: 0942 cost = 0.143938702\n",
      "Validation Loss: 0.144985\n",
      "Epoch: 0943 cost = 0.143820117\n",
      "Validation Loss: 0.13341056\n",
      "Epoch: 0944 cost = 0.143704729\n",
      "Validation Loss: 0.13624342\n",
      "Epoch: 0945 cost = 0.143592317\n",
      "Validation Loss: 0.12802872\n",
      "Epoch: 0946 cost = 0.143482895\n",
      "Validation Loss: 0.14880796\n",
      "Epoch: 0947 cost = 0.143376195\n",
      "Validation Loss: 0.1326262\n",
      "Epoch: 0948 cost = 0.143272102\n",
      "Validation Loss: 0.12797329\n",
      "Epoch: 0949 cost = 0.143170453\n",
      "Validation Loss: 0.17442577\n",
      "Epoch: 0950 cost = 0.143071304\n",
      "Validation Loss: 0.16348334\n",
      "Epoch: 0951 cost = 0.142974383\n",
      "Validation Loss: 0.1410006\n",
      "Epoch: 0952 cost = 0.142879669\n",
      "Validation Loss: 0.13479383\n",
      "Epoch: 0953 cost = 0.142787074\n",
      "Validation Loss: 0.13688852\n",
      "Epoch: 0954 cost = 0.142696518\n",
      "Validation Loss: 0.13308026\n",
      "Epoch: 0955 cost = 0.142607939\n",
      "Validation Loss: 0.12399128\n",
      "Epoch: 0956 cost = 0.142521186\n",
      "Validation Loss: 0.15757734\n",
      "Epoch: 0957 cost = 0.142436208\n",
      "Validation Loss: 0.1398008\n",
      "Epoch: 0958 cost = 0.142352995\n",
      "Validation Loss: 0.12897749\n",
      "Epoch: 0959 cost = 0.142271494\n",
      "Validation Loss: 0.12571913\n",
      "Epoch: 0960 cost = 0.142191574\n",
      "Validation Loss: 0.12823509\n",
      "Epoch: 0961 cost = 0.142113186\n",
      "Validation Loss: 0.12965022\n",
      "Epoch: 0962 cost = 0.142036333\n",
      "Validation Loss: 0.12673396\n",
      "Epoch: 0963 cost = 0.141960960\n",
      "Validation Loss: 0.15186958\n",
      "Epoch: 0964 cost = 0.141886908\n",
      "Validation Loss: 0.16938902\n",
      "Epoch: 0965 cost = 0.141814253\n",
      "Validation Loss: 0.15033214\n",
      "Epoch: 0966 cost = 0.141742898\n",
      "Validation Loss: 0.1407523\n",
      "Epoch: 0967 cost = 0.141672828\n",
      "Validation Loss: 0.12568614\n",
      "Epoch: 0968 cost = 0.141603955\n",
      "Validation Loss: 0.1293583\n",
      "Epoch: 0969 cost = 0.141536354\n",
      "Validation Loss: 0.14160317\n",
      "Epoch: 0970 cost = 0.141469879\n",
      "Validation Loss: 0.14501683\n",
      "Epoch: 0971 cost = 0.141404479\n",
      "Validation Loss: 0.15665542\n",
      "Epoch: 0972 cost = 0.141340184\n",
      "Validation Loss: 0.1333517\n",
      "Epoch: 0973 cost = 0.141276955\n",
      "Validation Loss: 0.14363821\n",
      "Epoch: 0974 cost = 0.141214771\n",
      "Validation Loss: 0.1338367\n",
      "Epoch: 0975 cost = 0.141153547\n",
      "Validation Loss: 0.12722212\n",
      "Epoch: 0976 cost = 0.141093354\n",
      "Validation Loss: 0.12734722\n",
      "Epoch: 0977 cost = 0.141034039\n",
      "Validation Loss: 0.12680353\n",
      "Epoch: 0978 cost = 0.140975661\n",
      "Validation Loss: 0.12505846\n",
      "Epoch: 0979 cost = 0.140918201\n",
      "Validation Loss: 0.12496699\n",
      "Epoch: 0980 cost = 0.140861591\n",
      "Validation Loss: 0.12565914\n",
      "Epoch: 0981 cost = 0.140805803\n",
      "Validation Loss: 0.12765832\n",
      "Epoch: 0982 cost = 0.140750876\n",
      "Validation Loss: 0.12362791\n",
      "Epoch: 0983 cost = 0.140696754\n",
      "Validation Loss: 0.20311262\n",
      "Epoch: 0984 cost = 0.140643370\n",
      "Validation Loss: 0.14276287\n",
      "Epoch: 0985 cost = 0.140590801\n",
      "Validation Loss: 0.124525316\n",
      "Epoch: 0986 cost = 0.140538915\n",
      "Validation Loss: 0.12368783\n",
      "Epoch: 0987 cost = 0.140487819\n",
      "Validation Loss: 0.12623246\n",
      "Epoch: 0988 cost = 0.140437362\n",
      "Validation Loss: 0.12708151\n",
      "Epoch: 0989 cost = 0.140387628\n",
      "Validation Loss: 0.13345139\n",
      "Epoch: 0990 cost = 0.140338612\n",
      "Validation Loss: 0.14618878\n",
      "Epoch: 0991 cost = 0.140290153\n",
      "Validation Loss: 0.12332232\n",
      "Epoch: 0992 cost = 0.140242412\n",
      "Validation Loss: 0.15236664\n",
      "Epoch: 0993 cost = 0.140195284\n",
      "Validation Loss: 0.13585415\n",
      "Epoch: 0994 cost = 0.140148724\n",
      "Validation Loss: 0.124859735\n",
      "Epoch: 0995 cost = 0.140102840\n",
      "Validation Loss: 0.12548669\n",
      "Epoch: 0996 cost = 0.140057485\n",
      "Validation Loss: 0.14435998\n",
      "Epoch: 0997 cost = 0.140012693\n",
      "Validation Loss: 0.13099694\n",
      "Epoch: 0998 cost = 0.139968474\n",
      "Validation Loss: 0.124003574\n",
      "Epoch: 0999 cost = 0.139924827\n",
      "Validation Loss: 0.12808578\n",
      "Epoch: 1000 cost = 0.139881631\n",
      "Validation Loss: 0.12779523\n",
      "Epoch: 1001 cost = 0.139839035\n",
      "Validation Loss: 0.12371626\n",
      "Epoch: 1002 cost = 0.139796949\n",
      "Validation Loss: 0.1233033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1003 cost = 0.139755292\n",
      "Validation Loss: 0.14340332\n",
      "Epoch: 1004 cost = 0.139714134\n",
      "Validation Loss: 0.13428397\n",
      "Epoch: 1005 cost = 0.139673458\n",
      "Validation Loss: 0.13618809\n",
      "Epoch: 1006 cost = 0.139633262\n",
      "Validation Loss: 0.12629457\n",
      "Epoch: 1007 cost = 0.139593568\n",
      "Validation Loss: 0.13910207\n",
      "Epoch: 1008 cost = 0.139554212\n",
      "Validation Loss: 0.1472541\n",
      "Epoch: 1009 cost = 0.139515389\n",
      "Validation Loss: 0.14539571\n",
      "Epoch: 1010 cost = 0.139476916\n",
      "Validation Loss: 0.13139065\n",
      "Epoch: 1011 cost = 0.139438924\n",
      "Validation Loss: 0.1228707\n",
      "Epoch: 1012 cost = 0.139401269\n",
      "Validation Loss: 0.16588227\n",
      "Epoch: 1013 cost = 0.139364053\n",
      "Validation Loss: 0.1571755\n",
      "Epoch: 1014 cost = 0.139327216\n",
      "Validation Loss: 0.140031\n",
      "Epoch: 1015 cost = 0.139290771\n",
      "Validation Loss: 0.12862876\n",
      "Epoch: 1016 cost = 0.139254676\n",
      "Validation Loss: 0.12949622\n",
      "Epoch: 1017 cost = 0.139219024\n",
      "Validation Loss: 0.123280466\n",
      "Epoch: 1018 cost = 0.139183628\n",
      "Validation Loss: 0.12461388\n",
      "Epoch: 1019 cost = 0.139148682\n",
      "Validation Loss: 0.12418558\n",
      "Epoch: 1020 cost = 0.139113979\n",
      "Validation Loss: 0.12511587\n",
      "Epoch: 1021 cost = 0.139079639\n",
      "Validation Loss: 0.12201606\n",
      "Epoch: 1022 cost = 0.139045703\n",
      "Validation Loss: 0.1493107\n",
      "Epoch: 1023 cost = 0.139012034\n",
      "Validation Loss: 0.13602571\n",
      "Epoch: 1024 cost = 0.138978655\n",
      "Validation Loss: 0.12966795\n",
      "Epoch: 1025 cost = 0.138945651\n",
      "Validation Loss: 0.12622464\n",
      "Epoch: 1026 cost = 0.138912928\n",
      "Validation Loss: 0.12435633\n",
      "Epoch: 1027 cost = 0.138880519\n",
      "Validation Loss: 0.122045666\n",
      "Epoch: 1028 cost = 0.138848315\n",
      "Validation Loss: 0.121969596\n",
      "Epoch: 1029 cost = 0.138816479\n",
      "Validation Loss: 0.1572163\n",
      "Epoch: 1030 cost = 0.138784896\n",
      "Validation Loss: 0.13263029\n",
      "Epoch: 1031 cost = 0.138753572\n",
      "Validation Loss: 0.12490488\n",
      "Epoch: 1032 cost = 0.138722604\n",
      "Validation Loss: 0.13693435\n",
      "Epoch: 1033 cost = 0.138691876\n",
      "Validation Loss: 0.14109825\n",
      "Epoch: 1034 cost = 0.138661373\n",
      "Validation Loss: 0.12186315\n",
      "Epoch: 1035 cost = 0.138631076\n",
      "Validation Loss: 0.14276284\n",
      "Epoch: 1036 cost = 0.138601114\n",
      "Validation Loss: 0.13711567\n",
      "Epoch: 1037 cost = 0.138571386\n",
      "Validation Loss: 0.13733506\n",
      "Epoch: 1038 cost = 0.138541886\n",
      "Validation Loss: 0.12326558\n",
      "Epoch: 1039 cost = 0.138512645\n",
      "Validation Loss: 0.1236482\n",
      "Epoch: 1040 cost = 0.138483604\n",
      "Validation Loss: 0.12028805\n",
      "Epoch: 1041 cost = 0.138454807\n",
      "Validation Loss: 0.14461781\n",
      "Epoch: 1042 cost = 0.138426210\n",
      "Validation Loss: 0.12799072\n",
      "Epoch: 1043 cost = 0.138397864\n",
      "Validation Loss: 0.12987068\n",
      "Epoch: 1044 cost = 0.138369740\n",
      "Validation Loss: 0.13296406\n",
      "Epoch: 1045 cost = 0.138341811\n",
      "Validation Loss: 0.13100414\n",
      "Epoch: 1046 cost = 0.138314051\n",
      "Validation Loss: 0.1284341\n",
      "Epoch: 1047 cost = 0.138286554\n",
      "Validation Loss: 0.121069334\n",
      "Epoch: 1048 cost = 0.138259268\n",
      "Validation Loss: 0.12033304\n",
      "Epoch: 1049 cost = 0.138232141\n",
      "Validation Loss: 0.12303195\n",
      "Epoch: 1050 cost = 0.138205179\n",
      "Validation Loss: 0.12815213\n",
      "Epoch: 1051 cost = 0.138178512\n",
      "Validation Loss: 0.13589202\n",
      "Epoch: 1052 cost = 0.138151949\n",
      "Validation Loss: 0.12923005\n",
      "Epoch: 1053 cost = 0.138125572\n",
      "Validation Loss: 0.125778\n",
      "Epoch: 1054 cost = 0.138099428\n",
      "Validation Loss: 0.12399004\n",
      "Epoch: 1055 cost = 0.138073374\n",
      "Validation Loss: 0.1301361\n",
      "Epoch: 1056 cost = 0.138047576\n",
      "Validation Loss: 0.12703444\n",
      "Epoch: 1057 cost = 0.138021919\n",
      "Validation Loss: 0.12131479\n",
      "Epoch: 1058 cost = 0.137996435\n",
      "Validation Loss: 0.12255079\n",
      "Epoch: 1059 cost = 0.137971115\n",
      "Validation Loss: 0.12353979\n",
      "Epoch: 1060 cost = 0.137945949\n",
      "Validation Loss: 0.12387894\n",
      "Epoch: 1061 cost = 0.137920905\n",
      "Validation Loss: 0.12716894\n",
      "Epoch: 1062 cost = 0.137896078\n",
      "Validation Loss: 0.12395263\n",
      "Epoch: 1063 cost = 0.137871376\n",
      "Validation Loss: 0.12245617\n",
      "Epoch: 1064 cost = 0.137846826\n",
      "Validation Loss: 0.12143857\n",
      "Epoch: 1065 cost = 0.137822461\n",
      "Validation Loss: 0.121320345\n",
      "Epoch: 1066 cost = 0.137798178\n",
      "Validation Loss: 0.121695094\n",
      "Epoch: 1067 cost = 0.137774108\n",
      "Validation Loss: 0.12865674\n",
      "Epoch: 1068 cost = 0.137750104\n",
      "Validation Loss: 0.1385668\n",
      "Epoch: 1069 cost = 0.137726253\n",
      "Validation Loss: 0.121865354\n",
      "Epoch: 1070 cost = 0.137702590\n",
      "Validation Loss: 0.12109846\n",
      "Epoch: 1071 cost = 0.137679055\n",
      "Validation Loss: 0.12102066\n",
      "Epoch: 1072 cost = 0.137655572\n",
      "Validation Loss: 0.12507275\n",
      "Epoch: 1073 cost = 0.137632275\n",
      "Validation Loss: 0.12825942\n",
      "Epoch: 1074 cost = 0.137609088\n",
      "Validation Loss: 0.12440792\n",
      "Epoch: 1075 cost = 0.137586057\n",
      "Validation Loss: 0.12946093\n",
      "Epoch: 1076 cost = 0.137563115\n",
      "Validation Loss: 0.123603605\n",
      "Epoch: 1077 cost = 0.137540306\n",
      "Validation Loss: 0.12198905\n",
      "Epoch: 1078 cost = 0.137517578\n",
      "Validation Loss: 0.1227398\n",
      "Epoch: 1079 cost = 0.137494993\n",
      "Validation Loss: 0.121313766\n",
      "Epoch: 1080 cost = 0.137472501\n",
      "Validation Loss: 0.12312092\n",
      "Epoch: 1081 cost = 0.137450167\n",
      "Validation Loss: 0.13047224\n",
      "Epoch: 1082 cost = 0.137427890\n",
      "Validation Loss: 0.12338479\n",
      "Epoch: 1083 cost = 0.137405734\n",
      "Validation Loss: 0.12123662\n",
      "Epoch: 1084 cost = 0.137383675\n",
      "Validation Loss: 0.12055744\n",
      "Epoch: 1085 cost = 0.137361740\n",
      "Validation Loss: 0.120601945\n",
      "Epoch: 1086 cost = 0.137339874\n",
      "Validation Loss: 0.12006034\n",
      "Epoch: 1087 cost = 0.137318117\n",
      "Validation Loss: 0.14896943\n",
      "Epoch: 1088 cost = 0.137296418\n",
      "Validation Loss: 0.124822244\n",
      "Epoch: 1089 cost = 0.137274893\n",
      "Validation Loss: 0.12424168\n",
      "Epoch: 1090 cost = 0.137253421\n",
      "Validation Loss: 0.12430686\n",
      "Epoch: 1091 cost = 0.137232011\n",
      "Validation Loss: 0.13045628\n",
      "Epoch: 1092 cost = 0.137210698\n",
      "Validation Loss: 0.12449785\n",
      "Epoch: 1093 cost = 0.137189471\n",
      "Validation Loss: 0.12068613\n",
      "Epoch: 1094 cost = 0.137168366\n",
      "Validation Loss: 0.12962697\n",
      "Epoch: 1095 cost = 0.137147316\n",
      "Validation Loss: 0.13140686\n",
      "Epoch: 1096 cost = 0.137126356\n",
      "Validation Loss: 0.12407587\n",
      "Epoch: 1097 cost = 0.137105419\n",
      "Validation Loss: 0.12150774\n",
      "Epoch: 1098 cost = 0.137084595\n",
      "Validation Loss: 0.12458963\n",
      "Epoch: 1099 cost = 0.137063862\n",
      "Validation Loss: 0.124374375\n",
      "Epoch: 1100 cost = 0.137043191\n",
      "Validation Loss: 0.12000651\n",
      "Epoch: 1101 cost = 0.137022621\n",
      "Validation Loss: 0.14486879\n",
      "Epoch: 1102 cost = 0.137002058\n",
      "Validation Loss: 0.12802611\n",
      "Epoch: 1103 cost = 0.136981594\n",
      "Validation Loss: 0.12059853\n",
      "Epoch: 1104 cost = 0.136961193\n",
      "Validation Loss: 0.12334048\n",
      "Epoch: 1105 cost = 0.136940870\n",
      "Validation Loss: 0.12108099\n",
      "Epoch: 1106 cost = 0.136920599\n",
      "Validation Loss: 0.11989525\n",
      "Epoch: 1107 cost = 0.136900371\n",
      "Validation Loss: 0.14688438\n",
      "Epoch: 1108 cost = 0.136880195\n",
      "Validation Loss: 0.12894298\n",
      "Epoch: 1109 cost = 0.136860111\n",
      "Validation Loss: 0.12226492\n",
      "Epoch: 1110 cost = 0.136840058\n",
      "Validation Loss: 0.12128522\n",
      "Epoch: 1111 cost = 0.136820028\n",
      "Validation Loss: 0.123851776\n",
      "Epoch: 1112 cost = 0.136800073\n",
      "Validation Loss: 0.120492294\n",
      "Epoch: 1113 cost = 0.136780178\n",
      "Validation Loss: 0.12434058\n",
      "Epoch: 1114 cost = 0.136760306\n",
      "Validation Loss: 0.12678146\n",
      "Epoch: 1115 cost = 0.136740493\n",
      "Validation Loss: 0.13114984\n",
      "Epoch: 1116 cost = 0.136720705\n",
      "Validation Loss: 0.12859118\n",
      "Epoch: 1117 cost = 0.136700985\n",
      "Validation Loss: 0.12113795\n",
      "Epoch: 1118 cost = 0.136681284\n",
      "Validation Loss: 0.12134316\n",
      "Epoch: 1119 cost = 0.136661643\n",
      "Validation Loss: 0.12564565\n",
      "Epoch: 1120 cost = 0.136641992\n",
      "Validation Loss: 0.120672196\n",
      "Epoch: 1121 cost = 0.136622427\n",
      "Validation Loss: 0.119888894\n",
      "Epoch: 1122 cost = 0.136602892\n",
      "Validation Loss: 0.15156946\n",
      "Epoch: 1123 cost = 0.136583294\n",
      "Validation Loss: 0.12898678\n",
      "Epoch: 1124 cost = 0.136563833\n",
      "Validation Loss: 0.121914424\n",
      "Epoch: 1125 cost = 0.136544337\n",
      "Validation Loss: 0.13312683\n",
      "Epoch: 1126 cost = 0.136524835\n",
      "Validation Loss: 0.13506943\n",
      "Epoch: 1127 cost = 0.136505480\n",
      "Validation Loss: 0.13415296\n",
      "Epoch: 1128 cost = 0.136486052\n",
      "Validation Loss: 0.1319057\n",
      "Epoch: 1129 cost = 0.136466636\n",
      "Validation Loss: 0.123275615\n",
      "Epoch: 1130 cost = 0.136447253\n",
      "Validation Loss: 0.12499476\n",
      "Epoch: 1131 cost = 0.136427918\n",
      "Validation Loss: 0.12887771\n",
      "Epoch: 1132 cost = 0.136408533\n",
      "Validation Loss: 0.12349427\n",
      "Epoch: 1133 cost = 0.136389199\n",
      "Validation Loss: 0.11991986\n",
      "Epoch: 1134 cost = 0.136369871\n",
      "Validation Loss: 0.13293152\n",
      "Epoch: 1135 cost = 0.136350525\n",
      "Validation Loss: 0.15432705\n",
      "Epoch: 1136 cost = 0.136331192\n",
      "Validation Loss: 0.15231316\n",
      "Epoch: 1137 cost = 0.136311843\n",
      "Validation Loss: 0.1283977\n",
      "Epoch: 1138 cost = 0.136292513\n",
      "Validation Loss: 0.12133506\n",
      "Epoch: 1139 cost = 0.136273142\n",
      "Validation Loss: 0.123056285\n",
      "Epoch: 1140 cost = 0.136253832\n",
      "Validation Loss: 0.122457005\n",
      "Epoch: 1141 cost = 0.136234464\n",
      "Validation Loss: 0.124292545\n",
      "Epoch: 1142 cost = 0.136215080\n",
      "Validation Loss: 0.12314876\n",
      "Epoch: 1143 cost = 0.136195688\n",
      "Validation Loss: 0.124334976\n",
      "Epoch: 1144 cost = 0.136176315\n",
      "Validation Loss: 0.12022879\n",
      "Epoch: 1145 cost = 0.136156890\n",
      "Validation Loss: 0.11873417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1146 cost = 0.136137423\n",
      "Validation Loss: 0.15125085\n",
      "Epoch: 1147 cost = 0.136117945\n",
      "Validation Loss: 0.13440838\n",
      "Epoch: 1148 cost = 0.136098451\n",
      "Validation Loss: 0.12683694\n",
      "Epoch: 1149 cost = 0.136078856\n",
      "Validation Loss: 0.12403349\n",
      "Epoch: 1150 cost = 0.136059358\n",
      "Validation Loss: 0.120836735\n",
      "Epoch: 1151 cost = 0.136039756\n",
      "Validation Loss: 0.1225399\n",
      "Epoch: 1152 cost = 0.136020106\n",
      "Validation Loss: 0.12702776\n",
      "Epoch: 1153 cost = 0.136000387\n",
      "Validation Loss: 0.13146342\n",
      "Epoch: 1154 cost = 0.135980655\n",
      "Validation Loss: 0.12818377\n",
      "Epoch: 1155 cost = 0.135960925\n",
      "Validation Loss: 0.1261152\n",
      "Epoch: 1156 cost = 0.135941062\n",
      "Validation Loss: 0.12251502\n",
      "Epoch: 1157 cost = 0.135921195\n",
      "Validation Loss: 0.1256136\n",
      "Epoch: 1158 cost = 0.135901231\n",
      "Validation Loss: 0.126517\n",
      "Epoch: 1159 cost = 0.135881243\n",
      "Validation Loss: 0.13684234\n",
      "Epoch: 1160 cost = 0.135861160\n",
      "Validation Loss: 0.13731377\n",
      "Epoch: 1161 cost = 0.135840995\n",
      "Validation Loss: 0.13297352\n",
      "Epoch: 1162 cost = 0.135820742\n",
      "Validation Loss: 0.12469287\n",
      "Epoch: 1163 cost = 0.135800513\n",
      "Validation Loss: 0.12054884\n",
      "Epoch: 1164 cost = 0.135780092\n",
      "Validation Loss: 0.12101125\n",
      "Epoch: 1165 cost = 0.135759684\n",
      "Validation Loss: 0.120097704\n",
      "Epoch: 1166 cost = 0.135739123\n",
      "Validation Loss: 0.1240006\n",
      "Epoch: 1167 cost = 0.135718470\n",
      "Validation Loss: 0.122223124\n",
      "Epoch: 1168 cost = 0.135697741\n",
      "Validation Loss: 0.118264586\n",
      "Epoch: 1169 cost = 0.135676867\n",
      "Validation Loss: 0.14058778\n",
      "Epoch: 1170 cost = 0.135655943\n",
      "Validation Loss: 0.12813804\n",
      "Epoch: 1171 cost = 0.135634939\n",
      "Validation Loss: 0.12614295\n",
      "Epoch: 1172 cost = 0.135613717\n",
      "Validation Loss: 0.12890302\n",
      "Epoch: 1173 cost = 0.135592435\n",
      "Validation Loss: 0.12283781\n",
      "Epoch: 1174 cost = 0.135571059\n",
      "Validation Loss: 0.12071899\n",
      "Epoch: 1175 cost = 0.135549481\n",
      "Validation Loss: 0.11852866\n",
      "Epoch: 1176 cost = 0.135527832\n",
      "Validation Loss: 0.11821118\n",
      "Epoch: 1177 cost = 0.135505996\n",
      "Validation Loss: 0.141688\n",
      "Epoch: 1178 cost = 0.135484018\n",
      "Validation Loss: 0.123302475\n",
      "Epoch: 1179 cost = 0.135461936\n",
      "Validation Loss: 0.121553235\n",
      "Epoch: 1180 cost = 0.135439667\n",
      "Validation Loss: 0.122356735\n",
      "Epoch: 1181 cost = 0.135417224\n",
      "Validation Loss: 0.12545556\n",
      "Epoch: 1182 cost = 0.135394636\n",
      "Validation Loss: 0.13414563\n",
      "Epoch: 1183 cost = 0.135371915\n",
      "Validation Loss: 0.12848201\n",
      "Epoch: 1184 cost = 0.135348934\n",
      "Validation Loss: 0.1245717\n",
      "Epoch: 1185 cost = 0.135325799\n",
      "Validation Loss: 0.12065064\n",
      "Epoch: 1186 cost = 0.135302488\n",
      "Validation Loss: 0.122134216\n",
      "Epoch: 1187 cost = 0.135278931\n",
      "Validation Loss: 0.1265216\n",
      "Epoch: 1188 cost = 0.135255252\n",
      "Validation Loss: 0.12517497\n",
      "Epoch: 1189 cost = 0.135231364\n",
      "Validation Loss: 0.12069668\n",
      "Epoch: 1190 cost = 0.135207166\n",
      "Validation Loss: 0.11960118\n",
      "Epoch: 1191 cost = 0.135182914\n",
      "Validation Loss: 0.119179405\n",
      "Epoch: 1192 cost = 0.135158360\n",
      "Validation Loss: 0.11983076\n",
      "Epoch: 1193 cost = 0.135133540\n",
      "Validation Loss: 0.12171294\n",
      "Epoch: 1194 cost = 0.135108517\n",
      "Validation Loss: 0.11969609\n",
      "Epoch: 1195 cost = 0.135083229\n",
      "Validation Loss: 0.1199831\n",
      "Epoch: 1196 cost = 0.135057712\n",
      "Validation Loss: 0.12378429\n",
      "Epoch: 1197 cost = 0.135032012\n",
      "Validation Loss: 0.11823655\n",
      "Epoch: 1198 cost = 0.135005986\n",
      "Validation Loss: 0.11746908\n",
      "Epoch: 1199 cost = 0.134979708\n",
      "Validation Loss: 0.14187628\n",
      "Epoch: 1200 cost = 0.134953207\n",
      "Validation Loss: 0.120823205\n",
      "Epoch: 1201 cost = 0.134926457\n",
      "Validation Loss: 0.121940605\n",
      "Epoch: 1202 cost = 0.134899359\n",
      "Validation Loss: 0.11929175\n",
      "Epoch: 1203 cost = 0.134872021\n",
      "Validation Loss: 0.12329097\n",
      "Epoch: 1204 cost = 0.134844440\n",
      "Validation Loss: 0.12239442\n",
      "Epoch: 1205 cost = 0.134816566\n",
      "Validation Loss: 0.119404174\n",
      "Epoch: 1206 cost = 0.134788363\n",
      "Validation Loss: 0.11884151\n",
      "Epoch: 1207 cost = 0.134759886\n",
      "Validation Loss: 0.11866463\n",
      "Epoch: 1208 cost = 0.134731170\n",
      "Validation Loss: 0.11929942\n",
      "Epoch: 1209 cost = 0.134702115\n",
      "Validation Loss: 0.120924756\n",
      "Epoch: 1210 cost = 0.134672838\n",
      "Validation Loss: 0.12363764\n",
      "Epoch: 1211 cost = 0.134643231\n",
      "Validation Loss: 0.11964686\n",
      "Epoch: 1212 cost = 0.134613268\n",
      "Validation Loss: 0.11902989\n",
      "Epoch: 1213 cost = 0.134583042\n",
      "Validation Loss: 0.12252285\n",
      "Epoch: 1214 cost = 0.134552564\n",
      "Validation Loss: 0.12632269\n",
      "Epoch: 1215 cost = 0.134521661\n",
      "Validation Loss: 0.12513594\n",
      "Epoch: 1216 cost = 0.134490581\n",
      "Validation Loss: 0.12853877\n",
      "Epoch: 1217 cost = 0.134459146\n",
      "Validation Loss: 0.12393132\n",
      "Epoch: 1218 cost = 0.134427427\n",
      "Validation Loss: 0.12456224\n",
      "Epoch: 1219 cost = 0.134395389\n",
      "Validation Loss: 0.122366756\n",
      "Epoch: 1220 cost = 0.134363054\n",
      "Validation Loss: 0.1203502\n",
      "Epoch: 1221 cost = 0.134330351\n",
      "Validation Loss: 0.12191512\n",
      "Epoch: 1222 cost = 0.134297464\n",
      "Validation Loss: 0.12008587\n",
      "Epoch: 1223 cost = 0.134264189\n",
      "Validation Loss: 0.11990117\n",
      "Epoch: 1224 cost = 0.134230614\n",
      "Validation Loss: 0.12220166\n",
      "Epoch: 1225 cost = 0.134196819\n",
      "Validation Loss: 0.12507214\n",
      "Epoch: 1226 cost = 0.134162627\n",
      "Validation Loss: 0.12056658\n",
      "Epoch: 1227 cost = 0.134128183\n",
      "Validation Loss: 0.12015693\n",
      "Epoch: 1228 cost = 0.134093372\n",
      "Validation Loss: 0.11929083\n",
      "Epoch: 1229 cost = 0.134058346\n",
      "Validation Loss: 0.12095374\n",
      "Epoch: 1230 cost = 0.134023038\n",
      "Validation Loss: 0.119696096\n",
      "Epoch: 1231 cost = 0.133987358\n",
      "Validation Loss: 0.12230634\n",
      "Epoch: 1232 cost = 0.133951436\n",
      "Validation Loss: 0.12157313\n",
      "Epoch: 1233 cost = 0.133915185\n",
      "Validation Loss: 0.12215014\n",
      "Epoch: 1234 cost = 0.133878627\n",
      "Validation Loss: 0.11908281\n",
      "Epoch: 1235 cost = 0.133841773\n",
      "Validation Loss: 0.12037249\n",
      "Epoch: 1236 cost = 0.133804566\n",
      "Validation Loss: 0.12630576\n",
      "Epoch: 1237 cost = 0.133767057\n",
      "Validation Loss: 0.1374344\n",
      "Epoch: 1238 cost = 0.133729170\n",
      "Validation Loss: 0.14434734\n",
      "Epoch: 1239 cost = 0.133690991\n",
      "Validation Loss: 0.13922973\n",
      "Epoch: 1240 cost = 0.133652477\n",
      "Validation Loss: 0.12134854\n",
      "Epoch: 1241 cost = 0.133613559\n",
      "Validation Loss: 0.11725848\n",
      "Epoch: 1242 cost = 0.133574361\n",
      "Validation Loss: 0.14606996\n",
      "Epoch: 1243 cost = 0.133534729\n",
      "Validation Loss: 0.12104724\n",
      "Epoch: 1244 cost = 0.133494794\n",
      "Validation Loss: 0.12589549\n",
      "Epoch: 1245 cost = 0.133454485\n",
      "Validation Loss: 0.12759629\n",
      "Epoch: 1246 cost = 0.133413862\n",
      "Validation Loss: 0.123554796\n",
      "Epoch: 1247 cost = 0.133372773\n",
      "Validation Loss: 0.1261304\n",
      "Epoch: 1248 cost = 0.133331384\n",
      "Validation Loss: 0.1300519\n",
      "Epoch: 1249 cost = 0.133289647\n",
      "Validation Loss: 0.129348\n",
      "Epoch: 1250 cost = 0.133247527\n",
      "Validation Loss: 0.12602343\n",
      "Epoch: 1251 cost = 0.133205046\n",
      "Validation Loss: 0.11934112\n",
      "Epoch: 1252 cost = 0.133162192\n",
      "Validation Loss: 0.11902404\n",
      "Epoch: 1253 cost = 0.133118828\n",
      "Validation Loss: 0.12961921\n",
      "Epoch: 1254 cost = 0.133075084\n",
      "Validation Loss: 0.120182194\n",
      "Epoch: 1255 cost = 0.133030944\n",
      "Validation Loss: 0.118247695\n",
      "Epoch: 1256 cost = 0.132986299\n",
      "Validation Loss: 0.12334591\n",
      "Epoch: 1257 cost = 0.132941099\n",
      "Validation Loss: 0.12579347\n",
      "Epoch: 1258 cost = 0.132895345\n",
      "Validation Loss: 0.14014606\n",
      "Epoch: 1259 cost = 0.132849058\n",
      "Validation Loss: 0.1267223\n",
      "Epoch: 1260 cost = 0.132802168\n",
      "Validation Loss: 0.11887416\n",
      "Epoch: 1261 cost = 0.132754547\n",
      "Validation Loss: 0.11950438\n",
      "Epoch: 1262 cost = 0.132706296\n",
      "Validation Loss: 0.119259655\n",
      "Epoch: 1263 cost = 0.132657261\n",
      "Validation Loss: 0.121385634\n",
      "Epoch: 1264 cost = 0.132607520\n",
      "Validation Loss: 0.12037626\n",
      "Epoch: 1265 cost = 0.132556892\n",
      "Validation Loss: 0.120206915\n",
      "Epoch: 1266 cost = 0.132505437\n",
      "Validation Loss: 0.11727119\n",
      "Epoch: 1267 cost = 0.132452980\n",
      "Validation Loss: 0.13488078\n",
      "Epoch: 1268 cost = 0.132399607\n",
      "Validation Loss: 0.12481781\n",
      "Epoch: 1269 cost = 0.132345136\n",
      "Validation Loss: 0.12379354\n",
      "Epoch: 1270 cost = 0.132289659\n",
      "Validation Loss: 0.12994818\n",
      "Epoch: 1271 cost = 0.132232989\n",
      "Validation Loss: 0.14029503\n",
      "Epoch: 1272 cost = 0.132175170\n",
      "Validation Loss: 0.11917451\n",
      "Epoch: 1273 cost = 0.132116128\n",
      "Validation Loss: 0.121457174\n",
      "Epoch: 1274 cost = 0.132055821\n",
      "Validation Loss: 0.12281219\n",
      "Epoch: 1275 cost = 0.131994104\n",
      "Validation Loss: 0.124145195\n",
      "Epoch: 1276 cost = 0.131931077\n",
      "Validation Loss: 0.11751962\n",
      "Epoch: 1277 cost = 0.131866707\n",
      "Validation Loss: 0.11912349\n",
      "Epoch: 1278 cost = 0.131800797\n",
      "Validation Loss: 0.120780386\n",
      "Epoch: 1279 cost = 0.131733460\n",
      "Validation Loss: 0.123571545\n",
      "Epoch: 1280 cost = 0.131664602\n",
      "Validation Loss: 0.119901136\n",
      "Epoch: 1281 cost = 0.131594232\n",
      "Validation Loss: 0.12162738\n",
      "Epoch: 1282 cost = 0.131522220\n",
      "Validation Loss: 0.119916245\n",
      "Epoch: 1283 cost = 0.131448637\n",
      "Validation Loss: 0.12092901\n",
      "Epoch: 1284 cost = 0.131373493\n",
      "Validation Loss: 0.12472612\n",
      "Epoch: 1285 cost = 0.131296768\n",
      "Validation Loss: 0.12571068\n",
      "Epoch: 1286 cost = 0.131218379\n",
      "Validation Loss: 0.12859169\n",
      "Epoch: 1287 cost = 0.131138554\n",
      "Validation Loss: 0.12395737\n",
      "Epoch: 1288 cost = 0.131057315\n",
      "Validation Loss: 0.12746204\n",
      "Epoch: 1289 cost = 0.130974534\n",
      "Validation Loss: 0.118809335\n",
      "Epoch: 1290 cost = 0.130890527\n",
      "Validation Loss: 0.12050008\n",
      "Epoch: 1291 cost = 0.130805424\n",
      "Validation Loss: 0.13034168\n",
      "Epoch: 1292 cost = 0.130719222\n",
      "Validation Loss: 0.12490283\n",
      "Epoch: 1293 cost = 0.130632323\n",
      "Validation Loss: 0.12440168\n",
      "Epoch: 1294 cost = 0.130544854\n",
      "Validation Loss: 0.12355303\n",
      "Epoch: 1295 cost = 0.130456747\n",
      "Validation Loss: 0.11951206\n",
      "Epoch: 1296 cost = 0.130368162\n",
      "Validation Loss: 0.120723255\n",
      "Epoch: 1297 cost = 0.130279216\n",
      "Validation Loss: 0.12223684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1298 cost = 0.130189780\n",
      "Validation Loss: 0.11971989\n",
      "Epoch: 1299 cost = 0.130099807\n",
      "Validation Loss: 0.119279064\n",
      "Epoch: 1300 cost = 0.130009088\n",
      "Validation Loss: 0.12098039\n",
      "Epoch: 1301 cost = 0.129917588\n",
      "Validation Loss: 0.12841474\n",
      "Epoch: 1302 cost = 0.129824970\n",
      "Validation Loss: 0.13453598\n",
      "Epoch: 1303 cost = 0.129730929\n",
      "Validation Loss: 0.12281478\n",
      "Epoch: 1304 cost = 0.129635088\n",
      "Validation Loss: 0.119260594\n",
      "Epoch: 1305 cost = 0.129536657\n",
      "Validation Loss: 0.1192608\n",
      "Epoch: 1306 cost = 0.129434695\n",
      "Validation Loss: 0.119290456\n",
      "Epoch: 1307 cost = 0.129327336\n",
      "Validation Loss: 0.12532805\n",
      "Epoch: 1308 cost = 0.129211353\n",
      "Validation Loss: 0.1280877\n",
      "Epoch: 1309 cost = 0.129082013\n",
      "Validation Loss: 0.117892995\n",
      "Epoch: 1310 cost = 0.128934047\n",
      "Validation Loss: 0.12536088\n",
      "Epoch: 1311 cost = 0.128768630\n",
      "Validation Loss: 0.1214406\n",
      "Epoch: 1312 cost = 0.128598117\n",
      "Validation Loss: 0.12024871\n",
      "Epoch: 1313 cost = 0.128430686\n",
      "Validation Loss: 0.13228397\n",
      "Epoch: 1314 cost = 0.128256518\n",
      "Validation Loss: 0.14079526\n",
      "Epoch: 1315 cost = 0.128060457\n",
      "Validation Loss: 0.13834476\n",
      "Epoch: 1316 cost = 0.127831229\n",
      "Validation Loss: 0.1288447\n",
      "Epoch: 1317 cost = 0.127577176\n",
      "Validation Loss: 0.12047262\n",
      "Epoch: 1318 cost = 0.127321880\n",
      "Validation Loss: 0.12246363\n",
      "Epoch: 1319 cost = 0.127038300\n",
      "Validation Loss: 0.12712337\n",
      "Epoch: 1320 cost = 0.126681871\n",
      "Validation Loss: 0.14027408\n",
      "Epoch: 1321 cost = 0.126161619\n",
      "Validation Loss: 0.15428282\n",
      "Epoch: 1322 cost = 0.125281278\n",
      "Validation Loss: 0.12845661\n",
      "Epoch: 1323 cost = 0.123395047\n",
      "Validation Loss: 0.12451739\n",
      "Epoch: 1324 cost = 0.120573023\n",
      "Validation Loss: 0.12927802\n",
      "Epoch: 1325 cost = 0.119320662\n",
      "Validation Loss: 0.14094326\n",
      "Epoch: 1326 cost = 0.118293852\n",
      "Validation Loss: 0.14355688\n",
      "Epoch: 1327 cost = 0.116761614\n",
      "Validation Loss: 0.13306491\n",
      "Epoch: 1328 cost = 0.114905415\n",
      "Validation Loss: 0.14061116\n",
      "Epoch: 1329 cost = 0.113678337\n",
      "Validation Loss: 0.14287747\n",
      "Epoch: 1330 cost = 0.112232450\n",
      "Validation Loss: 0.18411645\n",
      "Epoch: 1331 cost = 0.110579293\n",
      "Validation Loss: 0.24792045\n",
      "Epoch: 1332 cost = 0.109342865\n",
      "Validation Loss: 0.22452489\n",
      "Epoch: 1333 cost = 0.108199911\n",
      "Validation Loss: 0.15252766\n",
      "Epoch: 1334 cost = 0.106899831\n",
      "Validation Loss: 0.1508385\n",
      "Epoch: 1335 cost = 0.105519520\n",
      "Validation Loss: 0.14104073\n",
      "Epoch: 1336 cost = 0.104111331\n",
      "Validation Loss: 0.13971457\n",
      "Epoch: 1337 cost = 0.102304000\n",
      "Validation Loss: 0.1123869\n",
      "Epoch: 1338 cost = 0.100290255\n",
      "Validation Loss: 0.18514298\n",
      "Epoch: 1339 cost = 0.098038010\n",
      "Validation Loss: 0.27880666\n",
      "Epoch: 1340 cost = 0.096032828\n",
      "Validation Loss: 0.3192531\n",
      "Epoch: 1341 cost = 0.094115903\n",
      "Validation Loss: 0.23299856\n",
      "Epoch: 1342 cost = 0.092474406\n",
      "Validation Loss: 0.17617832\n",
      "Epoch: 1343 cost = 0.090976171\n",
      "Validation Loss: 0.13372763\n",
      "Epoch: 1344 cost = 0.089462775\n",
      "Validation Loss: 0.10835311\n",
      "Epoch: 1345 cost = 0.087817021\n",
      "Validation Loss: 0.13206959\n",
      "Epoch: 1346 cost = 0.085975945\n",
      "Validation Loss: 0.12336506\n",
      "Epoch: 1347 cost = 0.084387538\n",
      "Validation Loss: 0.119426094\n",
      "Epoch: 1348 cost = 0.083028978\n",
      "Validation Loss: 0.115534\n",
      "Epoch: 1349 cost = 0.081791027\n",
      "Validation Loss: 0.1085061\n",
      "Epoch: 1350 cost = 0.080709362\n",
      "Validation Loss: 0.11361851\n",
      "Epoch: 1351 cost = 0.079740087\n",
      "Validation Loss: 0.111859985\n",
      "Epoch: 1352 cost = 0.078799995\n",
      "Validation Loss: 0.11426701\n",
      "Epoch: 1353 cost = 0.077939891\n",
      "Validation Loss: 0.12109827\n",
      "Epoch: 1354 cost = 0.077151320\n",
      "Validation Loss: 0.1158396\n",
      "Epoch: 1355 cost = 0.076384818\n",
      "Validation Loss: 0.11768607\n",
      "Epoch: 1356 cost = 0.075643149\n",
      "Validation Loss: 0.115374245\n",
      "Epoch: 1357 cost = 0.074918061\n",
      "Validation Loss: 0.12035875\n",
      "Epoch: 1358 cost = 0.074195559\n",
      "Validation Loss: 0.13657887\n",
      "Epoch: 1359 cost = 0.073454802\n",
      "Validation Loss: 0.11459563\n",
      "Epoch: 1360 cost = 0.072676511\n",
      "Validation Loss: 0.11204291\n",
      "Epoch: 1361 cost = 0.071848031\n",
      "Validation Loss: 0.106187604\n",
      "Epoch: 1362 cost = 0.071070569\n",
      "Validation Loss: 0.15481727\n",
      "Epoch: 1363 cost = 0.070391823\n",
      "Validation Loss: 0.10082234\n",
      "Epoch: 1364 cost = 0.069812470\n",
      "Validation Loss: 0.16120929\n",
      "Epoch: 1365 cost = 0.069326568\n",
      "Validation Loss: 0.11751026\n",
      "Epoch: 1366 cost = 0.068827140\n",
      "Validation Loss: 0.108712226\n",
      "Epoch: 1367 cost = 0.068371785\n",
      "Validation Loss: 0.10524172\n",
      "Epoch: 1368 cost = 0.067963202\n",
      "Validation Loss: 0.10705227\n",
      "Epoch: 1369 cost = 0.067573794\n",
      "Validation Loss: 0.10766351\n",
      "Epoch: 1370 cost = 0.067203611\n",
      "Validation Loss: 0.10652825\n",
      "Epoch: 1371 cost = 0.066847893\n",
      "Validation Loss: 0.11509412\n",
      "Epoch: 1372 cost = 0.066437480\n",
      "Validation Loss: 0.13158302\n",
      "Epoch: 1373 cost = 0.065871505\n",
      "Validation Loss: 0.13029028\n",
      "Epoch: 1374 cost = 0.065517068\n",
      "Validation Loss: 0.108824365\n",
      "Epoch: 1375 cost = 0.065200601\n",
      "Validation Loss: 0.10500474\n",
      "Epoch: 1376 cost = 0.064915782\n",
      "Validation Loss: 0.099656\n",
      "Epoch: 1377 cost = 0.064635738\n",
      "Validation Loss: 0.23263851\n",
      "Epoch: 1378 cost = 0.064357961\n",
      "Validation Loss: 0.17308648\n",
      "Epoch: 1379 cost = 0.064098405\n",
      "Validation Loss: 0.13125058\n",
      "Epoch: 1380 cost = 0.063856230\n",
      "Validation Loss: 0.13141116\n",
      "Epoch: 1381 cost = 0.063615484\n",
      "Validation Loss: 0.11129654\n",
      "Epoch: 1382 cost = 0.063389914\n",
      "Validation Loss: 0.10582984\n",
      "Epoch: 1383 cost = 0.063162463\n",
      "Validation Loss: 0.120363906\n",
      "Epoch: 1384 cost = 0.062949878\n",
      "Validation Loss: 0.10066784\n",
      "Epoch: 1385 cost = 0.062729147\n",
      "Validation Loss: 0.09833964\n",
      "Epoch: 1386 cost = 0.062514871\n",
      "Validation Loss: 0.11936666\n",
      "Epoch: 1387 cost = 0.062283913\n",
      "Validation Loss: 0.10644114\n",
      "Epoch: 1388 cost = 0.062028395\n",
      "Validation Loss: 0.10676692\n",
      "Epoch: 1389 cost = 0.061721930\n",
      "Validation Loss: 0.10162877\n",
      "Epoch: 1390 cost = 0.061337875\n",
      "Validation Loss: 0.09966303\n",
      "Epoch: 1391 cost = 0.060867915\n",
      "Validation Loss: 0.13764895\n",
      "Epoch: 1392 cost = 0.060283257\n",
      "Validation Loss: 0.13180736\n",
      "Epoch: 1393 cost = 0.059532751\n",
      "Validation Loss: 0.11836888\n",
      "Epoch: 1394 cost = 0.058721104\n",
      "Validation Loss: 0.10599596\n",
      "Epoch: 1395 cost = 0.057973542\n",
      "Validation Loss: 0.08772388\n",
      "Epoch: 1396 cost = 0.057083764\n",
      "Validation Loss: 0.10681165\n",
      "Epoch: 1397 cost = 0.056195099\n",
      "Validation Loss: 0.10620262\n",
      "Epoch: 1398 cost = 0.055337721\n",
      "Validation Loss: 0.09403732\n",
      "Epoch: 1399 cost = 0.053688969\n",
      "Validation Loss: 0.078602195\n",
      "Epoch: 1400 cost = 0.051434349\n",
      "Validation Loss: 0.10897999\n",
      "Epoch: 1401 cost = 0.051016927\n",
      "Validation Loss: 0.0975034\n",
      "Epoch: 1402 cost = 0.050497977\n",
      "Validation Loss: 0.08055158\n",
      "Epoch: 1403 cost = 0.050056646\n",
      "Validation Loss: 0.099673055\n",
      "Epoch: 1404 cost = 0.049606135\n",
      "Validation Loss: 0.086874\n",
      "Epoch: 1405 cost = 0.049226871\n",
      "Validation Loss: 0.07676771\n",
      "Epoch: 1406 cost = 0.048845653\n",
      "Validation Loss: 0.12477585\n",
      "Epoch: 1407 cost = 0.048498284\n",
      "Validation Loss: 0.088744\n",
      "Epoch: 1408 cost = 0.048179591\n",
      "Validation Loss: 0.07600107\n",
      "Epoch: 1409 cost = 0.047880571\n",
      "Validation Loss: 0.118919685\n",
      "Epoch: 1410 cost = 0.047588329\n",
      "Validation Loss: 0.09780263\n",
      "Epoch: 1411 cost = 0.047292082\n",
      "Validation Loss: 0.10080008\n",
      "Epoch: 1412 cost = 0.047007003\n",
      "Validation Loss: 0.11942141\n",
      "Epoch: 1413 cost = 0.046725718\n",
      "Validation Loss: 0.14710286\n",
      "Epoch: 1414 cost = 0.046439118\n",
      "Validation Loss: 0.13094048\n",
      "Epoch: 1415 cost = 0.046145012\n",
      "Validation Loss: 0.11030462\n",
      "Epoch: 1416 cost = 0.045845026\n",
      "Validation Loss: 0.1064309\n",
      "Epoch: 1417 cost = 0.045570721\n",
      "Validation Loss: 0.103811525\n",
      "Epoch: 1418 cost = 0.045329200\n",
      "Validation Loss: 0.080393076\n",
      "Epoch: 1419 cost = 0.045122927\n",
      "Validation Loss: 0.07621695\n",
      "Epoch: 1420 cost = 0.044924622\n",
      "Validation Loss: 0.0727083\n",
      "Epoch: 1421 cost = 0.044737060\n",
      "Validation Loss: 0.13189417\n",
      "Epoch: 1422 cost = 0.044558560\n",
      "Validation Loss: 0.1027387\n",
      "Epoch: 1423 cost = 0.044389224\n",
      "Validation Loss: 0.069617674\n",
      "Epoch: 1424 cost = 0.044231578\n",
      "Validation Loss: 0.10288638\n",
      "Epoch: 1425 cost = 0.044083167\n",
      "Validation Loss: 0.077831216\n",
      "Epoch: 1426 cost = 0.043940607\n",
      "Validation Loss: 0.07107628\n",
      "Epoch: 1427 cost = 0.043803584\n",
      "Validation Loss: 0.075531065\n",
      "Epoch: 1428 cost = 0.043671709\n",
      "Validation Loss: 0.09867538\n",
      "Epoch: 1429 cost = 0.043544164\n",
      "Validation Loss: 0.12743674\n",
      "Epoch: 1430 cost = 0.043420570\n",
      "Validation Loss: 0.09702532\n",
      "Epoch: 1431 cost = 0.043300633\n",
      "Validation Loss: 0.08190649\n",
      "Epoch: 1432 cost = 0.043183655\n",
      "Validation Loss: 0.056501366\n",
      "Epoch: 1433 cost = 0.043069015\n",
      "Validation Loss: 0.10387639\n",
      "Epoch: 1434 cost = 0.042956362\n",
      "Validation Loss: 0.085286945\n",
      "Epoch: 1435 cost = 0.042845345\n",
      "Validation Loss: 0.072568245\n",
      "Epoch: 1436 cost = 0.042735743\n",
      "Validation Loss: 0.06671313\n",
      "Epoch: 1437 cost = 0.042626966\n",
      "Validation Loss: 0.06421253\n",
      "Epoch: 1438 cost = 0.042518599\n",
      "Validation Loss: 0.06341044\n",
      "Epoch: 1439 cost = 0.042409748\n",
      "Validation Loss: 0.062486928\n",
      "Epoch: 1440 cost = 0.042299643\n",
      "Validation Loss: 0.056637693\n",
      "Epoch: 1441 cost = 0.042186954\n",
      "Validation Loss: 0.07466708\n",
      "Epoch: 1442 cost = 0.042070235\n",
      "Validation Loss: 0.0933941\n",
      "Epoch: 1443 cost = 0.041947941\n",
      "Validation Loss: 0.08302222\n",
      "Epoch: 1444 cost = 0.041819025\n",
      "Validation Loss: 0.0552464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1445 cost = 0.041683762\n",
      "Validation Loss: 0.11920845\n",
      "Epoch: 1446 cost = 0.041543585\n",
      "Validation Loss: 0.088680856\n",
      "Epoch: 1447 cost = 0.041400665\n",
      "Validation Loss: 0.094576865\n",
      "Epoch: 1448 cost = 0.041246435\n",
      "Validation Loss: 0.122797094\n",
      "Epoch: 1449 cost = 0.041027191\n",
      "Validation Loss: 0.12701473\n",
      "Epoch: 1450 cost = 0.040858308\n",
      "Validation Loss: 0.105087526\n",
      "Epoch: 1451 cost = 0.040723424\n",
      "Validation Loss: 0.091768734\n",
      "Epoch: 1452 cost = 0.040577295\n",
      "Validation Loss: 0.08517875\n",
      "Epoch: 1453 cost = 0.040420202\n",
      "Validation Loss: 0.06670099\n",
      "Epoch: 1454 cost = 0.040204987\n",
      "Validation Loss: 0.056944106\n",
      "Epoch: 1455 cost = 0.039885936\n",
      "Validation Loss: 0.05798191\n",
      "Epoch: 1456 cost = 0.039538881\n",
      "Validation Loss: 0.06281021\n",
      "Epoch: 1457 cost = 0.038895335\n",
      "Validation Loss: 0.071164414\n",
      "Epoch: 1458 cost = 0.038597550\n",
      "Validation Loss: 0.068572335\n",
      "Epoch: 1459 cost = 0.038153476\n",
      "Validation Loss: 0.06288348\n",
      "Epoch: 1460 cost = 0.037616267\n",
      "Validation Loss: 0.056712504\n",
      "Epoch: 1461 cost = 0.037463388\n",
      "Validation Loss: 0.051047754\n",
      "Epoch: 1462 cost = 0.037171834\n",
      "Validation Loss: 0.11396788\n",
      "Epoch: 1463 cost = 0.036858204\n",
      "Validation Loss: 0.05863008\n",
      "Epoch: 1464 cost = 0.036617708\n",
      "Validation Loss: 0.04777378\n",
      "Epoch: 1465 cost = 0.036381907\n",
      "Validation Loss: 0.084416024\n",
      "Epoch: 1466 cost = 0.036155879\n",
      "Validation Loss: 0.057934646\n",
      "Epoch: 1467 cost = 0.036018869\n",
      "Validation Loss: 0.06153492\n",
      "Epoch: 1468 cost = 0.035914436\n",
      "Validation Loss: 0.04804544\n",
      "Epoch: 1469 cost = 0.035803696\n",
      "Validation Loss: 0.04901701\n",
      "Epoch: 1470 cost = 0.035690326\n",
      "Validation Loss: 0.04575649\n",
      "Epoch: 1471 cost = 0.035588091\n",
      "Validation Loss: 0.13252787\n",
      "Epoch: 1472 cost = 0.035498494\n",
      "Validation Loss: 0.07216749\n",
      "Epoch: 1473 cost = 0.035414852\n",
      "Validation Loss: 0.052424412\n",
      "Epoch: 1474 cost = 0.035338585\n",
      "Validation Loss: 0.044325303\n",
      "Epoch: 1475 cost = 0.035265121\n",
      "Validation Loss: 0.11524578\n",
      "Epoch: 1476 cost = 0.035194916\n",
      "Validation Loss: 0.07010683\n",
      "Epoch: 1477 cost = 0.035128021\n",
      "Validation Loss: 0.063832976\n",
      "Epoch: 1478 cost = 0.035064961\n",
      "Validation Loss: 0.053404033\n",
      "Epoch: 1479 cost = 0.035003684\n",
      "Validation Loss: 0.040654816\n",
      "Epoch: 1480 cost = 0.034945223\n",
      "Validation Loss: 0.08825659\n",
      "Epoch: 1481 cost = 0.034888893\n",
      "Validation Loss: 0.05961262\n",
      "Epoch: 1482 cost = 0.034834645\n",
      "Validation Loss: 0.05294975\n",
      "Epoch: 1483 cost = 0.034781773\n",
      "Validation Loss: 0.046264548\n",
      "Epoch: 1484 cost = 0.034730796\n",
      "Validation Loss: 0.050610226\n",
      "Epoch: 1485 cost = 0.034681259\n",
      "Validation Loss: 0.057290908\n",
      "Epoch: 1486 cost = 0.034633317\n",
      "Validation Loss: 0.06024237\n",
      "Epoch: 1487 cost = 0.034586513\n",
      "Validation Loss: 0.05453485\n",
      "Epoch: 1488 cost = 0.034541102\n",
      "Validation Loss: 0.04861787\n",
      "Epoch: 1489 cost = 0.034496825\n",
      "Validation Loss: 0.051717848\n",
      "Epoch: 1490 cost = 0.034453623\n",
      "Validation Loss: 0.04327541\n",
      "Epoch: 1491 cost = 0.034411472\n",
      "Validation Loss: 0.04282053\n",
      "Epoch: 1492 cost = 0.034370363\n",
      "Validation Loss: 0.045302667\n",
      "Epoch: 1493 cost = 0.034330068\n",
      "Validation Loss: 0.04980075\n",
      "Epoch: 1494 cost = 0.034290727\n",
      "Validation Loss: 0.04840561\n",
      "Epoch: 1495 cost = 0.034252183\n",
      "Validation Loss: 0.056250535\n",
      "Epoch: 1496 cost = 0.034214528\n",
      "Validation Loss: 0.04279384\n",
      "Epoch: 1497 cost = 0.034177548\n",
      "Validation Loss: 0.041712616\n",
      "Epoch: 1498 cost = 0.034141374\n",
      "Validation Loss: 0.0578504\n",
      "Epoch: 1499 cost = 0.034105833\n",
      "Validation Loss: 0.08367785\n",
      "Epoch: 1500 cost = 0.034071045\n",
      "Validation Loss: 0.06549464\n",
      "Epoch: 1501 cost = 0.034036843\n",
      "Validation Loss: 0.04459762\n",
      "Epoch: 1502 cost = 0.034003266\n",
      "Validation Loss: 0.050159454\n",
      "Epoch: 1503 cost = 0.033970283\n",
      "Validation Loss: 0.04852311\n",
      "Epoch: 1504 cost = 0.033937888\n",
      "Validation Loss: 0.08071148\n",
      "Epoch: 1505 cost = 0.033906066\n",
      "Validation Loss: 0.069399156\n",
      "Epoch: 1506 cost = 0.033874759\n",
      "Validation Loss: 0.05354028\n",
      "Epoch: 1507 cost = 0.033843944\n",
      "Validation Loss: 0.05088274\n",
      "Epoch: 1508 cost = 0.033813669\n",
      "Validation Loss: 0.061250526\n",
      "Epoch: 1509 cost = 0.033783844\n",
      "Validation Loss: 0.049997218\n",
      "Epoch: 1510 cost = 0.033754522\n",
      "Validation Loss: 0.045746055\n",
      "Epoch: 1511 cost = 0.033725642\n",
      "Validation Loss: 0.051041506\n",
      "Epoch: 1512 cost = 0.033697209\n",
      "Validation Loss: 0.046033185\n",
      "Epoch: 1513 cost = 0.033669189\n",
      "Validation Loss: 0.045136567\n",
      "Epoch: 1514 cost = 0.033641618\n",
      "Validation Loss: 0.054316133\n",
      "Epoch: 1515 cost = 0.033614418\n",
      "Validation Loss: 0.046620026\n",
      "Epoch: 1516 cost = 0.033587616\n",
      "Validation Loss: 0.04596285\n",
      "Epoch: 1517 cost = 0.033561189\n",
      "Validation Loss: 0.05296038\n",
      "Epoch: 1518 cost = 0.033535149\n",
      "Validation Loss: 0.054151747\n",
      "Epoch: 1519 cost = 0.033509471\n",
      "Validation Loss: 0.049792532\n",
      "Epoch: 1520 cost = 0.033484177\n",
      "Validation Loss: 0.04755874\n",
      "Epoch: 1521 cost = 0.033459158\n",
      "Validation Loss: 0.04475253\n",
      "Epoch: 1522 cost = 0.033434518\n",
      "Validation Loss: 0.04254935\n",
      "Epoch: 1523 cost = 0.033410148\n",
      "Validation Loss: 0.04538516\n",
      "Epoch: 1524 cost = 0.033386170\n",
      "Validation Loss: 0.042529143\n",
      "Epoch: 1525 cost = 0.033362418\n",
      "Validation Loss: 0.045360755\n",
      "Epoch: 1526 cost = 0.033339090\n",
      "Validation Loss: 0.047210384\n",
      "Epoch: 1527 cost = 0.033315881\n",
      "Validation Loss: 0.04541\n",
      "Epoch: 1528 cost = 0.033293131\n",
      "Validation Loss: 0.05108587\n",
      "Epoch: 1529 cost = 0.033270492\n",
      "Validation Loss: 0.0598495\n",
      "Epoch: 1530 cost = 0.033248259\n",
      "Validation Loss: 0.076431595\n",
      "Epoch: 1531 cost = 0.033226141\n",
      "Validation Loss: 0.073975116\n",
      "Epoch: 1532 cost = 0.033204464\n",
      "Validation Loss: 0.057085104\n",
      "Epoch: 1533 cost = 0.033182857\n",
      "Validation Loss: 0.040848825\n",
      "Epoch: 1534 cost = 0.033161666\n",
      "Validation Loss: 0.044191495\n",
      "Epoch: 1535 cost = 0.033140486\n",
      "Validation Loss: 0.045904625\n",
      "Epoch: 1536 cost = 0.033119807\n",
      "Validation Loss: 0.047112428\n",
      "Epoch: 1537 cost = 0.033099079\n",
      "Validation Loss: 0.04758735\n",
      "Epoch: 1538 cost = 0.033078824\n",
      "Validation Loss: 0.05783032\n",
      "Epoch: 1539 cost = 0.033058495\n",
      "Validation Loss: 0.08189108\n",
      "Epoch: 1540 cost = 0.033038756\n",
      "Validation Loss: 0.06943591\n",
      "Epoch: 1541 cost = 0.033018775\n",
      "Validation Loss: 0.07812725\n",
      "Epoch: 1542 cost = 0.032999461\n",
      "Validation Loss: 0.099758446\n",
      "Epoch: 1543 cost = 0.032979830\n",
      "Validation Loss: 0.080743216\n",
      "Epoch: 1544 cost = 0.032960926\n",
      "Validation Loss: 0.0530363\n",
      "Epoch: 1545 cost = 0.032941644\n",
      "Validation Loss: 0.043855347\n",
      "Epoch: 1546 cost = 0.032923122\n",
      "Validation Loss: 0.0405044\n",
      "Epoch: 1547 cost = 0.032904135\n",
      "Validation Loss: 0.09172193\n",
      "Epoch: 1548 cost = 0.032885933\n",
      "Validation Loss: 0.05039852\n",
      "Epoch: 1549 cost = 0.032867310\n",
      "Validation Loss: 0.042380735\n",
      "Epoch: 1550 cost = 0.032849476\n",
      "Validation Loss: 0.045062013\n",
      "Epoch: 1551 cost = 0.032831086\n",
      "Validation Loss: 0.063655764\n",
      "Epoch: 1552 cost = 0.032813585\n",
      "Validation Loss: 0.057182573\n",
      "Epoch: 1553 cost = 0.032795476\n",
      "Validation Loss: 0.08147152\n",
      "Epoch: 1554 cost = 0.032778267\n",
      "Validation Loss: 0.08858493\n",
      "Epoch: 1555 cost = 0.032760445\n",
      "Validation Loss: 0.05939693\n",
      "Epoch: 1556 cost = 0.032743499\n",
      "Validation Loss: 0.039752796\n",
      "Epoch: 1557 cost = 0.032725927\n",
      "Validation Loss: 0.08724724\n",
      "Epoch: 1558 cost = 0.032709232\n",
      "Validation Loss: 0.055009834\n",
      "Epoch: 1559 cost = 0.032691861\n",
      "Validation Loss: 0.04735663\n",
      "Epoch: 1560 cost = 0.032675460\n",
      "Validation Loss: 0.05213193\n",
      "Epoch: 1561 cost = 0.032658298\n",
      "Validation Loss: 0.04801511\n",
      "Epoch: 1562 cost = 0.032642101\n",
      "Validation Loss: 0.047335375\n",
      "Epoch: 1563 cost = 0.032625138\n",
      "Validation Loss: 0.046324126\n",
      "Epoch: 1564 cost = 0.032609196\n",
      "Validation Loss: 0.076976694\n",
      "Epoch: 1565 cost = 0.032592380\n",
      "Validation Loss: 0.08456978\n",
      "Epoch: 1566 cost = 0.032576660\n",
      "Validation Loss: 0.06866042\n",
      "Epoch: 1567 cost = 0.032559972\n",
      "Validation Loss: 0.058824174\n",
      "Epoch: 1568 cost = 0.032544502\n",
      "Validation Loss: 0.047773633\n",
      "Epoch: 1569 cost = 0.032527866\n",
      "Validation Loss: 0.045463674\n",
      "Epoch: 1570 cost = 0.032512728\n",
      "Validation Loss: 0.039962962\n",
      "Epoch: 1571 cost = 0.032495983\n",
      "Validation Loss: 0.04859051\n",
      "Epoch: 1572 cost = 0.032481304\n",
      "Validation Loss: 0.053465288\n",
      "Epoch: 1573 cost = 0.032464321\n",
      "Validation Loss: 0.053538024\n",
      "Epoch: 1574 cost = 0.032450268\n",
      "Validation Loss: 0.045413934\n",
      "Epoch: 1575 cost = 0.032432798\n",
      "Validation Loss: 0.05366273\n",
      "Epoch: 1576 cost = 0.032419931\n",
      "Validation Loss: 0.064307906\n",
      "Epoch: 1577 cost = 0.032401321\n",
      "Validation Loss: 0.060371865\n",
      "Epoch: 1578 cost = 0.032390828\n",
      "Validation Loss: 0.059619546\n",
      "Epoch: 1579 cost = 0.032370411\n",
      "Validation Loss: 0.053173065\n",
      "Epoch: 1580 cost = 0.032365867\n",
      "Validation Loss: 0.041911174\n",
      "Epoch: 1581 cost = 0.032344529\n",
      "Validation Loss: 0.04148568\n",
      "Epoch: 1582 cost = 0.032357599\n",
      "Validation Loss: 0.040956497\n",
      "Epoch: 1583 cost = 0.032349720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03755016\n",
      "Epoch: 1584 cost = 0.032327922\n",
      "Validation Loss: 0.100389935\n",
      "Epoch: 1585 cost = 0.032285516\n",
      "Validation Loss: 0.064170435\n",
      "Epoch: 1586 cost = 0.032286266\n",
      "Validation Loss: 0.06062351\n",
      "Epoch: 1587 cost = 0.032258827\n",
      "Validation Loss: 0.043938078\n",
      "Epoch: 1588 cost = 0.032265555\n",
      "Validation Loss: 0.040686965\n",
      "Epoch: 1589 cost = 0.032236818\n",
      "Validation Loss: 0.044062387\n",
      "Epoch: 1590 cost = 0.032238121\n",
      "Validation Loss: 0.05058541\n",
      "Epoch: 1591 cost = 0.032201696\n",
      "Validation Loss: 0.048816726\n",
      "Epoch: 1592 cost = 0.032202827\n",
      "Validation Loss: 0.048519604\n",
      "Epoch: 1593 cost = 0.032165176\n",
      "Validation Loss: 0.057308763\n",
      "Epoch: 1594 cost = 0.032168898\n",
      "Validation Loss: 0.06251373\n",
      "Epoch: 1595 cost = 0.032131791\n",
      "Validation Loss: 0.051561102\n",
      "Epoch: 1596 cost = 0.032137030\n",
      "Validation Loss: 0.04622175\n",
      "Epoch: 1597 cost = 0.032099577\n",
      "Validation Loss: 0.05457384\n",
      "Epoch: 1598 cost = 0.032106714\n",
      "Validation Loss: 0.040436823\n",
      "Epoch: 1599 cost = 0.032066959\n",
      "Validation Loss: 0.036068983\n",
      "Epoch: 1600 cost = 0.032075811\n",
      "Validation Loss: 0.09723801\n",
      "Epoch: 1601 cost = 0.032032569\n",
      "Validation Loss: 0.064739674\n",
      "Epoch: 1602 cost = 0.032042543\n",
      "Validation Loss: 0.07294866\n",
      "Epoch: 1603 cost = 0.031996881\n",
      "Validation Loss: 0.079211816\n",
      "Epoch: 1604 cost = 0.032007861\n",
      "Validation Loss: 0.060043305\n",
      "Epoch: 1605 cost = 0.031960487\n",
      "Validation Loss: 0.03813459\n",
      "Epoch: 1606 cost = 0.031972829\n",
      "Validation Loss: 0.03911871\n",
      "Epoch: 1607 cost = 0.031923141\n",
      "Validation Loss: 0.036613517\n",
      "Epoch: 1608 cost = 0.031936886\n",
      "Validation Loss: 0.0459627\n",
      "Epoch: 1609 cost = 0.031884311\n",
      "Validation Loss: 0.04576173\n",
      "Epoch: 1610 cost = 0.031898788\n",
      "Validation Loss: 0.06254838\n",
      "Epoch: 1611 cost = 0.031843932\n",
      "Validation Loss: 0.064756945\n",
      "Epoch: 1612 cost = 0.031857659\n",
      "Validation Loss: 0.05568947\n",
      "Epoch: 1613 cost = 0.031802158\n",
      "Validation Loss: 0.058286045\n",
      "Epoch: 1614 cost = 0.031812408\n",
      "Validation Loss: 0.055432\n",
      "Epoch: 1615 cost = 0.031759717\n",
      "Validation Loss: 0.04653761\n",
      "Epoch: 1616 cost = 0.031762525\n",
      "Validation Loss: 0.038733196\n",
      "Epoch: 1617 cost = 0.031717685\n",
      "Validation Loss: 0.038507096\n",
      "Epoch: 1618 cost = 0.031709400\n",
      "Validation Loss: 0.05170509\n",
      "Epoch: 1619 cost = 0.031676360\n",
      "Validation Loss: 0.0477061\n",
      "Epoch: 1620 cost = 0.031656036\n",
      "Validation Loss: 0.06600996\n",
      "Epoch: 1621 cost = 0.031631649\n",
      "Validation Loss: 0.066061355\n",
      "Epoch: 1622 cost = 0.031604062\n",
      "Validation Loss: 0.0682291\n",
      "Epoch: 1623 cost = 0.031580052\n",
      "Validation Loss: 0.055664696\n",
      "Epoch: 1624 cost = 0.031551936\n",
      "Validation Loss: 0.07193017\n",
      "Epoch: 1625 cost = 0.031524628\n",
      "Validation Loss: 0.060292065\n",
      "Epoch: 1626 cost = 0.031496463\n",
      "Validation Loss: 0.05041257\n",
      "Epoch: 1627 cost = 0.031467470\n",
      "Validation Loss: 0.048705626\n",
      "Epoch: 1628 cost = 0.031438071\n",
      "Validation Loss: 0.056910705\n",
      "Epoch: 1629 cost = 0.031408323\n",
      "Validation Loss: 0.059374966\n",
      "Epoch: 1630 cost = 0.031378066\n",
      "Validation Loss: 0.086869\n",
      "Epoch: 1631 cost = 0.031347698\n",
      "Validation Loss: 0.088745914\n",
      "Epoch: 1632 cost = 0.031316961\n",
      "Validation Loss: 0.07580799\n",
      "Epoch: 1633 cost = 0.031286204\n",
      "Validation Loss: 0.07447177\n",
      "Epoch: 1634 cost = 0.031255283\n",
      "Validation Loss: 0.07689034\n",
      "Epoch: 1635 cost = 0.031224511\n",
      "Validation Loss: 0.065303884\n",
      "Epoch: 1636 cost = 0.031193951\n",
      "Validation Loss: 0.051080834\n",
      "Epoch: 1637 cost = 0.031163799\n",
      "Validation Loss: 0.050819628\n",
      "Epoch: 1638 cost = 0.031134344\n",
      "Validation Loss: 0.05456655\n",
      "Epoch: 1639 cost = 0.031105735\n",
      "Validation Loss: 0.06056956\n",
      "Epoch: 1640 cost = 0.031078112\n",
      "Validation Loss: 0.055515386\n",
      "Epoch: 1641 cost = 0.031051599\n",
      "Validation Loss: 0.05799517\n",
      "Epoch: 1642 cost = 0.031026128\n",
      "Validation Loss: 0.056485157\n",
      "Epoch: 1643 cost = 0.031001719\n",
      "Validation Loss: 0.058144983\n",
      "Epoch: 1644 cost = 0.030978402\n",
      "Validation Loss: 0.05141347\n",
      "Epoch: 1645 cost = 0.030955978\n",
      "Validation Loss: 0.044766337\n",
      "Epoch: 1646 cost = 0.030934527\n",
      "Validation Loss: 0.03911269\n",
      "Epoch: 1647 cost = 0.030913886\n",
      "Validation Loss: 0.037626345\n",
      "Epoch: 1648 cost = 0.030894087\n",
      "Validation Loss: 0.04090746\n",
      "Epoch: 1649 cost = 0.030875012\n",
      "Validation Loss: 0.042018052\n",
      "Epoch: 1650 cost = 0.030856653\n",
      "Validation Loss: 0.040085953\n",
      "Epoch: 1651 cost = 0.030838947\n",
      "Validation Loss: 0.046816427\n",
      "Epoch: 1652 cost = 0.030821825\n",
      "Validation Loss: 0.06137295\n",
      "Epoch: 1653 cost = 0.030805284\n",
      "Validation Loss: 0.067106485\n",
      "Epoch: 1654 cost = 0.030789296\n",
      "Validation Loss: 0.06051569\n",
      "Epoch: 1655 cost = 0.030773790\n",
      "Validation Loss: 0.08094758\n",
      "Epoch: 1656 cost = 0.030758739\n",
      "Validation Loss: 0.07075827\n",
      "Epoch: 1657 cost = 0.030744133\n",
      "Validation Loss: 0.08936595\n",
      "Epoch: 1658 cost = 0.030729882\n",
      "Validation Loss: 0.08250189\n",
      "Epoch: 1659 cost = 0.030716042\n",
      "Validation Loss: 0.044605512\n",
      "Epoch: 1660 cost = 0.030702569\n",
      "Validation Loss: 0.04468162\n",
      "Epoch: 1661 cost = 0.030689404\n",
      "Validation Loss: 0.048480384\n",
      "Epoch: 1662 cost = 0.030676591\n",
      "Validation Loss: 0.045705963\n",
      "Epoch: 1663 cost = 0.030663998\n",
      "Validation Loss: 0.03642773\n",
      "Epoch: 1664 cost = 0.030651749\n",
      "Validation Loss: 0.042053666\n",
      "Epoch: 1665 cost = 0.030639701\n",
      "Validation Loss: 0.041501366\n",
      "Epoch: 1666 cost = 0.030627913\n",
      "Validation Loss: 0.039729994\n",
      "Epoch: 1667 cost = 0.030616373\n",
      "Validation Loss: 0.041705392\n",
      "Epoch: 1668 cost = 0.030605035\n",
      "Validation Loss: 0.041331783\n",
      "Epoch: 1669 cost = 0.030593887\n",
      "Validation Loss: 0.04097306\n",
      "Epoch: 1670 cost = 0.030582959\n",
      "Validation Loss: 0.0365164\n",
      "Epoch: 1671 cost = 0.030572174\n",
      "Validation Loss: 0.038988464\n",
      "Epoch: 1672 cost = 0.030561633\n",
      "Validation Loss: 0.04182953\n",
      "Epoch: 1673 cost = 0.030551132\n",
      "Validation Loss: 0.04522924\n",
      "Epoch: 1674 cost = 0.030540977\n",
      "Validation Loss: 0.04395961\n",
      "Epoch: 1675 cost = 0.030530745\n",
      "Validation Loss: 0.04179371\n",
      "Epoch: 1676 cost = 0.030520917\n",
      "Validation Loss: 0.03675057\n",
      "Epoch: 1677 cost = 0.030510947\n",
      "Validation Loss: 0.041118048\n",
      "Epoch: 1678 cost = 0.030501474\n",
      "Validation Loss: 0.045941655\n",
      "Epoch: 1679 cost = 0.030491642\n",
      "Validation Loss: 0.054181546\n",
      "Epoch: 1680 cost = 0.030482519\n",
      "Validation Loss: 0.04411958\n",
      "Epoch: 1681 cost = 0.030472840\n",
      "Validation Loss: 0.039475903\n",
      "Epoch: 1682 cost = 0.030464097\n",
      "Validation Loss: 0.03851321\n",
      "Epoch: 1683 cost = 0.030454463\n",
      "Validation Loss: 0.037726033\n",
      "Epoch: 1684 cost = 0.030446162\n",
      "Validation Loss: 0.035030328\n",
      "Epoch: 1685 cost = 0.030436462\n",
      "Validation Loss: 0.095717296\n",
      "Epoch: 1686 cost = 0.030428706\n",
      "Validation Loss: 0.06344073\n",
      "Epoch: 1687 cost = 0.030418836\n",
      "Validation Loss: 0.046039246\n",
      "Epoch: 1688 cost = 0.030411754\n",
      "Validation Loss: 0.04943281\n",
      "Epoch: 1689 cost = 0.030401502\n",
      "Validation Loss: 0.047939844\n",
      "Epoch: 1690 cost = 0.030395313\n",
      "Validation Loss: 0.041605446\n",
      "Epoch: 1691 cost = 0.030384353\n",
      "Validation Loss: 0.04652177\n",
      "Epoch: 1692 cost = 0.030379477\n",
      "Validation Loss: 0.042866725\n",
      "Epoch: 1693 cost = 0.030367418\n",
      "Validation Loss: 0.04777902\n",
      "Epoch: 1694 cost = 0.030364447\n",
      "Validation Loss: 0.040311214\n",
      "Epoch: 1695 cost = 0.030350531\n",
      "Validation Loss: 0.044556823\n",
      "Epoch: 1696 cost = 0.030350470\n",
      "Validation Loss: 0.048835292\n",
      "Epoch: 1697 cost = 0.030333716\n",
      "Validation Loss: 0.039121863\n",
      "Epoch: 1698 cost = 0.030338235\n",
      "Validation Loss: 0.038478643\n",
      "Epoch: 1699 cost = 0.030317029\n",
      "Validation Loss: 0.045610595\n",
      "Epoch: 1700 cost = 0.030329005\n",
      "Validation Loss: 0.058017686\n",
      "Epoch: 1701 cost = 0.030301269\n",
      "Validation Loss: 0.062454112\n",
      "Epoch: 1702 cost = 0.030325722\n",
      "Validation Loss: 0.052357905\n",
      "Epoch: 1703 cost = 0.030289156\n",
      "Validation Loss: 0.035936095\n",
      "Epoch: 1704 cost = 0.030334543\n",
      "Validation Loss: 0.038358524\n",
      "Epoch: 1705 cost = 0.030289679\n",
      "Validation Loss: 0.038013488\n",
      "Epoch: 1706 cost = 0.030365108\n",
      "Validation Loss: 0.05429842\n",
      "Epoch: 1707 cost = 0.030320888\n",
      "Validation Loss: 0.06504165\n",
      "Epoch: 1708 cost = 0.030405343\n",
      "Validation Loss: 0.076978676\n",
      "Epoch: 1709 cost = 0.030363520\n",
      "Validation Loss: 0.051553797\n",
      "Epoch: 1710 cost = 0.030402570\n",
      "Validation Loss: 0.041271426\n",
      "Epoch: 1711 cost = 0.030343255\n",
      "Validation Loss: 0.042084623\n",
      "Epoch: 1712 cost = 0.030376192\n",
      "Validation Loss: 0.040717583\n",
      "Epoch: 1713 cost = 0.030307803\n",
      "Validation Loss: 0.046224136\n",
      "Epoch: 1714 cost = 0.030352762\n",
      "Validation Loss: 0.049786072\n",
      "Epoch: 1715 cost = 0.030282946\n",
      "Validation Loss: 0.04139342\n",
      "Epoch: 1716 cost = 0.030335166\n",
      "Validation Loss: 0.04369335\n",
      "Epoch: 1717 cost = 0.030265655\n",
      "Validation Loss: 0.043523237\n",
      "Epoch: 1718 cost = 0.030320684\n",
      "Validation Loss: 0.045281224\n",
      "Epoch: 1719 cost = 0.030252063\n",
      "Validation Loss: 0.03743006\n",
      "Epoch: 1720 cost = 0.030307282\n",
      "Validation Loss: 0.05577451\n",
      "Epoch: 1721 cost = 0.030238795\n",
      "Validation Loss: 0.05287715\n",
      "Epoch: 1722 cost = 0.030293663\n",
      "Validation Loss: 0.052264933\n",
      "Epoch: 1723 cost = 0.030224514\n",
      "Validation Loss: 0.059384488\n",
      "Epoch: 1724 cost = 0.030279662\n",
      "Validation Loss: 0.040843647\n",
      "Epoch: 1725 cost = 0.030210035\n",
      "Validation Loss: 0.03977906\n",
      "Epoch: 1726 cost = 0.030265717\n",
      "Validation Loss: 0.04448304\n",
      "Epoch: 1727 cost = 0.030195907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.053776488\n",
      "Epoch: 1728 cost = 0.030252226\n",
      "Validation Loss: 0.069231704\n",
      "Epoch: 1729 cost = 0.030182274\n",
      "Validation Loss: 0.077126764\n",
      "Epoch: 1730 cost = 0.030239143\n",
      "Validation Loss: 0.07554285\n",
      "Epoch: 1731 cost = 0.030169146\n",
      "Validation Loss: 0.06697156\n",
      "Epoch: 1732 cost = 0.030226479\n",
      "Validation Loss: 0.05528117\n",
      "Epoch: 1733 cost = 0.030156358\n",
      "Validation Loss: 0.054082178\n",
      "Epoch: 1734 cost = 0.030214061\n",
      "Validation Loss: 0.060932733\n",
      "Epoch: 1735 cost = 0.030143866\n",
      "Validation Loss: 0.04861785\n",
      "Epoch: 1736 cost = 0.030201892\n",
      "Validation Loss: 0.056317907\n",
      "Epoch: 1737 cost = 0.030131620\n",
      "Validation Loss: 0.045609303\n",
      "Epoch: 1738 cost = 0.030189966\n",
      "Validation Loss: 0.053630006\n",
      "Epoch: 1739 cost = 0.030119584\n",
      "Validation Loss: 0.042385153\n",
      "Epoch: 1740 cost = 0.030178272\n",
      "Validation Loss: 0.048914637\n",
      "Epoch: 1741 cost = 0.030107770\n",
      "Validation Loss: 0.036125008\n",
      "Epoch: 1742 cost = 0.030166804\n",
      "Validation Loss: 0.033125717\n",
      "Epoch: 1743 cost = 0.030096240\n",
      "Validation Loss: 0.07651399\n",
      "Epoch: 1744 cost = 0.030155521\n",
      "Validation Loss: 0.04767548\n",
      "Epoch: 1745 cost = 0.030084900\n",
      "Validation Loss: 0.04715832\n",
      "Epoch: 1746 cost = 0.030144458\n",
      "Validation Loss: 0.04528653\n",
      "Epoch: 1747 cost = 0.030073765\n",
      "Validation Loss: 0.052052937\n",
      "Epoch: 1748 cost = 0.030133603\n",
      "Validation Loss: 0.056305923\n",
      "Epoch: 1749 cost = 0.030062845\n",
      "Validation Loss: 0.05027833\n",
      "Epoch: 1750 cost = 0.030122933\n",
      "Validation Loss: 0.04964998\n",
      "Epoch: 1751 cost = 0.030052076\n",
      "Validation Loss: 0.042284254\n",
      "Epoch: 1752 cost = 0.030112456\n",
      "Validation Loss: 0.039997704\n",
      "Epoch: 1753 cost = 0.030041492\n",
      "Validation Loss: 0.037394065\n",
      "Epoch: 1754 cost = 0.030102132\n",
      "Validation Loss: 0.048844915\n",
      "Epoch: 1755 cost = 0.030031128\n",
      "Validation Loss: 0.04282138\n",
      "Epoch: 1756 cost = 0.030091992\n",
      "Validation Loss: 0.06009243\n",
      "Epoch: 1757 cost = 0.030020913\n",
      "Validation Loss: 0.06270576\n",
      "Epoch: 1758 cost = 0.030082010\n",
      "Validation Loss: 0.059132468\n",
      "Epoch: 1759 cost = 0.030010870\n",
      "Validation Loss: 0.04885507\n",
      "Epoch: 1760 cost = 0.030072206\n",
      "Validation Loss: 0.05373831\n",
      "Epoch: 1761 cost = 0.030000963\n",
      "Validation Loss: 0.04340454\n",
      "Epoch: 1762 cost = 0.030062533\n",
      "Validation Loss: 0.050222613\n",
      "Epoch: 1763 cost = 0.029991199\n",
      "Validation Loss: 0.057561826\n",
      "Epoch: 1764 cost = 0.030053009\n",
      "Validation Loss: 0.050322626\n",
      "Epoch: 1765 cost = 0.029981596\n",
      "Validation Loss: 0.043518122\n",
      "Epoch: 1766 cost = 0.030043624\n",
      "Validation Loss: 0.061310776\n",
      "Epoch: 1767 cost = 0.029972115\n",
      "Validation Loss: 0.046384912\n",
      "Epoch: 1768 cost = 0.030034405\n",
      "Validation Loss: 0.043590095\n",
      "Epoch: 1769 cost = 0.029962769\n",
      "Validation Loss: 0.041976176\n",
      "Epoch: 1770 cost = 0.030025315\n",
      "Validation Loss: 0.036477942\n",
      "Epoch: 1771 cost = 0.029953568\n",
      "Validation Loss: 0.040980533\n",
      "Epoch: 1772 cost = 0.030016329\n",
      "Validation Loss: 0.053572685\n",
      "Epoch: 1773 cost = 0.029944468\n",
      "Validation Loss: 0.04242494\n",
      "Epoch: 1774 cost = 0.030007494\n",
      "Validation Loss: 0.045600943\n",
      "Epoch: 1775 cost = 0.029935506\n",
      "Validation Loss: 0.036688913\n",
      "Epoch: 1776 cost = 0.029998757\n",
      "Validation Loss: 0.07231203\n",
      "Epoch: 1777 cost = 0.029926651\n",
      "Validation Loss: 0.07548975\n",
      "Epoch: 1778 cost = 0.029990164\n",
      "Validation Loss: 0.078627825\n",
      "Epoch: 1779 cost = 0.029917922\n",
      "Validation Loss: 0.04663731\n",
      "Epoch: 1780 cost = 0.029981689\n",
      "Validation Loss: 0.045570243\n",
      "Epoch: 1781 cost = 0.029909312\n",
      "Validation Loss: 0.043606807\n",
      "Epoch: 1782 cost = 0.029973316\n",
      "Validation Loss: 0.04491868\n",
      "Epoch: 1783 cost = 0.029900806\n",
      "Validation Loss: 0.03866223\n",
      "Epoch: 1784 cost = 0.029965058\n",
      "Validation Loss: 0.03863105\n",
      "Epoch: 1785 cost = 0.029892399\n",
      "Validation Loss: 0.039407235\n",
      "Epoch: 1786 cost = 0.029956890\n",
      "Validation Loss: 0.04405499\n",
      "Epoch: 1787 cost = 0.029884090\n",
      "Validation Loss: 0.04207558\n",
      "Epoch: 1788 cost = 0.029948826\n",
      "Validation Loss: 0.05464905\n",
      "Epoch: 1789 cost = 0.029875876\n",
      "Validation Loss: 0.035952263\n",
      "Epoch: 1790 cost = 0.029940859\n",
      "Validation Loss: 0.035029244\n",
      "Epoch: 1791 cost = 0.029867762\n",
      "Validation Loss: 0.033412278\n",
      "Epoch: 1792 cost = 0.029933003\n",
      "Validation Loss: 0.061173417\n",
      "Epoch: 1793 cost = 0.029859712\n",
      "Validation Loss: 0.05862894\n",
      "Epoch: 1794 cost = 0.029925230\n",
      "Validation Loss: 0.06289271\n",
      "Epoch: 1795 cost = 0.029851774\n",
      "Validation Loss: 0.04967617\n",
      "Epoch: 1796 cost = 0.029917556\n",
      "Validation Loss: 0.071786724\n",
      "Epoch: 1797 cost = 0.029843924\n",
      "Validation Loss: 0.054173958\n",
      "Epoch: 1798 cost = 0.029909982\n",
      "Validation Loss: 0.041696925\n",
      "Epoch: 1799 cost = 0.029836171\n",
      "Validation Loss: 0.041313622\n",
      "Epoch: 1800 cost = 0.029902478\n",
      "Validation Loss: 0.045986593\n",
      "Epoch: 1801 cost = 0.029828486\n",
      "Validation Loss: 0.04692454\n",
      "Epoch: 1802 cost = 0.029895069\n",
      "Validation Loss: 0.04730741\n",
      "Epoch: 1803 cost = 0.029820891\n",
      "Validation Loss: 0.03993965\n",
      "Epoch: 1804 cost = 0.029887724\n",
      "Validation Loss: 0.052728236\n",
      "Epoch: 1805 cost = 0.029813340\n",
      "Validation Loss: 0.04146474\n",
      "Epoch: 1806 cost = 0.029880461\n",
      "Validation Loss: 0.04215355\n",
      "Epoch: 1807 cost = 0.029805916\n",
      "Validation Loss: 0.039865177\n",
      "Epoch: 1808 cost = 0.029873297\n",
      "Validation Loss: 0.049079128\n",
      "Epoch: 1809 cost = 0.029798505\n",
      "Validation Loss: 0.04890416\n",
      "Epoch: 1810 cost = 0.029866188\n",
      "Validation Loss: 0.057226174\n",
      "Epoch: 1811 cost = 0.029791199\n",
      "Validation Loss: 0.049425855\n",
      "Epoch: 1812 cost = 0.029859146\n",
      "Validation Loss: 0.051067855\n",
      "Epoch: 1813 cost = 0.029783965\n",
      "Validation Loss: 0.03937956\n",
      "Epoch: 1814 cost = 0.029852178\n",
      "Validation Loss: 0.059595533\n",
      "Epoch: 1815 cost = 0.029776783\n",
      "Validation Loss: 0.060551737\n",
      "Epoch: 1816 cost = 0.029845278\n",
      "Validation Loss: 0.06269321\n",
      "Epoch: 1817 cost = 0.029769650\n",
      "Validation Loss: 0.0444529\n",
      "Epoch: 1818 cost = 0.029838443\n",
      "Validation Loss: 0.04529356\n",
      "Epoch: 1819 cost = 0.029762601\n",
      "Validation Loss: 0.046844058\n",
      "Epoch: 1820 cost = 0.029831647\n",
      "Validation Loss: 0.03802957\n",
      "Epoch: 1821 cost = 0.029755604\n",
      "Validation Loss: 0.038873386\n",
      "Epoch: 1822 cost = 0.029824977\n",
      "Validation Loss: 0.040303048\n",
      "Epoch: 1823 cost = 0.029748690\n",
      "Validation Loss: 0.04301334\n",
      "Epoch: 1824 cost = 0.029818321\n",
      "Validation Loss: 0.038010612\n",
      "Epoch: 1825 cost = 0.029741824\n",
      "Validation Loss: 0.038080964\n",
      "Epoch: 1826 cost = 0.029811769\n",
      "Validation Loss: 0.04274819\n",
      "Epoch: 1827 cost = 0.029735010\n",
      "Validation Loss: 0.040797032\n",
      "Epoch: 1828 cost = 0.029805219\n",
      "Validation Loss: 0.040301558\n",
      "Epoch: 1829 cost = 0.029728235\n",
      "Validation Loss: 0.0370349\n",
      "Epoch: 1830 cost = 0.029798707\n",
      "Validation Loss: 0.04156771\n",
      "Epoch: 1831 cost = 0.029721528\n",
      "Validation Loss: 0.03915583\n",
      "Epoch: 1832 cost = 0.029792317\n",
      "Validation Loss: 0.04125633\n",
      "Epoch: 1833 cost = 0.029714871\n",
      "Validation Loss: 0.049782604\n",
      "Epoch: 1834 cost = 0.029785958\n",
      "Validation Loss: 0.043528914\n",
      "Epoch: 1835 cost = 0.029708281\n",
      "Validation Loss: 0.04618523\n",
      "Epoch: 1836 cost = 0.029779635\n",
      "Validation Loss: 0.036855437\n",
      "Epoch: 1837 cost = 0.029701746\n",
      "Validation Loss: 0.037954\n",
      "Epoch: 1838 cost = 0.029773364\n",
      "Validation Loss: 0.04059112\n",
      "Epoch: 1839 cost = 0.029695223\n",
      "Validation Loss: 0.049230624\n",
      "Epoch: 1840 cost = 0.029767176\n",
      "Validation Loss: 0.050488167\n",
      "Epoch: 1841 cost = 0.029688749\n",
      "Validation Loss: 0.050328083\n",
      "Epoch: 1842 cost = 0.029761005\n",
      "Validation Loss: 0.042295944\n",
      "Epoch: 1843 cost = 0.029682325\n",
      "Validation Loss: 0.035091896\n",
      "Epoch: 1844 cost = 0.029754846\n",
      "Validation Loss: 0.037072755\n",
      "Epoch: 1845 cost = 0.029675970\n",
      "Validation Loss: 0.03711741\n",
      "Epoch: 1846 cost = 0.029748788\n",
      "Validation Loss: 0.03610309\n",
      "Epoch: 1847 cost = 0.029669671\n",
      "Validation Loss: 0.03607963\n",
      "Epoch: 1848 cost = 0.029742752\n",
      "Validation Loss: 0.042845987\n",
      "Epoch: 1849 cost = 0.029663376\n",
      "Validation Loss: 0.03365232\n",
      "Epoch: 1850 cost = 0.029736758\n",
      "Validation Loss: 0.038481314\n",
      "Epoch: 1851 cost = 0.029657151\n",
      "Validation Loss: 0.041058958\n",
      "Epoch: 1852 cost = 0.029730814\n",
      "Validation Loss: 0.05027087\n",
      "Epoch: 1853 cost = 0.029650938\n",
      "Validation Loss: 0.04180583\n",
      "Epoch: 1854 cost = 0.029724908\n",
      "Validation Loss: 0.0494237\n",
      "Epoch: 1855 cost = 0.029644783\n",
      "Validation Loss: 0.03704712\n",
      "Epoch: 1856 cost = 0.029719028\n",
      "Validation Loss: 0.0339458\n",
      "Epoch: 1857 cost = 0.029638683\n",
      "Validation Loss: 0.038370553\n",
      "Epoch: 1858 cost = 0.029713212\n",
      "Validation Loss: 0.037555587\n",
      "Epoch: 1859 cost = 0.029632598\n",
      "Validation Loss: 0.04198394\n",
      "Epoch: 1860 cost = 0.029707408\n",
      "Validation Loss: 0.03807645\n",
      "Epoch: 1861 cost = 0.029626534\n",
      "Validation Loss: 0.037660826\n",
      "Epoch: 1862 cost = 0.029701657\n",
      "Validation Loss: 0.03622234\n",
      "Epoch: 1863 cost = 0.029620546\n",
      "Validation Loss: 0.03847408\n",
      "Epoch: 1864 cost = 0.029695965\n",
      "Validation Loss: 0.04166603\n",
      "Epoch: 1865 cost = 0.029614594\n",
      "Validation Loss: 0.04009039\n",
      "Epoch: 1866 cost = 0.029690272\n",
      "Validation Loss: 0.03160647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1867 cost = 0.029608690\n",
      "Validation Loss: 0.074182056\n",
      "Epoch: 1868 cost = 0.029684618\n",
      "Validation Loss: 0.04654875\n",
      "Epoch: 1869 cost = 0.029602818\n",
      "Validation Loss: 0.033248883\n",
      "Epoch: 1870 cost = 0.029679010\n",
      "Validation Loss: 0.036093757\n",
      "Epoch: 1871 cost = 0.029596950\n",
      "Validation Loss: 0.043389514\n",
      "Epoch: 1872 cost = 0.029673436\n",
      "Validation Loss: 0.04618799\n",
      "Epoch: 1873 cost = 0.029591123\n",
      "Validation Loss: 0.043385748\n",
      "Epoch: 1874 cost = 0.029667878\n",
      "Validation Loss: 0.035164535\n",
      "Epoch: 1875 cost = 0.029585355\n",
      "Validation Loss: 0.040383365\n",
      "Epoch: 1876 cost = 0.029662385\n",
      "Validation Loss: 0.038992133\n",
      "Epoch: 1877 cost = 0.029579585\n",
      "Validation Loss: 0.040494643\n",
      "Epoch: 1878 cost = 0.029656891\n",
      "Validation Loss: 0.05634775\n",
      "Epoch: 1879 cost = 0.029573846\n",
      "Validation Loss: 0.038995273\n",
      "Epoch: 1880 cost = 0.029651413\n",
      "Validation Loss: 0.040365223\n",
      "Epoch: 1881 cost = 0.029568198\n",
      "Validation Loss: 0.03764365\n",
      "Epoch: 1882 cost = 0.029645995\n",
      "Validation Loss: 0.04064986\n",
      "Epoch: 1883 cost = 0.029562532\n",
      "Validation Loss: 0.038264476\n",
      "Epoch: 1884 cost = 0.029640658\n",
      "Validation Loss: 0.03899898\n",
      "Epoch: 1885 cost = 0.029556920\n",
      "Validation Loss: 0.039407082\n",
      "Epoch: 1886 cost = 0.029635302\n",
      "Validation Loss: 0.043489907\n",
      "Epoch: 1887 cost = 0.029551368\n",
      "Validation Loss: 0.04368194\n",
      "Epoch: 1888 cost = 0.029629974\n",
      "Validation Loss: 0.042412907\n",
      "Epoch: 1889 cost = 0.029545772\n",
      "Validation Loss: 0.0430094\n",
      "Epoch: 1890 cost = 0.029624660\n",
      "Validation Loss: 0.037644587\n",
      "Epoch: 1891 cost = 0.029540236\n",
      "Validation Loss: 0.038245905\n",
      "Epoch: 1892 cost = 0.029619351\n",
      "Validation Loss: 0.036765683\n",
      "Epoch: 1893 cost = 0.029534731\n",
      "Validation Loss: 0.034639012\n",
      "Epoch: 1894 cost = 0.029614156\n",
      "Validation Loss: 0.036597636\n",
      "Epoch: 1895 cost = 0.029529254\n",
      "Validation Loss: 0.041155923\n",
      "Epoch: 1896 cost = 0.029608917\n",
      "Validation Loss: 0.036928754\n",
      "Epoch: 1897 cost = 0.029523811\n",
      "Validation Loss: 0.038471412\n",
      "Epoch: 1898 cost = 0.029603737\n",
      "Validation Loss: 0.037471794\n",
      "Epoch: 1899 cost = 0.029518409\n",
      "Validation Loss: 0.035621636\n",
      "Epoch: 1900 cost = 0.029598547\n",
      "Validation Loss: 0.04319354\n",
      "Epoch: 1901 cost = 0.029513020\n",
      "Validation Loss: 0.040488888\n",
      "Epoch: 1902 cost = 0.029593433\n",
      "Validation Loss: 0.040492795\n",
      "Epoch: 1903 cost = 0.029507661\n",
      "Validation Loss: 0.044074874\n",
      "Epoch: 1904 cost = 0.029588295\n",
      "Validation Loss: 0.044773288\n",
      "Epoch: 1905 cost = 0.029502319\n",
      "Validation Loss: 0.048407283\n",
      "Epoch: 1906 cost = 0.029583202\n",
      "Validation Loss: 0.0386002\n",
      "Epoch: 1907 cost = 0.029497022\n",
      "Validation Loss: 0.043372605\n",
      "Epoch: 1908 cost = 0.029578155\n",
      "Validation Loss: 0.03950099\n",
      "Epoch: 1909 cost = 0.029491744\n",
      "Validation Loss: 0.044816885\n",
      "Epoch: 1910 cost = 0.029573123\n",
      "Validation Loss: 0.042382076\n",
      "Epoch: 1911 cost = 0.029486489\n",
      "Validation Loss: 0.046479907\n",
      "Epoch: 1912 cost = 0.029568085\n",
      "Validation Loss: 0.04823036\n",
      "Epoch: 1913 cost = 0.029481246\n",
      "Validation Loss: 0.038668543\n",
      "Epoch: 1914 cost = 0.029563070\n",
      "Validation Loss: 0.03605148\n",
      "Epoch: 1915 cost = 0.029476043\n",
      "Validation Loss: 0.040544283\n",
      "Epoch: 1916 cost = 0.029558093\n",
      "Validation Loss: 0.042069927\n",
      "Epoch: 1917 cost = 0.029470867\n",
      "Validation Loss: 0.03494827\n",
      "Epoch: 1918 cost = 0.029553150\n",
      "Validation Loss: 0.038866527\n",
      "Epoch: 1919 cost = 0.029465732\n",
      "Validation Loss: 0.03497894\n",
      "Epoch: 1920 cost = 0.029548215\n",
      "Validation Loss: 0.034762513\n",
      "Epoch: 1921 cost = 0.029460600\n",
      "Validation Loss: 0.037688833\n",
      "Epoch: 1922 cost = 0.029543306\n",
      "Validation Loss: 0.038161784\n",
      "Epoch: 1923 cost = 0.029455480\n",
      "Validation Loss: 0.036845993\n",
      "Epoch: 1924 cost = 0.029538418\n",
      "Validation Loss: 0.034677297\n",
      "Epoch: 1925 cost = 0.029450419\n",
      "Validation Loss: 0.036708765\n",
      "Epoch: 1926 cost = 0.029533555\n",
      "Validation Loss: 0.042960465\n",
      "Epoch: 1927 cost = 0.029445336\n",
      "Validation Loss: 0.040793862\n",
      "Epoch: 1928 cost = 0.029528711\n",
      "Validation Loss: 0.03315601\n",
      "Epoch: 1929 cost = 0.029440311\n",
      "Validation Loss: 0.03901784\n",
      "Epoch: 1930 cost = 0.029523903\n",
      "Validation Loss: 0.03580351\n",
      "Epoch: 1931 cost = 0.029435347\n",
      "Validation Loss: 0.03556343\n",
      "Epoch: 1932 cost = 0.029519093\n",
      "Validation Loss: 0.03631593\n",
      "Epoch: 1933 cost = 0.029430353\n",
      "Validation Loss: 0.033719137\n",
      "Epoch: 1934 cost = 0.029514280\n",
      "Validation Loss: 0.034764364\n",
      "Epoch: 1935 cost = 0.029425360\n",
      "Validation Loss: 0.03752055\n",
      "Epoch: 1936 cost = 0.029509498\n",
      "Validation Loss: 0.03664093\n",
      "Epoch: 1937 cost = 0.029420429\n",
      "Validation Loss: 0.03826962\n",
      "Epoch: 1938 cost = 0.029504771\n",
      "Validation Loss: 0.038501244\n",
      "Epoch: 1939 cost = 0.029415496\n",
      "Validation Loss: 0.041779585\n",
      "Epoch: 1940 cost = 0.029500032\n",
      "Validation Loss: 0.03678556\n",
      "Epoch: 1941 cost = 0.029410605\n",
      "Validation Loss: 0.04394654\n",
      "Epoch: 1942 cost = 0.029495339\n",
      "Validation Loss: 0.04425122\n",
      "Epoch: 1943 cost = 0.029405734\n",
      "Validation Loss: 0.039997216\n",
      "Epoch: 1944 cost = 0.029490648\n",
      "Validation Loss: 0.036151174\n",
      "Epoch: 1945 cost = 0.029400874\n",
      "Validation Loss: 0.03752272\n",
      "Epoch: 1946 cost = 0.029485996\n",
      "Validation Loss: 0.038553055\n",
      "Epoch: 1947 cost = 0.029396070\n",
      "Validation Loss: 0.045777846\n",
      "Epoch: 1948 cost = 0.029481352\n",
      "Validation Loss: 0.07056505\n",
      "Epoch: 1949 cost = 0.029391230\n",
      "Validation Loss: 0.06798837\n",
      "Epoch: 1950 cost = 0.029476730\n",
      "Validation Loss: 0.07043545\n",
      "Epoch: 1951 cost = 0.029386430\n",
      "Validation Loss: 0.056860253\n",
      "Epoch: 1952 cost = 0.029472094\n",
      "Validation Loss: 0.047927856\n",
      "Epoch: 1953 cost = 0.029381646\n",
      "Validation Loss: 0.040831514\n",
      "Epoch: 1954 cost = 0.029467467\n",
      "Validation Loss: 0.035531342\n",
      "Epoch: 1955 cost = 0.029376909\n",
      "Validation Loss: 0.033476174\n",
      "Epoch: 1956 cost = 0.029462879\n",
      "Validation Loss: 0.03499485\n",
      "Epoch: 1957 cost = 0.029372177\n",
      "Validation Loss: 0.03760274\n",
      "Epoch: 1958 cost = 0.029458309\n",
      "Validation Loss: 0.037642565\n",
      "Epoch: 1959 cost = 0.029367441\n",
      "Validation Loss: 0.03581517\n",
      "Epoch: 1960 cost = 0.029453758\n",
      "Validation Loss: 0.03542689\n",
      "Epoch: 1961 cost = 0.029362769\n",
      "Validation Loss: 0.035572194\n",
      "Epoch: 1962 cost = 0.029449215\n",
      "Validation Loss: 0.04740555\n",
      "Epoch: 1963 cost = 0.029358102\n",
      "Validation Loss: 0.038932472\n",
      "Epoch: 1964 cost = 0.029444688\n",
      "Validation Loss: 0.04307852\n",
      "Epoch: 1965 cost = 0.029353432\n",
      "Validation Loss: 0.03748436\n",
      "Epoch: 1966 cost = 0.029440184\n",
      "Validation Loss: 0.038448244\n",
      "Epoch: 1967 cost = 0.029348793\n",
      "Validation Loss: 0.03441795\n",
      "Epoch: 1968 cost = 0.029435718\n",
      "Validation Loss: 0.036997303\n",
      "Epoch: 1969 cost = 0.029344176\n",
      "Validation Loss: 0.03554039\n",
      "Epoch: 1970 cost = 0.029431230\n",
      "Validation Loss: 0.0414395\n",
      "Epoch: 1971 cost = 0.029339588\n",
      "Validation Loss: 0.04123458\n",
      "Epoch: 1972 cost = 0.029426787\n",
      "Validation Loss: 0.03872673\n",
      "Epoch: 1973 cost = 0.029334993\n",
      "Validation Loss: 0.04489677\n",
      "Epoch: 1974 cost = 0.029422331\n",
      "Validation Loss: 0.039377857\n",
      "Epoch: 1975 cost = 0.029330414\n",
      "Validation Loss: 0.04102085\n",
      "Epoch: 1976 cost = 0.029417905\n",
      "Validation Loss: 0.043252494\n",
      "Epoch: 1977 cost = 0.029325857\n",
      "Validation Loss: 0.04509626\n",
      "Epoch: 1978 cost = 0.029413483\n",
      "Validation Loss: 0.06119045\n",
      "Epoch: 1979 cost = 0.029321341\n",
      "Validation Loss: 0.0552029\n",
      "Epoch: 1980 cost = 0.029409069\n",
      "Validation Loss: 0.049017876\n",
      "Epoch: 1981 cost = 0.029316820\n",
      "Validation Loss: 0.034276426\n",
      "Epoch: 1982 cost = 0.029404702\n",
      "Validation Loss: 0.046170212\n",
      "Epoch: 1983 cost = 0.029312317\n",
      "Validation Loss: 0.03575377\n",
      "Epoch: 1984 cost = 0.029400346\n",
      "Validation Loss: 0.035874\n",
      "Epoch: 1985 cost = 0.029307845\n",
      "Validation Loss: 0.041741554\n",
      "Epoch: 1986 cost = 0.029395996\n",
      "Validation Loss: 0.04087157\n",
      "Epoch: 1987 cost = 0.029303407\n",
      "Validation Loss: 0.045519363\n",
      "Epoch: 1988 cost = 0.029391624\n",
      "Validation Loss: 0.04033108\n",
      "Epoch: 1989 cost = 0.029298951\n",
      "Validation Loss: 0.04046437\n",
      "Epoch: 1990 cost = 0.029387296\n",
      "Validation Loss: 0.03777339\n",
      "Epoch: 1991 cost = 0.029294512\n",
      "Validation Loss: 0.037801024\n",
      "Epoch: 1992 cost = 0.029382973\n",
      "Validation Loss: 0.03822062\n",
      "Epoch: 1993 cost = 0.029290083\n",
      "Validation Loss: 0.04371166\n",
      "Epoch: 1994 cost = 0.029378655\n",
      "Validation Loss: 0.05229098\n",
      "Epoch: 1995 cost = 0.029285689\n",
      "Validation Loss: 0.056084096\n",
      "Epoch: 1996 cost = 0.029374340\n",
      "Validation Loss: 0.05892968\n",
      "Epoch: 1997 cost = 0.029281310\n",
      "Validation Loss: 0.049348358\n",
      "Epoch: 1998 cost = 0.029370080\n",
      "Validation Loss: 0.05523803\n",
      "Epoch: 1999 cost = 0.029276956\n",
      "Validation Loss: 0.042774566\n",
      "Epoch: 2000 cost = 0.029365818\n",
      "Validation Loss: 0.043347992\n",
      "Epoch: 2001 cost = 0.029272589\n",
      "Validation Loss: 0.040398315\n",
      "Epoch: 2002 cost = 0.029361565\n",
      "Validation Loss: 0.03527497\n",
      "Epoch: 2003 cost = 0.029268285\n",
      "Validation Loss: 0.03707347\n",
      "Epoch: 2004 cost = 0.029357351\n",
      "Validation Loss: 0.04187104\n",
      "Epoch: 2005 cost = 0.029263951\n",
      "Validation Loss: 0.04959058\n",
      "Epoch: 2006 cost = 0.029353077\n",
      "Validation Loss: 0.042910863\n",
      "Epoch: 2007 cost = 0.029259627\n",
      "Validation Loss: 0.039726146\n",
      "Epoch: 2008 cost = 0.029348849\n",
      "Validation Loss: 0.048426062\n",
      "Epoch: 2009 cost = 0.029255357\n",
      "Validation Loss: 0.04950858\n",
      "Epoch: 2010 cost = 0.029344664\n",
      "Validation Loss: 0.047474\n",
      "Epoch: 2011 cost = 0.029251075\n",
      "Validation Loss: 0.033680517\n",
      "Epoch: 2012 cost = 0.029340468\n",
      "Validation Loss: 0.038699344\n",
      "Epoch: 2013 cost = 0.029246840\n",
      "Validation Loss: 0.0319517\n",
      "Epoch: 2014 cost = 0.029336298\n",
      "Validation Loss: 0.03620277\n",
      "Epoch: 2015 cost = 0.029242567\n",
      "Validation Loss: 0.03848902\n",
      "Epoch: 2016 cost = 0.029332089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.048333865\n",
      "Epoch: 2017 cost = 0.029238336\n",
      "Validation Loss: 0.051809028\n",
      "Epoch: 2018 cost = 0.029327933\n",
      "Validation Loss: 0.04111028\n",
      "Epoch: 2019 cost = 0.029234135\n",
      "Validation Loss: 0.033936426\n",
      "Epoch: 2020 cost = 0.029323806\n",
      "Validation Loss: 0.046201512\n",
      "Epoch: 2021 cost = 0.029229909\n",
      "Validation Loss: 0.040701278\n",
      "Epoch: 2022 cost = 0.029319680\n",
      "Validation Loss: 0.042407617\n",
      "Epoch: 2023 cost = 0.029225731\n",
      "Validation Loss: 0.03508912\n",
      "Epoch: 2024 cost = 0.029315525\n",
      "Validation Loss: 0.03779184\n",
      "Epoch: 2025 cost = 0.029221536\n",
      "Validation Loss: 0.04121454\n",
      "Epoch: 2026 cost = 0.029311392\n",
      "Validation Loss: 0.043475267\n",
      "Epoch: 2027 cost = 0.029217390\n",
      "Validation Loss: 0.030916013\n",
      "Epoch: 2028 cost = 0.029307293\n",
      "Validation Loss: 0.09678713\n",
      "Epoch: 2029 cost = 0.029213231\n",
      "Validation Loss: 0.0637342\n",
      "Epoch: 2030 cost = 0.029303214\n",
      "Validation Loss: 0.054434076\n",
      "Epoch: 2031 cost = 0.029209103\n",
      "Validation Loss: 0.040576074\n",
      "Epoch: 2032 cost = 0.029299117\n",
      "Validation Loss: 0.04142886\n",
      "Epoch: 2033 cost = 0.029204994\n",
      "Validation Loss: 0.0422774\n",
      "Epoch: 2034 cost = 0.029295039\n",
      "Validation Loss: 0.040413227\n",
      "Epoch: 2035 cost = 0.029200878\n",
      "Validation Loss: 0.045894686\n",
      "Epoch: 2036 cost = 0.029290963\n",
      "Validation Loss: 0.04495019\n",
      "Epoch: 2037 cost = 0.029196789\n",
      "Validation Loss: 0.042040218\n",
      "Epoch: 2038 cost = 0.029286922\n",
      "Validation Loss: 0.03910516\n",
      "Epoch: 2039 cost = 0.029192709\n",
      "Validation Loss: 0.03819349\n",
      "Epoch: 2040 cost = 0.029282880\n",
      "Validation Loss: 0.042147886\n",
      "Epoch: 2041 cost = 0.029188642\n",
      "Validation Loss: 0.045467857\n",
      "Epoch: 2042 cost = 0.029278841\n",
      "Validation Loss: 0.035778448\n",
      "Epoch: 2043 cost = 0.029184575\n",
      "Validation Loss: 0.04122734\n",
      "Epoch: 2044 cost = 0.029274787\n",
      "Validation Loss: 0.046934288\n",
      "Epoch: 2045 cost = 0.029180537\n",
      "Validation Loss: 0.045725442\n",
      "Epoch: 2046 cost = 0.029270814\n",
      "Validation Loss: 0.049521126\n",
      "Epoch: 2047 cost = 0.029176502\n",
      "Validation Loss: 0.04298781\n",
      "Epoch: 2048 cost = 0.029266780\n",
      "Validation Loss: 0.05016017\n",
      "Epoch: 2049 cost = 0.029172471\n",
      "Validation Loss: 0.04451616\n",
      "Epoch: 2050 cost = 0.029262788\n",
      "Validation Loss: 0.041254267\n",
      "Epoch: 2051 cost = 0.029168469\n",
      "Validation Loss: 0.0390644\n",
      "Epoch: 2052 cost = 0.029258779\n",
      "Validation Loss: 0.03942047\n",
      "Epoch: 2053 cost = 0.029164474\n",
      "Validation Loss: 0.040503852\n",
      "Epoch: 2054 cost = 0.029254844\n",
      "Validation Loss: 0.038100537\n",
      "Epoch: 2055 cost = 0.029160499\n",
      "Validation Loss: 0.03802204\n",
      "Epoch: 2056 cost = 0.029250864\n",
      "Validation Loss: 0.036696095\n",
      "Epoch: 2057 cost = 0.029156552\n",
      "Validation Loss: 0.03598141\n",
      "Epoch: 2058 cost = 0.029246885\n",
      "Validation Loss: 0.039663732\n",
      "Epoch: 2059 cost = 0.029152577\n",
      "Validation Loss: 0.04259747\n",
      "Epoch: 2060 cost = 0.029242928\n",
      "Validation Loss: 0.040756814\n",
      "Epoch: 2061 cost = 0.029148633\n",
      "Validation Loss: 0.034971666\n",
      "Epoch: 2062 cost = 0.029239024\n",
      "Validation Loss: 0.038009625\n",
      "Epoch: 2063 cost = 0.029144678\n",
      "Validation Loss: 0.036559872\n",
      "Epoch: 2064 cost = 0.029235071\n",
      "Validation Loss: 0.03759605\n",
      "Epoch: 2065 cost = 0.029140746\n",
      "Validation Loss: 0.038688354\n",
      "Epoch: 2066 cost = 0.029231143\n",
      "Validation Loss: 0.050498676\n",
      "Epoch: 2067 cost = 0.029136847\n",
      "Validation Loss: 0.040068235\n",
      "Epoch: 2068 cost = 0.029227239\n",
      "Validation Loss: 0.03733507\n",
      "Epoch: 2069 cost = 0.029132935\n",
      "Validation Loss: 0.042127628\n",
      "Epoch: 2070 cost = 0.029223320\n",
      "Validation Loss: 0.0470434\n",
      "Epoch: 2071 cost = 0.029129066\n",
      "Validation Loss: 0.043430824\n",
      "Epoch: 2072 cost = 0.029219408\n",
      "Validation Loss: 0.03580526\n",
      "Epoch: 2073 cost = 0.029125184\n",
      "Validation Loss: 0.033639498\n",
      "Epoch: 2074 cost = 0.029215560\n",
      "Validation Loss: 0.038735878\n",
      "Epoch: 2075 cost = 0.029121331\n",
      "Validation Loss: 0.038454298\n",
      "Epoch: 2076 cost = 0.029211653\n",
      "Validation Loss: 0.03650312\n",
      "Epoch: 2077 cost = 0.029117457\n",
      "Validation Loss: 0.034330465\n",
      "Epoch: 2078 cost = 0.029207779\n",
      "Validation Loss: 0.03425664\n",
      "Epoch: 2079 cost = 0.029113618\n",
      "Validation Loss: 0.043201648\n",
      "Epoch: 2080 cost = 0.029203929\n",
      "Validation Loss: 0.039962534\n",
      "Epoch: 2081 cost = 0.029109780\n",
      "Validation Loss: 0.04068342\n",
      "Epoch: 2082 cost = 0.029200073\n",
      "Validation Loss: 0.040721264\n",
      "Epoch: 2083 cost = 0.029105957\n",
      "Validation Loss: 0.03486492\n",
      "Epoch: 2084 cost = 0.029196241\n",
      "Validation Loss: 0.035572663\n",
      "Epoch: 2085 cost = 0.029102158\n",
      "Validation Loss: 0.044329364\n",
      "Epoch: 2086 cost = 0.029192399\n",
      "Validation Loss: 0.039606187\n",
      "Epoch: 2087 cost = 0.029098359\n",
      "Validation Loss: 0.03926203\n",
      "Epoch: 2088 cost = 0.029188576\n",
      "Validation Loss: 0.043490298\n",
      "Epoch: 2089 cost = 0.029094561\n",
      "Validation Loss: 0.04657017\n",
      "Epoch: 2090 cost = 0.029184758\n",
      "Validation Loss: 0.0363552\n",
      "Epoch: 2091 cost = 0.029090775\n",
      "Validation Loss: 0.039395023\n",
      "Epoch: 2092 cost = 0.029180941\n",
      "Validation Loss: 0.050577536\n",
      "Epoch: 2093 cost = 0.029087025\n",
      "Validation Loss: 0.040456373\n",
      "Epoch: 2094 cost = 0.029177153\n",
      "Validation Loss: 0.042233553\n",
      "Epoch: 2095 cost = 0.029083284\n",
      "Validation Loss: 0.034846112\n",
      "Epoch: 2096 cost = 0.029173370\n",
      "Validation Loss: 0.034876436\n",
      "Epoch: 2097 cost = 0.029079521\n",
      "Validation Loss: 0.039894845\n",
      "Epoch: 2098 cost = 0.029169566\n",
      "Validation Loss: 0.03870374\n",
      "Epoch: 2099 cost = 0.029075797\n",
      "Validation Loss: 0.04471961\n",
      "Epoch: 2100 cost = 0.029165822\n",
      "Validation Loss: 0.04068095\n",
      "Epoch: 2101 cost = 0.029072074\n",
      "Validation Loss: 0.036992736\n",
      "Epoch: 2102 cost = 0.029162040\n",
      "Validation Loss: 0.034181483\n",
      "Epoch: 2103 cost = 0.029068312\n",
      "Validation Loss: 0.03331537\n",
      "Epoch: 2104 cost = 0.029158256\n",
      "Validation Loss: 0.033452302\n",
      "Epoch: 2105 cost = 0.029064629\n",
      "Validation Loss: 0.03680644\n",
      "Epoch: 2106 cost = 0.029154502\n",
      "Validation Loss: 0.04323847\n",
      "Epoch: 2107 cost = 0.029060924\n",
      "Validation Loss: 0.04224042\n",
      "Epoch: 2108 cost = 0.029150758\n",
      "Validation Loss: 0.033209722\n",
      "Epoch: 2109 cost = 0.029057242\n",
      "Validation Loss: 0.03263495\n",
      "Epoch: 2110 cost = 0.029147048\n",
      "Validation Loss: 0.037318397\n",
      "Epoch: 2111 cost = 0.029053578\n",
      "Validation Loss: 0.03242332\n",
      "Epoch: 2112 cost = 0.029143307\n",
      "Validation Loss: 0.039388973\n",
      "Epoch: 2113 cost = 0.029049924\n",
      "Validation Loss: 0.04951578\n",
      "Epoch: 2114 cost = 0.029139591\n",
      "Validation Loss: 0.056991354\n",
      "Epoch: 2115 cost = 0.029046262\n",
      "Validation Loss: 0.0550187\n",
      "Epoch: 2116 cost = 0.029135869\n",
      "Validation Loss: 0.047349926\n",
      "Epoch: 2117 cost = 0.029042594\n",
      "Validation Loss: 0.03794201\n",
      "Epoch: 2118 cost = 0.029132157\n",
      "Validation Loss: 0.036311608\n",
      "Epoch: 2119 cost = 0.029038956\n",
      "Validation Loss: 0.034768693\n",
      "Epoch: 2120 cost = 0.029128469\n",
      "Validation Loss: 0.039195426\n",
      "Epoch: 2121 cost = 0.029035314\n",
      "Validation Loss: 0.04092754\n",
      "Epoch: 2122 cost = 0.029124769\n",
      "Validation Loss: 0.03971334\n",
      "Epoch: 2123 cost = 0.029031717\n",
      "Validation Loss: 0.038053606\n",
      "Epoch: 2124 cost = 0.029121118\n",
      "Validation Loss: 0.035510227\n",
      "Epoch: 2125 cost = 0.029028114\n",
      "Validation Loss: 0.036228642\n",
      "Epoch: 2126 cost = 0.029117458\n",
      "Validation Loss: 0.034520164\n",
      "Epoch: 2127 cost = 0.029024521\n",
      "Validation Loss: 0.03631334\n",
      "Epoch: 2128 cost = 0.029113780\n",
      "Validation Loss: 0.035924535\n",
      "Epoch: 2129 cost = 0.029020926\n",
      "Validation Loss: 0.040773213\n",
      "Epoch: 2130 cost = 0.029110121\n",
      "Validation Loss: 0.04354989\n",
      "Epoch: 2131 cost = 0.029017332\n",
      "Validation Loss: 0.046311725\n",
      "Epoch: 2132 cost = 0.029106464\n",
      "Validation Loss: 0.03973064\n",
      "Epoch: 2133 cost = 0.029013766\n",
      "Validation Loss: 0.03814914\n",
      "Epoch: 2134 cost = 0.029102804\n",
      "Validation Loss: 0.034571517\n",
      "Epoch: 2135 cost = 0.029010200\n",
      "Validation Loss: 0.03542503\n",
      "Epoch: 2136 cost = 0.029099178\n",
      "Validation Loss: 0.038020346\n",
      "Epoch: 2137 cost = 0.029006632\n",
      "Validation Loss: 0.03744576\n",
      "Epoch: 2138 cost = 0.029095569\n",
      "Validation Loss: 0.035324723\n",
      "Epoch: 2139 cost = 0.029003087\n",
      "Validation Loss: 0.039888147\n",
      "Epoch: 2140 cost = 0.029091940\n",
      "Validation Loss: 0.06895823\n",
      "Epoch: 2141 cost = 0.028999561\n",
      "Validation Loss: 0.063040145\n",
      "Epoch: 2142 cost = 0.029088336\n",
      "Validation Loss: 0.053012982\n",
      "Epoch: 2143 cost = 0.028996051\n",
      "Validation Loss: 0.03541067\n",
      "Epoch: 2144 cost = 0.029084722\n",
      "Validation Loss: 0.03854584\n",
      "Epoch: 2145 cost = 0.028992535\n",
      "Validation Loss: 0.03633241\n",
      "Epoch: 2146 cost = 0.029081122\n",
      "Validation Loss: 0.036465224\n",
      "Epoch: 2147 cost = 0.028989000\n",
      "Validation Loss: 0.036628656\n",
      "Epoch: 2148 cost = 0.029077529\n",
      "Validation Loss: 0.03629836\n",
      "Epoch: 2149 cost = 0.028985525\n",
      "Validation Loss: 0.039105\n",
      "Epoch: 2150 cost = 0.029073950\n",
      "Validation Loss: 0.04964512\n",
      "Epoch: 2151 cost = 0.028981988\n",
      "Validation Loss: 0.04493\n",
      "Epoch: 2152 cost = 0.029070381\n",
      "Validation Loss: 0.037883967\n",
      "Epoch: 2153 cost = 0.028978523\n",
      "Validation Loss: 0.036087498\n",
      "Epoch: 2154 cost = 0.029066804\n",
      "Validation Loss: 0.03372835\n",
      "Epoch: 2155 cost = 0.028975042\n",
      "Validation Loss: 0.03806833\n",
      "Epoch: 2156 cost = 0.029063238\n",
      "Validation Loss: 0.043910485\n",
      "Epoch: 2157 cost = 0.028971566\n",
      "Validation Loss: 0.06012787\n",
      "Epoch: 2158 cost = 0.029059683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1033533\n",
      "Epoch: 2159 cost = 0.028968117\n",
      "Validation Loss: 0.06034065\n",
      "Epoch: 2160 cost = 0.029056149\n",
      "Validation Loss: 0.06341968\n",
      "Epoch: 2161 cost = 0.028964661\n",
      "Validation Loss: 0.042393006\n",
      "Epoch: 2162 cost = 0.029052627\n",
      "Validation Loss: 0.039860927\n",
      "Epoch: 2163 cost = 0.028961210\n",
      "Validation Loss: 0.041512713\n",
      "Epoch: 2164 cost = 0.029049058\n",
      "Validation Loss: 0.038995877\n",
      "Epoch: 2165 cost = 0.028957758\n",
      "Validation Loss: 0.03419517\n",
      "Epoch: 2166 cost = 0.029045523\n",
      "Validation Loss: 0.044241425\n",
      "Epoch: 2167 cost = 0.028954335\n",
      "Validation Loss: 0.041235387\n",
      "Epoch: 2168 cost = 0.029041995\n",
      "Validation Loss: 0.032264203\n",
      "Epoch: 2169 cost = 0.028950884\n",
      "Validation Loss: 0.03697617\n",
      "Epoch: 2170 cost = 0.029038512\n",
      "Validation Loss: 0.036455546\n",
      "Epoch: 2171 cost = 0.028947512\n",
      "Validation Loss: 0.035593126\n",
      "Epoch: 2172 cost = 0.029035008\n",
      "Validation Loss: 0.042514816\n",
      "Epoch: 2173 cost = 0.028944069\n",
      "Validation Loss: 0.054401614\n",
      "Epoch: 2174 cost = 0.029031503\n",
      "Validation Loss: 0.07798542\n",
      "Epoch: 2175 cost = 0.028940665\n",
      "Validation Loss: 0.0821517\n",
      "Epoch: 2176 cost = 0.029027994\n",
      "Validation Loss: 0.07823553\n",
      "Epoch: 2177 cost = 0.028937270\n",
      "Validation Loss: 0.042747844\n",
      "Epoch: 2178 cost = 0.029024525\n",
      "Validation Loss: 0.059789978\n",
      "Epoch: 2179 cost = 0.028933901\n",
      "Validation Loss: 0.05834602\n",
      "Epoch: 2180 cost = 0.029021038\n",
      "Validation Loss: 0.054612234\n",
      "Epoch: 2181 cost = 0.028930509\n",
      "Validation Loss: 0.048662096\n",
      "Epoch: 2182 cost = 0.029017556\n",
      "Validation Loss: 0.04965289\n",
      "Epoch: 2183 cost = 0.028927157\n",
      "Validation Loss: 0.041570634\n",
      "Epoch: 2184 cost = 0.029014116\n",
      "Validation Loss: 0.039406013\n",
      "Epoch: 2185 cost = 0.028923774\n",
      "Validation Loss: 0.04177326\n",
      "Epoch: 2186 cost = 0.029010648\n",
      "Validation Loss: 0.036814693\n",
      "Epoch: 2187 cost = 0.028920439\n",
      "Validation Loss: 0.034634527\n",
      "Epoch: 2188 cost = 0.029007186\n",
      "Validation Loss: 0.080431625\n",
      "Epoch: 2189 cost = 0.028917076\n",
      "Validation Loss: 0.10231159\n",
      "Epoch: 2190 cost = 0.029003683\n",
      "Validation Loss: 0.13159777\n",
      "Epoch: 2191 cost = 0.028913729\n",
      "Validation Loss: 0.07604367\n",
      "Epoch: 2192 cost = 0.029000275\n",
      "Validation Loss: 0.047457036\n",
      "Epoch: 2193 cost = 0.028910385\n",
      "Validation Loss: 0.03517089\n",
      "Epoch: 2194 cost = 0.028996814\n",
      "Validation Loss: 0.034382895\n",
      "Epoch: 2195 cost = 0.028907044\n",
      "Validation Loss: 0.0361294\n",
      "Epoch: 2196 cost = 0.028993405\n",
      "Validation Loss: 0.035022035\n",
      "Epoch: 2197 cost = 0.028903699\n",
      "Validation Loss: 0.040488962\n",
      "Epoch: 2198 cost = 0.028989983\n",
      "Validation Loss: 0.047723096\n",
      "Epoch: 2199 cost = 0.028900405\n",
      "Validation Loss: 0.040380042\n",
      "Epoch: 2200 cost = 0.028986579\n",
      "Validation Loss: 0.04348496\n",
      "Epoch: 2201 cost = 0.028897089\n",
      "Validation Loss: 0.04655236\n",
      "Epoch: 2202 cost = 0.028983157\n",
      "Validation Loss: 0.038403425\n",
      "Epoch: 2203 cost = 0.028893793\n",
      "Validation Loss: 0.037424237\n",
      "Epoch: 2204 cost = 0.028979756\n",
      "Validation Loss: 0.03670522\n",
      "Epoch: 2205 cost = 0.028890487\n",
      "Validation Loss: 0.035772752\n",
      "Epoch: 2206 cost = 0.028976336\n",
      "Validation Loss: 0.035461098\n",
      "Epoch: 2207 cost = 0.028887181\n",
      "Validation Loss: 0.034900278\n",
      "Epoch: 2208 cost = 0.028972937\n",
      "Validation Loss: 0.0354405\n",
      "Epoch: 2209 cost = 0.028883872\n",
      "Validation Loss: 0.03350245\n",
      "Epoch: 2210 cost = 0.028969579\n",
      "Validation Loss: 0.03685626\n",
      "Epoch: 2211 cost = 0.028880623\n",
      "Validation Loss: 0.038575448\n",
      "Epoch: 2212 cost = 0.028966190\n",
      "Validation Loss: 0.051672246\n",
      "Epoch: 2213 cost = 0.028877346\n",
      "Validation Loss: 0.039800555\n",
      "Epoch: 2214 cost = 0.028962826\n",
      "Validation Loss: 0.042505194\n",
      "Epoch: 2215 cost = 0.028874079\n",
      "Validation Loss: 0.036656357\n",
      "Epoch: 2216 cost = 0.028959454\n",
      "Validation Loss: 0.04106787\n",
      "Epoch: 2217 cost = 0.028870805\n",
      "Validation Loss: 0.03660081\n",
      "Epoch: 2218 cost = 0.028956089\n",
      "Validation Loss: 0.03461906\n",
      "Epoch: 2219 cost = 0.028867546\n",
      "Validation Loss: 0.035181504\n",
      "Epoch: 2220 cost = 0.028952709\n",
      "Validation Loss: 0.036042072\n",
      "Epoch: 2221 cost = 0.028864285\n",
      "Validation Loss: 0.040513605\n",
      "Epoch: 2222 cost = 0.028949339\n",
      "Validation Loss: 0.038786594\n",
      "Epoch: 2223 cost = 0.028861037\n",
      "Validation Loss: 0.031329345\n",
      "Epoch: 2224 cost = 0.028945987\n",
      "Validation Loss: 0.034868434\n",
      "Epoch: 2225 cost = 0.028857798\n",
      "Validation Loss: 0.033942357\n",
      "Epoch: 2226 cost = 0.028942655\n",
      "Validation Loss: 0.03408691\n",
      "Epoch: 2227 cost = 0.028854562\n",
      "Validation Loss: 0.038012233\n",
      "Epoch: 2228 cost = 0.028939332\n",
      "Validation Loss: 0.03935913\n",
      "Epoch: 2229 cost = 0.028851338\n",
      "Validation Loss: 0.03519643\n",
      "Epoch: 2230 cost = 0.028935989\n",
      "Validation Loss: 0.06323646\n",
      "Epoch: 2231 cost = 0.028848104\n",
      "Validation Loss: 0.069704644\n",
      "Epoch: 2232 cost = 0.028932667\n",
      "Validation Loss: 0.0778382\n",
      "Epoch: 2233 cost = 0.028844882\n",
      "Validation Loss: 0.050861433\n",
      "Epoch: 2234 cost = 0.028929313\n",
      "Validation Loss: 0.06207923\n",
      "Epoch: 2235 cost = 0.028841667\n",
      "Validation Loss: 0.04549536\n",
      "Epoch: 2236 cost = 0.028926012\n",
      "Validation Loss: 0.040980898\n",
      "Epoch: 2237 cost = 0.028838459\n",
      "Validation Loss: 0.03228562\n",
      "Epoch: 2238 cost = 0.028922720\n",
      "Validation Loss: 0.032653797\n",
      "Epoch: 2239 cost = 0.028835271\n",
      "Validation Loss: 0.037133116\n",
      "Epoch: 2240 cost = 0.028919413\n",
      "Validation Loss: 0.037709072\n",
      "Epoch: 2241 cost = 0.028832071\n",
      "Validation Loss: 0.04109636\n",
      "Epoch: 2242 cost = 0.028916105\n",
      "Validation Loss: 0.038084175\n",
      "Epoch: 2243 cost = 0.028828860\n",
      "Validation Loss: 0.041658394\n",
      "Epoch: 2244 cost = 0.028912801\n",
      "Validation Loss: 0.03730399\n",
      "Epoch: 2245 cost = 0.028825662\n",
      "Validation Loss: 0.03651007\n",
      "Epoch: 2246 cost = 0.028909521\n",
      "Validation Loss: 0.033761486\n",
      "Epoch: 2247 cost = 0.028822506\n",
      "Validation Loss: 0.03183413\n",
      "Epoch: 2248 cost = 0.028906229\n",
      "Validation Loss: 0.035578605\n",
      "Epoch: 2249 cost = 0.028819317\n",
      "Validation Loss: 0.036250103\n",
      "Epoch: 2250 cost = 0.028902940\n",
      "Validation Loss: 0.035544675\n",
      "Epoch: 2251 cost = 0.028816115\n",
      "Validation Loss: 0.037050437\n",
      "Epoch: 2252 cost = 0.028899656\n",
      "Validation Loss: 0.043847647\n",
      "Epoch: 2253 cost = 0.028812952\n",
      "Validation Loss: 0.04435923\n",
      "Epoch: 2254 cost = 0.028896395\n",
      "Validation Loss: 0.038354833\n",
      "Epoch: 2255 cost = 0.028809796\n",
      "Validation Loss: 0.038459413\n",
      "Epoch: 2256 cost = 0.028893132\n",
      "Validation Loss: 0.03841584\n",
      "Epoch: 2257 cost = 0.028806649\n",
      "Validation Loss: 0.03915736\n",
      "Epoch: 2258 cost = 0.028889898\n",
      "Validation Loss: 0.036198672\n",
      "Epoch: 2259 cost = 0.028803482\n",
      "Validation Loss: 0.039608832\n",
      "Epoch: 2260 cost = 0.028886620\n",
      "Validation Loss: 0.040203225\n",
      "Epoch: 2261 cost = 0.028800331\n",
      "Validation Loss: 0.036052503\n",
      "Epoch: 2262 cost = 0.028883336\n",
      "Validation Loss: 0.03903678\n",
      "Epoch: 2263 cost = 0.028797173\n",
      "Validation Loss: 0.038016327\n",
      "Epoch: 2264 cost = 0.028880100\n",
      "Validation Loss: 0.042329226\n",
      "Epoch: 2265 cost = 0.028794043\n",
      "Validation Loss: 0.04027008\n",
      "Epoch: 2266 cost = 0.028876871\n",
      "Validation Loss: 0.04027536\n",
      "Epoch: 2267 cost = 0.028790886\n",
      "Validation Loss: 0.044398148\n",
      "Epoch: 2268 cost = 0.028873620\n",
      "Validation Loss: 0.036927514\n",
      "Epoch: 2269 cost = 0.028787767\n",
      "Validation Loss: 0.03863724\n",
      "Epoch: 2270 cost = 0.028870377\n",
      "Validation Loss: 0.044524737\n",
      "Epoch: 2271 cost = 0.028784635\n",
      "Validation Loss: 0.039662946\n",
      "Epoch: 2272 cost = 0.028867147\n",
      "Validation Loss: 0.037305314\n",
      "Epoch: 2273 cost = 0.028781514\n",
      "Validation Loss: 0.037799668\n",
      "Epoch: 2274 cost = 0.028863940\n",
      "Validation Loss: 0.03677791\n",
      "Epoch: 2275 cost = 0.028778397\n",
      "Validation Loss: 0.03911841\n",
      "Epoch: 2276 cost = 0.028860717\n",
      "Validation Loss: 0.04395369\n",
      "Epoch: 2277 cost = 0.028775296\n",
      "Validation Loss: 0.037845958\n",
      "Epoch: 2278 cost = 0.028857541\n",
      "Validation Loss: 0.040740173\n",
      "Epoch: 2279 cost = 0.028772172\n",
      "Validation Loss: 0.042260632\n",
      "Epoch: 2280 cost = 0.028854305\n",
      "Validation Loss: 0.04144992\n",
      "Epoch: 2281 cost = 0.028769072\n",
      "Validation Loss: 0.041197013\n",
      "Epoch: 2282 cost = 0.028851084\n",
      "Validation Loss: 0.051266175\n",
      "Epoch: 2283 cost = 0.028765956\n",
      "Validation Loss: 0.06280201\n",
      "Epoch: 2284 cost = 0.028847902\n",
      "Validation Loss: 0.049128044\n",
      "Epoch: 2285 cost = 0.028762870\n",
      "Validation Loss: 0.047002926\n",
      "Epoch: 2286 cost = 0.028844692\n",
      "Validation Loss: 0.039426267\n",
      "Epoch: 2287 cost = 0.028759796\n",
      "Validation Loss: 0.036290485\n",
      "Epoch: 2288 cost = 0.028841519\n",
      "Validation Loss: 0.04199796\n",
      "Epoch: 2289 cost = 0.028756702\n",
      "Validation Loss: 0.04039744\n",
      "Epoch: 2290 cost = 0.028838349\n",
      "Validation Loss: 0.053162742\n",
      "Epoch: 2291 cost = 0.028753603\n",
      "Validation Loss: 0.04852821\n",
      "Epoch: 2292 cost = 0.028835137\n",
      "Validation Loss: 0.037842378\n",
      "Epoch: 2293 cost = 0.028750515\n",
      "Validation Loss: 0.038179174\n",
      "Epoch: 2294 cost = 0.028831945\n",
      "Validation Loss: 0.03548652\n",
      "Epoch: 2295 cost = 0.028747439\n",
      "Validation Loss: 0.03357887\n",
      "Epoch: 2296 cost = 0.028828764\n",
      "Validation Loss: 0.034640763\n",
      "Epoch: 2297 cost = 0.028744363\n",
      "Validation Loss: 0.036677927\n",
      "Epoch: 2298 cost = 0.028825600\n",
      "Validation Loss: 0.035592705\n",
      "Epoch: 2299 cost = 0.028741288\n",
      "Validation Loss: 0.033542268\n",
      "Epoch: 2300 cost = 0.028822425\n",
      "Validation Loss: 0.0371641\n",
      "Epoch: 2301 cost = 0.028738244\n",
      "Validation Loss: 0.040374737\n",
      "Epoch: 2302 cost = 0.028819270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.051250614\n",
      "Epoch: 2303 cost = 0.028735204\n",
      "Validation Loss: 0.0447942\n",
      "Epoch: 2304 cost = 0.028816131\n",
      "Validation Loss: 0.04336292\n",
      "Epoch: 2305 cost = 0.028732126\n",
      "Validation Loss: 0.036482926\n",
      "Epoch: 2306 cost = 0.028812956\n",
      "Validation Loss: 0.036007464\n",
      "Epoch: 2307 cost = 0.028729065\n",
      "Validation Loss: 0.032965746\n",
      "Epoch: 2308 cost = 0.028809775\n",
      "Validation Loss: 0.033668883\n",
      "Epoch: 2309 cost = 0.028725996\n",
      "Validation Loss: 0.036416706\n",
      "Epoch: 2310 cost = 0.028806625\n",
      "Validation Loss: 0.036224578\n",
      "Epoch: 2311 cost = 0.028722965\n",
      "Validation Loss: 0.03912972\n",
      "Epoch: 2312 cost = 0.028803490\n",
      "Validation Loss: 0.037813578\n",
      "Epoch: 2313 cost = 0.028719904\n",
      "Validation Loss: 0.03983916\n",
      "Epoch: 2314 cost = 0.028800347\n",
      "Validation Loss: 0.03981708\n",
      "Epoch: 2315 cost = 0.028716862\n",
      "Validation Loss: 0.039664496\n",
      "Epoch: 2316 cost = 0.028797214\n",
      "Validation Loss: 0.03936169\n",
      "Epoch: 2317 cost = 0.028713867\n",
      "Validation Loss: 0.039238464\n",
      "Epoch: 2318 cost = 0.028794095\n",
      "Validation Loss: 0.03577832\n",
      "Epoch: 2319 cost = 0.028710785\n",
      "Validation Loss: 0.039097045\n",
      "Epoch: 2320 cost = 0.028790962\n",
      "Validation Loss: 0.03557043\n",
      "Epoch: 2321 cost = 0.028707796\n",
      "Validation Loss: 0.034601178\n",
      "Epoch: 2322 cost = 0.028787832\n",
      "Validation Loss: 0.041614093\n",
      "Epoch: 2323 cost = 0.028704774\n",
      "Validation Loss: 0.03678281\n",
      "Epoch: 2324 cost = 0.028784711\n",
      "Validation Loss: 0.042037822\n",
      "Epoch: 2325 cost = 0.028701748\n",
      "Validation Loss: 0.03574426\n",
      "Epoch: 2326 cost = 0.028781591\n",
      "Validation Loss: 0.03456065\n",
      "Epoch: 2327 cost = 0.028698746\n",
      "Validation Loss: 0.040132865\n",
      "Epoch: 2328 cost = 0.028778476\n",
      "Validation Loss: 0.036311258\n",
      "Epoch: 2329 cost = 0.028695708\n",
      "Validation Loss: 0.038915258\n",
      "Epoch: 2330 cost = 0.028775364\n",
      "Validation Loss: 0.04034512\n",
      "Epoch: 2331 cost = 0.028692710\n",
      "Validation Loss: 0.032552425\n",
      "Epoch: 2332 cost = 0.028772239\n",
      "Validation Loss: 0.034554\n",
      "Epoch: 2333 cost = 0.028689686\n",
      "Validation Loss: 0.03742859\n",
      "Epoch: 2334 cost = 0.028769144\n",
      "Validation Loss: 0.035797205\n",
      "Epoch: 2335 cost = 0.028686696\n",
      "Validation Loss: 0.034339298\n",
      "Epoch: 2336 cost = 0.028766040\n",
      "Validation Loss: 0.035105992\n",
      "Epoch: 2337 cost = 0.028683712\n",
      "Validation Loss: 0.034674656\n",
      "Epoch: 2338 cost = 0.028762955\n",
      "Validation Loss: 0.036129657\n",
      "Epoch: 2339 cost = 0.028680711\n",
      "Validation Loss: 0.03951522\n",
      "Epoch: 2340 cost = 0.028759878\n",
      "Validation Loss: 0.039278097\n",
      "Epoch: 2341 cost = 0.028677718\n",
      "Validation Loss: 0.03351466\n",
      "Epoch: 2342 cost = 0.028756756\n",
      "Validation Loss: 0.03779681\n",
      "Epoch: 2343 cost = 0.028674731\n",
      "Validation Loss: 0.034072533\n",
      "Epoch: 2344 cost = 0.028753656\n",
      "Validation Loss: 0.032175332\n",
      "Epoch: 2345 cost = 0.028671724\n",
      "Validation Loss: 0.037898537\n",
      "Epoch: 2346 cost = 0.028750581\n",
      "Validation Loss: 0.039766572\n",
      "Epoch: 2347 cost = 0.028668764\n",
      "Validation Loss: 0.036514346\n",
      "Epoch: 2348 cost = 0.028747511\n",
      "Validation Loss: 0.036568925\n",
      "Epoch: 2349 cost = 0.028665805\n",
      "Validation Loss: 0.035803836\n",
      "Epoch: 2350 cost = 0.028744429\n",
      "Validation Loss: 0.033628266\n",
      "Epoch: 2351 cost = 0.028662807\n",
      "Validation Loss: 0.038356125\n",
      "Epoch: 2352 cost = 0.028741353\n",
      "Validation Loss: 0.036215756\n",
      "Epoch: 2353 cost = 0.028659839\n",
      "Validation Loss: 0.035127066\n",
      "Epoch: 2354 cost = 0.028738287\n",
      "Validation Loss: 0.05189118\n",
      "Epoch: 2355 cost = 0.028656886\n",
      "Validation Loss: 0.03581166\n",
      "Epoch: 2356 cost = 0.028735205\n",
      "Validation Loss: 0.036442507\n",
      "Epoch: 2357 cost = 0.028653917\n",
      "Validation Loss: 0.040151156\n",
      "Epoch: 2358 cost = 0.028732150\n",
      "Validation Loss: 0.044377163\n",
      "Epoch: 2359 cost = 0.028650968\n",
      "Validation Loss: 0.057021428\n",
      "Epoch: 2360 cost = 0.028729082\n",
      "Validation Loss: 0.058243293\n",
      "Epoch: 2361 cost = 0.028648015\n",
      "Validation Loss: 0.041934576\n",
      "Epoch: 2362 cost = 0.028726043\n",
      "Validation Loss: 0.03538193\n",
      "Epoch: 2363 cost = 0.028645058\n",
      "Validation Loss: 0.03630735\n",
      "Epoch: 2364 cost = 0.028722995\n",
      "Validation Loss: 0.035361275\n",
      "Epoch: 2365 cost = 0.028642099\n",
      "Validation Loss: 0.03950978\n",
      "Epoch: 2366 cost = 0.028719948\n",
      "Validation Loss: 0.041259862\n",
      "Epoch: 2367 cost = 0.028639174\n",
      "Validation Loss: 0.041133042\n",
      "Epoch: 2368 cost = 0.028716884\n",
      "Validation Loss: 0.044165816\n",
      "Epoch: 2369 cost = 0.028636216\n",
      "Validation Loss: 0.044416096\n",
      "Epoch: 2370 cost = 0.028713848\n",
      "Validation Loss: 0.04544142\n",
      "Epoch: 2371 cost = 0.028633278\n",
      "Validation Loss: 0.039396085\n",
      "Epoch: 2372 cost = 0.028710807\n",
      "Validation Loss: 0.035826523\n",
      "Epoch: 2373 cost = 0.028630361\n",
      "Validation Loss: 0.03621162\n",
      "Epoch: 2374 cost = 0.028707765\n",
      "Validation Loss: 0.040093813\n",
      "Epoch: 2375 cost = 0.028627426\n",
      "Validation Loss: 0.05136727\n",
      "Epoch: 2376 cost = 0.028704728\n",
      "Validation Loss: 0.04508832\n",
      "Epoch: 2377 cost = 0.028624502\n",
      "Validation Loss: 0.045564637\n",
      "Epoch: 2378 cost = 0.028701730\n",
      "Validation Loss: 0.042380594\n",
      "Epoch: 2379 cost = 0.028621586\n",
      "Validation Loss: 0.042721674\n",
      "Epoch: 2380 cost = 0.028698664\n",
      "Validation Loss: 0.03809662\n",
      "Epoch: 2381 cost = 0.028618668\n",
      "Validation Loss: 0.03715618\n",
      "Epoch: 2382 cost = 0.028695621\n",
      "Validation Loss: 0.041788936\n",
      "Epoch: 2383 cost = 0.028615752\n",
      "Validation Loss: 0.04078732\n",
      "Epoch: 2384 cost = 0.028692618\n",
      "Validation Loss: 0.039865263\n",
      "Epoch: 2385 cost = 0.028612858\n",
      "Validation Loss: 0.040355574\n",
      "Epoch: 2386 cost = 0.028689598\n",
      "Validation Loss: 0.054262493\n",
      "Epoch: 2387 cost = 0.028609940\n",
      "Validation Loss: 0.0659143\n",
      "Epoch: 2388 cost = 0.028686596\n",
      "Validation Loss: 0.08271705\n",
      "Epoch: 2389 cost = 0.028607035\n",
      "Validation Loss: 0.06276836\n",
      "Epoch: 2390 cost = 0.028683593\n",
      "Validation Loss: 0.051839784\n",
      "Epoch: 2391 cost = 0.028604122\n",
      "Validation Loss: 0.03339778\n",
      "Epoch: 2392 cost = 0.028680556\n",
      "Validation Loss: 0.034728352\n",
      "Epoch: 2393 cost = 0.028601213\n",
      "Validation Loss: 0.037688076\n",
      "Epoch: 2394 cost = 0.028677534\n",
      "Validation Loss: 0.03934503\n",
      "Epoch: 2395 cost = 0.028598320\n",
      "Validation Loss: 0.039295282\n",
      "Epoch: 2396 cost = 0.028674535\n",
      "Validation Loss: 0.035338417\n",
      "Epoch: 2397 cost = 0.028595429\n",
      "Validation Loss: 0.03673347\n",
      "Epoch: 2398 cost = 0.028671541\n",
      "Validation Loss: 0.041173212\n",
      "Epoch: 2399 cost = 0.028592565\n",
      "Validation Loss: 0.044659384\n",
      "Epoch: 2400 cost = 0.028668533\n",
      "Validation Loss: 0.038386896\n",
      "Epoch: 2401 cost = 0.028589679\n",
      "Validation Loss: 0.038102366\n",
      "Epoch: 2402 cost = 0.028665531\n",
      "Validation Loss: 0.040303618\n",
      "Epoch: 2403 cost = 0.028586784\n",
      "Validation Loss: 0.037716277\n",
      "Epoch: 2404 cost = 0.028662517\n",
      "Validation Loss: 0.04606701\n",
      "Epoch: 2405 cost = 0.028583917\n",
      "Validation Loss: 0.052809455\n",
      "Epoch: 2406 cost = 0.028659523\n",
      "Validation Loss: 0.049859583\n",
      "Epoch: 2407 cost = 0.028581039\n",
      "Validation Loss: 0.043870274\n",
      "Epoch: 2408 cost = 0.028656527\n",
      "Validation Loss: 0.048484262\n",
      "Epoch: 2409 cost = 0.028578173\n",
      "Validation Loss: 0.0662388\n",
      "Epoch: 2410 cost = 0.028653557\n",
      "Validation Loss: 0.07504713\n",
      "Epoch: 2411 cost = 0.028575302\n",
      "Validation Loss: 0.04969015\n",
      "Epoch: 2412 cost = 0.028650587\n",
      "Validation Loss: 0.045501456\n",
      "Epoch: 2413 cost = 0.028572454\n",
      "Validation Loss: 0.037714746\n",
      "Epoch: 2414 cost = 0.028647591\n",
      "Validation Loss: 0.039458886\n",
      "Epoch: 2415 cost = 0.028569565\n",
      "Validation Loss: 0.03494214\n",
      "Epoch: 2416 cost = 0.028644618\n",
      "Validation Loss: 0.035030838\n",
      "Epoch: 2417 cost = 0.028566737\n",
      "Validation Loss: 0.041153736\n",
      "Epoch: 2418 cost = 0.028641665\n",
      "Validation Loss: 0.038594447\n",
      "Epoch: 2419 cost = 0.028563880\n",
      "Validation Loss: 0.041544877\n",
      "Epoch: 2420 cost = 0.028638690\n",
      "Validation Loss: 0.041070156\n",
      "Epoch: 2421 cost = 0.028561007\n",
      "Validation Loss: 0.039122503\n",
      "Epoch: 2422 cost = 0.028635693\n",
      "Validation Loss: 0.037034586\n",
      "Epoch: 2423 cost = 0.028558168\n",
      "Validation Loss: 0.037702505\n",
      "Epoch: 2424 cost = 0.028632713\n",
      "Validation Loss: 0.037399314\n",
      "Epoch: 2425 cost = 0.028555337\n",
      "Validation Loss: 0.034832288\n",
      "Epoch: 2426 cost = 0.028629743\n",
      "Validation Loss: 0.040753365\n",
      "Epoch: 2427 cost = 0.028552487\n",
      "Validation Loss: 0.066184215\n",
      "Epoch: 2428 cost = 0.028626800\n",
      "Validation Loss: 0.06849324\n",
      "Epoch: 2429 cost = 0.028549650\n",
      "Validation Loss: 0.045777954\n",
      "Epoch: 2430 cost = 0.028623851\n",
      "Validation Loss: 0.039649133\n",
      "Epoch: 2431 cost = 0.028546852\n",
      "Validation Loss: 0.037300456\n",
      "Epoch: 2432 cost = 0.028620896\n",
      "Validation Loss: 0.040426373\n",
      "Epoch: 2433 cost = 0.028544008\n",
      "Validation Loss: 0.038335517\n",
      "Epoch: 2434 cost = 0.028617947\n",
      "Validation Loss: 0.034607753\n",
      "Epoch: 2435 cost = 0.028541191\n",
      "Validation Loss: 0.033526953\n",
      "Epoch: 2436 cost = 0.028615003\n",
      "Validation Loss: 0.03316378\n",
      "Epoch: 2437 cost = 0.028538358\n",
      "Validation Loss: 0.03400832\n",
      "Epoch: 2438 cost = 0.028612060\n",
      "Validation Loss: 0.038058907\n",
      "Epoch: 2439 cost = 0.028535554\n",
      "Validation Loss: 0.036644235\n",
      "Epoch: 2440 cost = 0.028609131\n",
      "Validation Loss: 0.035950545\n",
      "Epoch: 2441 cost = 0.028532755\n",
      "Validation Loss: 0.03876772\n",
      "Epoch: 2442 cost = 0.028606163\n",
      "Validation Loss: 0.03629915\n",
      "Epoch: 2443 cost = 0.028529936\n",
      "Validation Loss: 0.034472983\n",
      "Epoch: 2444 cost = 0.028603240\n",
      "Validation Loss: 0.033884685\n",
      "Epoch: 2445 cost = 0.028527135\n",
      "Validation Loss: 0.036939263\n",
      "Epoch: 2446 cost = 0.028600293\n",
      "Validation Loss: 0.040171314\n",
      "Epoch: 2447 cost = 0.028524335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.050024964\n",
      "Epoch: 2448 cost = 0.028597360\n",
      "Validation Loss: 0.04859685\n",
      "Epoch: 2449 cost = 0.028521529\n",
      "Validation Loss: 0.044674195\n",
      "Epoch: 2450 cost = 0.028594406\n",
      "Validation Loss: 0.05138349\n",
      "Epoch: 2451 cost = 0.028518707\n",
      "Validation Loss: 0.058308456\n",
      "Epoch: 2452 cost = 0.028591486\n",
      "Validation Loss: 0.044004608\n",
      "Epoch: 2453 cost = 0.028515953\n",
      "Validation Loss: 0.03878633\n",
      "Epoch: 2454 cost = 0.028588542\n",
      "Validation Loss: 0.035041176\n",
      "Epoch: 2455 cost = 0.028513172\n",
      "Validation Loss: 0.03638776\n",
      "Epoch: 2456 cost = 0.028585649\n",
      "Validation Loss: 0.034267824\n",
      "Epoch: 2457 cost = 0.028510369\n",
      "Validation Loss: 0.040341362\n",
      "Epoch: 2458 cost = 0.028582722\n",
      "Validation Loss: 0.05185391\n",
      "Epoch: 2459 cost = 0.028507590\n",
      "Validation Loss: 0.040572025\n",
      "Epoch: 2460 cost = 0.028579803\n",
      "Validation Loss: 0.03972142\n",
      "Epoch: 2461 cost = 0.028504818\n",
      "Validation Loss: 0.038921427\n",
      "Epoch: 2462 cost = 0.028576872\n",
      "Validation Loss: 0.037555605\n",
      "Epoch: 2463 cost = 0.028502053\n",
      "Validation Loss: 0.03488377\n",
      "Epoch: 2464 cost = 0.028573944\n",
      "Validation Loss: 0.038344122\n",
      "Epoch: 2465 cost = 0.028499269\n",
      "Validation Loss: 0.03394113\n",
      "Epoch: 2466 cost = 0.028571048\n",
      "Validation Loss: 0.037308477\n",
      "Epoch: 2467 cost = 0.028496526\n",
      "Validation Loss: 0.036535133\n",
      "Epoch: 2468 cost = 0.028568156\n",
      "Validation Loss: 0.03423965\n",
      "Epoch: 2469 cost = 0.028493759\n",
      "Validation Loss: 0.037356146\n",
      "Epoch: 2470 cost = 0.028565229\n",
      "Validation Loss: 0.036043987\n",
      "Epoch: 2471 cost = 0.028490978\n",
      "Validation Loss: 0.034613233\n",
      "Epoch: 2472 cost = 0.028562332\n",
      "Validation Loss: 0.03539625\n",
      "Epoch: 2473 cost = 0.028488211\n",
      "Validation Loss: 0.04257116\n",
      "Epoch: 2474 cost = 0.028559425\n",
      "Validation Loss: 0.044067364\n",
      "Epoch: 2475 cost = 0.028485476\n",
      "Validation Loss: 0.04934349\n",
      "Epoch: 2476 cost = 0.028556557\n",
      "Validation Loss: 0.04370763\n",
      "Epoch: 2477 cost = 0.028482748\n",
      "Validation Loss: 0.036023382\n",
      "Epoch: 2478 cost = 0.028553667\n",
      "Validation Loss: 0.040514346\n",
      "Epoch: 2479 cost = 0.028479998\n",
      "Validation Loss: 0.060757488\n",
      "Epoch: 2480 cost = 0.028550761\n",
      "Validation Loss: 0.08085001\n",
      "Epoch: 2481 cost = 0.028477247\n",
      "Validation Loss: 0.08743974\n",
      "Epoch: 2482 cost = 0.028547870\n",
      "Validation Loss: 0.105120644\n",
      "Epoch: 2483 cost = 0.028474499\n",
      "Validation Loss: 0.10830521\n",
      "Epoch: 2484 cost = 0.028544983\n",
      "Validation Loss: 0.10298053\n",
      "Epoch: 2485 cost = 0.028471778\n",
      "Validation Loss: 0.088646956\n",
      "Epoch: 2486 cost = 0.028542120\n",
      "Validation Loss: 0.063840315\n",
      "Epoch: 2487 cost = 0.028469065\n",
      "Validation Loss: 0.047130816\n",
      "Epoch: 2488 cost = 0.028539217\n",
      "Validation Loss: 0.041794054\n",
      "Epoch: 2489 cost = 0.028466342\n",
      "Validation Loss: 0.03944928\n",
      "Epoch: 2490 cost = 0.028536364\n",
      "Validation Loss: 0.03633717\n",
      "Epoch: 2491 cost = 0.028463619\n",
      "Validation Loss: 0.034596805\n",
      "Epoch: 2492 cost = 0.028533498\n",
      "Validation Loss: 0.036866948\n",
      "Epoch: 2493 cost = 0.028460888\n",
      "Validation Loss: 0.034997236\n",
      "Epoch: 2494 cost = 0.028530611\n",
      "Validation Loss: 0.039935075\n",
      "Epoch: 2495 cost = 0.028458191\n",
      "Validation Loss: 0.045525085\n",
      "Epoch: 2496 cost = 0.028527741\n",
      "Validation Loss: 0.039485518\n",
      "Epoch: 2497 cost = 0.028455490\n",
      "Validation Loss: 0.037780605\n",
      "Epoch: 2498 cost = 0.028524923\n",
      "Validation Loss: 0.046245467\n",
      "Epoch: 2499 cost = 0.028452786\n",
      "Validation Loss: 0.04910806\n",
      "Epoch: 2500 cost = 0.028522074\n",
      "Validation Loss: 0.03974855\n",
      "Epoch: 2501 cost = 0.028450085\n",
      "Validation Loss: 0.0379848\n",
      "Epoch: 2502 cost = 0.028519196\n",
      "Validation Loss: 0.042341277\n",
      "Epoch: 2503 cost = 0.028447369\n",
      "Validation Loss: 0.048256636\n",
      "Epoch: 2504 cost = 0.028516321\n",
      "Validation Loss: 0.067213684\n",
      "Epoch: 2505 cost = 0.028444675\n",
      "Validation Loss: 0.052533943\n",
      "Epoch: 2506 cost = 0.028513454\n",
      "Validation Loss: 0.059473842\n",
      "Epoch: 2507 cost = 0.028441981\n",
      "Validation Loss: 0.053063467\n",
      "Epoch: 2508 cost = 0.028510599\n",
      "Validation Loss: 0.038399074\n",
      "Epoch: 2509 cost = 0.028439288\n",
      "Validation Loss: 0.03234044\n",
      "Epoch: 2510 cost = 0.028507742\n",
      "Validation Loss: 0.031804852\n",
      "Epoch: 2511 cost = 0.028436622\n",
      "Validation Loss: 0.03714902\n",
      "Epoch: 2512 cost = 0.028504946\n",
      "Validation Loss: 0.050830904\n",
      "Epoch: 2513 cost = 0.028433935\n",
      "Validation Loss: 0.04244625\n",
      "Epoch: 2514 cost = 0.028502087\n",
      "Validation Loss: 0.048115782\n",
      "Epoch: 2515 cost = 0.028431261\n",
      "Validation Loss: 0.04445813\n",
      "Epoch: 2516 cost = 0.028499226\n",
      "Validation Loss: 0.036208544\n",
      "Epoch: 2517 cost = 0.028428583\n",
      "Validation Loss: 0.03212028\n",
      "Epoch: 2518 cost = 0.028496397\n",
      "Validation Loss: 0.033576332\n",
      "Epoch: 2519 cost = 0.028425913\n",
      "Validation Loss: 0.03400065\n",
      "Epoch: 2520 cost = 0.028493555\n",
      "Validation Loss: 0.03718184\n",
      "Epoch: 2521 cost = 0.028423255\n",
      "Validation Loss: 0.040196702\n",
      "Epoch: 2522 cost = 0.028490750\n",
      "Validation Loss: 0.03926364\n",
      "Epoch: 2523 cost = 0.028420593\n",
      "Validation Loss: 0.03672602\n",
      "Epoch: 2524 cost = 0.028487939\n",
      "Validation Loss: 0.0370572\n",
      "Epoch: 2525 cost = 0.028417962\n",
      "Validation Loss: 0.042345118\n",
      "Epoch: 2526 cost = 0.028485104\n",
      "Validation Loss: 0.043272316\n",
      "Epoch: 2527 cost = 0.028415293\n",
      "Validation Loss: 0.047576305\n",
      "Epoch: 2528 cost = 0.028482291\n",
      "Validation Loss: 0.048289787\n",
      "Epoch: 2529 cost = 0.028412633\n",
      "Validation Loss: 0.06236934\n",
      "Epoch: 2530 cost = 0.028479468\n",
      "Validation Loss: 0.05031528\n",
      "Epoch: 2531 cost = 0.028410002\n",
      "Validation Loss: 0.033297904\n",
      "Epoch: 2532 cost = 0.028476666\n",
      "Validation Loss: 0.035321407\n",
      "Epoch: 2533 cost = 0.028407346\n",
      "Validation Loss: 0.03620914\n",
      "Epoch: 2534 cost = 0.028473852\n",
      "Validation Loss: 0.03615416\n",
      "Epoch: 2535 cost = 0.028404730\n",
      "Validation Loss: 0.034978632\n",
      "Epoch: 2536 cost = 0.028471049\n",
      "Validation Loss: 0.030776458\n",
      "Epoch: 2537 cost = 0.028402109\n",
      "Validation Loss: 0.05836673\n",
      "Epoch: 2538 cost = 0.028468268\n",
      "Validation Loss: 0.037057072\n",
      "Epoch: 2539 cost = 0.028399490\n",
      "Validation Loss: 0.03834616\n",
      "Epoch: 2540 cost = 0.028465467\n",
      "Validation Loss: 0.04170096\n",
      "Epoch: 2541 cost = 0.028396858\n",
      "Validation Loss: 0.042883843\n",
      "Epoch: 2542 cost = 0.028462655\n",
      "Validation Loss: 0.06762661\n",
      "Epoch: 2543 cost = 0.028394233\n",
      "Validation Loss: 0.06287644\n",
      "Epoch: 2544 cost = 0.028459845\n",
      "Validation Loss: 0.058477532\n",
      "Epoch: 2545 cost = 0.028391624\n",
      "Validation Loss: 0.040469334\n",
      "Epoch: 2546 cost = 0.028457086\n",
      "Validation Loss: 0.044786863\n",
      "Epoch: 2547 cost = 0.028388997\n",
      "Validation Loss: 0.053257614\n",
      "Epoch: 2548 cost = 0.028454276\n",
      "Validation Loss: 0.055356134\n",
      "Epoch: 2549 cost = 0.028386384\n",
      "Validation Loss: 0.052525688\n",
      "Epoch: 2550 cost = 0.028451511\n",
      "Validation Loss: 0.04995164\n",
      "Epoch: 2551 cost = 0.028383784\n",
      "Validation Loss: 0.03691622\n",
      "Epoch: 2552 cost = 0.028448705\n",
      "Validation Loss: 0.03812942\n",
      "Epoch: 2553 cost = 0.028381188\n",
      "Validation Loss: 0.039825138\n",
      "Epoch: 2554 cost = 0.028445940\n",
      "Validation Loss: 0.043352097\n",
      "Epoch: 2555 cost = 0.028378575\n",
      "Validation Loss: 0.05145134\n",
      "Epoch: 2556 cost = 0.028443193\n",
      "Validation Loss: 0.045117095\n",
      "Epoch: 2557 cost = 0.028376025\n",
      "Validation Loss: 0.037923176\n",
      "Epoch: 2558 cost = 0.028440438\n",
      "Validation Loss: 0.03107208\n",
      "Epoch: 2559 cost = 0.028373437\n",
      "Validation Loss: 0.032823883\n",
      "Epoch: 2560 cost = 0.028437645\n",
      "Validation Loss: 0.03789039\n",
      "Epoch: 2561 cost = 0.028370854\n",
      "Validation Loss: 0.039396316\n",
      "Epoch: 2562 cost = 0.028434880\n",
      "Validation Loss: 0.039459314\n",
      "Epoch: 2563 cost = 0.028368263\n",
      "Validation Loss: 0.03903219\n",
      "Epoch: 2564 cost = 0.028432149\n",
      "Validation Loss: 0.037258584\n",
      "Epoch: 2565 cost = 0.028365701\n",
      "Validation Loss: 0.03725098\n",
      "Epoch: 2566 cost = 0.028429367\n",
      "Validation Loss: 0.035937056\n",
      "Epoch: 2567 cost = 0.028363101\n",
      "Validation Loss: 0.034763854\n",
      "Epoch: 2568 cost = 0.028426653\n",
      "Validation Loss: 0.03461071\n",
      "Epoch: 2569 cost = 0.028360559\n",
      "Validation Loss: 0.036997613\n",
      "Epoch: 2570 cost = 0.028423890\n",
      "Validation Loss: 0.033511713\n",
      "Epoch: 2571 cost = 0.028357985\n",
      "Validation Loss: 0.031683814\n",
      "Epoch: 2572 cost = 0.028421160\n",
      "Validation Loss: 0.033847757\n",
      "Epoch: 2573 cost = 0.028355421\n",
      "Validation Loss: 0.035938926\n",
      "Epoch: 2574 cost = 0.028418415\n",
      "Validation Loss: 0.06292538\n",
      "Epoch: 2575 cost = 0.028352886\n",
      "Validation Loss: 0.0673647\n",
      "Epoch: 2576 cost = 0.028415683\n",
      "Validation Loss: 0.057774656\n",
      "Epoch: 2577 cost = 0.028350364\n",
      "Validation Loss: 0.040073838\n",
      "Epoch: 2578 cost = 0.028412959\n",
      "Validation Loss: 0.036100544\n",
      "Epoch: 2579 cost = 0.028347829\n",
      "Validation Loss: 0.040610995\n",
      "Epoch: 2580 cost = 0.028410247\n",
      "Validation Loss: 0.04307255\n",
      "Epoch: 2581 cost = 0.028345290\n",
      "Validation Loss: 0.037454713\n",
      "Epoch: 2582 cost = 0.028407567\n",
      "Validation Loss: 0.03402846\n",
      "Epoch: 2583 cost = 0.028342773\n",
      "Validation Loss: 0.03654354\n",
      "Epoch: 2584 cost = 0.028404839\n",
      "Validation Loss: 0.03531197\n",
      "Epoch: 2585 cost = 0.028340252\n",
      "Validation Loss: 0.039999586\n",
      "Epoch: 2586 cost = 0.028402119\n",
      "Validation Loss: 0.038416635\n",
      "Epoch: 2587 cost = 0.028337721\n",
      "Validation Loss: 0.056191474\n",
      "Epoch: 2588 cost = 0.028399399\n",
      "Validation Loss: 0.061499923\n",
      "Epoch: 2589 cost = 0.028335193\n",
      "Validation Loss: 0.06859452\n",
      "Epoch: 2590 cost = 0.028396685\n",
      "Validation Loss: 0.08666272\n",
      "Epoch: 2591 cost = 0.028332685\n",
      "Validation Loss: 0.07665092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2592 cost = 0.028393987\n",
      "Validation Loss: 0.056054093\n",
      "Epoch: 2593 cost = 0.028330195\n",
      "Validation Loss: 0.04175807\n",
      "Epoch: 2594 cost = 0.028391323\n",
      "Validation Loss: 0.03904169\n",
      "Epoch: 2595 cost = 0.028327699\n",
      "Validation Loss: 0.04169625\n",
      "Epoch: 2596 cost = 0.028388629\n",
      "Validation Loss: 0.037665226\n",
      "Epoch: 2597 cost = 0.028325231\n",
      "Validation Loss: 0.035422537\n",
      "Epoch: 2598 cost = 0.028385950\n",
      "Validation Loss: 0.032168046\n",
      "Epoch: 2599 cost = 0.028322699\n",
      "Validation Loss: 0.034931287\n",
      "Epoch: 2600 cost = 0.028383269\n",
      "Validation Loss: 0.046374965\n",
      "Epoch: 2601 cost = 0.028320228\n",
      "Validation Loss: 0.03958879\n",
      "Epoch: 2602 cost = 0.028380604\n",
      "Validation Loss: 0.05112518\n",
      "Epoch: 2603 cost = 0.028317758\n",
      "Validation Loss: 0.041487932\n",
      "Epoch: 2604 cost = 0.028377976\n",
      "Validation Loss: 0.034472518\n",
      "Epoch: 2605 cost = 0.028315277\n",
      "Validation Loss: 0.03243688\n",
      "Epoch: 2606 cost = 0.028375324\n",
      "Validation Loss: 0.037837524\n",
      "Epoch: 2607 cost = 0.028312806\n",
      "Validation Loss: 0.03877712\n",
      "Epoch: 2608 cost = 0.028372657\n",
      "Validation Loss: 0.048296142\n",
      "Epoch: 2609 cost = 0.028310349\n",
      "Validation Loss: 0.04054283\n",
      "Epoch: 2610 cost = 0.028369998\n",
      "Validation Loss: 0.041493814\n",
      "Epoch: 2611 cost = 0.028307925\n",
      "Validation Loss: 0.040619515\n",
      "Epoch: 2612 cost = 0.028367367\n",
      "Validation Loss: 0.03809325\n",
      "Epoch: 2613 cost = 0.028305451\n",
      "Validation Loss: 0.042298544\n",
      "Epoch: 2614 cost = 0.028364700\n",
      "Validation Loss: 0.037525702\n",
      "Epoch: 2615 cost = 0.028303017\n",
      "Validation Loss: 0.04275327\n",
      "Epoch: 2616 cost = 0.028362110\n",
      "Validation Loss: 0.04409342\n",
      "Epoch: 2617 cost = 0.028300574\n",
      "Validation Loss: 0.050667986\n",
      "Epoch: 2618 cost = 0.028359465\n",
      "Validation Loss: 0.0418563\n",
      "Epoch: 2619 cost = 0.028298150\n",
      "Validation Loss: 0.040331297\n",
      "Epoch: 2620 cost = 0.028356844\n",
      "Validation Loss: 0.032390527\n",
      "Epoch: 2621 cost = 0.028295695\n",
      "Validation Loss: 0.0344956\n",
      "Epoch: 2622 cost = 0.028354197\n",
      "Validation Loss: 0.034082208\n",
      "Epoch: 2623 cost = 0.028293300\n",
      "Validation Loss: 0.036886737\n",
      "Epoch: 2624 cost = 0.028351560\n",
      "Validation Loss: 0.037741903\n",
      "Epoch: 2625 cost = 0.028290851\n",
      "Validation Loss: 0.04909146\n",
      "Epoch: 2626 cost = 0.028348993\n",
      "Validation Loss: 0.055442967\n",
      "Epoch: 2627 cost = 0.028288455\n",
      "Validation Loss: 0.044191547\n",
      "Epoch: 2628 cost = 0.028346368\n",
      "Validation Loss: 0.036658607\n",
      "Epoch: 2629 cost = 0.028286048\n",
      "Validation Loss: 0.031776227\n",
      "Epoch: 2630 cost = 0.028343779\n",
      "Validation Loss: 0.037756134\n",
      "Epoch: 2631 cost = 0.028283648\n",
      "Validation Loss: 0.033754997\n",
      "Epoch: 2632 cost = 0.028341197\n",
      "Validation Loss: 0.034018062\n",
      "Epoch: 2633 cost = 0.028281296\n",
      "Validation Loss: 0.035794087\n",
      "Epoch: 2634 cost = 0.028338636\n",
      "Validation Loss: 0.03600542\n",
      "Epoch: 2635 cost = 0.028278896\n",
      "Validation Loss: 0.03549225\n",
      "Epoch: 2636 cost = 0.028336067\n",
      "Validation Loss: 0.033570793\n",
      "Epoch: 2637 cost = 0.028276507\n",
      "Validation Loss: 0.031384215\n",
      "Epoch: 2638 cost = 0.028333513\n",
      "Validation Loss: 0.032423794\n",
      "Epoch: 2639 cost = 0.028274149\n",
      "Validation Loss: 0.031883784\n",
      "Epoch: 2640 cost = 0.028330927\n",
      "Validation Loss: 0.038853794\n",
      "Epoch: 2641 cost = 0.028271749\n",
      "Validation Loss: 0.037066557\n",
      "Epoch: 2642 cost = 0.028328346\n",
      "Validation Loss: 0.03593483\n",
      "Epoch: 2643 cost = 0.028269387\n",
      "Validation Loss: 0.036733408\n",
      "Epoch: 2644 cost = 0.028325756\n",
      "Validation Loss: 0.036123004\n",
      "Epoch: 2645 cost = 0.028266997\n",
      "Validation Loss: 0.044806127\n",
      "Epoch: 2646 cost = 0.028323225\n",
      "Validation Loss: 0.032665424\n",
      "Epoch: 2647 cost = 0.028264668\n",
      "Validation Loss: 0.03637647\n",
      "Epoch: 2648 cost = 0.028320669\n",
      "Validation Loss: 0.03563104\n",
      "Epoch: 2649 cost = 0.028262325\n",
      "Validation Loss: 0.034734417\n",
      "Epoch: 2650 cost = 0.028318148\n",
      "Validation Loss: 0.035966046\n",
      "Epoch: 2651 cost = 0.028259989\n",
      "Validation Loss: 0.03742556\n",
      "Epoch: 2652 cost = 0.028315659\n",
      "Validation Loss: 0.032380514\n",
      "Epoch: 2653 cost = 0.028257658\n",
      "Validation Loss: 0.032652754\n",
      "Epoch: 2654 cost = 0.028313091\n",
      "Validation Loss: 0.03175964\n",
      "Epoch: 2655 cost = 0.028255346\n",
      "Validation Loss: 0.03629579\n",
      "Epoch: 2656 cost = 0.028310576\n",
      "Validation Loss: 0.037414536\n",
      "Epoch: 2657 cost = 0.028253002\n",
      "Validation Loss: 0.038024873\n",
      "Epoch: 2658 cost = 0.028308059\n",
      "Validation Loss: 0.033976216\n",
      "Epoch: 2659 cost = 0.028250672\n",
      "Validation Loss: 0.035169486\n",
      "Epoch: 2660 cost = 0.028305564\n",
      "Validation Loss: 0.041607957\n",
      "Epoch: 2661 cost = 0.028248393\n",
      "Validation Loss: 0.031010957\n",
      "Epoch: 2662 cost = 0.028303067\n",
      "Validation Loss: 0.031227795\n",
      "Epoch: 2663 cost = 0.028246101\n",
      "Validation Loss: 0.034090266\n",
      "Epoch: 2664 cost = 0.028300593\n",
      "Validation Loss: 0.0444726\n",
      "Epoch: 2665 cost = 0.028243792\n",
      "Validation Loss: 0.056839194\n",
      "Epoch: 2666 cost = 0.028298084\n",
      "Validation Loss: 0.052019242\n",
      "Epoch: 2667 cost = 0.028241478\n",
      "Validation Loss: 0.042329654\n",
      "Epoch: 2668 cost = 0.028295590\n",
      "Validation Loss: 0.042070787\n",
      "Epoch: 2669 cost = 0.028239182\n",
      "Validation Loss: 0.042928483\n",
      "Epoch: 2670 cost = 0.028293110\n",
      "Validation Loss: 0.038131993\n",
      "Epoch: 2671 cost = 0.028236912\n",
      "Validation Loss: 0.045530677\n",
      "Epoch: 2672 cost = 0.028290641\n",
      "Validation Loss: 0.042673446\n",
      "Epoch: 2673 cost = 0.028234626\n",
      "Validation Loss: 0.058537807\n",
      "Epoch: 2674 cost = 0.028288141\n",
      "Validation Loss: 0.059651624\n",
      "Epoch: 2675 cost = 0.028232350\n",
      "Validation Loss: 0.069531836\n",
      "Epoch: 2676 cost = 0.028285694\n",
      "Validation Loss: 0.056206197\n",
      "Epoch: 2677 cost = 0.028230106\n",
      "Validation Loss: 0.035572816\n",
      "Epoch: 2678 cost = 0.028283235\n",
      "Validation Loss: 0.03541747\n",
      "Epoch: 2679 cost = 0.028227860\n",
      "Validation Loss: 0.036435865\n",
      "Epoch: 2680 cost = 0.028280821\n",
      "Validation Loss: 0.03474649\n",
      "Epoch: 2681 cost = 0.028225619\n",
      "Validation Loss: 0.03445842\n",
      "Epoch: 2682 cost = 0.028278411\n",
      "Validation Loss: 0.035035815\n",
      "Epoch: 2683 cost = 0.028223374\n",
      "Validation Loss: 0.03864076\n",
      "Epoch: 2684 cost = 0.028275949\n",
      "Validation Loss: 0.034839068\n",
      "Epoch: 2685 cost = 0.028221116\n",
      "Validation Loss: 0.03340385\n",
      "Epoch: 2686 cost = 0.028273518\n",
      "Validation Loss: 0.03555552\n",
      "Epoch: 2687 cost = 0.028218869\n",
      "Validation Loss: 0.037513178\n",
      "Epoch: 2688 cost = 0.028271066\n",
      "Validation Loss: 0.035748277\n",
      "Epoch: 2689 cost = 0.028216648\n",
      "Validation Loss: 0.034540206\n",
      "Epoch: 2690 cost = 0.028268645\n",
      "Validation Loss: 0.036912218\n",
      "Epoch: 2691 cost = 0.028214404\n",
      "Validation Loss: 0.03411596\n",
      "Epoch: 2692 cost = 0.028266226\n",
      "Validation Loss: 0.040528767\n",
      "Epoch: 2693 cost = 0.028212184\n",
      "Validation Loss: 0.03199088\n",
      "Epoch: 2694 cost = 0.028263815\n",
      "Validation Loss: 0.03875186\n",
      "Epoch: 2695 cost = 0.028209984\n",
      "Validation Loss: 0.03549099\n",
      "Epoch: 2696 cost = 0.028261403\n",
      "Validation Loss: 0.037158128\n",
      "Epoch: 2697 cost = 0.028207771\n",
      "Validation Loss: 0.035654042\n",
      "Epoch: 2698 cost = 0.028259025\n",
      "Validation Loss: 0.041585356\n",
      "Epoch: 2699 cost = 0.028205576\n",
      "Validation Loss: 0.04805667\n",
      "Epoch: 2700 cost = 0.028256661\n",
      "Validation Loss: 0.049276102\n",
      "Epoch: 2701 cost = 0.028203408\n",
      "Validation Loss: 0.041347373\n",
      "Epoch: 2702 cost = 0.028254292\n",
      "Validation Loss: 0.036280423\n",
      "Epoch: 2703 cost = 0.028201219\n",
      "Validation Loss: 0.034191716\n",
      "Epoch: 2704 cost = 0.028251917\n",
      "Validation Loss: 0.033113774\n",
      "Epoch: 2705 cost = 0.028199019\n",
      "Validation Loss: 0.033585567\n",
      "Epoch: 2706 cost = 0.028249562\n",
      "Validation Loss: 0.03969181\n",
      "Epoch: 2707 cost = 0.028196853\n",
      "Validation Loss: 0.03910855\n",
      "Epoch: 2708 cost = 0.028247173\n",
      "Validation Loss: 0.037592057\n",
      "Epoch: 2709 cost = 0.028194667\n",
      "Validation Loss: 0.03638695\n",
      "Epoch: 2710 cost = 0.028244835\n",
      "Validation Loss: 0.03461107\n",
      "Epoch: 2711 cost = 0.028192500\n",
      "Validation Loss: 0.040436845\n",
      "Epoch: 2712 cost = 0.028242455\n",
      "Validation Loss: 0.036593944\n",
      "Epoch: 2713 cost = 0.028190343\n",
      "Validation Loss: 0.037090715\n",
      "Epoch: 2714 cost = 0.028240088\n",
      "Validation Loss: 0.03836795\n",
      "Epoch: 2715 cost = 0.028188191\n",
      "Validation Loss: 0.038322598\n",
      "Epoch: 2716 cost = 0.028237755\n",
      "Validation Loss: 0.043752726\n",
      "Epoch: 2717 cost = 0.028186041\n",
      "Validation Loss: 0.041221276\n",
      "Epoch: 2718 cost = 0.028235415\n",
      "Validation Loss: 0.042718496\n",
      "Epoch: 2719 cost = 0.028183901\n",
      "Validation Loss: 0.031821325\n",
      "Epoch: 2720 cost = 0.028233065\n",
      "Validation Loss: 0.034972265\n",
      "Epoch: 2721 cost = 0.028181744\n",
      "Validation Loss: 0.036466606\n",
      "Epoch: 2722 cost = 0.028230753\n",
      "Validation Loss: 0.034739673\n",
      "Epoch: 2723 cost = 0.028179629\n",
      "Validation Loss: 0.03376105\n",
      "Epoch: 2724 cost = 0.028228457\n",
      "Validation Loss: 0.03828026\n",
      "Epoch: 2725 cost = 0.028177495\n",
      "Validation Loss: 0.03954947\n",
      "Epoch: 2726 cost = 0.028226097\n",
      "Validation Loss: 0.03569819\n",
      "Epoch: 2727 cost = 0.028175362\n",
      "Validation Loss: 0.037836697\n",
      "Epoch: 2728 cost = 0.028223806\n",
      "Validation Loss: 0.03522518\n",
      "Epoch: 2729 cost = 0.028173241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03941684\n",
      "Epoch: 2730 cost = 0.028221468\n",
      "Validation Loss: 0.050957628\n",
      "Epoch: 2731 cost = 0.028171114\n",
      "Validation Loss: 0.053951025\n",
      "Epoch: 2732 cost = 0.028219192\n",
      "Validation Loss: 0.060059022\n",
      "Epoch: 2733 cost = 0.028169009\n",
      "Validation Loss: 0.046912707\n",
      "Epoch: 2734 cost = 0.028216927\n",
      "Validation Loss: 0.042924073\n",
      "Epoch: 2735 cost = 0.028166925\n",
      "Validation Loss: 0.039873067\n",
      "Epoch: 2736 cost = 0.028214658\n",
      "Validation Loss: 0.04542128\n",
      "Epoch: 2737 cost = 0.028164847\n",
      "Validation Loss: 0.04371018\n",
      "Epoch: 2738 cost = 0.028212359\n",
      "Validation Loss: 0.040209826\n",
      "Epoch: 2739 cost = 0.028162742\n",
      "Validation Loss: 0.039001428\n",
      "Epoch: 2740 cost = 0.028210115\n",
      "Validation Loss: 0.041886542\n",
      "Epoch: 2741 cost = 0.028160646\n",
      "Validation Loss: 0.049819827\n",
      "Epoch: 2742 cost = 0.028207853\n",
      "Validation Loss: 0.041247\n",
      "Epoch: 2743 cost = 0.028158581\n",
      "Validation Loss: 0.033903036\n",
      "Epoch: 2744 cost = 0.028205574\n",
      "Validation Loss: 0.0336776\n",
      "Epoch: 2745 cost = 0.028156504\n",
      "Validation Loss: 0.03252039\n",
      "Epoch: 2746 cost = 0.028203340\n",
      "Validation Loss: 0.033935986\n",
      "Epoch: 2747 cost = 0.028154433\n",
      "Validation Loss: 0.037282914\n",
      "Epoch: 2748 cost = 0.028201072\n",
      "Validation Loss: 0.03641687\n",
      "Epoch: 2749 cost = 0.028152341\n",
      "Validation Loss: 0.033848573\n",
      "Epoch: 2750 cost = 0.028198796\n",
      "Validation Loss: 0.03335274\n",
      "Epoch: 2751 cost = 0.028150291\n",
      "Validation Loss: 0.036283057\n",
      "Epoch: 2752 cost = 0.028196565\n",
      "Validation Loss: 0.03400621\n",
      "Epoch: 2753 cost = 0.028148254\n",
      "Validation Loss: 0.03510275\n",
      "Epoch: 2754 cost = 0.028194355\n",
      "Validation Loss: 0.038025554\n",
      "Epoch: 2755 cost = 0.028146186\n",
      "Validation Loss: 0.04132452\n",
      "Epoch: 2756 cost = 0.028192140\n",
      "Validation Loss: 0.03522935\n",
      "Epoch: 2757 cost = 0.028144145\n",
      "Validation Loss: 0.03348189\n",
      "Epoch: 2758 cost = 0.028189900\n",
      "Validation Loss: 0.035670627\n",
      "Epoch: 2759 cost = 0.028142091\n",
      "Validation Loss: 0.03810093\n",
      "Epoch: 2760 cost = 0.028187692\n",
      "Validation Loss: 0.043230362\n",
      "Epoch: 2761 cost = 0.028140060\n",
      "Validation Loss: 0.03541326\n",
      "Epoch: 2762 cost = 0.028185479\n",
      "Validation Loss: 0.034373764\n",
      "Epoch: 2763 cost = 0.028138044\n",
      "Validation Loss: 0.034092035\n",
      "Epoch: 2764 cost = 0.028183272\n",
      "Validation Loss: 0.032993086\n",
      "Epoch: 2765 cost = 0.028136028\n",
      "Validation Loss: 0.04459005\n",
      "Epoch: 2766 cost = 0.028181097\n",
      "Validation Loss: 0.057516333\n",
      "Epoch: 2767 cost = 0.028134000\n",
      "Validation Loss: 0.046118494\n",
      "Epoch: 2768 cost = 0.028178907\n",
      "Validation Loss: 0.03919968\n",
      "Epoch: 2769 cost = 0.028131982\n",
      "Validation Loss: 0.038307577\n",
      "Epoch: 2770 cost = 0.028176671\n",
      "Validation Loss: 0.03530239\n",
      "Epoch: 2771 cost = 0.028129975\n",
      "Validation Loss: 0.041625906\n",
      "Epoch: 2772 cost = 0.028174527\n",
      "Validation Loss: 0.03610447\n",
      "Epoch: 2773 cost = 0.028128002\n",
      "Validation Loss: 0.03411472\n",
      "Epoch: 2774 cost = 0.028172383\n",
      "Validation Loss: 0.033781774\n",
      "Epoch: 2775 cost = 0.028125994\n",
      "Validation Loss: 0.03648398\n",
      "Epoch: 2776 cost = 0.028170181\n",
      "Validation Loss: 0.038893465\n",
      "Epoch: 2777 cost = 0.028124006\n",
      "Validation Loss: 0.0356359\n",
      "Epoch: 2778 cost = 0.028168061\n",
      "Validation Loss: 0.037764896\n",
      "Epoch: 2779 cost = 0.028121978\n",
      "Validation Loss: 0.036406167\n",
      "Epoch: 2780 cost = 0.028165880\n",
      "Validation Loss: 0.031898934\n",
      "Epoch: 2781 cost = 0.028120006\n",
      "Validation Loss: 0.03339561\n",
      "Epoch: 2782 cost = 0.028163713\n",
      "Validation Loss: 0.034468856\n",
      "Epoch: 2783 cost = 0.028118033\n",
      "Validation Loss: 0.03684259\n",
      "Epoch: 2784 cost = 0.028161550\n",
      "Validation Loss: 0.037035856\n",
      "Epoch: 2785 cost = 0.028116065\n",
      "Validation Loss: 0.040050324\n",
      "Epoch: 2786 cost = 0.028159403\n",
      "Validation Loss: 0.041578077\n",
      "Epoch: 2787 cost = 0.028114092\n",
      "Validation Loss: 0.044189543\n",
      "Epoch: 2788 cost = 0.028157277\n",
      "Validation Loss: 0.0430497\n",
      "Epoch: 2789 cost = 0.028112113\n",
      "Validation Loss: 0.047834404\n",
      "Epoch: 2790 cost = 0.028155164\n",
      "Validation Loss: 0.042484287\n",
      "Epoch: 2791 cost = 0.028110163\n",
      "Validation Loss: 0.03922454\n",
      "Epoch: 2792 cost = 0.028153025\n",
      "Validation Loss: 0.04104293\n",
      "Epoch: 2793 cost = 0.028108200\n",
      "Validation Loss: 0.034497894\n",
      "Epoch: 2794 cost = 0.028150877\n",
      "Validation Loss: 0.04387433\n",
      "Epoch: 2795 cost = 0.028106251\n",
      "Validation Loss: 0.03638094\n",
      "Epoch: 2796 cost = 0.028148761\n",
      "Validation Loss: 0.03248461\n",
      "Epoch: 2797 cost = 0.028104299\n",
      "Validation Loss: 0.032735743\n",
      "Epoch: 2798 cost = 0.028146667\n",
      "Validation Loss: 0.038786266\n",
      "Epoch: 2799 cost = 0.028102348\n",
      "Validation Loss: 0.038746994\n",
      "Epoch: 2800 cost = 0.028144549\n",
      "Validation Loss: 0.036552746\n",
      "Epoch: 2801 cost = 0.028100420\n",
      "Validation Loss: 0.03740743\n",
      "Epoch: 2802 cost = 0.028142452\n",
      "Validation Loss: 0.042008933\n",
      "Epoch: 2803 cost = 0.028098461\n",
      "Validation Loss: 0.042896785\n",
      "Epoch: 2804 cost = 0.028140339\n",
      "Validation Loss: 0.04590444\n",
      "Epoch: 2805 cost = 0.028096527\n",
      "Validation Loss: 0.04499888\n",
      "Epoch: 2806 cost = 0.028138255\n",
      "Validation Loss: 0.036730625\n",
      "Epoch: 2807 cost = 0.028094635\n",
      "Validation Loss: 0.033151172\n",
      "Epoch: 2808 cost = 0.028136165\n",
      "Validation Loss: 0.036690135\n",
      "Epoch: 2809 cost = 0.028092696\n",
      "Validation Loss: 0.038331907\n",
      "Epoch: 2810 cost = 0.028134061\n",
      "Validation Loss: 0.04548291\n",
      "Epoch: 2811 cost = 0.028090778\n",
      "Validation Loss: 0.051748727\n",
      "Epoch: 2812 cost = 0.028132015\n",
      "Validation Loss: 0.060390092\n",
      "Epoch: 2813 cost = 0.028088857\n",
      "Validation Loss: 0.052484833\n",
      "Epoch: 2814 cost = 0.028129940\n",
      "Validation Loss: 0.04878914\n",
      "Epoch: 2815 cost = 0.028086972\n",
      "Validation Loss: 0.035400033\n",
      "Epoch: 2816 cost = 0.028127881\n",
      "Validation Loss: 0.03492576\n",
      "Epoch: 2817 cost = 0.028085054\n",
      "Validation Loss: 0.031867094\n",
      "Epoch: 2818 cost = 0.028125829\n",
      "Validation Loss: 0.034748\n",
      "Epoch: 2819 cost = 0.028083169\n",
      "Validation Loss: 0.03373429\n",
      "Epoch: 2820 cost = 0.028123779\n",
      "Validation Loss: 0.034615085\n",
      "Epoch: 2821 cost = 0.028081265\n",
      "Validation Loss: 0.034081142\n",
      "Epoch: 2822 cost = 0.028121694\n",
      "Validation Loss: 0.03336821\n",
      "Epoch: 2823 cost = 0.028079390\n",
      "Validation Loss: 0.046979096\n",
      "Epoch: 2824 cost = 0.028119664\n",
      "Validation Loss: 0.046075493\n",
      "Epoch: 2825 cost = 0.028077485\n",
      "Validation Loss: 0.03944413\n",
      "Epoch: 2826 cost = 0.028117636\n",
      "Validation Loss: 0.03759762\n",
      "Epoch: 2827 cost = 0.028075599\n",
      "Validation Loss: 0.033793394\n",
      "Epoch: 2828 cost = 0.028115587\n",
      "Validation Loss: 0.03584541\n",
      "Epoch: 2829 cost = 0.028073733\n",
      "Validation Loss: 0.04135215\n",
      "Epoch: 2830 cost = 0.028113565\n",
      "Validation Loss: 0.033758968\n",
      "Epoch: 2831 cost = 0.028071859\n",
      "Validation Loss: 0.03244417\n",
      "Epoch: 2832 cost = 0.028111567\n",
      "Validation Loss: 0.042543147\n",
      "Epoch: 2833 cost = 0.028070027\n",
      "Validation Loss: 0.04006951\n",
      "Epoch: 2834 cost = 0.028109540\n",
      "Validation Loss: 0.040169228\n",
      "Epoch: 2835 cost = 0.028068160\n",
      "Validation Loss: 0.039355256\n",
      "Epoch: 2836 cost = 0.028107551\n",
      "Validation Loss: 0.036922194\n",
      "Epoch: 2837 cost = 0.028066297\n",
      "Validation Loss: 0.036697414\n",
      "Epoch: 2838 cost = 0.028105511\n",
      "Validation Loss: 0.03277876\n",
      "Epoch: 2839 cost = 0.028064416\n",
      "Validation Loss: 0.035389986\n",
      "Epoch: 2840 cost = 0.028103505\n",
      "Validation Loss: 0.037616227\n",
      "Epoch: 2841 cost = 0.028062573\n",
      "Validation Loss: 0.046723127\n",
      "Epoch: 2842 cost = 0.028101487\n",
      "Validation Loss: 0.051292937\n",
      "Epoch: 2843 cost = 0.028060744\n",
      "Validation Loss: 0.04419205\n",
      "Epoch: 2844 cost = 0.028099501\n",
      "Validation Loss: 0.041600116\n",
      "Epoch: 2845 cost = 0.028058900\n",
      "Validation Loss: 0.035376754\n",
      "Epoch: 2846 cost = 0.028097504\n",
      "Validation Loss: 0.036104314\n",
      "Epoch: 2847 cost = 0.028057024\n",
      "Validation Loss: 0.03473967\n",
      "Epoch: 2848 cost = 0.028095532\n",
      "Validation Loss: 0.031873707\n",
      "Epoch: 2849 cost = 0.028055210\n",
      "Validation Loss: 0.039007876\n",
      "Epoch: 2850 cost = 0.028093530\n",
      "Validation Loss: 0.040080134\n",
      "Epoch: 2851 cost = 0.028053365\n",
      "Validation Loss: 0.03882842\n",
      "Epoch: 2852 cost = 0.028091545\n",
      "Validation Loss: 0.04269116\n",
      "Epoch: 2853 cost = 0.028051513\n",
      "Validation Loss: 0.06608075\n",
      "Epoch: 2854 cost = 0.028089589\n",
      "Validation Loss: 0.07518765\n",
      "Epoch: 2855 cost = 0.028049721\n",
      "Validation Loss: 0.052739605\n",
      "Epoch: 2856 cost = 0.028087604\n",
      "Validation Loss: 0.039915085\n",
      "Epoch: 2857 cost = 0.028047904\n",
      "Validation Loss: 0.04110403\n",
      "Epoch: 2858 cost = 0.028085656\n",
      "Validation Loss: 0.043173045\n",
      "Epoch: 2859 cost = 0.028046091\n",
      "Validation Loss: 0.034563433\n",
      "Epoch: 2860 cost = 0.028083672\n",
      "Validation Loss: 0.03485139\n",
      "Epoch: 2861 cost = 0.028044281\n",
      "Validation Loss: 0.034185164\n",
      "Epoch: 2862 cost = 0.028081747\n",
      "Validation Loss: 0.033070862\n",
      "Epoch: 2863 cost = 0.028042483\n",
      "Validation Loss: 0.03571176\n",
      "Epoch: 2864 cost = 0.028079819\n",
      "Validation Loss: 0.03758457\n",
      "Epoch: 2865 cost = 0.028040679\n",
      "Validation Loss: 0.03785045\n",
      "Epoch: 2866 cost = 0.028077858\n",
      "Validation Loss: 0.038162973\n",
      "Epoch: 2867 cost = 0.028038881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03454954\n",
      "Epoch: 2868 cost = 0.028075943\n",
      "Validation Loss: 0.03563389\n",
      "Epoch: 2869 cost = 0.028037094\n",
      "Validation Loss: 0.038491193\n",
      "Epoch: 2870 cost = 0.028074012\n",
      "Validation Loss: 0.04066798\n",
      "Epoch: 2871 cost = 0.028035286\n",
      "Validation Loss: 0.044939507\n",
      "Epoch: 2872 cost = 0.028072063\n",
      "Validation Loss: 0.05663768\n",
      "Epoch: 2873 cost = 0.028033502\n",
      "Validation Loss: 0.056062624\n",
      "Epoch: 2874 cost = 0.028070157\n",
      "Validation Loss: 0.04641252\n",
      "Epoch: 2875 cost = 0.028031709\n",
      "Validation Loss: 0.054483477\n",
      "Epoch: 2876 cost = 0.028068221\n",
      "Validation Loss: 0.061555255\n",
      "Epoch: 2877 cost = 0.028029955\n",
      "Validation Loss: 0.082728185\n",
      "Epoch: 2878 cost = 0.028066318\n",
      "Validation Loss: 0.07263959\n",
      "Epoch: 2879 cost = 0.028028186\n",
      "Validation Loss: 0.06098943\n",
      "Epoch: 2880 cost = 0.028064419\n",
      "Validation Loss: 0.045260593\n",
      "Epoch: 2881 cost = 0.028026416\n",
      "Validation Loss: 0.039118655\n",
      "Epoch: 2882 cost = 0.028062517\n",
      "Validation Loss: 0.03470497\n",
      "Epoch: 2883 cost = 0.028024635\n",
      "Validation Loss: 0.03775131\n",
      "Epoch: 2884 cost = 0.028060602\n",
      "Validation Loss: 0.039349433\n",
      "Epoch: 2885 cost = 0.028022885\n",
      "Validation Loss: 0.036616433\n",
      "Epoch: 2886 cost = 0.028058728\n",
      "Validation Loss: 0.033938415\n",
      "Epoch: 2887 cost = 0.028021132\n",
      "Validation Loss: 0.035781227\n",
      "Epoch: 2888 cost = 0.028056856\n",
      "Validation Loss: 0.033982426\n",
      "Epoch: 2889 cost = 0.028019378\n",
      "Validation Loss: 0.033565257\n",
      "Epoch: 2890 cost = 0.028054979\n",
      "Validation Loss: 0.032220997\n",
      "Epoch: 2891 cost = 0.028017623\n",
      "Validation Loss: 0.033780236\n",
      "Epoch: 2892 cost = 0.028053079\n",
      "Validation Loss: 0.032804538\n",
      "Epoch: 2893 cost = 0.028015897\n",
      "Validation Loss: 0.0327307\n",
      "Epoch: 2894 cost = 0.028051203\n",
      "Validation Loss: 0.033578422\n",
      "Epoch: 2895 cost = 0.028014126\n",
      "Validation Loss: 0.039317448\n",
      "Epoch: 2896 cost = 0.028049346\n",
      "Validation Loss: 0.03799987\n",
      "Epoch: 2897 cost = 0.028012384\n",
      "Validation Loss: 0.035649482\n",
      "Epoch: 2898 cost = 0.028047462\n",
      "Validation Loss: 0.033557974\n",
      "Epoch: 2899 cost = 0.028010673\n",
      "Validation Loss: 0.034802064\n",
      "Epoch: 2900 cost = 0.028045602\n",
      "Validation Loss: 0.037639044\n",
      "Epoch: 2901 cost = 0.028008943\n",
      "Validation Loss: 0.040593546\n",
      "Epoch: 2902 cost = 0.028043769\n",
      "Validation Loss: 0.03935262\n",
      "Epoch: 2903 cost = 0.028007222\n",
      "Validation Loss: 0.03892361\n",
      "Epoch: 2904 cost = 0.028041884\n",
      "Validation Loss: 0.034736108\n",
      "Epoch: 2905 cost = 0.028005501\n",
      "Validation Loss: 0.036161777\n",
      "Epoch: 2906 cost = 0.028040072\n",
      "Validation Loss: 0.03586321\n",
      "Epoch: 2907 cost = 0.028003785\n",
      "Validation Loss: 0.03591308\n",
      "Epoch: 2908 cost = 0.028038207\n",
      "Validation Loss: 0.035109077\n",
      "Epoch: 2909 cost = 0.028002048\n",
      "Validation Loss: 0.037623994\n",
      "Epoch: 2910 cost = 0.028036374\n",
      "Validation Loss: 0.035637062\n",
      "Epoch: 2911 cost = 0.028000351\n",
      "Validation Loss: 0.03214898\n",
      "Epoch: 2912 cost = 0.028034517\n",
      "Validation Loss: 0.032486163\n",
      "Epoch: 2913 cost = 0.027998634\n",
      "Validation Loss: 0.035740763\n",
      "Epoch: 2914 cost = 0.028032697\n",
      "Validation Loss: 0.037935607\n",
      "Epoch: 2915 cost = 0.027996925\n",
      "Validation Loss: 0.038476452\n",
      "Epoch: 2916 cost = 0.028030832\n",
      "Validation Loss: 0.03574944\n",
      "Epoch: 2917 cost = 0.027995223\n",
      "Validation Loss: 0.03827925\n",
      "Epoch: 2918 cost = 0.028029001\n",
      "Validation Loss: 0.034635816\n",
      "Epoch: 2919 cost = 0.027993525\n",
      "Validation Loss: 0.03283428\n",
      "Epoch: 2920 cost = 0.028027171\n",
      "Validation Loss: 0.036357906\n",
      "Epoch: 2921 cost = 0.027991827\n",
      "Validation Loss: 0.037987873\n",
      "Epoch: 2922 cost = 0.028025388\n",
      "Validation Loss: 0.037678827\n",
      "Epoch: 2923 cost = 0.027990133\n",
      "Validation Loss: 0.038493738\n",
      "Epoch: 2924 cost = 0.028023586\n",
      "Validation Loss: 0.03690949\n",
      "Epoch: 2925 cost = 0.027988466\n",
      "Validation Loss: 0.04226589\n",
      "Epoch: 2926 cost = 0.028021765\n",
      "Validation Loss: 0.034538504\n",
      "Epoch: 2927 cost = 0.027986786\n",
      "Validation Loss: 0.035704933\n",
      "Epoch: 2928 cost = 0.028019992\n",
      "Validation Loss: 0.03386876\n",
      "Epoch: 2929 cost = 0.027985088\n",
      "Validation Loss: 0.037288036\n",
      "Epoch: 2930 cost = 0.028018192\n",
      "Validation Loss: 0.035128668\n",
      "Epoch: 2931 cost = 0.027983424\n",
      "Validation Loss: 0.033494696\n",
      "Epoch: 2932 cost = 0.028016404\n",
      "Validation Loss: 0.034124188\n",
      "Epoch: 2933 cost = 0.027981744\n",
      "Validation Loss: 0.03942155\n",
      "Epoch: 2934 cost = 0.028014616\n",
      "Validation Loss: 0.04009949\n",
      "Epoch: 2935 cost = 0.027980080\n",
      "Validation Loss: 0.040767692\n",
      "Epoch: 2936 cost = 0.028012838\n",
      "Validation Loss: 0.03677247\n",
      "Epoch: 2937 cost = 0.027978406\n",
      "Validation Loss: 0.03504744\n",
      "Epoch: 2938 cost = 0.028011051\n",
      "Validation Loss: 0.034122363\n",
      "Epoch: 2939 cost = 0.027976740\n",
      "Validation Loss: 0.0384214\n",
      "Epoch: 2940 cost = 0.028009268\n",
      "Validation Loss: 0.0624102\n",
      "Epoch: 2941 cost = 0.027975071\n",
      "Validation Loss: 0.061244927\n",
      "Epoch: 2942 cost = 0.028007481\n",
      "Validation Loss: 0.0444629\n",
      "Epoch: 2943 cost = 0.027973412\n",
      "Validation Loss: 0.04456221\n",
      "Epoch: 2944 cost = 0.028005711\n",
      "Validation Loss: 0.044622023\n",
      "Epoch: 2945 cost = 0.027971780\n",
      "Validation Loss: 0.0486937\n",
      "Epoch: 2946 cost = 0.028003936\n",
      "Validation Loss: 0.04127106\n",
      "Epoch: 2947 cost = 0.027970140\n",
      "Validation Loss: 0.038098805\n",
      "Epoch: 2948 cost = 0.028002191\n",
      "Validation Loss: 0.033716194\n",
      "Epoch: 2949 cost = 0.027968491\n",
      "Validation Loss: 0.0382204\n",
      "Epoch: 2950 cost = 0.028000440\n",
      "Validation Loss: 0.033539962\n",
      "Epoch: 2951 cost = 0.027966855\n",
      "Validation Loss: 0.034723636\n",
      "Epoch: 2952 cost = 0.027998706\n",
      "Validation Loss: 0.039603487\n",
      "Epoch: 2953 cost = 0.027965202\n",
      "Validation Loss: 0.040843748\n",
      "Epoch: 2954 cost = 0.027996982\n",
      "Validation Loss: 0.04989013\n",
      "Epoch: 2955 cost = 0.027963590\n",
      "Validation Loss: 0.053325493\n",
      "Epoch: 2956 cost = 0.027995244\n",
      "Validation Loss: 0.039341692\n",
      "Epoch: 2957 cost = 0.027961957\n",
      "Validation Loss: 0.04105682\n",
      "Epoch: 2958 cost = 0.027993488\n",
      "Validation Loss: 0.04170131\n",
      "Epoch: 2959 cost = 0.027960323\n",
      "Validation Loss: 0.036128435\n",
      "Epoch: 2960 cost = 0.027991750\n",
      "Validation Loss: 0.038284168\n",
      "Epoch: 2961 cost = 0.027958702\n",
      "Validation Loss: 0.04372627\n",
      "Epoch: 2962 cost = 0.027990017\n",
      "Validation Loss: 0.040225044\n",
      "Epoch: 2963 cost = 0.027957085\n",
      "Validation Loss: 0.036746006\n",
      "Epoch: 2964 cost = 0.027988297\n",
      "Validation Loss: 0.03855671\n",
      "Epoch: 2965 cost = 0.027955474\n",
      "Validation Loss: 0.037829544\n",
      "Epoch: 2966 cost = 0.027986544\n",
      "Validation Loss: 0.033528827\n",
      "Epoch: 2967 cost = 0.027953848\n",
      "Validation Loss: 0.03075409\n",
      "Epoch: 2968 cost = 0.027984821\n",
      "Validation Loss: 0.05069954\n",
      "Epoch: 2969 cost = 0.027952259\n",
      "Validation Loss: 0.03448429\n",
      "Epoch: 2970 cost = 0.027983106\n",
      "Validation Loss: 0.038505185\n",
      "Epoch: 2971 cost = 0.027950640\n",
      "Validation Loss: 0.036431827\n",
      "Epoch: 2972 cost = 0.027981399\n",
      "Validation Loss: 0.036169883\n",
      "Epoch: 2973 cost = 0.027949034\n",
      "Validation Loss: 0.039206\n",
      "Epoch: 2974 cost = 0.027979675\n",
      "Validation Loss: 0.035144474\n",
      "Epoch: 2975 cost = 0.027947459\n",
      "Validation Loss: 0.04170156\n",
      "Epoch: 2976 cost = 0.027978018\n",
      "Validation Loss: 0.04349864\n",
      "Epoch: 2977 cost = 0.027945840\n",
      "Validation Loss: 0.044172317\n",
      "Epoch: 2978 cost = 0.027976313\n",
      "Validation Loss: 0.037511773\n",
      "Epoch: 2979 cost = 0.027944258\n",
      "Validation Loss: 0.03412512\n",
      "Epoch: 2980 cost = 0.027974617\n",
      "Validation Loss: 0.0345441\n",
      "Epoch: 2981 cost = 0.027942676\n",
      "Validation Loss: 0.042157013\n",
      "Epoch: 2982 cost = 0.027972934\n",
      "Validation Loss: 0.03658491\n",
      "Epoch: 2983 cost = 0.027941076\n",
      "Validation Loss: 0.03461097\n",
      "Epoch: 2984 cost = 0.027971237\n",
      "Validation Loss: 0.038249042\n",
      "Epoch: 2985 cost = 0.027939479\n",
      "Validation Loss: 0.042007796\n",
      "Epoch: 2986 cost = 0.027969549\n",
      "Validation Loss: 0.04893794\n",
      "Epoch: 2987 cost = 0.027937908\n",
      "Validation Loss: 0.05754622\n",
      "Epoch: 2988 cost = 0.027967857\n",
      "Validation Loss: 0.04279821\n",
      "Epoch: 2989 cost = 0.027936331\n",
      "Validation Loss: 0.032974694\n",
      "Epoch: 2990 cost = 0.027966198\n",
      "Validation Loss: 0.033661697\n",
      "Epoch: 2991 cost = 0.027934739\n",
      "Validation Loss: 0.04675956\n",
      "Epoch: 2992 cost = 0.027964517\n",
      "Validation Loss: 0.050603863\n",
      "Epoch: 2993 cost = 0.027933166\n",
      "Validation Loss: 0.03647432\n",
      "Epoch: 2994 cost = 0.027962831\n",
      "Validation Loss: 0.04293481\n",
      "Epoch: 2995 cost = 0.027931620\n",
      "Validation Loss: 0.04369848\n",
      "Epoch: 2996 cost = 0.027961174\n",
      "Validation Loss: 0.04263541\n",
      "Epoch: 2997 cost = 0.027930050\n",
      "Validation Loss: 0.04082845\n",
      "Epoch: 2998 cost = 0.027959493\n",
      "Validation Loss: 0.033285614\n",
      "Epoch: 2999 cost = 0.027928486\n",
      "Validation Loss: 0.035602476\n",
      "Epoch: 3000 cost = 0.027957838\n",
      "Validation Loss: 0.03390606\n",
      "Epoch: 3001 cost = 0.027926936\n",
      "Validation Loss: 0.03606688\n",
      "Epoch: 3002 cost = 0.027956208\n",
      "Validation Loss: 0.03832973\n",
      "Epoch: 3003 cost = 0.027925374\n",
      "Validation Loss: 0.03410707\n",
      "Epoch: 3004 cost = 0.027954528\n",
      "Validation Loss: 0.041237526\n",
      "Epoch: 3005 cost = 0.027923818\n",
      "Validation Loss: 0.04209156\n",
      "Epoch: 3006 cost = 0.027952891\n",
      "Validation Loss: 0.029551527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3007 cost = 0.027922257\n",
      "Validation Loss: 0.057098\n",
      "Epoch: 3008 cost = 0.027951218\n",
      "Validation Loss: 0.043879375\n",
      "Epoch: 3009 cost = 0.027920717\n",
      "Validation Loss: 0.044610046\n",
      "Epoch: 3010 cost = 0.027949589\n",
      "Validation Loss: 0.053929217\n",
      "Epoch: 3011 cost = 0.027919176\n",
      "Validation Loss: 0.06076191\n",
      "Epoch: 3012 cost = 0.027947954\n",
      "Validation Loss: 0.050608456\n",
      "Epoch: 3013 cost = 0.027917643\n",
      "Validation Loss: 0.04063895\n",
      "Epoch: 3014 cost = 0.027946336\n",
      "Validation Loss: 0.040627114\n",
      "Epoch: 3015 cost = 0.027916120\n",
      "Validation Loss: 0.035240684\n",
      "Epoch: 3016 cost = 0.027944703\n",
      "Validation Loss: 0.03634193\n",
      "Epoch: 3017 cost = 0.027914588\n",
      "Validation Loss: 0.032866377\n",
      "Epoch: 3018 cost = 0.027943091\n",
      "Validation Loss: 0.032450203\n",
      "Epoch: 3019 cost = 0.027913034\n",
      "Validation Loss: 0.03071184\n",
      "Epoch: 3020 cost = 0.027941495\n",
      "Validation Loss: 0.03349995\n",
      "Epoch: 3021 cost = 0.027911525\n",
      "Validation Loss: 0.03777986\n",
      "Epoch: 3022 cost = 0.027939858\n",
      "Validation Loss: 0.05139278\n",
      "Epoch: 3023 cost = 0.027909989\n",
      "Validation Loss: 0.06544267\n",
      "Epoch: 3024 cost = 0.027938234\n",
      "Validation Loss: 0.0785941\n",
      "Epoch: 3025 cost = 0.027908455\n",
      "Validation Loss: 0.058578547\n",
      "Epoch: 3026 cost = 0.027936582\n",
      "Validation Loss: 0.053003505\n",
      "Epoch: 3027 cost = 0.027906941\n",
      "Validation Loss: 0.043530867\n",
      "Epoch: 3028 cost = 0.027934969\n",
      "Validation Loss: 0.040977083\n",
      "Epoch: 3029 cost = 0.027905440\n",
      "Validation Loss: 0.04217344\n",
      "Epoch: 3030 cost = 0.027933364\n",
      "Validation Loss: 0.0504988\n",
      "Epoch: 3031 cost = 0.027903908\n",
      "Validation Loss: 0.05270411\n",
      "Epoch: 3032 cost = 0.027931765\n",
      "Validation Loss: 0.061518483\n",
      "Epoch: 3033 cost = 0.027902412\n",
      "Validation Loss: 0.060909018\n",
      "Epoch: 3034 cost = 0.027930167\n",
      "Validation Loss: 0.04247761\n",
      "Epoch: 3035 cost = 0.027900911\n",
      "Validation Loss: 0.03361685\n",
      "Epoch: 3036 cost = 0.027928595\n",
      "Validation Loss: 0.039707463\n",
      "Epoch: 3037 cost = 0.027899417\n",
      "Validation Loss: 0.033812553\n",
      "Epoch: 3038 cost = 0.027927022\n",
      "Validation Loss: 0.03119633\n",
      "Epoch: 3039 cost = 0.027897904\n",
      "Validation Loss: 0.035097234\n",
      "Epoch: 3040 cost = 0.027925419\n",
      "Validation Loss: 0.038896814\n",
      "Epoch: 3041 cost = 0.027896403\n",
      "Validation Loss: 0.032652617\n",
      "Epoch: 3042 cost = 0.027923857\n",
      "Validation Loss: 0.035638336\n",
      "Epoch: 3043 cost = 0.027894910\n",
      "Validation Loss: 0.034533508\n",
      "Epoch: 3044 cost = 0.027922256\n",
      "Validation Loss: 0.03990471\n",
      "Epoch: 3045 cost = 0.027893415\n",
      "Validation Loss: 0.041199513\n",
      "Epoch: 3046 cost = 0.027920657\n",
      "Validation Loss: 0.043845296\n",
      "Epoch: 3047 cost = 0.027891908\n",
      "Validation Loss: 0.04506642\n",
      "Epoch: 3048 cost = 0.027919083\n",
      "Validation Loss: 0.040016714\n",
      "Epoch: 3049 cost = 0.027890424\n",
      "Validation Loss: 0.040206563\n",
      "Epoch: 3050 cost = 0.027917491\n",
      "Validation Loss: 0.03726605\n",
      "Epoch: 3051 cost = 0.027888958\n",
      "Validation Loss: 0.037920278\n",
      "Epoch: 3052 cost = 0.027915954\n",
      "Validation Loss: 0.041456416\n",
      "Epoch: 3053 cost = 0.027887485\n",
      "Validation Loss: 0.033997387\n",
      "Epoch: 3054 cost = 0.027914377\n",
      "Validation Loss: 0.038538054\n",
      "Epoch: 3055 cost = 0.027885966\n",
      "Validation Loss: 0.04064002\n",
      "Epoch: 3056 cost = 0.027912822\n",
      "Validation Loss: 0.048721902\n",
      "Epoch: 3057 cost = 0.027884519\n",
      "Validation Loss: 0.046210054\n",
      "Epoch: 3058 cost = 0.027911266\n",
      "Validation Loss: 0.04309373\n",
      "Epoch: 3059 cost = 0.027883054\n",
      "Validation Loss: 0.034711026\n",
      "Epoch: 3060 cost = 0.027909706\n",
      "Validation Loss: 0.038108237\n",
      "Epoch: 3061 cost = 0.027881562\n",
      "Validation Loss: 0.041646764\n",
      "Epoch: 3062 cost = 0.027908162\n",
      "Validation Loss: 0.04264989\n",
      "Epoch: 3063 cost = 0.027880129\n",
      "Validation Loss: 0.040172756\n",
      "Epoch: 3064 cost = 0.027906632\n",
      "Validation Loss: 0.03966979\n",
      "Epoch: 3065 cost = 0.027878644\n",
      "Validation Loss: 0.039427806\n",
      "Epoch: 3066 cost = 0.027905085\n",
      "Validation Loss: 0.0456459\n",
      "Epoch: 3067 cost = 0.027877179\n",
      "Validation Loss: 0.04867835\n",
      "Epoch: 3068 cost = 0.027903527\n",
      "Validation Loss: 0.046294026\n",
      "Epoch: 3069 cost = 0.027875750\n",
      "Validation Loss: 0.046041533\n",
      "Epoch: 3070 cost = 0.027901991\n",
      "Validation Loss: 0.04554592\n",
      "Epoch: 3071 cost = 0.027874283\n",
      "Validation Loss: 0.038029373\n",
      "Epoch: 3072 cost = 0.027900446\n",
      "Validation Loss: 0.03552755\n",
      "Epoch: 3073 cost = 0.027872826\n",
      "Validation Loss: 0.037880562\n",
      "Epoch: 3074 cost = 0.027898935\n",
      "Validation Loss: 0.038886458\n",
      "Epoch: 3075 cost = 0.027871391\n",
      "Validation Loss: 0.033595648\n",
      "Epoch: 3076 cost = 0.027897410\n",
      "Validation Loss: 0.03753971\n",
      "Epoch: 3077 cost = 0.027869917\n",
      "Validation Loss: 0.033503596\n",
      "Epoch: 3078 cost = 0.027895893\n",
      "Validation Loss: 0.03705207\n",
      "Epoch: 3079 cost = 0.027868499\n",
      "Validation Loss: 0.041619718\n",
      "Epoch: 3080 cost = 0.027894389\n",
      "Validation Loss: 0.0363235\n",
      "Epoch: 3081 cost = 0.027867061\n",
      "Validation Loss: 0.033476092\n",
      "Epoch: 3082 cost = 0.027892834\n",
      "Validation Loss: 0.032953095\n",
      "Epoch: 3083 cost = 0.027865594\n",
      "Validation Loss: 0.037392642\n",
      "Epoch: 3084 cost = 0.027891328\n",
      "Validation Loss: 0.03286183\n",
      "Epoch: 3085 cost = 0.027864179\n",
      "Validation Loss: 0.034125265\n",
      "Epoch: 3086 cost = 0.027889787\n",
      "Validation Loss: 0.03615228\n",
      "Epoch: 3087 cost = 0.027862726\n",
      "Validation Loss: 0.03613941\n",
      "Epoch: 3088 cost = 0.027888287\n",
      "Validation Loss: 0.03245608\n",
      "Epoch: 3089 cost = 0.027861296\n",
      "Validation Loss: 0.036187235\n",
      "Epoch: 3090 cost = 0.027886790\n",
      "Validation Loss: 0.037259057\n",
      "Epoch: 3091 cost = 0.027859877\n",
      "Validation Loss: 0.036701288\n",
      "Epoch: 3092 cost = 0.027885273\n",
      "Validation Loss: 0.034509882\n",
      "Epoch: 3093 cost = 0.027858439\n",
      "Validation Loss: 0.040810663\n",
      "Epoch: 3094 cost = 0.027883769\n",
      "Validation Loss: 0.054269534\n",
      "Epoch: 3095 cost = 0.027857032\n",
      "Validation Loss: 0.073317215\n",
      "Epoch: 3096 cost = 0.027882264\n",
      "Validation Loss: 0.070534\n",
      "Epoch: 3097 cost = 0.027855601\n",
      "Validation Loss: 0.05422143\n",
      "Epoch: 3098 cost = 0.027880760\n",
      "Validation Loss: 0.048602946\n",
      "Epoch: 3099 cost = 0.027854193\n",
      "Validation Loss: 0.04547691\n",
      "Epoch: 3100 cost = 0.027879290\n",
      "Validation Loss: 0.041576136\n",
      "Epoch: 3101 cost = 0.027852767\n",
      "Validation Loss: 0.03529403\n",
      "Epoch: 3102 cost = 0.027877802\n",
      "Validation Loss: 0.03688294\n",
      "Epoch: 3103 cost = 0.027851343\n",
      "Validation Loss: 0.038209785\n",
      "Epoch: 3104 cost = 0.027876302\n",
      "Validation Loss: 0.046945628\n",
      "Epoch: 3105 cost = 0.027849949\n",
      "Validation Loss: 0.043353308\n",
      "Epoch: 3106 cost = 0.027874818\n",
      "Validation Loss: 0.0384846\n",
      "Epoch: 3107 cost = 0.027848545\n",
      "Validation Loss: 0.032287914\n",
      "Epoch: 3108 cost = 0.027873338\n",
      "Validation Loss: 0.036949545\n",
      "Epoch: 3109 cost = 0.027847126\n",
      "Validation Loss: 0.03844366\n",
      "Epoch: 3110 cost = 0.027871870\n",
      "Validation Loss: 0.049448818\n",
      "Epoch: 3111 cost = 0.027845720\n",
      "Validation Loss: 0.05805623\n",
      "Epoch: 3112 cost = 0.027870358\n",
      "Validation Loss: 0.05764587\n",
      "Epoch: 3113 cost = 0.027844326\n",
      "Validation Loss: 0.057669826\n",
      "Epoch: 3114 cost = 0.027868909\n",
      "Validation Loss: 0.04536941\n",
      "Epoch: 3115 cost = 0.027842942\n",
      "Validation Loss: 0.050107796\n",
      "Epoch: 3116 cost = 0.027867450\n",
      "Validation Loss: 0.04094491\n",
      "Epoch: 3117 cost = 0.027841544\n",
      "Validation Loss: 0.044743583\n",
      "Epoch: 3118 cost = 0.027865981\n",
      "Validation Loss: 0.04112504\n",
      "Epoch: 3119 cost = 0.027840148\n",
      "Validation Loss: 0.034931157\n",
      "Epoch: 3120 cost = 0.027864530\n",
      "Validation Loss: 0.035440624\n",
      "Epoch: 3121 cost = 0.027838758\n",
      "Validation Loss: 0.033848096\n",
      "Epoch: 3122 cost = 0.027863071\n",
      "Validation Loss: 0.041041546\n",
      "Epoch: 3123 cost = 0.027837372\n",
      "Validation Loss: 0.033991393\n",
      "Epoch: 3124 cost = 0.027861624\n",
      "Validation Loss: 0.03225974\n",
      "Epoch: 3125 cost = 0.027835994\n",
      "Validation Loss: 0.034421463\n",
      "Epoch: 3126 cost = 0.027860153\n",
      "Validation Loss: 0.03513682\n",
      "Epoch: 3127 cost = 0.027834604\n",
      "Validation Loss: 0.036684733\n",
      "Epoch: 3128 cost = 0.027858698\n",
      "Validation Loss: 0.034239147\n",
      "Epoch: 3129 cost = 0.027833227\n",
      "Validation Loss: 0.036517486\n",
      "Epoch: 3130 cost = 0.027857235\n",
      "Validation Loss: 0.037251364\n",
      "Epoch: 3131 cost = 0.027831843\n",
      "Validation Loss: 0.03748924\n",
      "Epoch: 3132 cost = 0.027855790\n",
      "Validation Loss: 0.038433317\n",
      "Epoch: 3133 cost = 0.027830460\n",
      "Validation Loss: 0.038654227\n",
      "Epoch: 3134 cost = 0.027854337\n",
      "Validation Loss: 0.03922154\n",
      "Epoch: 3135 cost = 0.027829096\n",
      "Validation Loss: 0.037502024\n",
      "Epoch: 3136 cost = 0.027852909\n",
      "Validation Loss: 0.040335067\n",
      "Epoch: 3137 cost = 0.027827719\n",
      "Validation Loss: 0.03954543\n",
      "Epoch: 3138 cost = 0.027851450\n",
      "Validation Loss: 0.032400135\n",
      "Epoch: 3139 cost = 0.027826358\n",
      "Validation Loss: 0.031559363\n",
      "Epoch: 3140 cost = 0.027850011\n",
      "Validation Loss: 0.032803494\n",
      "Epoch: 3141 cost = 0.027824961\n",
      "Validation Loss: 0.0473278\n",
      "Epoch: 3142 cost = 0.027848584\n",
      "Validation Loss: 0.04777239\n",
      "Epoch: 3143 cost = 0.027823608\n",
      "Validation Loss: 0.042932887\n",
      "Epoch: 3144 cost = 0.027847131\n",
      "Validation Loss: 0.042272445\n",
      "Epoch: 3145 cost = 0.027822233\n",
      "Validation Loss: 0.035303835\n",
      "Epoch: 3146 cost = 0.027845692\n",
      "Validation Loss: 0.035005752\n",
      "Epoch: 3147 cost = 0.027820882\n",
      "Validation Loss: 0.03933284\n",
      "Epoch: 3148 cost = 0.027844279\n",
      "Validation Loss: 0.03818654\n",
      "Epoch: 3149 cost = 0.027819511\n",
      "Validation Loss: 0.04406226\n",
      "Epoch: 3150 cost = 0.027842844\n",
      "Validation Loss: 0.037328713\n",
      "Epoch: 3151 cost = 0.027818160\n",
      "Validation Loss: 0.03571502\n",
      "Epoch: 3152 cost = 0.027841418\n",
      "Validation Loss: 0.035263628\n",
      "Epoch: 3153 cost = 0.027816823\n",
      "Validation Loss: 0.036076907\n",
      "Epoch: 3154 cost = 0.027840012\n",
      "Validation Loss: 0.039377283\n",
      "Epoch: 3155 cost = 0.027815457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.041625913\n",
      "Epoch: 3156 cost = 0.027838604\n",
      "Validation Loss: 0.04101451\n",
      "Epoch: 3157 cost = 0.027814109\n",
      "Validation Loss: 0.04743531\n",
      "Epoch: 3158 cost = 0.027837200\n",
      "Validation Loss: 0.040656272\n",
      "Epoch: 3159 cost = 0.027812778\n",
      "Validation Loss: 0.036374018\n",
      "Epoch: 3160 cost = 0.027835775\n",
      "Validation Loss: 0.031215962\n",
      "Epoch: 3161 cost = 0.027811422\n",
      "Validation Loss: 0.03108426\n",
      "Epoch: 3162 cost = 0.027834388\n",
      "Validation Loss: 0.031226402\n",
      "Epoch: 3163 cost = 0.027810081\n",
      "Validation Loss: 0.031243565\n",
      "Epoch: 3164 cost = 0.027832952\n",
      "Validation Loss: 0.032246806\n",
      "Epoch: 3165 cost = 0.027808748\n",
      "Validation Loss: 0.041653283\n",
      "Epoch: 3166 cost = 0.027831586\n",
      "Validation Loss: 0.051483277\n",
      "Epoch: 3167 cost = 0.027807409\n",
      "Validation Loss: 0.059358414\n",
      "Epoch: 3168 cost = 0.027830192\n",
      "Validation Loss: 0.035297707\n",
      "Epoch: 3169 cost = 0.027806068\n",
      "Validation Loss: 0.033556625\n",
      "Epoch: 3170 cost = 0.027828786\n",
      "Validation Loss: 0.0333097\n",
      "Epoch: 3171 cost = 0.027804711\n",
      "Validation Loss: 0.032099813\n",
      "Epoch: 3172 cost = 0.027827386\n",
      "Validation Loss: 0.033212632\n",
      "Epoch: 3173 cost = 0.027803395\n",
      "Validation Loss: 0.033928055\n",
      "Epoch: 3174 cost = 0.027825968\n",
      "Validation Loss: 0.03938899\n",
      "Epoch: 3175 cost = 0.027802062\n",
      "Validation Loss: 0.03650135\n",
      "Epoch: 3176 cost = 0.027824582\n",
      "Validation Loss: 0.034142148\n",
      "Epoch: 3177 cost = 0.027800752\n",
      "Validation Loss: 0.032463975\n",
      "Epoch: 3178 cost = 0.027823203\n",
      "Validation Loss: 0.031256028\n",
      "Epoch: 3179 cost = 0.027799422\n",
      "Validation Loss: 0.03428042\n",
      "Epoch: 3180 cost = 0.027821827\n",
      "Validation Loss: 0.03344642\n",
      "Epoch: 3181 cost = 0.027798113\n",
      "Validation Loss: 0.037019756\n",
      "Epoch: 3182 cost = 0.027820423\n",
      "Validation Loss: 0.03423649\n",
      "Epoch: 3183 cost = 0.027796774\n",
      "Validation Loss: 0.031764053\n",
      "Epoch: 3184 cost = 0.027819068\n",
      "Validation Loss: 0.033256814\n",
      "Epoch: 3185 cost = 0.027795450\n",
      "Validation Loss: 0.040786814\n",
      "Epoch: 3186 cost = 0.027817681\n",
      "Validation Loss: 0.042854253\n",
      "Epoch: 3187 cost = 0.027794139\n",
      "Validation Loss: 0.039192658\n",
      "Epoch: 3188 cost = 0.027816278\n",
      "Validation Loss: 0.0517507\n",
      "Epoch: 3189 cost = 0.027792825\n",
      "Validation Loss: 0.054217957\n",
      "Epoch: 3190 cost = 0.027814893\n",
      "Validation Loss: 0.052987006\n",
      "Epoch: 3191 cost = 0.027791492\n",
      "Validation Loss: 0.048719566\n",
      "Epoch: 3192 cost = 0.027813520\n",
      "Validation Loss: 0.044716947\n",
      "Epoch: 3193 cost = 0.027790177\n",
      "Validation Loss: 0.04748523\n",
      "Epoch: 3194 cost = 0.027812164\n",
      "Validation Loss: 0.042315174\n",
      "Epoch: 3195 cost = 0.027788878\n",
      "Validation Loss: 0.038424704\n",
      "Epoch: 3196 cost = 0.027810768\n",
      "Validation Loss: 0.03666308\n",
      "Epoch: 3197 cost = 0.027787567\n",
      "Validation Loss: 0.034827966\n",
      "Epoch: 3198 cost = 0.027809420\n",
      "Validation Loss: 0.031316563\n",
      "Epoch: 3199 cost = 0.027786267\n",
      "Validation Loss: 0.036970895\n",
      "Epoch: 3200 cost = 0.027808047\n",
      "Validation Loss: 0.037921537\n",
      "Epoch: 3201 cost = 0.027784962\n",
      "Validation Loss: 0.037238754\n",
      "Epoch: 3202 cost = 0.027806690\n",
      "Validation Loss: 0.035627678\n",
      "Epoch: 3203 cost = 0.027783658\n",
      "Validation Loss: 0.033632778\n",
      "Epoch: 3204 cost = 0.027805332\n",
      "Validation Loss: 0.033230446\n",
      "Epoch: 3205 cost = 0.027782354\n",
      "Validation Loss: 0.038096398\n",
      "Epoch: 3206 cost = 0.027803985\n",
      "Validation Loss: 0.037355404\n",
      "Epoch: 3207 cost = 0.027781089\n",
      "Validation Loss: 0.033214793\n",
      "Epoch: 3208 cost = 0.027802643\n",
      "Validation Loss: 0.040339373\n",
      "Epoch: 3209 cost = 0.027779783\n",
      "Validation Loss: 0.038990803\n",
      "Epoch: 3210 cost = 0.027801269\n",
      "Validation Loss: 0.037369765\n",
      "Epoch: 3211 cost = 0.027778463\n",
      "Validation Loss: 0.036852423\n",
      "Epoch: 3212 cost = 0.027799937\n",
      "Validation Loss: 0.034683846\n",
      "Epoch: 3213 cost = 0.027777192\n",
      "Validation Loss: 0.035506893\n",
      "Epoch: 3214 cost = 0.027798582\n",
      "Validation Loss: 0.03451425\n",
      "Epoch: 3215 cost = 0.027775917\n",
      "Validation Loss: 0.034590904\n",
      "Epoch: 3216 cost = 0.027797222\n",
      "Validation Loss: 0.034497164\n",
      "Epoch: 3217 cost = 0.027774604\n",
      "Validation Loss: 0.041185603\n",
      "Epoch: 3218 cost = 0.027795937\n",
      "Validation Loss: 0.04076962\n",
      "Epoch: 3219 cost = 0.027773345\n",
      "Validation Loss: 0.035653304\n",
      "Epoch: 3220 cost = 0.027794564\n",
      "Validation Loss: 0.03270786\n",
      "Epoch: 3221 cost = 0.027772041\n",
      "Validation Loss: 0.035826158\n",
      "Epoch: 3222 cost = 0.027793248\n",
      "Validation Loss: 0.035932858\n",
      "Epoch: 3223 cost = 0.027770786\n",
      "Validation Loss: 0.032372247\n",
      "Epoch: 3224 cost = 0.027791907\n",
      "Validation Loss: 0.03703804\n",
      "Epoch: 3225 cost = 0.027769502\n",
      "Validation Loss: 0.043274947\n",
      "Epoch: 3226 cost = 0.027790598\n",
      "Validation Loss: 0.047535177\n",
      "Epoch: 3227 cost = 0.027768218\n",
      "Validation Loss: 0.036162816\n",
      "Epoch: 3228 cost = 0.027789282\n",
      "Validation Loss: 0.032248035\n",
      "Epoch: 3229 cost = 0.027766953\n",
      "Validation Loss: 0.031649437\n",
      "Epoch: 3230 cost = 0.027787946\n",
      "Validation Loss: 0.033613183\n",
      "Epoch: 3231 cost = 0.027765682\n",
      "Validation Loss: 0.035386167\n",
      "Epoch: 3232 cost = 0.027786620\n",
      "Validation Loss: 0.034604073\n",
      "Epoch: 3233 cost = 0.027764409\n",
      "Validation Loss: 0.033066288\n",
      "Epoch: 3234 cost = 0.027785301\n",
      "Validation Loss: 0.032781605\n",
      "Epoch: 3235 cost = 0.027763136\n",
      "Validation Loss: 0.034119833\n",
      "Epoch: 3236 cost = 0.027783977\n",
      "Validation Loss: 0.03643847\n",
      "Epoch: 3237 cost = 0.027761865\n",
      "Validation Loss: 0.035140563\n",
      "Epoch: 3238 cost = 0.027782665\n",
      "Validation Loss: 0.035916246\n",
      "Epoch: 3239 cost = 0.027760601\n",
      "Validation Loss: 0.041587986\n",
      "Epoch: 3240 cost = 0.027781351\n",
      "Validation Loss: 0.058903422\n",
      "Epoch: 3241 cost = 0.027759320\n",
      "Validation Loss: 0.054518443\n",
      "Epoch: 3242 cost = 0.027780003\n",
      "Validation Loss: 0.04183685\n",
      "Epoch: 3243 cost = 0.027758066\n",
      "Validation Loss: 0.039269503\n",
      "Epoch: 3244 cost = 0.027778701\n",
      "Validation Loss: 0.04491881\n",
      "Epoch: 3245 cost = 0.027756826\n",
      "Validation Loss: 0.042550642\n",
      "Epoch: 3246 cost = 0.027777399\n",
      "Validation Loss: 0.04151828\n",
      "Epoch: 3247 cost = 0.027755556\n",
      "Validation Loss: 0.04453682\n",
      "Epoch: 3248 cost = 0.027776086\n",
      "Validation Loss: 0.055930745\n",
      "Epoch: 3249 cost = 0.027754302\n",
      "Validation Loss: 0.051692333\n",
      "Epoch: 3250 cost = 0.027774786\n",
      "Validation Loss: 0.04730451\n",
      "Epoch: 3251 cost = 0.027753052\n",
      "Validation Loss: 0.03342879\n",
      "Epoch: 3252 cost = 0.027773503\n",
      "Validation Loss: 0.030758752\n",
      "Epoch: 3253 cost = 0.027751785\n",
      "Validation Loss: 0.03104197\n",
      "Epoch: 3254 cost = 0.027772183\n",
      "Validation Loss: 0.03403953\n",
      "Epoch: 3255 cost = 0.027750552\n",
      "Validation Loss: 0.03563378\n",
      "Epoch: 3256 cost = 0.027770861\n",
      "Validation Loss: 0.03650839\n",
      "Epoch: 3257 cost = 0.027749298\n",
      "Validation Loss: 0.037260618\n",
      "Epoch: 3258 cost = 0.027769594\n",
      "Validation Loss: 0.03604556\n",
      "Epoch: 3259 cost = 0.027748042\n",
      "Validation Loss: 0.03561437\n",
      "Epoch: 3260 cost = 0.027768303\n",
      "Validation Loss: 0.032295417\n",
      "Epoch: 3261 cost = 0.027746783\n",
      "Validation Loss: 0.033701193\n",
      "Epoch: 3262 cost = 0.027767014\n",
      "Validation Loss: 0.036324576\n",
      "Epoch: 3263 cost = 0.027745555\n",
      "Validation Loss: 0.036357917\n",
      "Epoch: 3264 cost = 0.027765710\n",
      "Validation Loss: 0.040062696\n",
      "Epoch: 3265 cost = 0.027744313\n",
      "Validation Loss: 0.038620748\n",
      "Epoch: 3266 cost = 0.027764417\n",
      "Validation Loss: 0.041671943\n",
      "Epoch: 3267 cost = 0.027743062\n",
      "Validation Loss: 0.033829838\n",
      "Epoch: 3268 cost = 0.027763116\n",
      "Validation Loss: 0.03472572\n",
      "Epoch: 3269 cost = 0.027741834\n",
      "Validation Loss: 0.03118042\n",
      "Epoch: 3270 cost = 0.027761833\n",
      "Validation Loss: 0.035574\n",
      "Epoch: 3271 cost = 0.027740579\n",
      "Validation Loss: 0.037631974\n",
      "Epoch: 3272 cost = 0.027760540\n",
      "Validation Loss: 0.03709856\n",
      "Epoch: 3273 cost = 0.027739357\n",
      "Validation Loss: 0.03392868\n",
      "Epoch: 3274 cost = 0.027759278\n",
      "Validation Loss: 0.032551866\n",
      "Epoch: 3275 cost = 0.027738099\n",
      "Validation Loss: 0.031424474\n",
      "Epoch: 3276 cost = 0.027757995\n",
      "Validation Loss: 0.036897175\n",
      "Epoch: 3277 cost = 0.027736884\n",
      "Validation Loss: 0.03448021\n",
      "Epoch: 3278 cost = 0.027756708\n",
      "Validation Loss: 0.04525757\n",
      "Epoch: 3279 cost = 0.027735658\n",
      "Validation Loss: 0.058774337\n",
      "Epoch: 3280 cost = 0.027755434\n",
      "Validation Loss: 0.059984013\n",
      "Epoch: 3281 cost = 0.027734430\n",
      "Validation Loss: 0.04704298\n",
      "Epoch: 3282 cost = 0.027754158\n",
      "Validation Loss: 0.03720204\n",
      "Epoch: 3283 cost = 0.027733195\n",
      "Validation Loss: 0.040599443\n",
      "Epoch: 3284 cost = 0.027752897\n",
      "Validation Loss: 0.050340272\n",
      "Epoch: 3285 cost = 0.027731947\n",
      "Validation Loss: 0.04206472\n",
      "Epoch: 3286 cost = 0.027751618\n",
      "Validation Loss: 0.037001036\n",
      "Epoch: 3287 cost = 0.027730756\n",
      "Validation Loss: 0.039541155\n",
      "Epoch: 3288 cost = 0.027750345\n",
      "Validation Loss: 0.033161372\n",
      "Epoch: 3289 cost = 0.027729516\n",
      "Validation Loss: 0.030898172\n",
      "Epoch: 3290 cost = 0.027749084\n",
      "Validation Loss: 0.035136208\n",
      "Epoch: 3291 cost = 0.027728308\n",
      "Validation Loss: 0.037439767\n",
      "Epoch: 3292 cost = 0.027747807\n",
      "Validation Loss: 0.034657434\n",
      "Epoch: 3293 cost = 0.027727090\n",
      "Validation Loss: 0.034214605\n",
      "Epoch: 3294 cost = 0.027746542\n",
      "Validation Loss: 0.035750102\n",
      "Epoch: 3295 cost = 0.027725858\n",
      "Validation Loss: 0.03838805\n",
      "Epoch: 3296 cost = 0.027745302\n",
      "Validation Loss: 0.038861487\n",
      "Epoch: 3297 cost = 0.027724640\n",
      "Validation Loss: 0.04220515\n",
      "Epoch: 3298 cost = 0.027744034\n",
      "Validation Loss: 0.03654493\n",
      "Epoch: 3299 cost = 0.027723407\n",
      "Validation Loss: 0.034476727\n",
      "Epoch: 3300 cost = 0.027742768\n",
      "Validation Loss: 0.033578377\n",
      "Epoch: 3301 cost = 0.027722195\n",
      "Validation Loss: 0.033673618\n",
      "Epoch: 3302 cost = 0.027741513\n",
      "Validation Loss: 0.035430133\n",
      "Epoch: 3303 cost = 0.027720987\n",
      "Validation Loss: 0.035760462\n",
      "Epoch: 3304 cost = 0.027740269\n",
      "Validation Loss: 0.036940813\n",
      "Epoch: 3305 cost = 0.027719769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03563728\n",
      "Epoch: 3306 cost = 0.027739004\n",
      "Validation Loss: 0.034386173\n",
      "Epoch: 3307 cost = 0.027718588\n",
      "Validation Loss: 0.036573336\n",
      "Epoch: 3308 cost = 0.027737775\n",
      "Validation Loss: 0.036979508\n",
      "Epoch: 3309 cost = 0.027717367\n",
      "Validation Loss: 0.034618907\n",
      "Epoch: 3310 cost = 0.027736532\n",
      "Validation Loss: 0.033173848\n",
      "Epoch: 3311 cost = 0.027716173\n",
      "Validation Loss: 0.03774881\n",
      "Epoch: 3312 cost = 0.027735285\n",
      "Validation Loss: 0.048148185\n",
      "Epoch: 3313 cost = 0.027714969\n",
      "Validation Loss: 0.055853654\n",
      "Epoch: 3314 cost = 0.027734038\n",
      "Validation Loss: 0.042433172\n",
      "Epoch: 3315 cost = 0.027713772\n",
      "Validation Loss: 0.039705012\n",
      "Epoch: 3316 cost = 0.027732789\n",
      "Validation Loss: 0.041280676\n",
      "Epoch: 3317 cost = 0.027712566\n",
      "Validation Loss: 0.036450945\n",
      "Epoch: 3318 cost = 0.027731555\n",
      "Validation Loss: 0.034621146\n",
      "Epoch: 3319 cost = 0.027711343\n",
      "Validation Loss: 0.035588805\n",
      "Epoch: 3320 cost = 0.027730318\n",
      "Validation Loss: 0.03568158\n",
      "Epoch: 3321 cost = 0.027710175\n",
      "Validation Loss: 0.03693243\n",
      "Epoch: 3322 cost = 0.027729093\n",
      "Validation Loss: 0.034771133\n",
      "Epoch: 3323 cost = 0.027708953\n",
      "Validation Loss: 0.039614864\n",
      "Epoch: 3324 cost = 0.027727858\n",
      "Validation Loss: 0.033293404\n",
      "Epoch: 3325 cost = 0.027707752\n",
      "Validation Loss: 0.035779264\n",
      "Epoch: 3326 cost = 0.027726628\n",
      "Validation Loss: 0.03870664\n",
      "Epoch: 3327 cost = 0.027706551\n",
      "Validation Loss: 0.044243775\n",
      "Epoch: 3328 cost = 0.027725389\n",
      "Validation Loss: 0.044286165\n",
      "Epoch: 3329 cost = 0.027705373\n",
      "Validation Loss: 0.053260874\n",
      "Epoch: 3330 cost = 0.027724130\n",
      "Validation Loss: 0.054480556\n",
      "Epoch: 3331 cost = 0.027704190\n",
      "Validation Loss: 0.039769445\n",
      "Epoch: 3332 cost = 0.027722919\n",
      "Validation Loss: 0.052528925\n",
      "Epoch: 3333 cost = 0.027702988\n",
      "Validation Loss: 0.048867002\n",
      "Epoch: 3334 cost = 0.027721683\n",
      "Validation Loss: 0.052870765\n",
      "Epoch: 3335 cost = 0.027701805\n",
      "Validation Loss: 0.058502562\n",
      "Epoch: 3336 cost = 0.027720451\n",
      "Validation Loss: 0.052092917\n",
      "Epoch: 3337 cost = 0.027700624\n",
      "Validation Loss: 0.042472277\n",
      "Epoch: 3338 cost = 0.027719252\n",
      "Validation Loss: 0.034492087\n",
      "Epoch: 3339 cost = 0.027699427\n",
      "Validation Loss: 0.033204265\n",
      "Epoch: 3340 cost = 0.027718010\n",
      "Validation Loss: 0.034670252\n",
      "Epoch: 3341 cost = 0.027698231\n",
      "Validation Loss: 0.033128034\n",
      "Epoch: 3342 cost = 0.027716794\n",
      "Validation Loss: 0.032182194\n",
      "Epoch: 3343 cost = 0.027697020\n",
      "Validation Loss: 0.03496029\n",
      "Epoch: 3344 cost = 0.027715565\n",
      "Validation Loss: 0.042461753\n",
      "Epoch: 3345 cost = 0.027695879\n",
      "Validation Loss: 0.046288855\n",
      "Epoch: 3346 cost = 0.027714350\n",
      "Validation Loss: 0.035507176\n",
      "Epoch: 3347 cost = 0.027694688\n",
      "Validation Loss: 0.034113742\n",
      "Epoch: 3348 cost = 0.027713145\n",
      "Validation Loss: 0.0381796\n",
      "Epoch: 3349 cost = 0.027693509\n",
      "Validation Loss: 0.046513308\n",
      "Epoch: 3350 cost = 0.027711946\n",
      "Validation Loss: 0.044032704\n",
      "Epoch: 3351 cost = 0.027692338\n",
      "Validation Loss: 0.039536353\n",
      "Epoch: 3352 cost = 0.027710744\n",
      "Validation Loss: 0.032943405\n",
      "Epoch: 3353 cost = 0.027691151\n",
      "Validation Loss: 0.033918507\n",
      "Epoch: 3354 cost = 0.027709520\n",
      "Validation Loss: 0.0389332\n",
      "Epoch: 3355 cost = 0.027689989\n",
      "Validation Loss: 0.040999476\n",
      "Epoch: 3356 cost = 0.027708343\n",
      "Validation Loss: 0.03835775\n",
      "Epoch: 3357 cost = 0.027688826\n",
      "Validation Loss: 0.039500616\n",
      "Epoch: 3358 cost = 0.027707128\n",
      "Validation Loss: 0.044380587\n",
      "Epoch: 3359 cost = 0.027687654\n",
      "Validation Loss: 0.039217234\n",
      "Epoch: 3360 cost = 0.027705929\n",
      "Validation Loss: 0.034292422\n",
      "Epoch: 3361 cost = 0.027686475\n",
      "Validation Loss: 0.036475714\n",
      "Epoch: 3362 cost = 0.027704738\n",
      "Validation Loss: 0.033720892\n",
      "Epoch: 3363 cost = 0.027685301\n",
      "Validation Loss: 0.031788643\n",
      "Epoch: 3364 cost = 0.027703522\n",
      "Validation Loss: 0.036386285\n",
      "Epoch: 3365 cost = 0.027684153\n",
      "Validation Loss: 0.039472565\n",
      "Epoch: 3366 cost = 0.027702319\n",
      "Validation Loss: 0.03651892\n",
      "Epoch: 3367 cost = 0.027682969\n",
      "Validation Loss: 0.036086172\n",
      "Epoch: 3368 cost = 0.027701098\n",
      "Validation Loss: 0.04267586\n",
      "Epoch: 3369 cost = 0.027681809\n",
      "Validation Loss: 0.047368646\n",
      "Epoch: 3370 cost = 0.027699918\n",
      "Validation Loss: 0.039096814\n",
      "Epoch: 3371 cost = 0.027680633\n",
      "Validation Loss: 0.03690328\n",
      "Epoch: 3372 cost = 0.027698755\n",
      "Validation Loss: 0.045854174\n",
      "Epoch: 3373 cost = 0.027679475\n",
      "Validation Loss: 0.037719302\n",
      "Epoch: 3374 cost = 0.027697556\n",
      "Validation Loss: 0.033444956\n",
      "Epoch: 3375 cost = 0.027678288\n",
      "Validation Loss: 0.0364239\n",
      "Epoch: 3376 cost = 0.027696353\n",
      "Validation Loss: 0.036853835\n",
      "Epoch: 3377 cost = 0.027677138\n",
      "Validation Loss: 0.036113624\n",
      "Epoch: 3378 cost = 0.027695164\n",
      "Validation Loss: 0.045336306\n",
      "Epoch: 3379 cost = 0.027675993\n",
      "Validation Loss: 0.045511957\n",
      "Epoch: 3380 cost = 0.027693952\n",
      "Validation Loss: 0.043591876\n",
      "Epoch: 3381 cost = 0.027674831\n",
      "Validation Loss: 0.035943422\n",
      "Epoch: 3382 cost = 0.027692756\n",
      "Validation Loss: 0.03716942\n",
      "Epoch: 3383 cost = 0.027673673\n",
      "Validation Loss: 0.03629523\n",
      "Epoch: 3384 cost = 0.027691594\n",
      "Validation Loss: 0.03689078\n",
      "Epoch: 3385 cost = 0.027672506\n",
      "Validation Loss: 0.040295992\n",
      "Epoch: 3386 cost = 0.027690412\n",
      "Validation Loss: 0.0384753\n",
      "Epoch: 3387 cost = 0.027671374\n",
      "Validation Loss: 0.03805121\n",
      "Epoch: 3388 cost = 0.027689202\n",
      "Validation Loss: 0.036153704\n",
      "Epoch: 3389 cost = 0.027670196\n",
      "Validation Loss: 0.038412623\n",
      "Epoch: 3390 cost = 0.027688034\n",
      "Validation Loss: 0.0415137\n",
      "Epoch: 3391 cost = 0.027669058\n",
      "Validation Loss: 0.040817805\n",
      "Epoch: 3392 cost = 0.027686848\n",
      "Validation Loss: 0.038719416\n",
      "Epoch: 3393 cost = 0.027667883\n",
      "Validation Loss: 0.04537345\n",
      "Epoch: 3394 cost = 0.027685663\n",
      "Validation Loss: 0.041666683\n",
      "Epoch: 3395 cost = 0.027666770\n",
      "Validation Loss: 0.04044709\n",
      "Epoch: 3396 cost = 0.027684496\n",
      "Validation Loss: 0.03431994\n",
      "Epoch: 3397 cost = 0.027665615\n",
      "Validation Loss: 0.03593209\n",
      "Epoch: 3398 cost = 0.027683309\n",
      "Validation Loss: 0.048502885\n",
      "Epoch: 3399 cost = 0.027664446\n",
      "Validation Loss: 0.061399184\n",
      "Epoch: 3400 cost = 0.027682144\n",
      "Validation Loss: 0.05415897\n",
      "Epoch: 3401 cost = 0.027663308\n",
      "Validation Loss: 0.043991446\n",
      "Epoch: 3402 cost = 0.027680975\n",
      "Validation Loss: 0.03827144\n",
      "Epoch: 3403 cost = 0.027662151\n",
      "Validation Loss: 0.045195177\n",
      "Epoch: 3404 cost = 0.027679798\n",
      "Validation Loss: 0.05034975\n",
      "Epoch: 3405 cost = 0.027661034\n",
      "Validation Loss: 0.041206703\n",
      "Epoch: 3406 cost = 0.027678619\n",
      "Validation Loss: 0.034459937\n",
      "Epoch: 3407 cost = 0.027659855\n",
      "Validation Loss: 0.03521066\n",
      "Epoch: 3408 cost = 0.027677448\n",
      "Validation Loss: 0.03571384\n",
      "Epoch: 3409 cost = 0.027658728\n",
      "Validation Loss: 0.030781196\n",
      "Epoch: 3410 cost = 0.027676272\n",
      "Validation Loss: 0.033455137\n",
      "Epoch: 3411 cost = 0.027657596\n",
      "Validation Loss: 0.03489718\n",
      "Epoch: 3412 cost = 0.027675124\n",
      "Validation Loss: 0.033847906\n",
      "Epoch: 3413 cost = 0.027656446\n",
      "Validation Loss: 0.034556974\n",
      "Epoch: 3414 cost = 0.027673947\n",
      "Validation Loss: 0.036298927\n",
      "Epoch: 3415 cost = 0.027655324\n",
      "Validation Loss: 0.037911456\n",
      "Epoch: 3416 cost = 0.027672787\n",
      "Validation Loss: 0.03866966\n",
      "Epoch: 3417 cost = 0.027654180\n",
      "Validation Loss: 0.035767727\n",
      "Epoch: 3418 cost = 0.027671631\n",
      "Validation Loss: 0.03529083\n",
      "Epoch: 3419 cost = 0.027653054\n",
      "Validation Loss: 0.03326749\n",
      "Epoch: 3420 cost = 0.027670474\n",
      "Validation Loss: 0.039267592\n",
      "Epoch: 3421 cost = 0.027651918\n",
      "Validation Loss: 0.042709894\n",
      "Epoch: 3422 cost = 0.027669300\n",
      "Validation Loss: 0.04094245\n",
      "Epoch: 3423 cost = 0.027650771\n",
      "Validation Loss: 0.036840446\n",
      "Epoch: 3424 cost = 0.027668195\n",
      "Validation Loss: 0.034314122\n",
      "Epoch: 3425 cost = 0.027649637\n",
      "Validation Loss: 0.03418975\n",
      "Epoch: 3426 cost = 0.027667044\n",
      "Validation Loss: 0.04377474\n",
      "Epoch: 3427 cost = 0.027648544\n",
      "Validation Loss: 0.039244007\n",
      "Epoch: 3428 cost = 0.027665874\n",
      "Validation Loss: 0.03763469\n",
      "Epoch: 3429 cost = 0.027647393\n",
      "Validation Loss: 0.038268514\n",
      "Epoch: 3430 cost = 0.027664737\n",
      "Validation Loss: 0.03190867\n",
      "Epoch: 3431 cost = 0.027646256\n",
      "Validation Loss: 0.034755528\n",
      "Epoch: 3432 cost = 0.027663570\n",
      "Validation Loss: 0.036117967\n",
      "Epoch: 3433 cost = 0.027645135\n",
      "Validation Loss: 0.03326999\n",
      "Epoch: 3434 cost = 0.027662429\n",
      "Validation Loss: 0.04034791\n",
      "Epoch: 3435 cost = 0.027644007\n",
      "Validation Loss: 0.03937864\n",
      "Epoch: 3436 cost = 0.027661282\n",
      "Validation Loss: 0.05381845\n",
      "Epoch: 3437 cost = 0.027642879\n",
      "Validation Loss: 0.08561742\n",
      "Epoch: 3438 cost = 0.027660117\n",
      "Validation Loss: 0.06439743\n",
      "Epoch: 3439 cost = 0.027641750\n",
      "Validation Loss: 0.05815555\n",
      "Epoch: 3440 cost = 0.027658989\n",
      "Validation Loss: 0.046891034\n",
      "Epoch: 3441 cost = 0.027640611\n",
      "Validation Loss: 0.041089915\n",
      "Epoch: 3442 cost = 0.027657838\n",
      "Validation Loss: 0.03724764\n",
      "Epoch: 3443 cost = 0.027639492\n",
      "Validation Loss: 0.04187767\n",
      "Epoch: 3444 cost = 0.027656710\n",
      "Validation Loss: 0.04358292\n",
      "Epoch: 3445 cost = 0.027638382\n",
      "Validation Loss: 0.031900853\n",
      "Epoch: 3446 cost = 0.027655573\n",
      "Validation Loss: 0.03693103\n",
      "Epoch: 3447 cost = 0.027637251\n",
      "Validation Loss: 0.048300862\n",
      "Epoch: 3448 cost = 0.027654424\n",
      "Validation Loss: 0.047636088\n",
      "Epoch: 3449 cost = 0.027636136\n",
      "Validation Loss: 0.047792114\n",
      "Epoch: 3450 cost = 0.027653280\n",
      "Validation Loss: 0.042257126\n",
      "Epoch: 3451 cost = 0.027634999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.037775997\n",
      "Epoch: 3452 cost = 0.027652157\n",
      "Validation Loss: 0.038719855\n",
      "Epoch: 3453 cost = 0.027633908\n",
      "Validation Loss: 0.04083612\n",
      "Epoch: 3454 cost = 0.027651017\n",
      "Validation Loss: 0.03598695\n",
      "Epoch: 3455 cost = 0.027632787\n",
      "Validation Loss: 0.03619266\n",
      "Epoch: 3456 cost = 0.027649858\n",
      "Validation Loss: 0.032251254\n",
      "Epoch: 3457 cost = 0.027631643\n",
      "Validation Loss: 0.036327403\n",
      "Epoch: 3458 cost = 0.027648762\n",
      "Validation Loss: 0.03648804\n",
      "Epoch: 3459 cost = 0.027630520\n",
      "Validation Loss: 0.03538831\n",
      "Epoch: 3460 cost = 0.027647610\n",
      "Validation Loss: 0.036824618\n",
      "Epoch: 3461 cost = 0.027629439\n",
      "Validation Loss: 0.03559595\n",
      "Epoch: 3462 cost = 0.027646461\n",
      "Validation Loss: 0.04080116\n",
      "Epoch: 3463 cost = 0.027628301\n",
      "Validation Loss: 0.039147694\n",
      "Epoch: 3464 cost = 0.027645317\n",
      "Validation Loss: 0.0359484\n",
      "Epoch: 3465 cost = 0.027627225\n",
      "Validation Loss: 0.04146408\n",
      "Epoch: 3466 cost = 0.027644177\n",
      "Validation Loss: 0.054541696\n",
      "Epoch: 3467 cost = 0.027626094\n",
      "Validation Loss: 0.058734197\n",
      "Epoch: 3468 cost = 0.027643071\n",
      "Validation Loss: 0.056275465\n",
      "Epoch: 3469 cost = 0.027624979\n",
      "Validation Loss: 0.042982027\n",
      "Epoch: 3470 cost = 0.027641948\n",
      "Validation Loss: 0.031422973\n",
      "Epoch: 3471 cost = 0.027623847\n",
      "Validation Loss: 0.031694908\n",
      "Epoch: 3472 cost = 0.027640815\n",
      "Validation Loss: 0.03275112\n",
      "Epoch: 3473 cost = 0.027622770\n",
      "Validation Loss: 0.034225892\n",
      "Epoch: 3474 cost = 0.027639676\n",
      "Validation Loss: 0.04760953\n",
      "Epoch: 3475 cost = 0.027621659\n",
      "Validation Loss: 0.041035857\n",
      "Epoch: 3476 cost = 0.027638586\n",
      "Validation Loss: 0.03597108\n",
      "Epoch: 3477 cost = 0.027620558\n",
      "Validation Loss: 0.03590997\n",
      "Epoch: 3478 cost = 0.027637445\n",
      "Validation Loss: 0.035609756\n",
      "Epoch: 3479 cost = 0.027619424\n",
      "Validation Loss: 0.040401783\n",
      "Epoch: 3480 cost = 0.027636314\n",
      "Validation Loss: 0.03557837\n",
      "Epoch: 3481 cost = 0.027618359\n",
      "Validation Loss: 0.036406603\n",
      "Epoch: 3482 cost = 0.027635197\n",
      "Validation Loss: 0.044346593\n",
      "Epoch: 3483 cost = 0.027617239\n",
      "Validation Loss: 0.053823184\n",
      "Epoch: 3484 cost = 0.027634092\n",
      "Validation Loss: 0.042874794\n",
      "Epoch: 3485 cost = 0.027616123\n",
      "Validation Loss: 0.03430795\n",
      "Epoch: 3486 cost = 0.027632982\n",
      "Validation Loss: 0.037338607\n",
      "Epoch: 3487 cost = 0.027615023\n",
      "Validation Loss: 0.037041925\n",
      "Epoch: 3488 cost = 0.027631856\n",
      "Validation Loss: 0.032637347\n",
      "Epoch: 3489 cost = 0.027613913\n",
      "Validation Loss: 0.034702606\n",
      "Epoch: 3490 cost = 0.027630731\n",
      "Validation Loss: 0.035129253\n",
      "Epoch: 3491 cost = 0.027612837\n",
      "Validation Loss: 0.0349514\n",
      "Epoch: 3492 cost = 0.027629648\n",
      "Validation Loss: 0.03351003\n",
      "Epoch: 3493 cost = 0.027611764\n",
      "Validation Loss: 0.038087938\n",
      "Epoch: 3494 cost = 0.027628522\n",
      "Validation Loss: 0.03778599\n",
      "Epoch: 3495 cost = 0.027610636\n",
      "Validation Loss: 0.04207647\n",
      "Epoch: 3496 cost = 0.027627403\n",
      "Validation Loss: 0.040021382\n",
      "Epoch: 3497 cost = 0.027609520\n",
      "Validation Loss: 0.037410125\n",
      "Epoch: 3498 cost = 0.027626303\n",
      "Validation Loss: 0.036227766\n",
      "Epoch: 3499 cost = 0.027608439\n",
      "Validation Loss: 0.035840828\n",
      "Epoch: 3500 cost = 0.027625188\n",
      "Validation Loss: 0.03804698\n",
      "Epoch: 3501 cost = 0.027607347\n",
      "Validation Loss: 0.03529654\n",
      "Epoch: 3502 cost = 0.027624064\n",
      "Validation Loss: 0.032380752\n",
      "Epoch: 3503 cost = 0.027606284\n",
      "Validation Loss: 0.032298777\n",
      "Epoch: 3504 cost = 0.027622977\n",
      "Validation Loss: 0.03695222\n",
      "Epoch: 3505 cost = 0.027605170\n",
      "Validation Loss: 0.03834902\n",
      "Epoch: 3506 cost = 0.027621889\n",
      "Validation Loss: 0.036839698\n",
      "Epoch: 3507 cost = 0.027604082\n",
      "Validation Loss: 0.03957009\n",
      "Epoch: 3508 cost = 0.027620755\n",
      "Validation Loss: 0.03825985\n",
      "Epoch: 3509 cost = 0.027602958\n",
      "Validation Loss: 0.035343844\n",
      "Epoch: 3510 cost = 0.027619665\n",
      "Validation Loss: 0.039314494\n",
      "Epoch: 3511 cost = 0.027601879\n",
      "Validation Loss: 0.05949676\n",
      "Epoch: 3512 cost = 0.027618600\n",
      "Validation Loss: 0.053069357\n",
      "Epoch: 3513 cost = 0.027600784\n",
      "Validation Loss: 0.048897784\n",
      "Epoch: 3514 cost = 0.027617476\n",
      "Validation Loss: 0.042485688\n",
      "Epoch: 3515 cost = 0.027599693\n",
      "Validation Loss: 0.045685776\n",
      "Epoch: 3516 cost = 0.027616385\n",
      "Validation Loss: 0.06404428\n",
      "Epoch: 3517 cost = 0.027598601\n",
      "Validation Loss: 0.07017145\n",
      "Epoch: 3518 cost = 0.027615283\n",
      "Validation Loss: 0.06604128\n",
      "Epoch: 3519 cost = 0.027597532\n",
      "Validation Loss: 0.041009616\n",
      "Epoch: 3520 cost = 0.027614199\n",
      "Validation Loss: 0.03664212\n",
      "Epoch: 3521 cost = 0.027596449\n",
      "Validation Loss: 0.035135955\n",
      "Epoch: 3522 cost = 0.027613101\n",
      "Validation Loss: 0.03479186\n",
      "Epoch: 3523 cost = 0.027595362\n",
      "Validation Loss: 0.0323503\n",
      "Epoch: 3524 cost = 0.027611984\n",
      "Validation Loss: 0.03707821\n",
      "Epoch: 3525 cost = 0.027594272\n",
      "Validation Loss: 0.04556247\n",
      "Epoch: 3526 cost = 0.027610908\n",
      "Validation Loss: 0.054314047\n",
      "Epoch: 3527 cost = 0.027593180\n",
      "Validation Loss: 0.040010925\n",
      "Epoch: 3528 cost = 0.027609812\n",
      "Validation Loss: 0.032553386\n",
      "Epoch: 3529 cost = 0.027592104\n",
      "Validation Loss: 0.031667758\n",
      "Epoch: 3530 cost = 0.027608732\n",
      "Validation Loss: 0.03246758\n",
      "Epoch: 3531 cost = 0.027591033\n",
      "Validation Loss: 0.03573566\n",
      "Epoch: 3532 cost = 0.027607620\n",
      "Validation Loss: 0.03668879\n",
      "Epoch: 3533 cost = 0.027589948\n",
      "Validation Loss: 0.03622125\n",
      "Epoch: 3534 cost = 0.027606555\n",
      "Validation Loss: 0.037748776\n",
      "Epoch: 3535 cost = 0.027588853\n",
      "Validation Loss: 0.03308329\n",
      "Epoch: 3536 cost = 0.027605467\n",
      "Validation Loss: 0.037716754\n",
      "Epoch: 3537 cost = 0.027587765\n",
      "Validation Loss: 0.041196477\n",
      "Epoch: 3538 cost = 0.027604357\n",
      "Validation Loss: 0.03748631\n",
      "Epoch: 3539 cost = 0.027586685\n",
      "Validation Loss: 0.043957848\n",
      "Epoch: 3540 cost = 0.027603264\n",
      "Validation Loss: 0.034641374\n",
      "Epoch: 3541 cost = 0.027585610\n",
      "Validation Loss: 0.03208913\n",
      "Epoch: 3542 cost = 0.027602188\n",
      "Validation Loss: 0.032155838\n",
      "Epoch: 3543 cost = 0.027584523\n",
      "Validation Loss: 0.03643111\n",
      "Epoch: 3544 cost = 0.027601116\n",
      "Validation Loss: 0.033859536\n",
      "Epoch: 3545 cost = 0.027583443\n",
      "Validation Loss: 0.031415623\n",
      "Epoch: 3546 cost = 0.027600019\n",
      "Validation Loss: 0.034366034\n",
      "Epoch: 3547 cost = 0.027582365\n",
      "Validation Loss: 0.04345928\n",
      "Epoch: 3548 cost = 0.027598927\n",
      "Validation Loss: 0.04515757\n",
      "Epoch: 3549 cost = 0.027581323\n",
      "Validation Loss: 0.037334647\n",
      "Epoch: 3550 cost = 0.027597870\n",
      "Validation Loss: 0.032491297\n",
      "Epoch: 3551 cost = 0.027580251\n",
      "Validation Loss: 0.034333155\n",
      "Epoch: 3552 cost = 0.027596794\n",
      "Validation Loss: 0.03511564\n",
      "Epoch: 3553 cost = 0.027579167\n",
      "Validation Loss: 0.03699188\n",
      "Epoch: 3554 cost = 0.027595720\n",
      "Validation Loss: 0.038793806\n",
      "Epoch: 3555 cost = 0.027578093\n",
      "Validation Loss: 0.03623194\n",
      "Epoch: 3556 cost = 0.027594649\n",
      "Validation Loss: 0.030671787\n",
      "Epoch: 3557 cost = 0.027577008\n",
      "Validation Loss: 0.03651187\n",
      "Epoch: 3558 cost = 0.027593588\n",
      "Validation Loss: 0.030470835\n",
      "Epoch: 3559 cost = 0.027575954\n",
      "Validation Loss: 0.030234171\n",
      "Epoch: 3560 cost = 0.027592489\n",
      "Validation Loss: 0.030787991\n",
      "Epoch: 3561 cost = 0.027574867\n",
      "Validation Loss: 0.032877784\n",
      "Epoch: 3562 cost = 0.027591419\n",
      "Validation Loss: 0.03219567\n",
      "Epoch: 3563 cost = 0.027573807\n",
      "Validation Loss: 0.034368567\n",
      "Epoch: 3564 cost = 0.027590347\n",
      "Validation Loss: 0.036762\n",
      "Epoch: 3565 cost = 0.027572733\n",
      "Validation Loss: 0.034091115\n",
      "Epoch: 3566 cost = 0.027589287\n",
      "Validation Loss: 0.036719806\n",
      "Epoch: 3567 cost = 0.027571648\n",
      "Validation Loss: 0.037188485\n",
      "Epoch: 3568 cost = 0.027588228\n",
      "Validation Loss: 0.0504263\n",
      "Epoch: 3569 cost = 0.027570585\n",
      "Validation Loss: 0.046767958\n",
      "Epoch: 3570 cost = 0.027587141\n",
      "Validation Loss: 0.03404193\n",
      "Epoch: 3571 cost = 0.027569535\n",
      "Validation Loss: 0.034284264\n",
      "Epoch: 3572 cost = 0.027586055\n",
      "Validation Loss: 0.037761495\n",
      "Epoch: 3573 cost = 0.027568448\n",
      "Validation Loss: 0.04266293\n",
      "Epoch: 3574 cost = 0.027584995\n",
      "Validation Loss: 0.034680746\n",
      "Epoch: 3575 cost = 0.027567396\n",
      "Validation Loss: 0.03573056\n",
      "Epoch: 3576 cost = 0.027583931\n",
      "Validation Loss: 0.03480352\n",
      "Epoch: 3577 cost = 0.027566330\n",
      "Validation Loss: 0.03726271\n",
      "Epoch: 3578 cost = 0.027582865\n",
      "Validation Loss: 0.035561584\n",
      "Epoch: 3579 cost = 0.027565278\n",
      "Validation Loss: 0.03646406\n",
      "Epoch: 3580 cost = 0.027581806\n",
      "Validation Loss: 0.0369257\n",
      "Epoch: 3581 cost = 0.027564217\n",
      "Validation Loss: 0.036752935\n",
      "Epoch: 3582 cost = 0.027580736\n",
      "Validation Loss: 0.034773882\n",
      "Epoch: 3583 cost = 0.027563152\n",
      "Validation Loss: 0.03967645\n",
      "Epoch: 3584 cost = 0.027579661\n",
      "Validation Loss: 0.039167456\n",
      "Epoch: 3585 cost = 0.027562085\n",
      "Validation Loss: 0.046860393\n",
      "Epoch: 3586 cost = 0.027578617\n",
      "Validation Loss: 0.052604135\n",
      "Epoch: 3587 cost = 0.027561020\n",
      "Validation Loss: 0.037354928\n",
      "Epoch: 3588 cost = 0.027577540\n",
      "Validation Loss: 0.03332806\n",
      "Epoch: 3589 cost = 0.027559954\n",
      "Validation Loss: 0.038361847\n",
      "Epoch: 3590 cost = 0.027576500\n",
      "Validation Loss: 0.039071392\n",
      "Epoch: 3591 cost = 0.027558885\n",
      "Validation Loss: 0.036757026\n",
      "Epoch: 3592 cost = 0.027575447\n",
      "Validation Loss: 0.037465867\n",
      "Epoch: 3593 cost = 0.027557850\n",
      "Validation Loss: 0.047661938\n",
      "Epoch: 3594 cost = 0.027574358\n",
      "Validation Loss: 0.042450063\n",
      "Epoch: 3595 cost = 0.027556790\n",
      "Validation Loss: 0.047600485\n",
      "Epoch: 3596 cost = 0.027573285\n",
      "Validation Loss: 0.036366697\n",
      "Epoch: 3597 cost = 0.027555718\n",
      "Validation Loss: 0.038910795\n",
      "Epoch: 3598 cost = 0.027572251\n",
      "Validation Loss: 0.043612495\n",
      "Epoch: 3599 cost = 0.027554659\n",
      "Validation Loss: 0.042577047\n",
      "Epoch: 3600 cost = 0.027571209\n",
      "Validation Loss: 0.038545944\n",
      "Epoch: 3601 cost = 0.027553611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.038212005\n",
      "Epoch: 3602 cost = 0.027570144\n",
      "Validation Loss: 0.032065757\n",
      "Epoch: 3603 cost = 0.027552542\n",
      "Validation Loss: 0.040613074\n",
      "Epoch: 3604 cost = 0.027569089\n",
      "Validation Loss: 0.04062475\n",
      "Epoch: 3605 cost = 0.027551497\n",
      "Validation Loss: 0.037473124\n",
      "Epoch: 3606 cost = 0.027568000\n",
      "Validation Loss: 0.041014522\n",
      "Epoch: 3607 cost = 0.027550436\n",
      "Validation Loss: 0.040824234\n",
      "Epoch: 3608 cost = 0.027566954\n",
      "Validation Loss: 0.03990606\n",
      "Epoch: 3609 cost = 0.027549399\n",
      "Validation Loss: 0.037982613\n",
      "Epoch: 3610 cost = 0.027565919\n",
      "Validation Loss: 0.03632365\n",
      "Epoch: 3611 cost = 0.027548308\n",
      "Validation Loss: 0.036982358\n",
      "Epoch: 3612 cost = 0.027564865\n",
      "Validation Loss: 0.041158378\n",
      "Epoch: 3613 cost = 0.027547257\n",
      "Validation Loss: 0.036908075\n",
      "Epoch: 3614 cost = 0.027563825\n",
      "Validation Loss: 0.035958495\n",
      "Epoch: 3615 cost = 0.027546225\n",
      "Validation Loss: 0.041833997\n",
      "Epoch: 3616 cost = 0.027562796\n",
      "Validation Loss: 0.04045899\n",
      "Epoch: 3617 cost = 0.027545147\n",
      "Validation Loss: 0.039943516\n",
      "Epoch: 3618 cost = 0.027561745\n",
      "Validation Loss: 0.049859416\n",
      "Epoch: 3619 cost = 0.027544118\n",
      "Validation Loss: 0.048643954\n",
      "Epoch: 3620 cost = 0.027560700\n",
      "Validation Loss: 0.045399316\n",
      "Epoch: 3621 cost = 0.027543064\n",
      "Validation Loss: 0.04668249\n",
      "Epoch: 3622 cost = 0.027559627\n",
      "Validation Loss: 0.035833612\n",
      "Epoch: 3623 cost = 0.027541993\n",
      "Validation Loss: 0.038183026\n",
      "Epoch: 3624 cost = 0.027558587\n",
      "Validation Loss: 0.035825316\n",
      "Epoch: 3625 cost = 0.027540954\n",
      "Validation Loss: 0.036872588\n",
      "Epoch: 3626 cost = 0.027557526\n",
      "Validation Loss: 0.030962937\n",
      "Epoch: 3627 cost = 0.027539923\n",
      "Validation Loss: 0.041138317\n",
      "Epoch: 3628 cost = 0.027556519\n",
      "Validation Loss: 0.039685905\n",
      "Epoch: 3629 cost = 0.027538863\n",
      "Validation Loss: 0.039977416\n",
      "Epoch: 3630 cost = 0.027555501\n",
      "Validation Loss: 0.04195207\n",
      "Epoch: 3631 cost = 0.027537834\n",
      "Validation Loss: 0.037972786\n",
      "Epoch: 3632 cost = 0.027554449\n",
      "Validation Loss: 0.03865926\n",
      "Epoch: 3633 cost = 0.027536807\n",
      "Validation Loss: 0.034776967\n",
      "Epoch: 3634 cost = 0.027553379\n",
      "Validation Loss: 0.035409182\n",
      "Epoch: 3635 cost = 0.027535765\n",
      "Validation Loss: 0.03910599\n",
      "Epoch: 3636 cost = 0.027552359\n",
      "Validation Loss: 0.042593658\n",
      "Epoch: 3637 cost = 0.027534683\n",
      "Validation Loss: 0.033695456\n",
      "Epoch: 3638 cost = 0.027551352\n",
      "Validation Loss: 0.036346603\n",
      "Epoch: 3639 cost = 0.027533633\n",
      "Validation Loss: 0.035649516\n",
      "Epoch: 3640 cost = 0.027550308\n",
      "Validation Loss: 0.043280363\n",
      "Epoch: 3641 cost = 0.027532618\n",
      "Validation Loss: 0.054233152\n",
      "Epoch: 3642 cost = 0.027549255\n",
      "Validation Loss: 0.065207385\n",
      "Epoch: 3643 cost = 0.027531587\n",
      "Validation Loss: 0.059702918\n",
      "Epoch: 3644 cost = 0.027548206\n",
      "Validation Loss: 0.03747422\n",
      "Epoch: 3645 cost = 0.027530528\n",
      "Validation Loss: 0.036693085\n",
      "Epoch: 3646 cost = 0.027547190\n",
      "Validation Loss: 0.061526548\n",
      "Epoch: 3647 cost = 0.027529485\n",
      "Validation Loss: 0.06707318\n",
      "Epoch: 3648 cost = 0.027546131\n",
      "Validation Loss: 0.056485835\n",
      "Epoch: 3649 cost = 0.027528422\n",
      "Validation Loss: 0.06250912\n",
      "Epoch: 3650 cost = 0.027545069\n",
      "Validation Loss: 0.06913466\n",
      "Epoch: 3651 cost = 0.027527383\n",
      "Validation Loss: 0.042873736\n",
      "Epoch: 3652 cost = 0.027544066\n",
      "Validation Loss: 0.04079983\n",
      "Epoch: 3653 cost = 0.027526359\n",
      "Validation Loss: 0.034745373\n",
      "Epoch: 3654 cost = 0.027543058\n",
      "Validation Loss: 0.035318717\n",
      "Epoch: 3655 cost = 0.027525346\n",
      "Validation Loss: 0.035607062\n",
      "Epoch: 3656 cost = 0.027542004\n",
      "Validation Loss: 0.03740446\n",
      "Epoch: 3657 cost = 0.027524270\n",
      "Validation Loss: 0.041760236\n",
      "Epoch: 3658 cost = 0.027541006\n",
      "Validation Loss: 0.04588218\n",
      "Epoch: 3659 cost = 0.027523234\n",
      "Validation Loss: 0.041460034\n",
      "Epoch: 3660 cost = 0.027539965\n",
      "Validation Loss: 0.045371477\n",
      "Epoch: 3661 cost = 0.027522209\n",
      "Validation Loss: 0.038150918\n",
      "Epoch: 3662 cost = 0.027538945\n",
      "Validation Loss: 0.038698345\n",
      "Epoch: 3663 cost = 0.027521181\n",
      "Validation Loss: 0.03747321\n",
      "Epoch: 3664 cost = 0.027537917\n",
      "Validation Loss: 0.034841374\n",
      "Epoch: 3665 cost = 0.027520112\n",
      "Validation Loss: 0.03491885\n",
      "Epoch: 3666 cost = 0.027536879\n",
      "Validation Loss: 0.037665807\n",
      "Epoch: 3667 cost = 0.027519079\n",
      "Validation Loss: 0.044345923\n",
      "Epoch: 3668 cost = 0.027535840\n",
      "Validation Loss: 0.04934197\n",
      "Epoch: 3669 cost = 0.027518069\n",
      "Validation Loss: 0.043611024\n",
      "Epoch: 3670 cost = 0.027534806\n",
      "Validation Loss: 0.03405082\n",
      "Epoch: 3671 cost = 0.027517033\n",
      "Validation Loss: 0.03399575\n",
      "Epoch: 3672 cost = 0.027533819\n",
      "Validation Loss: 0.03411346\n",
      "Epoch: 3673 cost = 0.027515992\n",
      "Validation Loss: 0.03705419\n",
      "Epoch: 3674 cost = 0.027532768\n",
      "Validation Loss: 0.0430109\n",
      "Epoch: 3675 cost = 0.027514958\n",
      "Validation Loss: 0.044155236\n",
      "Epoch: 3676 cost = 0.027531754\n",
      "Validation Loss: 0.04588073\n",
      "Epoch: 3677 cost = 0.027513916\n",
      "Validation Loss: 0.052128892\n",
      "Epoch: 3678 cost = 0.027530725\n",
      "Validation Loss: 0.054828316\n",
      "Epoch: 3679 cost = 0.027512884\n",
      "Validation Loss: 0.048244793\n",
      "Epoch: 3680 cost = 0.027529698\n",
      "Validation Loss: 0.035356864\n",
      "Epoch: 3681 cost = 0.027511849\n",
      "Validation Loss: 0.036239278\n",
      "Epoch: 3682 cost = 0.027528683\n",
      "Validation Loss: 0.03676601\n",
      "Epoch: 3683 cost = 0.027510813\n",
      "Validation Loss: 0.035889376\n",
      "Epoch: 3684 cost = 0.027527662\n",
      "Validation Loss: 0.03539968\n",
      "Epoch: 3685 cost = 0.027509790\n",
      "Validation Loss: 0.032374244\n",
      "Epoch: 3686 cost = 0.027526644\n",
      "Validation Loss: 0.038659777\n",
      "Epoch: 3687 cost = 0.027508743\n",
      "Validation Loss: 0.049168456\n",
      "Epoch: 3688 cost = 0.027525622\n",
      "Validation Loss: 0.052107092\n",
      "Epoch: 3689 cost = 0.027507756\n",
      "Validation Loss: 0.049474087\n",
      "Epoch: 3690 cost = 0.027524589\n",
      "Validation Loss: 0.031368554\n",
      "Epoch: 3691 cost = 0.027506711\n",
      "Validation Loss: 0.03352796\n",
      "Epoch: 3692 cost = 0.027523573\n",
      "Validation Loss: 0.032427594\n",
      "Epoch: 3693 cost = 0.027505681\n",
      "Validation Loss: 0.0347754\n",
      "Epoch: 3694 cost = 0.027522571\n",
      "Validation Loss: 0.035009664\n",
      "Epoch: 3695 cost = 0.027504657\n",
      "Validation Loss: 0.035038806\n",
      "Epoch: 3696 cost = 0.027521560\n",
      "Validation Loss: 0.051771417\n",
      "Epoch: 3697 cost = 0.027503637\n",
      "Validation Loss: 0.05353913\n",
      "Epoch: 3698 cost = 0.027520534\n",
      "Validation Loss: 0.049292196\n",
      "Epoch: 3699 cost = 0.027502625\n",
      "Validation Loss: 0.035802826\n",
      "Epoch: 3700 cost = 0.027519541\n",
      "Validation Loss: 0.034615166\n",
      "Epoch: 3701 cost = 0.027501564\n",
      "Validation Loss: 0.034679547\n",
      "Epoch: 3702 cost = 0.027518512\n",
      "Validation Loss: 0.032770466\n",
      "Epoch: 3703 cost = 0.027500555\n",
      "Validation Loss: 0.03299918\n",
      "Epoch: 3704 cost = 0.027517485\n",
      "Validation Loss: 0.045475997\n",
      "Epoch: 3705 cost = 0.027499518\n",
      "Validation Loss: 0.046355806\n",
      "Epoch: 3706 cost = 0.027516494\n",
      "Validation Loss: 0.03494526\n",
      "Epoch: 3707 cost = 0.027498498\n",
      "Validation Loss: 0.03465955\n",
      "Epoch: 3708 cost = 0.027515464\n",
      "Validation Loss: 0.03455218\n",
      "Epoch: 3709 cost = 0.027497496\n",
      "Validation Loss: 0.038882967\n",
      "Epoch: 3710 cost = 0.027514463\n",
      "Validation Loss: 0.04227054\n",
      "Epoch: 3711 cost = 0.027496443\n",
      "Validation Loss: 0.058261525\n",
      "Epoch: 3712 cost = 0.027513430\n",
      "Validation Loss: 0.047030844\n",
      "Epoch: 3713 cost = 0.027495439\n",
      "Validation Loss: 0.041869227\n",
      "Epoch: 3714 cost = 0.027512429\n",
      "Validation Loss: 0.05117937\n",
      "Epoch: 3715 cost = 0.027494409\n",
      "Validation Loss: 0.04099687\n",
      "Epoch: 3716 cost = 0.027511424\n",
      "Validation Loss: 0.03479699\n",
      "Epoch: 3717 cost = 0.027493393\n",
      "Validation Loss: 0.031738453\n",
      "Epoch: 3718 cost = 0.027510417\n",
      "Validation Loss: 0.032089032\n",
      "Epoch: 3719 cost = 0.027492352\n",
      "Validation Loss: 0.04110652\n",
      "Epoch: 3720 cost = 0.027509429\n",
      "Validation Loss: 0.039949644\n",
      "Epoch: 3721 cost = 0.027491357\n",
      "Validation Loss: 0.03690507\n",
      "Epoch: 3722 cost = 0.027508410\n",
      "Validation Loss: 0.03219191\n",
      "Epoch: 3723 cost = 0.027490324\n",
      "Validation Loss: 0.030893115\n",
      "Epoch: 3724 cost = 0.027507416\n",
      "Validation Loss: 0.034806173\n",
      "Epoch: 3725 cost = 0.027489328\n",
      "Validation Loss: 0.040769186\n",
      "Epoch: 3726 cost = 0.027506405\n",
      "Validation Loss: 0.05355186\n",
      "Epoch: 3727 cost = 0.027488311\n",
      "Validation Loss: 0.054233216\n",
      "Epoch: 3728 cost = 0.027505430\n",
      "Validation Loss: 0.046087075\n",
      "Epoch: 3729 cost = 0.027487289\n",
      "Validation Loss: 0.043361135\n",
      "Epoch: 3730 cost = 0.027504418\n",
      "Validation Loss: 0.049705904\n",
      "Epoch: 3731 cost = 0.027486288\n",
      "Validation Loss: 0.0571592\n",
      "Epoch: 3732 cost = 0.027503414\n",
      "Validation Loss: 0.047991373\n",
      "Epoch: 3733 cost = 0.027485264\n",
      "Validation Loss: 0.0451467\n",
      "Epoch: 3734 cost = 0.027502437\n",
      "Validation Loss: 0.03545101\n",
      "Epoch: 3735 cost = 0.027484249\n",
      "Validation Loss: 0.036588684\n",
      "Epoch: 3736 cost = 0.027501429\n",
      "Validation Loss: 0.03992216\n",
      "Epoch: 3737 cost = 0.027483220\n",
      "Validation Loss: 0.035416808\n",
      "Epoch: 3738 cost = 0.027500438\n",
      "Validation Loss: 0.034212954\n",
      "Epoch: 3739 cost = 0.027482230\n",
      "Validation Loss: 0.03305445\n",
      "Epoch: 3740 cost = 0.027499453\n",
      "Validation Loss: 0.03416412\n",
      "Epoch: 3741 cost = 0.027481219\n",
      "Validation Loss: 0.044684708\n",
      "Epoch: 3742 cost = 0.027498464\n",
      "Validation Loss: 0.04544349\n",
      "Epoch: 3743 cost = 0.027480213\n",
      "Validation Loss: 0.035324376\n",
      "Epoch: 3744 cost = 0.027497454\n",
      "Validation Loss: 0.035090987\n",
      "Epoch: 3745 cost = 0.027479195\n",
      "Validation Loss: 0.04553316\n",
      "Epoch: 3746 cost = 0.027496469\n",
      "Validation Loss: 0.035441034\n",
      "Epoch: 3747 cost = 0.027478187\n",
      "Validation Loss: 0.033962198\n",
      "Epoch: 3748 cost = 0.027495442\n",
      "Validation Loss: 0.041390635\n",
      "Epoch: 3749 cost = 0.027477180\n",
      "Validation Loss: 0.036504563\n",
      "Epoch: 3750 cost = 0.027494486\n",
      "Validation Loss: 0.032129806\n",
      "Epoch: 3751 cost = 0.027476167\n",
      "Validation Loss: 0.03156349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3752 cost = 0.027493470\n",
      "Validation Loss: 0.032114685\n",
      "Epoch: 3753 cost = 0.027475158\n",
      "Validation Loss: 0.032739323\n",
      "Epoch: 3754 cost = 0.027492471\n",
      "Validation Loss: 0.033625744\n",
      "Epoch: 3755 cost = 0.027474164\n",
      "Validation Loss: 0.031434033\n",
      "Epoch: 3756 cost = 0.027491507\n",
      "Validation Loss: 0.03876111\n",
      "Epoch: 3757 cost = 0.027473146\n",
      "Validation Loss: 0.050144833\n",
      "Epoch: 3758 cost = 0.027490515\n",
      "Validation Loss: 0.043026973\n",
      "Epoch: 3759 cost = 0.027472147\n",
      "Validation Loss: 0.03201479\n",
      "Epoch: 3760 cost = 0.027489546\n",
      "Validation Loss: 0.034919124\n",
      "Epoch: 3761 cost = 0.027471154\n",
      "Validation Loss: 0.03214852\n",
      "Epoch: 3762 cost = 0.027488571\n",
      "Validation Loss: 0.031981353\n",
      "Epoch: 3763 cost = 0.027470126\n",
      "Validation Loss: 0.030616134\n",
      "Epoch: 3764 cost = 0.027487561\n",
      "Validation Loss: 0.03094955\n",
      "Epoch: 3765 cost = 0.027469144\n",
      "Validation Loss: 0.031678196\n",
      "Epoch: 3766 cost = 0.027486572\n",
      "Validation Loss: 0.032446146\n",
      "Epoch: 3767 cost = 0.027468132\n",
      "Validation Loss: 0.038767625\n",
      "Epoch: 3768 cost = 0.027485584\n",
      "Validation Loss: 0.04696241\n",
      "Epoch: 3769 cost = 0.027467136\n",
      "Validation Loss: 0.04426505\n",
      "Epoch: 3770 cost = 0.027484615\n",
      "Validation Loss: 0.043488882\n",
      "Epoch: 3771 cost = 0.027466130\n",
      "Validation Loss: 0.04715283\n",
      "Epoch: 3772 cost = 0.027483645\n",
      "Validation Loss: 0.038672745\n",
      "Epoch: 3773 cost = 0.027465160\n",
      "Validation Loss: 0.034682024\n",
      "Epoch: 3774 cost = 0.027482631\n",
      "Validation Loss: 0.030685008\n",
      "Epoch: 3775 cost = 0.027464150\n",
      "Validation Loss: 0.03332097\n",
      "Epoch: 3776 cost = 0.027481659\n",
      "Validation Loss: 0.033835012\n",
      "Epoch: 3777 cost = 0.027463157\n",
      "Validation Loss: 0.03396158\n",
      "Epoch: 3778 cost = 0.027480661\n",
      "Validation Loss: 0.03865566\n",
      "Epoch: 3779 cost = 0.027462149\n",
      "Validation Loss: 0.03687495\n",
      "Epoch: 3780 cost = 0.027479696\n",
      "Validation Loss: 0.033384867\n",
      "Epoch: 3781 cost = 0.027461156\n",
      "Validation Loss: 0.034654368\n",
      "Epoch: 3782 cost = 0.027478720\n",
      "Validation Loss: 0.03345971\n",
      "Epoch: 3783 cost = 0.027460159\n",
      "Validation Loss: 0.033362277\n",
      "Epoch: 3784 cost = 0.027477720\n",
      "Validation Loss: 0.031012582\n",
      "Epoch: 3785 cost = 0.027459163\n",
      "Validation Loss: 0.032754004\n",
      "Epoch: 3786 cost = 0.027476758\n",
      "Validation Loss: 0.03445649\n",
      "Epoch: 3787 cost = 0.027458174\n",
      "Validation Loss: 0.032701276\n",
      "Epoch: 3788 cost = 0.027475808\n",
      "Validation Loss: 0.030542504\n",
      "Epoch: 3789 cost = 0.027457177\n",
      "Validation Loss: 0.04204582\n",
      "Epoch: 3790 cost = 0.027474801\n",
      "Validation Loss: 0.050219927\n",
      "Epoch: 3791 cost = 0.027456186\n",
      "Validation Loss: 0.047608137\n",
      "Epoch: 3792 cost = 0.027473832\n",
      "Validation Loss: 0.032143563\n",
      "Epoch: 3793 cost = 0.027455207\n",
      "Validation Loss: 0.033837594\n",
      "Epoch: 3794 cost = 0.027472880\n",
      "Validation Loss: 0.034290392\n",
      "Epoch: 3795 cost = 0.027454205\n",
      "Validation Loss: 0.032161027\n",
      "Epoch: 3796 cost = 0.027471940\n",
      "Validation Loss: 0.031193247\n",
      "Epoch: 3797 cost = 0.027453222\n",
      "Validation Loss: 0.03513565\n",
      "Epoch: 3798 cost = 0.027470961\n",
      "Validation Loss: 0.03837481\n",
      "Epoch: 3799 cost = 0.027452248\n",
      "Validation Loss: 0.033703018\n",
      "Epoch: 3800 cost = 0.027469984\n",
      "Validation Loss: 0.036877323\n",
      "Epoch: 3801 cost = 0.027451251\n",
      "Validation Loss: 0.03746838\n",
      "Epoch: 3802 cost = 0.027469016\n",
      "Validation Loss: 0.0379159\n",
      "Epoch: 3803 cost = 0.027450277\n",
      "Validation Loss: 0.035022587\n",
      "Epoch: 3804 cost = 0.027468068\n",
      "Validation Loss: 0.030850768\n",
      "Epoch: 3805 cost = 0.027449281\n",
      "Validation Loss: 0.034191396\n",
      "Epoch: 3806 cost = 0.027467102\n",
      "Validation Loss: 0.034704365\n",
      "Epoch: 3807 cost = 0.027448307\n",
      "Validation Loss: 0.035501786\n",
      "Epoch: 3808 cost = 0.027466130\n",
      "Validation Loss: 0.032222223\n",
      "Epoch: 3809 cost = 0.027447308\n",
      "Validation Loss: 0.034763616\n",
      "Epoch: 3810 cost = 0.027465193\n",
      "Validation Loss: 0.032038484\n",
      "Epoch: 3811 cost = 0.027446344\n",
      "Validation Loss: 0.033617087\n",
      "Epoch: 3812 cost = 0.027464202\n",
      "Validation Loss: 0.03202824\n",
      "Epoch: 3813 cost = 0.027445344\n",
      "Validation Loss: 0.031618513\n",
      "Epoch: 3814 cost = 0.027463247\n",
      "Validation Loss: 0.031386226\n",
      "Epoch: 3815 cost = 0.027444359\n",
      "Validation Loss: 0.030950256\n",
      "Epoch: 3816 cost = 0.027462288\n",
      "Validation Loss: 0.0314893\n",
      "Epoch: 3817 cost = 0.027443380\n",
      "Validation Loss: 0.033926446\n",
      "Epoch: 3818 cost = 0.027461308\n",
      "Validation Loss: 0.03646412\n",
      "Epoch: 3819 cost = 0.027442401\n",
      "Validation Loss: 0.037409596\n",
      "Epoch: 3820 cost = 0.027460355\n",
      "Validation Loss: 0.034894027\n",
      "Epoch: 3821 cost = 0.027441437\n",
      "Validation Loss: 0.034577288\n",
      "Epoch: 3822 cost = 0.027459381\n",
      "Validation Loss: 0.038031783\n",
      "Epoch: 3823 cost = 0.027440447\n",
      "Validation Loss: 0.04434024\n",
      "Epoch: 3824 cost = 0.027458433\n",
      "Validation Loss: 0.04246549\n",
      "Epoch: 3825 cost = 0.027439470\n",
      "Validation Loss: 0.03411136\n",
      "Epoch: 3826 cost = 0.027457470\n",
      "Validation Loss: 0.036779586\n",
      "Epoch: 3827 cost = 0.027438496\n",
      "Validation Loss: 0.036838356\n",
      "Epoch: 3828 cost = 0.027456506\n",
      "Validation Loss: 0.038473904\n",
      "Epoch: 3829 cost = 0.027437505\n",
      "Validation Loss: 0.03700946\n",
      "Epoch: 3830 cost = 0.027455548\n",
      "Validation Loss: 0.05183914\n",
      "Epoch: 3831 cost = 0.027436541\n",
      "Validation Loss: 0.048971318\n",
      "Epoch: 3832 cost = 0.027454600\n",
      "Validation Loss: 0.04175302\n",
      "Epoch: 3833 cost = 0.027435553\n",
      "Validation Loss: 0.041144673\n",
      "Epoch: 3834 cost = 0.027453642\n",
      "Validation Loss: 0.04699769\n",
      "Epoch: 3835 cost = 0.027434582\n",
      "Validation Loss: 0.050529785\n",
      "Epoch: 3836 cost = 0.027452669\n",
      "Validation Loss: 0.04817693\n",
      "Epoch: 3837 cost = 0.027433607\n",
      "Validation Loss: 0.041996785\n",
      "Epoch: 3838 cost = 0.027451734\n",
      "Validation Loss: 0.04734644\n",
      "Epoch: 3839 cost = 0.027432633\n",
      "Validation Loss: 0.03888161\n",
      "Epoch: 3840 cost = 0.027450761\n",
      "Validation Loss: 0.03728909\n",
      "Epoch: 3841 cost = 0.027431690\n",
      "Validation Loss: 0.03701227\n",
      "Epoch: 3842 cost = 0.027449839\n",
      "Validation Loss: 0.044143267\n",
      "Epoch: 3843 cost = 0.027430684\n",
      "Validation Loss: 0.044452045\n",
      "Epoch: 3844 cost = 0.027448861\n",
      "Validation Loss: 0.042013463\n",
      "Epoch: 3845 cost = 0.027429704\n",
      "Validation Loss: 0.036500074\n",
      "Epoch: 3846 cost = 0.027447922\n",
      "Validation Loss: 0.034788124\n",
      "Epoch: 3847 cost = 0.027428745\n",
      "Validation Loss: 0.033451088\n",
      "Epoch: 3848 cost = 0.027446966\n",
      "Validation Loss: 0.03173504\n",
      "Epoch: 3849 cost = 0.027427801\n",
      "Validation Loss: 0.0354301\n",
      "Epoch: 3850 cost = 0.027446033\n",
      "Validation Loss: 0.0374572\n",
      "Epoch: 3851 cost = 0.027426810\n",
      "Validation Loss: 0.036766537\n",
      "Epoch: 3852 cost = 0.027445077\n",
      "Validation Loss: 0.034588426\n",
      "Epoch: 3853 cost = 0.027425837\n",
      "Validation Loss: 0.033712827\n",
      "Epoch: 3854 cost = 0.027444149\n",
      "Validation Loss: 0.035112396\n",
      "Epoch: 3855 cost = 0.027424869\n",
      "Validation Loss: 0.033424426\n",
      "Epoch: 3856 cost = 0.027443186\n",
      "Validation Loss: 0.03374744\n",
      "Epoch: 3857 cost = 0.027423913\n",
      "Validation Loss: 0.035426456\n",
      "Epoch: 3858 cost = 0.027442248\n",
      "Validation Loss: 0.03395161\n",
      "Epoch: 3859 cost = 0.027422928\n",
      "Validation Loss: 0.034733884\n",
      "Epoch: 3860 cost = 0.027441271\n",
      "Validation Loss: 0.03911958\n",
      "Epoch: 3861 cost = 0.027421986\n",
      "Validation Loss: 0.049330015\n",
      "Epoch: 3862 cost = 0.027440348\n",
      "Validation Loss: 0.03565349\n",
      "Epoch: 3863 cost = 0.027420993\n",
      "Validation Loss: 0.041779593\n",
      "Epoch: 3864 cost = 0.027439383\n",
      "Validation Loss: 0.050295606\n",
      "Epoch: 3865 cost = 0.027420040\n",
      "Validation Loss: 0.04707602\n",
      "Epoch: 3866 cost = 0.027438444\n",
      "Validation Loss: 0.042044695\n",
      "Epoch: 3867 cost = 0.027419060\n",
      "Validation Loss: 0.04214234\n",
      "Epoch: 3868 cost = 0.027437511\n",
      "Validation Loss: 0.039110225\n",
      "Epoch: 3869 cost = 0.027418112\n",
      "Validation Loss: 0.034589358\n",
      "Epoch: 3870 cost = 0.027436561\n",
      "Validation Loss: 0.035019327\n",
      "Epoch: 3871 cost = 0.027417160\n",
      "Validation Loss: 0.03542173\n",
      "Epoch: 3872 cost = 0.027435638\n",
      "Validation Loss: 0.03345491\n",
      "Epoch: 3873 cost = 0.027416215\n",
      "Validation Loss: 0.03399894\n",
      "Epoch: 3874 cost = 0.027434680\n",
      "Validation Loss: 0.03292343\n",
      "Epoch: 3875 cost = 0.027415257\n",
      "Validation Loss: 0.04659837\n",
      "Epoch: 3876 cost = 0.027433756\n",
      "Validation Loss: 0.050220888\n",
      "Epoch: 3877 cost = 0.027414285\n",
      "Validation Loss: 0.04356186\n",
      "Epoch: 3878 cost = 0.027432809\n",
      "Validation Loss: 0.046874225\n",
      "Epoch: 3879 cost = 0.027413316\n",
      "Validation Loss: 0.051408634\n",
      "Epoch: 3880 cost = 0.027431904\n",
      "Validation Loss: 0.051759325\n",
      "Epoch: 3881 cost = 0.027412346\n",
      "Validation Loss: 0.0371397\n",
      "Epoch: 3882 cost = 0.027430963\n",
      "Validation Loss: 0.030781653\n",
      "Epoch: 3883 cost = 0.027411396\n",
      "Validation Loss: 0.033961505\n",
      "Epoch: 3884 cost = 0.027430018\n",
      "Validation Loss: 0.03076619\n",
      "Epoch: 3885 cost = 0.027410448\n",
      "Validation Loss: 0.0317666\n",
      "Epoch: 3886 cost = 0.027429089\n",
      "Validation Loss: 0.030784765\n",
      "Epoch: 3887 cost = 0.027409483\n",
      "Validation Loss: 0.0332361\n",
      "Epoch: 3888 cost = 0.027428130\n",
      "Validation Loss: 0.03150046\n",
      "Epoch: 3889 cost = 0.027408524\n",
      "Validation Loss: 0.032734603\n",
      "Epoch: 3890 cost = 0.027427230\n",
      "Validation Loss: 0.031132108\n",
      "Epoch: 3891 cost = 0.027407545\n",
      "Validation Loss: 0.033489253\n",
      "Epoch: 3892 cost = 0.027426262\n",
      "Validation Loss: 0.046206497\n",
      "Epoch: 3893 cost = 0.027406602\n",
      "Validation Loss: 0.040194195\n",
      "Epoch: 3894 cost = 0.027425322\n",
      "Validation Loss: 0.036917713\n",
      "Epoch: 3895 cost = 0.027405656\n",
      "Validation Loss: 0.04108874\n",
      "Epoch: 3896 cost = 0.027424407\n",
      "Validation Loss: 0.047932703\n",
      "Epoch: 3897 cost = 0.027404706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.041338015\n",
      "Epoch: 3898 cost = 0.027423475\n",
      "Validation Loss: 0.046361547\n",
      "Epoch: 3899 cost = 0.027403751\n",
      "Validation Loss: 0.049903452\n",
      "Epoch: 3900 cost = 0.027422544\n",
      "Validation Loss: 0.038047906\n",
      "Epoch: 3901 cost = 0.027402808\n",
      "Validation Loss: 0.034773707\n",
      "Epoch: 3902 cost = 0.027421622\n",
      "Validation Loss: 0.035067145\n",
      "Epoch: 3903 cost = 0.027401845\n",
      "Validation Loss: 0.033397835\n",
      "Epoch: 3904 cost = 0.027420704\n",
      "Validation Loss: 0.030273367\n",
      "Epoch: 3905 cost = 0.027400908\n",
      "Validation Loss: 0.03340085\n",
      "Epoch: 3906 cost = 0.027419792\n",
      "Validation Loss: 0.03537035\n",
      "Epoch: 3907 cost = 0.027399943\n",
      "Validation Loss: 0.03972165\n",
      "Epoch: 3908 cost = 0.027418886\n",
      "Validation Loss: 0.04777266\n",
      "Epoch: 3909 cost = 0.027399009\n",
      "Validation Loss: 0.055046655\n",
      "Epoch: 3910 cost = 0.027417923\n",
      "Validation Loss: 0.05720243\n",
      "Epoch: 3911 cost = 0.027398053\n",
      "Validation Loss: 0.04566844\n",
      "Epoch: 3912 cost = 0.027416994\n",
      "Validation Loss: 0.04189815\n",
      "Epoch: 3913 cost = 0.027397099\n",
      "Validation Loss: 0.036476936\n",
      "Epoch: 3914 cost = 0.027416048\n",
      "Validation Loss: 0.030903721\n",
      "Epoch: 3915 cost = 0.027396150\n",
      "Validation Loss: 0.03513006\n",
      "Epoch: 3916 cost = 0.027415119\n",
      "Validation Loss: 0.04113269\n",
      "Epoch: 3917 cost = 0.027395187\n",
      "Validation Loss: 0.043575015\n",
      "Epoch: 3918 cost = 0.027414222\n",
      "Validation Loss: 0.047889076\n",
      "Epoch: 3919 cost = 0.027394241\n",
      "Validation Loss: 0.04233967\n",
      "Epoch: 3920 cost = 0.027413303\n",
      "Validation Loss: 0.044708017\n",
      "Epoch: 3921 cost = 0.027393329\n",
      "Validation Loss: 0.037781667\n",
      "Epoch: 3922 cost = 0.027412359\n",
      "Validation Loss: 0.035356756\n",
      "Epoch: 3923 cost = 0.027392357\n",
      "Validation Loss: 0.036497068\n",
      "Epoch: 3924 cost = 0.027411429\n",
      "Validation Loss: 0.03827941\n",
      "Epoch: 3925 cost = 0.027391430\n",
      "Validation Loss: 0.036686104\n",
      "Epoch: 3926 cost = 0.027410507\n",
      "Validation Loss: 0.03831322\n",
      "Epoch: 3927 cost = 0.027390468\n",
      "Validation Loss: 0.037842266\n",
      "Epoch: 3928 cost = 0.027409568\n",
      "Validation Loss: 0.032158423\n",
      "Epoch: 3929 cost = 0.027389542\n",
      "Validation Loss: 0.030862134\n",
      "Epoch: 3930 cost = 0.027408628\n",
      "Validation Loss: 0.0328614\n",
      "Epoch: 3931 cost = 0.027388605\n",
      "Validation Loss: 0.03359015\n",
      "Epoch: 3932 cost = 0.027407756\n",
      "Validation Loss: 0.035881028\n",
      "Epoch: 3933 cost = 0.027387638\n",
      "Validation Loss: 0.03357764\n",
      "Epoch: 3934 cost = 0.027406799\n",
      "Validation Loss: 0.03809266\n",
      "Epoch: 3935 cost = 0.027386701\n",
      "Validation Loss: 0.034701485\n",
      "Epoch: 3936 cost = 0.027405899\n",
      "Validation Loss: 0.035350468\n",
      "Epoch: 3937 cost = 0.027385773\n",
      "Validation Loss: 0.042958003\n",
      "Epoch: 3938 cost = 0.027404945\n",
      "Validation Loss: 0.038664836\n",
      "Epoch: 3939 cost = 0.027384813\n",
      "Validation Loss: 0.03359689\n",
      "Epoch: 3940 cost = 0.027404040\n",
      "Validation Loss: 0.029952615\n",
      "Epoch: 3941 cost = 0.027383867\n",
      "Validation Loss: 0.033228394\n",
      "Epoch: 3942 cost = 0.027403113\n",
      "Validation Loss: 0.031190908\n",
      "Epoch: 3943 cost = 0.027382909\n",
      "Validation Loss: 0.035742648\n",
      "Epoch: 3944 cost = 0.027402183\n",
      "Validation Loss: 0.04146807\n",
      "Epoch: 3945 cost = 0.027381956\n",
      "Validation Loss: 0.04445379\n",
      "Epoch: 3946 cost = 0.027401272\n",
      "Validation Loss: 0.045100436\n",
      "Epoch: 3947 cost = 0.027381015\n",
      "Validation Loss: 0.0431589\n",
      "Epoch: 3948 cost = 0.027400326\n",
      "Validation Loss: 0.03908467\n",
      "Epoch: 3949 cost = 0.027380093\n",
      "Validation Loss: 0.03240391\n",
      "Epoch: 3950 cost = 0.027399439\n",
      "Validation Loss: 0.032511503\n",
      "Epoch: 3951 cost = 0.027379141\n",
      "Validation Loss: 0.03470331\n",
      "Epoch: 3952 cost = 0.027398511\n",
      "Validation Loss: 0.035067733\n",
      "Epoch: 3953 cost = 0.027378221\n",
      "Validation Loss: 0.037438422\n",
      "Epoch: 3954 cost = 0.027397597\n",
      "Validation Loss: 0.036100466\n",
      "Epoch: 3955 cost = 0.027377272\n",
      "Validation Loss: 0.03800225\n",
      "Epoch: 3956 cost = 0.027396693\n",
      "Validation Loss: 0.03774773\n",
      "Epoch: 3957 cost = 0.027376333\n",
      "Validation Loss: 0.036524765\n",
      "Epoch: 3958 cost = 0.027395784\n",
      "Validation Loss: 0.035082415\n",
      "Epoch: 3959 cost = 0.027375393\n",
      "Validation Loss: 0.03590417\n",
      "Epoch: 3960 cost = 0.027394846\n",
      "Validation Loss: 0.03210153\n",
      "Epoch: 3961 cost = 0.027374457\n",
      "Validation Loss: 0.031526715\n",
      "Epoch: 3962 cost = 0.027393937\n",
      "Validation Loss: 0.030200355\n",
      "Epoch: 3963 cost = 0.027373522\n",
      "Validation Loss: 0.032905098\n",
      "Epoch: 3964 cost = 0.027393027\n",
      "Validation Loss: 0.041127156\n",
      "Epoch: 3965 cost = 0.027372601\n",
      "Validation Loss: 0.058357976\n",
      "Epoch: 3966 cost = 0.027392100\n",
      "Validation Loss: 0.060376618\n",
      "Epoch: 3967 cost = 0.027371655\n",
      "Validation Loss: 0.04312668\n",
      "Epoch: 3968 cost = 0.027391226\n",
      "Validation Loss: 0.03839658\n",
      "Epoch: 3969 cost = 0.027370715\n",
      "Validation Loss: 0.03563964\n",
      "Epoch: 3970 cost = 0.027390306\n",
      "Validation Loss: 0.03937654\n",
      "Epoch: 3971 cost = 0.027369788\n",
      "Validation Loss: 0.036448684\n",
      "Epoch: 3972 cost = 0.027389391\n",
      "Validation Loss: 0.03684701\n",
      "Epoch: 3973 cost = 0.027368857\n",
      "Validation Loss: 0.034946\n",
      "Epoch: 3974 cost = 0.027388459\n",
      "Validation Loss: 0.03391632\n",
      "Epoch: 3975 cost = 0.027367909\n",
      "Validation Loss: 0.046385396\n",
      "Epoch: 3976 cost = 0.027387546\n",
      "Validation Loss: 0.06483912\n",
      "Epoch: 3977 cost = 0.027366986\n",
      "Validation Loss: 0.083660066\n",
      "Epoch: 3978 cost = 0.027386641\n",
      "Validation Loss: 0.07134503\n",
      "Epoch: 3979 cost = 0.027366040\n",
      "Validation Loss: 0.051093638\n",
      "Epoch: 3980 cost = 0.027385735\n",
      "Validation Loss: 0.049586177\n",
      "Epoch: 3981 cost = 0.027365113\n",
      "Validation Loss: 0.04027086\n",
      "Epoch: 3982 cost = 0.027384835\n",
      "Validation Loss: 0.031225074\n",
      "Epoch: 3983 cost = 0.027364207\n",
      "Validation Loss: 0.029642405\n",
      "Epoch: 3984 cost = 0.027383914\n",
      "Validation Loss: 0.030120395\n",
      "Epoch: 3985 cost = 0.027363250\n",
      "Validation Loss: 0.028998379\n",
      "Epoch: 3986 cost = 0.027383010\n",
      "Validation Loss: 0.047512766\n",
      "Epoch: 3987 cost = 0.027362317\n",
      "Validation Loss: 0.032106318\n",
      "Epoch: 3988 cost = 0.027382077\n",
      "Validation Loss: 0.029972829\n",
      "Epoch: 3989 cost = 0.027361383\n",
      "Validation Loss: 0.031758662\n",
      "Epoch: 3990 cost = 0.027381184\n",
      "Validation Loss: 0.03791937\n",
      "Epoch: 3991 cost = 0.027360470\n",
      "Validation Loss: 0.037881587\n",
      "Epoch: 3992 cost = 0.027380257\n",
      "Validation Loss: 0.040253043\n",
      "Epoch: 3993 cost = 0.027359507\n",
      "Validation Loss: 0.04408774\n",
      "Epoch: 3994 cost = 0.027379366\n",
      "Validation Loss: 0.036411677\n",
      "Epoch: 3995 cost = 0.027358564\n",
      "Validation Loss: 0.036803357\n",
      "Epoch: 3996 cost = 0.027378425\n",
      "Validation Loss: 0.035353478\n",
      "Epoch: 3997 cost = 0.027357655\n",
      "Validation Loss: 0.032705612\n",
      "Epoch: 3998 cost = 0.027377490\n",
      "Validation Loss: 0.03580109\n",
      "Epoch: 3999 cost = 0.027356692\n",
      "Validation Loss: 0.037453096\n",
      "Epoch: 4000 cost = 0.027376579\n",
      "Validation Loss: 0.0475767\n",
      "Epoch: 4001 cost = 0.027355779\n",
      "Validation Loss: 0.037488513\n",
      "Epoch: 4002 cost = 0.027375695\n",
      "Validation Loss: 0.030915203\n",
      "Epoch: 4003 cost = 0.027354851\n",
      "Validation Loss: 0.032734722\n",
      "Epoch: 4004 cost = 0.027374755\n",
      "Validation Loss: 0.029841695\n",
      "Epoch: 4005 cost = 0.027353928\n",
      "Validation Loss: 0.032750588\n",
      "Epoch: 4006 cost = 0.027373863\n",
      "Validation Loss: 0.030868357\n",
      "Epoch: 4007 cost = 0.027353003\n",
      "Validation Loss: 0.033244263\n",
      "Epoch: 4008 cost = 0.027372965\n",
      "Validation Loss: 0.033121347\n",
      "Epoch: 4009 cost = 0.027352072\n",
      "Validation Loss: 0.031048466\n",
      "Epoch: 4010 cost = 0.027372036\n",
      "Validation Loss: 0.031251896\n",
      "Epoch: 4011 cost = 0.027351138\n",
      "Validation Loss: 0.036504656\n",
      "Epoch: 4012 cost = 0.027371155\n",
      "Validation Loss: 0.04164505\n",
      "Epoch: 4013 cost = 0.027350211\n",
      "Validation Loss: 0.04518283\n",
      "Epoch: 4014 cost = 0.027370254\n",
      "Validation Loss: 0.039680924\n",
      "Epoch: 4015 cost = 0.027349286\n",
      "Validation Loss: 0.035297696\n",
      "Epoch: 4016 cost = 0.027369345\n",
      "Validation Loss: 0.040040858\n",
      "Epoch: 4017 cost = 0.027348362\n",
      "Validation Loss: 0.046798464\n",
      "Epoch: 4018 cost = 0.027368448\n",
      "Validation Loss: 0.05400864\n",
      "Epoch: 4019 cost = 0.027347454\n",
      "Validation Loss: 0.056210257\n",
      "Epoch: 4020 cost = 0.027367546\n",
      "Validation Loss: 0.050217584\n",
      "Epoch: 4021 cost = 0.027346529\n",
      "Validation Loss: 0.04333696\n",
      "Epoch: 4022 cost = 0.027366640\n",
      "Validation Loss: 0.036991607\n",
      "Epoch: 4023 cost = 0.027345604\n",
      "Validation Loss: 0.03345686\n",
      "Epoch: 4024 cost = 0.027365767\n",
      "Validation Loss: 0.032994177\n",
      "Epoch: 4025 cost = 0.027344688\n",
      "Validation Loss: 0.033702\n",
      "Epoch: 4026 cost = 0.027364866\n",
      "Validation Loss: 0.04362538\n",
      "Epoch: 4027 cost = 0.027343766\n",
      "Validation Loss: 0.04399826\n",
      "Epoch: 4028 cost = 0.027363967\n",
      "Validation Loss: 0.038284216\n",
      "Epoch: 4029 cost = 0.027342829\n",
      "Validation Loss: 0.032879524\n",
      "Epoch: 4030 cost = 0.027363073\n",
      "Validation Loss: 0.03290262\n",
      "Epoch: 4031 cost = 0.027341930\n",
      "Validation Loss: 0.033792146\n",
      "Epoch: 4032 cost = 0.027362176\n",
      "Validation Loss: 0.0312563\n",
      "Epoch: 4033 cost = 0.027340998\n",
      "Validation Loss: 0.033061583\n",
      "Epoch: 4034 cost = 0.027361265\n",
      "Validation Loss: 0.033411454\n",
      "Epoch: 4035 cost = 0.027340081\n",
      "Validation Loss: 0.03801808\n",
      "Epoch: 4036 cost = 0.027360365\n",
      "Validation Loss: 0.036673844\n",
      "Epoch: 4037 cost = 0.027339139\n",
      "Validation Loss: 0.03418225\n",
      "Epoch: 4038 cost = 0.027359472\n",
      "Validation Loss: 0.033187676\n",
      "Epoch: 4039 cost = 0.027338207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.031978212\n",
      "Epoch: 4040 cost = 0.027358561\n",
      "Validation Loss: 0.032541808\n",
      "Epoch: 4041 cost = 0.027337311\n",
      "Validation Loss: 0.031430095\n",
      "Epoch: 4042 cost = 0.027357662\n",
      "Validation Loss: 0.031782024\n",
      "Epoch: 4043 cost = 0.027336366\n",
      "Validation Loss: 0.03753767\n",
      "Epoch: 4044 cost = 0.027356772\n",
      "Validation Loss: 0.05104726\n",
      "Epoch: 4045 cost = 0.027335466\n",
      "Validation Loss: 0.049568545\n",
      "Epoch: 4046 cost = 0.027355869\n",
      "Validation Loss: 0.04772007\n",
      "Epoch: 4047 cost = 0.027334546\n",
      "Validation Loss: 0.040269915\n",
      "Epoch: 4048 cost = 0.027354984\n",
      "Validation Loss: 0.035447508\n",
      "Epoch: 4049 cost = 0.027333620\n",
      "Validation Loss: 0.03395161\n",
      "Epoch: 4050 cost = 0.027354069\n",
      "Validation Loss: 0.03574708\n",
      "Epoch: 4051 cost = 0.027332705\n",
      "Validation Loss: 0.035895884\n",
      "Epoch: 4052 cost = 0.027353143\n",
      "Validation Loss: 0.037935216\n",
      "Epoch: 4053 cost = 0.027331795\n",
      "Validation Loss: 0.036785576\n",
      "Epoch: 4054 cost = 0.027352253\n",
      "Validation Loss: 0.032102\n",
      "Epoch: 4055 cost = 0.027330854\n",
      "Validation Loss: 0.03530081\n",
      "Epoch: 4056 cost = 0.027351352\n",
      "Validation Loss: 0.029988049\n",
      "Epoch: 4057 cost = 0.027329943\n",
      "Validation Loss: 0.031640314\n",
      "Epoch: 4058 cost = 0.027350457\n",
      "Validation Loss: 0.0315491\n",
      "Epoch: 4059 cost = 0.027329018\n",
      "Validation Loss: 0.03240332\n",
      "Epoch: 4060 cost = 0.027349556\n",
      "Validation Loss: 0.029586945\n",
      "Epoch: 4061 cost = 0.027328091\n",
      "Validation Loss: 0.03176315\n",
      "Epoch: 4062 cost = 0.027348661\n",
      "Validation Loss: 0.033015978\n",
      "Epoch: 4063 cost = 0.027327184\n",
      "Validation Loss: 0.034719545\n",
      "Epoch: 4064 cost = 0.027347765\n",
      "Validation Loss: 0.04632442\n",
      "Epoch: 4065 cost = 0.027326270\n",
      "Validation Loss: 0.048586488\n",
      "Epoch: 4066 cost = 0.027346844\n",
      "Validation Loss: 0.043447442\n",
      "Epoch: 4067 cost = 0.027325359\n",
      "Validation Loss: 0.03845905\n",
      "Epoch: 4068 cost = 0.027345973\n",
      "Validation Loss: 0.03552382\n",
      "Epoch: 4069 cost = 0.027324433\n",
      "Validation Loss: 0.03647864\n",
      "Epoch: 4070 cost = 0.027345054\n",
      "Validation Loss: 0.035442334\n",
      "Epoch: 4071 cost = 0.027323527\n",
      "Validation Loss: 0.031344708\n",
      "Epoch: 4072 cost = 0.027344167\n",
      "Validation Loss: 0.03301584\n",
      "Epoch: 4073 cost = 0.027322598\n",
      "Validation Loss: 0.031807885\n",
      "Epoch: 4074 cost = 0.027343291\n",
      "Validation Loss: 0.04626698\n",
      "Epoch: 4075 cost = 0.027321706\n",
      "Validation Loss: 0.06126193\n",
      "Epoch: 4076 cost = 0.027342419\n",
      "Validation Loss: 0.050205573\n",
      "Epoch: 4077 cost = 0.027320773\n",
      "Validation Loss: 0.03956432\n",
      "Epoch: 4078 cost = 0.027341492\n",
      "Validation Loss: 0.03557591\n",
      "Epoch: 4079 cost = 0.027319851\n",
      "Validation Loss: 0.033298567\n",
      "Epoch: 4080 cost = 0.027340595\n",
      "Validation Loss: 0.03450385\n",
      "Epoch: 4081 cost = 0.027318920\n",
      "Validation Loss: 0.04118465\n",
      "Epoch: 4082 cost = 0.027339691\n",
      "Validation Loss: 0.04729333\n",
      "Epoch: 4083 cost = 0.027318022\n",
      "Validation Loss: 0.044439923\n",
      "Epoch: 4084 cost = 0.027338815\n",
      "Validation Loss: 0.048636265\n",
      "Epoch: 4085 cost = 0.027317125\n",
      "Validation Loss: 0.043186344\n",
      "Epoch: 4086 cost = 0.027337966\n",
      "Validation Loss: 0.03738375\n",
      "Epoch: 4087 cost = 0.027316190\n",
      "Validation Loss: 0.04481793\n",
      "Epoch: 4088 cost = 0.027337063\n",
      "Validation Loss: 0.040433016\n",
      "Epoch: 4089 cost = 0.027315286\n",
      "Validation Loss: 0.033544533\n",
      "Epoch: 4090 cost = 0.027336156\n",
      "Validation Loss: 0.036719467\n",
      "Epoch: 4091 cost = 0.027314381\n",
      "Validation Loss: 0.031119365\n",
      "Epoch: 4092 cost = 0.027335251\n",
      "Validation Loss: 0.032180358\n",
      "Epoch: 4093 cost = 0.027313455\n",
      "Validation Loss: 0.034734357\n",
      "Epoch: 4094 cost = 0.027334364\n",
      "Validation Loss: 0.03289045\n",
      "Epoch: 4095 cost = 0.027312562\n",
      "Validation Loss: 0.034222193\n",
      "Epoch: 4096 cost = 0.027333463\n",
      "Validation Loss: 0.03452156\n",
      "Epoch: 4097 cost = 0.027311650\n",
      "Validation Loss: 0.038922686\n",
      "Epoch: 4098 cost = 0.027332588\n",
      "Validation Loss: 0.047409788\n",
      "Epoch: 4099 cost = 0.027310735\n",
      "Validation Loss: 0.044894658\n",
      "Epoch: 4100 cost = 0.027331696\n",
      "Validation Loss: 0.03989581\n",
      "Epoch: 4101 cost = 0.027309823\n",
      "Validation Loss: 0.037848923\n",
      "Epoch: 4102 cost = 0.027330801\n",
      "Validation Loss: 0.038584746\n",
      "Epoch: 4103 cost = 0.027308918\n",
      "Validation Loss: 0.0368398\n",
      "Epoch: 4104 cost = 0.027329941\n",
      "Validation Loss: 0.03740545\n",
      "Epoch: 4105 cost = 0.027308000\n",
      "Validation Loss: 0.036387544\n",
      "Epoch: 4106 cost = 0.027329030\n",
      "Validation Loss: 0.033071987\n",
      "Epoch: 4107 cost = 0.027307090\n",
      "Validation Loss: 0.031445708\n",
      "Epoch: 4108 cost = 0.027328131\n",
      "Validation Loss: 0.03146688\n",
      "Epoch: 4109 cost = 0.027306188\n",
      "Validation Loss: 0.03405916\n",
      "Epoch: 4110 cost = 0.027327244\n",
      "Validation Loss: 0.035338283\n",
      "Epoch: 4111 cost = 0.027305272\n",
      "Validation Loss: 0.032851934\n",
      "Epoch: 4112 cost = 0.027326347\n",
      "Validation Loss: 0.03518428\n",
      "Epoch: 4113 cost = 0.027304367\n",
      "Validation Loss: 0.030741276\n",
      "Epoch: 4114 cost = 0.027325474\n",
      "Validation Loss: 0.030424569\n",
      "Epoch: 4115 cost = 0.027303432\n",
      "Validation Loss: 0.033719856\n",
      "Epoch: 4116 cost = 0.027324564\n",
      "Validation Loss: 0.032469787\n",
      "Epoch: 4117 cost = 0.027302522\n",
      "Validation Loss: 0.034451492\n",
      "Epoch: 4118 cost = 0.027323674\n",
      "Validation Loss: 0.033979315\n",
      "Epoch: 4119 cost = 0.027301631\n",
      "Validation Loss: 0.032896664\n",
      "Epoch: 4120 cost = 0.027322794\n",
      "Validation Loss: 0.03200494\n",
      "Epoch: 4121 cost = 0.027300710\n",
      "Validation Loss: 0.032557063\n",
      "Epoch: 4122 cost = 0.027321908\n",
      "Validation Loss: 0.047872845\n",
      "Epoch: 4123 cost = 0.027299827\n",
      "Validation Loss: 0.050656892\n",
      "Epoch: 4124 cost = 0.027321011\n",
      "Validation Loss: 0.03648151\n",
      "Epoch: 4125 cost = 0.027298901\n",
      "Validation Loss: 0.034037177\n",
      "Epoch: 4126 cost = 0.027320107\n",
      "Validation Loss: 0.033355594\n",
      "Epoch: 4127 cost = 0.027297996\n",
      "Validation Loss: 0.04206652\n",
      "Epoch: 4128 cost = 0.027319224\n",
      "Validation Loss: 0.043672763\n",
      "Epoch: 4129 cost = 0.027297071\n",
      "Validation Loss: 0.038505018\n",
      "Epoch: 4130 cost = 0.027318332\n",
      "Validation Loss: 0.0347455\n",
      "Epoch: 4131 cost = 0.027296170\n",
      "Validation Loss: 0.035117496\n",
      "Epoch: 4132 cost = 0.027317442\n",
      "Validation Loss: 0.033208437\n",
      "Epoch: 4133 cost = 0.027295279\n",
      "Validation Loss: 0.032847807\n",
      "Epoch: 4134 cost = 0.027316548\n",
      "Validation Loss: 0.03581982\n",
      "Epoch: 4135 cost = 0.027294343\n",
      "Validation Loss: 0.03796401\n",
      "Epoch: 4136 cost = 0.027315675\n",
      "Validation Loss: 0.04241125\n",
      "Epoch: 4137 cost = 0.027293426\n",
      "Validation Loss: 0.042884298\n",
      "Epoch: 4138 cost = 0.027314783\n",
      "Validation Loss: 0.037069235\n",
      "Epoch: 4139 cost = 0.027292532\n",
      "Validation Loss: 0.03175165\n",
      "Epoch: 4140 cost = 0.027313886\n",
      "Validation Loss: 0.032948323\n",
      "Epoch: 4141 cost = 0.027291625\n",
      "Validation Loss: 0.035842273\n",
      "Epoch: 4142 cost = 0.027312989\n",
      "Validation Loss: 0.055799693\n",
      "Epoch: 4143 cost = 0.027290703\n",
      "Validation Loss: 0.044230465\n",
      "Epoch: 4144 cost = 0.027312111\n",
      "Validation Loss: 0.04794921\n",
      "Epoch: 4145 cost = 0.027289815\n",
      "Validation Loss: 0.04008553\n",
      "Epoch: 4146 cost = 0.027311226\n",
      "Validation Loss: 0.04283757\n",
      "Epoch: 4147 cost = 0.027288924\n",
      "Validation Loss: 0.049569666\n",
      "Epoch: 4148 cost = 0.027310332\n",
      "Validation Loss: 0.05401263\n",
      "Epoch: 4149 cost = 0.027288016\n",
      "Validation Loss: 0.057125602\n",
      "Epoch: 4150 cost = 0.027309430\n",
      "Validation Loss: 0.05510951\n",
      "Epoch: 4151 cost = 0.027287077\n",
      "Validation Loss: 0.062116995\n",
      "Epoch: 4152 cost = 0.027308550\n",
      "Validation Loss: 0.042357616\n",
      "Epoch: 4153 cost = 0.027286184\n",
      "Validation Loss: 0.035979185\n",
      "Epoch: 4154 cost = 0.027307696\n",
      "Validation Loss: 0.03458837\n",
      "Epoch: 4155 cost = 0.027285279\n",
      "Validation Loss: 0.037177917\n",
      "Epoch: 4156 cost = 0.027306800\n",
      "Validation Loss: 0.04265067\n",
      "Epoch: 4157 cost = 0.027284389\n",
      "Validation Loss: 0.042072088\n",
      "Epoch: 4158 cost = 0.027305905\n",
      "Validation Loss: 0.039300103\n",
      "Epoch: 4159 cost = 0.027283480\n",
      "Validation Loss: 0.03932629\n",
      "Epoch: 4160 cost = 0.027305036\n",
      "Validation Loss: 0.04124962\n",
      "Epoch: 4161 cost = 0.027282580\n",
      "Validation Loss: 0.04161081\n",
      "Epoch: 4162 cost = 0.027304129\n",
      "Validation Loss: 0.03509758\n",
      "Epoch: 4163 cost = 0.027281675\n",
      "Validation Loss: 0.03829354\n",
      "Epoch: 4164 cost = 0.027303254\n",
      "Validation Loss: 0.03924162\n",
      "Epoch: 4165 cost = 0.027280771\n",
      "Validation Loss: 0.035758156\n",
      "Epoch: 4166 cost = 0.027302372\n",
      "Validation Loss: 0.03299784\n",
      "Epoch: 4167 cost = 0.027279860\n",
      "Validation Loss: 0.03373081\n",
      "Epoch: 4168 cost = 0.027301462\n",
      "Validation Loss: 0.033970296\n",
      "Epoch: 4169 cost = 0.027278941\n",
      "Validation Loss: 0.03543591\n",
      "Epoch: 4170 cost = 0.027300606\n",
      "Validation Loss: 0.046377443\n",
      "Epoch: 4171 cost = 0.027278060\n",
      "Validation Loss: 0.05535569\n",
      "Epoch: 4172 cost = 0.027299679\n",
      "Validation Loss: 0.054783225\n",
      "Epoch: 4173 cost = 0.027277145\n",
      "Validation Loss: 0.042229977\n",
      "Epoch: 4174 cost = 0.027298786\n",
      "Validation Loss: 0.03499945\n",
      "Epoch: 4175 cost = 0.027276221\n",
      "Validation Loss: 0.031633135\n",
      "Epoch: 4176 cost = 0.027297925\n",
      "Validation Loss: 0.033959556\n",
      "Epoch: 4177 cost = 0.027275339\n",
      "Validation Loss: 0.033877358\n",
      "Epoch: 4178 cost = 0.027297049\n",
      "Validation Loss: 0.03868513\n",
      "Epoch: 4179 cost = 0.027274432\n",
      "Validation Loss: 0.035028037\n",
      "Epoch: 4180 cost = 0.027296163\n",
      "Validation Loss: 0.052314963\n",
      "Epoch: 4181 cost = 0.027273533\n",
      "Validation Loss: 0.06483282\n",
      "Epoch: 4182 cost = 0.027295249\n",
      "Validation Loss: 0.055887036\n",
      "Epoch: 4183 cost = 0.027272647\n",
      "Validation Loss: 0.044993643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4184 cost = 0.027294365\n",
      "Validation Loss: 0.033723995\n",
      "Epoch: 4185 cost = 0.027271722\n",
      "Validation Loss: 0.03130902\n",
      "Epoch: 4186 cost = 0.027293505\n",
      "Validation Loss: 0.030852325\n",
      "Epoch: 4187 cost = 0.027270836\n",
      "Validation Loss: 0.030035418\n",
      "Epoch: 4188 cost = 0.027292613\n",
      "Validation Loss: 0.03277892\n",
      "Epoch: 4189 cost = 0.027269905\n",
      "Validation Loss: 0.033151403\n",
      "Epoch: 4190 cost = 0.027291731\n",
      "Validation Loss: 0.03426626\n",
      "Epoch: 4191 cost = 0.027269010\n",
      "Validation Loss: 0.0348884\n",
      "Epoch: 4192 cost = 0.027290837\n",
      "Validation Loss: 0.03680079\n",
      "Epoch: 4193 cost = 0.027268096\n",
      "Validation Loss: 0.033668756\n",
      "Epoch: 4194 cost = 0.027289971\n",
      "Validation Loss: 0.032705683\n",
      "Epoch: 4195 cost = 0.027267212\n",
      "Validation Loss: 0.031199083\n",
      "Epoch: 4196 cost = 0.027289082\n",
      "Validation Loss: 0.031359542\n",
      "Epoch: 4197 cost = 0.027266317\n",
      "Validation Loss: 0.034910496\n",
      "Epoch: 4198 cost = 0.027288160\n",
      "Validation Loss: 0.033195768\n",
      "Epoch: 4199 cost = 0.027265402\n",
      "Validation Loss: 0.03451726\n",
      "Epoch: 4200 cost = 0.027287298\n",
      "Validation Loss: 0.04114239\n",
      "Epoch: 4201 cost = 0.027264491\n",
      "Validation Loss: 0.041208196\n",
      "Epoch: 4202 cost = 0.027286417\n",
      "Validation Loss: 0.034300983\n",
      "Epoch: 4203 cost = 0.027263591\n",
      "Validation Loss: 0.03480671\n",
      "Epoch: 4204 cost = 0.027285555\n",
      "Validation Loss: 0.03526147\n",
      "Epoch: 4205 cost = 0.027262701\n",
      "Validation Loss: 0.033746142\n",
      "Epoch: 4206 cost = 0.027284670\n",
      "Validation Loss: 0.03432776\n",
      "Epoch: 4207 cost = 0.027261782\n",
      "Validation Loss: 0.0326572\n",
      "Epoch: 4208 cost = 0.027283794\n",
      "Validation Loss: 0.02940921\n",
      "Epoch: 4209 cost = 0.027260893\n",
      "Validation Loss: 0.028869404\n",
      "Epoch: 4210 cost = 0.027282881\n",
      "Validation Loss: 0.053074073\n",
      "Epoch: 4211 cost = 0.027259987\n",
      "Validation Loss: 0.042147942\n",
      "Epoch: 4212 cost = 0.027281984\n",
      "Validation Loss: 0.039575197\n",
      "Epoch: 4213 cost = 0.027259076\n",
      "Validation Loss: 0.0451358\n",
      "Epoch: 4214 cost = 0.027281095\n",
      "Validation Loss: 0.050475486\n",
      "Epoch: 4215 cost = 0.027258169\n",
      "Validation Loss: 0.036396403\n",
      "Epoch: 4216 cost = 0.027280230\n",
      "Validation Loss: 0.032608338\n",
      "Epoch: 4217 cost = 0.027257254\n",
      "Validation Loss: 0.02953598\n",
      "Epoch: 4218 cost = 0.027279331\n",
      "Validation Loss: 0.031221598\n",
      "Epoch: 4219 cost = 0.027256370\n",
      "Validation Loss: 0.031461246\n",
      "Epoch: 4220 cost = 0.027278432\n",
      "Validation Loss: 0.037611477\n",
      "Epoch: 4221 cost = 0.027255467\n",
      "Validation Loss: 0.036788385\n",
      "Epoch: 4222 cost = 0.027277551\n",
      "Validation Loss: 0.037785225\n",
      "Epoch: 4223 cost = 0.027254570\n",
      "Validation Loss: 0.032997984\n",
      "Epoch: 4224 cost = 0.027276666\n",
      "Validation Loss: 0.031482507\n",
      "Epoch: 4225 cost = 0.027253668\n",
      "Validation Loss: 0.032234736\n",
      "Epoch: 4226 cost = 0.027275785\n",
      "Validation Loss: 0.03566715\n",
      "Epoch: 4227 cost = 0.027252756\n",
      "Validation Loss: 0.050855964\n",
      "Epoch: 4228 cost = 0.027274905\n",
      "Validation Loss: 0.04889904\n",
      "Epoch: 4229 cost = 0.027251856\n",
      "Validation Loss: 0.036252953\n",
      "Epoch: 4230 cost = 0.027274013\n",
      "Validation Loss: 0.03473882\n",
      "Epoch: 4231 cost = 0.027250981\n",
      "Validation Loss: 0.038476907\n",
      "Epoch: 4232 cost = 0.027273125\n",
      "Validation Loss: 0.03405543\n",
      "Epoch: 4233 cost = 0.027250060\n",
      "Validation Loss: 0.03108693\n",
      "Epoch: 4234 cost = 0.027272274\n",
      "Validation Loss: 0.039760962\n",
      "Epoch: 4235 cost = 0.027249148\n",
      "Validation Loss: 0.08023104\n",
      "Epoch: 4236 cost = 0.027271390\n",
      "Validation Loss: 0.09728854\n",
      "Epoch: 4237 cost = 0.027248263\n",
      "Validation Loss: 0.085177064\n",
      "Epoch: 4238 cost = 0.027270480\n",
      "Validation Loss: 0.08377302\n",
      "Epoch: 4239 cost = 0.027247358\n",
      "Validation Loss: 0.06878635\n",
      "Epoch: 4240 cost = 0.027269621\n",
      "Validation Loss: 0.066341594\n",
      "Epoch: 4241 cost = 0.027246447\n",
      "Validation Loss: 0.057478976\n",
      "Epoch: 4242 cost = 0.027268727\n",
      "Validation Loss: 0.066081166\n",
      "Epoch: 4243 cost = 0.027245555\n",
      "Validation Loss: 0.04739966\n",
      "Epoch: 4244 cost = 0.027267815\n",
      "Validation Loss: 0.033752915\n",
      "Epoch: 4245 cost = 0.027244651\n",
      "Validation Loss: 0.032397695\n",
      "Epoch: 4246 cost = 0.027266954\n",
      "Validation Loss: 0.03096741\n",
      "Epoch: 4247 cost = 0.027243721\n",
      "Validation Loss: 0.031906057\n",
      "Epoch: 4248 cost = 0.027266060\n",
      "Validation Loss: 0.03171904\n",
      "Epoch: 4249 cost = 0.027242844\n",
      "Validation Loss: 0.032981165\n",
      "Epoch: 4250 cost = 0.027265163\n",
      "Validation Loss: 0.033097524\n",
      "Epoch: 4251 cost = 0.027241943\n",
      "Validation Loss: 0.035086516\n",
      "Epoch: 4252 cost = 0.027264277\n",
      "Validation Loss: 0.034028538\n",
      "Epoch: 4253 cost = 0.027241026\n",
      "Validation Loss: 0.0376578\n",
      "Epoch: 4254 cost = 0.027263410\n",
      "Validation Loss: 0.039491203\n",
      "Epoch: 4255 cost = 0.027240145\n",
      "Validation Loss: 0.036602657\n",
      "Epoch: 4256 cost = 0.027262521\n",
      "Validation Loss: 0.037842184\n",
      "Epoch: 4257 cost = 0.027239238\n",
      "Validation Loss: 0.041108992\n",
      "Epoch: 4258 cost = 0.027261638\n",
      "Validation Loss: 0.039305545\n",
      "Epoch: 4259 cost = 0.027238332\n",
      "Validation Loss: 0.043342773\n",
      "Epoch: 4260 cost = 0.027260774\n",
      "Validation Loss: 0.037878655\n",
      "Epoch: 4261 cost = 0.027237433\n",
      "Validation Loss: 0.034003254\n",
      "Epoch: 4262 cost = 0.027259878\n",
      "Validation Loss: 0.035858836\n",
      "Epoch: 4263 cost = 0.027236553\n",
      "Validation Loss: 0.03435239\n",
      "Epoch: 4264 cost = 0.027259009\n",
      "Validation Loss: 0.034680877\n",
      "Epoch: 4265 cost = 0.027235640\n",
      "Validation Loss: 0.036126155\n",
      "Epoch: 4266 cost = 0.027258102\n",
      "Validation Loss: 0.036590725\n",
      "Epoch: 4267 cost = 0.027234740\n",
      "Validation Loss: 0.035874736\n",
      "Epoch: 4268 cost = 0.027257224\n",
      "Validation Loss: 0.033045698\n",
      "Epoch: 4269 cost = 0.027233833\n",
      "Validation Loss: 0.0346485\n",
      "Epoch: 4270 cost = 0.027256337\n",
      "Validation Loss: 0.032496244\n",
      "Epoch: 4271 cost = 0.027232948\n",
      "Validation Loss: 0.03126601\n",
      "Epoch: 4272 cost = 0.027255447\n",
      "Validation Loss: 0.034853302\n",
      "Epoch: 4273 cost = 0.027232047\n",
      "Validation Loss: 0.0340977\n",
      "Epoch: 4274 cost = 0.027254570\n",
      "Validation Loss: 0.035724852\n",
      "Epoch: 4275 cost = 0.027231147\n",
      "Validation Loss: 0.036871836\n",
      "Epoch: 4276 cost = 0.027253684\n",
      "Validation Loss: 0.03866907\n",
      "Epoch: 4277 cost = 0.027230214\n",
      "Validation Loss: 0.03895215\n",
      "Epoch: 4278 cost = 0.027252797\n",
      "Validation Loss: 0.042884286\n",
      "Epoch: 4279 cost = 0.027229330\n",
      "Validation Loss: 0.050870344\n",
      "Epoch: 4280 cost = 0.027251889\n",
      "Validation Loss: 0.037511095\n",
      "Epoch: 4281 cost = 0.027228430\n",
      "Validation Loss: 0.032754723\n",
      "Epoch: 4282 cost = 0.027251012\n",
      "Validation Loss: 0.034981713\n",
      "Epoch: 4283 cost = 0.027227542\n",
      "Validation Loss: 0.038211074\n",
      "Epoch: 4284 cost = 0.027250139\n",
      "Validation Loss: 0.035901874\n",
      "Epoch: 4285 cost = 0.027226641\n",
      "Validation Loss: 0.037131794\n",
      "Epoch: 4286 cost = 0.027249255\n",
      "Validation Loss: 0.031057606\n",
      "Epoch: 4287 cost = 0.027225731\n",
      "Validation Loss: 0.030118033\n",
      "Epoch: 4288 cost = 0.027248400\n",
      "Validation Loss: 0.0331337\n",
      "Epoch: 4289 cost = 0.027224848\n",
      "Validation Loss: 0.036101453\n",
      "Epoch: 4290 cost = 0.027247507\n",
      "Validation Loss: 0.035811946\n",
      "Epoch: 4291 cost = 0.027223946\n",
      "Validation Loss: 0.03368131\n",
      "Epoch: 4292 cost = 0.027246609\n",
      "Validation Loss: 0.034758646\n",
      "Epoch: 4293 cost = 0.027223046\n",
      "Validation Loss: 0.03722111\n",
      "Epoch: 4294 cost = 0.027245731\n",
      "Validation Loss: 0.03572975\n",
      "Epoch: 4295 cost = 0.027222125\n",
      "Validation Loss: 0.032565027\n",
      "Epoch: 4296 cost = 0.027244814\n",
      "Validation Loss: 0.032093253\n",
      "Epoch: 4297 cost = 0.027221221\n",
      "Validation Loss: 0.033785176\n",
      "Epoch: 4298 cost = 0.027243936\n",
      "Validation Loss: 0.03520971\n",
      "Epoch: 4299 cost = 0.027220336\n",
      "Validation Loss: 0.037770882\n",
      "Epoch: 4300 cost = 0.027243053\n",
      "Validation Loss: 0.035134938\n",
      "Epoch: 4301 cost = 0.027219410\n",
      "Validation Loss: 0.035502717\n",
      "Epoch: 4302 cost = 0.027242191\n",
      "Validation Loss: 0.036465064\n",
      "Epoch: 4303 cost = 0.027218527\n",
      "Validation Loss: 0.036238685\n",
      "Epoch: 4304 cost = 0.027241291\n",
      "Validation Loss: 0.03661405\n",
      "Epoch: 4305 cost = 0.027217633\n",
      "Validation Loss: 0.038667075\n",
      "Epoch: 4306 cost = 0.027240417\n",
      "Validation Loss: 0.036106907\n",
      "Epoch: 4307 cost = 0.027216742\n",
      "Validation Loss: 0.03428964\n",
      "Epoch: 4308 cost = 0.027239517\n",
      "Validation Loss: 0.036620017\n",
      "Epoch: 4309 cost = 0.027215839\n",
      "Validation Loss: 0.032188658\n",
      "Epoch: 4310 cost = 0.027238652\n",
      "Validation Loss: 0.03236733\n",
      "Epoch: 4311 cost = 0.027214914\n",
      "Validation Loss: 0.031880006\n",
      "Epoch: 4312 cost = 0.027237781\n",
      "Validation Loss: 0.032629125\n",
      "Epoch: 4313 cost = 0.027214020\n",
      "Validation Loss: 0.033339057\n",
      "Epoch: 4314 cost = 0.027236886\n",
      "Validation Loss: 0.032180358\n",
      "Epoch: 4315 cost = 0.027213139\n",
      "Validation Loss: 0.036573064\n",
      "Epoch: 4316 cost = 0.027235994\n",
      "Validation Loss: 0.035271317\n",
      "Epoch: 4317 cost = 0.027212243\n",
      "Validation Loss: 0.029120464\n",
      "Epoch: 4318 cost = 0.027235099\n",
      "Validation Loss: 0.03168251\n",
      "Epoch: 4319 cost = 0.027211305\n",
      "Validation Loss: 0.030166907\n",
      "Epoch: 4320 cost = 0.027234207\n",
      "Validation Loss: 0.032269794\n",
      "Epoch: 4321 cost = 0.027210420\n",
      "Validation Loss: 0.03257749\n",
      "Epoch: 4322 cost = 0.027233317\n",
      "Validation Loss: 0.032527674\n",
      "Epoch: 4323 cost = 0.027209501\n",
      "Validation Loss: 0.032067552\n",
      "Epoch: 4324 cost = 0.027232436\n",
      "Validation Loss: 0.029861722\n",
      "Epoch: 4325 cost = 0.027208625\n",
      "Validation Loss: 0.031410564\n",
      "Epoch: 4326 cost = 0.027231522\n",
      "Validation Loss: 0.035634723\n",
      "Epoch: 4327 cost = 0.027207719\n",
      "Validation Loss: 0.038328383\n",
      "Epoch: 4328 cost = 0.027230647\n",
      "Validation Loss: 0.037011087\n",
      "Epoch: 4329 cost = 0.027206818\n",
      "Validation Loss: 0.035063747\n",
      "Epoch: 4330 cost = 0.027229779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03234966\n",
      "Epoch: 4331 cost = 0.027205904\n",
      "Validation Loss: 0.03360378\n",
      "Epoch: 4332 cost = 0.027228909\n",
      "Validation Loss: 0.031207401\n",
      "Epoch: 4333 cost = 0.027205024\n",
      "Validation Loss: 0.037203684\n",
      "Epoch: 4334 cost = 0.027227991\n",
      "Validation Loss: 0.037031077\n",
      "Epoch: 4335 cost = 0.027204128\n",
      "Validation Loss: 0.03655242\n",
      "Epoch: 4336 cost = 0.027227103\n",
      "Validation Loss: 0.053519573\n",
      "Epoch: 4337 cost = 0.027203205\n",
      "Validation Loss: 0.057322342\n",
      "Epoch: 4338 cost = 0.027226229\n",
      "Validation Loss: 0.053779203\n",
      "Epoch: 4339 cost = 0.027202301\n",
      "Validation Loss: 0.054639746\n",
      "Epoch: 4340 cost = 0.027225370\n",
      "Validation Loss: 0.036421534\n",
      "Epoch: 4341 cost = 0.027201416\n",
      "Validation Loss: 0.039539095\n",
      "Epoch: 4342 cost = 0.027224453\n",
      "Validation Loss: 0.055435997\n",
      "Epoch: 4343 cost = 0.027200520\n",
      "Validation Loss: 0.040998846\n",
      "Epoch: 4344 cost = 0.027223555\n",
      "Validation Loss: 0.03328844\n",
      "Epoch: 4345 cost = 0.027199626\n",
      "Validation Loss: 0.03437763\n",
      "Epoch: 4346 cost = 0.027222659\n",
      "Validation Loss: 0.03479902\n",
      "Epoch: 4347 cost = 0.027198712\n",
      "Validation Loss: 0.036106188\n",
      "Epoch: 4348 cost = 0.027221791\n",
      "Validation Loss: 0.036501743\n",
      "Epoch: 4349 cost = 0.027197818\n",
      "Validation Loss: 0.049768798\n",
      "Epoch: 4350 cost = 0.027220898\n",
      "Validation Loss: 0.05672653\n",
      "Epoch: 4351 cost = 0.027196912\n",
      "Validation Loss: 0.05228036\n",
      "Epoch: 4352 cost = 0.027220017\n",
      "Validation Loss: 0.058261994\n",
      "Epoch: 4353 cost = 0.027196023\n",
      "Validation Loss: 0.046200354\n",
      "Epoch: 4354 cost = 0.027219138\n",
      "Validation Loss: 0.050897244\n",
      "Epoch: 4355 cost = 0.027195103\n",
      "Validation Loss: 0.053755827\n",
      "Epoch: 4356 cost = 0.027218244\n",
      "Validation Loss: 0.06805044\n",
      "Epoch: 4357 cost = 0.027194173\n",
      "Validation Loss: 0.050125282\n",
      "Epoch: 4358 cost = 0.027217334\n",
      "Validation Loss: 0.032520417\n",
      "Epoch: 4359 cost = 0.027193323\n",
      "Validation Loss: 0.03251788\n",
      "Epoch: 4360 cost = 0.027216439\n",
      "Validation Loss: 0.029879453\n",
      "Epoch: 4361 cost = 0.027192394\n",
      "Validation Loss: 0.045612875\n",
      "Epoch: 4362 cost = 0.027215575\n",
      "Validation Loss: 0.039856657\n",
      "Epoch: 4363 cost = 0.027191484\n",
      "Validation Loss: 0.036447868\n",
      "Epoch: 4364 cost = 0.027214673\n",
      "Validation Loss: 0.037866503\n",
      "Epoch: 4365 cost = 0.027190610\n",
      "Validation Loss: 0.0317107\n",
      "Epoch: 4366 cost = 0.027213773\n",
      "Validation Loss: 0.03366612\n",
      "Epoch: 4367 cost = 0.027189677\n",
      "Validation Loss: 0.033437103\n",
      "Epoch: 4368 cost = 0.027212900\n",
      "Validation Loss: 0.03378166\n",
      "Epoch: 4369 cost = 0.027188787\n",
      "Validation Loss: 0.035358995\n",
      "Epoch: 4370 cost = 0.027211994\n",
      "Validation Loss: 0.033478383\n",
      "Epoch: 4371 cost = 0.027187873\n",
      "Validation Loss: 0.03125496\n",
      "Epoch: 4372 cost = 0.027211107\n",
      "Validation Loss: 0.03428778\n",
      "Epoch: 4373 cost = 0.027186991\n",
      "Validation Loss: 0.031903032\n",
      "Epoch: 4374 cost = 0.027210219\n",
      "Validation Loss: 0.036258217\n",
      "Epoch: 4375 cost = 0.027186078\n",
      "Validation Loss: 0.038231727\n",
      "Epoch: 4376 cost = 0.027209341\n",
      "Validation Loss: 0.036206357\n",
      "Epoch: 4377 cost = 0.027185178\n",
      "Validation Loss: 0.03458657\n",
      "Epoch: 4378 cost = 0.027208463\n",
      "Validation Loss: 0.032750458\n",
      "Epoch: 4379 cost = 0.027184286\n",
      "Validation Loss: 0.03199421\n",
      "Epoch: 4380 cost = 0.027207543\n",
      "Validation Loss: 0.03477494\n",
      "Epoch: 4381 cost = 0.027183380\n",
      "Validation Loss: 0.04219575\n",
      "Epoch: 4382 cost = 0.027206663\n",
      "Validation Loss: 0.040499866\n",
      "Epoch: 4383 cost = 0.027182456\n",
      "Validation Loss: 0.03681427\n",
      "Epoch: 4384 cost = 0.027205781\n",
      "Validation Loss: 0.034615368\n",
      "Epoch: 4385 cost = 0.027181572\n",
      "Validation Loss: 0.038136456\n",
      "Epoch: 4386 cost = 0.027204861\n",
      "Validation Loss: 0.04262305\n",
      "Epoch: 4387 cost = 0.027180636\n",
      "Validation Loss: 0.041856047\n",
      "Epoch: 4388 cost = 0.027203964\n",
      "Validation Loss: 0.041722436\n",
      "Epoch: 4389 cost = 0.027179733\n",
      "Validation Loss: 0.040389482\n",
      "Epoch: 4390 cost = 0.027203103\n",
      "Validation Loss: 0.039317295\n",
      "Epoch: 4391 cost = 0.027178849\n",
      "Validation Loss: 0.036275093\n",
      "Epoch: 4392 cost = 0.027202201\n",
      "Validation Loss: 0.036746312\n",
      "Epoch: 4393 cost = 0.027177952\n",
      "Validation Loss: 0.046595823\n",
      "Epoch: 4394 cost = 0.027201322\n",
      "Validation Loss: 0.04377398\n",
      "Epoch: 4395 cost = 0.027177050\n",
      "Validation Loss: 0.036913153\n",
      "Epoch: 4396 cost = 0.027200390\n",
      "Validation Loss: 0.033411406\n",
      "Epoch: 4397 cost = 0.027176148\n",
      "Validation Loss: 0.035908148\n",
      "Epoch: 4398 cost = 0.027199505\n",
      "Validation Loss: 0.040518798\n",
      "Epoch: 4399 cost = 0.027175227\n",
      "Validation Loss: 0.059170887\n",
      "Epoch: 4400 cost = 0.027198631\n",
      "Validation Loss: 0.039463364\n",
      "Epoch: 4401 cost = 0.027174323\n",
      "Validation Loss: 0.035263743\n",
      "Epoch: 4402 cost = 0.027197727\n",
      "Validation Loss: 0.041886415\n",
      "Epoch: 4403 cost = 0.027173406\n",
      "Validation Loss: 0.054816566\n",
      "Epoch: 4404 cost = 0.027196825\n",
      "Validation Loss: 0.05547337\n",
      "Epoch: 4405 cost = 0.027172525\n",
      "Validation Loss: 0.05715896\n",
      "Epoch: 4406 cost = 0.027195944\n",
      "Validation Loss: 0.044989426\n",
      "Epoch: 4407 cost = 0.027171622\n",
      "Validation Loss: 0.038744558\n",
      "Epoch: 4408 cost = 0.027195050\n",
      "Validation Loss: 0.037670296\n",
      "Epoch: 4409 cost = 0.027170740\n",
      "Validation Loss: 0.03220787\n",
      "Epoch: 4410 cost = 0.027194170\n",
      "Validation Loss: 0.034244437\n",
      "Epoch: 4411 cost = 0.027169822\n",
      "Validation Loss: 0.037672732\n",
      "Epoch: 4412 cost = 0.027193293\n",
      "Validation Loss: 0.035512865\n",
      "Epoch: 4413 cost = 0.027168909\n",
      "Validation Loss: 0.0379665\n",
      "Epoch: 4414 cost = 0.027192381\n",
      "Validation Loss: 0.048095036\n",
      "Epoch: 4415 cost = 0.027167995\n",
      "Validation Loss: 0.05513891\n",
      "Epoch: 4416 cost = 0.027191511\n",
      "Validation Loss: 0.04085645\n",
      "Epoch: 4417 cost = 0.027167094\n",
      "Validation Loss: 0.03418653\n",
      "Epoch: 4418 cost = 0.027190578\n",
      "Validation Loss: 0.036663767\n",
      "Epoch: 4419 cost = 0.027166186\n",
      "Validation Loss: 0.046313334\n",
      "Epoch: 4420 cost = 0.027189679\n",
      "Validation Loss: 0.03650622\n",
      "Epoch: 4421 cost = 0.027165305\n",
      "Validation Loss: 0.032543894\n",
      "Epoch: 4422 cost = 0.027188807\n",
      "Validation Loss: 0.03354348\n",
      "Epoch: 4423 cost = 0.027164401\n",
      "Validation Loss: 0.033032164\n",
      "Epoch: 4424 cost = 0.027187892\n",
      "Validation Loss: 0.033119675\n",
      "Epoch: 4425 cost = 0.027163467\n",
      "Validation Loss: 0.032997366\n",
      "Epoch: 4426 cost = 0.027187014\n",
      "Validation Loss: 0.036117014\n",
      "Epoch: 4427 cost = 0.027162563\n",
      "Validation Loss: 0.035552785\n",
      "Epoch: 4428 cost = 0.027186128\n",
      "Validation Loss: 0.032484796\n",
      "Epoch: 4429 cost = 0.027161671\n",
      "Validation Loss: 0.033081736\n",
      "Epoch: 4430 cost = 0.027185242\n",
      "Validation Loss: 0.034479488\n",
      "Epoch: 4431 cost = 0.027160762\n",
      "Validation Loss: 0.03725338\n",
      "Epoch: 4432 cost = 0.027184334\n",
      "Validation Loss: 0.03942848\n",
      "Epoch: 4433 cost = 0.027159852\n",
      "Validation Loss: 0.037385754\n",
      "Epoch: 4434 cost = 0.027183434\n",
      "Validation Loss: 0.03541234\n",
      "Epoch: 4435 cost = 0.027158943\n",
      "Validation Loss: 0.03699239\n",
      "Epoch: 4436 cost = 0.027182519\n",
      "Validation Loss: 0.034858875\n",
      "Epoch: 4437 cost = 0.027158034\n",
      "Validation Loss: 0.03702056\n",
      "Epoch: 4438 cost = 0.027181623\n",
      "Validation Loss: 0.03751599\n",
      "Epoch: 4439 cost = 0.027157119\n",
      "Validation Loss: 0.03529468\n",
      "Epoch: 4440 cost = 0.027180748\n",
      "Validation Loss: 0.0385878\n",
      "Epoch: 4441 cost = 0.027156227\n",
      "Validation Loss: 0.034808356\n",
      "Epoch: 4442 cost = 0.027179863\n",
      "Validation Loss: 0.02968097\n",
      "Epoch: 4443 cost = 0.027155330\n",
      "Validation Loss: 0.032313038\n",
      "Epoch: 4444 cost = 0.027178935\n",
      "Validation Loss: 0.031918842\n",
      "Epoch: 4445 cost = 0.027154415\n",
      "Validation Loss: 0.040277287\n",
      "Epoch: 4446 cost = 0.027178054\n",
      "Validation Loss: 0.047211923\n",
      "Epoch: 4447 cost = 0.027153517\n",
      "Validation Loss: 0.04577158\n",
      "Epoch: 4448 cost = 0.027177153\n",
      "Validation Loss: 0.03750448\n",
      "Epoch: 4449 cost = 0.027152612\n",
      "Validation Loss: 0.03847551\n",
      "Epoch: 4450 cost = 0.027176247\n",
      "Validation Loss: 0.04116516\n",
      "Epoch: 4451 cost = 0.027151706\n",
      "Validation Loss: 0.03412032\n",
      "Epoch: 4452 cost = 0.027175355\n",
      "Validation Loss: 0.03392129\n",
      "Epoch: 4453 cost = 0.027150790\n",
      "Validation Loss: 0.033852547\n",
      "Epoch: 4454 cost = 0.027174470\n",
      "Validation Loss: 0.035158068\n",
      "Epoch: 4455 cost = 0.027149890\n",
      "Validation Loss: 0.033714533\n",
      "Epoch: 4456 cost = 0.027173555\n",
      "Validation Loss: 0.038336776\n",
      "Epoch: 4457 cost = 0.027148979\n",
      "Validation Loss: 0.03974645\n",
      "Epoch: 4458 cost = 0.027172647\n",
      "Validation Loss: 0.0365158\n",
      "Epoch: 4459 cost = 0.027148063\n",
      "Validation Loss: 0.032702938\n",
      "Epoch: 4460 cost = 0.027171790\n",
      "Validation Loss: 0.03371351\n",
      "Epoch: 4461 cost = 0.027147191\n",
      "Validation Loss: 0.031940594\n",
      "Epoch: 4462 cost = 0.027170897\n",
      "Validation Loss: 0.035842493\n",
      "Epoch: 4463 cost = 0.027146270\n",
      "Validation Loss: 0.04063986\n",
      "Epoch: 4464 cost = 0.027169976\n",
      "Validation Loss: 0.041934818\n",
      "Epoch: 4465 cost = 0.027145344\n",
      "Validation Loss: 0.05405017\n",
      "Epoch: 4466 cost = 0.027169091\n",
      "Validation Loss: 0.049031977\n",
      "Epoch: 4467 cost = 0.027144423\n",
      "Validation Loss: 0.0501484\n",
      "Epoch: 4468 cost = 0.027168166\n",
      "Validation Loss: 0.03310523\n",
      "Epoch: 4469 cost = 0.027143545\n",
      "Validation Loss: 0.03172991\n",
      "Epoch: 4470 cost = 0.027167215\n",
      "Validation Loss: 0.037825808\n",
      "Epoch: 4471 cost = 0.027142601\n",
      "Validation Loss: 0.0430109\n",
      "Epoch: 4472 cost = 0.027166357\n",
      "Validation Loss: 0.048528712\n",
      "Epoch: 4473 cost = 0.027141688\n",
      "Validation Loss: 0.042897906\n",
      "Epoch: 4474 cost = 0.027165451\n",
      "Validation Loss: 0.049712434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4475 cost = 0.027140766\n",
      "Validation Loss: 0.06467884\n",
      "Epoch: 4476 cost = 0.027164538\n",
      "Validation Loss: 0.054838464\n",
      "Epoch: 4477 cost = 0.027139887\n",
      "Validation Loss: 0.038691737\n",
      "Epoch: 4478 cost = 0.027163636\n",
      "Validation Loss: 0.04701008\n",
      "Epoch: 4479 cost = 0.027138977\n",
      "Validation Loss: 0.03404746\n",
      "Epoch: 4480 cost = 0.027162731\n",
      "Validation Loss: 0.03618025\n",
      "Epoch: 4481 cost = 0.027138057\n",
      "Validation Loss: 0.039401658\n",
      "Epoch: 4482 cost = 0.027161821\n",
      "Validation Loss: 0.039170902\n",
      "Epoch: 4483 cost = 0.027137157\n",
      "Validation Loss: 0.048154756\n",
      "Epoch: 4484 cost = 0.027160931\n",
      "Validation Loss: 0.055598345\n",
      "Epoch: 4485 cost = 0.027136242\n",
      "Validation Loss: 0.050913546\n",
      "Epoch: 4486 cost = 0.027160017\n",
      "Validation Loss: 0.041967027\n",
      "Epoch: 4487 cost = 0.027135347\n",
      "Validation Loss: 0.041016236\n",
      "Epoch: 4488 cost = 0.027159119\n",
      "Validation Loss: 0.043008544\n",
      "Epoch: 4489 cost = 0.027134421\n",
      "Validation Loss: 0.03789891\n",
      "Epoch: 4490 cost = 0.027158251\n",
      "Validation Loss: 0.05261896\n",
      "Epoch: 4491 cost = 0.027133515\n",
      "Validation Loss: 0.04277685\n",
      "Epoch: 4492 cost = 0.027157318\n",
      "Validation Loss: 0.034694698\n",
      "Epoch: 4493 cost = 0.027132614\n",
      "Validation Loss: 0.03208035\n",
      "Epoch: 4494 cost = 0.027156397\n",
      "Validation Loss: 0.03638212\n",
      "Epoch: 4495 cost = 0.027131698\n",
      "Validation Loss: 0.03323455\n",
      "Epoch: 4496 cost = 0.027155500\n",
      "Validation Loss: 0.032038715\n",
      "Epoch: 4497 cost = 0.027130778\n",
      "Validation Loss: 0.029301047\n",
      "Epoch: 4498 cost = 0.027154616\n",
      "Validation Loss: 0.03205365\n",
      "Epoch: 4499 cost = 0.027129889\n",
      "Validation Loss: 0.031061854\n",
      "Epoch: 4500 cost = 0.027153701\n",
      "Validation Loss: 0.03145431\n",
      "Epoch: 4501 cost = 0.027128952\n",
      "Validation Loss: 0.03341157\n",
      "Epoch: 4502 cost = 0.027152784\n",
      "Validation Loss: 0.03264523\n",
      "Epoch: 4503 cost = 0.027128042\n",
      "Validation Loss: 0.032721195\n",
      "Epoch: 4504 cost = 0.027151894\n",
      "Validation Loss: 0.03442345\n",
      "Epoch: 4505 cost = 0.027127129\n",
      "Validation Loss: 0.036589045\n",
      "Epoch: 4506 cost = 0.027150971\n",
      "Validation Loss: 0.046514902\n",
      "Epoch: 4507 cost = 0.027126256\n",
      "Validation Loss: 0.039094504\n",
      "Epoch: 4508 cost = 0.027150070\n",
      "Validation Loss: 0.046448182\n",
      "Epoch: 4509 cost = 0.027125314\n",
      "Validation Loss: 0.04149713\n",
      "Epoch: 4510 cost = 0.027149167\n",
      "Validation Loss: 0.03702405\n",
      "Epoch: 4511 cost = 0.027124418\n",
      "Validation Loss: 0.03654085\n",
      "Epoch: 4512 cost = 0.027148278\n",
      "Validation Loss: 0.047316756\n",
      "Epoch: 4513 cost = 0.027123496\n",
      "Validation Loss: 0.05629116\n",
      "Epoch: 4514 cost = 0.027147367\n",
      "Validation Loss: 0.049644545\n",
      "Epoch: 4515 cost = 0.027122577\n",
      "Validation Loss: 0.039771605\n",
      "Epoch: 4516 cost = 0.027146424\n",
      "Validation Loss: 0.03540822\n",
      "Epoch: 4517 cost = 0.027121686\n",
      "Validation Loss: 0.035970476\n",
      "Epoch: 4518 cost = 0.027145525\n",
      "Validation Loss: 0.03487263\n",
      "Epoch: 4519 cost = 0.027120773\n",
      "Validation Loss: 0.03218571\n",
      "Epoch: 4520 cost = 0.027144622\n",
      "Validation Loss: 0.032446798\n",
      "Epoch: 4521 cost = 0.027119854\n",
      "Validation Loss: 0.036940135\n",
      "Epoch: 4522 cost = 0.027143721\n",
      "Validation Loss: 0.036869098\n",
      "Epoch: 4523 cost = 0.027118955\n",
      "Validation Loss: 0.042321477\n",
      "Epoch: 4524 cost = 0.027142801\n",
      "Validation Loss: 0.03630461\n",
      "Epoch: 4525 cost = 0.027118010\n",
      "Validation Loss: 0.032469817\n",
      "Epoch: 4526 cost = 0.027141888\n",
      "Validation Loss: 0.041607656\n",
      "Epoch: 4527 cost = 0.027117111\n",
      "Validation Loss: 0.034610614\n",
      "Epoch: 4528 cost = 0.027140975\n",
      "Validation Loss: 0.03221049\n",
      "Epoch: 4529 cost = 0.027116192\n",
      "Validation Loss: 0.033661403\n",
      "Epoch: 4530 cost = 0.027140067\n",
      "Validation Loss: 0.041332733\n",
      "Epoch: 4531 cost = 0.027115281\n",
      "Validation Loss: 0.038455833\n",
      "Epoch: 4532 cost = 0.027139165\n",
      "Validation Loss: 0.03579667\n",
      "Epoch: 4533 cost = 0.027114362\n",
      "Validation Loss: 0.03659904\n",
      "Epoch: 4534 cost = 0.027138249\n",
      "Validation Loss: 0.03758001\n",
      "Epoch: 4535 cost = 0.027113471\n",
      "Validation Loss: 0.034639116\n",
      "Epoch: 4536 cost = 0.027137360\n",
      "Validation Loss: 0.03477555\n",
      "Epoch: 4537 cost = 0.027112565\n",
      "Validation Loss: 0.034731247\n",
      "Epoch: 4538 cost = 0.027136460\n",
      "Validation Loss: 0.038666874\n",
      "Epoch: 4539 cost = 0.027111667\n",
      "Validation Loss: 0.034771785\n",
      "Epoch: 4540 cost = 0.027135543\n",
      "Validation Loss: 0.0341129\n",
      "Epoch: 4541 cost = 0.027110719\n",
      "Validation Loss: 0.034992535\n",
      "Epoch: 4542 cost = 0.027134666\n",
      "Validation Loss: 0.03848758\n",
      "Epoch: 4543 cost = 0.027109823\n",
      "Validation Loss: 0.03215685\n",
      "Epoch: 4544 cost = 0.027133731\n",
      "Validation Loss: 0.039047424\n",
      "Epoch: 4545 cost = 0.027108908\n",
      "Validation Loss: 0.047796845\n",
      "Epoch: 4546 cost = 0.027132807\n",
      "Validation Loss: 0.06193672\n",
      "Epoch: 4547 cost = 0.027107973\n",
      "Validation Loss: 0.05709067\n",
      "Epoch: 4548 cost = 0.027131856\n",
      "Validation Loss: 0.043155003\n",
      "Epoch: 4549 cost = 0.027107071\n",
      "Validation Loss: 0.043366555\n",
      "Epoch: 4550 cost = 0.027130958\n",
      "Validation Loss: 0.040009536\n",
      "Epoch: 4551 cost = 0.027106149\n",
      "Validation Loss: 0.03744648\n",
      "Epoch: 4552 cost = 0.027130068\n",
      "Validation Loss: 0.041798364\n",
      "Epoch: 4553 cost = 0.027105240\n",
      "Validation Loss: 0.04200392\n",
      "Epoch: 4554 cost = 0.027129134\n",
      "Validation Loss: 0.037443444\n",
      "Epoch: 4555 cost = 0.027104310\n",
      "Validation Loss: 0.035842746\n",
      "Epoch: 4556 cost = 0.027128228\n",
      "Validation Loss: 0.03649296\n",
      "Epoch: 4557 cost = 0.027103381\n",
      "Validation Loss: 0.030837085\n",
      "Epoch: 4558 cost = 0.027127312\n",
      "Validation Loss: 0.032291144\n",
      "Epoch: 4559 cost = 0.027102483\n",
      "Validation Loss: 0.043470733\n",
      "Epoch: 4560 cost = 0.027126376\n",
      "Validation Loss: 0.040842064\n",
      "Epoch: 4561 cost = 0.027101578\n",
      "Validation Loss: 0.037046786\n",
      "Epoch: 4562 cost = 0.027125450\n",
      "Validation Loss: 0.03508821\n",
      "Epoch: 4563 cost = 0.027100652\n",
      "Validation Loss: 0.033181194\n",
      "Epoch: 4564 cost = 0.027124571\n",
      "Validation Loss: 0.03151316\n",
      "Epoch: 4565 cost = 0.027099746\n",
      "Validation Loss: 0.033461586\n",
      "Epoch: 4566 cost = 0.027123654\n",
      "Validation Loss: 0.04071476\n",
      "Epoch: 4567 cost = 0.027098832\n",
      "Validation Loss: 0.037741102\n",
      "Epoch: 4568 cost = 0.027122729\n",
      "Validation Loss: 0.03100838\n",
      "Epoch: 4569 cost = 0.027097895\n",
      "Validation Loss: 0.031220445\n",
      "Epoch: 4570 cost = 0.027121826\n",
      "Validation Loss: 0.036088414\n",
      "Epoch: 4571 cost = 0.027096998\n",
      "Validation Loss: 0.039876405\n",
      "Epoch: 4572 cost = 0.027120912\n",
      "Validation Loss: 0.05270685\n",
      "Epoch: 4573 cost = 0.027096093\n",
      "Validation Loss: 0.05193585\n",
      "Epoch: 4574 cost = 0.027119997\n",
      "Validation Loss: 0.046276473\n",
      "Epoch: 4575 cost = 0.027095162\n",
      "Validation Loss: 0.030388514\n",
      "Epoch: 4576 cost = 0.027119053\n",
      "Validation Loss: 0.03447487\n",
      "Epoch: 4577 cost = 0.027094232\n",
      "Validation Loss: 0.03150274\n",
      "Epoch: 4578 cost = 0.027118148\n",
      "Validation Loss: 0.032442022\n",
      "Epoch: 4579 cost = 0.027093321\n",
      "Validation Loss: 0.033595767\n",
      "Epoch: 4580 cost = 0.027117217\n",
      "Validation Loss: 0.033284586\n",
      "Epoch: 4581 cost = 0.027092407\n",
      "Validation Loss: 0.03360157\n",
      "Epoch: 4582 cost = 0.027116330\n",
      "Validation Loss: 0.03287653\n",
      "Epoch: 4583 cost = 0.027091491\n",
      "Validation Loss: 0.0331376\n",
      "Epoch: 4584 cost = 0.027115401\n",
      "Validation Loss: 0.033875413\n",
      "Epoch: 4585 cost = 0.027090590\n",
      "Validation Loss: 0.0367016\n",
      "Epoch: 4586 cost = 0.027114466\n",
      "Validation Loss: 0.032300618\n",
      "Epoch: 4587 cost = 0.027089656\n",
      "Validation Loss: 0.03175273\n",
      "Epoch: 4588 cost = 0.027113566\n",
      "Validation Loss: 0.034381267\n",
      "Epoch: 4589 cost = 0.027088751\n",
      "Validation Loss: 0.036747284\n",
      "Epoch: 4590 cost = 0.027112664\n",
      "Validation Loss: 0.038042072\n",
      "Epoch: 4591 cost = 0.027087843\n",
      "Validation Loss: 0.043399177\n",
      "Epoch: 4592 cost = 0.027111724\n",
      "Validation Loss: 0.03377377\n",
      "Epoch: 4593 cost = 0.027086923\n",
      "Validation Loss: 0.033755906\n",
      "Epoch: 4594 cost = 0.027110809\n",
      "Validation Loss: 0.042976562\n",
      "Epoch: 4595 cost = 0.027085980\n",
      "Validation Loss: 0.03905142\n",
      "Epoch: 4596 cost = 0.027109879\n",
      "Validation Loss: 0.051440608\n",
      "Epoch: 4597 cost = 0.027085081\n",
      "Validation Loss: 0.041762624\n",
      "Epoch: 4598 cost = 0.027108977\n",
      "Validation Loss: 0.042117912\n",
      "Epoch: 4599 cost = 0.027084152\n",
      "Validation Loss: 0.035379067\n",
      "Epoch: 4600 cost = 0.027108033\n",
      "Validation Loss: 0.036731936\n",
      "Epoch: 4601 cost = 0.027083238\n",
      "Validation Loss: 0.03176837\n",
      "Epoch: 4602 cost = 0.027107096\n",
      "Validation Loss: 0.031460606\n",
      "Epoch: 4603 cost = 0.027082333\n",
      "Validation Loss: 0.03366715\n",
      "Epoch: 4604 cost = 0.027106162\n",
      "Validation Loss: 0.031529527\n",
      "Epoch: 4605 cost = 0.027081392\n",
      "Validation Loss: 0.033298913\n",
      "Epoch: 4606 cost = 0.027105252\n",
      "Validation Loss: 0.03481126\n",
      "Epoch: 4607 cost = 0.027080475\n",
      "Validation Loss: 0.05117903\n",
      "Epoch: 4608 cost = 0.027104320\n",
      "Validation Loss: 0.06064385\n",
      "Epoch: 4609 cost = 0.027079540\n",
      "Validation Loss: 0.0625596\n",
      "Epoch: 4610 cost = 0.027103395\n",
      "Validation Loss: 0.05781163\n",
      "Epoch: 4611 cost = 0.027078624\n",
      "Validation Loss: 0.053833656\n",
      "Epoch: 4612 cost = 0.027102484\n",
      "Validation Loss: 0.052203577\n",
      "Epoch: 4613 cost = 0.027077730\n",
      "Validation Loss: 0.051685594\n",
      "Epoch: 4614 cost = 0.027101557\n",
      "Validation Loss: 0.03934421\n",
      "Epoch: 4615 cost = 0.027076811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.034784675\n",
      "Epoch: 4616 cost = 0.027100652\n",
      "Validation Loss: 0.03304956\n",
      "Epoch: 4617 cost = 0.027075880\n",
      "Validation Loss: 0.03507794\n",
      "Epoch: 4618 cost = 0.027099742\n",
      "Validation Loss: 0.03247294\n",
      "Epoch: 4619 cost = 0.027074977\n",
      "Validation Loss: 0.034838896\n",
      "Epoch: 4620 cost = 0.027098786\n",
      "Validation Loss: 0.03590319\n",
      "Epoch: 4621 cost = 0.027074046\n",
      "Validation Loss: 0.03290783\n",
      "Epoch: 4622 cost = 0.027097894\n",
      "Validation Loss: 0.031845026\n",
      "Epoch: 4623 cost = 0.027073139\n",
      "Validation Loss: 0.035486847\n",
      "Epoch: 4624 cost = 0.027096985\n",
      "Validation Loss: 0.040572148\n",
      "Epoch: 4625 cost = 0.027072213\n",
      "Validation Loss: 0.037662297\n",
      "Epoch: 4626 cost = 0.027096050\n",
      "Validation Loss: 0.04304114\n",
      "Epoch: 4627 cost = 0.027071261\n",
      "Validation Loss: 0.038860653\n",
      "Epoch: 4628 cost = 0.027095092\n",
      "Validation Loss: 0.0418987\n",
      "Epoch: 4629 cost = 0.027070377\n",
      "Validation Loss: 0.043158136\n",
      "Epoch: 4630 cost = 0.027094180\n",
      "Validation Loss: 0.052445453\n",
      "Epoch: 4631 cost = 0.027069440\n",
      "Validation Loss: 0.05154408\n",
      "Epoch: 4632 cost = 0.027093243\n",
      "Validation Loss: 0.038422324\n",
      "Epoch: 4633 cost = 0.027068536\n",
      "Validation Loss: 0.035403643\n",
      "Epoch: 4634 cost = 0.027092295\n",
      "Validation Loss: 0.034081787\n",
      "Epoch: 4635 cost = 0.027067582\n",
      "Validation Loss: 0.033473525\n",
      "Epoch: 4636 cost = 0.027091377\n",
      "Validation Loss: 0.03380527\n",
      "Epoch: 4637 cost = 0.027066667\n",
      "Validation Loss: 0.037705705\n",
      "Epoch: 4638 cost = 0.027090460\n",
      "Validation Loss: 0.035783984\n",
      "Epoch: 4639 cost = 0.027065780\n",
      "Validation Loss: 0.03768625\n",
      "Epoch: 4640 cost = 0.027089542\n",
      "Validation Loss: 0.036365785\n",
      "Epoch: 4641 cost = 0.027064842\n",
      "Validation Loss: 0.036444638\n",
      "Epoch: 4642 cost = 0.027088622\n",
      "Validation Loss: 0.03597081\n",
      "Epoch: 4643 cost = 0.027063922\n",
      "Validation Loss: 0.036311947\n",
      "Epoch: 4644 cost = 0.027087688\n",
      "Validation Loss: 0.03607019\n",
      "Epoch: 4645 cost = 0.027062993\n",
      "Validation Loss: 0.06461898\n",
      "Epoch: 4646 cost = 0.027086786\n",
      "Validation Loss: 0.09710132\n",
      "Epoch: 4647 cost = 0.027062060\n",
      "Validation Loss: 0.08528128\n",
      "Epoch: 4648 cost = 0.027085847\n",
      "Validation Loss: 0.09890574\n",
      "Epoch: 4649 cost = 0.027061147\n",
      "Validation Loss: 0.06357173\n",
      "Epoch: 4650 cost = 0.027084918\n",
      "Validation Loss: 0.058646172\n",
      "Epoch: 4651 cost = 0.027060220\n",
      "Validation Loss: 0.042360026\n",
      "Epoch: 4652 cost = 0.027083997\n",
      "Validation Loss: 0.03847118\n",
      "Epoch: 4653 cost = 0.027059297\n",
      "Validation Loss: 0.0462769\n",
      "Epoch: 4654 cost = 0.027083045\n",
      "Validation Loss: 0.038344726\n",
      "Epoch: 4655 cost = 0.027058385\n",
      "Validation Loss: 0.037516043\n",
      "Epoch: 4656 cost = 0.027082131\n",
      "Validation Loss: 0.047969602\n",
      "Epoch: 4657 cost = 0.027057455\n",
      "Validation Loss: 0.041812185\n",
      "Epoch: 4658 cost = 0.027081188\n",
      "Validation Loss: 0.043593872\n",
      "Epoch: 4659 cost = 0.027056530\n",
      "Validation Loss: 0.047066297\n",
      "Epoch: 4660 cost = 0.027080234\n",
      "Validation Loss: 0.034598757\n",
      "Epoch: 4661 cost = 0.027055625\n",
      "Validation Loss: 0.037083924\n",
      "Epoch: 4662 cost = 0.027079305\n",
      "Validation Loss: 0.044937994\n",
      "Epoch: 4663 cost = 0.027054679\n",
      "Validation Loss: 0.037909485\n",
      "Epoch: 4664 cost = 0.027078383\n",
      "Validation Loss: 0.03451326\n",
      "Epoch: 4665 cost = 0.027053780\n",
      "Validation Loss: 0.03585631\n",
      "Epoch: 4666 cost = 0.027077477\n",
      "Validation Loss: 0.033327445\n",
      "Epoch: 4667 cost = 0.027052850\n",
      "Validation Loss: 0.034129083\n",
      "Epoch: 4668 cost = 0.027076526\n",
      "Validation Loss: 0.0350088\n",
      "Epoch: 4669 cost = 0.027051929\n",
      "Validation Loss: 0.033721335\n",
      "Epoch: 4670 cost = 0.027075601\n",
      "Validation Loss: 0.030582532\n",
      "Epoch: 4671 cost = 0.027050986\n",
      "Validation Loss: 0.036412906\n",
      "Epoch: 4672 cost = 0.027074635\n",
      "Validation Loss: 0.039591394\n",
      "Epoch: 4673 cost = 0.027050081\n",
      "Validation Loss: 0.053981237\n",
      "Epoch: 4674 cost = 0.027073719\n",
      "Validation Loss: 0.058010563\n",
      "Epoch: 4675 cost = 0.027049156\n",
      "Validation Loss: 0.04788447\n",
      "Epoch: 4676 cost = 0.027072770\n",
      "Validation Loss: 0.042146813\n",
      "Epoch: 4677 cost = 0.027048235\n",
      "Validation Loss: 0.04137878\n",
      "Epoch: 4678 cost = 0.027071841\n",
      "Validation Loss: 0.036512997\n",
      "Epoch: 4679 cost = 0.027047292\n",
      "Validation Loss: 0.036157083\n",
      "Epoch: 4680 cost = 0.027070899\n",
      "Validation Loss: 0.034664594\n",
      "Epoch: 4681 cost = 0.027046380\n",
      "Validation Loss: 0.035103954\n",
      "Epoch: 4682 cost = 0.027069996\n",
      "Validation Loss: 0.033009958\n",
      "Epoch: 4683 cost = 0.027045447\n",
      "Validation Loss: 0.03323557\n",
      "Epoch: 4684 cost = 0.027069101\n",
      "Validation Loss: 0.037414134\n",
      "Epoch: 4685 cost = 0.027044505\n",
      "Validation Loss: 0.035581958\n",
      "Epoch: 4686 cost = 0.027068156\n",
      "Validation Loss: 0.034498464\n",
      "Epoch: 4687 cost = 0.027043599\n",
      "Validation Loss: 0.03395082\n",
      "Epoch: 4688 cost = 0.027067230\n",
      "Validation Loss: 0.032164425\n",
      "Epoch: 4689 cost = 0.027042698\n",
      "Validation Loss: 0.035221305\n",
      "Epoch: 4690 cost = 0.027066250\n",
      "Validation Loss: 0.031925853\n",
      "Epoch: 4691 cost = 0.027041776\n",
      "Validation Loss: 0.030511951\n",
      "Epoch: 4692 cost = 0.027065347\n",
      "Validation Loss: 0.034292016\n",
      "Epoch: 4693 cost = 0.027040831\n",
      "Validation Loss: 0.036239557\n",
      "Epoch: 4694 cost = 0.027064401\n",
      "Validation Loss: 0.035931\n",
      "Epoch: 4695 cost = 0.027039910\n",
      "Validation Loss: 0.03489662\n",
      "Epoch: 4696 cost = 0.027063429\n",
      "Validation Loss: 0.03223548\n",
      "Epoch: 4697 cost = 0.027038978\n",
      "Validation Loss: 0.035901878\n",
      "Epoch: 4698 cost = 0.027062521\n",
      "Validation Loss: 0.03440828\n",
      "Epoch: 4699 cost = 0.027038061\n",
      "Validation Loss: 0.033541042\n",
      "Epoch: 4700 cost = 0.027061594\n",
      "Validation Loss: 0.039537333\n",
      "Epoch: 4701 cost = 0.027037139\n",
      "Validation Loss: 0.046153393\n",
      "Epoch: 4702 cost = 0.027060647\n",
      "Validation Loss: 0.060858842\n",
      "Epoch: 4703 cost = 0.027036199\n",
      "Validation Loss: 0.04792144\n",
      "Epoch: 4704 cost = 0.027059700\n",
      "Validation Loss: 0.036315355\n",
      "Epoch: 4705 cost = 0.027035283\n",
      "Validation Loss: 0.033173826\n",
      "Epoch: 4706 cost = 0.027058788\n",
      "Validation Loss: 0.03331889\n",
      "Epoch: 4707 cost = 0.027034375\n",
      "Validation Loss: 0.040921815\n",
      "Epoch: 4708 cost = 0.027057874\n",
      "Validation Loss: 0.056427706\n",
      "Epoch: 4709 cost = 0.027033422\n",
      "Validation Loss: 0.07282979\n",
      "Epoch: 4710 cost = 0.027056903\n",
      "Validation Loss: 0.06962268\n",
      "Epoch: 4711 cost = 0.027032493\n",
      "Validation Loss: 0.044406626\n",
      "Epoch: 4712 cost = 0.027055986\n",
      "Validation Loss: 0.041396085\n",
      "Epoch: 4713 cost = 0.027031591\n",
      "Validation Loss: 0.04031431\n",
      "Epoch: 4714 cost = 0.027055021\n",
      "Validation Loss: 0.037422236\n",
      "Epoch: 4715 cost = 0.027030640\n",
      "Validation Loss: 0.034203246\n",
      "Epoch: 4716 cost = 0.027054083\n",
      "Validation Loss: 0.034498595\n",
      "Epoch: 4717 cost = 0.027029715\n",
      "Validation Loss: 0.03350154\n",
      "Epoch: 4718 cost = 0.027053160\n",
      "Validation Loss: 0.031035617\n",
      "Epoch: 4719 cost = 0.027028820\n",
      "Validation Loss: 0.032504775\n",
      "Epoch: 4720 cost = 0.027052247\n",
      "Validation Loss: 0.03737187\n",
      "Epoch: 4721 cost = 0.027027891\n",
      "Validation Loss: 0.04748858\n",
      "Epoch: 4722 cost = 0.027051279\n",
      "Validation Loss: 0.049931124\n",
      "Epoch: 4723 cost = 0.027026952\n",
      "Validation Loss: 0.068628505\n",
      "Epoch: 4724 cost = 0.027050319\n",
      "Validation Loss: 0.059826225\n",
      "Epoch: 4725 cost = 0.027026009\n",
      "Validation Loss: 0.04120302\n",
      "Epoch: 4726 cost = 0.027049397\n",
      "Validation Loss: 0.0384806\n",
      "Epoch: 4727 cost = 0.027025082\n",
      "Validation Loss: 0.032993022\n",
      "Epoch: 4728 cost = 0.027048467\n",
      "Validation Loss: 0.03512018\n",
      "Epoch: 4729 cost = 0.027024126\n",
      "Validation Loss: 0.037331764\n",
      "Epoch: 4730 cost = 0.027047530\n",
      "Validation Loss: 0.041438214\n",
      "Epoch: 4731 cost = 0.027023251\n",
      "Validation Loss: 0.03760984\n",
      "Epoch: 4732 cost = 0.027046555\n",
      "Validation Loss: 0.039136704\n",
      "Epoch: 4733 cost = 0.027022291\n",
      "Validation Loss: 0.034251206\n",
      "Epoch: 4734 cost = 0.027045626\n",
      "Validation Loss: 0.03551605\n",
      "Epoch: 4735 cost = 0.027021358\n",
      "Validation Loss: 0.040151156\n",
      "Epoch: 4736 cost = 0.027044700\n",
      "Validation Loss: 0.03795286\n",
      "Epoch: 4737 cost = 0.027020448\n",
      "Validation Loss: 0.043744784\n",
      "Epoch: 4738 cost = 0.027043753\n",
      "Validation Loss: 0.05099257\n",
      "Epoch: 4739 cost = 0.027019506\n",
      "Validation Loss: 0.053066142\n",
      "Epoch: 4740 cost = 0.027042815\n",
      "Validation Loss: 0.04726015\n",
      "Epoch: 4741 cost = 0.027018582\n",
      "Validation Loss: 0.03863662\n",
      "Epoch: 4742 cost = 0.027041856\n",
      "Validation Loss: 0.03470111\n",
      "Epoch: 4743 cost = 0.027017656\n",
      "Validation Loss: 0.033468135\n",
      "Epoch: 4744 cost = 0.027040944\n",
      "Validation Loss: 0.034861807\n",
      "Epoch: 4745 cost = 0.027016725\n",
      "Validation Loss: 0.038533412\n",
      "Epoch: 4746 cost = 0.027040002\n",
      "Validation Loss: 0.03695377\n",
      "Epoch: 4747 cost = 0.027015807\n",
      "Validation Loss: 0.03639713\n",
      "Epoch: 4748 cost = 0.027039052\n",
      "Validation Loss: 0.037811812\n",
      "Epoch: 4749 cost = 0.027014880\n",
      "Validation Loss: 0.043825015\n",
      "Epoch: 4750 cost = 0.027038088\n",
      "Validation Loss: 0.04676305\n",
      "Epoch: 4751 cost = 0.027013951\n",
      "Validation Loss: 0.047472343\n",
      "Epoch: 4752 cost = 0.027037166\n",
      "Validation Loss: 0.048242018\n",
      "Epoch: 4753 cost = 0.027013001\n",
      "Validation Loss: 0.05186746\n",
      "Epoch: 4754 cost = 0.027036222\n",
      "Validation Loss: 0.037766296\n",
      "Epoch: 4755 cost = 0.027012083\n",
      "Validation Loss: 0.035497684\n",
      "Epoch: 4756 cost = 0.027035277\n",
      "Validation Loss: 0.033853848\n",
      "Epoch: 4757 cost = 0.027011165\n",
      "Validation Loss: 0.033271115\n",
      "Epoch: 4758 cost = 0.027034327\n",
      "Validation Loss: 0.032162953\n",
      "Epoch: 4759 cost = 0.027010219\n",
      "Validation Loss: 0.031075152\n",
      "Epoch: 4760 cost = 0.027033371\n",
      "Validation Loss: 0.031898897\n",
      "Epoch: 4761 cost = 0.027009286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.034111086\n",
      "Epoch: 4762 cost = 0.027032437\n",
      "Validation Loss: 0.032841813\n",
      "Epoch: 4763 cost = 0.027008369\n",
      "Validation Loss: 0.035368603\n",
      "Epoch: 4764 cost = 0.027031502\n",
      "Validation Loss: 0.040414646\n",
      "Epoch: 4765 cost = 0.027007427\n",
      "Validation Loss: 0.0455365\n",
      "Epoch: 4766 cost = 0.027030554\n",
      "Validation Loss: 0.05819931\n",
      "Epoch: 4767 cost = 0.027006486\n",
      "Validation Loss: 0.037171252\n",
      "Epoch: 4768 cost = 0.027029605\n",
      "Validation Loss: 0.03422947\n",
      "Epoch: 4769 cost = 0.027005572\n",
      "Validation Loss: 0.035773877\n",
      "Epoch: 4770 cost = 0.027028664\n",
      "Validation Loss: 0.038077746\n",
      "Epoch: 4771 cost = 0.027004641\n",
      "Validation Loss: 0.039864276\n",
      "Epoch: 4772 cost = 0.027027733\n",
      "Validation Loss: 0.038379528\n",
      "Epoch: 4773 cost = 0.027003712\n",
      "Validation Loss: 0.034190428\n",
      "Epoch: 4774 cost = 0.027026780\n",
      "Validation Loss: 0.03256003\n",
      "Epoch: 4775 cost = 0.027002771\n",
      "Validation Loss: 0.03350851\n",
      "Epoch: 4776 cost = 0.027025828\n",
      "Validation Loss: 0.033965163\n",
      "Epoch: 4777 cost = 0.027001868\n",
      "Validation Loss: 0.04096246\n",
      "Epoch: 4778 cost = 0.027024903\n",
      "Validation Loss: 0.03251924\n",
      "Epoch: 4779 cost = 0.027000927\n",
      "Validation Loss: 0.03166355\n",
      "Epoch: 4780 cost = 0.027023963\n",
      "Validation Loss: 0.03087536\n",
      "Epoch: 4781 cost = 0.027000005\n",
      "Validation Loss: 0.035380363\n",
      "Epoch: 4782 cost = 0.027022993\n",
      "Validation Loss: 0.03287057\n",
      "Epoch: 4783 cost = 0.026999075\n",
      "Validation Loss: 0.033850063\n",
      "Epoch: 4784 cost = 0.027022047\n",
      "Validation Loss: 0.04828463\n",
      "Epoch: 4785 cost = 0.026998132\n",
      "Validation Loss: 0.053138457\n",
      "Epoch: 4786 cost = 0.027021109\n",
      "Validation Loss: 0.054993436\n",
      "Epoch: 4787 cost = 0.026997208\n",
      "Validation Loss: 0.056941573\n",
      "Epoch: 4788 cost = 0.027020155\n",
      "Validation Loss: 0.058777474\n",
      "Epoch: 4789 cost = 0.026996272\n",
      "Validation Loss: 0.07301169\n",
      "Epoch: 4790 cost = 0.027019248\n",
      "Validation Loss: 0.050126474\n",
      "Epoch: 4791 cost = 0.026995335\n",
      "Validation Loss: 0.038539056\n",
      "Epoch: 4792 cost = 0.027018289\n",
      "Validation Loss: 0.03538586\n",
      "Epoch: 4793 cost = 0.026994414\n",
      "Validation Loss: 0.040856626\n",
      "Epoch: 4794 cost = 0.027017325\n",
      "Validation Loss: 0.037986457\n",
      "Epoch: 4795 cost = 0.026993483\n",
      "Validation Loss: 0.052849345\n",
      "Epoch: 4796 cost = 0.027016397\n",
      "Validation Loss: 0.06923903\n",
      "Epoch: 4797 cost = 0.026992559\n",
      "Validation Loss: 0.0468068\n",
      "Epoch: 4798 cost = 0.027015426\n",
      "Validation Loss: 0.03971213\n",
      "Epoch: 4799 cost = 0.026991614\n",
      "Validation Loss: 0.0346077\n",
      "Epoch: 4800 cost = 0.027014475\n",
      "Validation Loss: 0.033247244\n",
      "Epoch: 4801 cost = 0.026990679\n",
      "Validation Loss: 0.034031432\n",
      "Epoch: 4802 cost = 0.027013516\n",
      "Validation Loss: 0.038179368\n",
      "Epoch: 4803 cost = 0.026989762\n",
      "Validation Loss: 0.04180013\n",
      "Epoch: 4804 cost = 0.027012575\n",
      "Validation Loss: 0.033296492\n",
      "Epoch: 4805 cost = 0.026988817\n",
      "Validation Loss: 0.03225041\n",
      "Epoch: 4806 cost = 0.027011622\n",
      "Validation Loss: 0.037871297\n",
      "Epoch: 4807 cost = 0.026987862\n",
      "Validation Loss: 0.040130455\n",
      "Epoch: 4808 cost = 0.027010689\n",
      "Validation Loss: 0.04244463\n",
      "Epoch: 4809 cost = 0.026986924\n",
      "Validation Loss: 0.03944636\n",
      "Epoch: 4810 cost = 0.027009737\n",
      "Validation Loss: 0.037760116\n",
      "Epoch: 4811 cost = 0.026986017\n",
      "Validation Loss: 0.035162117\n",
      "Epoch: 4812 cost = 0.027008779\n",
      "Validation Loss: 0.03582935\n",
      "Epoch: 4813 cost = 0.026985080\n",
      "Validation Loss: 0.032552853\n",
      "Epoch: 4814 cost = 0.027007821\n",
      "Validation Loss: 0.03222414\n",
      "Epoch: 4815 cost = 0.026984159\n",
      "Validation Loss: 0.03531355\n",
      "Epoch: 4816 cost = 0.027006866\n",
      "Validation Loss: 0.033430092\n",
      "Epoch: 4817 cost = 0.026983233\n",
      "Validation Loss: 0.032585952\n",
      "Epoch: 4818 cost = 0.027005949\n",
      "Validation Loss: 0.037584405\n",
      "Epoch: 4819 cost = 0.026982317\n",
      "Validation Loss: 0.03614654\n",
      "Epoch: 4820 cost = 0.027005009\n",
      "Validation Loss: 0.06376506\n",
      "Epoch: 4821 cost = 0.026981359\n",
      "Validation Loss: 0.060444344\n",
      "Epoch: 4822 cost = 0.027004065\n",
      "Validation Loss: 0.0462241\n",
      "Epoch: 4823 cost = 0.026980435\n",
      "Validation Loss: 0.036647897\n",
      "Epoch: 4824 cost = 0.027003113\n",
      "Validation Loss: 0.029154375\n",
      "Epoch: 4825 cost = 0.026979520\n",
      "Validation Loss: 0.03066627\n",
      "Epoch: 4826 cost = 0.027002145\n",
      "Validation Loss: 0.030984893\n",
      "Epoch: 4827 cost = 0.026978576\n",
      "Validation Loss: 0.03309316\n",
      "Epoch: 4828 cost = 0.027001181\n",
      "Validation Loss: 0.048141774\n",
      "Epoch: 4829 cost = 0.026977628\n",
      "Validation Loss: 0.04356088\n",
      "Epoch: 4830 cost = 0.027000228\n",
      "Validation Loss: 0.041514777\n",
      "Epoch: 4831 cost = 0.026976717\n",
      "Validation Loss: 0.038357433\n",
      "Epoch: 4832 cost = 0.026999294\n",
      "Validation Loss: 0.042037986\n",
      "Epoch: 4833 cost = 0.026975767\n",
      "Validation Loss: 0.036350064\n",
      "Epoch: 4834 cost = 0.026998334\n",
      "Validation Loss: 0.046494223\n",
      "Epoch: 4835 cost = 0.026974827\n",
      "Validation Loss: 0.052240636\n",
      "Epoch: 4836 cost = 0.026997393\n",
      "Validation Loss: 0.061089035\n",
      "Epoch: 4837 cost = 0.026973869\n",
      "Validation Loss: 0.060732525\n",
      "Epoch: 4838 cost = 0.026996434\n",
      "Validation Loss: 0.041257225\n",
      "Epoch: 4839 cost = 0.026972943\n",
      "Validation Loss: 0.033518113\n",
      "Epoch: 4840 cost = 0.026995500\n",
      "Validation Loss: 0.03295455\n",
      "Epoch: 4841 cost = 0.026972021\n",
      "Validation Loss: 0.031836763\n",
      "Epoch: 4842 cost = 0.026994547\n",
      "Validation Loss: 0.033598825\n",
      "Epoch: 4843 cost = 0.026971080\n",
      "Validation Loss: 0.03187828\n",
      "Epoch: 4844 cost = 0.026993604\n",
      "Validation Loss: 0.03138378\n",
      "Epoch: 4845 cost = 0.026970150\n",
      "Validation Loss: 0.03499818\n",
      "Epoch: 4846 cost = 0.026992661\n",
      "Validation Loss: 0.04493559\n",
      "Epoch: 4847 cost = 0.026969238\n",
      "Validation Loss: 0.047260247\n",
      "Epoch: 4848 cost = 0.026991717\n",
      "Validation Loss: 0.041181874\n",
      "Epoch: 4849 cost = 0.026968306\n",
      "Validation Loss: 0.044511035\n",
      "Epoch: 4850 cost = 0.026990739\n",
      "Validation Loss: 0.03666139\n",
      "Epoch: 4851 cost = 0.026967375\n",
      "Validation Loss: 0.041672688\n",
      "Epoch: 4852 cost = 0.026989800\n",
      "Validation Loss: 0.040318865\n",
      "Epoch: 4853 cost = 0.026966444\n",
      "Validation Loss: 0.035743304\n",
      "Epoch: 4854 cost = 0.026988837\n",
      "Validation Loss: 0.034428798\n",
      "Epoch: 4855 cost = 0.026965504\n",
      "Validation Loss: 0.035997804\n",
      "Epoch: 4856 cost = 0.026987902\n",
      "Validation Loss: 0.037539147\n",
      "Epoch: 4857 cost = 0.026964562\n",
      "Validation Loss: 0.049726993\n",
      "Epoch: 4858 cost = 0.026986940\n",
      "Validation Loss: 0.06827538\n",
      "Epoch: 4859 cost = 0.026963621\n",
      "Validation Loss: 0.04810277\n",
      "Epoch: 4860 cost = 0.026985970\n",
      "Validation Loss: 0.039578576\n",
      "Epoch: 4861 cost = 0.026962709\n",
      "Validation Loss: 0.03416683\n",
      "Epoch: 4862 cost = 0.026985009\n",
      "Validation Loss: 0.039338347\n",
      "Epoch: 4863 cost = 0.026961777\n",
      "Validation Loss: 0.037392013\n",
      "Epoch: 4864 cost = 0.026984087\n",
      "Validation Loss: 0.038488116\n",
      "Epoch: 4865 cost = 0.026960826\n",
      "Validation Loss: 0.030393016\n",
      "Epoch: 4866 cost = 0.026983130\n",
      "Validation Loss: 0.032438647\n",
      "Epoch: 4867 cost = 0.026959892\n",
      "Validation Loss: 0.031070037\n",
      "Epoch: 4868 cost = 0.026982175\n",
      "Validation Loss: 0.029327685\n",
      "Epoch: 4869 cost = 0.026958969\n",
      "Validation Loss: 0.0342218\n",
      "Epoch: 4870 cost = 0.026981219\n",
      "Validation Loss: 0.04257495\n",
      "Epoch: 4871 cost = 0.026958007\n",
      "Validation Loss: 0.041019157\n",
      "Epoch: 4872 cost = 0.026980268\n",
      "Validation Loss: 0.047640193\n",
      "Epoch: 4873 cost = 0.026957111\n",
      "Validation Loss: 0.05620948\n",
      "Epoch: 4874 cost = 0.026979303\n",
      "Validation Loss: 0.03959735\n",
      "Epoch: 4875 cost = 0.026956138\n",
      "Validation Loss: 0.030437764\n",
      "Epoch: 4876 cost = 0.026978339\n",
      "Validation Loss: 0.03609843\n",
      "Epoch: 4877 cost = 0.026955221\n",
      "Validation Loss: 0.033762835\n",
      "Epoch: 4878 cost = 0.026977403\n",
      "Validation Loss: 0.0346116\n",
      "Epoch: 4879 cost = 0.026954287\n",
      "Validation Loss: 0.034081157\n",
      "Epoch: 4880 cost = 0.026976466\n",
      "Validation Loss: 0.033248622\n",
      "Epoch: 4881 cost = 0.026953341\n",
      "Validation Loss: 0.03274469\n",
      "Epoch: 4882 cost = 0.026975511\n",
      "Validation Loss: 0.033726476\n",
      "Epoch: 4883 cost = 0.026952426\n",
      "Validation Loss: 0.030903697\n",
      "Epoch: 4884 cost = 0.026974557\n",
      "Validation Loss: 0.033276502\n",
      "Epoch: 4885 cost = 0.026951472\n",
      "Validation Loss: 0.036313985\n",
      "Epoch: 4886 cost = 0.026973563\n",
      "Validation Loss: 0.035878226\n",
      "Epoch: 4887 cost = 0.026950557\n",
      "Validation Loss: 0.04172416\n",
      "Epoch: 4888 cost = 0.026972613\n",
      "Validation Loss: 0.037003607\n",
      "Epoch: 4889 cost = 0.026949602\n",
      "Validation Loss: 0.037690226\n",
      "Epoch: 4890 cost = 0.026971671\n",
      "Validation Loss: 0.039762925\n",
      "Epoch: 4891 cost = 0.026948676\n",
      "Validation Loss: 0.037505563\n",
      "Epoch: 4892 cost = 0.026970736\n",
      "Validation Loss: 0.043305628\n",
      "Epoch: 4893 cost = 0.026947738\n",
      "Validation Loss: 0.046184007\n",
      "Epoch: 4894 cost = 0.026969780\n",
      "Validation Loss: 0.044781435\n",
      "Epoch: 4895 cost = 0.026946801\n",
      "Validation Loss: 0.035393137\n",
      "Epoch: 4896 cost = 0.026968838\n",
      "Validation Loss: 0.033122405\n",
      "Epoch: 4897 cost = 0.026945876\n",
      "Validation Loss: 0.031897202\n",
      "Epoch: 4898 cost = 0.026967866\n",
      "Validation Loss: 0.03206485\n",
      "Epoch: 4899 cost = 0.026944916\n",
      "Validation Loss: 0.030940209\n",
      "Epoch: 4900 cost = 0.026966883\n",
      "Validation Loss: 0.03520971\n",
      "Epoch: 4901 cost = 0.026944014\n",
      "Validation Loss: 0.028756049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4902 cost = 0.026965944\n",
      "Validation Loss: 0.058535747\n",
      "Epoch: 4903 cost = 0.026943062\n",
      "Validation Loss: 0.0503084\n",
      "Epoch: 4904 cost = 0.026964994\n",
      "Validation Loss: 0.052752748\n",
      "Epoch: 4905 cost = 0.026942111\n",
      "Validation Loss: 0.05699885\n",
      "Epoch: 4906 cost = 0.026964036\n",
      "Validation Loss: 0.051991835\n",
      "Epoch: 4907 cost = 0.026941165\n",
      "Validation Loss: 0.035065286\n",
      "Epoch: 4908 cost = 0.026963084\n",
      "Validation Loss: 0.03611215\n",
      "Epoch: 4909 cost = 0.026940247\n",
      "Validation Loss: 0.03281773\n",
      "Epoch: 4910 cost = 0.026962123\n",
      "Validation Loss: 0.03319149\n",
      "Epoch: 4911 cost = 0.026939317\n",
      "Validation Loss: 0.032024905\n",
      "Epoch: 4912 cost = 0.026961170\n",
      "Validation Loss: 0.032501057\n",
      "Epoch: 4913 cost = 0.026938375\n",
      "Validation Loss: 0.028945163\n",
      "Epoch: 4914 cost = 0.026960224\n",
      "Validation Loss: 0.035684045\n",
      "Epoch: 4915 cost = 0.026937435\n",
      "Validation Loss: 0.045241944\n",
      "Epoch: 4916 cost = 0.026959290\n",
      "Validation Loss: 0.044549577\n",
      "Epoch: 4917 cost = 0.026936490\n",
      "Validation Loss: 0.038008273\n",
      "Epoch: 4918 cost = 0.026958308\n",
      "Validation Loss: 0.03697517\n",
      "Epoch: 4919 cost = 0.026935551\n",
      "Validation Loss: 0.03471332\n",
      "Epoch: 4920 cost = 0.026957349\n",
      "Validation Loss: 0.035169024\n",
      "Epoch: 4921 cost = 0.026934610\n",
      "Validation Loss: 0.036561064\n",
      "Epoch: 4922 cost = 0.026956395\n",
      "Validation Loss: 0.037816215\n",
      "Epoch: 4923 cost = 0.026933668\n",
      "Validation Loss: 0.03243996\n",
      "Epoch: 4924 cost = 0.026955432\n",
      "Validation Loss: 0.032303825\n",
      "Epoch: 4925 cost = 0.026932749\n",
      "Validation Loss: 0.03239278\n",
      "Epoch: 4926 cost = 0.026954470\n",
      "Validation Loss: 0.030330842\n",
      "Epoch: 4927 cost = 0.026931814\n",
      "Validation Loss: 0.030294418\n",
      "Epoch: 4928 cost = 0.026953529\n",
      "Validation Loss: 0.02991409\n",
      "Epoch: 4929 cost = 0.026930911\n",
      "Validation Loss: 0.035628375\n",
      "Epoch: 4930 cost = 0.026952563\n",
      "Validation Loss: 0.03295591\n",
      "Epoch: 4931 cost = 0.026929964\n",
      "Validation Loss: 0.031123647\n",
      "Epoch: 4932 cost = 0.026951630\n",
      "Validation Loss: 0.032951258\n",
      "Epoch: 4933 cost = 0.026929029\n",
      "Validation Loss: 0.037319742\n",
      "Epoch: 4934 cost = 0.026950682\n",
      "Validation Loss: 0.05070279\n",
      "Epoch: 4935 cost = 0.026928078\n",
      "Validation Loss: 0.066497274\n",
      "Epoch: 4936 cost = 0.026949747\n",
      "Validation Loss: 0.06722534\n",
      "Epoch: 4937 cost = 0.026927137\n",
      "Validation Loss: 0.051416893\n",
      "Epoch: 4938 cost = 0.026948751\n",
      "Validation Loss: 0.040948212\n",
      "Epoch: 4939 cost = 0.026926193\n",
      "Validation Loss: 0.03215572\n",
      "Epoch: 4940 cost = 0.026947797\n",
      "Validation Loss: 0.03417524\n",
      "Epoch: 4941 cost = 0.026925263\n",
      "Validation Loss: 0.03919151\n",
      "Epoch: 4942 cost = 0.026946833\n",
      "Validation Loss: 0.04475338\n",
      "Epoch: 4943 cost = 0.026924317\n",
      "Validation Loss: 0.045656186\n",
      "Epoch: 4944 cost = 0.026945888\n",
      "Validation Loss: 0.04490467\n",
      "Epoch: 4945 cost = 0.026923391\n",
      "Validation Loss: 0.037172567\n",
      "Epoch: 4946 cost = 0.026944936\n",
      "Validation Loss: 0.038026795\n",
      "Epoch: 4947 cost = 0.026922443\n",
      "Validation Loss: 0.039773572\n",
      "Epoch: 4948 cost = 0.026943980\n",
      "Validation Loss: 0.03822163\n",
      "Epoch: 4949 cost = 0.026921502\n",
      "Validation Loss: 0.03320166\n",
      "Epoch: 4950 cost = 0.026942991\n",
      "Validation Loss: 0.03162408\n",
      "Epoch: 4951 cost = 0.026920545\n",
      "Validation Loss: 0.030292977\n",
      "Epoch: 4952 cost = 0.026942066\n",
      "Validation Loss: 0.03213319\n",
      "Epoch: 4953 cost = 0.026919626\n",
      "Validation Loss: 0.03144967\n",
      "Epoch: 4954 cost = 0.026941108\n",
      "Validation Loss: 0.03638647\n",
      "Epoch: 4955 cost = 0.026918693\n",
      "Validation Loss: 0.036678143\n",
      "Epoch: 4956 cost = 0.026940126\n",
      "Validation Loss: 0.036216974\n",
      "Epoch: 4957 cost = 0.026917760\n",
      "Validation Loss: 0.031248426\n",
      "Epoch: 4958 cost = 0.026939132\n",
      "Validation Loss: 0.031820808\n",
      "Epoch: 4959 cost = 0.026916807\n",
      "Validation Loss: 0.03460465\n",
      "Epoch: 4960 cost = 0.026938221\n",
      "Validation Loss: 0.033268742\n",
      "Epoch: 4961 cost = 0.026915886\n",
      "Validation Loss: 0.03450616\n",
      "Epoch: 4962 cost = 0.026937244\n",
      "Validation Loss: 0.034609422\n",
      "Epoch: 4963 cost = 0.026914935\n",
      "Validation Loss: 0.03540823\n",
      "Epoch: 4964 cost = 0.026936289\n",
      "Validation Loss: 0.03613782\n",
      "Epoch: 4965 cost = 0.026913982\n",
      "Validation Loss: 0.041965906\n",
      "Epoch: 4966 cost = 0.026935317\n",
      "Validation Loss: 0.044895235\n",
      "Epoch: 4967 cost = 0.026913060\n",
      "Validation Loss: 0.033981476\n",
      "Epoch: 4968 cost = 0.026934381\n",
      "Validation Loss: 0.034503736\n",
      "Epoch: 4969 cost = 0.026912113\n",
      "Validation Loss: 0.035506204\n",
      "Epoch: 4970 cost = 0.026933416\n",
      "Validation Loss: 0.03598686\n",
      "Epoch: 4971 cost = 0.026911181\n",
      "Validation Loss: 0.033209585\n",
      "Epoch: 4972 cost = 0.026932466\n",
      "Validation Loss: 0.033042945\n",
      "Epoch: 4973 cost = 0.026910249\n",
      "Validation Loss: 0.033613857\n",
      "Epoch: 4974 cost = 0.026931509\n",
      "Validation Loss: 0.03571329\n",
      "Epoch: 4975 cost = 0.026909320\n",
      "Validation Loss: 0.0331986\n",
      "Epoch: 4976 cost = 0.026930591\n",
      "Validation Loss: 0.037863262\n",
      "Epoch: 4977 cost = 0.026908391\n",
      "Validation Loss: 0.035370044\n",
      "Epoch: 4978 cost = 0.026929602\n",
      "Validation Loss: 0.05535875\n",
      "Epoch: 4979 cost = 0.026907443\n",
      "Validation Loss: 0.045135263\n",
      "Epoch: 4980 cost = 0.026928653\n",
      "Validation Loss: 0.03325188\n",
      "Epoch: 4981 cost = 0.026906520\n",
      "Validation Loss: 0.036037207\n",
      "Epoch: 4982 cost = 0.026927675\n",
      "Validation Loss: 0.033349242\n",
      "Epoch: 4983 cost = 0.026905573\n",
      "Validation Loss: 0.034960758\n",
      "Epoch: 4984 cost = 0.026926718\n",
      "Validation Loss: 0.03282895\n",
      "Epoch: 4985 cost = 0.026904630\n",
      "Validation Loss: 0.031511407\n",
      "Epoch: 4986 cost = 0.026925771\n",
      "Validation Loss: 0.03918259\n",
      "Epoch: 4987 cost = 0.026903694\n",
      "Validation Loss: 0.033668593\n",
      "Epoch: 4988 cost = 0.026924804\n",
      "Validation Loss: 0.03735328\n",
      "Epoch: 4989 cost = 0.026902744\n",
      "Validation Loss: 0.046994187\n",
      "Epoch: 4990 cost = 0.026923863\n",
      "Validation Loss: 0.04993724\n",
      "Epoch: 4991 cost = 0.026901788\n",
      "Validation Loss: 0.046625275\n",
      "Epoch: 4992 cost = 0.026922911\n",
      "Validation Loss: 0.032730855\n",
      "Epoch: 4993 cost = 0.026900882\n",
      "Validation Loss: 0.034452543\n",
      "Epoch: 4994 cost = 0.026921949\n",
      "Validation Loss: 0.033399105\n",
      "Epoch: 4995 cost = 0.026899933\n",
      "Validation Loss: 0.03267206\n",
      "Epoch: 4996 cost = 0.026920958\n",
      "Validation Loss: 0.030905437\n",
      "Epoch: 4997 cost = 0.026898979\n",
      "Validation Loss: 0.03221417\n",
      "Epoch: 4998 cost = 0.026920008\n",
      "Validation Loss: 0.03025655\n",
      "Epoch: 4999 cost = 0.026898066\n",
      "Validation Loss: 0.03257418\n",
      "Epoch: 5000 cost = 0.026919058\n",
      "Validation Loss: 0.04438989\n",
      "Optimization Finished!\n",
      "Test Loss: 0.039128814\n"
     ]
    }
   ],
   "source": [
    "#we store the variables here\n",
    "log_files_path = 'C:/Users/yy2895/Desktop/st19-14-19/tmp/model.ckpt'\n",
    "def layer_batch_normalization(x, n_out, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - n_out: integer, depth of input maps - number of sample in the batch \n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - batch-normalized maps   \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    beta_init = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_init)\n",
    "    \n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_init)\n",
    "\n",
    "    #tf.nn.moment: https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "    #calculate mean and variance of x\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "    \n",
    "    #tf.train.ExponentialMovingAverage:\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
    "    #Maintains moving averages of variables by employing an exponential decay.\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    \n",
    "    def mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "        \n",
    "    #tf.cond: https://www.tensorflow.org/api_docs/python/tf/cond\n",
    "    #Return true_fn() if the predicate pred is true else false_fn()\n",
    "    mean, var = tf.cond(phase_train, mean_var_with_update, lambda: (ema_mean, ema_var))\n",
    "    \n",
    "    \n",
    "    #Here, we changesd the shape of x into [[[x1]],[[x2] ],....]\n",
    "\n",
    "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var, beta, gamma, 1e-3, True)\n",
    "    \n",
    "    return tf.reshape(normed, [-1, n_out])\n",
    "\n",
    "def layer(x, weight_shape, bias_shape, phase_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape the the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize weights\n",
    "    weight_init = tf.random_normal_initializer(stddev=(1.0/weight_shape[0])**0.5)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    \n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "\n",
    "    logits = tf.matmul(x, W) + b\n",
    "    \n",
    "    #apply the non-linear function after the batch normalization\n",
    "    return tf.nn.sigmoid(layer_batch_normalization(logits, weight_shape[1], phase_train))\n",
    "def encoder(x, n_code, phase_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the network encoder part\n",
    "    input:\n",
    "        - x: input vector of the encoder\n",
    "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder)\n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector: reduced dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope(\"code\"):\n",
    "            output = layer(x, [19, n_code], [n_code], phase_train)\n",
    "\n",
    "\n",
    "    return output\n",
    "\n",
    "def decoder(x, n_code, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network encoder part\n",
    "    input:\n",
    "        - x: input vector of the decoder - reduced dimension vector\n",
    "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder) \n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector: reconstructed dimension of the initial vector\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        \n",
    "   \n",
    "        with tf.variable_scope(\"output\"):\n",
    "            output = layer(x, [ n_code, 19], [19], phase_train)\n",
    "\n",
    "    return output\n",
    "def loss(output, x):\n",
    "    \"\"\"\n",
    "    Compute the loss of the auto-encoder\n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the decoder\n",
    "        - x: true value of the sample batch - this is the input of the encoder\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"training\"):\n",
    "        \n",
    "        l2 = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x)), 1))\n",
    "        train_loss = tf.reduce_mean(l2)\n",
    "        train_summary_op = tf.summary.scalar(\"train_cost\", train_loss)\n",
    "        return train_loss, train_summary_op\n",
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op\n",
    "def evaluate(output, x):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        -output: prediction vector of the network for the validation set\n",
    "        -x: true value for the validation set\n",
    "    output:\n",
    "        - val_loss: loss of the autoencoder\n",
    "        - in_image_op: input image \n",
    "        - out_image_op:reconstructed image \n",
    "        - val_summary_op: summary of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"validation\"):\n",
    "        \n",
    "        #in_image_op = image_summary(\"input_image\", x)\n",
    "        \n",
    "        #out_image_op = image_summary(\"output_image\", output)\n",
    "        \n",
    "        l2_norm = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x, name=\"val_diff\")), 1))\n",
    "        \n",
    "        val_loss = tf.reduce_mean(l2_norm)\n",
    "        \n",
    "        val_summary_op = tf.summary.scalar(\"val_cost\", val_loss)\n",
    "        \n",
    "        #return val_loss, in_image_op, out_image_op, val_summary_op\n",
    "        return val_loss,  val_summary_op\n",
    "\"\"\"\n",
    "def image_summary(label, tensor):\n",
    "    #tf.summary.image: https://www.tensorflow.org/api_docs/python/tf/summary/image\n",
    "    #Outputs a Summary protocol buffer with images.\n",
    "\n",
    "    tensor_reshaped = tf.reshape(tensor, [-1, 19, 1, 1])\n",
    "    return tf.summary.image(label, tensor_reshaped)\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    print('we begin')\n",
    "\n",
    "    #if a python file, please use the 4 lines bellow and comment the \"n_code = '2'\"\n",
    "    #parser = argparse.ArgumentParser(description='Autoencoder')\n",
    "    #parser.add_argument('n_code', nargs=1, type=str)\n",
    "    #args = parser.parse_args(['--help'])\n",
    "    #n_code = args.n_code[0]\n",
    "    \n",
    "    #if a jupyter file, please comment the 4 above and use the one bellow\n",
    "    n_code = '14'\n",
    "    \n",
    "    #feel free to change with your own \n",
    "    #log_files_path = r'C:\\Users\\yy2895\\Desktop\\pys'\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.variable_scope(\"autoencoder_model\"):\n",
    "\n",
    "            #the input variables are first define as placeholder \n",
    "            # a placeholder is a variable/data which will be assigned later \n",
    "            # image vector & label, phase_train is a boolean \n",
    "            x = tf.placeholder(\"float\", [None, 19]) # MNIST data image of shape 28*28=784\n",
    "            \n",
    "            phase_train = tf.placeholder(tf.bool)\n",
    "            \n",
    "            #define the encoder \n",
    "            code = encoder(x, int(n_code), phase_train)\n",
    "            \n",
    "            #define the decoder\n",
    "            output = decoder(code, int(n_code), phase_train)\n",
    "            \n",
    "            #compute the loss \n",
    "            cost, train_summary_op = loss(output, x)\n",
    "\n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "            train_op = training(cost, global_step)\n",
    "\n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            #eval_op, in_image_op, out_image_op, val_summary_op = evaluate(output, x)\n",
    "            eval_op, val_summary_op = evaluate(output, x)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "\n",
    "            #save and restore variables to and from checkpoints.\n",
    "            #saver = tf.train.Saver(max_to_keep=200)\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "\n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            #train_writer = tf.summary.FileWriter(log_files_path+'mnist_autoencoder_hidden_' + n_code + '_logs/', graph=sess.graph)\n",
    "\n",
    "            #val_writer   = tf.summary.FileWriter(log_files_path+'mnist_autoencoder_hidden_' + n_code + '_logs/', graph=sess.graph)\n",
    "\n",
    "            #initialization of the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "\n",
    "            sess.run(init_op)\n",
    "            currentmin=10000000000\n",
    "            currentmin_index=-1\n",
    "            error_path=[]\n",
    "            togive1=[]\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                #total_batch = int(numberofsamples/batch_size)\n",
    "                \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "                    \n",
    "                    minibatch_x= trainset[i]\n",
    "                    \n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    _, new_cost, train_summary = sess.run([train_op, cost, train_summary_op], feed_dict={x: minibatch_x, phase_train: True})\n",
    "                    \n",
    "                    #train_writer.add_summary(train_summary, sess.run(global_step))\n",
    "                    \n",
    "                    # Compute average loss\n",
    "                    avg_cost += new_cost/total_batch\n",
    "                    \n",
    "                \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:0.9f}\".format(avg_cost))\n",
    "\n",
    "                    #the accuracy is evaluated using the validation dataset\n",
    "                    #train_writer.add_summary(train_summary, sess.run(global_step))\n",
    "\n",
    "                    #validation_loss, in_image, out_image, val_summary = sess.run([eval_op, in_image_op, out_image_op, val_summary_op], feed_dict={x: validationset, phase_train: False})\n",
    "                    validation_loss,  val_summary = sess.run([eval_op, val_summary_op], feed_dict={x: validationset, phase_train: False})\n",
    "                    #val_writer.add_summary(in_image, sess.run(global_step))\n",
    "                    #val_writer.add_summary(out_image, sess.run(global_step))\n",
    "                    val_writer.add_summary(val_summary, sess.run(global_step))\n",
    "                    print(\"Validation Loss:\", validation_loss)\n",
    "                    error_path.append(validation_loss)\n",
    "                    \n",
    "                    if validation_loss<currentmin:\n",
    "                        currentmin=validation_loss\n",
    "                        currentmin_index=epoch\n",
    "                        saver.save(sess, 'C:/Users/yy2895/Desktop/st19-14-19/tmp/model.ckpt')\n",
    "                        togive7=[]\n",
    "                        for i in range(len(d)):\n",
    "                            any_image = d[i].reshape(-1,19)\n",
    "                            output_any_image = sess.run(code,feed_dict={x:any_image,phase_train: False})\n",
    "                            togive7.append(output_any_image)\n",
    "                            \n",
    "                        togive1=togive7\n",
    "                    #save to use later\n",
    "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "                    #saver.save(sess, 'C:/Users/yy2895/Desktop/st19-14-19/tmp/model.ckpt')\n",
    "                    \n",
    "\n",
    "            print(\"Optimization Finished!\")\n",
    "\n",
    "            test_loss = sess.run(eval_op, feed_dict={x: testset, phase_train: False})\n",
    "            #nps_loss = sess.run(eval_op, feed_dict={x: mnist.validation.images, phase_train: False})\n",
    "            print(\"Test Loss:\", test_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028756049"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.25204715, 0.80150497, 0.02951745, 0.10669305, 0.10169823,\n",
       "         0.02269761, 0.29088235, 0.14584139, 0.708738  , 0.61218274,\n",
       "         0.1941818 , 0.01269354, 0.1751643 , 0.12654343]], dtype=float32),\n",
       " array([[0.26876733, 0.80278885, 0.01544675, 0.09581774, 0.09186165,\n",
       "         0.01447429, 0.35852137, 0.13997771, 0.6811743 , 0.6164866 ,\n",
       "         0.21612428, 0.00619126, 0.18753792, 0.1139154 ]], dtype=float32),\n",
       " array([[0.27154464, 0.80851066, 0.01878929, 0.11991043, 0.10562573,\n",
       "         0.01805211, 0.3667678 , 0.12485002, 0.7016876 , 0.6158034 ,\n",
       "         0.21087739, 0.00739287, 0.1939296 , 0.11161887]], dtype=float32),\n",
       " array([[0.25463548, 0.80363035, 0.02483327, 0.10641886, 0.10436142,\n",
       "         0.01976654, 0.33195987, 0.13467546, 0.7008578 , 0.60653156,\n",
       "         0.19142848, 0.01053145, 0.20586047, 0.12775642]], dtype=float32),\n",
       " array([[0.21282744, 0.81579167, 0.04584751, 0.10916752, 0.1094918 ,\n",
       "         0.03051892, 0.2709077 , 0.12491069, 0.742136  , 0.5925941 ,\n",
       "         0.16560906, 0.02190437, 0.21723983, 0.14805496]], dtype=float32),\n",
       " array([[0.2268815 , 0.8122664 , 0.02412977, 0.10412797, 0.10152084,\n",
       "         0.02120198, 0.3034458 , 0.1290498 , 0.70038444, 0.60265136,\n",
       "         0.20314687, 0.01009887, 0.21306369, 0.12315064]], dtype=float32),\n",
       " array([[0.23063108, 0.8060364 , 0.03929389, 0.11756739, 0.10971763,\n",
       "         0.0276726 , 0.2981572 , 0.12018602, 0.73563087, 0.5948437 ,\n",
       "         0.17366096, 0.01779779, 0.22508405, 0.13946939]], dtype=float32),\n",
       " array([[0.22498362, 0.8040816 , 0.02041948, 0.0932695 , 0.0905045 ,\n",
       "         0.01652175, 0.25940055, 0.12407134, 0.7141391 , 0.6004418 ,\n",
       "         0.1857332 , 0.00858022, 0.21597943, 0.12077255]], dtype=float32),\n",
       " array([[0.22664906, 0.81054074, 0.02504308, 0.10683611, 0.10087216,\n",
       "         0.02105802, 0.28993857, 0.1132331 , 0.7136725 , 0.59690803,\n",
       "         0.19490807, 0.01093322, 0.23114753, 0.1262164 ]], dtype=float32),\n",
       " array([[0.20277765, 0.80627865, 0.0196313 , 0.0857821 , 0.08440109,\n",
       "         0.01746065, 0.28293365, 0.12420759, 0.6799891 , 0.59998333,\n",
       "         0.20969559, 0.00838804, 0.21896069, 0.11356975]], dtype=float32),\n",
       " array([[0.1638565 , 0.8279128 , 0.03234966, 0.09329847, 0.09164865,\n",
       "         0.02533261, 0.19928284, 0.11146104, 0.75349206, 0.59161186,\n",
       "         0.1703458 , 0.01462863, 0.21689565, 0.12134024]], dtype=float32),\n",
       " array([[0.17614451, 0.82081854, 0.11247876, 0.13056459, 0.12750004,\n",
       "         0.06162827, 0.14640199, 0.11967602, 0.7988176 , 0.56992567,\n",
       "         0.14120784, 0.06169215, 0.24345364, 0.17753415]], dtype=float32),\n",
       " array([[0.18207318, 0.8261993 , 0.12266262, 0.15184262, 0.14004473,\n",
       "         0.07237802, 0.18175636, 0.1056332 , 0.808511  , 0.5692637 ,\n",
       "         0.1466684 , 0.06802482, 0.25649965, 0.17917326]], dtype=float32),\n",
       " array([[0.19228274, 0.8186104 , 0.17720792, 0.18223968, 0.17100826,\n",
       "         0.1048212 , 0.17702565, 0.11269305, 0.7888296 , 0.5648193 ,\n",
       "         0.15857618, 0.10256697, 0.2744069 , 0.18739241]], dtype=float32),\n",
       " array([[0.15090686, 0.83166265, 0.21760733, 0.14677705, 0.15370926,\n",
       "         0.10558713, 0.13746491, 0.11114769, 0.83593404, 0.56206363,\n",
       "         0.12234799, 0.1426956 , 0.25567833, 0.2019918 ]], dtype=float32),\n",
       " array([[0.15422185, 0.8271645 , 0.39127794, 0.17809923, 0.18174125,\n",
       "         0.18490815, 0.09920624, 0.11873336, 0.84974843, 0.54634756,\n",
       "         0.11848935, 0.30099612, 0.27361387, 0.24654947]], dtype=float32),\n",
       " array([[0.18660322, 0.8143428 , 0.04821827, 0.11513231, 0.11527637,\n",
       "         0.03435995, 0.16314611, 0.11363177, 0.7799137 , 0.5848802 ,\n",
       "         0.16900504, 0.02265011, 0.2367607 , 0.14531566]], dtype=float32),\n",
       " array([[0.18257336, 0.81271297, 0.08467655, 0.1513982 , 0.1357391 ,\n",
       "         0.06068631, 0.11700671, 0.10706308, 0.77420753, 0.578881  ,\n",
       "         0.18061702, 0.04243962, 0.24125919, 0.14062989]], dtype=float32),\n",
       " array([[0.20579799, 0.8040558 , 0.0228385 , 0.11942589, 0.1082223 ,\n",
       "         0.0221388 , 0.15225905, 0.10360751, 0.7243536 , 0.59672123,\n",
       "         0.20858842, 0.00896294, 0.23141217, 0.10508308]], dtype=float32),\n",
       " array([[0.15983722, 0.8174145 , 0.07727074, 0.12660864, 0.12453955,\n",
       "         0.0550409 , 0.11501491, 0.10862862, 0.75830364, 0.5766186 ,\n",
       "         0.18173867, 0.04030787, 0.24548703, 0.13677147]], dtype=float32),\n",
       " array([[0.13105525, 0.83440334, 0.15966322, 0.13700707, 0.13637595,\n",
       "         0.10308354, 0.09682257, 0.10877828, 0.8055695 , 0.56309986,\n",
       "         0.16395123, 0.09790728, 0.25151506, 0.16644464]], dtype=float32),\n",
       " array([[0.14244123, 0.8254936 , 0.10364041, 0.13322878, 0.12825723,\n",
       "         0.07870473, 0.09329471, 0.11063003, 0.77053195, 0.56975937,\n",
       "         0.19276793, 0.05631211, 0.2471111 , 0.14484872]], dtype=float32),\n",
       " array([[0.22650252, 0.7855873 , 0.07317171, 0.16213866, 0.14821842,\n",
       "         0.05390881, 0.1025058 , 0.1142104 , 0.7119024 , 0.5720442 ,\n",
       "         0.20980324, 0.03598989, 0.27720818, 0.14240278]], dtype=float32),\n",
       " array([[0.28054973, 0.7600778 , 0.02633814, 0.15051764, 0.13070135,\n",
       "         0.02574514, 0.13298139, 0.11464909, 0.6246481 , 0.5820242 ,\n",
       "         0.2606158 , 0.01046947, 0.28860283, 0.1157037 ]], dtype=float32),\n",
       " array([[0.23320338, 0.80018103, 0.1923138 , 0.22311641, 0.22354661,\n",
       "         0.11399834, 0.14010067, 0.10882276, 0.7486117 , 0.56670606,\n",
       "         0.1744563 , 0.11838798, 0.30341974, 0.17546245]], dtype=float32),\n",
       " array([[0.18903132, 0.8086168 , 0.11739015, 0.15363708, 0.14639996,\n",
       "         0.07129677, 0.08989508, 0.11228421, 0.79872173, 0.56521654,\n",
       "         0.16257106, 0.06642693, 0.26554364, 0.1734453 ]], dtype=float32),\n",
       " array([[0.22055246, 0.7914213 , 0.01671437, 0.10555065, 0.09908763,\n",
       "         0.01671173, 0.12490981, 0.11298193, 0.7170938 , 0.5894866 ,\n",
       "         0.21787578, 0.0063397 , 0.24741308, 0.11628962]], dtype=float32),\n",
       " array([[0.1869064 , 0.809602  , 0.06557348, 0.12516132, 0.12771603,\n",
       "         0.04029507, 0.10309207, 0.10948382, 0.7994344 , 0.5786725 ,\n",
       "         0.15337485, 0.03392127, 0.24517478, 0.15290302]], dtype=float32),\n",
       " array([[0.16934742, 0.813321  , 0.17279065, 0.1543968 , 0.15466711,\n",
       "         0.09816714, 0.10670216, 0.11109214, 0.8009262 , 0.56000245,\n",
       "         0.15889278, 0.11187696, 0.2779507 , 0.18654811]], dtype=float32),\n",
       " array([[0.22414422, 0.78305906, 0.10019534, 0.16455016, 0.15802316,\n",
       "         0.06630312, 0.10473064, 0.1166899 , 0.72192556, 0.56303835,\n",
       "         0.20159471, 0.05518671, 0.30010384, 0.16440822]], dtype=float32),\n",
       " array([[0.17691869, 0.80192256, 0.04625186, 0.1243817 , 0.11610412,\n",
       "         0.04109764, 0.12841673, 0.10574516, 0.7173466 , 0.57861894,\n",
       "         0.22091788, 0.0217426 , 0.26292935, 0.1237348 ]], dtype=float32),\n",
       " array([[0.20298047, 0.7982049 , 0.04578392, 0.13499203, 0.12612458,\n",
       "         0.03760419, 0.11460259, 0.10961638, 0.7403564 , 0.5838644 ,\n",
       "         0.20330007, 0.02102334, 0.25056455, 0.12940687]], dtype=float32),\n",
       " array([[0.25537133, 0.7786385 , 0.07334646, 0.17146279, 0.1529635 ,\n",
       "         0.0479788 , 0.09319013, 0.11360471, 0.7531771 , 0.57403064,\n",
       "         0.18540141, 0.03649427, 0.27255848, 0.15556149]], dtype=float32),\n",
       " array([[0.23608398, 0.7820026 , 0.01594703, 0.12005867, 0.10998018,\n",
       "         0.01820385, 0.12433289, 0.11098794, 0.65076935, 0.58864605,\n",
       "         0.2540894 , 0.00585139, 0.26770714, 0.10483379]], dtype=float32),\n",
       " array([[0.2552386 , 0.76667726, 0.00759612, 0.10999813, 0.093339  ,\n",
       "         0.01131809, 0.17025934, 0.10785048, 0.5780933 , 0.59746957,\n",
       "         0.30515715, 0.00240622, 0.26871747, 0.08488308]], dtype=float32),\n",
       " array([[0.2247075 , 0.78082824, 0.01576903, 0.11314604, 0.09904132,\n",
       "         0.01762183, 0.19097705, 0.1031443 , 0.64124334, 0.59222525,\n",
       "         0.2541751 , 0.00596345, 0.2670718 , 0.09878524]], dtype=float32),\n",
       " array([[0.2848135 , 0.76414555, 0.01553054, 0.13051026, 0.11496571,\n",
       "         0.0167152 , 0.19229466, 0.11245239, 0.62082994, 0.5904712 ,\n",
       "         0.26035273, 0.00568762, 0.2840987 , 0.10988917]], dtype=float32),\n",
       " array([[0.25916892, 0.78129935, 0.03030934, 0.14260964, 0.12904732,\n",
       "         0.0276598 , 0.16337782, 0.11404755, 0.68073636, 0.5822404 ,\n",
       "         0.22909379, 0.01266558, 0.28285375, 0.13068664]], dtype=float32),\n",
       " array([[0.24158853, 0.7831588 , 0.00899299, 0.10596284, 0.09703488,\n",
       "         0.01190948, 0.24153912, 0.10567074, 0.61316735, 0.60244095,\n",
       "         0.26985028, 0.00298364, 0.2616021 , 0.09021663]], dtype=float32),\n",
       " array([[0.32046676, 0.75391686, 0.00972098, 0.13076478, 0.11045403,\n",
       "         0.01116919, 0.23177502, 0.10667741, 0.60019726, 0.59413636,\n",
       "         0.26259097, 0.0032334 , 0.29461467, 0.10240065]], dtype=float32),\n",
       " array([[0.31142315, 0.76136416, 0.02625142, 0.15339567, 0.13607042,\n",
       "         0.0220074 , 0.16218388, 0.11442799, 0.6550731 , 0.5826221 ,\n",
       "         0.224442  , 0.01067979, 0.29665977, 0.13041401]], dtype=float32),\n",
       " array([[0.22624381, 0.7988362 , 0.0680513 , 0.14788646, 0.1421285 ,\n",
       "         0.04614802, 0.14936705, 0.11353807, 0.745055  , 0.57146907,\n",
       "         0.18204734, 0.03519954, 0.2868012 , 0.16151214]], dtype=float32),\n",
       " array([[0.2439147 , 0.79268956, 0.03079601, 0.13705195, 0.12585877,\n",
       "         0.02628044, 0.15646341, 0.10933319, 0.71664244, 0.5823269 ,\n",
       "         0.20305288, 0.01299849, 0.27622783, 0.13292924]], dtype=float32),\n",
       " array([[0.2326794 , 0.793622  , 0.01646628, 0.1013916 , 0.09985163,\n",
       "         0.01435487, 0.20552856, 0.11133049, 0.71669865, 0.5914061 ,\n",
       "         0.1941624 , 0.0064761 , 0.26069525, 0.12454246]], dtype=float32),\n",
       " array([[0.25285867, 0.7784326 , 0.01463904, 0.1071522 , 0.09641661,\n",
       "         0.01409171, 0.24829283, 0.10492809, 0.66426194, 0.5905961 ,\n",
       "         0.22646824, 0.00577716, 0.27671707, 0.11583495]], dtype=float32),\n",
       " array([[2.4724077e-01, 7.7199066e-01, 1.9048733e-03, 6.6128477e-02,\n",
       "         6.3090377e-02, 3.3374398e-03, 2.8911197e-01, 1.0601902e-01,\n",
       "         5.2970487e-01, 6.1750144e-01, 3.0059078e-01, 5.1185768e-04,\n",
       "         2.4609071e-01, 6.6454291e-02]], dtype=float32),\n",
       " array([[2.5663215e-01, 7.6601660e-01, 2.3260952e-03, 7.8719877e-02,\n",
       "         6.8017818e-02, 4.3248483e-03, 2.2743818e-01, 1.0820837e-01,\n",
       "         5.1161456e-01, 6.1226004e-01, 3.1993338e-01, 6.1322493e-04,\n",
       "         2.5189349e-01, 6.4801462e-02]], dtype=float32),\n",
       " array([[0.18814266, 0.8053678 , 0.01077633, 0.07468288, 0.07354543,\n",
       "         0.0104653 , 0.15550306, 0.11188738, 0.7065659 , 0.58881736,\n",
       "         0.19710527, 0.00414818, 0.24639918, 0.1109883 ]], dtype=float32),\n",
       " array([[2.35875383e-01, 7.86795974e-01, 1.55431451e-03, 5.55871613e-02,\n",
       "         5.44540882e-02, 2.62122904e-03, 2.59220332e-01, 1.17416725e-01,\n",
       "         5.99297047e-01, 6.14538074e-01, 2.63020933e-01, 3.96042509e-04,\n",
       "         2.32215181e-01, 7.65333623e-02]], dtype=float32),\n",
       " array([[0.2533322 , 0.78722656, 0.00724942, 0.09005735, 0.08032298,\n",
       "         0.00877538, 0.24691577, 0.11157642, 0.6394081 , 0.5964222 ,\n",
       "         0.24367459, 0.00251114, 0.25957233, 0.10488593]], dtype=float32),\n",
       " array([[0.20793737, 0.7994586 , 0.01206543, 0.08660536, 0.08565441,\n",
       "         0.01275631, 0.18912473, 0.11655727, 0.6510468 , 0.5885705 ,\n",
       "         0.22463629, 0.00465883, 0.26257893, 0.10945035]], dtype=float32),\n",
       " array([[0.25529525, 0.7852625 , 0.04372371, 0.13595203, 0.12619518,\n",
       "         0.03066783, 0.18389875, 0.11917852, 0.6986777 , 0.5751465 ,\n",
       "         0.19166979, 0.02086202, 0.28952217, 0.15042077]], dtype=float32),\n",
       " array([[0.23840988, 0.79308337, 0.00521107, 0.06360562, 0.06947591,\n",
       "         0.00581061, 0.27425298, 0.13830723, 0.65095145, 0.6135319 ,\n",
       "         0.22520338, 0.0017433 , 0.21285936, 0.1055476 ]], dtype=float32),\n",
       " array([[0.26541716, 0.7769782 , 0.00279914, 0.0629755 , 0.06183855,\n",
       "         0.00343259, 0.22396588, 0.12008723, 0.6169034 , 0.597929  ,\n",
       "         0.22983877, 0.00085809, 0.26150438, 0.09829766]], dtype=float32),\n",
       " array([[2.2417277e-01, 8.0722499e-01, 1.1691304e-03, 4.4420503e-02,\n",
       "         4.4623651e-02, 2.0209441e-03, 2.6731649e-01, 1.3476653e-01,\n",
       "         6.6294765e-01, 6.3349783e-01, 2.4142808e-01, 2.8859818e-04,\n",
       "         1.7034648e-01, 7.7584989e-02]], dtype=float32),\n",
       " array([[0.18601505, 0.81507576, 0.00508782, 0.05199512, 0.06026918,\n",
       "         0.00482869, 0.27015695, 0.11429112, 0.6945517 , 0.60240936,\n",
       "         0.17522953, 0.00185861, 0.23293833, 0.10302319]], dtype=float32),\n",
       " array([[0.16838668, 0.8279355 , 0.02358641, 0.08069103, 0.08848783,\n",
       "         0.01670297, 0.21158955, 0.09923181, 0.7535691 , 0.56485   ,\n",
       "         0.15003332, 0.01106261, 0.31006083, 0.14717509]], dtype=float32),\n",
       " array([[0.21614414, 0.81976527, 0.00718081, 0.10138577, 0.09319633,\n",
       "         0.00932363, 0.23487517, 0.09591939, 0.70774734, 0.5940778 ,\n",
       "         0.20228265, 0.00213058, 0.2735032 , 0.09724458]], dtype=float32),\n",
       " array([[0.2457768 , 0.80613804, 0.00535509, 0.10704003, 0.08913616,\n",
       "         0.00829709, 0.24944516, 0.09082107, 0.6457456 , 0.59007466,\n",
       "         0.24616402, 0.00157187, 0.2958136 , 0.09156344]], dtype=float32),\n",
       " array([[0.34454718, 0.77011234, 0.0077076 , 0.1480027 , 0.11547001,\n",
       "         0.01013699, 0.28033525, 0.09003817, 0.5865725 , 0.57354015,\n",
       "         0.2599803 , 0.00246797, 0.3700138 , 0.11046057]], dtype=float32),\n",
       " array([[0.2951569 , 0.77124405, 0.0502608 , 0.17514576, 0.1604397 ,\n",
       "         0.03388502, 0.2048368 , 0.10623246, 0.6485055 , 0.5570206 ,\n",
       "         0.19229528, 0.02342577, 0.377373  , 0.15234528]], dtype=float32),\n",
       " array([[0.2109055 , 0.8153559 , 0.02162418, 0.12353838, 0.10789172,\n",
       "         0.01911476, 0.25790137, 0.08034767, 0.735274  , 0.5725517 ,\n",
       "         0.17485276, 0.0089555 , 0.32108104, 0.12284224]], dtype=float32),\n",
       " array([[2.2363381e-01, 8.1096250e-01, 2.7371020e-04, 3.4233626e-02,\n",
       "         4.0774554e-02, 7.1466796e-04, 4.1575211e-01, 1.0807081e-01,\n",
       "         5.4774410e-01, 6.3546747e-01, 2.8240505e-01, 5.3687876e-05,\n",
       "         2.1903062e-01, 5.5864446e-02]], dtype=float32),\n",
       " array([[0.21004097, 0.82477546, 0.01349382, 0.09912793, 0.09308913,\n",
       "         0.01235412, 0.2769909 , 0.09488077, 0.7552611 , 0.6098312 ,\n",
       "         0.1667011 , 0.00528359, 0.21525775, 0.10440623]], dtype=float32),\n",
       " array([[0.25156456, 0.7942107 , 0.00651206, 0.11337803, 0.09051968,\n",
       "         0.00958811, 0.2713228 , 0.09613743, 0.6248829 , 0.58463633,\n",
       "         0.2491142 , 0.00193707, 0.30959877, 0.09426648]], dtype=float32),\n",
       " array([[3.0653858e-01, 7.7973682e-01, 4.2794360e-04, 6.6222303e-02,\n",
       "         5.6994289e-02, 1.3476650e-03, 4.4252661e-01, 9.8257005e-02,\n",
       "         4.6069133e-01, 6.0035008e-01, 3.5086563e-01, 7.9312937e-05,\n",
       "         3.3586332e-01, 6.4944565e-02]], dtype=float32),\n",
       " array([[2.3333043e-01, 8.0463129e-01, 8.6719979e-04, 6.2896229e-02,\n",
       "         5.5729419e-02, 2.2385186e-03, 3.3966580e-01, 1.1023484e-01,\n",
       "         5.6062752e-01, 6.1226410e-01, 2.9595095e-01, 1.7220961e-04,\n",
       "         2.5614634e-01, 6.3959725e-02]], dtype=float32),\n",
       " array([[1.9812866e-01, 8.3087397e-01, 1.5852191e-04, 2.9986035e-02,\n",
       "         3.0680981e-02, 5.8115035e-04, 3.6783502e-01, 1.2581666e-01,\n",
       "         6.0856402e-01, 6.5338939e-01, 2.9261899e-01, 2.5867035e-05,\n",
       "         1.5352648e-01, 4.8551083e-02]], dtype=float32),\n",
       " array([[3.4094384e-01, 8.0375808e-01, 4.8804132e-04, 5.4770645e-02,\n",
       "         5.0677918e-02, 1.2373498e-03, 3.5516879e-01, 1.6480081e-01,\n",
       "         6.2971109e-01, 6.5390575e-01, 2.8442091e-01, 9.2578404e-05,\n",
       "         1.4510448e-01, 7.7100746e-02]], dtype=float32),\n",
       " array([[3.7673381e-01, 7.7871233e-01, 3.2506281e-04, 6.0518138e-02,\n",
       "         4.8326354e-02, 1.0025086e-03, 2.9624102e-01, 1.5894698e-01,\n",
       "         5.2624965e-01, 6.2768489e-01, 3.3314189e-01, 5.4117085e-05,\n",
       "         2.0705967e-01, 7.2442167e-02]], dtype=float32),\n",
       " array([[3.6986172e-01, 8.0603802e-01, 1.1106398e-05, 2.9715901e-02,\n",
       "         2.7304275e-02, 9.4752206e-05, 5.6924337e-01, 1.3373379e-01,\n",
       "         3.9520803e-01, 6.5125680e-01, 4.2056659e-01, 9.9151862e-07,\n",
       "         2.2254010e-01, 3.8988791e-02]], dtype=float32),\n",
       " array([[2.2786850e-01, 8.4880048e-01, 2.1103472e-06, 1.0856336e-02,\n",
       "         1.0151837e-02, 2.1313768e-05, 6.7295265e-01, 9.6343413e-02,\n",
       "         5.1489598e-01, 6.5410781e-01, 3.3579931e-01, 1.7449062e-07,\n",
       "         1.9780210e-01, 3.1155590e-02]], dtype=float32),\n",
       " array([[1.9770013e-01, 8.6048472e-01, 2.1110334e-04, 3.6106888e-02,\n",
       "         3.7046343e-02, 6.3058111e-04, 4.9811658e-01, 8.9458875e-02,\n",
       "         6.4798301e-01, 6.1958802e-01, 2.1423531e-01, 3.8947488e-05,\n",
       "         2.4047719e-01, 6.1689802e-02]], dtype=float32),\n",
       " array([[0.39991972, 0.7782085 , 0.01025117, 0.13014339, 0.12247734,\n",
       "         0.00778785, 0.3458006 , 0.12276211, 0.65079033, 0.5715418 ,\n",
       "         0.16478786, 0.0035677 , 0.3521079 , 0.16019751]], dtype=float32),\n",
       " array([[4.0036407e-01, 7.7449000e-01, 3.0794486e-03, 1.1376094e-01,\n",
       "         1.1104496e-01, 3.9640544e-03, 4.4288543e-01, 1.3357565e-01,\n",
       "         5.5089462e-01, 5.9341854e-01, 2.1906215e-01, 7.5453473e-04,\n",
       "         3.2878062e-01, 1.0997787e-01]], dtype=float32),\n",
       " array([[0.37657028, 0.777698  , 0.00829568, 0.11898516, 0.11330571,\n",
       "         0.00656937, 0.43123937, 0.10692696, 0.6303945 , 0.5714595 ,\n",
       "         0.16797477, 0.00305149, 0.36812347, 0.14525539]], dtype=float32),\n",
       " array([[0.46424335, 0.74916786, 0.03688698, 0.20957345, 0.18674672,\n",
       "         0.01782188, 0.32024089, 0.10411199, 0.65864074, 0.5502856 ,\n",
       "         0.14127089, 0.01695966, 0.4292777 , 0.19371551]], dtype=float32),\n",
       " array([[0.36284283, 0.76994914, 0.19279335, 0.27629238, 0.2337849 ,\n",
       "         0.06767716, 0.23284371, 0.09517525, 0.78195333, 0.55062634,\n",
       "         0.1022281 , 0.12048645, 0.37530524, 0.20947677]], dtype=float32),\n",
       " array([[0.31024078, 0.7908964 , 0.01632965, 0.16886471, 0.12655929,\n",
       "         0.01429389, 0.18694389, 0.09710774, 0.7575156 , 0.5827499 ,\n",
       "         0.1584079 , 0.00515668, 0.28681445, 0.121591  ]], dtype=float32),\n",
       " array([[0.1535134 , 0.8536274 , 0.00413348, 0.06517959, 0.06059271,\n",
       "         0.00501979, 0.39337   , 0.07352731, 0.7978277 , 0.6098565 ,\n",
       "         0.14362562, 0.00130717, 0.21710902, 0.08532225]], dtype=float32),\n",
       " array([[0.13667066, 0.8443427 , 0.08884583, 0.1116498 , 0.10670255,\n",
       "         0.04511403, 0.41872534, 0.07221178, 0.81582516, 0.5721739 ,\n",
       "         0.11200809, 0.0578415 , 0.27976355, 0.14524484]], dtype=float32),\n",
       " array([[0.19399847, 0.8126801 , 0.02938018, 0.12272217, 0.10941317,\n",
       "         0.03212   , 0.3509531 , 0.09694653, 0.6219251 , 0.569147  ,\n",
       "         0.24196362, 0.01355939, 0.32004604, 0.11897077]], dtype=float32),\n",
       " array([[0.15363668, 0.8299227 , 0.04578789, 0.13209404, 0.11450965,\n",
       "         0.05687857, 0.34996533, 0.09156029, 0.60294944, 0.56312037,\n",
       "         0.27067408, 0.02264916, 0.32574207, 0.11249133]], dtype=float32),\n",
       " array([[0.03465185, 0.9101223 , 0.13798012, 0.05932103, 0.07115832,\n",
       "         0.08450422, 0.3425539 , 0.05512026, 0.8796239 , 0.5707003 ,\n",
       "         0.09614683, 0.11312838, 0.22367765, 0.11836878]], dtype=float32),\n",
       " array([[0.1716407 , 0.8306801 , 0.04821279, 0.12059098, 0.1086499 ,\n",
       "         0.03364781, 0.2915963 , 0.07894981, 0.79758966, 0.5592491 ,\n",
       "         0.14586979, 0.02422134, 0.3216805 , 0.15469131]], dtype=float32),\n",
       " array([[0.20253894, 0.8074976 , 0.30087215, 0.2096583 , 0.18763989,\n",
       "         0.13215399, 0.24744502, 0.07689132, 0.8122969 , 0.5341977 ,\n",
       "         0.12152593, 0.2416282 , 0.38376668, 0.21851455]], dtype=float32),\n",
       " array([[0.09816629, 0.840916  , 0.7230217 , 0.21002705, 0.2096959 ,\n",
       "         0.45609346, 0.14515124, 0.07384823, 0.8005739 , 0.50518966,\n",
       "         0.13871466, 0.7516535 , 0.40744546, 0.23705317]], dtype=float32),\n",
       " array([[0.19136964, 0.80012006, 0.6880066 , 0.30618477, 0.2701705 ,\n",
       "         0.39247197, 0.16277693, 0.07805935, 0.80837464, 0.5141133 ,\n",
       "         0.13526611, 0.683164  , 0.42017332, 0.25890902]], dtype=float32),\n",
       " array([[0.11559631, 0.83232206, 0.87503403, 0.25227574, 0.25927177,\n",
       "         0.5165272 , 0.13596602, 0.06749206, 0.89530694, 0.51343936,\n",
       "         0.07548876, 0.9066573 , 0.37191966, 0.29427388]], dtype=float32),\n",
       " array([[0.17301649, 0.810527  , 0.0438645 , 0.12205961, 0.1178125 ,\n",
       "         0.03150888, 0.13672271, 0.08433505, 0.8083791 , 0.57387376,\n",
       "         0.15951279, 0.02041767, 0.27601582, 0.13484672]], dtype=float32),\n",
       " array([[0.1958014 , 0.79370403, 0.00995017, 0.0951452 , 0.08563047,\n",
       "         0.01114603, 0.16502425, 0.08700802, 0.737739  , 0.5901691 ,\n",
       "         0.20907514, 0.0033916 , 0.25963897, 0.09709077]], dtype=float32),\n",
       " array([[0.11777753, 0.8321533 , 0.07092446, 0.12762682, 0.10430381,\n",
       "         0.0577396 , 0.12094499, 0.06875771, 0.8143404 , 0.57207596,\n",
       "         0.17236848, 0.03770238, 0.2537632 , 0.11106502]], dtype=float32),\n",
       " array([[0.15738115, 0.8082289 , 0.03977073, 0.12920024, 0.11720202,\n",
       "         0.04658579, 0.10860037, 0.09374977, 0.6781063 , 0.568471  ,\n",
       "         0.26518524, 0.0177572 , 0.28994176, 0.1082962 ]], dtype=float32),\n",
       " array([[0.15751997, 0.80264497, 0.02823129, 0.12114475, 0.10399608,\n",
       "         0.03855912, 0.12244917, 0.09215508, 0.63579386, 0.57049763,\n",
       "         0.29606083, 0.01185651, 0.29018745, 0.09632359]], dtype=float32),\n",
       " array([[0.15129408, 0.8044603 , 0.00337566, 0.07250483, 0.063835  ,\n",
       "         0.01002064, 0.13097546, 0.10522711, 0.50631195, 0.59242517,\n",
       "         0.4114591 , 0.00092004, 0.25514355, 0.06099708]], dtype=float32),\n",
       " array([[0.1804627 , 0.7884736 , 0.00960386, 0.07041898, 0.08211596,\n",
       "         0.01074932, 0.11299707, 0.11752248, 0.61162394, 0.5847931 ,\n",
       "         0.24906124, 0.00370606, 0.26477057, 0.09632899]], dtype=float32),\n",
       " array([[0.33543712, 0.73337096, 0.01781616, 0.151316  , 0.13514936,\n",
       "         0.0199123 , 0.15000272, 0.12525189, 0.5378774 , 0.57133704,\n",
       "         0.30576473, 0.00642997, 0.33819833, 0.1207647 ]], dtype=float32),\n",
       " array([[0.44597137, 0.70034254, 0.00497602, 0.16126876, 0.12803456,\n",
       "         0.00928354, 0.15910245, 0.13959146, 0.42930993, 0.58256507,\n",
       "         0.4035448 , 0.00127104, 0.34210277, 0.09924253]], dtype=float32),\n",
       " array([[0.38863888, 0.7214075 , 0.00554431, 0.12835348, 0.10650241,\n",
       "         0.00739003, 0.11761345, 0.13152836, 0.55173373, 0.5849313 ,\n",
       "         0.29929176, 0.00157275, 0.30049387, 0.10542687]], dtype=float32),\n",
       " array([[4.0968594e-01, 7.3170125e-01, 1.0255905e-03, 8.8736512e-02,\n",
       "         7.7341780e-02, 1.9571688e-03, 2.0162348e-01, 1.3383186e-01,\n",
       "         5.4669005e-01, 6.1133432e-01, 3.0447370e-01, 2.0561159e-04,\n",
       "         2.6236272e-01, 8.2811028e-02]], dtype=float32),\n",
       " array([[5.6042624e-01, 6.7502540e-01, 2.1491498e-04, 6.8929546e-02,\n",
       "         6.3551739e-02, 5.2699749e-04, 2.4296439e-01, 1.7639557e-01,\n",
       "         4.0504491e-01, 6.1790448e-01, 3.7239107e-01, 3.2979715e-05,\n",
       "         2.7931380e-01, 8.0390640e-02]], dtype=float32),\n",
       " array([[2.9180545e-01, 7.6990938e-01, 1.3889809e-03, 6.3495800e-02,\n",
       "         5.7932541e-02, 2.5078084e-03, 2.2371376e-01, 1.3344726e-01,\n",
       "         5.8749372e-01, 6.0701257e-01, 2.8156742e-01, 3.3469600e-04,\n",
       "         2.3863260e-01, 8.5556276e-02]], dtype=float32),\n",
       " array([[0.1623899 , 0.8228257 , 0.07737337, 0.11145004, 0.11550542,\n",
       "         0.04622452, 0.1625756 , 0.10583822, 0.7694273 , 0.57178926,\n",
       "         0.15441535, 0.04507373, 0.2595976 , 0.15056074]], dtype=float32),\n",
       " array([[0.23571935, 0.79717493, 0.13262825, 0.17435357, 0.15274274,\n",
       "         0.06129054, 0.11094727, 0.10132392, 0.8189851 , 0.5654165 ,\n",
       "         0.1284254 , 0.07928182, 0.27199203, 0.17990749]], dtype=float32),\n",
       " array([[0.19277947, 0.80762345, 0.33594018, 0.20393117, 0.19881713,\n",
       "         0.16271253, 0.10878795, 0.10225304, 0.797366  , 0.5483475 ,\n",
       "         0.14160267, 0.27269173, 0.30975565, 0.20582142]], dtype=float32),\n",
       " array([[0.22355871, 0.7971623 , 0.9591397 , 0.4517342 , 0.42003798,\n",
       "         0.7549299 , 0.10006602, 0.08217316, 0.85214335, 0.50157076,\n",
       "         0.09630582, 0.97446966, 0.41878477, 0.36534002]], dtype=float32),\n",
       " array([[0.22157757, 0.7814861 , 0.03918798, 0.12616165, 0.13643026,\n",
       "         0.02749394, 0.10109396, 0.12823252, 0.71609294, 0.58533263,\n",
       "         0.18346015, 0.01647687, 0.25470358, 0.1261739 ]], dtype=float32),\n",
       " array([[0.20397383, 0.7992567 , 0.07183533, 0.14442027, 0.12763935,\n",
       "         0.0484212 , 0.12991649, 0.09321153, 0.7672733 , 0.5661274 ,\n",
       "         0.18085694, 0.04043889, 0.2851119 , 0.1518865 ]], dtype=float32),\n",
       " array([[0.1124317 , 0.8453373 , 0.13414198, 0.11635638, 0.11208727,\n",
       "         0.07077686, 0.12116878, 0.07519651, 0.86502576, 0.56854665,\n",
       "         0.11864892, 0.09243921, 0.24247962, 0.15192604]], dtype=float32),\n",
       " array([[0.11693387, 0.8486279 , 0.01850404, 0.08269051, 0.07272939,\n",
       "         0.01639634, 0.15266733, 0.07260581, 0.86755115, 0.59960705,\n",
       "         0.13282435, 0.00719109, 0.19661511, 0.09948982]], dtype=float32),\n",
       " array([[0.07370997, 0.8718283 , 0.09069672, 0.08015449, 0.08603463,\n",
       "         0.05856647, 0.20377707, 0.06283843, 0.8644206 , 0.57026786,\n",
       "         0.12721446, 0.06374139, 0.24412388, 0.1364488 ]], dtype=float32),\n",
       " array([[0.04172648, 0.892205  , 0.6495055 , 0.11369495, 0.12656543,\n",
       "         0.42252126, 0.1613313 , 0.05921553, 0.8818797 , 0.52393764,\n",
       "         0.12475327, 0.7093474 , 0.30403355, 0.2144301 ]], dtype=float32),\n",
       " array([[0.11155358, 0.82225764, 0.6369032 , 0.2088305 , 0.2077573 ,\n",
       "         0.39745346, 0.13363522, 0.09078956, 0.79329485, 0.5291637 ,\n",
       "         0.16266717, 0.62112826, 0.34927797, 0.21060422]], dtype=float32),\n",
       " array([[0.17898406, 0.7830647 , 0.299799  , 0.20769861, 0.19089593,\n",
       "         0.18587065, 0.08890893, 0.10843488, 0.7342526 , 0.54102266,\n",
       "         0.20577116, 0.2170447 , 0.34134805, 0.1805509 ]], dtype=float32),\n",
       " array([[0.23620175, 0.76662344, 0.05620368, 0.15942754, 0.14742263,\n",
       "         0.05006494, 0.10173645, 0.11357196, 0.65848297, 0.5629926 ,\n",
       "         0.26147363, 0.02611989, 0.321753  , 0.13864197]], dtype=float32),\n",
       " array([[0.24906757, 0.7629492 , 0.04084041, 0.14786266, 0.12912656,\n",
       "         0.0277631 , 0.11262051, 0.10140454, 0.75277805, 0.5813534 ,\n",
       "         0.18391547, 0.01728597, 0.2733836 , 0.12736584]], dtype=float32),\n",
       " array([[0.2956002 , 0.75363785, 0.01894919, 0.14864397, 0.12450842,\n",
       "         0.01893849, 0.12752603, 0.10638576, 0.68162614, 0.5855888 ,\n",
       "         0.2455536 , 0.00664513, 0.2851743 , 0.11516369]], dtype=float32),\n",
       " array([[0.18037218, 0.80299455, 0.04670503, 0.11739464, 0.11555152,\n",
       "         0.03508911, 0.09890606, 0.1019577 , 0.77553946, 0.57601804,\n",
       "         0.18699172, 0.02209985, 0.262735  , 0.13632591]], dtype=float32),\n",
       " array([[0.12038802, 0.82467514, 0.22124133, 0.14558686, 0.1357871 ,\n",
       "         0.13849285, 0.08678634, 0.0847362 , 0.7972881 , 0.55097634,\n",
       "         0.1787038 , 0.16181348, 0.29226255, 0.15768899]], dtype=float32),\n",
       " array([[0.1943535 , 0.7886206 , 0.03721363, 0.12552306, 0.11667056,\n",
       "         0.03634906, 0.12809153, 0.10263116, 0.6877239 , 0.573478  ,\n",
       "         0.25006947, 0.01638409, 0.2917229 , 0.12176655]], dtype=float32),\n",
       " array([[0.27572128, 0.7452301 , 0.05038273, 0.15908124, 0.14282563,\n",
       "         0.04251884, 0.09587935, 0.12185286, 0.6217024 , 0.5590685 ,\n",
       "         0.27241793, 0.02341473, 0.33661744, 0.14577904]], dtype=float32),\n",
       " array([[0.2551966 , 0.7564324 , 0.0304379 , 0.151395  , 0.1342084 ,\n",
       "         0.03217973, 0.11426728, 0.10856669, 0.5875212 , 0.5747581 ,\n",
       "         0.29265907, 0.0125355 , 0.31308243, 0.10952446]], dtype=float32),\n",
       " array([[0.37286085, 0.7182195 , 0.01875616, 0.18476479, 0.15162417,\n",
       "         0.02163886, 0.12686191, 0.11946393, 0.53205293, 0.5791832 ,\n",
       "         0.3205076 , 0.00641166, 0.33216414, 0.11007831]], dtype=float32),\n",
       " array([[0.4181011 , 0.7235759 , 0.00827303, 0.2009249 , 0.14543776,\n",
       "         0.01214308, 0.1056069 , 0.11004827, 0.57794327, 0.5982475 ,\n",
       "         0.31196457, 0.00214591, 0.28877217, 0.08885082]], dtype=float32),\n",
       " array([[0.3876926 , 0.7254947 , 0.02535672, 0.22578482, 0.17287013,\n",
       "         0.0265159 , 0.07882281, 0.11409062, 0.59069103, 0.580885  ,\n",
       "         0.28298154, 0.00856568, 0.31214306, 0.10909089]], dtype=float32),\n",
       " array([[0.3062201 , 0.75769204, 0.01721047, 0.1520706 , 0.12572338,\n",
       "         0.01807517, 0.13422537, 0.10250229, 0.6330394 , 0.5854593 ,\n",
       "         0.25689226, 0.00626003, 0.29393137, 0.10833405]], dtype=float32),\n",
       " array([[0.26003423, 0.77193016, 0.07148661, 0.1763644 , 0.1624571 ,\n",
       "         0.05507682, 0.14028399, 0.11404733, 0.6596132 , 0.565109  ,\n",
       "         0.23471193, 0.03578584, 0.32591355, 0.14872092]], dtype=float32),\n",
       " array([[0.21324843, 0.7985526 , 0.1394125 , 0.16835845, 0.1626354 ,\n",
       "         0.08403419, 0.13845384, 0.10877602, 0.7516724 , 0.5574631 ,\n",
       "         0.18283068, 0.08809025, 0.3139931 , 0.18411674]], dtype=float32),\n",
       " array([[0.15225215, 0.82761794, 0.23151876, 0.15170094, 0.16019543,\n",
       "         0.11637713, 0.15310329, 0.09739203, 0.823488  , 0.55786663,\n",
       "         0.13677427, 0.17544217, 0.29201373, 0.19688357]], dtype=float32),\n",
       " array([[0.23297682, 0.78819025, 0.10192221, 0.15360793, 0.14684741,\n",
       "         0.05447506, 0.13149285, 0.11230417, 0.7994719 , 0.56405175,\n",
       "         0.15582895, 0.05830692, 0.29281   , 0.19303936]], dtype=float32),\n",
       " array([[0.20781478, 0.7946178 , 0.12859342, 0.15386687, 0.14667909,\n",
       "         0.06470126, 0.10261697, 0.1059391 , 0.81323385, 0.562629  ,\n",
       "         0.14631236, 0.07922055, 0.28421482, 0.187636  ]], dtype=float32),\n",
       " array([[0.20427915, 0.7943257 , 0.0352312 , 0.11656921, 0.11415689,\n",
       "         0.02670288, 0.17784972, 0.10218067, 0.7487112 , 0.58561206,\n",
       "         0.18841992, 0.01603023, 0.264946  , 0.13125868]], dtype=float32),\n",
       " array([[0.23657951, 0.7765857 , 0.04154019, 0.13682021, 0.12198086,\n",
       "         0.03111089, 0.17783856, 0.10268171, 0.72264177, 0.57884455,\n",
       "         0.20402578, 0.01927418, 0.2873174 , 0.13658781]], dtype=float32),\n",
       " array([[0.21586026, 0.7881525 , 0.01509701, 0.10649425, 0.09724291,\n",
       "         0.01680714, 0.19847786, 0.10383847, 0.6764626 , 0.5917987 ,\n",
       "         0.24277706, 0.00562608, 0.2660496 , 0.10608102]], dtype=float32),\n",
       " array([[0.22415842, 0.7855534 , 0.00500579, 0.08704096, 0.07740025,\n",
       "         0.00797798, 0.26567912, 0.10343849, 0.61710805, 0.6060412 ,\n",
       "         0.28460395, 0.00148932, 0.25294158, 0.08234704]], dtype=float32),\n",
       " array([[0.23577634, 0.7824098 , 0.00364031, 0.08628242, 0.0723118 ,\n",
       "         0.00692776, 0.28950003, 0.10612106, 0.58452827, 0.6059498 ,\n",
       "         0.31602985, 0.00100532, 0.25771436, 0.07909796]], dtype=float32),\n",
       " array([[2.56081730e-01, 7.75700748e-01, 9.66091873e-04, 6.39064759e-02,\n",
       "         5.73208667e-02, 2.63604429e-03, 3.14353287e-01, 1.17938794e-01,\n",
       "         4.98173982e-01, 6.20619714e-01, 3.68167162e-01, 2.07274876e-04,\n",
       "         2.42552549e-01, 6.21481650e-02]], dtype=float32),\n",
       " array([[2.6678821e-01, 7.5857335e-01, 1.7554230e-03, 6.4741723e-02,\n",
       "         6.0899254e-02, 3.6498415e-03, 2.8740853e-01, 1.3206360e-01,\n",
       "         4.6679986e-01, 6.0492116e-01, 3.5889134e-01, 4.4983486e-04,\n",
       "         2.7087465e-01, 7.6323263e-02]], dtype=float32),\n",
       " array([[0.2721752 , 0.7718859 , 0.00376792, 0.08286164, 0.07504946,\n",
       "         0.00628481, 0.2525386 , 0.12244888, 0.5364565 , 0.5969006 ,\n",
       "         0.31424925, 0.00111744, 0.2774737 , 0.09165748]], dtype=float32),\n",
       " array([[4.1003823e-01, 7.2850877e-01, 9.1480633e-04, 8.1932575e-02,\n",
       "         7.6473802e-02, 2.0405944e-03, 3.1803802e-01, 1.5107995e-01,\n",
       "         4.2387602e-01, 6.1406642e-01, 3.6617219e-01, 1.8672485e-04,\n",
       "         2.8244916e-01, 7.9135582e-02]], dtype=float32),\n",
       " array([[0.36668882, 0.75222063, 0.00344298, 0.09888725, 0.08955764,\n",
       "         0.00442227, 0.23148932, 0.13331546, 0.5826533 , 0.603519  ,\n",
       "         0.25412157, 0.00094509, 0.26915756, 0.10249036]], dtype=float32),\n",
       " array([[0.42277038, 0.7360241 , 0.00488441, 0.1256458 , 0.10998856,\n",
       "         0.00587746, 0.2887879 , 0.13770342, 0.563067  , 0.5986982 ,\n",
       "         0.26126465, 0.00135637, 0.29751712, 0.11490229]], dtype=float32),\n",
       " array([[0.33134952, 0.7714847 , 0.00857087, 0.11456341, 0.10401383,\n",
       "         0.0086952 , 0.28064328, 0.11687382, 0.64235836, 0.59352154,\n",
       "         0.22022516, 0.00292807, 0.2866837 , 0.1220988 ]], dtype=float32),\n",
       " array([[0.2961454 , 0.7824498 , 0.01389232, 0.12091404, 0.10696545,\n",
       "         0.01235603, 0.22213626, 0.11626083, 0.69445395, 0.5905252 ,\n",
       "         0.19536431, 0.00497605, 0.27234608, 0.1269264 ]], dtype=float32),\n",
       " array([[0.29687715, 0.7831131 , 0.0259805 , 0.14675687, 0.1254578 ,\n",
       "         0.02049911, 0.1984467 , 0.1120396 , 0.7134845 , 0.5828213 ,\n",
       "         0.1880856 , 0.01047523, 0.2843034 , 0.14007011]], dtype=float32),\n",
       " array([[0.18368545, 0.824163  , 0.06667475, 0.12133648, 0.11834313,\n",
       "         0.03554042, 0.1475551 , 0.10270375, 0.8264009 , 0.5798457 ,\n",
       "         0.12229414, 0.0353153 , 0.24456635, 0.15755564]], dtype=float32),\n",
       " array([[0.22841977, 0.8052218 , 0.03010543, 0.1296706 , 0.11970928,\n",
       "         0.02332567, 0.1621614 , 0.11348157, 0.76450986, 0.5907499 ,\n",
       "         0.16697432, 0.0120421 , 0.24499795, 0.13078852]], dtype=float32),\n",
       " array([[0.26856378, 0.78357506, 0.01139433, 0.11648292, 0.10421506,\n",
       "         0.01203177, 0.1958776 , 0.11858457, 0.68091404, 0.5988049 ,\n",
       "         0.21537283, 0.0037232 , 0.25233322, 0.1079714 ]], dtype=float32),\n",
       " array([[0.2403124 , 0.7898608 , 0.0094517 , 0.10901728, 0.08938231,\n",
       "         0.00997952, 0.17744201, 0.10866518, 0.72483   , 0.60774714,\n",
       "         0.1937089 , 0.00286532, 0.22205481, 0.09249223]], dtype=float32),\n",
       " array([[0.205249  , 0.8053982 , 0.02956895, 0.1201757 , 0.10743997,\n",
       "         0.0252316 , 0.16092409, 0.11043648, 0.7359564 , 0.5862011 ,\n",
       "         0.18865877, 0.01223518, 0.2520524 , 0.12259711]], dtype=float32),\n",
       " array([[0.21080504, 0.8058783 , 0.05907905, 0.12861265, 0.12180049,\n",
       "         0.03687764, 0.20382768, 0.10680997, 0.76221174, 0.5749528 ,\n",
       "         0.16111466, 0.0307125 , 0.27684927, 0.15660602]], dtype=float32),\n",
       " array([[0.14623076, 0.8279694 , 0.04830474, 0.1035121 , 0.10176732,\n",
       "         0.03628264, 0.18766479, 0.10551354, 0.7740223 , 0.5834401 ,\n",
       "         0.16563159, 0.02335095, 0.24259777, 0.12862216]], dtype=float32),\n",
       " array([[0.13026938, 0.8478173 , 0.19188184, 0.12577505, 0.12941928,\n",
       "         0.09925544, 0.19677603, 0.0934761 , 0.84387225, 0.5591386 ,\n",
       "         0.12618521, 0.14590687, 0.27416   , 0.19914825]], dtype=float32),\n",
       " array([[0.14307337, 0.8387858 , 0.25055614, 0.15669553, 0.15163527,\n",
       "         0.13786647, 0.17236508, 0.09550884, 0.8300587 , 0.55451757,\n",
       "         0.14044444, 0.19304723, 0.28881553, 0.20157698]], dtype=float32),\n",
       " array([[0.19887757, 0.7966851 , 0.02070673, 0.09488603, 0.10120609,\n",
       "         0.02070541, 0.24091788, 0.11689052, 0.636543  , 0.58442456,\n",
       "         0.2414541 , 0.00884807, 0.28278583, 0.11977741]], dtype=float32),\n",
       " array([[0.2305932 , 0.78425854, 0.02469195, 0.12613307, 0.10931335,\n",
       "         0.02392392, 0.18021207, 0.10341097, 0.6584754 , 0.5830529 ,\n",
       "         0.23601703, 0.01035259, 0.28162763, 0.11353903]], dtype=float32),\n",
       " array([[0.16893189, 0.81382275, 0.03347136, 0.09926061, 0.09424654,\n",
       "         0.02725773, 0.23211062, 0.08477688, 0.70716554, 0.58033174,\n",
       "         0.19980492, 0.01785438, 0.27565804, 0.11908667]], dtype=float32),\n",
       " array([[0.25116256, 0.7916001 , 0.0161089 , 0.12152338, 0.10286862,\n",
       "         0.01636499, 0.19926049, 0.09600637, 0.69283247, 0.58892906,\n",
       "         0.22097713, 0.0063039 , 0.27152294, 0.11435197]], dtype=float32),\n",
       " array([[2.5239265e-01, 7.7798533e-01, 1.7481352e-03, 7.4059188e-02,\n",
       "         6.5907508e-02, 3.7290761e-03, 2.2821809e-01, 1.0969658e-01,\n",
       "         5.2705735e-01, 6.1563408e-01, 3.2700518e-01, 4.2905813e-04,\n",
       "         2.4106522e-01, 6.4733930e-02]], dtype=float32),\n",
       " array([[0.29652926, 0.7571539 , 0.00672638, 0.11682668, 0.09531418,\n",
       "         0.00965355, 0.21752459, 0.10993055, 0.53178215, 0.5962435 ,\n",
       "         0.30230257, 0.0020874 , 0.28463307, 0.08539718]], dtype=float32),\n",
       " array([[0.30744904, 0.76024824, 0.00476787, 0.11125121, 0.09312116,\n",
       "         0.0077495 , 0.1970769 , 0.1217984 , 0.5264985 , 0.597847  ,\n",
       "         0.31182107, 0.00132012, 0.27955976, 0.08547308]], dtype=float32),\n",
       " array([[0.2908658 , 0.7614967 , 0.0029504 , 0.08132581, 0.07251837,\n",
       "         0.0051556 , 0.21602802, 0.12917446, 0.5016946 , 0.59338105,\n",
       "         0.3257815 , 0.00082146, 0.2862567 , 0.08873921]], dtype=float32),\n",
       " array([[3.4252116e-01, 7.5883704e-01, 1.5585931e-03, 8.7632209e-02,\n",
       "         7.8863204e-02, 3.4402267e-03, 2.8074479e-01, 1.3953780e-01,\n",
       "         4.7479039e-01, 6.0653126e-01, 3.4698284e-01, 3.4462873e-04,\n",
       "         2.7927002e-01, 8.0922484e-02]], dtype=float32),\n",
       " array([[0.2822449 , 0.78413576, 0.00469858, 0.09231567, 0.08280151,\n",
       "         0.00595168, 0.16333409, 0.12541391, 0.65047044, 0.59961134,\n",
       "         0.22627866, 0.00133808, 0.24754895, 0.09895169]], dtype=float32),\n",
       " array([[0.34129432, 0.7665494 , 0.00763283, 0.11129864, 0.10072655,\n",
       "         0.00785957, 0.21908079, 0.12904257, 0.6406968 , 0.58946866,\n",
       "         0.22068849, 0.00245557, 0.28501758, 0.12586363]], dtype=float32),\n",
       " array([[0.29804772, 0.784516  , 0.00952124, 0.10347521, 0.09599032,\n",
       "         0.00999214, 0.24649073, 0.11833608, 0.6437495 , 0.58336127,\n",
       "         0.22668733, 0.00349377, 0.293752  , 0.13131197]], dtype=float32),\n",
       " array([[0.3035971 , 0.76973456, 0.00551767, 0.09417   , 0.08290222,\n",
       "         0.00702895, 0.27899966, 0.12917866, 0.60092247, 0.5902339 ,\n",
       "         0.25532553, 0.00169112, 0.2852957 , 0.11306372]], dtype=float32),\n",
       " array([[3.3725640e-01, 7.7078068e-01, 1.3523025e-03, 7.6721221e-02,\n",
       "         6.8654433e-02, 2.3646117e-03, 3.8903314e-01, 1.2549286e-01,\n",
       "         5.8134317e-01, 6.1539596e-01, 2.6491067e-01, 3.0689515e-04,\n",
       "         2.5468698e-01, 8.6073972e-02]], dtype=float32),\n",
       " array([[0.37461606, 0.76081806, 0.00304901, 0.10330202, 0.08671743,\n",
       "         0.00432123, 0.42668515, 0.12160432, 0.58229005, 0.60246444,\n",
       "         0.25712207, 0.00081008, 0.28954244, 0.10458881]], dtype=float32),\n",
       " array([[0.26490253, 0.8036863 , 0.00368442, 0.08238614, 0.07347399,\n",
       "         0.00499672, 0.43443742, 0.109019  , 0.6779492 , 0.60795516,\n",
       "         0.21423928, 0.00104884, 0.25067806, 0.10053742]], dtype=float32),\n",
       " array([[2.4317741e-01, 8.0847603e-01, 2.8264108e-03, 7.5343564e-02,\n",
       "         6.9235265e-02, 4.6846853e-03, 4.3442601e-01, 1.1114569e-01,\n",
       "         6.3354087e-01, 6.0951728e-01, 2.4468471e-01, 7.6283747e-04,\n",
       "         2.4967691e-01, 8.9286879e-02]], dtype=float32),\n",
       " array([[0.23674801, 0.8136196 , 0.00474741, 0.08372314, 0.07543952,\n",
       "         0.00619713, 0.36946398, 0.10516109, 0.6925237 , 0.6060684 ,\n",
       "         0.20478384, 0.00141863, 0.24320039, 0.09752806]], dtype=float32),\n",
       " array([[0.27097198, 0.79689753, 0.00961014, 0.11001325, 0.09726261,\n",
       "         0.01173263, 0.3522591 , 0.11565039, 0.63768286, 0.58970386,\n",
       "         0.2353309 , 0.00324322, 0.28618515, 0.11650555]], dtype=float32),\n",
       " array([[0.16164686, 0.83281094, 0.0812861 , 0.1059174 , 0.11417282,\n",
       "         0.04386384, 0.30437478, 0.09981567, 0.77586234, 0.5688911 ,\n",
       "         0.13584845, 0.05127969, 0.28542852, 0.16825785]], dtype=float32),\n",
       " array([[0.15710309, 0.8359923 , 0.21726538, 0.15347196, 0.14813764,\n",
       "         0.11100933, 0.25793624, 0.09123838, 0.80401313, 0.55516195,\n",
       "         0.13378678, 0.16546243, 0.30518988, 0.1930638 ]], dtype=float32),\n",
       " array([[0.12766585, 0.85390526, 0.18410157, 0.12178475, 0.12909123,\n",
       "         0.08005112, 0.24123685, 0.08440337, 0.87010354, 0.5681844 ,\n",
       "         0.0971049 , 0.13832618, 0.25792235, 0.18934274]], dtype=float32),\n",
       " array([[0.14029837, 0.84744835, 0.3688727 , 0.16479784, 0.1593966 ,\n",
       "         0.14122385, 0.24321915, 0.07683499, 0.89860696, 0.5589198 ,\n",
       "         0.08147892, 0.32547575, 0.2740512 , 0.22553596]], dtype=float32),\n",
       " array([[0.11980189, 0.85213625, 0.31677827, 0.13413288, 0.13680679,\n",
       "         0.12391125, 0.24517994, 0.07965022, 0.8984312 , 0.5611482 ,\n",
       "         0.08606733, 0.27486032, 0.2616703 , 0.21940528]], dtype=float32),\n",
       " array([[0.10053867, 0.85821897, 0.6847223 , 0.18108565, 0.19338867,\n",
       "         0.33424535, 0.16973886, 0.07535866, 0.8980975 , 0.54331243,\n",
       "         0.08378673, 0.7113371 , 0.28762528, 0.24868292]], dtype=float32),\n",
       " array([[0.04975374, 0.8878603 , 0.49681428, 0.09218894, 0.10760307,\n",
       "         0.21959895, 0.16866527, 0.06568013, 0.9207578 , 0.5525245 ,\n",
       "         0.07860066, 0.5221273 , 0.23553203, 0.20547941]], dtype=float32),\n",
       " array([[0.05912104, 0.8759805 , 0.44212353, 0.10100775, 0.10868921,\n",
       "         0.20658913, 0.18823801, 0.06632847, 0.90728784, 0.5526827 ,\n",
       "         0.09463945, 0.44393966, 0.24867027, 0.19842015]], dtype=float32),\n",
       " array([[0.08967386, 0.8579817 , 0.10638862, 0.09463349, 0.09327564,\n",
       "         0.06550618, 0.219579  , 0.07204053, 0.8721773 , 0.58063716,\n",
       "         0.1295343 , 0.06830489, 0.22576477, 0.14073244]], dtype=float32),\n",
       " array([[0.03875341, 0.8916689 , 0.6058415 , 0.09490724, 0.12121624,\n",
       "         0.33481678, 0.16681619, 0.06266464, 0.89302564, 0.54844993,\n",
       "         0.10285719, 0.6597326 , 0.25172776, 0.18748444]], dtype=float32),\n",
       " array([[0.0765247 , 0.8577727 , 0.48958832, 0.14410579, 0.14616914,\n",
       "         0.2902396 , 0.15736602, 0.07095669, 0.85203564, 0.54783547,\n",
       "         0.14294848, 0.48096883, 0.2834035 , 0.18549412]], dtype=float32),\n",
       " array([[0.06416996, 0.8612182 , 0.36239177, 0.10925307, 0.1221151 ,\n",
       "         0.22919156, 0.14440565, 0.07550494, 0.81929386, 0.550085  ,\n",
       "         0.16725425, 0.3455945 , 0.27715987, 0.16452295]], dtype=float32),\n",
       " array([[0.11256982, 0.8294734 , 0.2735615 , 0.14769895, 0.14437437,\n",
       "         0.16755328, 0.08526098, 0.0868155 , 0.81185335, 0.5541864 ,\n",
       "         0.17278914, 0.21792485, 0.27802113, 0.1663266 ]], dtype=float32),\n",
       " array([[0.15830229, 0.8073992 , 0.16858876, 0.16892321, 0.15840589,\n",
       "         0.11588988, 0.08787557, 0.09365857, 0.7668839 , 0.56286556,\n",
       "         0.200517  , 0.10937527, 0.28479356, 0.15060344]], dtype=float32),\n",
       " array([[0.2682916 , 0.7560847 , 0.02559693, 0.14276643, 0.13708971,\n",
       "         0.02649721, 0.1394168 , 0.11934245, 0.62260973, 0.58432215,\n",
       "         0.27733898, 0.0099532 , 0.29376256, 0.11786611]], dtype=float32),\n",
       " array([[0.24194244, 0.77134055, 0.0155619 , 0.12719518, 0.11288144,\n",
       "         0.02110188, 0.11933836, 0.1169217 , 0.6295809 , 0.58768827,\n",
       "         0.30081737, 0.00536202, 0.27337545, 0.1044317 ]], dtype=float32),\n",
       " array([[0.21380621, 0.78281045, 0.03565692, 0.13446583, 0.12609863,\n",
       "         0.03396813, 0.10248064, 0.10954545, 0.68123096, 0.58060765,\n",
       "         0.24455166, 0.01544774, 0.2739821 , 0.11828744]], dtype=float32),\n",
       " array([[0.18354039, 0.80170447, 0.05174978, 0.11803707, 0.11679399,\n",
       "         0.03581017, 0.05973189, 0.11176127, 0.7858967 , 0.5756693 ,\n",
       "         0.17533349, 0.02491781, 0.24676563, 0.1420244 ]], dtype=float32),\n",
       " array([[0.26329276, 0.76582885, 0.07193485, 0.18628971, 0.16575873,\n",
       "         0.05820221, 0.03917876, 0.1266412 , 0.6967535 , 0.56201625,\n",
       "         0.23988174, 0.03368905, 0.2958126 , 0.15022035]], dtype=float32),\n",
       " array([[0.25311083, 0.76571095, 0.04361816, 0.1601988 , 0.14292565,\n",
       "         0.0380474 , 0.04118444, 0.12515543, 0.6934958 , 0.572101  ,\n",
       "         0.23815614, 0.01826753, 0.274514  , 0.13054812]], dtype=float32),\n",
       " array([[0.29397705, 0.7486446 , 0.03052324, 0.1717262 , 0.15109314,\n",
       "         0.03190544, 0.07152787, 0.12692529, 0.6092116 , 0.5781916 ,\n",
       "         0.28460902, 0.01151821, 0.2952505 , 0.11728743]], dtype=float32),\n",
       " array([[0.3288421 , 0.7368295 , 0.08037358, 0.20123805, 0.17997666,\n",
       "         0.05671484, 0.0611725 , 0.12038504, 0.61077666, 0.55309457,\n",
       "         0.25927743, 0.04424672, 0.3508839 , 0.1637213 ]], dtype=float32),\n",
       " array([[0.24621783, 0.76925915, 0.08293883, 0.15343827, 0.1525218 ,\n",
       "         0.04682033, 0.03970002, 0.13374974, 0.7461752 , 0.56355566,\n",
       "         0.17626137, 0.04328034, 0.2790164 , 0.1668256 ]], dtype=float32),\n",
       " array([[0.221144  , 0.79194486, 0.05711447, 0.14675532, 0.13322756,\n",
       "         0.03820115, 0.04541259, 0.11302909, 0.789887  , 0.5741238 ,\n",
       "         0.17062564, 0.02670561, 0.25134784, 0.14664054]], dtype=float32),\n",
       " array([[0.2714051 , 0.76843214, 0.01219148, 0.11281096, 0.10012525,\n",
       "         0.01219255, 0.0978791 , 0.12107778, 0.7097638 , 0.59211075,\n",
       "         0.22153057, 0.00407327, 0.25067395, 0.11667062]], dtype=float32),\n",
       " array([[0.2694479 , 0.76495993, 0.04923182, 0.16068219, 0.14472234,\n",
       "         0.03617122, 0.0893573 , 0.11640539, 0.6986244 , 0.5753393 ,\n",
       "         0.21342218, 0.02253902, 0.2878083 , 0.13972403]], dtype=float32),\n",
       " array([[0.18220814, 0.79983175, 0.10305144, 0.14380153, 0.14139733,\n",
       "         0.07143997, 0.11647814, 0.1079661 , 0.719496  , 0.56458724,\n",
       "         0.20647717, 0.06149137, 0.2963875 , 0.15345995]], dtype=float32),\n",
       " array([[0.18896073, 0.79868907, 0.04686604, 0.12335262, 0.11530621,\n",
       "         0.04042163, 0.11831768, 0.11016482, 0.71249855, 0.57247937,\n",
       "         0.22269058, 0.02275962, 0.27961737, 0.13645671]], dtype=float32),\n",
       " array([[0.25025696, 0.77313566, 0.00545058, 0.09096541, 0.08725857,\n",
       "         0.00809338, 0.16051424, 0.12216558, 0.60069996, 0.6023245 ,\n",
       "         0.28732198, 0.00160964, 0.25542653, 0.09035496]], dtype=float32),\n",
       " array([[0.26889345, 0.7674335 , 0.00683373, 0.09985384, 0.08781122,\n",
       "         0.00814832, 0.15116364, 0.11407017, 0.6567102 , 0.60203254,\n",
       "         0.24360149, 0.00211789, 0.24913362, 0.09596549]], dtype=float32),\n",
       " array([[0.3069107 , 0.75864756, 0.00816593, 0.11262593, 0.09955474,\n",
       "         0.00920034, 0.18476145, 0.12095014, 0.6432155 , 0.59788114,\n",
       "         0.24652165, 0.00255657, 0.26924366, 0.10861567]], dtype=float32),\n",
       " array([[0.2734605 , 0.7679147 , 0.02073416, 0.13435555, 0.11935736,\n",
       "         0.02177946, 0.1538473 , 0.11474545, 0.6088432 , 0.5819344 ,\n",
       "         0.26808634, 0.00826451, 0.29812038, 0.11756956]], dtype=float32),\n",
       " array([[0.21453275, 0.7948764 , 0.03974038, 0.13101332, 0.12195701,\n",
       "         0.03503432, 0.08890907, 0.12144491, 0.6976773 , 0.5737519 ,\n",
       "         0.22208877, 0.01765918, 0.27560607, 0.13442433]], dtype=float32),\n",
       " array([[0.28455758, 0.77472425, 0.01539944, 0.14251521, 0.12119351,\n",
       "         0.01715598, 0.13041875, 0.1225902 , 0.67475116, 0.5945695 ,\n",
       "         0.23863907, 0.00496851, 0.2603559 , 0.11077309]], dtype=float32),\n",
       " array([[0.34226224, 0.74632823, 0.02169019, 0.15653114, 0.13781719,\n",
       "         0.01888175, 0.11805279, 0.12597428, 0.6253109 , 0.5824639 ,\n",
       "         0.23851623, 0.00815911, 0.29978713, 0.12788607]], dtype=float32),\n",
       " array([[0.26187515, 0.78711   , 0.04094471, 0.14582203, 0.13971342,\n",
       "         0.03120358, 0.11910903, 0.12257326, 0.71152943, 0.57733065,\n",
       "         0.19943039, 0.01832049, 0.28424674, 0.14893855]], dtype=float32),\n",
       " array([[0.23127519, 0.7952554 , 0.05538729, 0.13891497, 0.1337037 ,\n",
       "         0.04074777, 0.1639935 , 0.11848439, 0.7179188 , 0.5721923 ,\n",
       "         0.19976375, 0.02752929, 0.29383004, 0.15898615]], dtype=float32),\n",
       " array([[0.24261051, 0.7958007 , 0.06179809, 0.1603148 , 0.14359389,\n",
       "         0.04135842, 0.14185604, 0.10342783, 0.7520802 , 0.57904017,\n",
       "         0.17634474, 0.03077376, 0.27684933, 0.14737085]], dtype=float32),\n",
       " array([[0.17771398, 0.81962883, 0.11895222, 0.13226753, 0.13643436,\n",
       "         0.06134192, 0.09578922, 0.10797718, 0.80971557, 0.5664324 ,\n",
       "         0.13954541, 0.07585966, 0.26763225, 0.17990108]], dtype=float32),\n",
       " array([[0.21951722, 0.799793  , 0.06336544, 0.14177015, 0.12858698,\n",
       "         0.04035304, 0.1037651 , 0.10889326, 0.78304726, 0.5742059 ,\n",
       "         0.16512613, 0.03197903, 0.26722938, 0.15790044]], dtype=float32),\n",
       " array([[0.17649579, 0.8009291 , 0.09922062, 0.1283363 , 0.12462978,\n",
       "         0.0554358 , 0.0832333 , 0.11526258, 0.77790207, 0.56745565,\n",
       "         0.15921804, 0.05667333, 0.26732904, 0.15883186]], dtype=float32),\n",
       " array([[0.16178448, 0.8091811 , 0.06256471, 0.09908058, 0.10406439,\n",
       "         0.04021209, 0.15617989, 0.10423703, 0.73727626, 0.5694276 ,\n",
       "         0.18248855, 0.03681536, 0.2833863 , 0.15133296]], dtype=float32),\n",
       " array([[0.15770255, 0.8115084 , 0.08282063, 0.1163548 , 0.11512936,\n",
       "         0.05110024, 0.12540667, 0.09995213, 0.7630607 , 0.5725154 ,\n",
       "         0.1706428 , 0.04839774, 0.27002966, 0.14339925]], dtype=float32),\n",
       " array([[0.20742843, 0.7972124 , 0.04374644, 0.13350774, 0.12362334,\n",
       "         0.03493971, 0.16974047, 0.09810919, 0.7101976 , 0.58338803,\n",
       "         0.20637171, 0.02077453, 0.27799407, 0.12447879]], dtype=float32),\n",
       " array([[0.21462624, 0.79141486, 0.01656274, 0.10931981, 0.09828158,\n",
       "         0.01815647, 0.1474499 , 0.10328334, 0.6633604 , 0.5900818 ,\n",
       "         0.24495198, 0.00639725, 0.26641926, 0.10384178]], dtype=float32),\n",
       " array([[0.2578682 , 0.77254295, 0.00447453, 0.09223085, 0.08203512,\n",
       "         0.00694919, 0.20634152, 0.11398832, 0.58644205, 0.6074418 ,\n",
       "         0.28931287, 0.00124724, 0.25597137, 0.08146629]], dtype=float32),\n",
       " array([[0.2407149 , 0.78608596, 0.0070325 , 0.1048354 , 0.08882488,\n",
       "         0.01057851, 0.24681364, 0.10355854, 0.60782236, 0.60400665,\n",
       "         0.28297535, 0.00215794, 0.26242858, 0.08494406]], dtype=float32),\n",
       " array([[0.2958562 , 0.7683088 , 0.0068382 , 0.11966108, 0.10277046,\n",
       "         0.0107759 , 0.29635566, 0.10959242, 0.53230774, 0.599933  ,\n",
       "         0.31966475, 0.00210321, 0.29517013, 0.09015403]], dtype=float32),\n",
       " array([[0.22879781, 0.7964771 , 0.01181629, 0.11047406, 0.10076495,\n",
       "         0.01477672, 0.19137587, 0.10838323, 0.63635194, 0.59710777,\n",
       "         0.25275868, 0.00408493, 0.26358142, 0.09686828]], dtype=float32),\n",
       " array([[0.26074687, 0.7818443 , 0.02062208, 0.12943164, 0.11437335,\n",
       "         0.02181227, 0.20712383, 0.11474805, 0.6300539 , 0.5822491 ,\n",
       "         0.2541816 , 0.00802061, 0.2995286 , 0.1223359 ]], dtype=float32),\n",
       " array([[0.28318065, 0.7739635 , 0.00645198, 0.09304272, 0.08618037,\n",
       "         0.00749954, 0.2302733 , 0.1222894 , 0.6392885 , 0.5972763 ,\n",
       "         0.24047975, 0.00200561, 0.27211678, 0.10968044]], dtype=float32),\n",
       " array([[0.3809209 , 0.72853017, 0.00613024, 0.13088265, 0.11456163,\n",
       "         0.00813715, 0.29106507, 0.12234247, 0.47751972, 0.6009015 ,\n",
       "         0.31551144, 0.00178982, 0.31455234, 0.09220981]], dtype=float32),\n",
       " array([[0.40816033, 0.73019755, 0.00585331, 0.14774565, 0.11906733,\n",
       "         0.0076661 , 0.21901625, 0.11969811, 0.52689344, 0.60294217,\n",
       "         0.2928344 , 0.00160172, 0.29845136, 0.09234305]], dtype=float32),\n",
       " array([[0.2807691 , 0.7816654 , 0.0099246 , 0.11619075, 0.10665483,\n",
       "         0.01075075, 0.23128386, 0.11541655, 0.6508071 , 0.60322887,\n",
       "         0.22480094, 0.00317874, 0.2627501 , 0.10228364]], dtype=float32),\n",
       " array([[0.29309103, 0.7864462 , 0.0066597 , 0.1078331 , 0.09440295,\n",
       "         0.00773182, 0.272448  , 0.10559612, 0.6727379 , 0.60526043,\n",
       "         0.22066899, 0.0020598 , 0.26062644, 0.10344866]], dtype=float32),\n",
       " array([[0.252877  , 0.7958688 , 0.01437753, 0.11640845, 0.10449035,\n",
       "         0.01420419, 0.24924691, 0.10576263, 0.6925092 , 0.59680617,\n",
       "         0.20703429, 0.00521132, 0.26551422, 0.11281331]], dtype=float32),\n",
       " array([[0.211135  , 0.8196513 , 0.03531593, 0.12196338, 0.11236478,\n",
       "         0.02654698, 0.23041295, 0.10380609, 0.78521395, 0.58612883,\n",
       "         0.1617964 , 0.01567871, 0.25984323, 0.14610444]], dtype=float32),\n",
       " array([[0.15334992, 0.84211373, 0.14129327, 0.13204977, 0.1386782 ,\n",
       "         0.07906241, 0.16800167, 0.11220516, 0.8323116 , 0.5671315 ,\n",
       "         0.13308743, 0.08919635, 0.26619878, 0.1935288 ]], dtype=float32),\n",
       " array([[0.17782494, 0.8257267 , 0.22107515, 0.16634081, 0.16090742,\n",
       "         0.11597492, 0.17066595, 0.10148059, 0.80689883, 0.55592406,\n",
       "         0.14511856, 0.16277969, 0.30414042, 0.2055574 ]], dtype=float32),\n",
       " array([[0.20461698, 0.8084536 , 0.08148456, 0.14823832, 0.14249139,\n",
       "         0.05389373, 0.21895412, 0.10422401, 0.7444025 , 0.5764144 ,\n",
       "         0.17740774, 0.04420089, 0.28844503, 0.15306348]], dtype=float32),\n",
       " array([[0.20310847, 0.81179255, 0.10876982, 0.15430517, 0.14372236,\n",
       "         0.06212722, 0.19368395, 0.09371635, 0.7757775 , 0.5702475 ,\n",
       "         0.15817448, 0.06749331, 0.29289347, 0.16663314]], dtype=float32),\n",
       " array([[0.21336357, 0.80798215, 0.03777465, 0.1296806 , 0.11910426,\n",
       "         0.02882016, 0.20134217, 0.1013923 , 0.75938493, 0.5884019 ,\n",
       "         0.17600964, 0.01695275, 0.2604774 , 0.13359185]], dtype=float32),\n",
       " array([[0.24170893, 0.79272985, 0.04821496, 0.1513879 , 0.1407133 ,\n",
       "         0.03674771, 0.25032356, 0.10459163, 0.7023117 , 0.58443236,\n",
       "         0.20008196, 0.02267789, 0.29092795, 0.1364461 ]], dtype=float32),\n",
       " array([[0.19322346, 0.8146275 , 0.02369088, 0.12118283, 0.10521222,\n",
       "         0.02428372, 0.2258379 , 0.09616351, 0.7332989 , 0.5954653 ,\n",
       "         0.20680471, 0.00925539, 0.25104102, 0.10881773]], dtype=float32),\n",
       " array([[0.1700198 , 0.82157624, 0.01719668, 0.09420791, 0.08872918,\n",
       "         0.01908522, 0.30446804, 0.09532672, 0.7105731 , 0.596882  ,\n",
       "         0.21769625, 0.00685901, 0.25360703, 0.10546029]], dtype=float32),\n",
       " array([[0.19474049, 0.812093  , 0.03110375, 0.11281115, 0.10580489,\n",
       "         0.02784907, 0.2545346 , 0.09748393, 0.7101258 , 0.58316624,\n",
       "         0.2091395 , 0.0144475 , 0.28130642, 0.12835544]], dtype=float32),\n",
       " array([[0.20630454, 0.8050356 , 0.03156006, 0.12909502, 0.11619615,\n",
       "         0.03297614, 0.2950911 , 0.09996852, 0.6627812 , 0.58394915,\n",
       "         0.24405393, 0.0139095 , 0.2940102 , 0.12044837]], dtype=float32),\n",
       " array([[0.26475853, 0.7783002 , 0.00747858, 0.10721847, 0.09833553,\n",
       "         0.01060062, 0.26634875, 0.11485397, 0.57581735, 0.6026162 ,\n",
       "         0.28502628, 0.00234511, 0.2730016 , 0.09196451]], dtype=float32),\n",
       " array([[0.28749287, 0.7679369 , 0.00485674, 0.10265584, 0.08736295,\n",
       "         0.00749881, 0.3063371 , 0.10487068, 0.5387836 , 0.60521185,\n",
       "         0.30384213, 0.00146034, 0.27996188, 0.08302776]], dtype=float32),\n",
       " array([[3.7546003e-01, 7.2859752e-01, 2.2702871e-03, 1.0574431e-01,\n",
       "         8.5525282e-02, 3.8992539e-03, 2.1757813e-01, 1.2225842e-01,\n",
       "         4.7492403e-01, 6.1204994e-01, 3.3025029e-01, 5.4126099e-04,\n",
       "         2.7502891e-01, 7.3196389e-02]], dtype=float32),\n",
       " array([[0.35225606, 0.74779016, 0.00468386, 0.12105999, 0.09959749,\n",
       "         0.00660985, 0.22964835, 0.11714772, 0.5396477 , 0.60676146,\n",
       "         0.2886654 , 0.00128465, 0.27657953, 0.08559938]], dtype=float32),\n",
       " array([[0.2861884 , 0.77286154, 0.00772955, 0.11019416, 0.0937457 ,\n",
       "         0.00961256, 0.19096124, 0.11662712, 0.6050241 , 0.59728724,\n",
       "         0.2579191 , 0.00243414, 0.26912656, 0.09781546]], dtype=float32),\n",
       " array([[3.3713013e-01, 7.5853777e-01, 1.6073809e-03, 8.9169152e-02,\n",
       "         7.7709399e-02, 3.1003484e-03, 3.0499685e-01, 1.1989819e-01,\n",
       "         5.0801200e-01, 6.1955273e-01, 3.1403700e-01, 3.6300992e-04,\n",
       "         2.5920948e-01, 7.1466021e-02]], dtype=float32),\n",
       " array([[0.3618305 , 0.7483253 , 0.00449271, 0.11967062, 0.09753051,\n",
       "         0.00638513, 0.2631233 , 0.11917829, 0.53282666, 0.60300314,\n",
       "         0.28967813, 0.00123683, 0.28783765, 0.09026294]], dtype=float32),\n",
       " array([[0.33188733, 0.7666499 , 0.00973791, 0.13108066, 0.11369414,\n",
       "         0.01104886, 0.2448552 , 0.11912459, 0.58935267, 0.5937535 ,\n",
       "         0.2510953 , 0.0031768 , 0.29459393, 0.10923897]], dtype=float32),\n",
       " array([[0.27346182, 0.7882861 , 0.0214494 , 0.12872599, 0.12096146,\n",
       "         0.018333  , 0.19190942, 0.11600006, 0.6638268 , 0.5849217 ,\n",
       "         0.20383178, 0.00863436, 0.2879514 , 0.12752159]], dtype=float32),\n",
       " array([[0.25406426, 0.79466856, 0.02026681, 0.11875726, 0.10490234,\n",
       "         0.01711695, 0.17144051, 0.11236727, 0.71317744, 0.58313453,\n",
       "         0.18966615, 0.00803959, 0.27423906, 0.13155834]], dtype=float32),\n",
       " array([[0.2468257 , 0.80809623, 0.02995448, 0.13781247, 0.12243002,\n",
       "         0.02332627, 0.19672401, 0.10425363, 0.7576595 , 0.58622897,\n",
       "         0.16864465, 0.0125215 , 0.2678296 , 0.1379988 ]], dtype=float32),\n",
       " array([[0.2680774 , 0.79483545, 0.03662956, 0.14299336, 0.13206731,\n",
       "         0.02516183, 0.18013196, 0.11170708, 0.7402409 , 0.58249176,\n",
       "         0.1681221 , 0.0162419 , 0.27826178, 0.14780979]], dtype=float32),\n",
       " array([[0.22667897, 0.81232905, 0.07155923, 0.15638867, 0.14514905,\n",
       "         0.04746389, 0.20157821, 0.10600291, 0.75980675, 0.5738669 ,\n",
       "         0.16634531, 0.03720214, 0.28934044, 0.16188107]], dtype=float32),\n",
       " array([[0.24348244, 0.79547554, 0.01304269, 0.11281306, 0.10588721,\n",
       "         0.01442261, 0.2923136 , 0.105593  , 0.6358224 , 0.59625554,\n",
       "         0.23279881, 0.00474298, 0.27832764, 0.10438234]], dtype=float32),\n",
       " array([[0.2375495 , 0.793777  , 0.00748527, 0.09933456, 0.08434799,\n",
       "         0.00913982, 0.29417458, 0.09817076, 0.65548486, 0.6051111 ,\n",
       "         0.2285662 , 0.00241803, 0.25420734, 0.08920654]], dtype=float32),\n",
       " array([[0.25486308, 0.79226506, 0.00304764, 0.08432287, 0.07256548,\n",
       "         0.00486167, 0.3472587 , 0.10234658, 0.6204366 , 0.61503166,\n",
       "         0.2551861 , 0.00081522, 0.24583575, 0.07859816]], dtype=float32),\n",
       " array([[0.22905979, 0.7994408 , 0.00494521, 0.08051223, 0.0715268 ,\n",
       "         0.00679971, 0.33247134, 0.09830694, 0.6250299 , 0.60199356,\n",
       "         0.24643166, 0.00160914, 0.26341122, 0.08986716]], dtype=float32),\n",
       " array([[0.22910364, 0.8032148 , 0.0102366 , 0.10743345, 0.09255032,\n",
       "         0.01376894, 0.33384082, 0.10265626, 0.6263667 , 0.59512556,\n",
       "         0.2554971 , 0.00349507, 0.27822095, 0.0985631 ]], dtype=float32),\n",
       " array([[0.26348934, 0.79006654, 0.01569556, 0.12868877, 0.1121837 ,\n",
       "         0.01749806, 0.3055741 , 0.10716327, 0.62112975, 0.58985335,\n",
       "         0.24274604, 0.00575611, 0.2944402 , 0.11005384]], dtype=float32),\n",
       " array([[0.21868204, 0.8088424 , 0.02767057, 0.11832619, 0.11533647,\n",
       "         0.02378478, 0.2573702 , 0.11052611, 0.695762  , 0.5843605 ,\n",
       "         0.1946094 , 0.0118105 , 0.28220844, 0.12915342]], dtype=float32),\n",
       " array([[0.23536037, 0.8086542 , 0.04187895, 0.14007942, 0.12747188,\n",
       "         0.03216591, 0.2338351 , 0.1058741 , 0.737456  , 0.57697743,\n",
       "         0.1808544 , 0.01940647, 0.29053432, 0.15017578]], dtype=float32),\n",
       " array([[0.17720117, 0.8283533 , 0.12625025, 0.13207501, 0.14039469,\n",
       "         0.06376839, 0.17950162, 0.10885077, 0.80937964, 0.5641825 ,\n",
       "         0.1307303 , 0.08128443, 0.28505093, 0.19324015]], dtype=float32),\n",
       " array([[0.17315787, 0.8323749 , 0.18093021, 0.14676213, 0.1476591 ,\n",
       "         0.08248436, 0.16791417, 0.09872169, 0.8465361 , 0.5615345 ,\n",
       "         0.11501916, 0.12834483, 0.2806341 , 0.20804386]], dtype=float32),\n",
       " array([[0.18769106, 0.8191464 , 0.14806019, 0.15123884, 0.14469764,\n",
       "         0.07426449, 0.15830322, 0.10237767, 0.82443976, 0.5629822 ,\n",
       "         0.13240157, 0.09619591, 0.2839259 , 0.19457936]], dtype=float32),\n",
       " array([[0.15367378, 0.83427435, 0.2505762 , 0.15140615, 0.15028621,\n",
       "         0.11148914, 0.13691282, 0.09020035, 0.85220826, 0.55642146,\n",
       "         0.11468226, 0.20119576, 0.28250217, 0.2078551 ]], dtype=float32),\n",
       " array([[0.13259432, 0.8363838 , 0.17156342, 0.12977621, 0.12870719,\n",
       "         0.08802307, 0.1081619 , 0.09332243, 0.8398775 , 0.5635419 ,\n",
       "         0.12852578, 0.12052512, 0.2599226 , 0.17373206]], dtype=float32),\n",
       " array([[0.14926428, 0.82808214, 0.13924526, 0.13813175, 0.13344635,\n",
       "         0.07819232, 0.11085992, 0.09471676, 0.8197504 , 0.5672767 ,\n",
       "         0.14339375, 0.08965468, 0.26329613, 0.16320801]], dtype=float32),\n",
       " array([[0.09041803, 0.85566807, 0.1583132 , 0.0991792 , 0.10637384,\n",
       "         0.08697336, 0.11205898, 0.08661231, 0.84948945, 0.56864077,\n",
       "         0.12812766, 0.1151014 , 0.236895  , 0.1546769 ]], dtype=float32),\n",
       " array([[0.11512591, 0.8398464 , 0.18536693, 0.13283753, 0.1311517 ,\n",
       "         0.11360461, 0.10780925, 0.08957633, 0.8130049 , 0.5640474 ,\n",
       "         0.15702662, 0.13205731, 0.26236066, 0.15563554]], dtype=float32),\n",
       " array([[0.13107352, 0.8270751 , 0.18428375, 0.14244588, 0.13752803,\n",
       "         0.11175636, 0.08143761, 0.09463919, 0.7956052 , 0.5610841 ,\n",
       "         0.16597614, 0.12894842, 0.26931602, 0.15659662]], dtype=float32),\n",
       " array([[0.13366449, 0.82040375, 0.11449246, 0.12284017, 0.12124433,\n",
       "         0.08150416, 0.09182947, 0.10110971, 0.7504124 , 0.5627068 ,\n",
       "         0.19731015, 0.07197609, 0.27561712, 0.14503434]], dtype=float32),\n",
       " array([[0.18066196, 0.8002483 , 0.05770677, 0.12738334, 0.12038232,\n",
       "         0.04740125, 0.10531621, 0.10880408, 0.7155565 , 0.57221246,\n",
       "         0.21856904, 0.02926616, 0.27587542, 0.1348431 ]], dtype=float32),\n",
       " array([[0.15781337, 0.8121912 , 0.06168541, 0.10906398, 0.11109282,\n",
       "         0.04514124, 0.11838719, 0.10791498, 0.74778646, 0.5729536 ,\n",
       "         0.19247384, 0.03322566, 0.26648548, 0.14186421]], dtype=float32),\n",
       " array([[0.21258518, 0.7928599 , 0.03292593, 0.12436529, 0.11460596,\n",
       "         0.02978083, 0.11495741, 0.11293872, 0.71676064, 0.5807328 ,\n",
       "         0.22107403, 0.01410345, 0.26718813, 0.12943405]], dtype=float32),\n",
       " array([[0.19358669, 0.80088896, 0.04368068, 0.1184039 , 0.11459967,\n",
       "         0.03426923, 0.11210871, 0.1119599 , 0.74410003, 0.57796   ,\n",
       "         0.1984078 , 0.02053218, 0.26451758, 0.13882726]], dtype=float32),\n",
       " array([[0.19773205, 0.7978292 , 0.04907501, 0.12520194, 0.11791018,\n",
       "         0.03767933, 0.09587798, 0.11210223, 0.7446403 , 0.5746874 ,\n",
       "         0.19873457, 0.02347941, 0.26786724, 0.1413916 ]], dtype=float32),\n",
       " array([[0.21751511, 0.781952  , 0.02968158, 0.10867991, 0.10464023,\n",
       "         0.02496216, 0.10598575, 0.12208095, 0.6983778 , 0.57518095,\n",
       "         0.22177488, 0.01305517, 0.27748793, 0.13750955]], dtype=float32),\n",
       " array([[0.2391164 , 0.7751464 , 0.02442218, 0.11419448, 0.10916544,\n",
       "         0.02176898, 0.11158367, 0.12316323, 0.67332375, 0.5789426 ,\n",
       "         0.231997  , 0.01011467, 0.28006488, 0.13045128]], dtype=float32),\n",
       " array([[0.20234804, 0.7943458 , 0.03153765, 0.10781484, 0.10692886,\n",
       "         0.02628573, 0.11442427, 0.11825278, 0.7113651 , 0.5783787 ,\n",
       "         0.21029617, 0.01419327, 0.26908848, 0.1346238 ]], dtype=float32),\n",
       " array([[0.2786107 , 0.7690242 , 0.02465979, 0.14070494, 0.12545171,\n",
       "         0.02221017, 0.10210372, 0.12039699, 0.6807204 , 0.58249944,\n",
       "         0.22774178, 0.00964808, 0.27819481, 0.12844718]], dtype=float32),\n",
       " array([[0.27829525, 0.7684187 , 0.00809339, 0.10895709, 0.0965592 ,\n",
       "         0.00986027, 0.12767403, 0.11894643, 0.64201677, 0.5970079 ,\n",
       "         0.25459057, 0.00253606, 0.25915778, 0.10110123]], dtype=float32),\n",
       " array([[0.2562907 , 0.7805607 , 0.01338243, 0.11455518, 0.10548086,\n",
       "         0.01432387, 0.12670746, 0.11754914, 0.6656595 , 0.5914698 ,\n",
       "         0.23622826, 0.00472503, 0.2641491 , 0.11115699]], dtype=float32),\n",
       " array([[0.25116253, 0.78395665, 0.02447714, 0.13183972, 0.11908291,\n",
       "         0.02260722, 0.1185746 , 0.1151689 , 0.6883996 , 0.5836211 ,\n",
       "         0.22170906, 0.00975731, 0.27422935, 0.12445436]], dtype=float32),\n",
       " array([[0.262445  , 0.7777088 , 0.01810356, 0.1271321 , 0.11729703,\n",
       "         0.01894418, 0.16425669, 0.1161674 , 0.63560605, 0.5878325 ,\n",
       "         0.24825768, 0.00681988, 0.28406912, 0.11496175]], dtype=float32),\n",
       " array([[0.32849926, 0.7494098 , 0.00303714, 0.10701698, 0.09349658,\n",
       "         0.00535066, 0.23139964, 0.11638477, 0.5000649 , 0.6132028 ,\n",
       "         0.3282724 , 0.00077011, 0.27056   , 0.07356831]], dtype=float32),\n",
       " array([[0.32666215, 0.750085  , 0.0056893 , 0.12337562, 0.10206553,\n",
       "         0.00827618, 0.23782855, 0.11095025, 0.5308839 , 0.6049103 ,\n",
       "         0.30420554, 0.00164554, 0.28317258, 0.08334426]], dtype=float32),\n",
       " array([[0.31785408, 0.7615424 , 0.00828537, 0.12313644, 0.1082482 ,\n",
       "         0.009615  , 0.2479823 , 0.11168409, 0.5943984 , 0.6021257 ,\n",
       "         0.25555444, 0.00263485, 0.28067777, 0.09782843]], dtype=float32),\n",
       " array([[0.27476957, 0.78592795, 0.01680996, 0.12558003, 0.11288542,\n",
       "         0.01665036, 0.2011266 , 0.11663176, 0.67826194, 0.58857477,\n",
       "         0.22198103, 0.00623005, 0.27939528, 0.12620912]], dtype=float32),\n",
       " array([[0.1923071 , 0.825298  , 0.03865645, 0.10887462, 0.1090588 ,\n",
       "         0.02897671, 0.18731765, 0.11458169, 0.7900586 , 0.5783888 ,\n",
       "         0.1633078 , 0.01817407, 0.26223138, 0.16253108]], dtype=float32),\n",
       " array([[0.1922239 , 0.8223831 , 0.04644259, 0.11281087, 0.11008835,\n",
       "         0.03237513, 0.1878948 , 0.11195459, 0.7975061 , 0.575963  ,\n",
       "         0.15824078, 0.02277469, 0.2655118 , 0.16765252]], dtype=float32),\n",
       " array([[0.24622306, 0.7963228 , 0.05993468, 0.14227065, 0.13619888,\n",
       "         0.03769585, 0.18327354, 0.11605369, 0.7557116 , 0.5717181 ,\n",
       "         0.16937529, 0.03047054, 0.29509825, 0.17436628]], dtype=float32),\n",
       " array([[0.24978817, 0.7916873 , 0.04285526, 0.14149837, 0.13156195,\n",
       "         0.03199762, 0.22322504, 0.1108912 , 0.71710235, 0.57881176,\n",
       "         0.19396523, 0.02000855, 0.29510152, 0.15030363]], dtype=float32),\n",
       " array([[0.20477544, 0.8042465 , 0.0354548 , 0.11470994, 0.11071768,\n",
       "         0.02748282, 0.23759688, 0.10468585, 0.7242405 , 0.5828267 ,\n",
       "         0.18982582, 0.01665587, 0.27930218, 0.13621181]], dtype=float32),\n",
       " array([[0.20863433, 0.8080274 , 0.01950625, 0.1022779 , 0.09588066,\n",
       "         0.01672583, 0.25299665, 0.10123296, 0.7479276 , 0.59383005,\n",
       "         0.18162821, 0.00791065, 0.25558951, 0.12360793]], dtype=float32),\n",
       " array([[0.23910032, 0.7956814 , 0.00922652, 0.10214638, 0.09054946,\n",
       "         0.01066407, 0.26559398, 0.10244469, 0.68927264, 0.6031987 ,\n",
       "         0.22219324, 0.00308272, 0.25330484, 0.10133691]], dtype=float32),\n",
       " array([[0.22298244, 0.7935765 , 0.00283803, 0.06564297, 0.06334277,\n",
       "         0.00432992, 0.2958285 , 0.1095917 , 0.62239   , 0.6132551 ,\n",
       "         0.2552927 , 0.00079845, 0.23977423, 0.0813262 ]], dtype=float32),\n",
       " array([[0.23978068, 0.7841416 , 0.00550441, 0.09289201, 0.07831436,\n",
       "         0.00854507, 0.31345704, 0.10354232, 0.57591516, 0.6034539 ,\n",
       "         0.29025403, 0.00169361, 0.26901022, 0.08300246]], dtype=float32),\n",
       " array([[0.25565994, 0.78535503, 0.0092527 , 0.1141262 , 0.09798548,\n",
       "         0.01278584, 0.2911345 , 0.10563014, 0.5837217 , 0.59799194,\n",
       "         0.27907556, 0.00307562, 0.2820762 , 0.09291275]], dtype=float32),\n",
       " array([[0.23487937, 0.8006857 , 0.01536964, 0.11977877, 0.10686405,\n",
       "         0.01779076, 0.29954872, 0.10265952, 0.6460957 , 0.59522295,\n",
       "         0.24062626, 0.00568323, 0.27766675, 0.10550079]], dtype=float32),\n",
       " array([[0.25423598, 0.7910917 , 0.02119811, 0.12611383, 0.11308201,\n",
       "         0.01992583, 0.23281842, 0.11359646, 0.6806945 , 0.58756536,\n",
       "         0.2152813 , 0.0081629 , 0.28165382, 0.12508322]], dtype=float32),\n",
       " array([[0.26111302, 0.7909807 , 0.0463977 , 0.14471121, 0.13542302,\n",
       "         0.03213633, 0.19981782, 0.11313434, 0.7149404 , 0.57576495,\n",
       "         0.18541971, 0.02209375, 0.29942378, 0.15541303]], dtype=float32),\n",
       " array([[0.24015273, 0.797668  , 0.07789083, 0.15229183, 0.14754412,\n",
       "         0.04669307, 0.1536881 , 0.11469968, 0.74328274, 0.5693505 ,\n",
       "         0.16856097, 0.04216242, 0.29788393, 0.17031102]], dtype=float32),\n",
       " array([[0.24385281, 0.7978544 , 0.0598537 , 0.15001532, 0.14002675,\n",
       "         0.04017378, 0.17846993, 0.11145625, 0.7415162 , 0.57347536,\n",
       "         0.17826836, 0.02994038, 0.29450986, 0.16190384]], dtype=float32),\n",
       " array([[0.21959403, 0.8050311 , 0.04926911, 0.13438383, 0.12720974,\n",
       "         0.03438075, 0.1579358 , 0.10846752, 0.7532728 , 0.57878965,\n",
       "         0.17372529, 0.02382379, 0.27442005, 0.14805917]], dtype=float32),\n",
       " array([[0.20010045, 0.8096962 , 0.04862916, 0.11866228, 0.11263718,\n",
       "         0.03102734, 0.12603295, 0.106691  , 0.7840176 , 0.5776913 ,\n",
       "         0.15615767, 0.02421077, 0.25980183, 0.15059215]], dtype=float32),\n",
       " array([[0.16209714, 0.8239974 , 0.07016401, 0.1091526 , 0.10824501,\n",
       "         0.04041491, 0.11891525, 0.10186657, 0.81086236, 0.5736335 ,\n",
       "         0.14167444, 0.03974917, 0.25354105, 0.15794915]], dtype=float32),\n",
       " array([[0.15985703, 0.8234131 , 0.05821541, 0.10739175, 0.10479781,\n",
       "         0.03927606, 0.15020482, 0.09826163, 0.78048885, 0.5747337 ,\n",
       "         0.165116  , 0.031855  , 0.26278806, 0.14659311]], dtype=float32),\n",
       " array([[0.1615864 , 0.8181047 , 0.07485549, 0.12820993, 0.1191337 ,\n",
       "         0.05463403, 0.12196718, 0.09948467, 0.752949  , 0.57269603,\n",
       "         0.18598486, 0.04090815, 0.26883954, 0.13727604]], dtype=float32),\n",
       " array([[0.18901397, 0.80453354, 0.05949092, 0.14172548, 0.130085  ,\n",
       "         0.04776391, 0.11312791, 0.10413816, 0.7111003 , 0.57693344,\n",
       "         0.20652123, 0.02933417, 0.27379066, 0.12557909]], dtype=float32),\n",
       " array([[0.1945396 , 0.8011408 , 0.05130195, 0.1341743 , 0.12326994,\n",
       "         0.04123731, 0.1120271 , 0.10809907, 0.71292156, 0.5769192 ,\n",
       "         0.20606215, 0.02443727, 0.27288324, 0.12797098]], dtype=float32),\n",
       " array([[0.20341873, 0.8000903 , 0.02317467, 0.10938911, 0.1049751 ,\n",
       "         0.02254269, 0.15571491, 0.10983738, 0.68082076, 0.5860405 ,\n",
       "         0.22491515, 0.00959629, 0.2684575 , 0.11603171]], dtype=float32),\n",
       " array([[0.22435859, 0.7924617 , 0.00771419, 0.09283923, 0.08562636,\n",
       "         0.01020556, 0.20815772, 0.10821722, 0.6368453 , 0.6007056 ,\n",
       "         0.25573972, 0.00252347, 0.25615284, 0.09281983]], dtype=float32),\n",
       " array([[0.27717862, 0.7742417 , 0.00616034, 0.10935789, 0.09380222,\n",
       "         0.00899915, 0.26952443, 0.10682338, 0.584875  , 0.6041613 ,\n",
       "         0.28396323, 0.00184759, 0.2733753 , 0.08770555]], dtype=float32),\n",
       " array([[0.25132   , 0.79259574, 0.01284891, 0.11986236, 0.1090168 ,\n",
       "         0.01469123, 0.24398567, 0.10504622, 0.65302837, 0.59882975,\n",
       "         0.23682618, 0.00451377, 0.2695287 , 0.10305471]], dtype=float32),\n",
       " array([[0.2553239 , 0.78698754, 0.01429669, 0.11731621, 0.10555321,\n",
       "         0.0159562 , 0.2346207 , 0.1114451 , 0.6445492 , 0.58996516,\n",
       "         0.24440826, 0.00519738, 0.28442276, 0.11421126]], dtype=float32),\n",
       " array([[0.25426856, 0.7799917 , 0.00630378, 0.09206275, 0.08359271,\n",
       "         0.00818896, 0.25051016, 0.11009451, 0.6089572 , 0.59866107,\n",
       "         0.25932726, 0.00200871, 0.27348456, 0.09542423]], dtype=float32),\n",
       " array([[2.9812878e-01, 7.5740713e-01, 1.5718663e-03, 7.6122418e-02,\n",
       "         6.8325758e-02, 3.0118134e-03, 3.3058524e-01, 1.1120677e-01,\n",
       "         4.8765135e-01, 6.1808276e-01, 3.2559887e-01, 3.7937859e-04,\n",
       "         2.6506454e-01, 6.6926576e-02]], dtype=float32),\n",
       " array([[3.45167667e-01, 7.42054284e-01, 1.67076301e-03, 9.04986262e-02,\n",
       "         7.29474798e-02, 3.16451513e-03, 3.30789536e-01, 1.07347615e-01,\n",
       "         4.70587075e-01, 6.14987910e-01, 3.36323410e-01, 4.05445840e-04,\n",
       "         2.78815418e-01, 6.84595406e-02]], dtype=float32),\n",
       " array([[0.2948565 , 0.77557886, 0.00607739, 0.11114573, 0.09619686,\n",
       "         0.00836802, 0.27810585, 0.10672691, 0.5748281 , 0.6028915 ,\n",
       "         0.27226862, 0.0018773 , 0.2790764 , 0.09029592]], dtype=float32),\n",
       " array([[0.23844197, 0.80288714, 0.01462492, 0.10864813, 0.10037886,\n",
       "         0.01456848, 0.2067193 , 0.10684785, 0.68939525, 0.59107035,\n",
       "         0.20814513, 0.0055673 , 0.26785952, 0.11662708]], dtype=float32),\n",
       " array([[0.24798587, 0.8018751 , 0.02425859, 0.13404904, 0.11673164,\n",
       "         0.021961  , 0.17759468, 0.10514641, 0.71530426, 0.5860103 ,\n",
       "         0.19870737, 0.00979116, 0.27183533, 0.12659925]], dtype=float32),\n",
       " array([[0.21183482, 0.8189959 , 0.03193218, 0.11856189, 0.11021281,\n",
       "         0.02496053, 0.18315718, 0.1042709 , 0.77085775, 0.5821852 ,\n",
       "         0.16870524, 0.01432329, 0.26359728, 0.14454687]], dtype=float32),\n",
       " array([[0.2320096 , 0.8094567 , 0.06350742, 0.15801771, 0.14460206,\n",
       "         0.04550925, 0.17834282, 0.1080987 , 0.7527914 , 0.57434314,\n",
       "         0.1771436 , 0.03162432, 0.28804728, 0.15857808]], dtype=float32),\n",
       " array([[0.23352548, 0.8077203 , 0.08072775, 0.16695654, 0.1545404 ,\n",
       "         0.05317945, 0.17794764, 0.11326056, 0.76921654, 0.57331127,\n",
       "         0.1667997 , 0.04100432, 0.28738064, 0.16854747]], dtype=float32),\n",
       " array([[0.22873707, 0.80241066, 0.06126473, 0.14881071, 0.139208  ,\n",
       "         0.04205235, 0.20294696, 0.11198337, 0.74923223, 0.5767428 ,\n",
       "         0.17520031, 0.02990633, 0.2863845 , 0.15629904]], dtype=float32),\n",
       " array([[0.17022368, 0.83087766, 0.05517661, 0.10886407, 0.10991628,\n",
       "         0.03386189, 0.20690762, 0.10238895, 0.82347006, 0.5816719 ,\n",
       "         0.13590544, 0.02853646, 0.25078732, 0.1602858 ]], dtype=float32),\n",
       " array([[0.18144196, 0.82108545, 0.07415581, 0.12546268, 0.12027805,\n",
       "         0.04338771, 0.16879094, 0.10190184, 0.8145938 , 0.57627136,\n",
       "         0.14136544, 0.04036235, 0.2606365 , 0.16361386]], dtype=float32),\n",
       " array([[0.21013644, 0.80500984, 0.04050434, 0.12353756, 0.11794087,\n",
       "         0.0295381 , 0.21037814, 0.10610706, 0.7531429 , 0.58410114,\n",
       "         0.17573388, 0.01865927, 0.26943928, 0.14038469]], dtype=float32),\n",
       " array([[0.17716894, 0.8143957 , 0.06135637, 0.12843683, 0.12309461,\n",
       "         0.04533707, 0.19450948, 0.10506406, 0.75193584, 0.58024174,\n",
       "         0.18203627, 0.03055108, 0.26936233, 0.13806131]], dtype=float32),\n",
       " array([[0.17240338, 0.8138602 , 0.03588228, 0.10737696, 0.10287921,\n",
       "         0.03094405, 0.26074114, 0.10315242, 0.72981507, 0.5855005 ,\n",
       "         0.19937406, 0.01637671, 0.26747504, 0.12666033]], dtype=float32),\n",
       " array([[0.18532513, 0.8098436 , 0.02197124, 0.09578156, 0.09454701,\n",
       "         0.02090366, 0.28838953, 0.10329673, 0.69914585, 0.58875495,\n",
       "         0.21356964, 0.00940999, 0.27184564, 0.12025145]], dtype=float32),\n",
       " array([[0.1946748 , 0.8077872 , 0.01784162, 0.09801228, 0.09441771,\n",
       "         0.01804068, 0.27183253, 0.10301665, 0.6981285 , 0.5931887 ,\n",
       "         0.21575163, 0.0071494 , 0.2639661 , 0.11316915]], dtype=float32),\n",
       " array([[0.2169445 , 0.8008867 , 0.01048757, 0.09652517, 0.09034023,\n",
       "         0.01283821, 0.2994167 , 0.10406394, 0.6604314 , 0.5990148 ,\n",
       "         0.24203098, 0.00368906, 0.26471472, 0.10239342]], dtype=float32),\n",
       " array([[0.22419204, 0.7917808 , 0.00481926, 0.07378884, 0.07086904,\n",
       "         0.00654217, 0.35824198, 0.10487104, 0.61836517, 0.60529023,\n",
       "         0.2560486 , 0.00154812, 0.26196498, 0.091526  ]], dtype=float32),\n",
       " array([[0.2909889 , 0.7626052 , 0.0038493 , 0.09617966, 0.08139101,\n",
       "         0.00620177, 0.3188384 , 0.10823978, 0.53397316, 0.60621876,\n",
       "         0.30810362, 0.00108935, 0.27925336, 0.08132371]], dtype=float32),\n",
       " array([[3.12762558e-01, 7.47722983e-01, 1.38931617e-03, 7.41433352e-02,\n",
       "         6.45124912e-02, 2.73692235e-03, 3.40898097e-01, 1.14405796e-01,\n",
       "         4.63500500e-01, 6.15216792e-01, 3.40546012e-01, 3.32194846e-04,\n",
       "         2.72862583e-01, 6.77925050e-02]], dtype=float32),\n",
       " array([[0.26512334, 0.7768788 , 0.00735766, 0.09861251, 0.08995054,\n",
       "         0.00888584, 0.27098218, 0.10801643, 0.58422446, 0.5996793 ,\n",
       "         0.2561736 , 0.00246017, 0.2772813 , 0.09289153]], dtype=float32),\n",
       " array([[3.0293450e-01, 7.6741022e-01, 1.2552955e-03, 6.8688147e-02,\n",
       "         6.3358501e-02, 2.4133562e-03, 3.5799718e-01, 1.1738543e-01,\n",
       "         5.2068186e-01, 6.1781055e-01, 3.0523601e-01, 2.9394004e-04,\n",
       "         2.5911856e-01, 7.3602967e-02]], dtype=float32),\n",
       " array([[0.31673566, 0.7659719 , 0.00318708, 0.09065684, 0.07987217,\n",
       "         0.00461372, 0.30669397, 0.11564797, 0.56459713, 0.60634416,\n",
       "         0.27125716, 0.00088398, 0.27363166, 0.08957792]], dtype=float32),\n",
       " array([[0.31411827, 0.7709228 , 0.00835977, 0.11860794, 0.10079562,\n",
       "         0.00958164, 0.25965786, 0.11256547, 0.6092685 , 0.5951432 ,\n",
       "         0.24412447, 0.00273748, 0.2859427 , 0.10640566]], dtype=float32),\n",
       " array([[0.3135632 , 0.77453905, 0.01135158, 0.12322254, 0.10862587,\n",
       "         0.01171708, 0.20545718, 0.11956485, 0.6315506 , 0.5891059 ,\n",
       "         0.23077938, 0.00393587, 0.28805423, 0.1195616 ]], dtype=float32),\n",
       " array([[0.27472445, 0.78915584, 0.04704281, 0.15446691, 0.14331283,\n",
       "         0.03139393, 0.1618161 , 0.11284356, 0.7042221 , 0.5759662 ,\n",
       "         0.17910573, 0.02243293, 0.2958875 , 0.14891137]], dtype=float32),\n",
       " array([[0.23779924, 0.80765206, 0.04349317, 0.14765766, 0.1319854 ,\n",
       "         0.03271917, 0.17629546, 0.10508576, 0.7431512 , 0.5800554 ,\n",
       "         0.17636177, 0.01994891, 0.27704084, 0.14244017]], dtype=float32),\n",
       " array([[0.21424857, 0.8184459 , 0.14314647, 0.16415735, 0.1641222 ,\n",
       "         0.06913959, 0.1664312 , 0.10627985, 0.8095769 , 0.5663436 ,\n",
       "         0.12829822, 0.09158113, 0.28905958, 0.19496173]], dtype=float32),\n",
       " array([[0.20025025, 0.822892  , 0.15580726, 0.16842829, 0.1580089 ,\n",
       "         0.07860932, 0.16561142, 0.10089882, 0.8283636 , 0.56598425,\n",
       "         0.12842904, 0.09991308, 0.28154194, 0.1940057 ]], dtype=float32),\n",
       " array([[0.18160124, 0.82608813, 0.18976453, 0.16703495, 0.16269818,\n",
       "         0.1010366 , 0.17698818, 0.1025813 , 0.81307477, 0.561722  ,\n",
       "         0.14045814, 0.1304806 , 0.29208314, 0.19669929]], dtype=float32),\n",
       " array([[0.18116966, 0.8257992 , 0.08518503, 0.13782492, 0.13311225,\n",
       "         0.05203717, 0.22451058, 0.09676881, 0.80588657, 0.5777015 ,\n",
       "         0.14642175, 0.04768552, 0.26875234, 0.16149935]], dtype=float32),\n",
       " array([[0.15465286, 0.8337079 , 0.09280875, 0.13534488, 0.12782396,\n",
       "         0.06344305, 0.22606489, 0.09181483, 0.7957827 , 0.5769579 ,\n",
       "         0.16084109, 0.05329145, 0.26677313, 0.1490053 ]], dtype=float32),\n",
       " array([[0.15941392, 0.8294908 , 0.08665867, 0.12487067, 0.12369691,\n",
       "         0.05330197, 0.18561928, 0.09674356, 0.80665904, 0.5766495 ,\n",
       "         0.14830865, 0.04974937, 0.26122156, 0.15571758]], dtype=float32),\n",
       " array([[0.13672173, 0.83833003, 0.09062296, 0.12771285, 0.11915231,\n",
       "         0.0667187 , 0.21699777, 0.08895765, 0.7969865 , 0.5776151 ,\n",
       "         0.16889659, 0.05173667, 0.2597128 , 0.14099045]], dtype=float32),\n",
       " array([[0.15571272, 0.8250292 , 0.0659055 , 0.12333386, 0.11565589,\n",
       "         0.05238004, 0.23076269, 0.09479452, 0.7601523 , 0.5777606 ,\n",
       "         0.18995127, 0.03492248, 0.2718763 , 0.13783048]], dtype=float32),\n",
       " array([[0.1681795 , 0.81890917, 0.02553375, 0.10276376, 0.09924536,\n",
       "         0.02583729, 0.23932357, 0.09865559, 0.7170493 , 0.5902562 ,\n",
       "         0.21468112, 0.0109573 , 0.25848442, 0.11336128]], dtype=float32),\n",
       " array([[0.21486066, 0.79633373, 0.03102006, 0.13063616, 0.11758988,\n",
       "         0.03166429, 0.2641554 , 0.10311731, 0.66054624, 0.58349943,\n",
       "         0.24518049, 0.01344009, 0.29235378, 0.12029705]], dtype=float32),\n",
       " array([[0.20248221, 0.807799  , 0.03432167, 0.12115805, 0.11682653,\n",
       "         0.03021434, 0.21760137, 0.10595632, 0.71376544, 0.58412236,\n",
       "         0.20699438, 0.015413  , 0.27497804, 0.13006249]], dtype=float32),\n",
       " array([[0.2156255 , 0.8017397 , 0.02854922, 0.12731095, 0.11519454,\n",
       "         0.02824971, 0.1920798 , 0.10682284, 0.6985691 , 0.5842129 ,\n",
       "         0.22536485, 0.0119288 , 0.27534792, 0.12405011]], dtype=float32),\n",
       " array([[0.24609677, 0.79789084, 0.02678417, 0.13876775, 0.12222992,\n",
       "         0.02501829, 0.19860923, 0.10621208, 0.7259179 , 0.5871578 ,\n",
       "         0.20826319, 0.01066342, 0.27299106, 0.13024636]], dtype=float32),\n",
       " array([[0.29236525, 0.76858854, 0.01023861, 0.1265494 , 0.11569748,\n",
       "         0.01195399, 0.20087662, 0.11032434, 0.60286736, 0.6016598 ,\n",
       "         0.25692466, 0.00333779, 0.27346933, 0.09497997]], dtype=float32),\n",
       " array([[0.29624712, 0.7575208 , 0.01578012, 0.13224456, 0.11539194,\n",
       "         0.01625943, 0.15651648, 0.11302111, 0.58806354, 0.58644086,\n",
       "         0.26330996, 0.00591069, 0.29615253, 0.10824851]], dtype=float32),\n",
       " array([[0.22478352, 0.7966693 , 0.02902832, 0.12231667, 0.11492199,\n",
       "         0.02566573, 0.12622394, 0.11712651, 0.70144105, 0.5800511 ,\n",
       "         0.21105264, 0.01228596, 0.2722237 , 0.13077524]], dtype=float32),\n",
       " array([[0.25230452, 0.78780085, 0.03167609, 0.13937315, 0.1258819 ,\n",
       "         0.02720366, 0.09929247, 0.12198383, 0.70539564, 0.57799196,\n",
       "         0.20953429, 0.01303234, 0.27461132, 0.13595769]], dtype=float32),\n",
       " array([[0.2469345 , 0.7894137 , 0.01111193, 0.10061545, 0.09323295,\n",
       "         0.01149795, 0.15566202, 0.11509947, 0.69011015, 0.5929469 ,\n",
       "         0.21654771, 0.00389832, 0.2566776 , 0.11370062]], dtype=float32),\n",
       " array([[0.22293057, 0.7960407 , 0.01367942, 0.09329031, 0.08942284,\n",
       "         0.01263181, 0.11996646, 0.11639169, 0.7132647 , 0.58814216,\n",
       "         0.19842115, 0.00521182, 0.25090283, 0.1196236 ]], dtype=float32),\n",
       " array([[0.27066892, 0.7788654 , 0.02901707, 0.13988721, 0.12497745,\n",
       "         0.02447161, 0.14352855, 0.11216883, 0.6702931 , 0.578427  ,\n",
       "         0.21822438, 0.0125065 , 0.29286876, 0.13254854]], dtype=float32),\n",
       " array([[0.26811185, 0.76735413, 0.01110001, 0.11123649, 0.0987669 ,\n",
       "         0.0122826 , 0.18227984, 0.1107772 , 0.59240544, 0.5921698 ,\n",
       "         0.2578722 , 0.00395481, 0.28117698, 0.09901118]], dtype=float32),\n",
       " array([[0.27358523, 0.7681412 , 0.01089549, 0.12023771, 0.10325931,\n",
       "         0.01282629, 0.16490725, 0.11275876, 0.59550786, 0.5943145 ,\n",
       "         0.26220024, 0.00366565, 0.27482873, 0.09525479]], dtype=float32),\n",
       " array([[0.24310686, 0.79665446, 0.01741854, 0.11858072, 0.10517678,\n",
       "         0.01683769, 0.19392934, 0.10683236, 0.70534295, 0.5906079 ,\n",
       "         0.20676216, 0.00664076, 0.2646428 , 0.11881676]], dtype=float32),\n",
       " array([[0.25022897, 0.79505444, 0.02739806, 0.13422251, 0.11941887,\n",
       "         0.0234261 , 0.18876618, 0.10940794, 0.7174287 , 0.5845451 ,\n",
       "         0.19743115, 0.01133914, 0.27522495, 0.13312435]], dtype=float32),\n",
       " array([[0.22057025, 0.8094737 , 0.03602975, 0.12363764, 0.11551768,\n",
       "         0.02864079, 0.19184141, 0.11216422, 0.75352514, 0.57807785,\n",
       "         0.18270135, 0.01638196, 0.27477005, 0.15240687]], dtype=float32),\n",
       " array([[0.20472343, 0.80749404, 0.03029922, 0.1121606 , 0.10531839,\n",
       "         0.02615429, 0.21910876, 0.10924145, 0.72201616, 0.58064026,\n",
       "         0.19951947, 0.01361239, 0.2751236 , 0.13733953]], dtype=float32),\n",
       " array([[0.21362081, 0.80685234, 0.03883826, 0.1216509 , 0.1142627 ,\n",
       "         0.02988565, 0.21936023, 0.1087774 , 0.741204  , 0.5791433 ,\n",
       "         0.18464272, 0.01828877, 0.27739155, 0.14733078]], dtype=float32),\n",
       " array([[0.23940605, 0.7757747 , 0.00700385, 0.0776851 , 0.07287826,\n",
       "         0.00758201, 0.24365672, 0.11421874, 0.631629  , 0.5944747 ,\n",
       "         0.23558894, 0.00245808, 0.26740986, 0.10463098]], dtype=float32),\n",
       " array([[0.24499142, 0.7789236 , 0.01048045, 0.09626234, 0.08674057,\n",
       "         0.01086194, 0.21397957, 0.10920894, 0.64283943, 0.5928171 ,\n",
       "         0.23069085, 0.00382662, 0.270045  , 0.10538025]], dtype=float32),\n",
       " array([[0.19531825, 0.8240375 , 0.03704016, 0.12148225, 0.11592741,\n",
       "         0.02994244, 0.23468782, 0.10269313, 0.7720338 , 0.58548003,\n",
       "         0.1715094 , 0.01696039, 0.26029652, 0.14142975]], dtype=float32),\n",
       " array([[0.20489612, 0.8237562 , 0.04559708, 0.13555752, 0.12468428,\n",
       "         0.03629772, 0.20883216, 0.10492606, 0.7865603 , 0.5808971 ,\n",
       "         0.1701269 , 0.02120868, 0.26432943, 0.1534392 ]], dtype=float32),\n",
       " array([[0.2149734 , 0.815777  , 0.05604639, 0.148842  , 0.1365007 ,\n",
       "         0.0430251 , 0.20265836, 0.10458429, 0.7653188 , 0.5780652 ,\n",
       "         0.17820159, 0.02713928, 0.2774417 , 0.15297987]], dtype=float32),\n",
       " array([[0.21026301, 0.8199714 , 0.09898864, 0.1830217 , 0.16699654,\n",
       "         0.07230292, 0.18332529, 0.10072765, 0.76655537, 0.57433456,\n",
       "         0.17824893, 0.05325129, 0.2855668 , 0.15683685]], dtype=float32),\n",
       " array([[0.21795326, 0.8066299 , 0.07045097, 0.15675603, 0.14594318,\n",
       "         0.05112068, 0.1604967 , 0.10851323, 0.74291486, 0.5738947 ,\n",
       "         0.18563992, 0.03590126, 0.2854981 , 0.15271227]], dtype=float32),\n",
       " array([[0.2230176 , 0.8057209 , 0.04477261, 0.14569914, 0.13226338,\n",
       "         0.03672885, 0.18581282, 0.10554719, 0.7368553 , 0.5812515 ,\n",
       "         0.1942242 , 0.02043326, 0.27631128, 0.13916773]], dtype=float32),\n",
       " array([[0.23800091, 0.7972062 , 0.0344414 , 0.14632308, 0.13038439,\n",
       "         0.03033996, 0.18260705, 0.10552118, 0.71312904, 0.5851972 ,\n",
       "         0.20630252, 0.01463022, 0.2758373 , 0.12793256]], dtype=float32),\n",
       " array([[0.24064237, 0.7971346 , 0.01445485, 0.11978953, 0.10805786,\n",
       "         0.01546093, 0.2383477 , 0.09894025, 0.68536943, 0.596983  ,\n",
       "         0.2197653 , 0.00527269, 0.26697186, 0.10627276]], dtype=float32),\n",
       " array([[0.1839111 , 0.814768  , 0.02693847, 0.10168201, 0.09986663,\n",
       "         0.02267475, 0.17937751, 0.10497118, 0.7423212 , 0.5872968 ,\n",
       "         0.18536785, 0.01189782, 0.2532749 , 0.12498274]], dtype=float32),\n",
       " array([[0.20016634, 0.813979  , 0.05416904, 0.13836502, 0.12858243,\n",
       "         0.04262882, 0.18108913, 0.10183109, 0.7455565 , 0.5776874 ,\n",
       "         0.18982714, 0.02695024, 0.27692693, 0.1430013 ]], dtype=float32),\n",
       " array([[0.1825142 , 0.8095882 , 0.03700466, 0.10675641, 0.10146224,\n",
       "         0.03015202, 0.17069452, 0.10979469, 0.7367754 , 0.5775458 ,\n",
       "         0.1944876 , 0.01737581, 0.26830357, 0.13776289]], dtype=float32),\n",
       " array([[0.1892344 , 0.8045731 , 0.03221245, 0.10347529, 0.1007231 ,\n",
       "         0.02586386, 0.15813173, 0.11228666, 0.7291615 , 0.5792464 ,\n",
       "         0.19274123, 0.01473721, 0.2667913 , 0.1346317 ]], dtype=float32),\n",
       " array([[0.20850237, 0.80102813, 0.042975  , 0.12331963, 0.11763532,\n",
       "         0.03279395, 0.13837443, 0.11257481, 0.731367  , 0.5758394 ,\n",
       "         0.19209968, 0.02044338, 0.27568775, 0.14323515]], dtype=float32),\n",
       " array([[0.22116792, 0.7969143 , 0.05099899, 0.13291994, 0.12643698,\n",
       "         0.03650808, 0.15058391, 0.11233437, 0.7307517 , 0.5738912 ,\n",
       "         0.18895775, 0.02508328, 0.28508827, 0.15044619]], dtype=float32),\n",
       " array([[0.22590216, 0.7890728 , 0.01592981, 0.10326324, 0.09751844,\n",
       "         0.01557587, 0.1697663 , 0.11135171, 0.6755057 , 0.5898279 ,\n",
       "         0.22186905, 0.00613374, 0.26553768, 0.11277036]], dtype=float32),\n",
       " array([[0.21899429, 0.7959756 , 0.02496195, 0.11453526, 0.10852282,\n",
       "         0.02172706, 0.14130752, 0.10976834, 0.7034161 , 0.58484703,\n",
       "         0.20568499, 0.01054054, 0.26672772, 0.12260556]], dtype=float32),\n",
       " array([[0.2221382 , 0.7991629 , 0.03207304, 0.12577295, 0.11471491,\n",
       "         0.02618684, 0.14232925, 0.10742314, 0.73245615, 0.5823957 ,\n",
       "         0.19343498, 0.01397766, 0.26729774, 0.13173851]], dtype=float32),\n",
       " array([[0.22754538, 0.78752935, 0.01136885, 0.0959798 , 0.09053187,\n",
       "         0.01240666, 0.19347854, 0.11011557, 0.6496652 , 0.59427303,\n",
       "         0.2370298 , 0.00413159, 0.26374024, 0.10374947]], dtype=float32),\n",
       " array([[0.19659637, 0.8058252 , 0.02556828, 0.10463982, 0.10037885,\n",
       "         0.02287853, 0.1777228 , 0.10648685, 0.7076888 , 0.5839331 ,\n",
       "         0.20698465, 0.01130742, 0.26668274, 0.12428637]], dtype=float32),\n",
       " array([[0.22814995, 0.7851264 , 0.01217574, 0.09835654, 0.09388413,\n",
       "         0.0130091 , 0.2137408 , 0.11250944, 0.6402441 , 0.5959956 ,\n",
       "         0.2359914 , 0.00441258, 0.26398024, 0.10226963]], dtype=float32),\n",
       " array([[2.5977388e-01, 7.5737673e-01, 1.9624261e-03, 6.4161569e-02,\n",
       "         6.0117695e-02, 3.1719441e-03, 2.3772581e-01, 1.1429952e-01,\n",
       "         5.1549071e-01, 6.1207622e-01, 3.0147511e-01, 5.2488741e-04,\n",
       "         2.5420624e-01, 7.0130728e-02]], dtype=float32),\n",
       " array([[3.2461780e-01, 7.2710401e-01, 5.8686465e-04, 6.2439591e-02,\n",
       "         5.3654186e-02, 1.3960473e-03, 3.1028220e-01, 1.1063911e-01,\n",
       "         3.8628164e-01, 6.2733507e-01, 3.8058111e-01, 1.2042964e-04,\n",
       "         2.5927958e-01, 4.9242735e-02]], dtype=float32),\n",
       " array([[3.5161191e-01, 7.3679262e-01, 2.7908708e-03, 1.0712283e-01,\n",
       "         8.6493641e-02, 4.6527446e-03, 2.1909052e-01, 1.1364805e-01,\n",
       "         4.6916047e-01, 6.0794687e-01, 3.2744542e-01, 7.2051899e-04,\n",
       "         2.8161892e-01, 7.1891539e-02]], dtype=float32),\n",
       " array([[3.19617689e-01, 7.63107002e-01, 2.78218673e-03, 9.51043591e-02,\n",
       "         7.98998103e-02, 4.44415817e-03, 2.84611851e-01, 1.11883216e-01,\n",
       "         5.46686292e-01, 6.09603763e-01, 2.87058026e-01, 7.30560743e-04,\n",
       "         2.68175155e-01, 8.04494172e-02]], dtype=float32),\n",
       " array([[0.2805835 , 0.7808411 , 0.00299245, 0.08466487, 0.07379286,\n",
       "         0.00472766, 0.2864619 , 0.11215515, 0.58510923, 0.60762876,\n",
       "         0.27059296, 0.00082064, 0.25915742, 0.08488566]], dtype=float32),\n",
       " array([[0.27778298, 0.786687  , 0.00299868, 0.08083425, 0.07337952,\n",
       "         0.00466288, 0.34134534, 0.11210515, 0.5897215 , 0.6066732 ,\n",
       "         0.26563743, 0.0008469 , 0.26471922, 0.09014633]], dtype=float32),\n",
       " array([[0.2894178 , 0.7844692 , 0.0033464 , 0.08511523, 0.07807755,\n",
       "         0.00480303, 0.36767152, 0.11552484, 0.6012132 , 0.6077876 ,\n",
       "         0.2506168 , 0.00094041, 0.26493993, 0.09378161]], dtype=float32),\n",
       " array([[0.32383415, 0.77509767, 0.0157287 , 0.138226  , 0.12331811,\n",
       "         0.01501004, 0.31659213, 0.11476614, 0.62320364, 0.5889474 ,\n",
       "         0.22548656, 0.00590223, 0.30433965, 0.12605518]], dtype=float32),\n",
       " array([[0.26023385, 0.79828507, 0.02760427, 0.12714237, 0.11856824,\n",
       "         0.02157265, 0.27354008, 0.10844765, 0.69923925, 0.5821885 ,\n",
       "         0.18768252, 0.01228899, 0.2918876 , 0.14214122]], dtype=float32),\n",
       " array([[0.26472458, 0.7969364 , 0.02813854, 0.13679624, 0.12180261,\n",
       "         0.02236561, 0.25877106, 0.10671553, 0.7137608 , 0.5842977 ,\n",
       "         0.18513381, 0.01198141, 0.28496504, 0.13839117]], dtype=float32),\n",
       " array([[0.26356846, 0.7961141 , 0.00290401, 0.07173884, 0.06919602,\n",
       "         0.00369675, 0.33774188, 0.11024903, 0.67001384, 0.61332095,\n",
       "         0.20921649, 0.00082434, 0.23905736, 0.09417898]], dtype=float32),\n",
       " array([[0.27358162, 0.7799006 , 0.00532031, 0.08631137, 0.07827114,\n",
       "         0.00593507, 0.28270486, 0.10953606, 0.6327343 , 0.6014131 ,\n",
       "         0.22040798, 0.00172741, 0.26293242, 0.09841903]], dtype=float32),\n",
       " array([[0.2801782 , 0.7895097 , 0.01093328, 0.12013344, 0.10389446,\n",
       "         0.01183153, 0.34696966, 0.10325794, 0.6469367 , 0.597907  ,\n",
       "         0.22158633, 0.00381243, 0.27873397, 0.10726407]], dtype=float32),\n",
       " array([[0.18718296, 0.8223982 , 0.01865199, 0.09708484, 0.09199353,\n",
       "         0.01818756, 0.3328573 , 0.09944039, 0.7061523 , 0.59155303,\n",
       "         0.19575079, 0.00774204, 0.26302442, 0.11477564]], dtype=float32),\n",
       " array([[0.20216478, 0.82105356, 0.01422559, 0.10380743, 0.09203778,\n",
       "         0.01557065, 0.3337334 , 0.09610893, 0.71478754, 0.5968938 ,\n",
       "         0.20107132, 0.0053242 , 0.25522026, 0.10799266]], dtype=float32),\n",
       " array([[0.17538552, 0.8324638 , 0.02559543, 0.10390534, 0.09728405,\n",
       "         0.02256561, 0.3184613 , 0.09404127, 0.7619784 , 0.59167385,\n",
       "         0.17094858, 0.0111406 , 0.2519198 , 0.12261296]], dtype=float32),\n",
       " array([[0.22325489, 0.80962723, 0.04568351, 0.13574983, 0.12667473,\n",
       "         0.03360467, 0.31125686, 0.10152496, 0.7307245 , 0.5803498 ,\n",
       "         0.17765644, 0.02217893, 0.2897272 , 0.14551991]], dtype=float32),\n",
       " array([[0.18105179, 0.8285947 , 0.1250054 , 0.14819762, 0.14829788,\n",
       "         0.07397904, 0.252314  , 0.10560104, 0.7884889 , 0.5675641 ,\n",
       "         0.14989232, 0.07707365, 0.29049602, 0.18124543]], dtype=float32),\n",
       " array([[0.18375298, 0.82488924, 0.17253065, 0.16719982, 0.1587254 ,\n",
       "         0.09801185, 0.18404944, 0.1084622 , 0.8057185 , 0.560097  ,\n",
       "         0.14648838, 0.11202098, 0.29260087, 0.19554503]], dtype=float32),\n",
       " array([[0.174055  , 0.8328261 , 0.15846708, 0.15606005, 0.15030742,\n",
       "         0.08289213, 0.19096112, 0.09898006, 0.8402005 , 0.5668007 ,\n",
       "         0.12574287, 0.10325573, 0.27287817, 0.19269976]], dtype=float32),\n",
       " array([[0.18499509, 0.82538944, 0.1349141 , 0.15197569, 0.14696822,\n",
       "         0.07191155, 0.19270305, 0.09873235, 0.8261848 , 0.5678387 ,\n",
       "         0.13404506, 0.08571279, 0.2777129 , 0.18818691]], dtype=float32),\n",
       " array([[0.18283994, 0.8224424 , 0.12622033, 0.15256229, 0.14325973,\n",
       "         0.07062837, 0.1696753 , 0.09589022, 0.81690335, 0.5679741 ,\n",
       "         0.14227146, 0.07872479, 0.2767942 , 0.17703639]], dtype=float32),\n",
       " array([[0.17259592, 0.81627375, 0.07702136, 0.12702726, 0.12513618,\n",
       "         0.05140237, 0.21454027, 0.10195792, 0.7642764 , 0.5744268 ,\n",
       "         0.17102833, 0.0425836 , 0.27695265, 0.15127258]], dtype=float32),\n",
       " array([[0.18347749, 0.8122409 , 0.06878747, 0.13447405, 0.1270472 ,\n",
       "         0.04779083, 0.16698934, 0.10376158, 0.7658181 , 0.57599616,\n",
       "         0.17336021, 0.03558759, 0.26979148, 0.14512081]], dtype=float32),\n",
       " array([[0.19114293, 0.80056113, 0.056866  , 0.13073605, 0.1264777 ,\n",
       "         0.04126357, 0.12643142, 0.11310987, 0.7336985 , 0.5777823 ,\n",
       "         0.18650435, 0.02737741, 0.2662932 , 0.1339869 ]], dtype=float32),\n",
       " array([[0.2038685 , 0.8006551 , 0.06369116, 0.14574187, 0.13350482,\n",
       "         0.04643193, 0.10415013, 0.10953522, 0.7442107 , 0.5741848 ,\n",
       "         0.18785502, 0.03122086, 0.2696807 , 0.13964058]], dtype=float32),\n",
       " array([[0.17551982, 0.8144732 , 0.12207142, 0.14946699, 0.14406614,\n",
       "         0.07916537, 0.11877491, 0.10383962, 0.75549257, 0.5629076 ,\n",
       "         0.18040204, 0.07573332, 0.28784236, 0.16123955]], dtype=float32),\n",
       " array([[0.16223659, 0.8236583 , 0.08186893, 0.13125607, 0.12421881,\n",
       "         0.0617754 , 0.10780047, 0.10350033, 0.77077955, 0.56676733,\n",
       "         0.18731625, 0.04581636, 0.27011773, 0.15279855]], dtype=float32),\n",
       " array([[0.16811034, 0.8193774 , 0.10774203, 0.14071485, 0.13580014,\n",
       "         0.07537321, 0.12531108, 0.10322388, 0.75958616, 0.56311595,\n",
       "         0.18829249, 0.06541475, 0.28576115, 0.1617801 ]], dtype=float32),\n",
       " array([[0.19197893, 0.80934054, 0.0696221 , 0.1379806 , 0.12957376,\n",
       "         0.0520493 , 0.11263436, 0.10609273, 0.7474161 , 0.5685095 ,\n",
       "         0.1947465 , 0.03748415, 0.27908918, 0.15176134]], dtype=float32),\n",
       " array([[0.16137062, 0.8248078 , 0.1403431 , 0.13957758, 0.14139223,\n",
       "         0.08384424, 0.0848807 , 0.10587897, 0.79758155, 0.55954933,\n",
       "         0.16099896, 0.09329394, 0.27503365, 0.17883527]], dtype=float32),\n",
       " array([[0.19152626, 0.81148785, 0.10239609, 0.1501943 , 0.1405247 ,\n",
       "         0.06519775, 0.10208224, 0.10334639, 0.7872422 , 0.5654403 ,\n",
       "         0.17012769, 0.05998009, 0.27765048, 0.16809988]], dtype=float32),\n",
       " array([[0.1746065 , 0.81136996, 0.05626974, 0.11377829, 0.11091112,\n",
       "         0.04060439, 0.11995065, 0.10412787, 0.7629923 , 0.57096356,\n",
       "         0.18475473, 0.03015094, 0.2697839 , 0.1496987 ]], dtype=float32),\n",
       " array([[0.20214316, 0.79527533, 0.0416564 , 0.11952251, 0.11254482,\n",
       "         0.03137839, 0.09743124, 0.11305977, 0.74489856, 0.576177  ,\n",
       "         0.19134317, 0.01938857, 0.26323396, 0.13849404]], dtype=float32),\n",
       " array([[0.18894175, 0.7973616 , 0.06749392, 0.1343946 , 0.12769078,\n",
       "         0.04743185, 0.07171381, 0.11096202, 0.74085873, 0.5716631 ,\n",
       "         0.19126807, 0.03484126, 0.26594347, 0.13819087]], dtype=float32),\n",
       " array([[0.21227373, 0.7864214 , 0.05102567, 0.13449426, 0.12451462,\n",
       "         0.03865978, 0.0803574 , 0.11462668, 0.7179737 , 0.57363504,\n",
       "         0.20697808, 0.02433062, 0.27159303, 0.13570945]], dtype=float32),\n",
       " array([[0.20780084, 0.7898144 , 0.04038301, 0.13282807, 0.12195464,\n",
       "         0.03461557, 0.07930863, 0.11223619, 0.7037624 , 0.57987154,\n",
       "         0.21936084, 0.01805222, 0.26102993, 0.12123077]], dtype=float32),\n",
       " array([[0.1975986 , 0.79540193, 0.05348346, 0.13351768, 0.12499458,\n",
       "         0.04128748, 0.08207636, 0.11132956, 0.72562   , 0.5763902 ,\n",
       "         0.20409176, 0.02581027, 0.26351303, 0.13096039]], dtype=float32),\n",
       " array([[0.20113432, 0.79442835, 0.05197891, 0.12867197, 0.12217792,\n",
       "         0.03836357, 0.07656668, 0.11454612, 0.73657686, 0.5742019 ,\n",
       "         0.19602749, 0.0251553 , 0.26460567, 0.13827066]], dtype=float32),\n",
       " array([[0.2215688 , 0.78747   , 0.04647073, 0.14043741, 0.12949054,\n",
       "         0.03799506, 0.09338125, 0.11472274, 0.7079741 , 0.5759042 ,\n",
       "         0.21635817, 0.02140683, 0.2749166 , 0.13422504]], dtype=float32),\n",
       " array([[0.21065418, 0.7892639 , 0.02317955, 0.10899876, 0.10390112,\n",
       "         0.02181775, 0.11850459, 0.11487402, 0.6904279 , 0.5844736 ,\n",
       "         0.22551204, 0.00953997, 0.26242977, 0.11904946]], dtype=float32),\n",
       " array([[0.21955444, 0.7896833 , 0.0281988 , 0.12218199, 0.11547747,\n",
       "         0.02552757, 0.1390585 , 0.11100127, 0.691349  , 0.5854229 ,\n",
       "         0.22161429, 0.01193597, 0.2683973 , 0.12058527]], dtype=float32),\n",
       " array([[0.23429182, 0.7872903 , 0.03285711, 0.12991036, 0.12152536,\n",
       "         0.02742356, 0.13509443, 0.11366724, 0.71012634, 0.5817574 ,\n",
       "         0.20985717, 0.01426306, 0.27402604, 0.13325438]], dtype=float32),\n",
       " array([[0.23849636, 0.7848761 , 0.01870366, 0.11618018, 0.10626309,\n",
       "         0.01875907, 0.17089643, 0.11299323, 0.68473417, 0.5883005 ,\n",
       "         0.23035744, 0.00721979, 0.2695071 , 0.11993798]], dtype=float32),\n",
       " array([[0.21721332, 0.7934539 , 0.01191325, 0.09227238, 0.08814882,\n",
       "         0.01289418, 0.19461279, 0.11331517, 0.68957144, 0.593667  ,\n",
       "         0.22727935, 0.00434594, 0.25595343, 0.11286448]], dtype=float32),\n",
       " array([[0.24274191, 0.7846125 , 0.01317853, 0.10865034, 0.09947361,\n",
       "         0.01422196, 0.19320846, 0.11076881, 0.66912806, 0.59422374,\n",
       "         0.2350547 , 0.0047576 , 0.26466283, 0.10967075]], dtype=float32),\n",
       " array([[0.25182915, 0.7831319 , 0.02405501, 0.1294053 , 0.11750645,\n",
       "         0.02209853, 0.155449  , 0.11301825, 0.68191016, 0.58447385,\n",
       "         0.22258773, 0.00971841, 0.27874064, 0.12502714]], dtype=float32),\n",
       " array([[0.24875437, 0.7869123 , 0.0218483 , 0.12757947, 0.1161399 ,\n",
       "         0.02138445, 0.18073763, 0.11219089, 0.6790549 , 0.5867409 ,\n",
       "         0.22824788, 0.00860553, 0.27810448, 0.12291445]], dtype=float32),\n",
       " array([[0.24850902, 0.7836961 , 0.01210419, 0.11116806, 0.09970705,\n",
       "         0.01384407, 0.19762303, 0.10927149, 0.65049654, 0.5919173 ,\n",
       "         0.2450566 , 0.00426902, 0.27550706, 0.10737297]], dtype=float32),\n",
       " array([[0.23855282, 0.7966975 , 0.02497364, 0.12497307, 0.11628291,\n",
       "         0.02228331, 0.18468075, 0.11099749, 0.71583414, 0.58718413,\n",
       "         0.20454867, 0.01020567, 0.27002788, 0.13013658]], dtype=float32),\n",
       " array([[0.2286419 , 0.8063828 , 0.04318685, 0.1355032 , 0.12824944,\n",
       "         0.03317812, 0.1832061 , 0.11314067, 0.7573262 , 0.5800313 ,\n",
       "         0.1827851 , 0.01991601, 0.2733247 , 0.1544474 ]], dtype=float32),\n",
       " array([[0.22869195, 0.80384254, 0.04535944, 0.1360373 , 0.12913775,\n",
       "         0.03478262, 0.17686996, 0.11479523, 0.7490465 , 0.5782089 ,\n",
       "         0.18736982, 0.02123316, 0.27736712, 0.1556959 ]], dtype=float32),\n",
       " array([[0.22158146, 0.79524684, 0.01932791, 0.10615081, 0.10018691,\n",
       "         0.01810658, 0.19284981, 0.11135811, 0.6987228 , 0.5885659 ,\n",
       "         0.21257949, 0.00778394, 0.2656862 , 0.12221652]], dtype=float32),\n",
       " array([[0.22989784, 0.7924492 , 0.01954564, 0.11107292, 0.1039501 ,\n",
       "         0.0180019 , 0.20148003, 0.10895792, 0.69377893, 0.59038204,\n",
       "         0.21137087, 0.0078535 , 0.2671343 , 0.11949827]], dtype=float32),\n",
       " array([[0.2357648 , 0.7954755 , 0.03167517, 0.12640251, 0.11726487,\n",
       "         0.0252993 , 0.19869854, 0.10960349, 0.7263325 , 0.5839689 ,\n",
       "         0.19380723, 0.01388381, 0.2756313 , 0.13840383]], dtype=float32),\n",
       " array([[0.22280306, 0.7988844 , 0.0324886 , 0.1244936 , 0.11449989,\n",
       "         0.02720639, 0.18797524, 0.10900621, 0.721072  , 0.5824209 ,\n",
       "         0.20114501, 0.0142861 , 0.27518156, 0.13520348]], dtype=float32),\n",
       " array([[0.21139164, 0.79688895, 0.02575435, 0.10851493, 0.10260661,\n",
       "         0.02204242, 0.19369997, 0.10874027, 0.70477897, 0.58536035,\n",
       "         0.20538414, 0.01113758, 0.27018592, 0.12587701]], dtype=float32),\n",
       " array([[0.17889367, 0.81452984, 0.03479881, 0.10201517, 0.10013152,\n",
       "         0.02706805, 0.18165508, 0.10696055, 0.75453216, 0.58276385,\n",
       "         0.18089439, 0.01634261, 0.25867847, 0.13629246]], dtype=float32),\n",
       " array([[0.20565067, 0.80028766, 0.03894604, 0.11453769, 0.10836374,\n",
       "         0.02934268, 0.18052344, 0.11052299, 0.73541987, 0.5791137 ,\n",
       "         0.19015986, 0.01843957, 0.27334836, 0.14305829]], dtype=float32),\n",
       " array([[0.19959427, 0.7900928 , 0.00760471, 0.06777771, 0.06928404,\n",
       "         0.00826034, 0.22436863, 0.11480303, 0.6492664 , 0.59644675,\n",
       "         0.23181182, 0.00275775, 0.2546336 , 0.10248645]], dtype=float32),\n",
       " array([[0.21870843, 0.7852438 , 0.01119161, 0.09121516, 0.08491414,\n",
       "         0.01226594, 0.21723334, 0.10827958, 0.6347702 , 0.5942706 ,\n",
       "         0.24321388, 0.00415621, 0.26656273, 0.10056975]], dtype=float32),\n",
       " array([[0.22013073, 0.7991418 , 0.0212599 , 0.11288229, 0.10398059,\n",
       "         0.01987476, 0.21760865, 0.10585184, 0.7017571 , 0.5900992 ,\n",
       "         0.20993008, 0.00863991, 0.26702762, 0.11952592]], dtype=float32),\n",
       " array([[0.2228984 , 0.7982172 , 0.01725022, 0.1047742 , 0.09756332,\n",
       "         0.01664977, 0.24283427, 0.10555468, 0.69511503, 0.5912526 ,\n",
       "         0.21308103, 0.00687443, 0.26838842, 0.11888678]], dtype=float32),\n",
       " array([[0.21692151, 0.7974182 , 0.01204606, 0.09441604, 0.08972628,\n",
       "         0.01281895, 0.22187854, 0.10812143, 0.67754483, 0.59603876,\n",
       "         0.22191861, 0.00445271, 0.25766978, 0.10704049]], dtype=float32),\n",
       " array([[0.208057  , 0.8056298 , 0.02872316, 0.11829863, 0.11001538,\n",
       "         0.02568046, 0.16380036, 0.10871839, 0.71730524, 0.5844121 ,\n",
       "         0.20367473, 0.01234541, 0.26569745, 0.12660363]], dtype=float32),\n",
       " array([[0.2357532 , 0.79238915, 0.0295947 , 0.12492874, 0.11511333,\n",
       "         0.02489006, 0.19271813, 0.11088676, 0.699168  , 0.5824919 ,\n",
       "         0.20678782, 0.01281392, 0.28153485, 0.13318169]], dtype=float32),\n",
       " array([[0.259163  , 0.7658331 , 0.00283336, 0.06993858, 0.06773961,\n",
       "         0.00416899, 0.27943173, 0.11462846, 0.54147816, 0.6096829 ,\n",
       "         0.28445584, 0.00081478, 0.2613282 , 0.07923029]], dtype=float32),\n",
       " array([[0.28841436, 0.7562428 , 0.0047782 , 0.09744902, 0.08361772,\n",
       "         0.00666838, 0.22003648, 0.11035182, 0.53503025, 0.6033278 ,\n",
       "         0.2912993 , 0.00143916, 0.27407628, 0.08113781]], dtype=float32),\n",
       " array([[0.234644  , 0.7925441 , 0.01366713, 0.10488749, 0.09618992,\n",
       "         0.0135044 , 0.182322  , 0.10773008, 0.6735928 , 0.59349823,\n",
       "         0.21400405, 0.00512026, 0.26165143, 0.10773918]], dtype=float32),\n",
       " array([[0.28276065, 0.77171105, 0.00416075, 0.09165383, 0.08179303,\n",
       "         0.0056637 , 0.22967881, 0.11027502, 0.5897847 , 0.60775346,\n",
       "         0.26058567, 0.0012047 , 0.2587121 , 0.08483387]], dtype=float32),\n",
       " array([[0.2713511 , 0.7831369 , 0.01129653, 0.1178102 , 0.10507188,\n",
       "         0.01238078, 0.22428042, 0.10763792, 0.63577217, 0.59755856,\n",
       "         0.23460627, 0.00393958, 0.2716382 , 0.10280673]], dtype=float32),\n",
       " array([[2.6232857e-01, 7.7028084e-01, 1.7853768e-03, 7.0606522e-02,\n",
       "         6.5104134e-02, 3.1702514e-03, 2.6208898e-01, 1.1268490e-01,\n",
       "         5.2479333e-01, 6.1952478e-01, 2.9573298e-01, 4.4328859e-04,\n",
       "         2.4260010e-01, 6.5184362e-02]], dtype=float32),\n",
       " array([[2.9019544e-01, 7.5876635e-01, 2.2784057e-03, 8.2450621e-02,\n",
       "         6.9450222e-02, 3.9200317e-03, 2.5888151e-01, 1.0849314e-01,\n",
       "         5.0021207e-01, 6.1098909e-01, 3.1099325e-01, 6.0748652e-04,\n",
       "         2.6423761e-01, 6.9581710e-02]], dtype=float32),\n",
       " array([[2.14647517e-01, 7.80916989e-01, 2.04372613e-04, 2.40634177e-02,\n",
       "         3.16887051e-02, 4.69682011e-04, 3.90866816e-01, 1.21310055e-01,\n",
       "         4.36035812e-01, 6.39533758e-01, 3.03270340e-01, 4.32431771e-05,\n",
       "         2.15530828e-01, 4.77472097e-02]], dtype=float32),\n",
       " array([[3.0803764e-01, 7.6742083e-01, 4.4977549e-04, 4.9893454e-02,\n",
       "         4.5444943e-02, 1.0643252e-03, 3.8260350e-01, 1.2319616e-01,\n",
       "         4.8936942e-01, 6.2287235e-01, 3.1875783e-01, 9.1851885e-05,\n",
       "         2.4695177e-01, 6.5551132e-02]], dtype=float32),\n",
       " array([[0.21127474, 0.8242908 , 0.00399673, 0.07016747, 0.06958736,\n",
       "         0.00518039, 0.3512649 , 0.10354766, 0.6930507 , 0.6125491 ,\n",
       "         0.197818  , 0.00123656, 0.2307369 , 0.09230469]], dtype=float32),\n",
       " array([[0.28899145, 0.79967976, 0.01134009, 0.12292559, 0.10545112,\n",
       "         0.01200422, 0.28773695, 0.10798683, 0.6871498 , 0.59391767,\n",
       "         0.20541976, 0.00394256, 0.27420604, 0.12132286]], dtype=float32),\n",
       " array([[0.29548678, 0.7929627 , 0.03340903, 0.16285834, 0.1404191 ,\n",
       "         0.02714491, 0.23515011, 0.11168517, 0.6977124 , 0.5805231 ,\n",
       "         0.19345254, 0.01411826, 0.29733917, 0.14493208]], dtype=float32),\n",
       " array([[0.27933487, 0.79695415, 0.02595867, 0.15322804, 0.13166578,\n",
       "         0.0234082 , 0.27637473, 0.1106896 , 0.7004684 , 0.58820903,\n",
       "         0.19755222, 0.01003776, 0.2834686 , 0.1320133 ]], dtype=float32),\n",
       " array([[0.29025716, 0.7848191 , 0.01915421, 0.1269432 , 0.11918215,\n",
       "         0.01703939, 0.34547332, 0.11253815, 0.6375053 , 0.5852166 ,\n",
       "         0.21431412, 0.00790909, 0.307406  , 0.13358405]], dtype=float32),\n",
       " array([[0.31148285, 0.7802791 , 0.02349794, 0.13888405, 0.12637982,\n",
       "         0.0177732 , 0.33751965, 0.10738518, 0.67027056, 0.5847561 ,\n",
       "         0.19036645, 0.01018069, 0.30682823, 0.14134917]], dtype=float32),\n",
       " array([[0.26076314, 0.8034905 , 0.00440406, 0.08937936, 0.08000609,\n",
       "         0.0060106 , 0.3974414 , 0.10919414, 0.67275953, 0.60994583,\n",
       "         0.21980375, 0.00127589, 0.2482821 , 0.098597  ]], dtype=float32),\n",
       " array([[0.25409567, 0.80741733, 0.00407344, 0.08246491, 0.07089181,\n",
       "         0.00514125, 0.41716558, 0.0969618 , 0.7033697 , 0.60939974,\n",
       "         0.20108387, 0.00124113, 0.24541576, 0.09919935]], dtype=float32),\n",
       " array([[2.16663554e-01, 8.17562640e-01, 5.86663082e-04, 4.39617373e-02,\n",
       "         4.03491333e-02, 1.28630968e-03, 4.38430250e-01, 1.02771856e-01,\n",
       "         6.50386274e-01, 6.31290972e-01, 2.42017850e-01, 1.24417871e-04,\n",
       "         2.04193801e-01, 6.51291758e-02]], dtype=float32),\n",
       " array([[0.25631654, 0.80553955, 0.00402454, 0.0929876 , 0.08109447,\n",
       "         0.00642238, 0.3848123 , 0.10388847, 0.61240715, 0.60830635,\n",
       "         0.252814  , 0.00116179, 0.2586539 , 0.08616847]], dtype=float32),\n",
       " array([[0.24692316, 0.80904305, 0.00954354, 0.11485918, 0.09561291,\n",
       "         0.0133458 , 0.4223755 , 0.10240812, 0.62592155, 0.59613496,\n",
       "         0.25031528, 0.00319317, 0.28055865, 0.10180978]], dtype=float32),\n",
       " array([[0.19138806, 0.8185508 , 0.00932019, 0.08339662, 0.0784881 ,\n",
       "         0.01221873, 0.3627793 , 0.10620473, 0.63037974, 0.592851  ,\n",
       "         0.23998906, 0.00341761, 0.268998  , 0.10049616]], dtype=float32),\n",
       " array([[0.30113393, 0.8016929 , 0.00882526, 0.12643853, 0.10872362,\n",
       "         0.01107883, 0.41560706, 0.10823067, 0.6513136 , 0.597909  ,\n",
       "         0.22691695, 0.0028395 , 0.28316393, 0.11454537]], dtype=float32),\n",
       " array([[0.21055278, 0.826647  , 0.0290135 , 0.11419264, 0.11003734,\n",
       "         0.02239552, 0.37296513, 0.09986442, 0.75310975, 0.5878652 ,\n",
       "         0.15946382, 0.01307479, 0.2706142 , 0.1394354 ]], dtype=float32),\n",
       " array([[0.31738693, 0.78867877, 0.04662448, 0.17357051, 0.15384923,\n",
       "         0.03086999, 0.340243  , 0.10821076, 0.7187617 , 0.5766799 ,\n",
       "         0.1711195 , 0.0216978 , 0.31693888, 0.16741918]], dtype=float32),\n",
       " array([[0.27059627, 0.8014718 , 0.02869926, 0.13669436, 0.1243984 ,\n",
       "         0.02236036, 0.3259124 , 0.10349055, 0.7129214 , 0.58204335,\n",
       "         0.18117292, 0.01268422, 0.2961073 , 0.1459048 ]], dtype=float32),\n",
       " array([[0.21409366, 0.81669676, 0.07811046, 0.14922383, 0.14153467,\n",
       "         0.04725403, 0.28094506, 0.09984458, 0.7642939 , 0.5750752 ,\n",
       "         0.15139979, 0.04309975, 0.2893466 , 0.16032366]], dtype=float32),\n",
       " array([[0.19778538, 0.8272293 , 0.11382649, 0.15581967, 0.14135213,\n",
       "         0.05975241, 0.29214656, 0.08968053, 0.82453465, 0.5722285 ,\n",
       "         0.12577295, 0.06966412, 0.28128397, 0.17912781]], dtype=float32),\n",
       " array([[0.17850678, 0.82636446, 0.00917221, 0.07807542, 0.07722095,\n",
       "         0.01028254, 0.30321968, 0.09978646, 0.72958654, 0.60170174,\n",
       "         0.19134642, 0.0032924 , 0.23528229, 0.10321292]], dtype=float32),\n",
       " array([[0.20341069, 0.8155525 , 0.01226733, 0.09764513, 0.08553041,\n",
       "         0.01380511, 0.3805812 , 0.08838394, 0.6956919 , 0.5956706 ,\n",
       "         0.21303003, 0.00477194, 0.2640729 , 0.10483894]], dtype=float32),\n",
       " array([[0.18115309, 0.8116707 , 0.0201329 , 0.10357548, 0.09139481,\n",
       "         0.02016226, 0.24179749, 0.09822414, 0.6969265 , 0.59071225,\n",
       "         0.20609133, 0.00809724, 0.25478968, 0.10251694]], dtype=float32),\n",
       " array([[0.1884376 , 0.8173057 , 0.02770888, 0.10808778, 0.10003869,\n",
       "         0.02379414, 0.26449507, 0.09640327, 0.72573423, 0.58485913,\n",
       "         0.18666239, 0.01238327, 0.2670711 , 0.12199835]], dtype=float32),\n",
       " array([[0.14184588, 0.84055066, 0.08274996, 0.12308291, 0.12220105,\n",
       "         0.06144432, 0.18971007, 0.09907739, 0.7733088 , 0.57209104,\n",
       "         0.16905032, 0.04649913, 0.26600215, 0.14415309]], dtype=float32),\n",
       " array([[0.15461195, 0.83872235, 0.1403878 , 0.16001964, 0.14658868,\n",
       "         0.09604946, 0.14390868, 0.09650816, 0.8036805 , 0.564569  ,\n",
       "         0.16026   , 0.08587241, 0.2723758 , 0.16279158]], dtype=float32),\n",
       " array([[0.14400603, 0.8444106 , 0.10694975, 0.13768004, 0.12912881,\n",
       "         0.07413573, 0.18922174, 0.09481567, 0.8248403 , 0.5716443 ,\n",
       "         0.15140064, 0.0611974 , 0.25842872, 0.16026649]], dtype=float32),\n",
       " array([[0.14014187, 0.8448142 , 0.19587956, 0.14359653, 0.14643411,\n",
       "         0.11108521, 0.1706548 , 0.09468476, 0.83434576, 0.55927354,\n",
       "         0.13877527, 0.14303689, 0.27913442, 0.19423345]], dtype=float32),\n",
       " array([[0.15402156, 0.8315068 , 0.18762423, 0.15372962, 0.14760208,\n",
       "         0.1130585 , 0.17374028, 0.09849553, 0.81651914, 0.5577919 ,\n",
       "         0.15612952, 0.13026397, 0.2890602 , 0.19186409]], dtype=float32),\n",
       " array([[0.19538498, 0.8056254 , 0.18712847, 0.17991662, 0.16875057,\n",
       "         0.09814093, 0.13471258, 0.10616773, 0.80744296, 0.5641447 ,\n",
       "         0.14606869, 0.11924889, 0.28438684, 0.18166253]], dtype=float32),\n",
       " array([[0.21208568, 0.7997172 , 0.25991535, 0.1985275 , 0.18408217,\n",
       "         0.11897015, 0.11659092, 0.09992696, 0.82184774, 0.555614  ,\n",
       "         0.1339541 , 0.19109981, 0.30055204, 0.2058392 ]], dtype=float32),\n",
       " array([[0.20027833, 0.8041565 , 0.127978  , 0.1567486 , 0.15453577,\n",
       "         0.06855838, 0.14075245, 0.10131301, 0.79503274, 0.56754297,\n",
       "         0.1519403 , 0.07870957, 0.2852669 , 0.17442325]], dtype=float32),\n",
       " array([[0.19501019, 0.79739445, 0.08445326, 0.14541306, 0.14068425,\n",
       "         0.05424737, 0.13963471, 0.10312705, 0.7469344 , 0.57394904,\n",
       "         0.18015216, 0.04564822, 0.27897283, 0.1434143 ]], dtype=float32),\n",
       " array([[0.22475694, 0.777728  , 0.03433542, 0.14203306, 0.1260663 ,\n",
       "         0.03272687, 0.12286565, 0.11563645, 0.6691648 , 0.5823106 ,\n",
       "         0.24007516, 0.01367419, 0.27396083, 0.11356677]], dtype=float32),\n",
       " array([[0.25384578, 0.7659089 , 0.0123783 , 0.11982813, 0.10612842,\n",
       "         0.01519802, 0.11949454, 0.11985948, 0.60982484, 0.59135896,\n",
       "         0.27373344, 0.00402817, 0.2675557 , 0.0952789 ]], dtype=float32),\n",
       " array([[0.19889475, 0.7923666 , 0.01189967, 0.10023748, 0.08809774,\n",
       "         0.0158812 , 0.16620818, 0.10388818, 0.63197184, 0.5917382 ,\n",
       "         0.2726904 , 0.00418046, 0.26068214, 0.09077282]], dtype=float32),\n",
       " array([[0.23666704, 0.7855135 , 0.01545189, 0.12302568, 0.10575581,\n",
       "         0.0201957 , 0.17812017, 0.10085934, 0.6019108 , 0.5847188 ,\n",
       "         0.28978547, 0.00588357, 0.28927878, 0.10107558]], dtype=float32),\n",
       " array([[2.4563356e-01, 7.7289259e-01, 1.7132170e-03, 6.4296611e-02,\n",
       "         6.1578881e-02, 3.4551304e-03, 2.4265751e-01, 1.1071986e-01,\n",
       "         5.0540078e-01, 6.0949266e-01, 3.3410975e-01, 4.4824765e-04,\n",
       "         2.5836515e-01, 6.8722382e-02]], dtype=float32),\n",
       " array([[0.30533686, 0.75676733, 0.00301681, 0.09551395, 0.08114676,\n",
       "         0.00553213, 0.24247487, 0.10948514, 0.4902114 , 0.59881115,\n",
       "         0.3407675 , 0.00083341, 0.29288238, 0.07887387]], dtype=float32),\n",
       " array([[3.2249272e-01, 7.5559586e-01, 2.1130606e-03, 8.1700593e-02,\n",
       "         7.1636088e-02, 3.6795924e-03, 2.7721378e-01, 1.1813676e-01,\n",
       "         5.2311724e-01, 6.0332865e-01, 3.1442848e-01, 5.5364839e-04,\n",
       "         2.7962404e-01, 8.4795669e-02]], dtype=float32),\n",
       " array([[0.3668161 , 0.75515646, 0.005396  , 0.12789539, 0.10748017,\n",
       "         0.00772465, 0.25391936, 0.11750757, 0.55304563, 0.59674925,\n",
       "         0.291396  , 0.00155548, 0.29707915, 0.10004709]], dtype=float32),\n",
       " array([[0.33332285, 0.7682622 , 0.00535403, 0.11227252, 0.09864742,\n",
       "         0.00682544, 0.21172445, 0.12110083, 0.6167557 , 0.5996594 ,\n",
       "         0.24866174, 0.00152701, 0.271169  , 0.10227187]], dtype=float32),\n",
       " array([[0.27635834, 0.7858559 , 0.03419703, 0.13440414, 0.13191997,\n",
       "         0.02295131, 0.21014062, 0.11421141, 0.7070076 , 0.5804468 ,\n",
       "         0.17693269, 0.01544077, 0.2920144 , 0.14713272]], dtype=float32),\n",
       " array([[0.26621568, 0.7906504 , 0.09445074, 0.17236182, 0.15865782,\n",
       "         0.05058257, 0.18719566, 0.10580515, 0.7592324 , 0.566739  ,\n",
       "         0.15582055, 0.05332302, 0.30816904, 0.1793259 ]], dtype=float32),\n",
       " array([[0.2552129 , 0.79179627, 0.17824203, 0.20919551, 0.19161491,\n",
       "         0.09085228, 0.13090272, 0.10814676, 0.76862943, 0.559618  ,\n",
       "         0.15405384, 0.11391397, 0.31227648, 0.18989968]], dtype=float32),\n",
       " array([[0.2357369 , 0.79719764, 0.21550597, 0.20711026, 0.19311684,\n",
       "         0.10830799, 0.11711787, 0.10545117, 0.77669156, 0.555029  ,\n",
       "         0.15228581, 0.1501068 , 0.31499082, 0.19686504]], dtype=float32),\n",
       " array([[0.1685723 , 0.8214148 , 0.24699272, 0.16218491, 0.16365099,\n",
       "         0.10884806, 0.11375895, 0.10160298, 0.83899856, 0.5590515 ,\n",
       "         0.11811433, 0.18460754, 0.27821243, 0.19945171]], dtype=float32),\n",
       " array([[0.17877467, 0.8160684 , 0.21372032, 0.16654445, 0.15979278,\n",
       "         0.09924281, 0.10663264, 0.10004528, 0.8369699 , 0.5603377 ,\n",
       "         0.12555595, 0.1507751 , 0.27681848, 0.19350009]], dtype=float32),\n",
       " array([[0.13374618, 0.83824074, 0.13169406, 0.12303957, 0.1224292 ,\n",
       "         0.07373055, 0.15163475, 0.08829696, 0.838525  , 0.569888  ,\n",
       "         0.13645999, 0.08747724, 0.25576022, 0.16504423]], dtype=float32),\n",
       " array([[0.13348871, 0.8340141 , 0.02687762, 0.0830749 , 0.0850739 ,\n",
       "         0.02396406, 0.20882802, 0.09490319, 0.7792881 , 0.5914103 ,\n",
       "         0.17916869, 0.01210982, 0.23237851, 0.11572263]], dtype=float32),\n",
       " array([[0.14775454, 0.82604766, 0.04480337, 0.11353811, 0.10375612,\n",
       "         0.03964048, 0.18076566, 0.09243484, 0.7668581 , 0.58470905,\n",
       "         0.19305807, 0.02124717, 0.24746954, 0.11820237]], dtype=float32),\n",
       " array([[0.1309547 , 0.8307021 , 0.05765283, 0.10343938, 0.10464286,\n",
       "         0.04788359, 0.1960194 , 0.09632405, 0.75151706, 0.5787978 ,\n",
       "         0.19498995, 0.03062338, 0.25910524, 0.12630372]], dtype=float32),\n",
       " array([[0.14488706, 0.8254109 , 0.0259368 , 0.09429706, 0.09186594,\n",
       "         0.02884641, 0.21720162, 0.10114732, 0.7169576 , 0.58691853,\n",
       "         0.2287933 , 0.01108402, 0.2528275 , 0.11096148]], dtype=float32),\n",
       " array([[0.13219927, 0.832379  , 0.05998364, 0.10444102, 0.10648848,\n",
       "         0.0499819 , 0.18592955, 0.10026036, 0.7576007 , 0.5769759 ,\n",
       "         0.1943932 , 0.03163379, 0.259553  , 0.13237856]], dtype=float32),\n",
       " array([[0.17740573, 0.81612945, 0.06441298, 0.12908162, 0.12295254,\n",
       "         0.04920588, 0.1581625 , 0.10646629, 0.77344185, 0.5743932 ,\n",
       "         0.18602388, 0.03259616, 0.2682217 , 0.1505238 ]], dtype=float32),\n",
       " array([[0.2124048 , 0.798954  , 0.1758326 , 0.18026361, 0.17428248,\n",
       "         0.10031111, 0.1250672 , 0.11319575, 0.771633  , 0.5579055 ,\n",
       "         0.1724357 , 0.1135938 , 0.3066399 , 0.19212626]], dtype=float32),\n",
       " array([[0.22058962, 0.79197073, 0.11321519, 0.16168495, 0.15415195,\n",
       "         0.06930029, 0.1144262 , 0.11610786, 0.7607733 , 0.5619761 ,\n",
       "         0.18196315, 0.06497227, 0.29794088, 0.1795441 ]], dtype=float32),\n",
       " array([[0.23714948, 0.7840284 , 0.05795828, 0.1539291 , 0.14166416,\n",
       "         0.04449259, 0.12928542, 0.11364024, 0.71816736, 0.5734792 ,\n",
       "         0.2118724 , 0.02765316, 0.28925171, 0.14740896]], dtype=float32),\n",
       " array([[0.24928814, 0.77825606, 0.0322667 , 0.12934558, 0.12302577,\n",
       "         0.02373363, 0.12358477, 0.11243293, 0.7265618 , 0.58349526,\n",
       "         0.19251059, 0.0138624 , 0.27006063, 0.13411953]], dtype=float32),\n",
       " array([[0.24671187, 0.7808563 , 0.02093785, 0.12534103, 0.11347788,\n",
       "         0.01931798, 0.13713133, 0.10863015, 0.69895744, 0.5892289 ,\n",
       "         0.21758857, 0.00806919, 0.26483914, 0.11607656]], dtype=float32),\n",
       " array([[0.19675471, 0.80559313, 0.05219143, 0.1277731 , 0.12546705,\n",
       "         0.03760726, 0.11426955, 0.10906576, 0.7655914 , 0.5787195 ,\n",
       "         0.18009976, 0.02516915, 0.26145914, 0.14275621]], dtype=float32),\n",
       " array([[0.17612629, 0.809695  , 0.06022158, 0.13324925, 0.12052512,\n",
       "         0.0475499 , 0.10111281, 0.10207631, 0.7602011 , 0.575749  ,\n",
       "         0.19490269, 0.02948336, 0.2601756 , 0.1327028 ]], dtype=float32),\n",
       " array([[0.19348456, 0.79846704, 0.07295989, 0.14634715, 0.13365532,\n",
       "         0.05550754, 0.08533129, 0.10848009, 0.7327707 , 0.5697411 ,\n",
       "         0.20628941, 0.03736296, 0.276348  , 0.13966008]], dtype=float32),\n",
       " array([[0.23155756, 0.78178215, 0.06374017, 0.15947214, 0.14372657,\n",
       "         0.04894942, 0.08747628, 0.11253236, 0.7021532 , 0.5706492 ,\n",
       "         0.2182444 , 0.03105466, 0.2886631 , 0.1391743 ]], dtype=float32),\n",
       " array([[0.21476819, 0.78287226, 0.05542113, 0.14347237, 0.13600476,\n",
       "         0.04498959, 0.09534212, 0.11260262, 0.6652214 , 0.57197833,\n",
       "         0.232816  , 0.02712921, 0.29167783, 0.12845503]], dtype=float32),\n",
       " array([[0.25552812, 0.77660656, 0.05575997, 0.1649202 , 0.14820054,\n",
       "         0.04315004, 0.09788013, 0.11447925, 0.69072556, 0.57211447,\n",
       "         0.21934518, 0.02620327, 0.2946257 , 0.14040017]], dtype=float32),\n",
       " array([[0.24219951, 0.78100616, 0.01642452, 0.1172016 , 0.10641854,\n",
       "         0.017123  , 0.12494449, 0.11245417, 0.67399126, 0.58943105,\n",
       "         0.23708415, 0.00605513, 0.26419204, 0.11046468]], dtype=float32),\n",
       " array([[2.9920408e-01, 7.5014091e-01, 2.1635527e-03, 8.2305938e-02,\n",
       "         7.5157642e-02, 3.5907524e-03, 1.8749422e-01, 1.1500179e-01,\n",
       "         5.3699201e-01, 6.1483002e-01, 3.0335540e-01, 5.4213847e-04,\n",
       "         2.5121832e-01, 7.1145892e-02]], dtype=float32),\n",
       " array([[3.38883102e-01, 7.30194986e-01, 1.83965964e-03, 9.38583985e-02,\n",
       "         7.50709027e-02, 3.40416026e-03, 1.91795200e-01, 1.11821845e-01,\n",
       "         4.83552665e-01, 6.14160478e-01, 3.39111239e-01, 4.35604394e-04,\n",
       "         2.62995571e-01, 6.49235696e-02]], dtype=float32),\n",
       " array([[0.34159887, 0.74236155, 0.00360946, 0.1176611 , 0.09375538,\n",
       "         0.00634349, 0.21006782, 0.11461555, 0.496593  , 0.60521877,\n",
       "         0.33826026, 0.0009424 , 0.28141773, 0.07702406]], dtype=float32),\n",
       " array([[0.2981787 , 0.76551014, 0.00567302, 0.11334697, 0.09580179,\n",
       "         0.00843367, 0.23766859, 0.11070749, 0.55845827, 0.6027537 ,\n",
       "         0.29371142, 0.00166843, 0.27519572, 0.08593741]], dtype=float32),\n",
       " array([[0.24605186, 0.78984016, 0.00854515, 0.10095183, 0.092173  ,\n",
       "         0.01094468, 0.22105035, 0.11234203, 0.62379986, 0.59697324,\n",
       "         0.2551901 , 0.00283453, 0.26578394, 0.09873074]], dtype=float32),\n",
       " array([[0.29392454, 0.7767549 , 0.00920514, 0.11685649, 0.10268393,\n",
       "         0.01078894, 0.2115701 , 0.11531464, 0.6352144 , 0.5948091 ,\n",
       "         0.24470831, 0.00301092, 0.27558407, 0.10871811]], dtype=float32),\n",
       " array([[0.31406435, 0.7626512 , 0.00819826, 0.11212129, 0.10294439,\n",
       "         0.00910896, 0.19795902, 0.12084214, 0.59435743, 0.59388286,\n",
       "         0.24968211, 0.0026944 , 0.28451428, 0.10692505]], dtype=float32),\n",
       " array([[0.3559714 , 0.7500415 , 0.00923784, 0.13355641, 0.11443543,\n",
       "         0.01034821, 0.21347144, 0.12090846, 0.5757794 , 0.5914535 ,\n",
       "         0.26176968, 0.00302437, 0.2996288 , 0.11073631]], dtype=float32),\n",
       " array([[0.3396591 , 0.76382816, 0.00967743, 0.13194935, 0.1149825 ,\n",
       "         0.01075443, 0.2580364 , 0.11695714, 0.6049135 , 0.5940041 ,\n",
       "         0.24722362, 0.0031903 , 0.2942403 , 0.11301897]], dtype=float32),\n",
       " array([[0.311193  , 0.76962614, 0.00412892, 0.09578173, 0.0844929 ,\n",
       "         0.00524674, 0.25705576, 0.11353673, 0.6087937 , 0.6048562 ,\n",
       "         0.24263668, 0.0011994 , 0.26461014, 0.09393243]], dtype=float32),\n",
       " array([[0.28433943, 0.78356165, 0.00463465, 0.09350043, 0.0822407 ,\n",
       "         0.00584307, 0.26842952, 0.10922706, 0.64567775, 0.60541254,\n",
       "         0.22962967, 0.00137791, 0.25570983, 0.09558912]], dtype=float32),\n",
       " array([[0.28753206, 0.7895042 , 0.00412201, 0.09638429, 0.08268157,\n",
       "         0.00568378, 0.32380268, 0.10654677, 0.64823127, 0.60872763,\n",
       "         0.23477788, 0.00116514, 0.25485805, 0.09349553]], dtype=float32),\n",
       " array([[0.20567814, 0.81383634, 0.0172208 , 0.09916489, 0.09503852,\n",
       "         0.01592832, 0.3244733 , 0.10054772, 0.7039419 , 0.5936838 ,\n",
       "         0.19139779, 0.00700927, 0.26426363, 0.11510033]], dtype=float32),\n",
       " array([[0.24404638, 0.8012742 , 0.01782002, 0.12247381, 0.11022885,\n",
       "         0.0185104 , 0.30764526, 0.10505059, 0.66795224, 0.590774  ,\n",
       "         0.22094299, 0.00683823, 0.28129008, 0.11678118]], dtype=float32),\n",
       " array([[0.2352216 , 0.79844815, 0.0192062 , 0.11528357, 0.1043564 ,\n",
       "         0.01888396, 0.2685697 , 0.107893  , 0.6626331 , 0.58645755,\n",
       "         0.2195832 , 0.00772988, 0.2822666 , 0.11904995]], dtype=float32),\n",
       " array([[0.16713123, 0.8311433 , 0.07642677, 0.11474627, 0.12046792,\n",
       "         0.04436755, 0.22294526, 0.10259462, 0.7869674 , 0.5738792 ,\n",
       "         0.14129913, 0.0445596 , 0.27153346, 0.1616832 ]], dtype=float32),\n",
       " array([[0.19574966, 0.82490605, 0.13339207, 0.15610741, 0.14826421,\n",
       "         0.07118176, 0.17841314, 0.10433083, 0.81900215, 0.5641743 ,\n",
       "         0.13430275, 0.08314989, 0.28433964, 0.19387475]], dtype=float32),\n",
       " array([[0.17926762, 0.8310356 , 0.21106732, 0.16204566, 0.16169254,\n",
       "         0.09930108, 0.17847706, 0.10254318, 0.8433052 , 0.56016546,\n",
       "         0.1188616 , 0.15106094, 0.2857143 , 0.21415278]], dtype=float32),\n",
       " array([[0.1732982 , 0.83007973, 0.14968699, 0.15261199, 0.14820866,\n",
       "         0.08079454, 0.18879299, 0.09821318, 0.82640654, 0.5672748 ,\n",
       "         0.13435744, 0.09698874, 0.27615383, 0.18561462]], dtype=float32),\n",
       " array([[0.16822858, 0.82853764, 0.16777879, 0.15371273, 0.14919771,\n",
       "         0.09012036, 0.18626824, 0.09766185, 0.822165  , 0.5645691 ,\n",
       "         0.13786946, 0.11322367, 0.2818136 , 0.18717758]], dtype=float32),\n",
       " array([[0.13729206, 0.8425592 , 0.11270706, 0.12546489, 0.12153786,\n",
       "         0.07023404, 0.18631342, 0.09106213, 0.83153975, 0.57124573,\n",
       "         0.14314535, 0.07011528, 0.25877926, 0.16462293]], dtype=float32),\n",
       " array([[0.14563933, 0.8317944 , 0.11297671, 0.13759583, 0.12934785,\n",
       "         0.07725828, 0.15876324, 0.09600101, 0.7993724 , 0.57042515,\n",
       "         0.16582318, 0.06707669, 0.2657053 , 0.15354761]], dtype=float32),\n",
       " array([[0.11394994, 0.84475386, 0.09373048, 0.1023904 , 0.10251949,\n",
       "         0.06106076, 0.15663317, 0.09116699, 0.82656395, 0.5732017 ,\n",
       "         0.14889783, 0.05704112, 0.2452394 , 0.14889656]], dtype=float32),\n",
       " array([[0.14138821, 0.8265327 , 0.06598686, 0.11010124, 0.10627887,\n",
       "         0.04699138, 0.14455298, 0.09927218, 0.7946224 , 0.5780096 ,\n",
       "         0.16720605, 0.03455563, 0.2481553 , 0.13751674]], dtype=float32),\n",
       " array([[0.16142341, 0.81618387, 0.13704981, 0.14547516, 0.14145306,\n",
       "         0.08666096, 0.12459972, 0.09926789, 0.76691175, 0.5643001 ,\n",
       "         0.17836799, 0.08829247, 0.28425145, 0.15924804]], dtype=float32),\n",
       " array([[0.17117672, 0.80897564, 0.10168693, 0.1443749 , 0.13606498,\n",
       "         0.07262077, 0.12808889, 0.10343077, 0.73999816, 0.56765753,\n",
       "         0.19806433, 0.05852614, 0.28395808, 0.14693458]], dtype=float32),\n",
       " array([[0.1875358 , 0.7961224 , 0.06742489, 0.13596615, 0.12877223,\n",
       "         0.05244132, 0.10939482, 0.11623699, 0.7177765 , 0.5718899 ,\n",
       "         0.21194182, 0.03344425, 0.27703568, 0.1387522 ]], dtype=float32),\n",
       " array([[0.18165562, 0.80860275, 0.0787074 , 0.13496263, 0.1338077 ,\n",
       "         0.05291794, 0.11609517, 0.10794236, 0.76655   , 0.5745972 ,\n",
       "         0.1776414 , 0.04207581, 0.26708588, 0.14845398]], dtype=float32),\n",
       " array([[0.19972998, 0.7991134 , 0.04184974, 0.12122305, 0.11577564,\n",
       "         0.03310344, 0.12714374, 0.11235312, 0.74769205, 0.57915914,\n",
       "         0.19659774, 0.01898818, 0.26502606, 0.13900626]], dtype=float32),\n",
       " array([[0.22311899, 0.7903992 , 0.02985788, 0.12071004, 0.11365493,\n",
       "         0.02578331, 0.1496717 , 0.11078007, 0.71779394, 0.5828065 ,\n",
       "         0.21310359, 0.01273092, 0.27178058, 0.13154624]], dtype=float32),\n",
       " array([[0.23614316, 0.77969027, 0.02010348, 0.11837494, 0.10923927,\n",
       "         0.02012336, 0.14114828, 0.1140712 , 0.6677174 , 0.58701956,\n",
       "         0.23991081, 0.00770828, 0.27179933, 0.11451877]], dtype=float32),\n",
       " array([[0.1968933 , 0.8005811 , 0.04819258, 0.12065881, 0.12103944,\n",
       "         0.03622074, 0.12706181, 0.11273148, 0.7265135 , 0.5763735 ,\n",
       "         0.19722693, 0.02355872, 0.27424645, 0.14014946]], dtype=float32),\n",
       " array([[0.23331979, 0.7871176 , 0.04697227, 0.14232033, 0.13094299,\n",
       "         0.03738342, 0.12774754, 0.11222033, 0.7097107 , 0.57419896,\n",
       "         0.21353391, 0.02183897, 0.2889293 , 0.14237839]], dtype=float32),\n",
       " array([[0.20792258, 0.7954041 , 0.04304377, 0.1233355 , 0.11934618,\n",
       "         0.03378818, 0.12844844, 0.10789011, 0.7063026 , 0.5751477 ,\n",
       "         0.20858292, 0.02093793, 0.28322166, 0.1358851 ]], dtype=float32),\n",
       " array([[0.2371472 , 0.78476137, 0.03733921, 0.13179432, 0.12113957,\n",
       "         0.03028285, 0.1355732 , 0.10848676, 0.6965704 , 0.5752798 ,\n",
       "         0.21721214, 0.01727377, 0.29088992, 0.13761161]], dtype=float32),\n",
       " array([[0.22588497, 0.78936124, 0.02335043, 0.11130004, 0.1078531 ,\n",
       "         0.02067418, 0.14132167, 0.11046028, 0.68713653, 0.5819233 ,\n",
       "         0.21797216, 0.00988436, 0.2789618 , 0.12522894]], dtype=float32),\n",
       " array([[0.23950164, 0.7832924 , 0.0325899 , 0.12710692, 0.11816727,\n",
       "         0.02759224, 0.15078008, 0.11167201, 0.6760986 , 0.57681394,\n",
       "         0.22511785, 0.01465846, 0.2926382 , 0.1337628 ]], dtype=float32),\n",
       " array([[0.25481796, 0.77688193, 0.02090321, 0.12465876, 0.11480321,\n",
       "         0.0201613 , 0.15743545, 0.11037504, 0.6394505 , 0.5849577 ,\n",
       "         0.2420616 , 0.00842321, 0.28678373, 0.11577592]], dtype=float32),\n",
       " array([[0.18944077, 0.813527  , 0.06060069, 0.12103371, 0.1239233 ,\n",
       "         0.04099255, 0.14048395, 0.10909767, 0.75796866, 0.57310706,\n",
       "         0.17487684, 0.03236995, 0.27607557, 0.15523198]], dtype=float32),\n",
       " array([[0.21542446, 0.8083011 , 0.06232518, 0.13484867, 0.12692036,\n",
       "         0.04177873, 0.16334201, 0.10538809, 0.7739572 , 0.57003814,\n",
       "         0.17325406, 0.03303068, 0.2871028 , 0.16921468]], dtype=float32),\n",
       " array([[0.22397521, 0.80034995, 0.04726595, 0.13084078, 0.12541322,\n",
       "         0.03597509, 0.19734943, 0.1079441 , 0.72531366, 0.57346964,\n",
       "         0.19921836, 0.02349477, 0.29671213, 0.15471743]], dtype=float32),\n",
       " array([[0.2040818 , 0.808304  , 0.0381026 , 0.12059893, 0.11432876,\n",
       "         0.03131904, 0.20260972, 0.10514362, 0.7387106 , 0.57982945,\n",
       "         0.19678609, 0.01775587, 0.27813688, 0.1414458 ]], dtype=float32),\n",
       " array([[0.23904818, 0.7927204 , 0.04458252, 0.153615  , 0.13782184,\n",
       "         0.03761991, 0.17203924, 0.10896192, 0.70665735, 0.5803808 ,\n",
       "         0.21308136, 0.01977504, 0.28710568, 0.13509324]], dtype=float32),\n",
       " array([[0.21953286, 0.7972339 , 0.02733851, 0.11396354, 0.10887241,\n",
       "         0.02290155, 0.19157009, 0.10620187, 0.71128917, 0.5840542 ,\n",
       "         0.20267811, 0.01203436, 0.27604783, 0.1300614 ]], dtype=float32),\n",
       " array([[0.19379519, 0.80762744, 0.0353095 , 0.10725416, 0.104256  ,\n",
       "         0.0270175 , 0.16855043, 0.10864838, 0.7507852 , 0.5798906 ,\n",
       "         0.18410863, 0.01645946, 0.26746994, 0.14136977]], dtype=float32),\n",
       " array([[0.21715282, 0.7936065 , 0.02629193, 0.10886175, 0.10286424,\n",
       "         0.02192904, 0.19495009, 0.10750856, 0.7080627 , 0.5833198 ,\n",
       "         0.20547348, 0.01151073, 0.27672905, 0.13008693]], dtype=float32),\n",
       " array([[0.20615889, 0.79722893, 0.02454614, 0.10048357, 0.09633962,\n",
       "         0.02000993, 0.21357957, 0.10660664, 0.71830004, 0.5854715 ,\n",
       "         0.19665846, 0.01075971, 0.26957905, 0.12859389]], dtype=float32),\n",
       " array([[0.21466404, 0.7966205 , 0.02506238, 0.11585986, 0.10715538,\n",
       "         0.02328607, 0.1866365 , 0.11094239, 0.7047634 , 0.5868601 ,\n",
       "         0.21491322, 0.01021264, 0.26851755, 0.12288541]], dtype=float32),\n",
       " array([[0.21932432, 0.7880896 , 0.00686709, 0.08043997, 0.07774197,\n",
       "         0.00846283, 0.2393225 , 0.11135285, 0.6393433 , 0.6017649 ,\n",
       "         0.2462102 , 0.00227825, 0.25442734, 0.09503405]], dtype=float32),\n",
       " array([[0.20908077, 0.79680014, 0.01520622, 0.0995208 , 0.09289438,\n",
       "         0.01581777, 0.205781  , 0.10964654, 0.6829626 , 0.59354883,\n",
       "         0.22403704, 0.00569011, 0.2592358 , 0.10828814]], dtype=float32),\n",
       " array([[0.22189882, 0.7992468 , 0.01404204, 0.10187408, 0.09528236,\n",
       "         0.01480433, 0.21083385, 0.10863405, 0.6929837 , 0.5936152 ,\n",
       "         0.22069505, 0.00522311, 0.2609553 , 0.11333555]], dtype=float32),\n",
       " array([[0.24956502, 0.79270506, 0.02495888, 0.13839446, 0.12032138,\n",
       "         0.02424799, 0.21959059, 0.10470968, 0.69239545, 0.5879617 ,\n",
       "         0.22264038, 0.00997016, 0.2803244 , 0.12302234]], dtype=float32),\n",
       " array([[0.21330456, 0.80636406, 0.0254964 , 0.11515649, 0.10753307,\n",
       "         0.02351325, 0.20816739, 0.1075556 , 0.71881825, 0.5856547 ,\n",
       "         0.20654719, 0.01070699, 0.27054983, 0.12940654]], dtype=float32),\n",
       " array([[0.2510802 , 0.78508013, 0.01500552, 0.11802783, 0.10469756,\n",
       "         0.01600496, 0.18293029, 0.1128402 , 0.6674436 , 0.5916735 ,\n",
       "         0.23367356, 0.00540623, 0.2696169 , 0.1122211 ]], dtype=float32),\n",
       " array([[0.266086  , 0.7738737 , 0.01603497, 0.1209692 , 0.10924324,\n",
       "         0.0156618 , 0.18005778, 0.11303396, 0.64256877, 0.5910252 ,\n",
       "         0.23232682, 0.00597165, 0.27777007, 0.11094408]], dtype=float32),\n",
       " array([[0.25154376, 0.78686684, 0.01445111, 0.11411482, 0.10311321,\n",
       "         0.01492443, 0.21045075, 0.11160114, 0.6714436 , 0.592943  ,\n",
       "         0.22626096, 0.00524241, 0.27042657, 0.11354264]], dtype=float32),\n",
       " array([[0.28433496, 0.7758995 , 0.01557842, 0.13339405, 0.11501525,\n",
       "         0.016409  , 0.1914178 , 0.11296832, 0.64937603, 0.5913422 ,\n",
       "         0.23941031, 0.00554279, 0.2803227 , 0.11367838]], dtype=float32),\n",
       " array([[0.2291903 , 0.80142534, 0.01424363, 0.10523801, 0.09828701,\n",
       "         0.01425836, 0.21158223, 0.10929728, 0.70819205, 0.5956295 ,\n",
       "         0.20554012, 0.00521887, 0.25564155, 0.11470036]], dtype=float32),\n",
       " array([[0.2258509 , 0.8058327 , 0.02782535, 0.12343237, 0.11416972,\n",
       "         0.0242891 , 0.18169773, 0.1114224 , 0.7338032 , 0.58468324,\n",
       "         0.19450897, 0.01159229, 0.26768175, 0.13514127]], dtype=float32),\n",
       " array([[0.22525544, 0.8019148 , 0.02476026, 0.11378331, 0.10754253,\n",
       "         0.02094446, 0.16481951, 0.11386847, 0.73020905, 0.5845319 ,\n",
       "         0.19177221, 0.01029438, 0.26567838, 0.13431501]], dtype=float32),\n",
       " array([[0.15113835, 0.83438665, 0.08745076, 0.10859504, 0.11557394,\n",
       "         0.05226281, 0.14028242, 0.11278874, 0.8115559 , 0.56770533,\n",
       "         0.14485197, 0.05147789, 0.26367742, 0.17719038]], dtype=float32),\n",
       " array([[0.19431928, 0.80883473, 0.08363824, 0.13293445, 0.1272108 ,\n",
       "         0.05118795, 0.1088397 , 0.11453649, 0.77856797, 0.56522614,\n",
       "         0.16364375, 0.04645465, 0.27950656, 0.1716556 ]], dtype=float32),\n",
       " array([[0.22634357, 0.7946345 , 0.06040762, 0.14948007, 0.13774167,\n",
       "         0.04253865, 0.14447057, 0.10827401, 0.7293934 , 0.57574797,\n",
       "         0.18886936, 0.02995393, 0.2855239 , 0.14537571]], dtype=float32),\n",
       " array([[0.22664891, 0.7884468 , 0.0238026 , 0.11423143, 0.10831929,\n",
       "         0.02021938, 0.16684176, 0.10912443, 0.6900651 , 0.5871373 ,\n",
       "         0.2070988 , 0.00995833, 0.2716315 , 0.12033021]], dtype=float32),\n",
       " array([[0.23108685, 0.7858665 , 0.02318995, 0.11950053, 0.10955897,\n",
       "         0.02051387, 0.15799664, 0.10702825, 0.679198  , 0.5876456 ,\n",
       "         0.21456972, 0.00956255, 0.27176052, 0.11492737]], dtype=float32),\n",
       " array([[0.242314  , 0.7833409 , 0.01759749, 0.12094344, 0.108453  ,\n",
       "         0.01738887, 0.1744969 , 0.1053847 , 0.660428  , 0.59285647,\n",
       "         0.22760142, 0.00671981, 0.26933286, 0.10594291]], dtype=float32),\n",
       " array([[0.2299191 , 0.7893155 , 0.00692016, 0.09436534, 0.08459893,\n",
       "         0.00921142, 0.20118743, 0.10517369, 0.6330317 , 0.60444754,\n",
       "         0.2535073 , 0.00220166, 0.24913125, 0.08656447]], dtype=float32),\n",
       " array([[0.24916413, 0.78554535, 0.00800579, 0.1085896 , 0.09271379,\n",
       "         0.01086709, 0.2134021 , 0.10536794, 0.6227507 , 0.6024874 ,\n",
       "         0.26320916, 0.00254502, 0.25802597, 0.08928738]], dtype=float32),\n",
       " array([[2.5125346e-01, 7.7508962e-01, 2.0173562e-03, 7.1818836e-02,\n",
       "         6.4314961e-02, 3.7043712e-03, 2.7932853e-01, 1.0805359e-01,\n",
       "         5.3685945e-01, 6.1717671e-01, 3.0384496e-01, 5.1952392e-04,\n",
       "         2.4549635e-01, 6.7157842e-02]], dtype=float32),\n",
       " array([[0.30691218, 0.7570718 , 0.00448717, 0.11039142, 0.0902568 ,\n",
       "         0.00729043, 0.2523847 , 0.11041367, 0.5062848 , 0.6040644 ,\n",
       "         0.31932077, 0.00127382, 0.28230384, 0.0785961 ]], dtype=float32),\n",
       " array([[0.24806918, 0.78498304, 0.00758531, 0.09645434, 0.08849341,\n",
       "         0.00965164, 0.22574076, 0.11176015, 0.59517926, 0.59857255,\n",
       "         0.25921425, 0.00251754, 0.268557  , 0.09333178]], dtype=float32),\n",
       " array([[0.27497488, 0.7797588 , 0.0128544 , 0.12472767, 0.10814767,\n",
       "         0.01457342, 0.22765677, 0.10957949, 0.6135184 , 0.59357697,\n",
       "         0.25028077, 0.00454215, 0.2822119 , 0.1043093 ]], dtype=float32),\n",
       " array([[0.3133933 , 0.76690733, 0.01091216, 0.12718809, 0.11159401,\n",
       "         0.01136056, 0.20487131, 0.11234545, 0.61498713, 0.59498686,\n",
       "         0.23688841, 0.00373587, 0.28379786, 0.10680963]], dtype=float32),\n",
       " array([[0.31614518, 0.7641492 , 0.00550491, 0.1065615 , 0.09481736,\n",
       "         0.00689529, 0.25055167, 0.11409776, 0.5827414 , 0.6027424 ,\n",
       "         0.2578459 , 0.00167529, 0.27614385, 0.09525162]], dtype=float32),\n",
       " array([[0.3070149 , 0.772917  , 0.02011149, 0.14103042, 0.12742901,\n",
       "         0.01719158, 0.22514927, 0.11200916, 0.6456197 , 0.58887595,\n",
       "         0.21283424, 0.00793711, 0.29371676, 0.1239647 ]], dtype=float32),\n",
       " array([[0.30559045, 0.7817578 , 0.01430698, 0.14922988, 0.12610386,\n",
       "         0.01533955, 0.25045666, 0.10523474, 0.6501045 , 0.59844214,\n",
       "         0.22758079, 0.00492472, 0.27752367, 0.10770999]], dtype=float32),\n",
       " array([[0.2712916 , 0.7844541 , 0.00865823, 0.10755396, 0.09517325,\n",
       "         0.00966539, 0.24997967, 0.10596776, 0.64375985, 0.5998889 ,\n",
       "         0.22719261, 0.00294022, 0.266289  , 0.10125999]], dtype=float32),\n",
       " array([[0.25304863, 0.79064995, 0.00770526, 0.09726129, 0.08511312,\n",
       "         0.00864868, 0.25828037, 0.10199399, 0.66049033, 0.60071045,\n",
       "         0.22008273, 0.00262438, 0.2585558 , 0.09928513]], dtype=float32),\n",
       " array([[0.18201412, 0.82686806, 0.04482028, 0.1077799 , 0.10970428,\n",
       "         0.02953526, 0.2127192 , 0.10596007, 0.7842184 , 0.5810211 ,\n",
       "         0.14811577, 0.02268912, 0.25927916, 0.15193538]], dtype=float32),\n",
       " array([[0.15492137, 0.8420064 , 0.09411213, 0.11738823, 0.11860665,\n",
       "         0.05754286, 0.17406093, 0.10632843, 0.82413936, 0.56541425,\n",
       "         0.14011227, 0.05703051, 0.26828843, 0.18706965]], dtype=float32),\n",
       " array([[0.16190028, 0.83669955, 0.14445162, 0.14802134, 0.1430615 ,\n",
       "         0.08795679, 0.15036142, 0.10662826, 0.8162903 , 0.5619285 ,\n",
       "         0.14733113, 0.09116663, 0.27846855, 0.1875653 ]], dtype=float32),\n",
       " array([[0.1981608 , 0.81491864, 0.10988992, 0.16009681, 0.14865269,\n",
       "         0.0694141 , 0.14385214, 0.11077807, 0.78142434, 0.5667783 ,\n",
       "         0.16314223, 0.06188451, 0.28415233, 0.1718739 ]], dtype=float32),\n",
       " array([[0.174795  , 0.81514615, 0.04587602, 0.09677622, 0.0961738 ,\n",
       "         0.0290484 , 0.16700041, 0.11066885, 0.78812855, 0.5731539 ,\n",
       "         0.15424334, 0.02370116, 0.2643109 , 0.16071273]], dtype=float32),\n",
       " array([[0.21377645, 0.8002099 , 0.07262036, 0.1407611 , 0.13344646,\n",
       "         0.04609256, 0.1773789 , 0.10718476, 0.74613667, 0.5710295 ,\n",
       "         0.17410152, 0.03946277, 0.29222104, 0.15960538]], dtype=float32),\n",
       " array([[0.17973922, 0.8174534 , 0.05257113, 0.12001727, 0.11285733,\n",
       "         0.03857806, 0.21453002, 0.09765501, 0.76354724, 0.5777135 ,\n",
       "         0.17654042, 0.02713485, 0.2737749 , 0.14442538]], dtype=float32),\n",
       " array([[0.17153265, 0.81729084, 0.04246188, 0.11546304, 0.10746092,\n",
       "         0.03423123, 0.19486323, 0.10169572, 0.7618631 , 0.5838203 ,\n",
       "         0.18219635, 0.01970547, 0.257474  , 0.13033816]], dtype=float32),\n",
       " array([[0.18357739, 0.81536657, 0.03641757, 0.1149848 , 0.10590118,\n",
       "         0.02957649, 0.20959154, 0.09865955, 0.76481503, 0.5858224 ,\n",
       "         0.18171683, 0.01653371, 0.25830898, 0.13101114]], dtype=float32),\n",
       " array([[0.18615931, 0.8096837 , 0.04698591, 0.12443405, 0.11657777,\n",
       "         0.03833586, 0.1923218 , 0.10277221, 0.731383  , 0.5806334 ,\n",
       "         0.19928257, 0.02259234, 0.27245253, 0.13270284]], dtype=float32),\n",
       " array([[0.19535467, 0.8033451 , 0.03205886, 0.11567389, 0.10898392,\n",
       "         0.02960368, 0.22147761, 0.10585637, 0.6960995 , 0.58389384,\n",
       "         0.22026922, 0.01430176, 0.27556935, 0.12460017]], dtype=float32),\n",
       " array([[0.18209966, 0.807585  , 0.03807122, 0.11361176, 0.10823669,\n",
       "         0.03328948, 0.20155904, 0.10499556, 0.7052273 , 0.5810647 ,\n",
       "         0.21258286, 0.01791839, 0.27417532, 0.126572  ]], dtype=float32),\n",
       " array([[0.2161413 , 0.7968449 , 0.02906175, 0.12013104, 0.1100269 ,\n",
       "         0.02604619, 0.177153  , 0.10902897, 0.70723724, 0.5831263 ,\n",
       "         0.21293378, 0.01249822, 0.27262914, 0.12822092]], dtype=float32),\n",
       " array([[0.23403849, 0.7970334 , 0.02661585, 0.12978494, 0.11818819,\n",
       "         0.02448343, 0.17651825, 0.10888378, 0.7142893 , 0.587338  ,\n",
       "         0.20991758, 0.01089056, 0.2680309 , 0.12696916]], dtype=float32),\n",
       " array([[0.22843772, 0.80037737, 0.03953287, 0.1388016 , 0.12818743,\n",
       "         0.03240991, 0.14085604, 0.11123037, 0.73397315, 0.58064187,\n",
       "         0.1967659 , 0.01761759, 0.27165174, 0.1396426 ]], dtype=float32),\n",
       " array([[0.24582045, 0.8006483 , 0.06478754, 0.18186252, 0.16258502,\n",
       "         0.05139005, 0.13836461, 0.10777352, 0.73567724, 0.5778373 ,\n",
       "         0.1982651 , 0.03057662, 0.28403205, 0.14606553]], dtype=float32),\n",
       " array([[0.24620329, 0.7916521 , 0.04741993, 0.15670763, 0.1421644 ,\n",
       "         0.03852958, 0.15575944, 0.11044881, 0.7085285 , 0.57830006,\n",
       "         0.20872322, 0.02169263, 0.2884016 , 0.14080378]], dtype=float32),\n",
       " array([[0.25184053, 0.79031783, 0.0338181 , 0.15109323, 0.13596539,\n",
       "         0.03027419, 0.16741942, 0.10909977, 0.69645077, 0.5849641 ,\n",
       "         0.2167036 , 0.01415824, 0.28065154, 0.12809038]], dtype=float32),\n",
       " array([[0.2552857 , 0.78719527, 0.02781703, 0.14244157, 0.1267414 ,\n",
       "         0.02554925, 0.16612063, 0.11058333, 0.6937032 , 0.58537984,\n",
       "         0.21857977, 0.01122803, 0.2791784 , 0.12656009]], dtype=float32),\n",
       " array([[0.25058624, 0.79125226, 0.02549533, 0.13878429, 0.12297481,\n",
       "         0.02370924, 0.15439874, 0.10786558, 0.7026596 , 0.5869687 ,\n",
       "         0.2144415 , 0.01015536, 0.2725691 , 0.12322687]], dtype=float32),\n",
       " array([[0.25479224, 0.78824514, 0.02005917, 0.13412943, 0.1184346 ,\n",
       "         0.02041887, 0.18299334, 0.10707115, 0.6773241 , 0.590964  ,\n",
       "         0.22915731, 0.00759106, 0.27349144, 0.11467978]], dtype=float32),\n",
       " array([[0.2557557 , 0.7864648 , 0.01957475, 0.13385953, 0.11814804,\n",
       "         0.01994746, 0.18450856, 0.10393362, 0.66259277, 0.58926535,\n",
       "         0.23285586, 0.00748969, 0.2820135 , 0.11212242]], dtype=float32),\n",
       " array([[0.1840873 , 0.81218696, 0.03089749, 0.09954464, 0.10076167,\n",
       "         0.0246453 , 0.15309635, 0.11185405, 0.73815817, 0.58162063,\n",
       "         0.18631445, 0.0141963 , 0.26054025, 0.13448249]], dtype=float32),\n",
       " array([[0.20691608, 0.7998306 , 0.02573097, 0.10269151, 0.09978279,\n",
       "         0.02150953, 0.14889328, 0.11491083, 0.7170415 , 0.580356  ,\n",
       "         0.19910201, 0.0112475 , 0.26907712, 0.13402592]], dtype=float32),\n",
       " array([[0.19921844, 0.8060072 , 0.03264654, 0.10609499, 0.10440349,\n",
       "         0.02582623, 0.1604204 , 0.114328  , 0.7356611 , 0.5783173 ,\n",
       "         0.18959874, 0.01508862, 0.27010664, 0.1429017 ]], dtype=float32),\n",
       " array([[0.21292323, 0.80016917, 0.02422962, 0.10504672, 0.099968  ,\n",
       "         0.02085798, 0.19562368, 0.11210177, 0.7208947 , 0.5825946 ,\n",
       "         0.19972518, 0.01042047, 0.27176026, 0.13536312]], dtype=float32),\n",
       " array([[0.22359742, 0.7921166 , 0.01403878, 0.09470427, 0.09117566,\n",
       "         0.01352881, 0.22232541, 0.11060943, 0.6839048 , 0.5913509 ,\n",
       "         0.21421619, 0.00546329, 0.26682904, 0.11706063]], dtype=float32),\n",
       " array([[0.25513086, 0.78072286, 0.0147793 , 0.11274674, 0.10255038,\n",
       "         0.01461625, 0.22180724, 0.10870956, 0.6576301 , 0.5919005 ,\n",
       "         0.22751862, 0.00558756, 0.2770506 , 0.11320605]], dtype=float32),\n",
       " array([[0.23797604, 0.79150534, 0.02316607, 0.11914214, 0.1096132 ,\n",
       "         0.02056015, 0.1964368 , 0.10957158, 0.69372106, 0.585548  ,\n",
       "         0.2096937 , 0.00958692, 0.277256  , 0.12645218]], dtype=float32),\n",
       " array([[0.20150845, 0.8108454 , 0.02976953, 0.11060974, 0.10636598,\n",
       "         0.0245576 , 0.18665802, 0.10808121, 0.7427447 , 0.58344436,\n",
       "         0.18664864, 0.01319987, 0.26564193, 0.13581017]], dtype=float32),\n",
       " array([[0.20992781, 0.80625   , 0.02411005, 0.11014498, 0.1020728 ,\n",
       "         0.02159612, 0.1991296 , 0.10697631, 0.7299567 , 0.5855062 ,\n",
       "         0.19845937, 0.01007169, 0.2667781 , 0.12943733]], dtype=float32),\n",
       " array([[0.19804211, 0.80897844, 0.03336678, 0.10977481, 0.10682995,\n",
       "         0.0269431 , 0.19460066, 0.10918854, 0.7341957 , 0.58073   ,\n",
       "         0.19099781, 0.0153239 , 0.27283028, 0.13897327]], dtype=float32),\n",
       " array([[0.2044188 , 0.8024195 , 0.03863142, 0.11486743, 0.10914592,\n",
       "         0.02960323, 0.16829215, 0.11123579, 0.73125887, 0.57741106,\n",
       "         0.19139187, 0.01823272, 0.2756111 , 0.1425356 ]], dtype=float32),\n",
       " array([[0.21868026, 0.79305285, 0.01646574, 0.10128677, 0.09695037,\n",
       "         0.01631211, 0.20446184, 0.10941404, 0.6653211 , 0.5905202 ,\n",
       "         0.22608137, 0.0064634 , 0.27039632, 0.11202534]], dtype=float32),\n",
       " array([[0.24493161, 0.7792396 , 0.00909715, 0.09747107, 0.08811797,\n",
       "         0.01038174, 0.18860401, 0.10862752, 0.6288517 , 0.5967831 ,\n",
       "         0.24593383, 0.00314273, 0.26500618, 0.09707188]], dtype=float32),\n",
       " array([[0.23524371, 0.7897608 , 0.01263594, 0.10169063, 0.09307809,\n",
       "         0.01308225, 0.20130727, 0.10959775, 0.6710764 , 0.59339476,\n",
       "         0.2243245 , 0.0045914 , 0.26540226, 0.10902488]], dtype=float32),\n",
       " array([[0.23108089, 0.79756176, 0.0177461 , 0.11500712, 0.1038024 ,\n",
       "         0.01749848, 0.1930057 , 0.10501949, 0.69326526, 0.59182113,\n",
       "         0.21476395, 0.00683095, 0.26498252, 0.11344475]], dtype=float32),\n",
       " array([[0.22403778, 0.79542595, 0.01664485, 0.10710312, 0.09795496,\n",
       "         0.01644737, 0.18589225, 0.10648206, 0.6816673 , 0.59027517,\n",
       "         0.21867296, 0.0064493 , 0.26659203, 0.11189041]], dtype=float32),\n",
       " array([[0.20909238, 0.8057562 , 0.02627864, 0.11227556, 0.10489903,\n",
       "         0.02361809, 0.18143967, 0.10929278, 0.71452683, 0.5830091 ,\n",
       "         0.20489787, 0.01119764, 0.2711864 , 0.12915073]], dtype=float32),\n",
       " array([[0.22314258, 0.8000596 , 0.0373284 , 0.1287615 , 0.11963362,\n",
       "         0.02999831, 0.18838462, 0.1095314 , 0.7164066 , 0.5801971 ,\n",
       "         0.19777699, 0.01685624, 0.28165385, 0.13764851]], dtype=float32),\n",
       " array([[0.24146038, 0.78028643, 0.00734253, 0.08650816, 0.08440613,\n",
       "         0.00848702, 0.2266539 , 0.11361279, 0.60988975, 0.59974027,\n",
       "         0.24614649, 0.00246324, 0.26568136, 0.09554971]], dtype=float32),\n",
       " array([[0.28239882, 0.7658007 , 0.01197099, 0.12057659, 0.10567678,\n",
       "         0.0129183 , 0.20644791, 0.10714803, 0.58821785, 0.5940186 ,\n",
       "         0.25661254, 0.00427833, 0.28730875, 0.09845025]], dtype=float32),\n",
       " array([[0.19011869, 0.81925315, 0.03391553, 0.10491007, 0.10603271,\n",
       "         0.02541494, 0.17030628, 0.11205966, 0.76654184, 0.5824973 ,\n",
       "         0.1678679 , 0.01556823, 0.25772518, 0.14364901]], dtype=float32),\n",
       " array([[0.23490696, 0.8038028 , 0.03675864, 0.13486369, 0.12209894,\n",
       "         0.02895456, 0.17906335, 0.10851989, 0.74583286, 0.58072805,\n",
       "         0.18529573, 0.0162928 , 0.27569702, 0.1448802 ]], dtype=float32),\n",
       " array([[0.22736949, 0.80029064, 0.0292558 , 0.12180251, 0.11433074,\n",
       "         0.02372573, 0.17641035, 0.1078148 , 0.7218072 , 0.58414364,\n",
       "         0.19162518, 0.01273341, 0.27228048, 0.13224505]], dtype=float32),\n",
       " array([[0.22695832, 0.79865545, 0.04081285, 0.13756539, 0.12663661,\n",
       "         0.03237643, 0.16334413, 0.10976803, 0.7180653 , 0.58048385,\n",
       "         0.1958852 , 0.0184585 , 0.2785819 , 0.13591479]], dtype=float32),\n",
       " array([[0.20923124, 0.8075358 , 0.054137  , 0.1369932 , 0.1300103 ,\n",
       "         0.03953816, 0.17071356, 0.10910951, 0.7439997 , 0.57822555,\n",
       "         0.18185925, 0.0263317 , 0.27690575, 0.14578599]], dtype=float32),\n",
       " array([[0.2165728 , 0.80115867, 0.06144741, 0.14488056, 0.13559945,\n",
       "         0.04363893, 0.1523691 , 0.10916504, 0.73343843, 0.57489306,\n",
       "         0.18629204, 0.03078687, 0.28472155, 0.14739703]], dtype=float32),\n",
       " array([[0.22840528, 0.7947175 , 0.04155031, 0.13567847, 0.12628551,\n",
       "         0.03237677, 0.17814183, 0.10735472, 0.70805395, 0.57942605,\n",
       "         0.20017187, 0.01930021, 0.28675252, 0.13664219]], dtype=float32),\n",
       " array([[0.21884447, 0.79728997, 0.03009122, 0.12192364, 0.1125778 ,\n",
       "         0.02443703, 0.16662088, 0.10447934, 0.71762305, 0.58523256,\n",
       "         0.19452092, 0.01314779, 0.26914778, 0.12490914]], dtype=float32),\n",
       " array([[0.20143792, 0.8053515 , 0.0419228 , 0.12194887, 0.11647785,\n",
       "         0.03140356, 0.15508763, 0.10275234, 0.7301811 , 0.5797999 ,\n",
       "         0.18677145, 0.02043811, 0.2733761 , 0.13418682]], dtype=float32),\n",
       " array([[0.2414352 , 0.78747165, 0.08840581, 0.16684183, 0.15478988,\n",
       "         0.05633669, 0.14037263, 0.10732255, 0.7064377 , 0.5666236 ,\n",
       "         0.19248702, 0.04985822, 0.31089818, 0.15846506]], dtype=float32),\n",
       " array([[0.22304039, 0.78865975, 0.05161252, 0.14268883, 0.1315631 ,\n",
       "         0.03925503, 0.14877433, 0.109029  , 0.6856076 , 0.57650566,\n",
       "         0.20877758, 0.02495693, 0.28989968, 0.13235447]], dtype=float32),\n",
       " array([[0.22445275, 0.79958546, 0.04879986, 0.15633105, 0.1418023 ,\n",
       "         0.04091295, 0.16632919, 0.1034484 , 0.70197976, 0.5827942 ,\n",
       "         0.20911112, 0.02232246, 0.28146687, 0.1264607 ]], dtype=float32),\n",
       " array([[0.2238367 , 0.8031646 , 0.03936561, 0.14508839, 0.1322208 ,\n",
       "         0.03415524, 0.15958057, 0.1017349 , 0.71125793, 0.58349746,\n",
       "         0.20747788, 0.01770798, 0.2769608 , 0.1268712 ]], dtype=float32),\n",
       " array([[0.22786689, 0.8007    , 0.04369168, 0.15045655, 0.13555175,\n",
       "         0.03755494, 0.16228281, 0.10474034, 0.7110895 , 0.58115304,\n",
       "         0.20986523, 0.01972567, 0.2818379 , 0.13171986]], dtype=float32),\n",
       " array([[0.22720772, 0.7983739 , 0.00815516, 0.10216527, 0.0973699 ,\n",
       "         0.01127734, 0.25361383, 0.09792674, 0.60847807, 0.60579544,\n",
       "         0.26562312, 0.00274496, 0.2618249 , 0.08524621]], dtype=float32),\n",
       " array([[0.28458115, 0.76682186, 0.00540163, 0.11295488, 0.09655074,\n",
       "         0.00818292, 0.23344316, 0.09863412, 0.53067076, 0.60825896,\n",
       "         0.30184597, 0.00162227, 0.2737512 , 0.07382632]], dtype=float32),\n",
       " array([[0.30622023, 0.7597421 , 0.00371288, 0.11092819, 0.09196811,\n",
       "         0.00609696, 0.22926003, 0.1012312 , 0.5168155 , 0.6129336 ,\n",
       "         0.30886063, 0.00100571, 0.26773667, 0.06875455]], dtype=float32),\n",
       " array([[0.2573178 , 0.7772339 , 0.00576627, 0.09209456, 0.08109987,\n",
       "         0.00748831, 0.17990065, 0.11058316, 0.60339355, 0.6003063 ,\n",
       "         0.25857803, 0.00179897, 0.26042038, 0.08858113]], dtype=float32),\n",
       " array([[0.2613577 , 0.7924145 , 0.01584875, 0.13424377, 0.11588829,\n",
       "         0.01769346, 0.1863959 , 0.10756876, 0.6614365 , 0.5938747 ,\n",
       "         0.23459582, 0.00559022, 0.27011594, 0.10720007]], dtype=float32),\n",
       " array([[0.27198774, 0.78586227, 0.00465179, 0.10217699, 0.09173163,\n",
       "         0.00695091, 0.24356249, 0.10732883, 0.5990552 , 0.6115047 ,\n",
       "         0.26483938, 0.00130022, 0.25390023, 0.08115569]], dtype=float32),\n",
       " array([[0.32848626, 0.7600712 , 0.01003379, 0.1389946 , 0.11736994,\n",
       "         0.01173404, 0.23868611, 0.10876419, 0.57111835, 0.59837013,\n",
       "         0.26531777, 0.00326429, 0.29211682, 0.09658689]], dtype=float32),\n",
       " array([[0.22794083, 0.794464  , 0.0225981 , 0.10043953, 0.10014483,\n",
       "         0.01762505, 0.20278412, 0.11476747, 0.6898458 , 0.58187944,\n",
       "         0.19316581, 0.00994372, 0.28185818, 0.13402608]], dtype=float32),\n",
       " array([[0.25176466, 0.78281677, 0.01792175, 0.10838888, 0.10249838,\n",
       "         0.01575048, 0.18059398, 0.11744495, 0.6620291 , 0.5842893 ,\n",
       "         0.21332212, 0.0071375 , 0.28238133, 0.12427521]], dtype=float32),\n",
       " array([[0.25130042, 0.78778434, 0.00629183, 0.08647381, 0.08054477,\n",
       "         0.00710745, 0.24201316, 0.10926599, 0.65527153, 0.60173637,\n",
       "         0.22181801, 0.00203973, 0.25709924, 0.09915582]], dtype=float32),\n",
       " array([[0.22817722, 0.7990124 , 0.00898397, 0.08619644, 0.07992408,\n",
       "         0.00905755, 0.24232031, 0.10682365, 0.70339894, 0.5974056 ,\n",
       "         0.19934545, 0.0031847 , 0.25304186, 0.10991967]], dtype=float32),\n",
       " array([[0.26337552, 0.78775287, 0.01777709, 0.11656971, 0.1041823 ,\n",
       "         0.01511258, 0.2239095 , 0.10779088, 0.70204514, 0.58836955,\n",
       "         0.1950723 , 0.00700184, 0.27671638, 0.12684712]], dtype=float32),\n",
       " array([[0.23877916, 0.7823347 , 0.00531098, 0.07960323, 0.0746231 ,\n",
       "         0.00667218, 0.28172946, 0.10741483, 0.5937563 , 0.6025972 ,\n",
       "         0.25162366, 0.0017201 , 0.26487783, 0.08815869]], dtype=float32),\n",
       " array([[0.22412062, 0.79356986, 0.00781488, 0.09301286, 0.08222576,\n",
       "         0.01013002, 0.26690835, 0.10252971, 0.6140591 , 0.5993114 ,\n",
       "         0.25389063, 0.00263211, 0.26542643, 0.08937427]], dtype=float32),\n",
       " array([[0.22662537, 0.7929724 , 0.00667672, 0.08765547, 0.0779011 ,\n",
       "         0.00840624, 0.29203847, 0.10057138, 0.62404644, 0.6028599 ,\n",
       "         0.2426209 , 0.00220431, 0.25978434, 0.08773749]], dtype=float32),\n",
       " array([[0.2407658 , 0.7834765 , 0.00271034, 0.06630461, 0.06334935,\n",
       "         0.00384146, 0.3296524 , 0.10503259, 0.578323  , 0.6122074 ,\n",
       "         0.25438577, 0.00078945, 0.2522908 , 0.0769056 ]], dtype=float32),\n",
       " array([[2.6607823e-01, 7.7961910e-01, 1.0808350e-03, 5.7481132e-02,\n",
       "         5.3087741e-02, 2.1075467e-03, 3.5201550e-01, 1.1254903e-01,\n",
       "         5.3684336e-01, 6.1724120e-01, 2.9504582e-01, 2.5830473e-04,\n",
       "         2.4927866e-01, 7.0331439e-02]], dtype=float32),\n",
       " array([[0.23170139, 0.80431265, 0.00605315, 0.08821904, 0.0787948 ,\n",
       "         0.00824695, 0.32385436, 0.10479182, 0.6358659 , 0.6014303 ,\n",
       "         0.24203168, 0.00193866, 0.26138806, 0.0941072 ]], dtype=float32),\n",
       " array([[0.2358817 , 0.80466247, 0.01531026, 0.10432716, 0.09420915,\n",
       "         0.01476464, 0.30465177, 0.10699528, 0.6906951 , 0.5885794 ,\n",
       "         0.20326777, 0.00592985, 0.2769833 , 0.12322729]], dtype=float32),\n",
       " array([[0.23049983, 0.81219906, 0.02224781, 0.11128506, 0.10515013,\n",
       "         0.01888717, 0.28454098, 0.10801127, 0.7289055 , 0.5857502 ,\n",
       "         0.18243022, 0.00929151, 0.27580422, 0.13811165]], dtype=float32),\n",
       " array([[0.2507149 , 0.8038115 , 0.03424293, 0.13922668, 0.1229813 ,\n",
       "         0.02801567, 0.26529935, 0.10752686, 0.7242215 , 0.57924324,\n",
       "         0.19054715, 0.01498795, 0.2919776 , 0.14738792]], dtype=float32),\n",
       " array([[0.21574569, 0.81382674, 0.04403322, 0.12719308, 0.11978737,\n",
       "         0.03108811, 0.28046167, 0.10286862, 0.75442356, 0.58041376,\n",
       "         0.16647072, 0.02129768, 0.28127828, 0.14988057]], dtype=float32),\n",
       " array([[0.23020779, 0.8081365 , 0.1013146 , 0.15184166, 0.14725323,\n",
       "         0.05407945, 0.2516844 , 0.10880866, 0.78034514, 0.566005  ,\n",
       "         0.14646883, 0.05999693, 0.30611318, 0.19345641]], dtype=float32),\n",
       " array([[0.2080972 , 0.81906664, 0.08812147, 0.14162958, 0.1353447 ,\n",
       "         0.05121002, 0.24912386, 0.10638295, 0.80367327, 0.5692193 ,\n",
       "         0.14514223, 0.04984668, 0.2889145 , 0.18862665]], dtype=float32),\n",
       " array([[0.18534546, 0.82726693, 0.09800582, 0.14665958, 0.13842571,\n",
       "         0.06132214, 0.22768928, 0.10084148, 0.8046219 , 0.5716641 ,\n",
       "         0.15020245, 0.05564116, 0.27881372, 0.17293654]], dtype=float32),\n",
       " array([[0.16708481, 0.83485746, 0.06753185, 0.12417701, 0.11857502,\n",
       "         0.04381938, 0.19605266, 0.0976539 , 0.82675797, 0.579279  ,\n",
       "         0.14020422, 0.03554728, 0.2515714 , 0.15803345]], dtype=float32),\n",
       " array([[0.16650662, 0.8297984 , 0.09817832, 0.1328695 , 0.12893094,\n",
       "         0.06020471, 0.17215368, 0.10234302, 0.81429696, 0.5707336 ,\n",
       "         0.14692976, 0.05674536, 0.26701468, 0.17025504]], dtype=float32),\n",
       " array([[0.16558307, 0.8261171 , 0.09720504, 0.138138  , 0.12917063,\n",
       "         0.06489196, 0.19689342, 0.0988782 , 0.7951409 , 0.5704039 ,\n",
       "         0.16318598, 0.05531439, 0.27633998, 0.161498  ]], dtype=float32),\n",
       " array([[0.12939413, 0.83661133, 0.10179653, 0.11687864, 0.1162248 ,\n",
       "         0.07218936, 0.20780526, 0.09833343, 0.7837954 , 0.56973743,\n",
       "         0.17301746, 0.06098114, 0.27129045, 0.15241623]], dtype=float32),\n",
       " array([[0.15029353, 0.8257767 , 0.08461411, 0.12190343, 0.11712109,\n",
       "         0.06023028, 0.18558885, 0.09731445, 0.77164954, 0.5695058 ,\n",
       "         0.17846583, 0.04882637, 0.27773568, 0.15081792]], dtype=float32),\n",
       " array([[0.16309358, 0.82069504, 0.07494342, 0.12590335, 0.12021585,\n",
       "         0.05508272, 0.19417726, 0.09751371, 0.75898147, 0.571559  ,\n",
       "         0.1855096 , 0.04172733, 0.281186  , 0.14779574]], dtype=float32),\n",
       " array([[0.18287914, 0.81215453, 0.0521226 , 0.11969262, 0.11435858,\n",
       "         0.04036649, 0.21586911, 0.10114883, 0.7454346 , 0.5750545 ,\n",
       "         0.19338275, 0.0267132 , 0.2827734 , 0.14617132]], dtype=float32),\n",
       " array([[0.19425699, 0.8042181 , 0.04501444, 0.12195541, 0.11695781,\n",
       "         0.03619174, 0.20039022, 0.10420712, 0.72086143, 0.5778775 ,\n",
       "         0.20310241, 0.02187537, 0.2825839 , 0.13697708]], dtype=float32),\n",
       " array([[0.21128011, 0.79852945, 0.02369832, 0.11490981, 0.10859914,\n",
       "         0.02251474, 0.1960589 , 0.1063988 , 0.70031464, 0.5881631 ,\n",
       "         0.21649662, 0.00960599, 0.2691444 , 0.11817524]], dtype=float32),\n",
       " array([[0.22575077, 0.7940351 , 0.0165098 , 0.11162998, 0.10214118,\n",
       "         0.0177684 , 0.22652924, 0.10372478, 0.6739521 , 0.5908965 ,\n",
       "         0.23551439, 0.00630797, 0.27338645, 0.11146732]], dtype=float32),\n",
       " array([[0.25126317, 0.77341354, 0.00760066, 0.09700127, 0.08750228,\n",
       "         0.00971324, 0.24292825, 0.10537571, 0.5940795 , 0.59772784,\n",
       "         0.27222592, 0.00253548, 0.27674186, 0.09226639]], dtype=float32),\n",
       " array([[0.2616103 , 0.77054477, 0.00750222, 0.10498943, 0.09147634,\n",
       "         0.00982275, 0.202725  , 0.10750405, 0.5918967 , 0.59914565,\n",
       "         0.27356133, 0.00238287, 0.270907  , 0.08849123]], dtype=float32),\n",
       " array([[0.2668185 , 0.7693304 , 0.00656282, 0.10178249, 0.08935165,\n",
       "         0.00876282, 0.21934424, 0.10687234, 0.58115727, 0.6009182 ,\n",
       "         0.27645412, 0.00206066, 0.27147976, 0.08670922]], dtype=float32),\n",
       " array([[0.25545484, 0.78026813, 0.01230748, 0.11005537, 0.09741922,\n",
       "         0.01348609, 0.18835719, 0.10866124, 0.6398682 , 0.59086204,\n",
       "         0.24462214, 0.00446033, 0.2748385 , 0.10695338]], dtype=float32),\n",
       " array([[0.27261758, 0.7659901 , 0.00479049, 0.09205654, 0.08429068,\n",
       "         0.00649545, 0.2079283 , 0.10981629, 0.5622894 , 0.6046794 ,\n",
       "         0.27524897, 0.00144663, 0.26520386, 0.08188704]], dtype=float32),\n",
       " array([[0.29239416, 0.7660105 , 0.01224242, 0.12477557, 0.10752667,\n",
       "         0.01317119, 0.1519519 , 0.11384929, 0.61602426, 0.5898709 ,\n",
       "         0.24948993, 0.00427114, 0.28116298, 0.1059244 ]], dtype=float32),\n",
       " array([[0.22985041, 0.79970396, 0.03579091, 0.12332613, 0.12012448,\n",
       "         0.02679178, 0.15521811, 0.11410514, 0.7253857 , 0.57809436,\n",
       "         0.1856875 , 0.0163591 , 0.2788959 , 0.14423506]], dtype=float32),\n",
       " array([[0.23772706, 0.8004232 , 0.05711624, 0.148824  , 0.1375682 ,\n",
       "         0.03971011, 0.14277163, 0.11352734, 0.7530602 , 0.57263905,\n",
       "         0.17757203, 0.0276889 , 0.2846388 , 0.15984686]], dtype=float32),\n",
       " array([[0.25249448, 0.8002175 , 0.05276052, 0.16383924, 0.14752933,\n",
       "         0.03968011, 0.17294164, 0.10865225, 0.7486079 , 0.5780911 ,\n",
       "         0.18489468, 0.02427827, 0.28498855, 0.15245387]], dtype=float32),\n",
       " array([[0.20759471, 0.8114163 , 0.08622744, 0.1409117 , 0.13886707,\n",
       "         0.05004235, 0.13970436, 0.11127588, 0.7911788 , 0.5685466 ,\n",
       "         0.15205954, 0.04810318, 0.28089038, 0.17709093]], dtype=float32),\n",
       " array([[0.18906516, 0.81733435, 0.10027233, 0.13841788, 0.13725278,\n",
       "         0.05790674, 0.13430053, 0.11020818, 0.80230606, 0.56704575,\n",
       "         0.14978175, 0.05811551, 0.27708396, 0.17922887]], dtype=float32),\n",
       " array([[0.17649509, 0.82077813, 0.08850547, 0.13303077, 0.12830457,\n",
       "         0.05632656, 0.13274276, 0.1063289 , 0.79933095, 0.568834  ,\n",
       "         0.15949592, 0.0496776 , 0.2711326 , 0.16777654]], dtype=float32),\n",
       " array([[0.1819839 , 0.8141148 , 0.08573166, 0.14249144, 0.13389574,\n",
       "         0.05861592, 0.12101389, 0.1067125 , 0.77648443, 0.5707944 ,\n",
       "         0.17465265, 0.04611685, 0.27224663, 0.15453811]], dtype=float32),\n",
       " array([[0.17790122, 0.8134397 , 0.0577346 , 0.12392582, 0.11891121,\n",
       "         0.04125643, 0.12705712, 0.10515068, 0.7708474 , 0.5775511 ,\n",
       "         0.17503294, 0.02882698, 0.26076195, 0.14093213]], dtype=float32),\n",
       " array([[0.19051848, 0.80316865, 0.03793492, 0.11574718, 0.1096952 ,\n",
       "         0.03036168, 0.14696985, 0.10594824, 0.73384905, 0.5814397 ,\n",
       "         0.1951045 , 0.01744606, 0.26479113, 0.12860121]], dtype=float32),\n",
       " array([[0.21454734, 0.79308796, 0.02275311, 0.11059585, 0.1046296 ,\n",
       "         0.02114222, 0.18278296, 0.10860836, 0.6874938 , 0.5865524 ,\n",
       "         0.21953891, 0.00938511, 0.2714451 , 0.11844587]], dtype=float32),\n",
       " array([[0.2073243 , 0.7946251 , 0.01258913, 0.09917375, 0.09275054,\n",
       "         0.01504678, 0.19890104, 0.10673694, 0.64218026, 0.59483314,\n",
       "         0.2511735 , 0.0045813 , 0.26203936, 0.09740315]], dtype=float32),\n",
       " array([[0.20004793, 0.8023319 , 0.01171856, 0.09292191, 0.08742352,\n",
       "         0.01374775, 0.2077521 , 0.10662694, 0.6705416 , 0.5957981 ,\n",
       "         0.23551439, 0.00424279, 0.2540319 , 0.10075405]], dtype=float32),\n",
       " array([[0.23178524, 0.7894602 , 0.01243657, 0.10503381, 0.09416159,\n",
       "         0.01416685, 0.18676771, 0.10959497, 0.65792215, 0.5921505 ,\n",
       "         0.24126552, 0.0044662 , 0.26536843, 0.10570358]], dtype=float32),\n",
       " array([[0.22023332, 0.79883426, 0.02017036, 0.11134695, 0.10336088,\n",
       "         0.01976859, 0.17434536, 0.11109315, 0.69672817, 0.5863185 ,\n",
       "         0.21738943, 0.00802664, 0.2674343 , 0.12122199]], dtype=float32),\n",
       " array([[0.24741332, 0.78222364, 0.00992536, 0.10431772, 0.09667684,\n",
       "         0.01185375, 0.20203122, 0.11111066, 0.62036693, 0.59657586,\n",
       "         0.25326896, 0.00340548, 0.26845008, 0.09856561]], dtype=float32),\n",
       " array([[0.25902143, 0.77737087, 0.01548665, 0.11715988, 0.10805501,\n",
       "         0.01570145, 0.19106004, 0.10919566, 0.6250039 , 0.58972394,\n",
       "         0.24128541, 0.00596658, 0.2831424 , 0.10896561]], dtype=float32),\n",
       " array([[0.30341184, 0.76140106, 0.01171572, 0.1252053 , 0.11179668,\n",
       "         0.01244187, 0.19903055, 0.11129946, 0.5938    , 0.5930502 ,\n",
       "         0.25336763, 0.00415096, 0.28944027, 0.10476968]], dtype=float32),\n",
       " array([[0.31348193, 0.7555083 , 0.00657625, 0.11196834, 0.0972768 ,\n",
       "         0.00801428, 0.20059693, 0.11165655, 0.5696565 , 0.5995272 ,\n",
       "         0.268205  , 0.00207358, 0.27936015, 0.0925474 ]], dtype=float32),\n",
       " array([[0.31237146, 0.75513357, 0.00572956, 0.10944403, 0.09223971,\n",
       "         0.00716635, 0.18047632, 0.10992281, 0.5730047 , 0.6004539 ,\n",
       "         0.26660147, 0.00175392, 0.27340165, 0.08837016]], dtype=float32),\n",
       " array([[0.2576754 , 0.78676283, 0.01018235, 0.10791726, 0.09535868,\n",
       "         0.0108683 , 0.16543658, 0.10890293, 0.6714451 , 0.59663355,\n",
       "         0.21920362, 0.0034895 , 0.25591654, 0.1032892 ]], dtype=float32),\n",
       " array([[0.2555249 , 0.7916421 , 0.02330081, 0.12930445, 0.11564485,\n",
       "         0.02026587, 0.16629034, 0.11026218, 0.7027437 , 0.5849105 ,\n",
       "         0.2010612 , 0.00939232, 0.27449074, 0.12763967]], dtype=float32),\n",
       " array([[0.24661064, 0.7889911 , 0.01228718, 0.10828487, 0.09693415,\n",
       "         0.01322682, 0.20601347, 0.10888483, 0.65801996, 0.5930737 ,\n",
       "         0.22908942, 0.00442001, 0.26774138, 0.10744562]], dtype=float32),\n",
       " array([[0.2718591 , 0.77166414, 0.00802821, 0.11036661, 0.09832603,\n",
       "         0.0101987 , 0.22859943, 0.10756747, 0.5631277 , 0.60002667,\n",
       "         0.27149135, 0.00263959, 0.27672896, 0.08748367]], dtype=float32),\n",
       " array([[0.27506837, 0.7739528 , 0.01052867, 0.1146688 , 0.09906002,\n",
       "         0.01170744, 0.23295684, 0.10703044, 0.6102542 , 0.5948288 ,\n",
       "         0.24646391, 0.00367457, 0.27951434, 0.09999125]], dtype=float32),\n",
       " array([[0.26303038, 0.7840442 , 0.01154903, 0.10926263, 0.09810802,\n",
       "         0.01218939, 0.25373355, 0.10866665, 0.6387733 , 0.59302914,\n",
       "         0.23017757, 0.00418043, 0.2785879 , 0.10872366]], dtype=float32),\n",
       " array([[0.25476956, 0.7977522 , 0.01244205, 0.11301883, 0.10120925,\n",
       "         0.01299877, 0.26972082, 0.10505533, 0.6878868 , 0.5958674 ,\n",
       "         0.21106058, 0.00446665, 0.26713392, 0.11325484]], dtype=float32),\n",
       " array([[0.22053953, 0.8117273 , 0.02487363, 0.12147482, 0.10951497,\n",
       "         0.02253618, 0.23022564, 0.10400643, 0.7339103 , 0.58747333,\n",
       "         0.19177517, 0.01022581, 0.2657442 , 0.12829432]], dtype=float32),\n",
       " array([[0.19397688, 0.8218806 , 0.06603789, 0.12070163, 0.11974852,\n",
       "         0.04016076, 0.20910753, 0.10806422, 0.79254675, 0.5709349 ,\n",
       "         0.14887342, 0.03629917, 0.27833012, 0.17563948]], dtype=float32),\n",
       " array([[0.21419339, 0.8067153 , 0.0151662 , 0.09414934, 0.09567704,\n",
       "         0.01448517, 0.28210208, 0.10814409, 0.6871918 , 0.59236145,\n",
       "         0.20470357, 0.00603842, 0.26872092, 0.11880662]], dtype=float32),\n",
       " array([[0.25179455, 0.7842789 , 0.01392633, 0.11419013, 0.10143633,\n",
       "         0.0149311 , 0.28773192, 0.10476722, 0.6267186 , 0.5926536 ,\n",
       "         0.24098456, 0.00518839, 0.2845554 , 0.10572726]], dtype=float32),\n",
       " array([[0.25883177, 0.78456527, 0.00758069, 0.10310518, 0.09071   ,\n",
       "         0.0095427 , 0.3233031 , 0.10437368, 0.6188979 , 0.6028693 ,\n",
       "         0.24992374, 0.00244033, 0.26947322, 0.09333243]], dtype=float32),\n",
       " array([[0.27854198, 0.78135437, 0.00365345, 0.09149104, 0.07838073,\n",
       "         0.00537416, 0.36497757, 0.10099734, 0.5999776 , 0.61124593,\n",
       "         0.26006982, 0.00103368, 0.26149344, 0.08260547]], dtype=float32),\n",
       " array([[0.2627119 , 0.7920901 , 0.00508236, 0.09345194, 0.08037222,\n",
       "         0.00686923, 0.32183024, 0.10317413, 0.6442075 , 0.6047261 ,\n",
       "         0.2408827 , 0.00153083, 0.26000783, 0.09352101]], dtype=float32),\n",
       " array([[0.25424808, 0.79655004, 0.00509163, 0.09208093, 0.07879739,\n",
       "         0.00715129, 0.3199005 , 0.1041284 , 0.6419871 , 0.60307723,\n",
       "         0.24434084, 0.00153731, 0.26010936, 0.09373174]], dtype=float32),\n",
       " array([[0.20517017, 0.8194671 , 0.0095175 , 0.09534905, 0.08552145,\n",
       "         0.01222333, 0.28148052, 0.10213777, 0.6890008 , 0.5981541 ,\n",
       "         0.22301313, 0.00325213, 0.25162232, 0.10098732]], dtype=float32),\n",
       " array([[0.23255482, 0.8046465 , 0.00961566, 0.09703101, 0.09020184,\n",
       "         0.01138298, 0.2918214 , 0.10819943, 0.6593096 , 0.59514374,\n",
       "         0.22713584, 0.00335776, 0.26743284, 0.10727165]], dtype=float32),\n",
       " array([[0.25034916, 0.7978386 , 0.01091676, 0.10507137, 0.09408672,\n",
       "         0.01273043, 0.29328093, 0.11109489, 0.64819974, 0.5901143 ,\n",
       "         0.23466843, 0.00389496, 0.28010017, 0.11410509]], dtype=float32),\n",
       " array([[0.22246347, 0.8151271 , 0.02465975, 0.11429938, 0.10924286,\n",
       "         0.02061704, 0.2923658 , 0.10502899, 0.73225385, 0.5872048 ,\n",
       "         0.17880517, 0.01053794, 0.2717411 , 0.13460653]], dtype=float32),\n",
       " array([[0.25271362, 0.80133146, 0.01213342, 0.1015354 , 0.09795112,\n",
       "         0.01168952, 0.2933126 , 0.11099382, 0.6931901 , 0.5927885 ,\n",
       "         0.19702166, 0.00451617, 0.27051285, 0.12363656]], dtype=float32),\n",
       " array([[0.2734366 , 0.7953797 , 0.01532614, 0.11537999, 0.10513396,\n",
       "         0.01356099, 0.2953794 , 0.10601732, 0.70354927, 0.589295  ,\n",
       "         0.19133565, 0.00599892, 0.2799512 , 0.13092686]], dtype=float32),\n",
       " array([[0.23426434, 0.80198896, 0.01595393, 0.10511344, 0.0951516 ,\n",
       "         0.0142345 , 0.21979515, 0.11227319, 0.72850555, 0.58968675,\n",
       "         0.18398318, 0.00598595, 0.25789297, 0.12477352]], dtype=float32),\n",
       " array([[0.22940914, 0.8070278 , 0.04656244, 0.13847283, 0.12767012,\n",
       "         0.03258256, 0.21617137, 0.10417914, 0.7440904 , 0.57802904,\n",
       "         0.16965778, 0.02242125, 0.28227782, 0.14689343]], dtype=float32),\n",
       " array([[0.176891  , 0.82938576, 0.09409839, 0.13128935, 0.13119127,\n",
       "         0.05396587, 0.18951036, 0.10604517, 0.80899733, 0.5702823 ,\n",
       "         0.13767835, 0.05424893, 0.27071115, 0.1742474 ]], dtype=float32),\n",
       " array([[0.17275827, 0.8320513 , 0.06866749, 0.12770595, 0.12271276,\n",
       "         0.04896479, 0.2162975 , 0.10579279, 0.7973518 , 0.57377017,\n",
       "         0.1592404 , 0.03562503, 0.26764286, 0.16243368]], dtype=float32),\n",
       " array([[0.17453161, 0.8179208 , 0.04516829, 0.10547892, 0.10626868,\n",
       "         0.03136818, 0.22740617, 0.10202678, 0.7567318 , 0.57886416,\n",
       "         0.16632123, 0.02311712, 0.2689663 , 0.14156593]], dtype=float32),\n",
       " array([[0.20278585, 0.8085436 , 0.03356114, 0.1200742 , 0.11249017,\n",
       "         0.02792527, 0.24638352, 0.10061821, 0.72117513, 0.58376795,\n",
       "         0.19279732, 0.01521667, 0.27457178, 0.12804645]], dtype=float32),\n",
       " array([[0.20340575, 0.8109343 , 0.05070926, 0.13186602, 0.12555607,\n",
       "         0.03814351, 0.20340441, 0.10475188, 0.7391902 , 0.5766315 ,\n",
       "         0.18364023, 0.02507035, 0.2807221 , 0.14414608]], dtype=float32),\n",
       " array([[0.14619748, 0.84197795, 0.12383654, 0.13099812, 0.1307584 ,\n",
       "         0.0748408 , 0.17316411, 0.10089521, 0.8293607 , 0.5669511 ,\n",
       "         0.13957117, 0.07694556, 0.26425093, 0.17733866]], dtype=float32),\n",
       " array([[0.13095315, 0.84983206, 0.13404717, 0.12248897, 0.12309654,\n",
       "         0.08091859, 0.152394  , 0.1027232 , 0.8525046 , 0.5634403 ,\n",
       "         0.13345316, 0.08507662, 0.2567867 , 0.18912268]], dtype=float32),\n",
       " array([[0.15577734, 0.8343922 , 0.14191224, 0.13563274, 0.13662513,\n",
       "         0.07971838, 0.143449  , 0.10539904, 0.8357341 , 0.5630184 ,\n",
       "         0.13713996, 0.09071118, 0.26932943, 0.19165973]], dtype=float32),\n",
       " array([[0.12217776, 0.84482133, 0.3180268 , 0.1473805 , 0.15893656,\n",
       "         0.16209485, 0.13703506, 0.10129762, 0.8498534 , 0.5545333 ,\n",
       "         0.12537387, 0.2606263 , 0.27639312, 0.20936365]], dtype=float32),\n",
       " array([[0.16131337, 0.81825733, 0.2611351 , 0.16983478, 0.16715586,\n",
       "         0.1436907 , 0.15282635, 0.10452596, 0.8045494 , 0.5546305 ,\n",
       "         0.15610126, 0.19478643, 0.30027026, 0.19938533]], dtype=float32),\n",
       " array([[0.16650945, 0.8118297 , 0.14328179, 0.15177608, 0.1468213 ,\n",
       "         0.08836098, 0.13217078, 0.10319808, 0.7825368 , 0.5655282 ,\n",
       "         0.17152865, 0.0892937 , 0.28161073, 0.16445793]], dtype=float32),\n",
       " array([[0.15839379, 0.8126449 , 0.11812387, 0.13519986, 0.13532627,\n",
       "         0.07168834, 0.1172242 , 0.10523971, 0.7902464 , 0.5699008 ,\n",
       "         0.16511507, 0.07030959, 0.26715988, 0.15725125]], dtype=float32),\n",
       " array([[0.16986267, 0.8107232 , 0.05596052, 0.12047873, 0.11763953,\n",
       "         0.04077155, 0.12752812, 0.09905347, 0.7743277 , 0.5805058 ,\n",
       "         0.17976147, 0.0283075 , 0.25529692, 0.13467613]], dtype=float32),\n",
       " array([[0.17563026, 0.80625755, 0.0142773 , 0.09101574, 0.08836764,\n",
       "         0.01614946, 0.13647139, 0.1034357 , 0.71220046, 0.5955428 ,\n",
       "         0.22691612, 0.00535116, 0.23708297, 0.1001436 ]], dtype=float32),\n",
       " array([[0.19467327, 0.79477274, 0.01490845, 0.09977843, 0.09027545,\n",
       "         0.01771507, 0.14387996, 0.10374005, 0.67130643, 0.5889757 ,\n",
       "         0.2532349 , 0.00567456, 0.2580117 , 0.10181986]], dtype=float32),\n",
       " array([[0.19438252, 0.7935901 , 0.01894861, 0.1068291 , 0.09857215,\n",
       "         0.02127936, 0.12921074, 0.10951911, 0.66359866, 0.5875525 ,\n",
       "         0.25026608, 0.00727216, 0.25993738, 0.1026855 ]], dtype=float32),\n",
       " array([[0.22361058, 0.7819146 , 0.00971817, 0.09813645, 0.09013536,\n",
       "         0.01267719, 0.15462393, 0.11397384, 0.6221384 , 0.5942164 ,\n",
       "         0.2715823 , 0.00324081, 0.2609254 , 0.09439822]], dtype=float32),\n",
       " array([[0.2513255 , 0.7705751 , 0.01052938, 0.11207306, 0.0968582 ,\n",
       "         0.01381437, 0.12279328, 0.11575442, 0.60162556, 0.58943564,\n",
       "         0.284797  , 0.00351539, 0.27152595, 0.09639288]], dtype=float32),\n",
       " array([[0.27238885, 0.764569  , 0.00696999, 0.10475067, 0.09341203,\n",
       "         0.00938309, 0.15132248, 0.11552611, 0.580538  , 0.5969652 ,\n",
       "         0.28297302, 0.0021712 , 0.2691453 , 0.09011661]], dtype=float32),\n",
       " array([[0.27708903, 0.76529455, 0.02002971, 0.12593263, 0.11817716,\n",
       "         0.01790279, 0.14203997, 0.11914355, 0.6370003 , 0.58439654,\n",
       "         0.23232734, 0.00784397, 0.28716218, 0.11977534]], dtype=float32),\n",
       " array([[0.3220238 , 0.75462884, 0.03103963, 0.16021919, 0.14089155,\n",
       "         0.02571171, 0.13180138, 0.11976306, 0.6387776 , 0.5742473 ,\n",
       "         0.23669471, 0.01305208, 0.3133698 , 0.14006345]], dtype=float32),\n",
       " array([[0.23957786, 0.7868657 , 0.04691407, 0.12982814, 0.12791006,\n",
       "         0.03188957, 0.12355393, 0.11780985, 0.71966445, 0.57154995,\n",
       "         0.18926428, 0.02304701, 0.2903486 , 0.15497765]], dtype=float32),\n",
       " array([[0.264345  , 0.78328586, 0.0694664 , 0.1654523 , 0.15183868,\n",
       "         0.04367693, 0.13048856, 0.11156717, 0.74278355, 0.5704824 ,\n",
       "         0.17926227, 0.03547088, 0.29680315, 0.16443627]], dtype=float32),\n",
       " array([[0.27660957, 0.7795439 , 0.0303891 , 0.14067496, 0.12890795,\n",
       "         0.02308764, 0.15608834, 0.11063249, 0.722242  , 0.58263165,\n",
       "         0.19341458, 0.01294976, 0.2821619 , 0.14119124]], dtype=float32),\n",
       " array([[0.2721309 , 0.7759503 , 0.03013834, 0.13701226, 0.12410529,\n",
       "         0.02358614, 0.18250786, 0.11017422, 0.6982572 , 0.58104897,\n",
       "         0.20562221, 0.01298549, 0.29130018, 0.13812914]], dtype=float32),\n",
       " array([[0.24119695, 0.78459346, 0.00666883, 0.09409323, 0.08773439,\n",
       "         0.00858407, 0.2278    , 0.10403878, 0.6245416 , 0.6054154 ,\n",
       "         0.25320962, 0.00213643, 0.2550778 , 0.08735484]], dtype=float32),\n",
       " array([[0.2465193 , 0.77439785, 0.00610436, 0.08967071, 0.07949868,\n",
       "         0.00800135, 0.21318193, 0.10707182, 0.59515464, 0.6002636 ,\n",
       "         0.26864266, 0.0019634 , 0.2632624 , 0.08704774]], dtype=float32),\n",
       " array([[0.24114735, 0.7789699 , 0.00305958, 0.07630699, 0.06689801,\n",
       "         0.00482116, 0.2014928 , 0.10562211, 0.5853413 , 0.6103344 ,\n",
       "         0.277775  , 0.00085781, 0.24126798, 0.07309639]], dtype=float32),\n",
       " array([[0.21778437, 0.7941106 , 0.00362618, 0.07241885, 0.06819541,\n",
       "         0.0057268 , 0.23317452, 0.1093447 , 0.59242696, 0.6099673 ,\n",
       "         0.2740039 , 0.00106785, 0.23850554, 0.07696632]], dtype=float32),\n",
       " array([[2.67055362e-01, 7.78750896e-01, 1.14992866e-03, 6.36862144e-02,\n",
       "         5.75090274e-02, 2.43296637e-03, 3.06529790e-01, 1.11989446e-01,\n",
       "         5.27772546e-01, 6.20753646e-01, 3.13392490e-01, 2.67745112e-04,\n",
       "         2.39190400e-01, 6.53457791e-02]], dtype=float32),\n",
       " array([[2.4385208e-01, 7.8430343e-01, 2.1945375e-03, 6.5979339e-02,\n",
       "         5.9910934e-02, 3.9005005e-03, 3.0202025e-01, 1.1307539e-01,\n",
       "         5.4605937e-01, 6.0700387e-01, 2.9602247e-01, 6.0471229e-04,\n",
       "         2.5721592e-01, 7.7227674e-02]], dtype=float32),\n",
       " array([[3.21354747e-01, 7.83239722e-01, 3.83194245e-04, 5.53923808e-02,\n",
       "         5.50673455e-02, 1.04647246e-03, 4.75180805e-01, 1.18929856e-01,\n",
       "         4.85197634e-01, 6.32385910e-01, 3.26952070e-01, 7.25611899e-05,\n",
       "         2.44708031e-01, 6.22357018e-02]], dtype=float32),\n",
       " array([[3.07851106e-01, 7.88488388e-01, 5.64737711e-04, 5.64488024e-02,\n",
       "         5.33739179e-02, 1.32870988e-03, 4.66742456e-01, 1.17194131e-01,\n",
       "         5.25845468e-01, 6.23351932e-01, 2.98721254e-01, 1.19214754e-04,\n",
       "         2.50242382e-01, 7.08098039e-02]], dtype=float32),\n",
       " array([[3.9251673e-01, 7.9520613e-01, 5.9798505e-05, 4.4914927e-02,\n",
       "         4.3968461e-02, 2.7451225e-04, 6.3021946e-01, 1.2288047e-01,\n",
       "         4.6245447e-01, 6.5471095e-01, 3.5346308e-01, 7.6063316e-06,\n",
       "         2.2122708e-01, 5.0336696e-02]], dtype=float32),\n",
       " array([[3.1830457e-01, 8.1511688e-01, 7.3928118e-04, 6.8634510e-02,\n",
       "         6.6042453e-02, 1.5469217e-03, 5.2112287e-01, 1.0885676e-01,\n",
       "         6.0490298e-01, 6.2984198e-01, 2.3997600e-01, 1.5930804e-04,\n",
       "         2.3593791e-01, 7.5587526e-02]], dtype=float32),\n",
       " array([[3.6834511e-01, 7.9812688e-01, 3.4481045e-04, 5.7104226e-02,\n",
       "         5.1718146e-02, 8.4292341e-04, 5.6838000e-01, 1.2237168e-01,\n",
       "         5.7065415e-01, 6.2595290e-01, 2.6729870e-01, 6.3969164e-05,\n",
       "         2.4817750e-01, 8.1083000e-02]], dtype=float32),\n",
       " array([[0.27049726, 0.8269221 , 0.0029207 , 0.07748637, 0.07594163,\n",
       "         0.00393812, 0.47621948, 0.10841584, 0.68007666, 0.61097294,\n",
       "         0.19069135, 0.00084117, 0.24919344, 0.10283418]], dtype=float32),\n",
       " array([[0.31806582, 0.79112107, 0.03061138, 0.14336728, 0.12181602,\n",
       "         0.02129747, 0.30870843, 0.11639296, 0.6934789 , 0.5689575 ,\n",
       "         0.1736318 , 0.01369322, 0.32128924, 0.16860354]], dtype=float32),\n",
       " array([[0.26371384, 0.80921036, 0.08010043, 0.16460995, 0.14697415,\n",
       "         0.0425956 , 0.25660318, 0.10486802, 0.7627531 , 0.5673207 ,\n",
       "         0.13767608, 0.04436073, 0.30629292, 0.17958274]], dtype=float32),\n",
       " array([[0.32246947, 0.7753312 , 0.20577869, 0.21276619, 0.19938262,\n",
       "         0.0801874 , 0.24717969, 0.11558139, 0.732717  , 0.5474336 ,\n",
       "         0.13374834, 0.14858599, 0.36692196, 0.23413308]], dtype=float32),\n",
       " array([[0.2421138 , 0.81169736, 0.07581683, 0.15358004, 0.13773383,\n",
       "         0.03905427, 0.23884913, 0.09931337, 0.7971131 , 0.57253206,\n",
       "         0.12771413, 0.04138315, 0.28603345, 0.17361566]], dtype=float32),\n",
       " array([[0.2523272 , 0.8068092 , 0.03026433, 0.12441629, 0.12977706,\n",
       "         0.02024266, 0.35965687, 0.10436531, 0.71372706, 0.5883288 ,\n",
       "         0.15798078, 0.01384365, 0.28729174, 0.13910942]], dtype=float32),\n",
       " array([[0.23305741, 0.8168025 , 0.00470274, 0.07979266, 0.06748616,\n",
       "         0.00503161, 0.3304194 , 0.09316654, 0.7644427 , 0.60958403,\n",
       "         0.16266651, 0.00144423, 0.22358227, 0.09921712]], dtype=float32),\n",
       " array([[0.18053941, 0.82581687, 0.01285565, 0.08974321, 0.07723517,\n",
       "         0.01437057, 0.33178878, 0.09641104, 0.71331793, 0.5912878 ,\n",
       "         0.20049301, 0.00486369, 0.25376374, 0.10600439]], dtype=float32),\n",
       " array([[0.11400713, 0.861383  , 0.02610265, 0.07866291, 0.07445715,\n",
       "         0.02128375, 0.28636566, 0.08192243, 0.82901794, 0.5956014 ,\n",
       "         0.13251719, 0.01189161, 0.21193646, 0.11067669]], dtype=float32),\n",
       " array([[0.07739898, 0.8709415 , 0.23473793, 0.11364337, 0.11057989,\n",
       "         0.15205292, 0.2482819 , 0.08342035, 0.8234705 , 0.55781215,\n",
       "         0.14309624, 0.18338238, 0.26455233, 0.15703873]], dtype=float32),\n",
       " array([[0.12587573, 0.8472992 , 0.04855588, 0.09277098, 0.09240083,\n",
       "         0.03925649, 0.2613206 , 0.09731723, 0.78791595, 0.57728374,\n",
       "         0.16538647, 0.02479578, 0.2521766 , 0.13789792]], dtype=float32),\n",
       " array([[0.10665856, 0.8432716 , 0.34207085, 0.13942578, 0.15284248,\n",
       "         0.19042043, 0.23100922, 0.09511368, 0.76769334, 0.54974   ,\n",
       "         0.15322421, 0.30186757, 0.30856788, 0.17931376]], dtype=float32),\n",
       " array([[0.15203512, 0.82804537, 0.58972627, 0.20887889, 0.2173934 ,\n",
       "         0.28982615, 0.16624886, 0.10015539, 0.83232313, 0.5382854 ,\n",
       "         0.11549626, 0.5758608 , 0.32701966, 0.2500904 ]], dtype=float32),\n",
       " array([[0.17182535, 0.81340116, 0.5406418 , 0.21574098, 0.21601965,\n",
       "         0.26181814, 0.12759449, 0.1044948 , 0.8228863 , 0.5369297 ,\n",
       "         0.12581815, 0.5096531 , 0.33008233, 0.24845512]], dtype=float32),\n",
       " array([[0.16317225, 0.82065266, 0.21980357, 0.15570116, 0.14883813,\n",
       "         0.10076865, 0.11586123, 0.09780622, 0.85605615, 0.5596735 ,\n",
       "         0.11941386, 0.15681227, 0.26887432, 0.19906469]], dtype=float32),\n",
       " array([[0.15905367, 0.82133514, 0.09738231, 0.13160248, 0.12391451,\n",
       "         0.05667537, 0.126942  , 0.09470601, 0.8354716 , 0.5746757 ,\n",
       "         0.1405163 , 0.05497815, 0.2475573 , 0.15654694]], dtype=float32),\n",
       " array([[0.20709783, 0.7967756 , 0.0350141 , 0.12257819, 0.11468869,\n",
       "         0.02635381, 0.15206067, 0.09993363, 0.7642103 , 0.5863733 ,\n",
       "         0.17869303, 0.01545302, 0.2538141 , 0.12750524]], dtype=float32),\n",
       " array([[0.13335438, 0.8207581 , 0.02148892, 0.08823853, 0.08288576,\n",
       "         0.02583149, 0.14764847, 0.09484264, 0.6986589 , 0.58671176,\n",
       "         0.24315703, 0.00919977, 0.24199785, 0.09543275]], dtype=float32),\n",
       " array([[0.11156002, 0.8358907 , 0.09462344, 0.11541056, 0.11300298,\n",
       "         0.07875874, 0.12984736, 0.09477396, 0.7589674 , 0.57125294,\n",
       "         0.20047787, 0.05504687, 0.2548168 , 0.12530482]], dtype=float32),\n",
       " array([[0.15544339, 0.81334466, 0.04218621, 0.12243742, 0.10842533,\n",
       "         0.04169744, 0.09531678, 0.10670164, 0.74497736, 0.58130425,\n",
       "         0.2158738 , 0.01788221, 0.24042171, 0.11254337]], dtype=float32),\n",
       " array([[0.22795568, 0.7817151 , 0.008473  , 0.10001484, 0.09147584,\n",
       "         0.01166026, 0.13677758, 0.11423115, 0.63350844, 0.5966593 ,\n",
       "         0.27054477, 0.00268219, 0.24953936, 0.09125015]], dtype=float32),\n",
       " array([[0.26312023, 0.7579039 , 0.01290659, 0.11986607, 0.10421756,\n",
       "         0.01600517, 0.09143109, 0.1192124 , 0.57781345, 0.58243656,\n",
       "         0.29342246, 0.0045795 , 0.28019464, 0.09923451]], dtype=float32),\n",
       " array([[0.24984673, 0.76626223, 0.0553023 , 0.1599612 , 0.141859  ,\n",
       "         0.04627723, 0.11182   , 0.11524161, 0.62755454, 0.5659731 ,\n",
       "         0.25192025, 0.02686641, 0.31234238, 0.13365836]], dtype=float32),\n",
       " array([[0.22155352, 0.78273094, 0.06819173, 0.1428395 , 0.14276448,\n",
       "         0.04787767, 0.0860609 , 0.11953669, 0.68211347, 0.56493396,\n",
       "         0.21094403, 0.03598557, 0.29645172, 0.14683852]], dtype=float32),\n",
       " array([[0.2650268 , 0.77431494, 0.11141916, 0.18319   , 0.16954613,\n",
       "         0.0637969 , 0.09525057, 0.11663381, 0.738506  , 0.56040025,\n",
       "         0.1811732 , 0.06350216, 0.30784136, 0.1783563 ]], dtype=float32),\n",
       " array([[0.22233494, 0.7923298 , 0.07387123, 0.1484734 , 0.13448597,\n",
       "         0.04596798, 0.08353757, 0.1106758 , 0.7900848 , 0.568269  ,\n",
       "         0.16726436, 0.03819857, 0.26961657, 0.1651158 ]], dtype=float32),\n",
       " array([[0.247456  , 0.78370184, 0.04298859, 0.14283134, 0.13320316,\n",
       "         0.02999975, 0.12083662, 0.10860121, 0.7590687 , 0.5805801 ,\n",
       "         0.18007033, 0.01958157, 0.2679163 , 0.14513211]], dtype=float32),\n",
       " array([[0.27288535, 0.7667456 , 0.10942084, 0.18674393, 0.17354624,\n",
       "         0.06481232, 0.10878316, 0.11763052, 0.72316515, 0.56116843,\n",
       "         0.19383644, 0.06190694, 0.3154909 , 0.17787746]], dtype=float32),\n",
       " array([[0.22490436, 0.78333545, 0.0175916 , 0.1086606 , 0.1056337 ,\n",
       "         0.01798837, 0.1607594 , 0.1116351 , 0.6581849 , 0.5882837 ,\n",
       "         0.23938164, 0.00686852, 0.2698439 , 0.11100429]], dtype=float32),\n",
       " array([[2.2442764e-01, 7.7250767e-01, 1.5407650e-03, 5.7787772e-02,\n",
       "         5.5661432e-02, 2.8154680e-03, 1.6722786e-01, 1.1275654e-01,\n",
       "         5.6679982e-01, 6.1625969e-01, 2.9373536e-01, 3.8635908e-04,\n",
       "         2.2434318e-01, 6.4007960e-02]], dtype=float32),\n",
       " array([[0.26903868, 0.7710569 , 0.00309442, 0.08734488, 0.07056148,\n",
       "         0.00521495, 0.14748098, 0.10500568, 0.5974576 , 0.6016373 ,\n",
       "         0.29237565, 0.00086813, 0.24997938, 0.07969097]], dtype=float32),\n",
       " array([[0.23252049, 0.79048824, 0.00774251, 0.10019328, 0.08844163,\n",
       "         0.010119  , 0.12764394, 0.11065497, 0.66177154, 0.5987316 ,\n",
       "         0.24367952, 0.00243852, 0.24089327, 0.0909098 ]], dtype=float32),\n",
       " array([[0.18640476, 0.8073067 , 0.02547959, 0.10755917, 0.10208154,\n",
       "         0.0248224 , 0.13250475, 0.11511362, 0.71006966, 0.58333725,\n",
       "         0.21369927, 0.01027951, 0.25438076, 0.11778434]], dtype=float32),\n",
       " array([[0.21117803, 0.80054104, 0.01471854, 0.10515776, 0.09877504,\n",
       "         0.01829893, 0.19366947, 0.11052053, 0.6429481 , 0.58683026,\n",
       "         0.259215  , 0.0055181 , 0.2724622 , 0.10824583]], dtype=float32),\n",
       " array([[0.24766469, 0.7788524 , 0.03052246, 0.12848242, 0.12329145,\n",
       "         0.02678304, 0.1630394 , 0.11740668, 0.6366914 , 0.5755848 ,\n",
       "         0.23521252, 0.01356381, 0.3000524 , 0.13007398]], dtype=float32),\n",
       " array([[0.35811403, 0.7429694 , 0.01742434, 0.15285955, 0.13625738,\n",
       "         0.01665617, 0.20975643, 0.12106559, 0.5768447 , 0.581661  ,\n",
       "         0.25883335, 0.00653857, 0.32249907, 0.12606192]], dtype=float32),\n",
       " array([[0.37041208, 0.743646  , 0.00345313, 0.0997619 , 0.0913369 ,\n",
       "         0.00476058, 0.29137996, 0.12295549, 0.5331452 , 0.5984237 ,\n",
       "         0.28806365, 0.00100333, 0.29837394, 0.10186007]], dtype=float32),\n",
       " array([[0.30433825, 0.7780412 , 0.01024374, 0.11733112, 0.11093665,\n",
       "         0.01008386, 0.28336856, 0.10513644, 0.64452356, 0.59706545,\n",
       "         0.21604417, 0.00372558, 0.28187466, 0.11174133]], dtype=float32),\n",
       " array([[0.28599972, 0.79359484, 0.03411119, 0.16143331, 0.14148858,\n",
       "         0.0245332 , 0.24849242, 0.09654056, 0.743373  , 0.5885097 ,\n",
       "         0.16882122, 0.0148085 , 0.27905807, 0.13673808]], dtype=float32),\n",
       " array([[0.22525169, 0.80429417, 0.06142097, 0.13490999, 0.12749113,\n",
       "         0.03480388, 0.1824724 , 0.10232172, 0.7848495 , 0.57448477,\n",
       "         0.14562899, 0.03253759, 0.2768794 , 0.16322376]], dtype=float32),\n",
       " array([[0.22924103, 0.7931661 , 0.064272  , 0.1443173 , 0.13246073,\n",
       "         0.04235293, 0.14650981, 0.11629158, 0.7456213 , 0.5689109 ,\n",
       "         0.17741165, 0.03196631, 0.28756407, 0.16056453]], dtype=float32),\n",
       " array([[0.16300218, 0.8196248 , 0.21477632, 0.16455683, 0.16962905,\n",
       "         0.11401599, 0.11637243, 0.11913645, 0.80500966, 0.56317157,\n",
       "         0.1416581 , 0.14057586, 0.27446705, 0.1811945 ]], dtype=float32),\n",
       " array([[0.17864144, 0.81585294, 0.14684491, 0.16927415, 0.15224303,\n",
       "         0.08896936, 0.11934093, 0.11294795, 0.82465935, 0.56785095,\n",
       "         0.15022351, 0.08192246, 0.26320562, 0.17424981]], dtype=float32),\n",
       " array([[0.1552111 , 0.82456297, 0.12525867, 0.13399714, 0.13161711,\n",
       "         0.07349069, 0.11730316, 0.10854949, 0.82962483, 0.56708294,\n",
       "         0.14642389, 0.07427798, 0.25919163, 0.1761736 ]], dtype=float32),\n",
       " array([[0.19926961, 0.80247116, 0.14695282, 0.167823  , 0.1550842 ,\n",
       "         0.07766283, 0.10813896, 0.10306877, 0.81585807, 0.5660434 ,\n",
       "         0.14649673, 0.09003985, 0.27578616, 0.17769238]], dtype=float32),\n",
       " array([[0.13556385, 0.8303351 , 0.26470792, 0.15786298, 0.15240127,\n",
       "         0.12847887, 0.11249761, 0.08893047, 0.8562219 , 0.56406456,\n",
       "         0.12308186, 0.20096028, 0.26010385, 0.17978798]], dtype=float32),\n",
       " array([[0.16075358, 0.8156408 , 0.20640789, 0.15159507, 0.15187095,\n",
       "         0.10609033, 0.16132547, 0.09001465, 0.8017936 , 0.56025434,\n",
       "         0.15175545, 0.15604761, 0.2954926 , 0.18254021]], dtype=float32),\n",
       " array([[0.10260977, 0.8411148 , 0.10661627, 0.1014707 , 0.10872777,\n",
       "         0.07262434, 0.15364397, 0.09071428, 0.80226314, 0.57555217,\n",
       "         0.16667673, 0.06743445, 0.24641444, 0.13636269]], dtype=float32),\n",
       " array([[0.1436009 , 0.8110764 , 0.06187175, 0.11963425, 0.11351515,\n",
       "         0.05482493, 0.15023208, 0.10690932, 0.7358786 , 0.57983947,\n",
       "         0.21848205, 0.02949   , 0.25760558, 0.12131096]], dtype=float32),\n",
       " array([[0.15869172, 0.8076542 , 0.03876149, 0.11184305, 0.10374131,\n",
       "         0.03606338, 0.1715564 , 0.10267919, 0.74012333, 0.58636415,\n",
       "         0.21486738, 0.01701532, 0.25130236, 0.11580083]], dtype=float32),\n",
       " array([[0.14927118, 0.8124477 , 0.11872109, 0.13152938, 0.12975144,\n",
       "         0.08328253, 0.14906836, 0.10057692, 0.746132  , 0.56486815,\n",
       "         0.20203836, 0.07409798, 0.28856778, 0.15226033]], dtype=float32),\n",
       " array([[0.1537911 , 0.81739664, 0.13286082, 0.1428318 , 0.13731968,\n",
       "         0.09133296, 0.13372542, 0.09846438, 0.7771192 , 0.5644973 ,\n",
       "         0.19045936, 0.08353626, 0.28342745, 0.16139495]], dtype=float32),\n",
       " array([[0.16719863, 0.8071602 , 0.09569833, 0.13262312, 0.13286744,\n",
       "         0.07130171, 0.14592355, 0.10139244, 0.7212903 , 0.56478566,\n",
       "         0.21696563, 0.05759755, 0.2984073 , 0.15218438]], dtype=float32),\n",
       " array([[0.21519285, 0.78677917, 0.03821214, 0.12584837, 0.11873902,\n",
       "         0.03194622, 0.10402352, 0.11161563, 0.7180379 , 0.5774899 ,\n",
       "         0.21823528, 0.0174123 , 0.27274877, 0.13423951]], dtype=float32),\n",
       " array([[0.1451842 , 0.81598866, 0.15969214, 0.11525069, 0.13488956,\n",
       "         0.08130856, 0.09973072, 0.11376689, 0.79354036, 0.5595423 ,\n",
       "         0.15417841, 0.11342213, 0.28123012, 0.18725537]], dtype=float32),\n",
       " array([[0.2182808 , 0.78667825, 0.17421085, 0.183714  , 0.16856961,\n",
       "         0.09629682, 0.10259826, 0.10684494, 0.7821791 , 0.559518  ,\n",
       "         0.17403914, 0.11191762, 0.30230793, 0.18707481]], dtype=float32),\n",
       " array([[0.220736  , 0.7856488 , 0.02565957, 0.11981064, 0.11544655,\n",
       "         0.0252085 , 0.15369551, 0.11103915, 0.6906403 , 0.5868445 ,\n",
       "         0.23988523, 0.01051461, 0.2710827 , 0.12224021]], dtype=float32),\n",
       " array([[2.6790693e-01, 7.6355720e-01, 2.2393919e-03, 7.4954651e-02,\n",
       "         6.8534300e-02, 3.8877788e-03, 1.7737232e-01, 1.1461051e-01,\n",
       "         5.9773523e-01, 6.1300075e-01, 2.9848656e-01, 5.7359861e-04,\n",
       "         2.3985782e-01, 7.7991165e-02]], dtype=float32),\n",
       " array([[0.25829598, 0.76985526, 0.01793806, 0.12825866, 0.1129208 ,\n",
       "         0.01894207, 0.16908182, 0.10721958, 0.6329079 , 0.5899041 ,\n",
       "         0.25675336, 0.00684731, 0.2806842 , 0.1067847 ]], dtype=float32),\n",
       " array([[0.2470884 , 0.7763658 , 0.02643848, 0.12736256, 0.11797413,\n",
       "         0.02372592, 0.12291984, 0.1145189 , 0.6707759 , 0.5821843 ,\n",
       "         0.23170877, 0.01108188, 0.27956304, 0.1242446 ]], dtype=float32),\n",
       " array([[0.22746517, 0.7880416 , 0.01413862, 0.11934578, 0.10403536,\n",
       "         0.0187453 , 0.11945646, 0.11085837, 0.6400088 , 0.5902611 ,\n",
       "         0.27642342, 0.00495136, 0.2631594 , 0.09969182]], dtype=float32),\n",
       " array([[0.22150053, 0.7955718 , 0.01702492, 0.1223611 , 0.10598777,\n",
       "         0.01982654, 0.13758881, 0.10414255, 0.6861128 , 0.5927457 ,\n",
       "         0.24241205, 0.00621982, 0.25526765, 0.10355932]], dtype=float32),\n",
       " array([[0.24835202, 0.7856193 , 0.03938156, 0.14327782, 0.13135563,\n",
       "         0.03131315, 0.1440024 , 0.11120274, 0.70972097, 0.57959163,\n",
       "         0.2071187 , 0.0176868 , 0.28388223, 0.13877648]], dtype=float32),\n",
       " array([[0.3426358 , 0.7411095 , 0.00659678, 0.10871409, 0.10829007,\n",
       "         0.00787002, 0.20435147, 0.12960361, 0.53173625, 0.5960169 ,\n",
       "         0.28790057, 0.00211137, 0.29949847, 0.10556641]], dtype=float32),\n",
       " array([[0.32517993, 0.743151  , 0.01413208, 0.144404  , 0.12198551,\n",
       "         0.01657728, 0.16608538, 0.11825062, 0.533192  , 0.5853196 ,\n",
       "         0.3023597 , 0.00505375, 0.3120769 , 0.10528768]], dtype=float32),\n",
       " array([[0.2491286 , 0.79094964, 0.02075095, 0.12949397, 0.11659422,\n",
       "         0.02029493, 0.18440147, 0.10742109, 0.6833742 , 0.5900873 ,\n",
       "         0.22192009, 0.00813053, 0.2728665 , 0.11751615]], dtype=float32),\n",
       " array([[0.33712262, 0.76757884, 0.00906667, 0.13302912, 0.11001288,\n",
       "         0.009439  , 0.19469623, 0.10849704, 0.68838567, 0.60036993,\n",
       "         0.21659967, 0.0028711 , 0.2655751 , 0.11310897]], dtype=float32),\n",
       " array([[0.31048414, 0.773633  , 0.00995546, 0.12435365, 0.10628378,\n",
       "         0.01049332, 0.2002907 , 0.11061101, 0.6792058 , 0.59776473,\n",
       "         0.22220312, 0.00329556, 0.2672412 , 0.11402442]], dtype=float32),\n",
       " array([[0.27150974, 0.77903026, 0.00483217, 0.09756491, 0.08443198,\n",
       "         0.00729496, 0.22660561, 0.11141589, 0.6031507 , 0.6036122 ,\n",
       "         0.2770581 , 0.00141361, 0.26170683, 0.08981662]], dtype=float32),\n",
       " array([[0.27115536, 0.76592857, 0.00714269, 0.10159224, 0.09038248,\n",
       "         0.00921977, 0.27083406, 0.10847464, 0.5455888 , 0.59875953,\n",
       "         0.28234652, 0.00236815, 0.28517574, 0.08857092]], dtype=float32),\n",
       " array([[0.32863748, 0.7530988 , 0.00627738, 0.12312448, 0.09876554,\n",
       "         0.0087874 , 0.2447809 , 0.11078728, 0.5312573 , 0.5975469 ,\n",
       "         0.29834703, 0.00191438, 0.2942042 , 0.08990074]], dtype=float32),\n",
       " array([[3.3569369e-01, 7.5873584e-01, 9.9982170e-04, 7.9247750e-02,\n",
       "         6.7274295e-02, 2.2550356e-03, 3.1743228e-01, 1.1460027e-01,\n",
       "         4.7931245e-01, 6.2045729e-01, 3.3769417e-01, 2.1714446e-04,\n",
       "         2.6079646e-01, 6.5464176e-02]], dtype=float32),\n",
       " array([[3.3103812e-01, 7.6885194e-01, 1.9424806e-03, 9.4653018e-02,\n",
       "         7.4070811e-02, 3.4663277e-03, 2.8866312e-01, 1.0754001e-01,\n",
       "         5.6457525e-01, 6.1361814e-01, 2.8476244e-01, 4.6989118e-04,\n",
       "         2.5817224e-01, 7.6397888e-02]], dtype=float32),\n",
       " array([[3.3838984e-01, 7.7740550e-01, 7.7408575e-04, 7.6665029e-02,\n",
       "         6.2495649e-02, 1.8130161e-03, 3.4559888e-01, 1.1311169e-01,\n",
       "         5.4455531e-01, 6.2374598e-01, 3.0427441e-01, 1.5691323e-04,\n",
       "         2.4430275e-01, 6.8857081e-02]], dtype=float32),\n",
       " array([[0.39716583, 0.77088785, 0.00405066, 0.1346704 , 0.10709488,\n",
       "         0.00640129, 0.4207012 , 0.10643033, 0.54636115, 0.6009237 ,\n",
       "         0.28627953, 0.00115795, 0.30965766, 0.10186165]], dtype=float32),\n",
       " array([[0.23276773, 0.8104801 , 0.01151168, 0.09807595, 0.09469489,\n",
       "         0.0120383 , 0.34329337, 0.10998691, 0.6661168 , 0.5957665 ,\n",
       "         0.2052567 , 0.00424941, 0.26969048, 0.11292006]], dtype=float32),\n",
       " array([[0.30891237, 0.78316325, 0.02530593, 0.14700867, 0.1275351 ,\n",
       "         0.02097629, 0.2610214 , 0.1202497 , 0.6677093 , 0.5794273 ,\n",
       "         0.20159686, 0.01015778, 0.30551597, 0.14462967]], dtype=float32),\n",
       " array([[0.17061678, 0.8330483 , 0.08585481, 0.10126655, 0.11721061,\n",
       "         0.03897052, 0.25851068, 0.10662315, 0.8055813 , 0.5716752 ,\n",
       "         0.11568735, 0.05554309, 0.27565798, 0.18686308]], dtype=float32),\n",
       " array([[0.24737264, 0.8045804 , 0.21150133, 0.19501495, 0.18228778,\n",
       "         0.09089105, 0.24230629, 0.1055233 , 0.80788505, 0.5590323 ,\n",
       "         0.12314581, 0.14836155, 0.31882742, 0.22275957]], dtype=float32),\n",
       " array([[0.22156252, 0.8123275 , 0.18967019, 0.17042708, 0.16589993,\n",
       "         0.083831  , 0.25250176, 0.10175233, 0.8110414 , 0.5594841 ,\n",
       "         0.12580587, 0.13625468, 0.31412628, 0.21999162]], dtype=float32),\n",
       " array([[0.17441323, 0.82559824, 0.28911173, 0.16600597, 0.16816996,\n",
       "         0.12076143, 0.200754  , 0.0964594 , 0.83667934, 0.5564236 ,\n",
       "         0.11205675, 0.238048  , 0.30010423, 0.2206343 ]], dtype=float32),\n",
       " array([[0.16169025, 0.8281435 , 0.19595978, 0.15893228, 0.15034845,\n",
       "         0.10044336, 0.15471578, 0.09713588, 0.8299546 , 0.56398857,\n",
       "         0.13093646, 0.13602072, 0.27573442, 0.18488929]], dtype=float32),\n",
       " array([[0.13372391, 0.84043294, 0.15721829, 0.12683871, 0.12660553,\n",
       "         0.07986383, 0.18655065, 0.08859849, 0.8442878 , 0.5699775 ,\n",
       "         0.12287337, 0.10968798, 0.2593495 , 0.1730562 ]], dtype=float32),\n",
       " array([[0.11845192, 0.84899914, 0.01965714, 0.07667077, 0.07480736,\n",
       "         0.01988563, 0.23762858, 0.08912465, 0.8055041 , 0.5993902 ,\n",
       "         0.16995691, 0.00816259, 0.21291272, 0.1063994 ]], dtype=float32),\n",
       " array([[0.11534586, 0.84654033, 0.06876869, 0.1033842 , 0.10093607,\n",
       "         0.0546435 , 0.21153256, 0.08741834, 0.79106104, 0.57919043,\n",
       "         0.17322169, 0.03896867, 0.24968734, 0.13026868]], dtype=float32),\n",
       " array([[0.12625413, 0.8385935 , 0.03498657, 0.09661986, 0.09364708,\n",
       "         0.03521942, 0.22550817, 0.09383941, 0.7501836 , 0.5889057 ,\n",
       "         0.20113353, 0.01607721, 0.2421497 , 0.1102109 ]], dtype=float32),\n",
       " array([[0.14076352, 0.8278619 , 0.01836771, 0.08734594, 0.08516338,\n",
       "         0.02443194, 0.24895091, 0.10341015, 0.67109066, 0.5898847 ,\n",
       "         0.25537977, 0.00740349, 0.2550828 , 0.10048853]], dtype=float32),\n",
       " array([[0.2201827 , 0.79351854, 0.00698954, 0.09478991, 0.081581  ,\n",
       "         0.01107602, 0.22504826, 0.11015215, 0.6144264 , 0.59686387,\n",
       "         0.28701764, 0.00219615, 0.2608877 , 0.09097177]], dtype=float32),\n",
       " array([[0.22776917, 0.7929317 , 0.00820315, 0.1031282 , 0.08720829,\n",
       "         0.01230083, 0.23505442, 0.10705638, 0.61647475, 0.5969214 ,\n",
       "         0.279875  , 0.00263516, 0.26442018, 0.09160608]], dtype=float32),\n",
       " array([[0.30770996, 0.7607812 , 0.0067846 , 0.10430942, 0.0908459 ,\n",
       "         0.00823022, 0.22557393, 0.11999199, 0.60071915, 0.59321535,\n",
       "         0.26215172, 0.00215131, 0.2842843 , 0.10756163]], dtype=float32),\n",
       " array([[0.3143475 , 0.76391876, 0.00313102, 0.10047417, 0.08528813,\n",
       "         0.00528067, 0.24863613, 0.11414488, 0.55248463, 0.60803455,\n",
       "         0.29984626, 0.00081696, 0.2675368 , 0.08203184]], dtype=float32),\n",
       " array([[0.23795293, 0.7941764 , 0.01889455, 0.11051418, 0.10914171,\n",
       "         0.01716136, 0.22626255, 0.11191148, 0.6719458 , 0.589562  ,\n",
       "         0.20980135, 0.0076236 , 0.27589804, 0.12049642]], dtype=float32),\n",
       " array([[0.28610763, 0.7842475 , 0.03728829, 0.15877159, 0.14048323,\n",
       "         0.02793239, 0.18051806, 0.11019175, 0.7208457 , 0.58120394,\n",
       "         0.18849547, 0.01611068, 0.28830132, 0.14506201]], dtype=float32),\n",
       " array([[0.28299692, 0.78106254, 0.08378465, 0.18063198, 0.16415676,\n",
       "         0.05084403, 0.13689418, 0.11782833, 0.73438746, 0.5653138 ,\n",
       "         0.1783227 , 0.04417159, 0.3102906 , 0.1784708 ]], dtype=float32),\n",
       " array([[0.26302817, 0.79544795, 0.12519354, 0.19863434, 0.18121162,\n",
       "         0.06996501, 0.13343826, 0.11135927, 0.7817802 , 0.56609154,\n",
       "         0.15667751, 0.07157332, 0.29866052, 0.18828046]], dtype=float32),\n",
       " array([[0.2479202 , 0.79457945, 0.16716449, 0.20973004, 0.18988384,\n",
       "         0.09062049, 0.11443429, 0.11270139, 0.78472644, 0.56284904,\n",
       "         0.15555179, 0.10081083, 0.29917145, 0.18895322]], dtype=float32),\n",
       " array([[0.22097474, 0.8089176 , 0.03555502, 0.1341136 , 0.12257753,\n",
       "         0.02856823, 0.14807476, 0.1022832 , 0.76691425, 0.58409697,\n",
       "         0.17932415, 0.01577813, 0.2601281 , 0.13794515]], dtype=float32),\n",
       " array([[0.19691147, 0.8123513 , 0.0675275 , 0.14725854, 0.13461755,\n",
       "         0.0482689 , 0.12055092, 0.10173909, 0.7713312 , 0.5758617 ,\n",
       "         0.174813  , 0.03462799, 0.26634043, 0.14462665]], dtype=float32),\n",
       " array([[0.19277336, 0.8128397 , 0.05286998, 0.14122288, 0.12501003,\n",
       "         0.04351822, 0.13133061, 0.100178  , 0.7548055 , 0.57665473,\n",
       "         0.19296317, 0.02540402, 0.26855916, 0.13575532]], dtype=float32),\n",
       " array([[0.14126247, 0.8309404 , 0.06106709, 0.10452507, 0.1060225 ,\n",
       "         0.04227545, 0.14271143, 0.10082922, 0.7931969 , 0.5789349 ,\n",
       "         0.16000783, 0.03252714, 0.24640663, 0.13900985]], dtype=float32),\n",
       " array([[0.16900212, 0.8141141 , 0.06279791, 0.12564036, 0.11754875,\n",
       "         0.0491808 , 0.13358437, 0.10575188, 0.75078136, 0.57345444,\n",
       "         0.19427927, 0.03218975, 0.26841155, 0.14009613]], dtype=float32),\n",
       " array([[0.16273485, 0.8153268 , 0.0476595 , 0.10792515, 0.10574579,\n",
       "         0.0377996 , 0.1653459 , 0.10615917, 0.7497756 , 0.5777294 ,\n",
       "         0.19133992, 0.0238141 , 0.2633333 , 0.13700841]], dtype=float32),\n",
       " array([[0.17266166, 0.8105269 , 0.06020876, 0.12680344, 0.11819897,\n",
       "         0.04966504, 0.1662091 , 0.10561622, 0.7296665 , 0.57376385,\n",
       "         0.20813334, 0.03075723, 0.2772871 , 0.13847561]], dtype=float32),\n",
       " array([[0.23899767, 0.7849971 , 0.0559081 , 0.1493195 , 0.13690874,\n",
       "         0.04205225, 0.15544853, 0.11371236, 0.7084783 , 0.5728534 ,\n",
       "         0.20854418, 0.02735197, 0.2954044 , 0.15013313]], dtype=float32),\n",
       " array([[0.19674833, 0.80382013, 0.0520863 , 0.12180578, 0.11904946,\n",
       "         0.03830051, 0.15643284, 0.1129332 , 0.74620444, 0.5746592 ,\n",
       "         0.18922201, 0.02605383, 0.2761361 , 0.15163279]], dtype=float32),\n",
       " array([[0.22438739, 0.7934425 , 0.04891675, 0.13383996, 0.12435734,\n",
       "         0.03504819, 0.1553944 , 0.11104494, 0.7468568 , 0.5764059 ,\n",
       "         0.18666644, 0.02356265, 0.2783466 , 0.15119375]], dtype=float32),\n",
       " array([[0.22359528, 0.79480505, 0.03036346, 0.12048823, 0.11229604,\n",
       "         0.02543689, 0.15793893, 0.1122946 , 0.7331501 , 0.58212197,\n",
       "         0.20067069, 0.01312214, 0.2693411 , 0.13793585]], dtype=float32),\n",
       " array([[0.2266351 , 0.7925605 , 0.01952756, 0.11201461, 0.10504295,\n",
       "         0.0184136 , 0.15765059, 0.11083456, 0.7092282 , 0.5899659 ,\n",
       "         0.21191332, 0.00769036, 0.25919044, 0.12008734]], dtype=float32),\n",
       " array([[0.20416315, 0.8009089 , 0.03368038, 0.11764526, 0.11160182,\n",
       "         0.0294871 , 0.16486798, 0.11205273, 0.71590275, 0.5805735 ,\n",
       "         0.21125674, 0.01503319, 0.27218112, 0.13390979]], dtype=float32),\n",
       " array([[0.19798584, 0.8041734 , 0.03658675, 0.1160725 , 0.11186123,\n",
       "         0.02999632, 0.14091054, 0.1115551 , 0.7347021 , 0.58039564,\n",
       "         0.19768077, 0.01672317, 0.26545212, 0.13581358]], dtype=float32),\n",
       " array([[0.19523752, 0.80306065, 0.0585827 , 0.12871133, 0.12072706,\n",
       "         0.04339134, 0.1154637 , 0.1131164 , 0.74630773, 0.57162356,\n",
       "         0.19298351, 0.02945197, 0.27426168, 0.14967206]], dtype=float32),\n",
       " array([[0.23002806, 0.7907094 , 0.04281997, 0.13714841, 0.12466323,\n",
       "         0.03329112, 0.10721117, 0.11378111, 0.7315073 , 0.5763278 ,\n",
       "         0.19931287, 0.01950198, 0.27417955, 0.14189325]], dtype=float32),\n",
       " array([[0.22365652, 0.7934184 , 0.03876078, 0.13046642, 0.12207059,\n",
       "         0.03077428, 0.1203235 , 0.11274143, 0.7249743 , 0.5792971 ,\n",
       "         0.20060661, 0.01745064, 0.27223265, 0.13698344]], dtype=float32),\n",
       " array([[0.24146672, 0.7825698 , 0.03173444, 0.13255183, 0.12131356,\n",
       "         0.02714122, 0.13592708, 0.11205206, 0.6863483 , 0.5808955 ,\n",
       "         0.22036605, 0.01373996, 0.28174448, 0.12874946]], dtype=float32),\n",
       " array([[0.20554121, 0.79516757, 0.03985748, 0.11785739, 0.11608244,\n",
       "         0.03025668, 0.12386065, 0.11255941, 0.7132777 , 0.5785413 ,\n",
       "         0.19845407, 0.01884681, 0.27358124, 0.13404074]], dtype=float32),\n",
       " array([[0.216466  , 0.79221994, 0.02713916, 0.11135515, 0.10826385,\n",
       "         0.02303127, 0.15536359, 0.1121199 , 0.6961911 , 0.58310926,\n",
       "         0.2110469 , 0.01177337, 0.2741015 , 0.12736627]], dtype=float32),\n",
       " array([[0.24991602, 0.7798304 , 0.02500902, 0.12644601, 0.11346383,\n",
       "         0.02197028, 0.16727625, 0.10738779, 0.6757796 , 0.5840091 ,\n",
       "         0.2230191 , 0.01049769, 0.28377897, 0.12335093]], dtype=float32),\n",
       " array([[0.25881562, 0.7755068 , 0.01952316, 0.12267258, 0.11254408,\n",
       "         0.01812358, 0.19911757, 0.10703885, 0.64559746, 0.5894602 ,\n",
       "         0.23197898, 0.00780955, 0.28460336, 0.11384805]], dtype=float32),\n",
       " array([[0.25139046, 0.7800302 , 0.02050297, 0.11719618, 0.10886224,\n",
       "         0.01892559, 0.21104135, 0.1097884 , 0.6498088 , 0.5862354 ,\n",
       "         0.23181729, 0.00845566, 0.28784287, 0.120951  ]], dtype=float32),\n",
       " array([[0.21831034, 0.7961663 , 0.03222405, 0.11619566, 0.11248074,\n",
       "         0.02645602, 0.19080117, 0.11194909, 0.69481677, 0.5810371 ,\n",
       "         0.2079693 , 0.0146338 , 0.28196737, 0.13402724]], dtype=float32),\n",
       " array([[0.23300685, 0.79438674, 0.02924183, 0.12643453, 0.11482015,\n",
       "         0.02597706, 0.16877016, 0.11314793, 0.70297486, 0.5816383 ,\n",
       "         0.21338135, 0.01237855, 0.27792877, 0.13294248]], dtype=float32),\n",
       " array([[0.18556422, 0.821201  , 0.04898204, 0.11283034, 0.11380742,\n",
       "         0.03523672, 0.1703672 , 0.11123522, 0.77741015, 0.57619077,\n",
       "         0.16970816, 0.0247561 , 0.2669518 , 0.15936422]], dtype=float32),\n",
       " array([[0.22440675, 0.80598074, 0.0533372 , 0.14345057, 0.13230449,\n",
       "         0.03987074, 0.16037078, 0.10871123, 0.7541553 , 0.57584536,\n",
       "         0.18539998, 0.02598894, 0.28044257, 0.15520135]], dtype=float32),\n",
       " array([[0.21656197, 0.8031954 , 0.04595948, 0.13043149, 0.12432554,\n",
       "         0.03517482, 0.17942616, 0.10778947, 0.72893715, 0.577351  ,\n",
       "         0.19441158, 0.02241491, 0.28386113, 0.14642145]], dtype=float32),\n",
       " array([[0.21914503, 0.79808325, 0.04676129, 0.13098824, 0.12228859,\n",
       "         0.0347503 , 0.16922964, 0.10654298, 0.7257405 , 0.5768002 ,\n",
       "         0.19426733, 0.02299459, 0.28460702, 0.14451951]], dtype=float32),\n",
       " array([[0.21322787, 0.79846317, 0.03314009, 0.12047125, 0.11152826,\n",
       "         0.02729818, 0.17033237, 0.10586102, 0.7168471 , 0.5825694 ,\n",
       "         0.20204313, 0.01497373, 0.27344403, 0.13049175]], dtype=float32),\n",
       " array([[0.24220574, 0.78716564, 0.01632023, 0.11318021, 0.1035017 ,\n",
       "         0.01581949, 0.18350783, 0.10696435, 0.6800949 , 0.5931185 ,\n",
       "         0.2199176 , 0.0062488 , 0.26568648, 0.1122366 ]], dtype=float32),\n",
       " array([[0.22363865, 0.7960322 , 0.01737985, 0.11432526, 0.10209125,\n",
       "         0.01759516, 0.17206559, 0.10617259, 0.69807535, 0.59423345,\n",
       "         0.2174949 , 0.00653185, 0.2554509 , 0.10903452]], dtype=float32),\n",
       " array([[0.22786085, 0.7912624 , 0.01562902, 0.11124101, 0.09994971,\n",
       "         0.01644124, 0.18783545, 0.10806951, 0.6747746 , 0.5941373 ,\n",
       "         0.228635  , 0.00579307, 0.2611739 , 0.10699706]], dtype=float32),\n",
       " array([[0.22246988, 0.79443866, 0.01125311, 0.10017575, 0.09141301,\n",
       "         0.01296508, 0.20461825, 0.10851067, 0.6649562 , 0.5980411 ,\n",
       "         0.2352017 , 0.00393346, 0.25534907, 0.1008043 ]], dtype=float32),\n",
       " array([[0.205911  , 0.80095816, 0.02026331, 0.10732248, 0.10150146,\n",
       "         0.0202057 , 0.19143994, 0.10951915, 0.6801451 , 0.58971417,\n",
       "         0.22244436, 0.00813022, 0.26526636, 0.11311355]], dtype=float32),\n",
       " array([[0.22997211, 0.79766214, 0.02706154, 0.12786028, 0.11465441,\n",
       "         0.02511774, 0.16424127, 0.11149188, 0.7060144 , 0.5835325 ,\n",
       "         0.2129867 , 0.01109721, 0.27392367, 0.1282047 ]], dtype=float32),\n",
       " array([[0.23619172, 0.7957636 , 0.02393742, 0.12491247, 0.11399218,\n",
       "         0.02227241, 0.1631351 , 0.11653618, 0.7092845 , 0.58634627,\n",
       "         0.20951754, 0.00935589, 0.26822463, 0.12768948]], dtype=float32),\n",
       " array([[0.26376048, 0.78602195, 0.01635444, 0.12285446, 0.10934596,\n",
       "         0.01649116, 0.20575309, 0.11135969, 0.67871815, 0.5896782 ,\n",
       "         0.22442707, 0.0060694 , 0.27817667, 0.12100135]], dtype=float32),\n",
       " array([[0.2529339 , 0.78796506, 0.02075396, 0.1220404 , 0.11253557,\n",
       "         0.01888712, 0.21554375, 0.11103258, 0.6840699 , 0.58788085,\n",
       "         0.21359558, 0.00825127, 0.2813592 , 0.12532635]], dtype=float32),\n",
       " array([[0.24276441, 0.797716  , 0.02061048, 0.12290318, 0.10968047,\n",
       "         0.01944892, 0.20787147, 0.10870329, 0.71578455, 0.58912426,\n",
       "         0.20618246, 0.00799854, 0.26998493, 0.12646165]], dtype=float32),\n",
       " array([[0.23081222, 0.79795325, 0.01675716, 0.10984454, 0.10306859,\n",
       "         0.01640715, 0.2126595 , 0.10875531, 0.69400156, 0.5927422 ,\n",
       "         0.21208268, 0.00642305, 0.26514336, 0.11666432]], dtype=float32),\n",
       " array([[0.23111396, 0.7998518 , 0.02625481, 0.12356016, 0.1121583 ,\n",
       "         0.0232496 , 0.19369963, 0.1070123 , 0.7137952 , 0.58515835,\n",
       "         0.2039279 , 0.01103798, 0.27440464, 0.12976205]], dtype=float32),\n",
       " array([[0.21930169, 0.79971933, 0.014141  , 0.09902679, 0.09257037,\n",
       "         0.01413762, 0.21529551, 0.10957588, 0.69978434, 0.5941498 ,\n",
       "         0.20974332, 0.00526387, 0.25782558, 0.11370528]], dtype=float32),\n",
       " array([[0.23449367, 0.7947775 , 0.02591232, 0.12181363, 0.1123736 ,\n",
       "         0.02252664, 0.18980192, 0.11001923, 0.6976153 , 0.5851311 ,\n",
       "         0.20679925, 0.01092681, 0.27638263, 0.12798731]], dtype=float32),\n",
       " array([[0.24138424, 0.7931678 , 0.02183044, 0.1255728 , 0.1127043 ,\n",
       "         0.0210796 , 0.20067792, 0.10720545, 0.6775984 , 0.5880443 ,\n",
       "         0.22160211, 0.00877271, 0.2769304 , 0.11930129]], dtype=float32),\n",
       " array([[0.25532317, 0.78069025, 0.01255007, 0.11652494, 0.10301725,\n",
       "         0.0139881 , 0.20039667, 0.10997336, 0.63047314, 0.59611005,\n",
       "         0.24381313, 0.00438595, 0.269983  , 0.10044552]], dtype=float32),\n",
       " array([[2.83126056e-01, 7.59327054e-01, 2.51352135e-03, 8.20629373e-02,\n",
       "         7.32262656e-02, 3.96392494e-03, 2.45174900e-01, 1.06806904e-01,\n",
       "         5.18697619e-01, 6.15512133e-01, 2.94478416e-01, 6.73443370e-04,\n",
       "         2.56445199e-01, 6.80906028e-02]], dtype=float32),\n",
       " array([[0.29251865, 0.76042014, 0.00479463, 0.10363969, 0.0869416 ,\n",
       "         0.00671729, 0.2343522 , 0.10442279, 0.5408998 , 0.6069926 ,\n",
       "         0.28494504, 0.00142341, 0.27057415, 0.07742142]], dtype=float32),\n",
       " array([[0.24829021, 0.79055214, 0.01449316, 0.1129847 , 0.10301375,\n",
       "         0.01459002, 0.21735092, 0.10734274, 0.65489733, 0.59357303,\n",
       "         0.22241303, 0.00543711, 0.27195704, 0.10868767]], dtype=float32),\n",
       " array([[0.22189441, 0.8087504 , 0.0232752 , 0.11728668, 0.10692018,\n",
       "         0.0216922 , 0.21756637, 0.10856555, 0.7184516 , 0.5866882 ,\n",
       "         0.20054667, 0.00954943, 0.26807553, 0.12903723]], dtype=float32),\n",
       " array([[0.24476872, 0.7994573 , 0.0255068 , 0.13123062, 0.11736597,\n",
       "         0.0233344 , 0.21489146, 0.10879844, 0.7020256 , 0.58574545,\n",
       "         0.20698796, 0.01047833, 0.27790517, 0.12983401]], dtype=float32),\n",
       " array([[0.170913  , 0.83393085, 0.0652466 , 0.11111992, 0.11761294,\n",
       "         0.04074984, 0.19251001, 0.11182421, 0.8085753 , 0.57475096,\n",
       "         0.1428381 , 0.03576034, 0.26204807, 0.17466564]], dtype=float32),\n",
       " array([[0.21171592, 0.81228596, 0.09708847, 0.14200434, 0.13994099,\n",
       "         0.05558736, 0.18297695, 0.11587456, 0.78667456, 0.56536835,\n",
       "         0.15319055, 0.05675204, 0.29194996, 0.19377503]], dtype=float32),\n",
       " array([[0.21152441, 0.8081528 , 0.08407868, 0.14100072, 0.13674292,\n",
       "         0.05018248, 0.16996282, 0.11232946, 0.77521855, 0.56985664,\n",
       "         0.15966564, 0.04714263, 0.28513232, 0.17608778]], dtype=float32),\n",
       " array([[0.2001321 , 0.8038494 , 0.06090219, 0.12583168, 0.11829048,\n",
       "         0.04013006, 0.14063238, 0.11119702, 0.7576702 , 0.57238996,\n",
       "         0.17355192, 0.03179573, 0.27508795, 0.15587808]], dtype=float32),\n",
       " array([[0.20530231, 0.8058634 , 0.04774979, 0.12749957, 0.12024935,\n",
       "         0.03320912, 0.16320027, 0.10449129, 0.7580772 , 0.5822943 ,\n",
       "         0.17199767, 0.02313103, 0.2645747 , 0.14019479]], dtype=float32),\n",
       " array([[0.21394768, 0.7980582 , 0.04038486, 0.12867261, 0.12012844,\n",
       "         0.03046643, 0.16872908, 0.10437654, 0.7255204 , 0.5845115 ,\n",
       "         0.18943234, 0.01874248, 0.26919165, 0.12969778]], dtype=float32),\n",
       " array([[0.20788892, 0.8001152 , 0.02536395, 0.11953665, 0.10721319,\n",
       "         0.02417991, 0.1678386 , 0.10399579, 0.70137525, 0.5889429 ,\n",
       "         0.21631807, 0.01045614, 0.2616045 , 0.11404587]], dtype=float32),\n",
       " array([[0.18947627, 0.80451655, 0.01859515, 0.10363118, 0.09606519,\n",
       "         0.0200258 , 0.20909679, 0.10193367, 0.67098826, 0.59330094,\n",
       "         0.23230879, 0.00737382, 0.2595824 , 0.10192007]], dtype=float32),\n",
       " array([[0.19954026, 0.8031884 , 0.01665132, 0.10597954, 0.09621382,\n",
       "         0.01829497, 0.21836385, 0.100943  , 0.6730414 , 0.5952393 ,\n",
       "         0.23158553, 0.00639274, 0.25875622, 0.10084394]], dtype=float32),\n",
       " array([[0.19112982, 0.8094547 , 0.03072852, 0.112781  , 0.10947424,\n",
       "         0.02759894, 0.19843929, 0.1058636 , 0.702896  , 0.5864402 ,\n",
       "         0.20872085, 0.01361309, 0.26788056, 0.12110069]], dtype=float32),\n",
       " array([[0.21117634, 0.80433667, 0.02841446, 0.12188844, 0.11103152,\n",
       "         0.02673947, 0.18676886, 0.10749473, 0.7092081 , 0.58487064,\n",
       "         0.21399602, 0.01195336, 0.27050275, 0.12544923]], dtype=float32),\n",
       " array([[0.21782415, 0.7962608 , 0.01731749, 0.10684603, 0.1003522 ,\n",
       "         0.01788737, 0.21205798, 0.1079    , 0.666552  , 0.5906167 ,\n",
       "         0.22984806, 0.00676459, 0.27055863, 0.11142255]], dtype=float32),\n",
       " array([[0.2667626 , 0.7761509 , 0.01062535, 0.10952251, 0.09883674,\n",
       "         0.01178013, 0.22425902, 0.10924829, 0.6272689 , 0.5958554 ,\n",
       "         0.24561137, 0.00372483, 0.27634442, 0.10387582]], dtype=float32),\n",
       " array([[0.26459995, 0.78126085, 0.02070248, 0.12709095, 0.11492511,\n",
       "         0.01925495, 0.20671673, 0.11057846, 0.6597438 , 0.5851683 ,\n",
       "         0.22558235, 0.00825534, 0.2916241 , 0.12380774]], dtype=float32),\n",
       " array([[0.22603892, 0.80526197, 0.03587659, 0.12403738, 0.1203561 ,\n",
       "         0.02778383, 0.2096068 , 0.11023584, 0.7339104 , 0.5817231 ,\n",
       "         0.18648279, 0.01651397, 0.27827296, 0.14604145]], dtype=float32),\n",
       " array([[0.24298616, 0.7937785 , 0.02534033, 0.12082699, 0.11350045,\n",
       "         0.02136707, 0.20411828, 0.10989634, 0.7019112 , 0.5850049 ,\n",
       "         0.2022928 , 0.01081199, 0.27900323, 0.13295935]], dtype=float32),\n",
       " array([[0.26951414, 0.77474034, 0.00828993, 0.10109594, 0.09216616,\n",
       "         0.00913166, 0.25487024, 0.10441379, 0.6174452 , 0.6008981 ,\n",
       "         0.24092579, 0.0028604 , 0.2714783 , 0.09724019]], dtype=float32),\n",
       " array([[0.2989787 , 0.76125664, 0.00829824, 0.11861851, 0.09988453,\n",
       "         0.00980091, 0.23347437, 0.10500889, 0.58247286, 0.6008535 ,\n",
       "         0.26227883, 0.00271629, 0.27862507, 0.09127281]], dtype=float32),\n",
       " array([[3.0086991e-01, 7.5549090e-01, 2.6994569e-03, 9.2635825e-02,\n",
       "         7.9364479e-02, 4.5248778e-03, 2.5046071e-01, 1.0807466e-01,\n",
       "         5.0172698e-01, 6.1447269e-01, 3.1171876e-01, 7.0727390e-04,\n",
       "         2.6327190e-01, 6.8230949e-02]], dtype=float32),\n",
       " array([[3.00635785e-01, 7.50526249e-01, 1.21794967e-03, 7.27468878e-02,\n",
       "         6.29866123e-02, 2.42439518e-03, 2.58008868e-01, 1.10902414e-01,\n",
       "         4.57281649e-01, 6.20617986e-01, 3.33382189e-01, 2.81033659e-04,\n",
       "         2.54510522e-01, 5.81970289e-02]], dtype=float32),\n",
       " array([[0.28991443, 0.77066725, 0.00362268, 0.09530243, 0.08055149,\n",
       "         0.00548714, 0.2601799 , 0.10718962, 0.55086505, 0.6088421 ,\n",
       "         0.28087056, 0.00101808, 0.26383987, 0.07760824]], dtype=float32),\n",
       " array([[0.24379805, 0.8010004 , 0.00911778, 0.09896997, 0.08957531,\n",
       "         0.01029448, 0.2682543 , 0.10170353, 0.6587204 , 0.59796774,\n",
       "         0.22196834, 0.00324695, 0.2651254 , 0.10327268]], dtype=float32),\n",
       " array([[0.2689298 , 0.792323  , 0.0067093 , 0.09934743, 0.08866191,\n",
       "         0.00836843, 0.29515225, 0.10629717, 0.63231224, 0.6002342 ,\n",
       "         0.23844038, 0.00218648, 0.2698581 , 0.10094641]], dtype=float32),\n",
       " array([[0.28247344, 0.7851426 , 0.00711713, 0.10735913, 0.09361745,\n",
       "         0.00898874, 0.2711899 , 0.11212525, 0.6198712 , 0.59916174,\n",
       "         0.24599963, 0.00224513, 0.2726282 , 0.10071508]], dtype=float32),\n",
       " array([[0.23902112, 0.80352175, 0.02375475, 0.11905301, 0.11370925,\n",
       "         0.02013595, 0.27212456, 0.10970815, 0.6966035 , 0.5883018 ,\n",
       "         0.19261838, 0.00995883, 0.27841017, 0.12941912]], dtype=float32),\n",
       " array([[0.2735292 , 0.7912644 , 0.0381087 , 0.1455871 , 0.13082254,\n",
       "         0.02762815, 0.26398292, 0.10845283, 0.70794433, 0.57879263,\n",
       "         0.18556467, 0.01750861, 0.30126026, 0.15056764]], dtype=float32),\n",
       " array([[0.25120345, 0.79850775, 0.01494454, 0.10466432, 0.09911326,\n",
       "         0.01342469, 0.31385818, 0.10560783, 0.6922501 , 0.5903524 ,\n",
       "         0.19669521, 0.00595778, 0.2810875 , 0.12723315]], dtype=float32),\n",
       " array([[0.24086607, 0.8052763 , 0.01294121, 0.10590547, 0.09415387,\n",
       "         0.01291616, 0.3066802 , 0.10225976, 0.71475106, 0.59429425,\n",
       "         0.19764824, 0.00478392, 0.2668049 , 0.11970995]], dtype=float32),\n",
       " array([[0.23746654, 0.8010372 , 0.01033621, 0.09896793, 0.09037093,\n",
       "         0.01047833, 0.33705252, 0.09875791, 0.69002277, 0.6014774 ,\n",
       "         0.20033835, 0.00370279, 0.2607096 , 0.1052108 ]], dtype=float32),\n",
       " array([[0.24575108, 0.79812276, 0.01819704, 0.11807509, 0.10375364,\n",
       "         0.0166421 , 0.2828957 , 0.10215298, 0.6997544 , 0.5911849 ,\n",
       "         0.19900273, 0.00714136, 0.27408206, 0.11998378]], dtype=float32),\n",
       " array([[0.16775218, 0.8339258 , 0.03868698, 0.10568544, 0.10386805,\n",
       "         0.03118284, 0.2400914 , 0.1047312 , 0.7734252 , 0.58199465,\n",
       "         0.16885068, 0.01839196, 0.2583307 , 0.14229584]], dtype=float32),\n",
       " array([[0.13548683, 0.8513584 , 0.10739642, 0.11890806, 0.11950005,\n",
       "         0.06841192, 0.19644943, 0.1034665 , 0.83406144, 0.5685729 ,\n",
       "         0.13781643, 0.06460391, 0.25854158, 0.17778829]], dtype=float32),\n",
       " array([[0.16049187, 0.8398399 , 0.1234206 , 0.13812234, 0.13464211,\n",
       "         0.07449625, 0.18905504, 0.10488539, 0.8283254 , 0.5658437 ,\n",
       "         0.13997903, 0.07502709, 0.27230725, 0.1875552 ]], dtype=float32),\n",
       " array([[0.19165291, 0.82242495, 0.07448895, 0.13472287, 0.12918943,\n",
       "         0.05122793, 0.22634138, 0.10507923, 0.7778634 , 0.5711147 ,\n",
       "         0.16870296, 0.04080923, 0.2845796 , 0.16971749]], dtype=float32),\n",
       " array([[0.16389231, 0.8305434 , 0.08692148, 0.12461017, 0.12653223,\n",
       "         0.05652753, 0.19964053, 0.10685448, 0.79247254, 0.5721473 ,\n",
       "         0.1574835 , 0.04946781, 0.27108288, 0.16666383]], dtype=float32),\n",
       " array([[0.197189  , 0.8092315 , 0.0517681 , 0.12927021, 0.12186617,\n",
       "         0.03819754, 0.18153691, 0.10874838, 0.7527574 , 0.5787989 ,\n",
       "         0.17927237, 0.0248828 , 0.2704431 , 0.14338748]], dtype=float32),\n",
       " array([[0.21976276, 0.7994701 , 0.03582548, 0.12114829, 0.11466537,\n",
       "         0.02760305, 0.2140671 , 0.10418733, 0.71833134, 0.5802317 ,\n",
       "         0.19283977, 0.01689722, 0.2828778 , 0.13828254]], dtype=float32),\n",
       " array([[0.23356879, 0.78880644, 0.00990303, 0.09614974, 0.08951121,\n",
       "         0.01085377, 0.25837326, 0.10188487, 0.64534646, 0.5992525 ,\n",
       "         0.2319462 , 0.00355506, 0.26371628, 0.09802383]], dtype=float32),\n",
       " array([[0.25786942, 0.7777291 , 0.00670391, 0.10389255, 0.08745496,\n",
       "         0.00894956, 0.25119463, 0.10388636, 0.6113456 , 0.6045858 ,\n",
       "         0.26083252, 0.00206458, 0.25957942, 0.08541209]], dtype=float32),\n",
       " array([[0.23636061, 0.78493905, 0.00419576, 0.08275184, 0.07430023,\n",
       "         0.00635653, 0.2587071 , 0.10613438, 0.588091  , 0.60789025,\n",
       "         0.27290058, 0.00123715, 0.25182566, 0.07869554]], dtype=float32),\n",
       " array([[0.23290013, 0.7877127 , 0.00398939, 0.08270465, 0.07349638,\n",
       "         0.00647384, 0.24872634, 0.10800357, 0.57741123, 0.60648036,\n",
       "         0.28333017, 0.00115123, 0.2529643 , 0.07760087]], dtype=float32),\n",
       " array([[0.24485686, 0.79118866, 0.00735905, 0.10215774, 0.08770268,\n",
       "         0.01032236, 0.2320322 , 0.10830046, 0.6155509 , 0.59798855,\n",
       "         0.26401615, 0.00233447, 0.26427156, 0.09246922]], dtype=float32),\n",
       " array([[0.24833381, 0.79370636, 0.00794566, 0.09876521, 0.08809224,\n",
       "         0.01000576, 0.24184978, 0.10489217, 0.6291447 , 0.595611  ,\n",
       "         0.24675396, 0.00271625, 0.26964286, 0.09958192]], dtype=float32),\n",
       " array([[0.2972675 , 0.77559376, 0.00755303, 0.10987207, 0.09690234,\n",
       "         0.00926486, 0.23948123, 0.10956236, 0.5902035 , 0.5937396 ,\n",
       "         0.2581064 , 0.00254528, 0.28619832, 0.10257882]], dtype=float32),\n",
       " array([[0.30481774, 0.7754401 , 0.00503279, 0.10066163, 0.08805469,\n",
       "         0.00667943, 0.25641826, 0.11306028, 0.5964044 , 0.5987024 ,\n",
       "         0.25683725, 0.00154272, 0.27584684, 0.09899391]], dtype=float32),\n",
       " array([[0.29898462, 0.77988374, 0.0048023 , 0.09762875, 0.0857153 ,\n",
       "         0.00629444, 0.27776626, 0.11381844, 0.61552024, 0.60100484,\n",
       "         0.24532524, 0.00143957, 0.26912716, 0.09948734]], dtype=float32),\n",
       " array([[3.1181654e-01, 7.7783495e-01, 2.6048745e-03, 8.4789932e-02,\n",
       "         7.4584521e-02, 3.7353616e-03, 2.8670093e-01, 1.1275319e-01,\n",
       "         6.0915190e-01, 6.0796046e-01, 2.4502468e-01, 7.0647360e-04,\n",
       "         2.5796750e-01, 9.0892062e-02]], dtype=float32),\n",
       " array([[3.0837300e-01, 7.8187829e-01, 2.2450287e-03, 8.3536841e-02,\n",
       "         7.2221845e-02, 3.5063745e-03, 3.0414060e-01, 1.1178420e-01,\n",
       "         6.0355628e-01, 6.0981029e-01, 2.5275275e-01, 5.8528216e-04,\n",
       "         2.5557682e-01, 8.7091863e-02]], dtype=float32),\n",
       " array([[0.26206973, 0.80096555, 0.00821954, 0.10243405, 0.09195696,\n",
       "         0.00918865, 0.2908716 , 0.10637898, 0.67249423, 0.59870213,\n",
       "         0.2092373 , 0.00277367, 0.26227063, 0.10686223]], dtype=float32),\n",
       " array([[0.23146904, 0.80936384, 0.01836356, 0.1111805 , 0.1021504 ,\n",
       "         0.01669519, 0.25349185, 0.10678598, 0.70754033, 0.58817697,\n",
       "         0.18921877, 0.00732571, 0.26825657, 0.12388131]], dtype=float32),\n",
       " array([[0.23068644, 0.80619824, 0.02143857, 0.11315226, 0.10725685,\n",
       "         0.01834708, 0.23759688, 0.1076915 , 0.70163715, 0.58613795,\n",
       "         0.18735851, 0.00896825, 0.27279705, 0.12602572]], dtype=float32),\n",
       " array([[0.23466599, 0.80487496, 0.0346281 , 0.13136834, 0.11981685,\n",
       "         0.02698088, 0.22229458, 0.10743026, 0.7204799 , 0.5792789 ,\n",
       "         0.18234389, 0.0156694 , 0.2823705 , 0.14002751]], dtype=float32),\n",
       " array([[0.24795027, 0.80117637, 0.05981611, 0.1616436 , 0.14505485,\n",
       "         0.04089274, 0.21130182, 0.10522432, 0.7305567 , 0.5747818 ,\n",
       "         0.1742667 , 0.02974861, 0.29401556, 0.15143906]], dtype=float32),\n",
       " array([[0.20202263, 0.819243  , 0.06868181, 0.13849273, 0.13210958,\n",
       "         0.04359056, 0.20535968, 0.10313879, 0.7770701 , 0.5748926 ,\n",
       "         0.15326294, 0.03672503, 0.27540156, 0.15859418]], dtype=float32),\n",
       " array([[0.20337364, 0.8171341 , 0.03091393, 0.11500081, 0.11022612,\n",
       "         0.02482722, 0.25597322, 0.1010406 , 0.74606925, 0.5851975 ,\n",
       "         0.17555574, 0.01406839, 0.26650503, 0.13476591]], dtype=float32),\n",
       " array([[0.18572307, 0.816711  , 0.02160681, 0.09689073, 0.09202306,\n",
       "         0.01857378, 0.2598089 , 0.09885441, 0.7402743 , 0.59000826,\n",
       "         0.17935643, 0.00929453, 0.25356036, 0.11990728]], dtype=float32),\n",
       " array([[0.20373337, 0.8042085 , 0.00451848, 0.07193367, 0.06828728,\n",
       "         0.00599431, 0.3177553 , 0.0982806 , 0.65149254, 0.61042523,\n",
       "         0.22812323, 0.00141664, 0.23751877, 0.08181572]], dtype=float32),\n",
       " array([[0.2300852 , 0.79122156, 0.0089785 , 0.09939139, 0.08603363,\n",
       "         0.0111854 , 0.28582537, 0.09766372, 0.614378  , 0.59752935,\n",
       "         0.2509786 , 0.00316393, 0.26857907, 0.09016014]], dtype=float32),\n",
       " array([[0.20107475, 0.81004506, 0.02116273, 0.11470433, 0.10141978,\n",
       "         0.02225373, 0.26640913, 0.09850999, 0.67718446, 0.5888081 ,\n",
       "         0.22148402, 0.00861084, 0.2692757 , 0.1079073 ]], dtype=float32),\n",
       " array([[0.14104143, 0.83974415, 0.04314332, 0.09947389, 0.10106388,\n",
       "         0.03505445, 0.21313637, 0.10452754, 0.7763031 , 0.58297503,\n",
       "         0.16690017, 0.02063443, 0.24530187, 0.13115095]], dtype=float32),\n",
       " array([[0.17367578, 0.8297627 , 0.08175773, 0.1285793 , 0.1256331 ,\n",
       "         0.05403279, 0.18712866, 0.10815694, 0.7978042 , 0.5687175 ,\n",
       "         0.15580387, 0.04485614, 0.2724054 , 0.17145975]], dtype=float32),\n",
       " array([[0.17925231, 0.82434326, 0.11607628, 0.14759238, 0.14415227,\n",
       "         0.07057086, 0.15981118, 0.10678267, 0.7970955 , 0.5667804 ,\n",
       "         0.152733  , 0.068836  , 0.27683225, 0.17417373]], dtype=float32),\n",
       " array([[0.21543075, 0.8051203 , 0.08389375, 0.14614579, 0.14752363,\n",
       "         0.05276941, 0.17771766, 0.11371776, 0.7476385 , 0.56885713,\n",
       "         0.17219047, 0.04621983, 0.29395318, 0.16918238]], dtype=float32),\n",
       " array([[0.21069993, 0.80451584, 0.1442293 , 0.16738382, 0.16238111,\n",
       "         0.07813494, 0.15111051, 0.10793642, 0.77607006, 0.5619811 ,\n",
       "         0.15566418, 0.09155007, 0.29898438, 0.18357354]], dtype=float32),\n",
       " array([[0.21520579, 0.8017887 , 0.0759616 , 0.14779177, 0.14054635,\n",
       "         0.04955476, 0.15526278, 0.1089372 , 0.75535333, 0.570687  ,\n",
       "         0.17479718, 0.04032863, 0.28563446, 0.15976362]], dtype=float32),\n",
       " array([[0.18238765, 0.82131964, 0.05719262, 0.12382449, 0.11873639,\n",
       "         0.03788016, 0.14913459, 0.10237055, 0.8128794 , 0.57921326,\n",
       "         0.15042461, 0.02861918, 0.25034416, 0.15293927]], dtype=float32),\n",
       " array([[0.15349618, 0.8283106 , 0.12589647, 0.13178985, 0.1284676 ,\n",
       "         0.0711221 , 0.11033827, 0.1036969 , 0.83326095, 0.56606805,\n",
       "         0.13939981, 0.07731393, 0.25644666, 0.17498496]], dtype=float32),\n",
       " array([[0.16061045, 0.8262287 , 0.12271404, 0.14525561, 0.13900489,\n",
       "         0.07628838, 0.10461771, 0.10314688, 0.8203944 , 0.56789565,\n",
       "         0.15252542, 0.07236192, 0.25888345, 0.16660462]], dtype=float32),\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "togive1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('C:/Users/yy2895/Desktop/update_stresult19-14-19.csv', 'w',newline='') as myfile:\n",
    "     wr = csv.writer(myfile)\n",
    "     for i in range(len(togive1)):\n",
    "        wr.writerow(list(togive1[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
