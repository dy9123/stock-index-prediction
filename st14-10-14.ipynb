{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "df=pd.read_csv('C:/Users/yy2895/Desktop/update_stresult19-14-19.csv',header=None)\n",
    "d = df.values\n",
    "ntotal=len(df)\n",
    "\n",
    "# we do not renormalize it \n",
    "#d = normalize(d, axis=0, norm='l2')\n",
    "\n",
    "\n",
    "resultu = []\n",
    "np.random.rand(4)\n",
    "# Return 100 results (for instance)\n",
    "for i in range(ntotal):\n",
    "    \n",
    "    res = random.random()\n",
    "    if res < 0.1:\n",
    "        resultu.append(1)\n",
    "    elif res < 0.2 and res>=0.1:\n",
    "        resultu.append(2)\n",
    "    elif res < 0.3 and res>=0.2:\n",
    "        resultu.append(3)\n",
    "    elif res < 0.4 and res>=0.3:\n",
    "        resultu.append(4)\n",
    "    elif res < 0.5 and res>=0.4:\n",
    "        resultu.append(5)\n",
    "    elif res < 0.6 and res>=0.5:\n",
    "        resultu.append(6)\n",
    "    elif res < 0.7 and res>=0.6:\n",
    "        resultu.append(7)\n",
    "    elif res < 0.8 and res>=0.7:\n",
    "        resultu.append(8)\n",
    "    else:\n",
    "        resultu.append(9)\n",
    "resultu=np.array(resultu)\n",
    "trainset=[]\n",
    "for i in range(1,8):\n",
    "    toinsert=d[resultu==i].astype(np.float32)\n",
    "    trainset.append(toinsert)\n",
    "validationset=d[resultu==8].astype(np.float32)\n",
    "testset=d[resultu==9].astype(np.float32)\n",
    "\n",
    "\n",
    "#x = data\n",
    "\n",
    "# Following Hinton-Salakhutdinov Architecture\n",
    "\n",
    "# 3 hidden layers for encoder\n",
    "n_encoder_h_1 = 14\n",
    "n_encoder_h_2 = 9\n",
    "\n",
    "\n",
    "\n",
    "#n_encoder_h_5 = 10\n",
    "\n",
    "\n",
    "# 3 hidden layers for decoder\n",
    "#n_decoder_h_1 = 10\n",
    "n_decoder_h_1 = 14\n",
    "n_decoder_h_2 = 19\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.005\n",
    "\n",
    "#batch_size = 7\n",
    "display_step = 1\n",
    "\n",
    "total_batch=7\n",
    "training_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we begin\n",
      "Epoch: 0001 cost = 1.477621658\n",
      "Validation Loss: 1.7107922\n",
      "Epoch: 0002 cost = 1.458867993\n",
      "Validation Loss: 1.6648624\n",
      "Epoch: 0003 cost = 1.441209946\n",
      "Validation Loss: 1.5608352\n",
      "Epoch: 0004 cost = 1.423821875\n",
      "Validation Loss: 1.516264\n",
      "Epoch: 0005 cost = 1.406043410\n",
      "Validation Loss: 1.4897624\n",
      "Epoch: 0006 cost = 1.388577700\n",
      "Validation Loss: 1.4662479\n",
      "Epoch: 0007 cost = 1.372014727\n",
      "Validation Loss: 1.4344769\n",
      "Epoch: 0008 cost = 1.356213604\n",
      "Validation Loss: 1.4100777\n",
      "Epoch: 0009 cost = 1.341070703\n",
      "Validation Loss: 1.3938932\n",
      "Epoch: 0010 cost = 1.326515998\n",
      "Validation Loss: 1.3718297\n",
      "Epoch: 0011 cost = 1.312378815\n",
      "Validation Loss: 1.3530461\n",
      "Epoch: 0012 cost = 1.298532673\n",
      "Validation Loss: 1.3393945\n",
      "Epoch: 0013 cost = 1.284949354\n",
      "Validation Loss: 1.3247288\n",
      "Epoch: 0014 cost = 1.271744268\n",
      "Validation Loss: 1.3120531\n",
      "Epoch: 0015 cost = 1.259104235\n",
      "Validation Loss: 1.2963032\n",
      "Epoch: 0016 cost = 1.247097441\n",
      "Validation Loss: 1.2779834\n",
      "Epoch: 0017 cost = 1.235615662\n",
      "Validation Loss: 1.2560174\n",
      "Epoch: 0018 cost = 1.224476610\n",
      "Validation Loss: 1.2553971\n",
      "Epoch: 0019 cost = 1.213505183\n",
      "Validation Loss: 1.2488527\n",
      "Epoch: 0020 cost = 1.202615431\n",
      "Validation Loss: 1.2320263\n",
      "Epoch: 0021 cost = 1.191847886\n",
      "Validation Loss: 1.2214099\n",
      "Epoch: 0022 cost = 1.181286624\n",
      "Validation Loss: 1.2153558\n",
      "Epoch: 0023 cost = 1.170941762\n",
      "Validation Loss: 1.2015046\n",
      "Epoch: 0024 cost = 1.160721813\n",
      "Validation Loss: 1.1973647\n",
      "Epoch: 0025 cost = 1.150520035\n",
      "Validation Loss: 1.1981441\n",
      "Epoch: 0026 cost = 1.140250427\n",
      "Validation Loss: 1.1434748\n",
      "Epoch: 0027 cost = 1.129801801\n",
      "Validation Loss: 1.1749606\n",
      "Epoch: 0028 cost = 1.119035295\n",
      "Validation Loss: 1.113577\n",
      "Epoch: 0029 cost = 1.107787286\n",
      "Validation Loss: 1.164266\n",
      "Epoch: 0030 cost = 1.095938802\n",
      "Validation Loss: 1.1169372\n",
      "Epoch: 0031 cost = 1.083803671\n",
      "Validation Loss: 1.1065099\n",
      "Epoch: 0032 cost = 1.072469626\n",
      "Validation Loss: 1.1704075\n",
      "Epoch: 0033 cost = 1.062462347\n",
      "Validation Loss: 1.1196545\n",
      "Epoch: 0034 cost = 1.053405421\n",
      "Validation Loss: 1.1029047\n",
      "Epoch: 0035 cost = 1.044911112\n",
      "Validation Loss: 1.1421672\n",
      "Epoch: 0036 cost = 1.036831617\n",
      "Validation Loss: 1.0620315\n",
      "Epoch: 0037 cost = 1.029094900\n",
      "Validation Loss: 1.0779399\n",
      "Epoch: 0038 cost = 1.021624480\n",
      "Validation Loss: 1.0175327\n",
      "Epoch: 0039 cost = 1.014365707\n",
      "Validation Loss: 1.0699967\n",
      "Epoch: 0040 cost = 1.007290474\n",
      "Validation Loss: 1.0062573\n",
      "Epoch: 0041 cost = 1.000381368\n",
      "Validation Loss: 1.0563947\n",
      "Epoch: 0042 cost = 0.993597993\n",
      "Validation Loss: 0.9877597\n",
      "Epoch: 0043 cost = 0.986904894\n",
      "Validation Loss: 1.0480304\n",
      "Epoch: 0044 cost = 0.980296263\n",
      "Validation Loss: 0.97288543\n",
      "Epoch: 0045 cost = 0.973771853\n",
      "Validation Loss: 1.0198543\n",
      "Epoch: 0046 cost = 0.967325866\n",
      "Validation Loss: 0.959113\n",
      "Epoch: 0047 cost = 0.960954394\n",
      "Validation Loss: 1.0267049\n",
      "Epoch: 0048 cost = 0.954654166\n",
      "Validation Loss: 0.9577714\n",
      "Epoch: 0049 cost = 0.948421104\n",
      "Validation Loss: 1.0129391\n",
      "Epoch: 0050 cost = 0.942253053\n",
      "Validation Loss: 0.94711256\n",
      "Epoch: 0051 cost = 0.936147903\n",
      "Validation Loss: 1.0053056\n",
      "Epoch: 0052 cost = 0.930102953\n",
      "Validation Loss: 0.92907935\n",
      "Epoch: 0053 cost = 0.924115564\n",
      "Validation Loss: 0.9915972\n",
      "Epoch: 0054 cost = 0.918183608\n",
      "Validation Loss: 0.92099833\n",
      "Epoch: 0055 cost = 0.912303882\n",
      "Validation Loss: 0.964605\n",
      "Epoch: 0056 cost = 0.906474633\n",
      "Validation Loss: 0.896531\n",
      "Epoch: 0057 cost = 0.900693383\n",
      "Validation Loss: 0.95192087\n",
      "Epoch: 0058 cost = 0.894957866\n",
      "Validation Loss: 0.8853677\n",
      "Epoch: 0059 cost = 0.889266414\n",
      "Validation Loss: 0.9645031\n",
      "Epoch: 0060 cost = 0.883617214\n",
      "Validation Loss: 0.8904641\n",
      "Epoch: 0061 cost = 0.878008434\n",
      "Validation Loss: 0.8677013\n",
      "Epoch: 0062 cost = 0.872438746\n",
      "Validation Loss: 0.9457814\n",
      "Epoch: 0063 cost = 0.866906822\n",
      "Validation Loss: 0.8757231\n",
      "Epoch: 0064 cost = 0.861411461\n",
      "Validation Loss: 0.8564501\n",
      "Epoch: 0065 cost = 0.855951803\n",
      "Validation Loss: 0.9383428\n",
      "Epoch: 0066 cost = 0.850526495\n",
      "Validation Loss: 0.8600736\n",
      "Epoch: 0067 cost = 0.845134939\n",
      "Validation Loss: 0.82902956\n",
      "Epoch: 0068 cost = 0.839776329\n",
      "Validation Loss: 0.9164252\n",
      "Epoch: 0069 cost = 0.834449768\n",
      "Validation Loss: 0.8607775\n",
      "Epoch: 0070 cost = 0.829154611\n",
      "Validation Loss: 0.84567493\n",
      "Epoch: 0071 cost = 0.823890218\n",
      "Validation Loss: 0.82069176\n",
      "Epoch: 0072 cost = 0.818656138\n",
      "Validation Loss: 0.8982431\n",
      "Epoch: 0073 cost = 0.813451835\n",
      "Validation Loss: 0.82764137\n",
      "Epoch: 0074 cost = 0.808276372\n",
      "Validation Loss: 0.80064124\n",
      "Epoch: 0075 cost = 0.803129332\n",
      "Validation Loss: 0.8744238\n",
      "Epoch: 0076 cost = 0.798010681\n",
      "Validation Loss: 0.78991514\n",
      "Epoch: 0077 cost = 0.792919593\n",
      "Validation Loss: 0.85064477\n",
      "Epoch: 0078 cost = 0.787855387\n",
      "Validation Loss: 0.78612405\n",
      "Epoch: 0079 cost = 0.782817824\n",
      "Validation Loss: 0.84704405\n",
      "Epoch: 0080 cost = 0.777806844\n",
      "Validation Loss: 0.78295815\n",
      "Epoch: 0081 cost = 0.772821231\n",
      "Validation Loss: 0.8405575\n",
      "Epoch: 0082 cost = 0.767861204\n",
      "Validation Loss: 0.79172546\n",
      "Epoch: 0083 cost = 0.762926340\n",
      "Validation Loss: 0.77619475\n",
      "Epoch: 0084 cost = 0.758015743\n",
      "Validation Loss: 0.85003966\n",
      "Epoch: 0085 cost = 0.753129499\n",
      "Validation Loss: 0.7766232\n",
      "Epoch: 0086 cost = 0.748267446\n",
      "Validation Loss: 0.74095947\n",
      "Epoch: 0087 cost = 0.743428358\n",
      "Validation Loss: 0.83688504\n",
      "Epoch: 0088 cost = 0.738612916\n",
      "Validation Loss: 0.76879615\n",
      "Epoch: 0089 cost = 0.733820115\n",
      "Validation Loss: 0.7542924\n",
      "Epoch: 0090 cost = 0.729049827\n",
      "Validation Loss: 0.74097896\n",
      "Epoch: 0091 cost = 0.724301892\n",
      "Validation Loss: 0.7300979\n",
      "Epoch: 0092 cost = 0.719575737\n",
      "Validation Loss: 0.8020255\n",
      "Epoch: 0093 cost = 0.714871475\n",
      "Validation Loss: 0.75226617\n",
      "Epoch: 0094 cost = 0.710188934\n",
      "Validation Loss: 0.74862957\n",
      "Epoch: 0095 cost = 0.705527442\n",
      "Validation Loss: 0.7486125\n",
      "Epoch: 0096 cost = 0.700887178\n",
      "Validation Loss: 0.73881257\n",
      "Epoch: 0097 cost = 0.696268056\n",
      "Validation Loss: 0.7318977\n",
      "Epoch: 0098 cost = 0.691669754\n",
      "Validation Loss: 0.71689755\n",
      "Epoch: 0099 cost = 0.687092270\n",
      "Validation Loss: 0.7888612\n",
      "Epoch: 0100 cost = 0.682535350\n",
      "Validation Loss: 0.7383345\n",
      "Epoch: 0101 cost = 0.677999130\n",
      "Validation Loss: 0.7371649\n",
      "Epoch: 0102 cost = 0.673483304\n",
      "Validation Loss: 0.7142081\n",
      "Epoch: 0103 cost = 0.668988109\n",
      "Validation Loss: 0.7847329\n",
      "Epoch: 0104 cost = 0.664513367\n",
      "Validation Loss: 0.7354474\n",
      "Epoch: 0105 cost = 0.660058890\n",
      "Validation Loss: 0.7239505\n",
      "Epoch: 0106 cost = 0.655624662\n",
      "Validation Loss: 0.7104376\n",
      "Epoch: 0107 cost = 0.651210581\n",
      "Validation Loss: 0.77853495\n",
      "Epoch: 0108 cost = 0.646816552\n",
      "Validation Loss: 0.73393214\n",
      "Epoch: 0109 cost = 0.642442831\n",
      "Validation Loss: 0.72445023\n",
      "Epoch: 0110 cost = 0.638088150\n",
      "Validation Loss: 0.70189416\n",
      "Epoch: 0111 cost = 0.633753095\n",
      "Validation Loss: 0.7607543\n",
      "Epoch: 0112 cost = 0.629437038\n",
      "Validation Loss: 0.70625615\n",
      "Epoch: 0113 cost = 0.625140190\n",
      "Validation Loss: 0.70733213\n",
      "Epoch: 0114 cost = 0.620861624\n",
      "Validation Loss: 0.6922265\n",
      "Epoch: 0115 cost = 0.616601425\n",
      "Validation Loss: 0.7534069\n",
      "Epoch: 0116 cost = 0.612359115\n",
      "Validation Loss: 0.6949101\n",
      "Epoch: 0117 cost = 0.608134338\n",
      "Validation Loss: 0.6811267\n",
      "Epoch: 0118 cost = 0.603926352\n",
      "Validation Loss: 0.7439565\n",
      "Epoch: 0119 cost = 0.599735251\n",
      "Validation Loss: 0.7299832\n",
      "Epoch: 0120 cost = 0.595560176\n",
      "Validation Loss: 0.6917064\n",
      "Epoch: 0121 cost = 0.591401134\n",
      "Validation Loss: 0.69247603\n",
      "Epoch: 0122 cost = 0.587257300\n",
      "Validation Loss: 0.7037531\n",
      "Epoch: 0123 cost = 0.583128827\n",
      "Validation Loss: 0.6855812\n",
      "Epoch: 0124 cost = 0.579014838\n",
      "Validation Loss: 0.73004895\n",
      "Epoch: 0125 cost = 0.574915137\n",
      "Validation Loss: 0.78052026\n",
      "Epoch: 0126 cost = 0.570829724\n",
      "Validation Loss: 0.7146042\n",
      "Epoch: 0127 cost = 0.566758054\n",
      "Validation Loss: 0.69843215\n",
      "Epoch: 0128 cost = 0.562700280\n",
      "Validation Loss: 0.6834907\n",
      "Epoch: 0129 cost = 0.558655960\n",
      "Validation Loss: 0.6340591\n",
      "Epoch: 0130 cost = 0.554626278\n",
      "Validation Loss: 0.73207957\n",
      "Epoch: 0131 cost = 0.550610261\n",
      "Validation Loss: 0.7259028\n",
      "Epoch: 0132 cost = 0.546609393\n",
      "Validation Loss: 0.758192\n",
      "Epoch: 0133 cost = 0.542624320\n",
      "Validation Loss: 0.7997623\n",
      "Epoch: 0134 cost = 0.538655783\n",
      "Validation Loss: 0.8529816\n",
      "Epoch: 0135 cost = 0.534706014\n",
      "Validation Loss: 0.70666325\n",
      "Epoch: 0136 cost = 0.530775402\n",
      "Validation Loss: 0.5854787\n",
      "Epoch: 0137 cost = 0.526866445\n",
      "Validation Loss: 0.63258857\n",
      "Epoch: 0138 cost = 0.522980673\n",
      "Validation Loss: 0.6224531\n",
      "Epoch: 0139 cost = 0.519120574\n",
      "Validation Loss: 0.670191\n",
      "Epoch: 0140 cost = 0.515288021\n",
      "Validation Loss: 0.8335359\n",
      "Epoch: 0141 cost = 0.511484193\n",
      "Validation Loss: 0.9281468\n",
      "Epoch: 0142 cost = 0.507711283\n",
      "Validation Loss: 0.8022552\n",
      "Epoch: 0143 cost = 0.503970099\n",
      "Validation Loss: 0.7887306\n",
      "Epoch: 0144 cost = 0.500261303\n",
      "Validation Loss: 0.7048552\n",
      "Epoch: 0145 cost = 0.496585633\n",
      "Validation Loss: 0.6520431\n",
      "Epoch: 0146 cost = 0.492942874\n",
      "Validation Loss: 0.6232419\n",
      "Epoch: 0147 cost = 0.489334094\n",
      "Validation Loss: 0.64271176\n",
      "Epoch: 0148 cost = 0.485757781\n",
      "Validation Loss: 0.6297527\n",
      "Epoch: 0149 cost = 0.482214928\n",
      "Validation Loss: 0.5698083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0150 cost = 0.478704308\n",
      "Validation Loss: 0.5312332\n",
      "Epoch: 0151 cost = 0.475225670\n",
      "Validation Loss: 0.48282394\n",
      "Epoch: 0152 cost = 0.471778904\n",
      "Validation Loss: 0.46818602\n",
      "Epoch: 0153 cost = 0.468362940\n",
      "Validation Loss: 0.49305475\n",
      "Epoch: 0154 cost = 0.464977754\n",
      "Validation Loss: 0.5406811\n",
      "Epoch: 0155 cost = 0.461622374\n",
      "Validation Loss: 0.47731873\n",
      "Epoch: 0156 cost = 0.458295728\n",
      "Validation Loss: 0.4245923\n",
      "Epoch: 0157 cost = 0.454997561\n",
      "Validation Loss: 0.56960374\n",
      "Epoch: 0158 cost = 0.451727424\n",
      "Validation Loss: 0.44081053\n",
      "Epoch: 0159 cost = 0.448483965\n",
      "Validation Loss: 0.43207896\n",
      "Epoch: 0160 cost = 0.445267809\n",
      "Validation Loss: 0.36091083\n",
      "Epoch: 0161 cost = 0.442077777\n",
      "Validation Loss: 0.4587518\n",
      "Epoch: 0162 cost = 0.438913912\n",
      "Validation Loss: 0.37674206\n",
      "Epoch: 0163 cost = 0.435776357\n",
      "Validation Loss: 0.4033853\n",
      "Epoch: 0164 cost = 0.432664509\n",
      "Validation Loss: 0.46771216\n",
      "Epoch: 0165 cost = 0.429578270\n",
      "Validation Loss: 0.5331566\n",
      "Epoch: 0166 cost = 0.426517593\n",
      "Validation Loss: 0.53056705\n",
      "Epoch: 0167 cost = 0.423482835\n",
      "Validation Loss: 0.52874774\n",
      "Epoch: 0168 cost = 0.420473226\n",
      "Validation Loss: 0.5407613\n",
      "Epoch: 0169 cost = 0.417488775\n",
      "Validation Loss: 0.4892055\n",
      "Epoch: 0170 cost = 0.414529869\n",
      "Validation Loss: 0.45069233\n",
      "Epoch: 0171 cost = 0.411596068\n",
      "Validation Loss: 0.382826\n",
      "Epoch: 0172 cost = 0.408686591\n",
      "Validation Loss: 0.37011918\n",
      "Epoch: 0173 cost = 0.405802224\n",
      "Validation Loss: 0.44938076\n",
      "Epoch: 0174 cost = 0.402941946\n",
      "Validation Loss: 0.46301433\n",
      "Epoch: 0175 cost = 0.400106149\n",
      "Validation Loss: 0.4190235\n",
      "Epoch: 0176 cost = 0.397294364\n",
      "Validation Loss: 0.3863828\n",
      "Epoch: 0177 cost = 0.394506340\n",
      "Validation Loss: 0.30623612\n",
      "Epoch: 0178 cost = 0.391741804\n",
      "Validation Loss: 0.438343\n",
      "Epoch: 0179 cost = 0.389001016\n",
      "Validation Loss: 0.46251127\n",
      "Epoch: 0180 cost = 0.386282678\n",
      "Validation Loss: 0.4301101\n",
      "Epoch: 0181 cost = 0.383587939\n",
      "Validation Loss: 0.37219512\n",
      "Epoch: 0182 cost = 0.380915229\n",
      "Validation Loss: 0.39389977\n",
      "Epoch: 0183 cost = 0.378265134\n",
      "Validation Loss: 0.34590164\n",
      "Epoch: 0184 cost = 0.375637225\n",
      "Validation Loss: 0.29414776\n",
      "Epoch: 0185 cost = 0.373030922\n",
      "Validation Loss: 0.31800464\n",
      "Epoch: 0186 cost = 0.370446584\n",
      "Validation Loss: 0.4008831\n",
      "Epoch: 0187 cost = 0.367883516\n",
      "Validation Loss: 0.4393761\n",
      "Epoch: 0188 cost = 0.365341851\n",
      "Validation Loss: 0.42462444\n",
      "Epoch: 0189 cost = 0.362821868\n",
      "Validation Loss: 0.37907147\n",
      "Epoch: 0190 cost = 0.360322199\n",
      "Validation Loss: 0.31470782\n",
      "Epoch: 0191 cost = 0.357843224\n",
      "Validation Loss: 0.30138138\n",
      "Epoch: 0192 cost = 0.355384780\n",
      "Validation Loss: 0.4314018\n",
      "Epoch: 0193 cost = 0.352947009\n",
      "Validation Loss: 0.47750896\n",
      "Epoch: 0194 cost = 0.350528581\n",
      "Validation Loss: 0.40725958\n",
      "Epoch: 0195 cost = 0.348131095\n",
      "Validation Loss: 0.37355986\n",
      "Epoch: 0196 cost = 0.345752618\n",
      "Validation Loss: 0.35649318\n",
      "Epoch: 0197 cost = 0.343394458\n",
      "Validation Loss: 0.3437558\n",
      "Epoch: 0198 cost = 0.341054325\n",
      "Validation Loss: 0.3032058\n",
      "Epoch: 0199 cost = 0.338735389\n",
      "Validation Loss: 0.28836244\n",
      "Epoch: 0200 cost = 0.336433070\n",
      "Validation Loss: 0.30740723\n",
      "Epoch: 0201 cost = 0.334152145\n",
      "Validation Loss: 0.35435745\n",
      "Epoch: 0202 cost = 0.331887075\n",
      "Validation Loss: 0.3340311\n",
      "Epoch: 0203 cost = 0.329644284\n",
      "Validation Loss: 0.25590298\n",
      "Epoch: 0204 cost = 0.327414994\n",
      "Validation Loss: 0.28333816\n",
      "Epoch: 0205 cost = 0.325209869\n",
      "Validation Loss: 0.22589219\n",
      "Epoch: 0206 cost = 0.323014694\n",
      "Validation Loss: 0.23971292\n",
      "Epoch: 0207 cost = 0.320847430\n",
      "Validation Loss: 0.20427747\n",
      "Epoch: 0208 cost = 0.318685510\n",
      "Validation Loss: 0.26363203\n",
      "Epoch: 0209 cost = 0.316556492\n",
      "Validation Loss: 0.21306261\n",
      "Epoch: 0210 cost = 0.314425043\n",
      "Validation Loss: 0.20847264\n",
      "Epoch: 0211 cost = 0.312335504\n",
      "Validation Loss: 0.22217639\n",
      "Epoch: 0212 cost = 0.310232056\n",
      "Validation Loss: 0.21209946\n",
      "Epoch: 0213 cost = 0.308183925\n",
      "Validation Loss: 0.27749625\n",
      "Epoch: 0214 cost = 0.306104294\n",
      "Validation Loss: 0.2649254\n",
      "Epoch: 0215 cost = 0.304101654\n",
      "Validation Loss: 0.26876625\n",
      "Epoch: 0216 cost = 0.302040202\n",
      "Validation Loss: 0.24175107\n",
      "Epoch: 0217 cost = 0.300089534\n",
      "Validation Loss: 0.2064071\n",
      "Epoch: 0218 cost = 0.298038249\n",
      "Validation Loss: 0.20547496\n",
      "Epoch: 0219 cost = 0.296150412\n",
      "Validation Loss: 0.25700548\n",
      "Epoch: 0220 cost = 0.294098198\n",
      "Validation Loss: 0.23240565\n",
      "Epoch: 0221 cost = 0.292289632\n",
      "Validation Loss: 0.27446637\n",
      "Epoch: 0222 cost = 0.290223816\n",
      "Validation Loss: 0.21633391\n",
      "Epoch: 0223 cost = 0.288520362\n",
      "Validation Loss: 0.2315081\n",
      "Epoch: 0224 cost = 0.286426033\n",
      "Validation Loss: 0.17635655\n",
      "Epoch: 0225 cost = 0.284863928\n",
      "Validation Loss: 0.2641111\n",
      "Epoch: 0226 cost = 0.282731597\n",
      "Validation Loss: 0.20336938\n",
      "Epoch: 0227 cost = 0.281346947\n",
      "Validation Loss: 0.30920753\n",
      "Epoch: 0228 cost = 0.279177376\n",
      "Validation Loss: 0.25205627\n",
      "Epoch: 0229 cost = 0.277969450\n",
      "Validation Loss: 0.32802358\n",
      "Epoch: 0230 cost = 0.275770800\n",
      "Validation Loss: 0.24230617\n",
      "Epoch: 0231 cost = 0.274626396\n",
      "Validation Loss: 0.31104654\n",
      "Epoch: 0232 cost = 0.272389535\n",
      "Validation Loss: 0.17690232\n",
      "Epoch: 0233 cost = 0.271105464\n",
      "Validation Loss: 0.23418391\n",
      "Epoch: 0234 cost = 0.268832564\n",
      "Validation Loss: 0.18540233\n",
      "Epoch: 0235 cost = 0.267352658\n",
      "Validation Loss: 0.2211809\n",
      "Epoch: 0236 cost = 0.265142654\n",
      "Validation Loss: 0.1788045\n",
      "Epoch: 0237 cost = 0.263588137\n",
      "Validation Loss: 0.21290934\n",
      "Epoch: 0238 cost = 0.261542823\n",
      "Validation Loss: 0.1728775\n",
      "Epoch: 0239 cost = 0.259984244\n",
      "Validation Loss: 0.24712098\n",
      "Epoch: 0240 cost = 0.258103794\n",
      "Validation Loss: 0.21086155\n",
      "Epoch: 0241 cost = 0.256542587\n",
      "Validation Loss: 0.23050289\n",
      "Epoch: 0242 cost = 0.254781404\n",
      "Validation Loss: 0.23947829\n",
      "Epoch: 0243 cost = 0.253215287\n",
      "Validation Loss: 0.25546375\n",
      "Epoch: 0244 cost = 0.251531284\n",
      "Validation Loss: 0.31114465\n",
      "Epoch: 0245 cost = 0.249968774\n",
      "Validation Loss: 0.29510698\n",
      "Epoch: 0246 cost = 0.248336168\n",
      "Validation Loss: 0.22422916\n",
      "Epoch: 0247 cost = 0.246784593\n",
      "Validation Loss: 0.18660647\n",
      "Epoch: 0248 cost = 0.245191376\n",
      "Validation Loss: 0.16916336\n",
      "Epoch: 0249 cost = 0.243655318\n",
      "Validation Loss: 0.27421957\n",
      "Epoch: 0250 cost = 0.242095805\n",
      "Validation Loss: 0.23427433\n",
      "Epoch: 0251 cost = 0.240576757\n",
      "Validation Loss: 0.18390596\n",
      "Epoch: 0252 cost = 0.239047006\n",
      "Validation Loss: 0.20825128\n",
      "Epoch: 0253 cost = 0.237547381\n",
      "Validation Loss: 0.18409614\n",
      "Epoch: 0254 cost = 0.236044773\n",
      "Validation Loss: 0.17503242\n",
      "Epoch: 0255 cost = 0.234564745\n",
      "Validation Loss: 0.19634356\n",
      "Epoch: 0256 cost = 0.233086584\n",
      "Validation Loss: 0.22756563\n",
      "Epoch: 0257 cost = 0.231626973\n",
      "Validation Loss: 0.21397021\n",
      "Epoch: 0258 cost = 0.230171614\n",
      "Validation Loss: 0.19092825\n",
      "Epoch: 0259 cost = 0.228731805\n",
      "Validation Loss: 0.18379034\n",
      "Epoch: 0260 cost = 0.227297955\n",
      "Validation Loss: 0.16501541\n",
      "Epoch: 0261 cost = 0.225877360\n",
      "Validation Loss: 0.1798777\n",
      "Epoch: 0262 cost = 0.224463090\n",
      "Validation Loss: 0.17700079\n",
      "Epoch: 0263 cost = 0.223060442\n",
      "Validation Loss: 0.18614943\n",
      "Epoch: 0264 cost = 0.221664525\n",
      "Validation Loss: 0.21226828\n",
      "Epoch: 0265 cost = 0.220278529\n",
      "Validation Loss: 0.23845215\n",
      "Epoch: 0266 cost = 0.218899195\n",
      "Validation Loss: 0.20038511\n",
      "Epoch: 0267 cost = 0.217527754\n",
      "Validation Loss: 0.18994513\n",
      "Epoch: 0268 cost = 0.216163471\n",
      "Validation Loss: 0.18944281\n",
      "Epoch: 0269 cost = 0.214806425\n",
      "Validation Loss: 0.17080419\n",
      "Epoch: 0270 cost = 0.213456147\n",
      "Validation Loss: 0.1566681\n",
      "Epoch: 0271 cost = 0.212113312\n",
      "Validation Loss: 0.20749553\n",
      "Epoch: 0272 cost = 0.210778630\n",
      "Validation Loss: 0.18306917\n",
      "Epoch: 0273 cost = 0.209453078\n",
      "Validation Loss: 0.15372552\n",
      "Epoch: 0274 cost = 0.208137785\n",
      "Validation Loss: 0.17183028\n",
      "Epoch: 0275 cost = 0.206833616\n",
      "Validation Loss: 0.15508169\n",
      "Epoch: 0276 cost = 0.205540847\n",
      "Validation Loss: 0.1579216\n",
      "Epoch: 0277 cost = 0.204259811\n",
      "Validation Loss: 0.15587215\n",
      "Epoch: 0278 cost = 0.202989900\n",
      "Validation Loss: 0.14457853\n",
      "Epoch: 0279 cost = 0.201730679\n",
      "Validation Loss: 0.16813946\n",
      "Epoch: 0280 cost = 0.200481911\n",
      "Validation Loss: 0.14400737\n",
      "Epoch: 0281 cost = 0.199242964\n",
      "Validation Loss: 0.18264188\n",
      "Epoch: 0282 cost = 0.198014753\n",
      "Validation Loss: 0.16893409\n",
      "Epoch: 0283 cost = 0.196797865\n",
      "Validation Loss: 0.17618276\n",
      "Epoch: 0284 cost = 0.195594221\n",
      "Validation Loss: 0.19481741\n",
      "Epoch: 0285 cost = 0.194405351\n",
      "Validation Loss: 0.18505408\n",
      "Epoch: 0286 cost = 0.193232892\n",
      "Validation Loss: 0.1441454\n",
      "Epoch: 0287 cost = 0.192076949\n",
      "Validation Loss: 0.16873804\n",
      "Epoch: 0288 cost = 0.190937794\n",
      "Validation Loss: 0.21141152\n",
      "Epoch: 0289 cost = 0.189815085\n",
      "Validation Loss: 0.18734291\n",
      "Epoch: 0290 cost = 0.188708433\n",
      "Validation Loss: 0.15606812\n",
      "Epoch: 0291 cost = 0.187616446\n",
      "Validation Loss: 0.15611437\n",
      "Epoch: 0292 cost = 0.186538549\n",
      "Validation Loss: 0.15286025\n",
      "Epoch: 0293 cost = 0.185474172\n",
      "Validation Loss: 0.18227638\n",
      "Epoch: 0294 cost = 0.184422323\n",
      "Validation Loss: 0.21276084\n",
      "Epoch: 0295 cost = 0.183382394\n",
      "Validation Loss: 0.16089675\n",
      "Epoch: 0296 cost = 0.182354193\n",
      "Validation Loss: 0.14333917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0297 cost = 0.181336803\n",
      "Validation Loss: 0.16674986\n",
      "Epoch: 0298 cost = 0.180330519\n",
      "Validation Loss: 0.12897049\n",
      "Epoch: 0299 cost = 0.179334447\n",
      "Validation Loss: 0.14905226\n",
      "Epoch: 0300 cost = 0.178348490\n",
      "Validation Loss: 0.13620211\n",
      "Epoch: 0301 cost = 0.177372577\n",
      "Validation Loss: 0.13036627\n",
      "Epoch: 0302 cost = 0.176406024\n",
      "Validation Loss: 0.13494484\n",
      "Epoch: 0303 cost = 0.175448907\n",
      "Validation Loss: 0.13790295\n",
      "Epoch: 0304 cost = 0.174501123\n",
      "Validation Loss: 0.13899441\n",
      "Epoch: 0305 cost = 0.173562518\n",
      "Validation Loss: 0.16587202\n",
      "Epoch: 0306 cost = 0.172632662\n",
      "Validation Loss: 0.1725166\n",
      "Epoch: 0307 cost = 0.171711519\n",
      "Validation Loss: 0.18208444\n",
      "Epoch: 0308 cost = 0.170799145\n",
      "Validation Loss: 0.17970791\n",
      "Epoch: 0309 cost = 0.169894929\n",
      "Validation Loss: 0.14847215\n",
      "Epoch: 0310 cost = 0.168999295\n",
      "Validation Loss: 0.14017133\n",
      "Epoch: 0311 cost = 0.168111776\n",
      "Validation Loss: 0.13636804\n",
      "Epoch: 0312 cost = 0.167232407\n",
      "Validation Loss: 0.14295736\n",
      "Epoch: 0313 cost = 0.166360996\n",
      "Validation Loss: 0.13752852\n",
      "Epoch: 0314 cost = 0.165497446\n",
      "Validation Loss: 0.14114407\n",
      "Epoch: 0315 cost = 0.164641770\n",
      "Validation Loss: 0.13867414\n",
      "Epoch: 0316 cost = 0.163793462\n",
      "Validation Loss: 0.136265\n",
      "Epoch: 0317 cost = 0.162953047\n",
      "Validation Loss: 0.13795063\n",
      "Epoch: 0318 cost = 0.162120025\n",
      "Validation Loss: 0.1732792\n",
      "Epoch: 0319 cost = 0.161294115\n",
      "Validation Loss: 0.14441958\n",
      "Epoch: 0320 cost = 0.160475703\n",
      "Validation Loss: 0.12787169\n",
      "Epoch: 0321 cost = 0.159664684\n",
      "Validation Loss: 0.14364395\n",
      "Epoch: 0322 cost = 0.158860300\n",
      "Validation Loss: 0.124213725\n",
      "Epoch: 0323 cost = 0.158063092\n",
      "Validation Loss: 0.17548533\n",
      "Epoch: 0324 cost = 0.157272805\n",
      "Validation Loss: 0.18753552\n",
      "Epoch: 0325 cost = 0.156489232\n",
      "Validation Loss: 0.17964341\n",
      "Epoch: 0326 cost = 0.155712192\n",
      "Validation Loss: 0.15769416\n",
      "Epoch: 0327 cost = 0.154942014\n",
      "Validation Loss: 0.13806479\n",
      "Epoch: 0328 cost = 0.154178202\n",
      "Validation Loss: 0.13147654\n",
      "Epoch: 0329 cost = 0.153420955\n",
      "Validation Loss: 0.14323045\n",
      "Epoch: 0330 cost = 0.152669504\n",
      "Validation Loss: 0.14604974\n",
      "Epoch: 0331 cost = 0.151924291\n",
      "Validation Loss: 0.14651729\n",
      "Epoch: 0332 cost = 0.151185185\n",
      "Validation Loss: 0.14004263\n",
      "Epoch: 0333 cost = 0.150452143\n",
      "Validation Loss: 0.1541318\n",
      "Epoch: 0334 cost = 0.149724334\n",
      "Validation Loss: 0.13945669\n",
      "Epoch: 0335 cost = 0.149002324\n",
      "Validation Loss: 0.13160187\n",
      "Epoch: 0336 cost = 0.148284887\n",
      "Validation Loss: 0.12434619\n",
      "Epoch: 0337 cost = 0.147573769\n",
      "Validation Loss: 0.1204459\n",
      "Epoch: 0338 cost = 0.146866688\n",
      "Validation Loss: 0.14195205\n",
      "Epoch: 0339 cost = 0.146164792\n",
      "Validation Loss: 0.11894224\n",
      "Epoch: 0340 cost = 0.145466575\n",
      "Validation Loss: 0.13359207\n",
      "Epoch: 0341 cost = 0.144772774\n",
      "Validation Loss: 0.12242363\n",
      "Epoch: 0342 cost = 0.144082221\n",
      "Validation Loss: 0.12238712\n",
      "Epoch: 0343 cost = 0.143395460\n",
      "Validation Loss: 0.11904363\n",
      "Epoch: 0344 cost = 0.142710528\n",
      "Validation Loss: 0.14352714\n",
      "Epoch: 0345 cost = 0.142029607\n",
      "Validation Loss: 0.15655123\n",
      "Epoch: 0346 cost = 0.141348698\n",
      "Validation Loss: 0.14402792\n",
      "Epoch: 0347 cost = 0.140672675\n",
      "Validation Loss: 0.13608666\n",
      "Epoch: 0348 cost = 0.139995630\n",
      "Validation Loss: 0.14054663\n",
      "Epoch: 0349 cost = 0.139326572\n",
      "Validation Loss: 0.13861938\n",
      "Epoch: 0350 cost = 0.138656565\n",
      "Validation Loss: 0.12246666\n",
      "Epoch: 0351 cost = 0.138000935\n",
      "Validation Loss: 0.11452568\n",
      "Epoch: 0352 cost = 0.137344488\n",
      "Validation Loss: 0.12283206\n",
      "Epoch: 0353 cost = 0.136710187\n",
      "Validation Loss: 0.12236272\n",
      "Epoch: 0354 cost = 0.136071281\n",
      "Validation Loss: 0.12397313\n",
      "Epoch: 0355 cost = 0.135463348\n",
      "Validation Loss: 0.11358628\n",
      "Epoch: 0356 cost = 0.134839162\n",
      "Validation Loss: 0.12762287\n",
      "Epoch: 0357 cost = 0.134258736\n",
      "Validation Loss: 0.123842165\n",
      "Epoch: 0358 cost = 0.133642339\n",
      "Validation Loss: 0.12201412\n",
      "Epoch: 0359 cost = 0.133092119\n",
      "Validation Loss: 0.11391025\n",
      "Epoch: 0360 cost = 0.132473134\n",
      "Validation Loss: 0.11467487\n",
      "Epoch: 0361 cost = 0.131961157\n",
      "Validation Loss: 0.11625089\n",
      "Epoch: 0362 cost = 0.131324127\n",
      "Validation Loss: 0.11610065\n",
      "Epoch: 0363 cost = 0.130867080\n",
      "Validation Loss: 0.112585984\n",
      "Epoch: 0364 cost = 0.130186114\n",
      "Validation Loss: 0.13839984\n",
      "Epoch: 0365 cost = 0.129817816\n",
      "Validation Loss: 0.11424136\n",
      "Epoch: 0366 cost = 0.129049974\n",
      "Validation Loss: 0.11064673\n",
      "Epoch: 0367 cost = 0.128834829\n",
      "Validation Loss: 0.11714539\n",
      "Epoch: 0368 cost = 0.127909813\n",
      "Validation Loss: 0.11466038\n",
      "Epoch: 0369 cost = 0.127973072\n",
      "Validation Loss: 0.13960764\n",
      "Epoch: 0370 cost = 0.126781598\n",
      "Validation Loss: 0.13902274\n",
      "Epoch: 0371 cost = 0.127369003\n",
      "Validation Loss: 0.11158015\n",
      "Epoch: 0372 cost = 0.125785238\n",
      "Validation Loss: 0.14689995\n",
      "Epoch: 0373 cost = 0.127394014\n",
      "Validation Loss: 0.11722599\n",
      "Epoch: 0374 cost = 0.125425801\n",
      "Validation Loss: 0.20781407\n",
      "Epoch: 0375 cost = 0.128921384\n",
      "Validation Loss: 0.11712267\n",
      "Epoch: 0376 cost = 0.126979269\n",
      "Validation Loss: 0.177251\n",
      "Epoch: 0377 cost = 0.132499956\n",
      "Validation Loss: 0.13579471\n",
      "Epoch: 0378 cost = 0.128990404\n",
      "Validation Loss: 0.15934657\n",
      "Epoch: 0379 cost = 0.133943737\n",
      "Validation Loss: 0.13936156\n",
      "Epoch: 0380 cost = 0.126168514\n",
      "Validation Loss: 0.17036359\n",
      "Epoch: 0381 cost = 0.127172707\n",
      "Validation Loss: 0.10744591\n",
      "Epoch: 0382 cost = 0.122184362\n",
      "Validation Loss: 0.16819979\n",
      "Epoch: 0383 cost = 0.123224487\n",
      "Validation Loss: 0.09703743\n",
      "Epoch: 0384 cost = 0.120135001\n",
      "Validation Loss: 0.15503183\n",
      "Epoch: 0385 cost = 0.121527082\n",
      "Validation Loss: 0.095216446\n",
      "Epoch: 0386 cost = 0.118947901\n",
      "Validation Loss: 0.16276662\n",
      "Epoch: 0387 cost = 0.120476660\n",
      "Validation Loss: 0.10231005\n",
      "Epoch: 0388 cost = 0.117976992\n",
      "Validation Loss: 0.11062587\n",
      "Epoch: 0389 cost = 0.119412440\n",
      "Validation Loss: 0.09699621\n",
      "Epoch: 0390 cost = 0.116983102\n",
      "Validation Loss: 0.14164744\n",
      "Epoch: 0391 cost = 0.118262854\n",
      "Validation Loss: 0.102594644\n",
      "Epoch: 0392 cost = 0.115978437\n",
      "Validation Loss: 0.16383603\n",
      "Epoch: 0393 cost = 0.117135055\n",
      "Validation Loss: 0.12197468\n",
      "Epoch: 0394 cost = 0.115006983\n",
      "Validation Loss: 0.15378122\n",
      "Epoch: 0395 cost = 0.116071986\n",
      "Validation Loss: 0.104298644\n",
      "Epoch: 0396 cost = 0.114079349\n",
      "Validation Loss: 0.1100584\n",
      "Epoch: 0397 cost = 0.115067873\n",
      "Validation Loss: 0.10382873\n",
      "Epoch: 0398 cost = 0.113188417\n",
      "Validation Loss: 0.12716271\n",
      "Epoch: 0399 cost = 0.114110483\n",
      "Validation Loss: 0.099613525\n",
      "Epoch: 0400 cost = 0.112328032\n",
      "Validation Loss: 0.121485345\n",
      "Epoch: 0401 cost = 0.113192474\n",
      "Validation Loss: 0.09576079\n",
      "Epoch: 0402 cost = 0.111493482\n",
      "Validation Loss: 0.11020123\n",
      "Epoch: 0403 cost = 0.112308790\n",
      "Validation Loss: 0.0991375\n",
      "Epoch: 0404 cost = 0.110681317\n",
      "Validation Loss: 0.12192441\n",
      "Epoch: 0405 cost = 0.111455646\n",
      "Validation Loss: 0.09433323\n",
      "Epoch: 0406 cost = 0.109888907\n",
      "Validation Loss: 0.15462895\n",
      "Epoch: 0407 cost = 0.110629510\n",
      "Validation Loss: 0.09622043\n",
      "Epoch: 0408 cost = 0.109113685\n",
      "Validation Loss: 0.09556154\n",
      "Epoch: 0409 cost = 0.109827615\n",
      "Validation Loss: 0.089925036\n",
      "Epoch: 0410 cost = 0.108354069\n",
      "Validation Loss: 0.13502258\n",
      "Epoch: 0411 cost = 0.109046640\n",
      "Validation Loss: 0.09746675\n",
      "Epoch: 0412 cost = 0.107608282\n",
      "Validation Loss: 0.10312677\n",
      "Epoch: 0413 cost = 0.108284681\n",
      "Validation Loss: 0.10688774\n",
      "Epoch: 0414 cost = 0.106874907\n",
      "Validation Loss: 0.12392547\n",
      "Epoch: 0415 cost = 0.107539379\n",
      "Validation Loss: 0.11839249\n",
      "Epoch: 0416 cost = 0.106153165\n",
      "Validation Loss: 0.12266239\n",
      "Epoch: 0417 cost = 0.106809660\n",
      "Validation Loss: 0.09232427\n",
      "Epoch: 0418 cost = 0.105442145\n",
      "Validation Loss: 0.09697149\n",
      "Epoch: 0419 cost = 0.106093570\n",
      "Validation Loss: 0.09185272\n",
      "Epoch: 0420 cost = 0.104741242\n",
      "Validation Loss: 0.098169215\n",
      "Epoch: 0421 cost = 0.105390407\n",
      "Validation Loss: 0.098246306\n",
      "Epoch: 0422 cost = 0.104049464\n",
      "Validation Loss: 0.09830533\n",
      "Epoch: 0423 cost = 0.104699723\n",
      "Validation Loss: 0.10589427\n",
      "Epoch: 0424 cost = 0.103366918\n",
      "Validation Loss: 0.10189034\n",
      "Epoch: 0425 cost = 0.104020171\n",
      "Validation Loss: 0.097416855\n",
      "Epoch: 0426 cost = 0.102692881\n",
      "Validation Loss: 0.096209034\n",
      "Epoch: 0427 cost = 0.103351445\n",
      "Validation Loss: 0.086981006\n",
      "Epoch: 0428 cost = 0.102027004\n",
      "Validation Loss: 0.1099643\n",
      "Epoch: 0429 cost = 0.102692995\n",
      "Validation Loss: 0.0863282\n",
      "Epoch: 0430 cost = 0.101368966\n",
      "Validation Loss: 0.102531366\n",
      "Epoch: 0431 cost = 0.102044343\n",
      "Validation Loss: 0.09028164\n",
      "Epoch: 0432 cost = 0.100718507\n",
      "Validation Loss: 0.11337915\n",
      "Epoch: 0433 cost = 0.101404788\n",
      "Validation Loss: 0.08783578\n",
      "Epoch: 0434 cost = 0.100075118\n",
      "Validation Loss: 0.09702031\n",
      "Epoch: 0435 cost = 0.100774234\n",
      "Validation Loss: 0.08645455\n",
      "Epoch: 0436 cost = 0.099438940\n",
      "Validation Loss: 0.09572647\n",
      "Epoch: 0437 cost = 0.100152107\n",
      "Validation Loss: 0.077299654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0438 cost = 0.098809350\n",
      "Validation Loss: 0.0952519\n",
      "Epoch: 0439 cost = 0.099538411\n",
      "Validation Loss: 0.09328842\n",
      "Epoch: 0440 cost = 0.098186277\n",
      "Validation Loss: 0.087892294\n",
      "Epoch: 0441 cost = 0.098932534\n",
      "Validation Loss: 0.08885803\n",
      "Epoch: 0442 cost = 0.097569643\n",
      "Validation Loss: 0.11665178\n",
      "Epoch: 0443 cost = 0.098334184\n",
      "Validation Loss: 0.08808568\n",
      "Epoch: 0444 cost = 0.096959136\n",
      "Validation Loss: 0.091255605\n",
      "Epoch: 0445 cost = 0.097742854\n",
      "Validation Loss: 0.07910977\n",
      "Epoch: 0446 cost = 0.096354556\n",
      "Validation Loss: 0.08678697\n",
      "Epoch: 0447 cost = 0.097158613\n",
      "Validation Loss: 0.07547068\n",
      "Epoch: 0448 cost = 0.095755569\n",
      "Validation Loss: 0.10675319\n",
      "Epoch: 0449 cost = 0.096581116\n",
      "Validation Loss: 0.08497336\n",
      "Epoch: 0450 cost = 0.095162043\n",
      "Validation Loss: 0.098439485\n",
      "Epoch: 0451 cost = 0.096010150\n",
      "Validation Loss: 0.08767751\n",
      "Epoch: 0452 cost = 0.094574096\n",
      "Validation Loss: 0.0985533\n",
      "Epoch: 0453 cost = 0.095445207\n",
      "Validation Loss: 0.08140134\n",
      "Epoch: 0454 cost = 0.093991186\n",
      "Validation Loss: 0.10078776\n",
      "Epoch: 0455 cost = 0.094886464\n",
      "Validation Loss: 0.081517816\n",
      "Epoch: 0456 cost = 0.093413486\n",
      "Validation Loss: 0.09238657\n",
      "Epoch: 0457 cost = 0.094333511\n",
      "Validation Loss: 0.08878879\n",
      "Epoch: 0458 cost = 0.092840622\n",
      "Validation Loss: 0.117625\n",
      "Epoch: 0459 cost = 0.093786327\n",
      "Validation Loss: 0.1069352\n",
      "Epoch: 0460 cost = 0.092272460\n",
      "Validation Loss: 0.13877305\n",
      "Epoch: 0461 cost = 0.093244265\n",
      "Validation Loss: 0.08298155\n",
      "Epoch: 0462 cost = 0.091709012\n",
      "Validation Loss: 0.09804662\n",
      "Epoch: 0463 cost = 0.092707020\n",
      "Validation Loss: 0.08367913\n",
      "Epoch: 0464 cost = 0.091150258\n",
      "Validation Loss: 0.09587708\n",
      "Epoch: 0465 cost = 0.092173908\n",
      "Validation Loss: 0.085853286\n",
      "Epoch: 0466 cost = 0.090595234\n",
      "Validation Loss: 0.12693751\n",
      "Epoch: 0467 cost = 0.091644084\n",
      "Validation Loss: 0.09908257\n",
      "Epoch: 0468 cost = 0.090044528\n",
      "Validation Loss: 0.13080657\n",
      "Epoch: 0469 cost = 0.091116840\n",
      "Validation Loss: 0.107720695\n",
      "Epoch: 0470 cost = 0.089497631\n",
      "Validation Loss: 0.1345096\n",
      "Epoch: 0471 cost = 0.090591576\n",
      "Validation Loss: 0.087546535\n",
      "Epoch: 0472 cost = 0.088953833\n",
      "Validation Loss: 0.094180964\n",
      "Epoch: 0473 cost = 0.090067637\n",
      "Validation Loss: 0.09059873\n",
      "Epoch: 0474 cost = 0.088413583\n",
      "Validation Loss: 0.12343245\n",
      "Epoch: 0475 cost = 0.089544567\n",
      "Validation Loss: 0.09573266\n",
      "Epoch: 0476 cost = 0.087876188\n",
      "Validation Loss: 0.13733006\n",
      "Epoch: 0477 cost = 0.089022465\n",
      "Validation Loss: 0.098738186\n",
      "Epoch: 0478 cost = 0.087341734\n",
      "Validation Loss: 0.10156781\n",
      "Epoch: 0479 cost = 0.088501088\n",
      "Validation Loss: 0.07320716\n",
      "Epoch: 0480 cost = 0.086809538\n",
      "Validation Loss: 0.104871\n",
      "Epoch: 0481 cost = 0.087980717\n",
      "Validation Loss: 0.0823249\n",
      "Epoch: 0482 cost = 0.086280213\n",
      "Validation Loss: 0.08678934\n",
      "Epoch: 0483 cost = 0.087461560\n",
      "Validation Loss: 0.08282467\n",
      "Epoch: 0484 cost = 0.085753259\n",
      "Validation Loss: 0.0928967\n",
      "Epoch: 0485 cost = 0.086944064\n",
      "Validation Loss: 0.0755555\n",
      "Epoch: 0486 cost = 0.085228374\n",
      "Validation Loss: 0.08987174\n",
      "Epoch: 0487 cost = 0.086428088\n",
      "Validation Loss: 0.08929723\n",
      "Epoch: 0488 cost = 0.084705955\n",
      "Validation Loss: 0.10495511\n",
      "Epoch: 0489 cost = 0.085913835\n",
      "Validation Loss: 0.07417415\n",
      "Epoch: 0490 cost = 0.084185345\n",
      "Validation Loss: 0.069612294\n",
      "Epoch: 0491 cost = 0.085401776\n",
      "Validation Loss: 0.08919198\n",
      "Epoch: 0492 cost = 0.083666416\n",
      "Validation Loss: 0.087513156\n",
      "Epoch: 0493 cost = 0.084890954\n",
      "Validation Loss: 0.067917265\n",
      "Epoch: 0494 cost = 0.083149776\n",
      "Validation Loss: 0.08748392\n",
      "Epoch: 0495 cost = 0.084382469\n",
      "Validation Loss: 0.069262944\n",
      "Epoch: 0496 cost = 0.082634465\n",
      "Validation Loss: 0.082885586\n",
      "Epoch: 0497 cost = 0.083876038\n",
      "Validation Loss: 0.07626957\n",
      "Epoch: 0498 cost = 0.082120587\n",
      "Validation Loss: 0.10504661\n",
      "Epoch: 0499 cost = 0.083371360\n",
      "Validation Loss: 0.081696555\n",
      "Epoch: 0500 cost = 0.081608833\n",
      "Validation Loss: 0.09728288\n",
      "Epoch: 0501 cost = 0.082868833\n",
      "Validation Loss: 0.08150459\n",
      "Epoch: 0502 cost = 0.081098067\n",
      "Validation Loss: 0.09604063\n",
      "Epoch: 0503 cost = 0.082368784\n",
      "Validation Loss: 0.07754933\n",
      "Epoch: 0504 cost = 0.080589372\n",
      "Validation Loss: 0.08841579\n",
      "Epoch: 0505 cost = 0.081871005\n",
      "Validation Loss: 0.082824096\n",
      "Epoch: 0506 cost = 0.080082387\n",
      "Validation Loss: 0.11753082\n",
      "Epoch: 0507 cost = 0.081375756\n",
      "Validation Loss: 0.085982665\n",
      "Epoch: 0508 cost = 0.079577171\n",
      "Validation Loss: 0.08549812\n",
      "Epoch: 0509 cost = 0.080883471\n",
      "Validation Loss: 0.07508904\n",
      "Epoch: 0510 cost = 0.079074022\n",
      "Validation Loss: 0.07651063\n",
      "Epoch: 0511 cost = 0.080394314\n",
      "Validation Loss: 0.08344063\n",
      "Epoch: 0512 cost = 0.078573419\n",
      "Validation Loss: 0.084863335\n",
      "Epoch: 0513 cost = 0.079908438\n",
      "Validation Loss: 0.07858298\n",
      "Epoch: 0514 cost = 0.078075375\n",
      "Validation Loss: 0.07219143\n",
      "Epoch: 0515 cost = 0.079425991\n",
      "Validation Loss: 0.07888404\n",
      "Epoch: 0516 cost = 0.077579875\n",
      "Validation Loss: 0.084518686\n",
      "Epoch: 0517 cost = 0.078946787\n",
      "Validation Loss: 0.07856252\n",
      "Epoch: 0518 cost = 0.077087824\n",
      "Validation Loss: 0.07714886\n",
      "Epoch: 0519 cost = 0.078471176\n",
      "Validation Loss: 0.06683711\n",
      "Epoch: 0520 cost = 0.076598451\n",
      "Validation Loss: 0.08132457\n",
      "Epoch: 0521 cost = 0.077998418\n",
      "Validation Loss: 0.064638466\n",
      "Epoch: 0522 cost = 0.076112644\n",
      "Validation Loss: 0.095426865\n",
      "Epoch: 0523 cost = 0.077528626\n",
      "Validation Loss: 0.07565071\n",
      "Epoch: 0524 cost = 0.075630217\n",
      "Validation Loss: 0.08481412\n",
      "Epoch: 0525 cost = 0.077060905\n",
      "Validation Loss: 0.07986465\n",
      "Epoch: 0526 cost = 0.075151209\n",
      "Validation Loss: 0.07131405\n",
      "Epoch: 0527 cost = 0.076594369\n",
      "Validation Loss: 0.07373126\n",
      "Epoch: 0528 cost = 0.074675375\n",
      "Validation Loss: 0.07622578\n",
      "Epoch: 0529 cost = 0.076128191\n",
      "Validation Loss: 0.07159141\n",
      "Epoch: 0530 cost = 0.074202562\n",
      "Validation Loss: 0.07459798\n",
      "Epoch: 0531 cost = 0.075662021\n",
      "Validation Loss: 0.06902298\n",
      "Epoch: 0532 cost = 0.073732715\n",
      "Validation Loss: 0.09025252\n",
      "Epoch: 0533 cost = 0.075194991\n",
      "Validation Loss: 0.09221211\n",
      "Epoch: 0534 cost = 0.073265609\n",
      "Validation Loss: 0.109775215\n",
      "Epoch: 0535 cost = 0.074727519\n",
      "Validation Loss: 0.08899092\n",
      "Epoch: 0536 cost = 0.072801314\n",
      "Validation Loss: 0.10468263\n",
      "Epoch: 0537 cost = 0.074258581\n",
      "Validation Loss: 0.07545351\n",
      "Epoch: 0538 cost = 0.072339509\n",
      "Validation Loss: 0.09262965\n",
      "Epoch: 0539 cost = 0.073789457\n",
      "Validation Loss: 0.06396729\n",
      "Epoch: 0540 cost = 0.071880503\n",
      "Validation Loss: 0.08780211\n",
      "Epoch: 0541 cost = 0.073319690\n",
      "Validation Loss: 0.061727747\n",
      "Epoch: 0542 cost = 0.071424091\n",
      "Validation Loss: 0.07463121\n",
      "Epoch: 0543 cost = 0.072850054\n",
      "Validation Loss: 0.08923719\n",
      "Epoch: 0544 cost = 0.070970295\n",
      "Validation Loss: 0.086511396\n",
      "Epoch: 0545 cost = 0.072380716\n",
      "Validation Loss: 0.06888699\n",
      "Epoch: 0546 cost = 0.070519456\n",
      "Validation Loss: 0.07828668\n",
      "Epoch: 0547 cost = 0.071911867\n",
      "Validation Loss: 0.07897807\n",
      "Epoch: 0548 cost = 0.070071051\n",
      "Validation Loss: 0.06702531\n",
      "Epoch: 0549 cost = 0.071443655\n",
      "Validation Loss: 0.068144865\n",
      "Epoch: 0550 cost = 0.069624687\n",
      "Validation Loss: 0.06997032\n",
      "Epoch: 0551 cost = 0.070976433\n",
      "Validation Loss: 0.062474802\n",
      "Epoch: 0552 cost = 0.069180674\n",
      "Validation Loss: 0.059955884\n",
      "Epoch: 0553 cost = 0.070509359\n",
      "Validation Loss: 0.10707173\n",
      "Epoch: 0554 cost = 0.068738348\n",
      "Validation Loss: 0.07439181\n",
      "Epoch: 0555 cost = 0.070042701\n",
      "Validation Loss: 0.06047491\n",
      "Epoch: 0556 cost = 0.068297213\n",
      "Validation Loss: 0.10945136\n",
      "Epoch: 0557 cost = 0.069576144\n",
      "Validation Loss: 0.06743515\n",
      "Epoch: 0558 cost = 0.067857137\n",
      "Validation Loss: 0.06732223\n",
      "Epoch: 0559 cost = 0.069109072\n",
      "Validation Loss: 0.06953767\n",
      "Epoch: 0560 cost = 0.067417097\n",
      "Validation Loss: 0.06307357\n",
      "Epoch: 0561 cost = 0.068641201\n",
      "Validation Loss: 0.0770592\n",
      "Epoch: 0562 cost = 0.066977337\n",
      "Validation Loss: 0.07370837\n",
      "Epoch: 0563 cost = 0.068172483\n",
      "Validation Loss: 0.09467312\n",
      "Epoch: 0564 cost = 0.066537446\n",
      "Validation Loss: 0.090790205\n",
      "Epoch: 0565 cost = 0.067702767\n",
      "Validation Loss: 0.0888299\n",
      "Epoch: 0566 cost = 0.066097156\n",
      "Validation Loss: 0.069392845\n",
      "Epoch: 0567 cost = 0.067232451\n",
      "Validation Loss: 0.076992676\n",
      "Epoch: 0568 cost = 0.065657474\n",
      "Validation Loss: 0.065600224\n",
      "Epoch: 0569 cost = 0.066762858\n",
      "Validation Loss: 0.079225644\n",
      "Epoch: 0570 cost = 0.065219471\n",
      "Validation Loss: 0.08793648\n",
      "Epoch: 0571 cost = 0.066295187\n",
      "Validation Loss: 0.06759278\n",
      "Epoch: 0572 cost = 0.064784708\n",
      "Validation Loss: 0.073447175\n",
      "Epoch: 0573 cost = 0.065831049\n",
      "Validation Loss: 0.05797835\n",
      "Epoch: 0574 cost = 0.064354213\n",
      "Validation Loss: 0.07729187\n",
      "Epoch: 0575 cost = 0.065371296\n",
      "Validation Loss: 0.06469987\n",
      "Epoch: 0576 cost = 0.063928655\n",
      "Validation Loss: 0.08094408\n",
      "Epoch: 0577 cost = 0.064915313\n",
      "Validation Loss: 0.08279755\n",
      "Epoch: 0578 cost = 0.063507316\n",
      "Validation Loss: 0.05767177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0579 cost = 0.064462357\n",
      "Validation Loss: 0.064053066\n",
      "Epoch: 0580 cost = 0.063089115\n",
      "Validation Loss: 0.0625979\n",
      "Epoch: 0581 cost = 0.064010764\n",
      "Validation Loss: 0.060268722\n",
      "Epoch: 0582 cost = 0.062671959\n",
      "Validation Loss: 0.080543764\n",
      "Epoch: 0583 cost = 0.063558896\n",
      "Validation Loss: 0.05622928\n",
      "Epoch: 0584 cost = 0.062255388\n",
      "Validation Loss: 0.08727768\n",
      "Epoch: 0585 cost = 0.063105603\n",
      "Validation Loss: 0.05893024\n",
      "Epoch: 0586 cost = 0.061837254\n",
      "Validation Loss: 0.055485576\n",
      "Epoch: 0587 cost = 0.062649118\n",
      "Validation Loss: 0.06247819\n",
      "Epoch: 0588 cost = 0.061416688\n",
      "Validation Loss: 0.06353625\n",
      "Epoch: 0589 cost = 0.062188564\n",
      "Validation Loss: 0.070001625\n",
      "Epoch: 0590 cost = 0.060992319\n",
      "Validation Loss: 0.07001673\n",
      "Epoch: 0591 cost = 0.061722081\n",
      "Validation Loss: 0.057865698\n",
      "Epoch: 0592 cost = 0.060563274\n",
      "Validation Loss: 0.059112377\n",
      "Epoch: 0593 cost = 0.061247984\n",
      "Validation Loss: 0.052014787\n",
      "Epoch: 0594 cost = 0.060126983\n",
      "Validation Loss: 0.075208366\n",
      "Epoch: 0595 cost = 0.060765511\n",
      "Validation Loss: 0.055174652\n",
      "Epoch: 0596 cost = 0.059683375\n",
      "Validation Loss: 0.05400517\n",
      "Epoch: 0597 cost = 0.060271545\n",
      "Validation Loss: 0.0529377\n",
      "Epoch: 0598 cost = 0.059229262\n",
      "Validation Loss: 0.062327877\n",
      "Epoch: 0599 cost = 0.059764080\n",
      "Validation Loss: 0.056274258\n",
      "Epoch: 0600 cost = 0.058763372\n",
      "Validation Loss: 0.07022518\n",
      "Epoch: 0601 cost = 0.059240780\n",
      "Validation Loss: 0.07285686\n",
      "Epoch: 0602 cost = 0.058283319\n",
      "Validation Loss: 0.08835826\n",
      "Epoch: 0603 cost = 0.058699690\n",
      "Validation Loss: 0.05962374\n",
      "Epoch: 0604 cost = 0.057789394\n",
      "Validation Loss: 0.062727965\n",
      "Epoch: 0605 cost = 0.058139925\n",
      "Validation Loss: 0.066512674\n",
      "Epoch: 0606 cost = 0.057284032\n",
      "Validation Loss: 0.049418226\n",
      "Epoch: 0607 cost = 0.057564118\n",
      "Validation Loss: 0.06361321\n",
      "Epoch: 0608 cost = 0.056772902\n",
      "Validation Loss: 0.057805154\n",
      "Epoch: 0609 cost = 0.056980928\n",
      "Validation Loss: 0.058600426\n",
      "Epoch: 0610 cost = 0.056264062\n",
      "Validation Loss: 0.06480442\n",
      "Epoch: 0611 cost = 0.056404536\n",
      "Validation Loss: 0.0657092\n",
      "Epoch: 0612 cost = 0.055762988\n",
      "Validation Loss: 0.07390906\n",
      "Epoch: 0613 cost = 0.055845656\n",
      "Validation Loss: 0.057730474\n",
      "Epoch: 0614 cost = 0.055269766\n",
      "Validation Loss: 0.06479655\n",
      "Epoch: 0615 cost = 0.055306845\n",
      "Validation Loss: 0.054162785\n",
      "Epoch: 0616 cost = 0.054783011\n",
      "Validation Loss: 0.06130971\n",
      "Epoch: 0617 cost = 0.054784194\n",
      "Validation Loss: 0.05816762\n",
      "Epoch: 0618 cost = 0.054301658\n",
      "Validation Loss: 0.070442736\n",
      "Epoch: 0619 cost = 0.054271352\n",
      "Validation Loss: 0.0590612\n",
      "Epoch: 0620 cost = 0.053822922\n",
      "Validation Loss: 0.05231445\n",
      "Epoch: 0621 cost = 0.053764121\n",
      "Validation Loss: 0.043997392\n",
      "Epoch: 0622 cost = 0.053346197\n",
      "Validation Loss: 0.069556415\n",
      "Epoch: 0623 cost = 0.053259018\n",
      "Validation Loss: 0.05127182\n",
      "Epoch: 0624 cost = 0.052869313\n",
      "Validation Loss: 0.05398744\n",
      "Epoch: 0625 cost = 0.052753584\n",
      "Validation Loss: 0.061802953\n",
      "Epoch: 0626 cost = 0.052389598\n",
      "Validation Loss: 0.057019737\n",
      "Epoch: 0627 cost = 0.052245434\n",
      "Validation Loss: 0.04979404\n",
      "Epoch: 0628 cost = 0.051903683\n",
      "Validation Loss: 0.060687993\n",
      "Epoch: 0629 cost = 0.051731740\n",
      "Validation Loss: 0.06458357\n",
      "Epoch: 0630 cost = 0.051407133\n",
      "Validation Loss: 0.0666808\n",
      "Epoch: 0631 cost = 0.051208951\n",
      "Validation Loss: 0.055627454\n",
      "Epoch: 0632 cost = 0.050893002\n",
      "Validation Loss: 0.053726215\n",
      "Epoch: 0633 cost = 0.050670127\n",
      "Validation Loss: 0.056209367\n",
      "Epoch: 0634 cost = 0.050354886\n",
      "Validation Loss: 0.062001\n",
      "Epoch: 0635 cost = 0.050108977\n",
      "Validation Loss: 0.055510573\n",
      "Epoch: 0636 cost = 0.049792702\n",
      "Validation Loss: 0.059884626\n",
      "Epoch: 0637 cost = 0.049525649\n",
      "Validation Loss: 0.06315917\n",
      "Epoch: 0638 cost = 0.049219998\n",
      "Validation Loss: 0.04943001\n",
      "Epoch: 0639 cost = 0.048931736\n",
      "Validation Loss: 0.057020552\n",
      "Epoch: 0640 cost = 0.048652378\n",
      "Validation Loss: 0.08763759\n",
      "Epoch: 0641 cost = 0.048340764\n",
      "Validation Loss: 0.09267441\n",
      "Epoch: 0642 cost = 0.048093588\n",
      "Validation Loss: 0.06115376\n",
      "Epoch: 0643 cost = 0.047761725\n",
      "Validation Loss: 0.0412618\n",
      "Epoch: 0644 cost = 0.047539229\n",
      "Validation Loss: 0.07286964\n",
      "Epoch: 0645 cost = 0.047201722\n",
      "Validation Loss: 0.05404298\n",
      "Epoch: 0646 cost = 0.046989195\n",
      "Validation Loss: 0.070141986\n",
      "Epoch: 0647 cost = 0.046663904\n",
      "Validation Loss: 0.085252516\n",
      "Epoch: 0648 cost = 0.046449200\n",
      "Validation Loss: 0.0800514\n",
      "Epoch: 0649 cost = 0.046147650\n",
      "Validation Loss: 0.054839984\n",
      "Epoch: 0650 cost = 0.045925612\n",
      "Validation Loss: 0.038021006\n",
      "Epoch: 0651 cost = 0.045650811\n",
      "Validation Loss: 0.058058295\n",
      "Epoch: 0652 cost = 0.045422531\n",
      "Validation Loss: 0.045196418\n",
      "Epoch: 0653 cost = 0.045170442\n",
      "Validation Loss: 0.053245664\n",
      "Epoch: 0654 cost = 0.044940732\n",
      "Validation Loss: 0.048056003\n",
      "Epoch: 0655 cost = 0.044705542\n",
      "Validation Loss: 0.056811273\n",
      "Epoch: 0656 cost = 0.044479150\n",
      "Validation Loss: 0.05982355\n",
      "Epoch: 0657 cost = 0.044256224\n",
      "Validation Loss: 0.056421153\n",
      "Epoch: 0658 cost = 0.044035023\n",
      "Validation Loss: 0.052213773\n",
      "Epoch: 0659 cost = 0.043820204\n",
      "Validation Loss: 0.043760445\n",
      "Epoch: 0660 cost = 0.043606075\n",
      "Validation Loss: 0.046920408\n",
      "Epoch: 0661 cost = 0.043397567\n",
      "Validation Loss: 0.047632813\n",
      "Epoch: 0662 cost = 0.043190083\n",
      "Validation Loss: 0.059391923\n",
      "Epoch: 0663 cost = 0.042987041\n",
      "Validation Loss: 0.06690062\n",
      "Epoch: 0664 cost = 0.042785653\n",
      "Validation Loss: 0.061015055\n",
      "Epoch: 0665 cost = 0.042588173\n",
      "Validation Loss: 0.057797085\n",
      "Epoch: 0666 cost = 0.042393557\n",
      "Validation Loss: 0.068203285\n",
      "Epoch: 0667 cost = 0.042201848\n",
      "Validation Loss: 0.08958414\n",
      "Epoch: 0668 cost = 0.042013588\n",
      "Validation Loss: 0.07038341\n",
      "Epoch: 0669 cost = 0.041828002\n",
      "Validation Loss: 0.0611202\n",
      "Epoch: 0670 cost = 0.041645892\n",
      "Validation Loss: 0.05387811\n",
      "Epoch: 0671 cost = 0.041467370\n",
      "Validation Loss: 0.0521756\n",
      "Epoch: 0672 cost = 0.041291108\n",
      "Validation Loss: 0.056072116\n",
      "Epoch: 0673 cost = 0.041118379\n",
      "Validation Loss: 0.048983116\n",
      "Epoch: 0674 cost = 0.040948646\n",
      "Validation Loss: 0.04970906\n",
      "Epoch: 0675 cost = 0.040781170\n",
      "Validation Loss: 0.041796997\n",
      "Epoch: 0676 cost = 0.040616288\n",
      "Validation Loss: 0.03402446\n",
      "Epoch: 0677 cost = 0.040453589\n",
      "Validation Loss: 0.067580074\n",
      "Epoch: 0678 cost = 0.040293707\n",
      "Validation Loss: 0.07281604\n",
      "Epoch: 0679 cost = 0.040135054\n",
      "Validation Loss: 0.06187527\n",
      "Epoch: 0680 cost = 0.039978554\n",
      "Validation Loss: 0.056602422\n",
      "Epoch: 0681 cost = 0.039823445\n",
      "Validation Loss: 0.04926743\n",
      "Epoch: 0682 cost = 0.039670084\n",
      "Validation Loss: 0.046923816\n",
      "Epoch: 0683 cost = 0.039517766\n",
      "Validation Loss: 0.056512352\n",
      "Epoch: 0684 cost = 0.039367176\n",
      "Validation Loss: 0.0396421\n",
      "Epoch: 0685 cost = 0.039217649\n",
      "Validation Loss: 0.032559883\n",
      "Epoch: 0686 cost = 0.039069819\n",
      "Validation Loss: 0.050503634\n",
      "Epoch: 0687 cost = 0.038923008\n",
      "Validation Loss: 0.045787886\n",
      "Epoch: 0688 cost = 0.038778212\n",
      "Validation Loss: 0.042325966\n",
      "Epoch: 0689 cost = 0.038634851\n",
      "Validation Loss: 0.042332225\n",
      "Epoch: 0690 cost = 0.038493256\n",
      "Validation Loss: 0.048077658\n",
      "Epoch: 0691 cost = 0.038353942\n",
      "Validation Loss: 0.06526919\n",
      "Epoch: 0692 cost = 0.038216290\n",
      "Validation Loss: 0.064483024\n",
      "Epoch: 0693 cost = 0.038080829\n",
      "Validation Loss: 0.055308692\n",
      "Epoch: 0694 cost = 0.037947298\n",
      "Validation Loss: 0.05521875\n",
      "Epoch: 0695 cost = 0.037815727\n",
      "Validation Loss: 0.06237778\n",
      "Epoch: 0696 cost = 0.037686441\n",
      "Validation Loss: 0.046589445\n",
      "Epoch: 0697 cost = 0.037558286\n",
      "Validation Loss: 0.04281308\n",
      "Epoch: 0698 cost = 0.037431961\n",
      "Validation Loss: 0.059419632\n",
      "Epoch: 0699 cost = 0.037307093\n",
      "Validation Loss: 0.06174947\n",
      "Epoch: 0700 cost = 0.037183129\n",
      "Validation Loss: 0.064887606\n",
      "Epoch: 0701 cost = 0.037060561\n",
      "Validation Loss: 0.052887723\n",
      "Epoch: 0702 cost = 0.036938392\n",
      "Validation Loss: 0.046507858\n",
      "Epoch: 0703 cost = 0.036817829\n",
      "Validation Loss: 0.04473239\n",
      "Epoch: 0704 cost = 0.036697512\n",
      "Validation Loss: 0.05014196\n",
      "Epoch: 0705 cost = 0.036577344\n",
      "Validation Loss: 0.05839891\n",
      "Epoch: 0706 cost = 0.036458259\n",
      "Validation Loss: 0.05926835\n",
      "Epoch: 0707 cost = 0.036338775\n",
      "Validation Loss: 0.060114563\n",
      "Epoch: 0708 cost = 0.036219916\n",
      "Validation Loss: 0.062013153\n",
      "Epoch: 0709 cost = 0.036100901\n",
      "Validation Loss: 0.053066418\n",
      "Epoch: 0710 cost = 0.035981865\n",
      "Validation Loss: 0.052507274\n",
      "Epoch: 0711 cost = 0.035862709\n",
      "Validation Loss: 0.041902132\n",
      "Epoch: 0712 cost = 0.035743579\n",
      "Validation Loss: 0.04239059\n",
      "Epoch: 0713 cost = 0.035623724\n",
      "Validation Loss: 0.044922907\n",
      "Epoch: 0714 cost = 0.035504225\n",
      "Validation Loss: 0.04496187\n",
      "Epoch: 0715 cost = 0.035383618\n",
      "Validation Loss: 0.044813998\n",
      "Epoch: 0716 cost = 0.035263173\n",
      "Validation Loss: 0.038720053\n",
      "Epoch: 0717 cost = 0.035142622\n",
      "Validation Loss: 0.039321955\n",
      "Epoch: 0718 cost = 0.035020888\n",
      "Validation Loss: 0.035340384\n",
      "Epoch: 0719 cost = 0.034899814\n",
      "Validation Loss: 0.03580635\n",
      "Epoch: 0720 cost = 0.034778304\n",
      "Validation Loss: 0.039944567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0721 cost = 0.034656226\n",
      "Validation Loss: 0.03309557\n",
      "Epoch: 0722 cost = 0.034534315\n",
      "Validation Loss: 0.032610264\n",
      "Epoch: 0723 cost = 0.034411554\n",
      "Validation Loss: 0.03440112\n",
      "Epoch: 0724 cost = 0.034289165\n",
      "Validation Loss: 0.036040787\n",
      "Epoch: 0725 cost = 0.034166657\n",
      "Validation Loss: 0.03395988\n",
      "Epoch: 0726 cost = 0.034043509\n",
      "Validation Loss: 0.040052876\n",
      "Epoch: 0727 cost = 0.033920148\n",
      "Validation Loss: 0.042465355\n",
      "Epoch: 0728 cost = 0.033796698\n",
      "Validation Loss: 0.04376876\n",
      "Epoch: 0729 cost = 0.033672975\n",
      "Validation Loss: 0.042418364\n",
      "Epoch: 0730 cost = 0.033548412\n",
      "Validation Loss: 0.036559906\n",
      "Epoch: 0731 cost = 0.033423647\n",
      "Validation Loss: 0.038142674\n",
      "Epoch: 0732 cost = 0.033298515\n",
      "Validation Loss: 0.03536274\n",
      "Epoch: 0733 cost = 0.033173019\n",
      "Validation Loss: 0.039554704\n",
      "Epoch: 0734 cost = 0.033046762\n",
      "Validation Loss: 0.041985437\n",
      "Epoch: 0735 cost = 0.032919828\n",
      "Validation Loss: 0.035649534\n",
      "Epoch: 0736 cost = 0.032793240\n",
      "Validation Loss: 0.04048741\n",
      "Epoch: 0737 cost = 0.032665788\n",
      "Validation Loss: 0.0399723\n",
      "Epoch: 0738 cost = 0.032538239\n",
      "Validation Loss: 0.039691683\n",
      "Epoch: 0739 cost = 0.032410471\n",
      "Validation Loss: 0.040026665\n",
      "Epoch: 0740 cost = 0.032282885\n",
      "Validation Loss: 0.04603084\n",
      "Epoch: 0741 cost = 0.032155580\n",
      "Validation Loss: 0.041046523\n",
      "Epoch: 0742 cost = 0.032028919\n",
      "Validation Loss: 0.03917618\n",
      "Epoch: 0743 cost = 0.031903268\n",
      "Validation Loss: 0.06544903\n",
      "Epoch: 0744 cost = 0.031779168\n",
      "Validation Loss: 0.059922412\n",
      "Epoch: 0745 cost = 0.031657409\n",
      "Validation Loss: 0.033153728\n",
      "Epoch: 0746 cost = 0.031537967\n",
      "Validation Loss: 0.0334128\n",
      "Epoch: 0747 cost = 0.031421537\n",
      "Validation Loss: 0.034478214\n",
      "Epoch: 0748 cost = 0.031308234\n",
      "Validation Loss: 0.035884053\n",
      "Epoch: 0749 cost = 0.031197531\n",
      "Validation Loss: 0.04547043\n",
      "Epoch: 0750 cost = 0.031089555\n",
      "Validation Loss: 0.048021045\n",
      "Epoch: 0751 cost = 0.030983541\n",
      "Validation Loss: 0.051636502\n",
      "Epoch: 0752 cost = 0.030880066\n",
      "Validation Loss: 0.039965346\n",
      "Epoch: 0753 cost = 0.030778401\n",
      "Validation Loss: 0.050343424\n",
      "Epoch: 0754 cost = 0.030678422\n",
      "Validation Loss: 0.04372721\n",
      "Epoch: 0755 cost = 0.030579784\n",
      "Validation Loss: 0.033037383\n",
      "Epoch: 0756 cost = 0.030482905\n",
      "Validation Loss: 0.038652815\n",
      "Epoch: 0757 cost = 0.030387426\n",
      "Validation Loss: 0.040715802\n",
      "Epoch: 0758 cost = 0.030293108\n",
      "Validation Loss: 0.039878298\n",
      "Epoch: 0759 cost = 0.030200353\n",
      "Validation Loss: 0.034938738\n",
      "Epoch: 0760 cost = 0.030108718\n",
      "Validation Loss: 0.034730528\n",
      "Epoch: 0761 cost = 0.030018623\n",
      "Validation Loss: 0.03695051\n",
      "Epoch: 0762 cost = 0.029929633\n",
      "Validation Loss: 0.047951296\n",
      "Epoch: 0763 cost = 0.029841855\n",
      "Validation Loss: 0.05026698\n",
      "Epoch: 0764 cost = 0.029755474\n",
      "Validation Loss: 0.037211798\n",
      "Epoch: 0765 cost = 0.029670278\n",
      "Validation Loss: 0.037247773\n",
      "Epoch: 0766 cost = 0.029586077\n",
      "Validation Loss: 0.053419553\n",
      "Epoch: 0767 cost = 0.029503229\n",
      "Validation Loss: 0.0648493\n",
      "Epoch: 0768 cost = 0.029421433\n",
      "Validation Loss: 0.04818241\n",
      "Epoch: 0769 cost = 0.029341017\n",
      "Validation Loss: 0.05266436\n",
      "Epoch: 0770 cost = 0.029261810\n",
      "Validation Loss: 0.047490854\n",
      "Epoch: 0771 cost = 0.029183413\n",
      "Validation Loss: 0.042709917\n",
      "Epoch: 0772 cost = 0.029106015\n",
      "Validation Loss: 0.042666186\n",
      "Epoch: 0773 cost = 0.029030290\n",
      "Validation Loss: 0.036603265\n",
      "Epoch: 0774 cost = 0.028955042\n",
      "Validation Loss: 0.03823923\n",
      "Epoch: 0775 cost = 0.028881511\n",
      "Validation Loss: 0.047015276\n",
      "Epoch: 0776 cost = 0.028809007\n",
      "Validation Loss: 0.04674789\n",
      "Epoch: 0777 cost = 0.028737159\n",
      "Validation Loss: 0.039980043\n",
      "Epoch: 0778 cost = 0.028666656\n",
      "Validation Loss: 0.04494742\n",
      "Epoch: 0779 cost = 0.028597205\n",
      "Validation Loss: 0.040518884\n",
      "Epoch: 0780 cost = 0.028528849\n",
      "Validation Loss: 0.040825464\n",
      "Epoch: 0781 cost = 0.028461428\n",
      "Validation Loss: 0.03820272\n",
      "Epoch: 0782 cost = 0.028394972\n",
      "Validation Loss: 0.040820558\n",
      "Epoch: 0783 cost = 0.028329308\n",
      "Validation Loss: 0.038956925\n",
      "Epoch: 0784 cost = 0.028264820\n",
      "Validation Loss: 0.03661958\n",
      "Epoch: 0785 cost = 0.028201140\n",
      "Validation Loss: 0.051165774\n",
      "Epoch: 0786 cost = 0.028138404\n",
      "Validation Loss: 0.062159065\n",
      "Epoch: 0787 cost = 0.028076510\n",
      "Validation Loss: 0.036179926\n",
      "Epoch: 0788 cost = 0.028015557\n",
      "Validation Loss: 0.036372915\n",
      "Epoch: 0789 cost = 0.027955428\n",
      "Validation Loss: 0.037778504\n",
      "Epoch: 0790 cost = 0.027896166\n",
      "Validation Loss: 0.043302767\n",
      "Epoch: 0791 cost = 0.027837258\n",
      "Validation Loss: 0.04704076\n",
      "Epoch: 0792 cost = 0.027779346\n",
      "Validation Loss: 0.050568234\n",
      "Epoch: 0793 cost = 0.027722055\n",
      "Validation Loss: 0.050245047\n",
      "Epoch: 0794 cost = 0.027665750\n",
      "Validation Loss: 0.04660645\n",
      "Epoch: 0795 cost = 0.027609832\n",
      "Validation Loss: 0.038741566\n",
      "Epoch: 0796 cost = 0.027555001\n",
      "Validation Loss: 0.04673452\n",
      "Epoch: 0797 cost = 0.027500818\n",
      "Validation Loss: 0.046076994\n",
      "Epoch: 0798 cost = 0.027446713\n",
      "Validation Loss: 0.049270656\n",
      "Epoch: 0799 cost = 0.027393601\n",
      "Validation Loss: 0.04375759\n",
      "Epoch: 0800 cost = 0.027341084\n",
      "Validation Loss: 0.035183482\n",
      "Epoch: 0801 cost = 0.027289289\n",
      "Validation Loss: 0.0344849\n",
      "Epoch: 0802 cost = 0.027238218\n",
      "Validation Loss: 0.04211254\n",
      "Epoch: 0803 cost = 0.027187194\n",
      "Validation Loss: 0.039601557\n",
      "Epoch: 0804 cost = 0.027137091\n",
      "Validation Loss: 0.036331445\n",
      "Epoch: 0805 cost = 0.027087518\n",
      "Validation Loss: 0.029815568\n",
      "Epoch: 0806 cost = 0.027038545\n",
      "Validation Loss: 0.052035585\n",
      "Epoch: 0807 cost = 0.026989746\n",
      "Validation Loss: 0.044127002\n",
      "Epoch: 0808 cost = 0.026941738\n",
      "Validation Loss: 0.042777594\n",
      "Epoch: 0809 cost = 0.026894120\n",
      "Validation Loss: 0.042021815\n",
      "Epoch: 0810 cost = 0.026847302\n",
      "Validation Loss: 0.055334695\n",
      "Epoch: 0811 cost = 0.026800448\n",
      "Validation Loss: 0.05606388\n",
      "Epoch: 0812 cost = 0.026754432\n",
      "Validation Loss: 0.041700672\n",
      "Epoch: 0813 cost = 0.026708769\n",
      "Validation Loss: 0.03384\n",
      "Epoch: 0814 cost = 0.026663371\n",
      "Validation Loss: 0.03928665\n",
      "Epoch: 0815 cost = 0.026618435\n",
      "Validation Loss: 0.03560703\n",
      "Epoch: 0816 cost = 0.026574505\n",
      "Validation Loss: 0.046546914\n",
      "Epoch: 0817 cost = 0.026530561\n",
      "Validation Loss: 0.058612097\n",
      "Epoch: 0818 cost = 0.026486887\n",
      "Validation Loss: 0.052594002\n",
      "Epoch: 0819 cost = 0.026443847\n",
      "Validation Loss: 0.04359496\n",
      "Epoch: 0820 cost = 0.026401373\n",
      "Validation Loss: 0.033564862\n",
      "Epoch: 0821 cost = 0.026358879\n",
      "Validation Loss: 0.043257046\n",
      "Epoch: 0822 cost = 0.026317166\n",
      "Validation Loss: 0.056541916\n",
      "Epoch: 0823 cost = 0.026275657\n",
      "Validation Loss: 0.06596208\n",
      "Epoch: 0824 cost = 0.026234638\n",
      "Validation Loss: 0.049710598\n",
      "Epoch: 0825 cost = 0.026193595\n",
      "Validation Loss: 0.04660222\n",
      "Epoch: 0826 cost = 0.026153509\n",
      "Validation Loss: 0.04139694\n",
      "Epoch: 0827 cost = 0.026113307\n",
      "Validation Loss: 0.028959343\n",
      "Epoch: 0828 cost = 0.026073310\n",
      "Validation Loss: 0.046477623\n",
      "Epoch: 0829 cost = 0.026034106\n",
      "Validation Loss: 0.036399562\n",
      "Epoch: 0830 cost = 0.025995292\n",
      "Validation Loss: 0.033108424\n",
      "Epoch: 0831 cost = 0.025956393\n",
      "Validation Loss: 0.029316079\n",
      "Epoch: 0832 cost = 0.025917858\n",
      "Validation Loss: 0.038340162\n",
      "Epoch: 0833 cost = 0.025879981\n",
      "Validation Loss: 0.04722951\n",
      "Epoch: 0834 cost = 0.025842059\n",
      "Validation Loss: 0.040045764\n",
      "Epoch: 0835 cost = 0.025804844\n",
      "Validation Loss: 0.03880567\n",
      "Epoch: 0836 cost = 0.025767797\n",
      "Validation Loss: 0.034072217\n",
      "Epoch: 0837 cost = 0.025730779\n",
      "Validation Loss: 0.030249996\n",
      "Epoch: 0838 cost = 0.025694475\n",
      "Validation Loss: 0.027312074\n",
      "Epoch: 0839 cost = 0.025658203\n",
      "Validation Loss: 0.07520973\n",
      "Epoch: 0840 cost = 0.025622211\n",
      "Validation Loss: 0.07057039\n",
      "Epoch: 0841 cost = 0.025586432\n",
      "Validation Loss: 0.05385297\n",
      "Epoch: 0842 cost = 0.025551051\n",
      "Validation Loss: 0.04320031\n",
      "Epoch: 0843 cost = 0.025515624\n",
      "Validation Loss: 0.033771086\n",
      "Epoch: 0844 cost = 0.025480899\n",
      "Validation Loss: 0.03936342\n",
      "Epoch: 0845 cost = 0.025446574\n",
      "Validation Loss: 0.035128586\n",
      "Epoch: 0846 cost = 0.025412109\n",
      "Validation Loss: 0.031945314\n",
      "Epoch: 0847 cost = 0.025378146\n",
      "Validation Loss: 0.030922845\n",
      "Epoch: 0848 cost = 0.025344209\n",
      "Validation Loss: 0.029589469\n",
      "Epoch: 0849 cost = 0.025310702\n",
      "Validation Loss: 0.027123157\n",
      "Epoch: 0850 cost = 0.025277083\n",
      "Validation Loss: 0.055430893\n",
      "Epoch: 0851 cost = 0.025244200\n",
      "Validation Loss: 0.051990353\n",
      "Epoch: 0852 cost = 0.025211408\n",
      "Validation Loss: 0.051798698\n",
      "Epoch: 0853 cost = 0.025178549\n",
      "Validation Loss: 0.04485214\n",
      "Epoch: 0854 cost = 0.025146109\n",
      "Validation Loss: 0.046713095\n",
      "Epoch: 0855 cost = 0.025114074\n",
      "Validation Loss: 0.034170758\n",
      "Epoch: 0856 cost = 0.025081953\n",
      "Validation Loss: 0.032833222\n",
      "Epoch: 0857 cost = 0.025050325\n",
      "Validation Loss: 0.04551821\n",
      "Epoch: 0858 cost = 0.025019040\n",
      "Validation Loss: 0.04776437\n",
      "Epoch: 0859 cost = 0.024987708\n",
      "Validation Loss: 0.046079174\n",
      "Epoch: 0860 cost = 0.024956258\n",
      "Validation Loss: 0.052734956\n",
      "Epoch: 0861 cost = 0.024925517\n",
      "Validation Loss: 0.061572652\n",
      "Epoch: 0862 cost = 0.024895171\n",
      "Validation Loss: 0.05408605\n",
      "Epoch: 0863 cost = 0.024864519\n",
      "Validation Loss: 0.044665605\n",
      "Epoch: 0864 cost = 0.024834339\n",
      "Validation Loss: 0.042971615\n",
      "Epoch: 0865 cost = 0.024804126\n",
      "Validation Loss: 0.0401388\n",
      "Epoch: 0866 cost = 0.024774258\n",
      "Validation Loss: 0.041783314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0867 cost = 0.024744634\n",
      "Validation Loss: 0.049095817\n",
      "Epoch: 0868 cost = 0.024715114\n",
      "Validation Loss: 0.03928757\n",
      "Epoch: 0869 cost = 0.024685769\n",
      "Validation Loss: 0.039943814\n",
      "Epoch: 0870 cost = 0.024656852\n",
      "Validation Loss: 0.028981151\n",
      "Epoch: 0871 cost = 0.024627682\n",
      "Validation Loss: 0.03177124\n",
      "Epoch: 0872 cost = 0.024598893\n",
      "Validation Loss: 0.047857404\n",
      "Epoch: 0873 cost = 0.024570136\n",
      "Validation Loss: 0.0651911\n",
      "Epoch: 0874 cost = 0.024541814\n",
      "Validation Loss: 0.044092853\n",
      "Epoch: 0875 cost = 0.024513575\n",
      "Validation Loss: 0.03624251\n",
      "Epoch: 0876 cost = 0.024485444\n",
      "Validation Loss: 0.036715824\n",
      "Epoch: 0877 cost = 0.024457545\n",
      "Validation Loss: 0.041062362\n",
      "Epoch: 0878 cost = 0.024429876\n",
      "Validation Loss: 0.039834805\n",
      "Epoch: 0879 cost = 0.024402088\n",
      "Validation Loss: 0.048515838\n",
      "Epoch: 0880 cost = 0.024374731\n",
      "Validation Loss: 0.053133823\n",
      "Epoch: 0881 cost = 0.024347526\n",
      "Validation Loss: 0.050868645\n",
      "Epoch: 0882 cost = 0.024320223\n",
      "Validation Loss: 0.063885726\n",
      "Epoch: 0883 cost = 0.024293396\n",
      "Validation Loss: 0.067650095\n",
      "Epoch: 0884 cost = 0.024266286\n",
      "Validation Loss: 0.049589187\n",
      "Epoch: 0885 cost = 0.024239635\n",
      "Validation Loss: 0.051720683\n",
      "Epoch: 0886 cost = 0.024213208\n",
      "Validation Loss: 0.051631145\n",
      "Epoch: 0887 cost = 0.024186864\n",
      "Validation Loss: 0.050730452\n",
      "Epoch: 0888 cost = 0.024160434\n",
      "Validation Loss: 0.04724398\n",
      "Epoch: 0889 cost = 0.024134616\n",
      "Validation Loss: 0.04702437\n",
      "Epoch: 0890 cost = 0.024108404\n",
      "Validation Loss: 0.047203075\n",
      "Epoch: 0891 cost = 0.024082435\n",
      "Validation Loss: 0.037725408\n",
      "Epoch: 0892 cost = 0.024056657\n",
      "Validation Loss: 0.03522052\n",
      "Epoch: 0893 cost = 0.024031075\n",
      "Validation Loss: 0.0313227\n",
      "Epoch: 0894 cost = 0.024005798\n",
      "Validation Loss: 0.03662026\n",
      "Epoch: 0895 cost = 0.023980330\n",
      "Validation Loss: 0.05888125\n",
      "Epoch: 0896 cost = 0.023955064\n",
      "Validation Loss: 0.070657246\n",
      "Epoch: 0897 cost = 0.023930140\n",
      "Validation Loss: 0.06792944\n",
      "Epoch: 0898 cost = 0.023904998\n",
      "Validation Loss: 0.0650428\n",
      "Epoch: 0899 cost = 0.023880069\n",
      "Validation Loss: 0.047640573\n",
      "Epoch: 0900 cost = 0.023855357\n",
      "Validation Loss: 0.03536147\n",
      "Epoch: 0901 cost = 0.023830799\n",
      "Validation Loss: 0.029572412\n",
      "Epoch: 0902 cost = 0.023806274\n",
      "Validation Loss: 0.026105514\n",
      "Epoch: 0903 cost = 0.023781837\n",
      "Validation Loss: 0.04097196\n",
      "Epoch: 0904 cost = 0.023757581\n",
      "Validation Loss: 0.02636406\n",
      "Epoch: 0905 cost = 0.023733428\n",
      "Validation Loss: 0.030850587\n",
      "Epoch: 0906 cost = 0.023709356\n",
      "Validation Loss: 0.025119243\n",
      "Epoch: 0907 cost = 0.023685414\n",
      "Validation Loss: 0.05203596\n",
      "Epoch: 0908 cost = 0.023661490\n",
      "Validation Loss: 0.040582955\n",
      "Epoch: 0909 cost = 0.023637711\n",
      "Validation Loss: 0.04240709\n",
      "Epoch: 0910 cost = 0.023614116\n",
      "Validation Loss: 0.052250467\n",
      "Epoch: 0911 cost = 0.023590539\n",
      "Validation Loss: 0.054607123\n",
      "Epoch: 0912 cost = 0.023567087\n",
      "Validation Loss: 0.050552055\n",
      "Epoch: 0913 cost = 0.023543656\n",
      "Validation Loss: 0.04213483\n",
      "Epoch: 0914 cost = 0.023520537\n",
      "Validation Loss: 0.032846037\n",
      "Epoch: 0915 cost = 0.023497121\n",
      "Validation Loss: 0.03372577\n",
      "Epoch: 0916 cost = 0.023474085\n",
      "Validation Loss: 0.032289907\n",
      "Epoch: 0917 cost = 0.023450846\n",
      "Validation Loss: 0.033679165\n",
      "Epoch: 0918 cost = 0.023428248\n",
      "Validation Loss: 0.035820488\n",
      "Epoch: 0919 cost = 0.023405365\n",
      "Validation Loss: 0.036918227\n",
      "Epoch: 0920 cost = 0.023382547\n",
      "Validation Loss: 0.03114004\n",
      "Epoch: 0921 cost = 0.023359786\n",
      "Validation Loss: 0.036737498\n",
      "Epoch: 0922 cost = 0.023337269\n",
      "Validation Loss: 0.0333868\n",
      "Epoch: 0923 cost = 0.023314822\n",
      "Validation Loss: 0.029262872\n",
      "Epoch: 0924 cost = 0.023292367\n",
      "Validation Loss: 0.03586096\n",
      "Epoch: 0925 cost = 0.023270139\n",
      "Validation Loss: 0.040921096\n",
      "Epoch: 0926 cost = 0.023247685\n",
      "Validation Loss: 0.045298003\n",
      "Epoch: 0927 cost = 0.023225638\n",
      "Validation Loss: 0.039358824\n",
      "Epoch: 0928 cost = 0.023203537\n",
      "Validation Loss: 0.037828915\n",
      "Epoch: 0929 cost = 0.023181477\n",
      "Validation Loss: 0.032696836\n",
      "Epoch: 0930 cost = 0.023159517\n",
      "Validation Loss: 0.032054376\n",
      "Epoch: 0931 cost = 0.023137456\n",
      "Validation Loss: 0.034673877\n",
      "Epoch: 0932 cost = 0.023115657\n",
      "Validation Loss: 0.039043315\n",
      "Epoch: 0933 cost = 0.023093831\n",
      "Validation Loss: 0.03006103\n",
      "Epoch: 0934 cost = 0.023072026\n",
      "Validation Loss: 0.024093313\n",
      "Epoch: 0935 cost = 0.023050318\n",
      "Validation Loss: 0.03769299\n",
      "Epoch: 0936 cost = 0.023028805\n",
      "Validation Loss: 0.035108577\n",
      "Epoch: 0937 cost = 0.023007190\n",
      "Validation Loss: 0.028693845\n",
      "Epoch: 0938 cost = 0.022985769\n",
      "Validation Loss: 0.029876458\n",
      "Epoch: 0939 cost = 0.022964295\n",
      "Validation Loss: 0.027068935\n",
      "Epoch: 0940 cost = 0.022942793\n",
      "Validation Loss: 0.031702265\n",
      "Epoch: 0941 cost = 0.022921610\n",
      "Validation Loss: 0.032539424\n",
      "Epoch: 0942 cost = 0.022900097\n",
      "Validation Loss: 0.031215442\n",
      "Epoch: 0943 cost = 0.022878998\n",
      "Validation Loss: 0.03975908\n",
      "Epoch: 0944 cost = 0.022857890\n",
      "Validation Loss: 0.038148493\n",
      "Epoch: 0945 cost = 0.022836682\n",
      "Validation Loss: 0.038683224\n",
      "Epoch: 0946 cost = 0.022815509\n",
      "Validation Loss: 0.038338073\n",
      "Epoch: 0947 cost = 0.022794640\n",
      "Validation Loss: 0.037473526\n",
      "Epoch: 0948 cost = 0.022773257\n",
      "Validation Loss: 0.037769645\n",
      "Epoch: 0949 cost = 0.022752317\n",
      "Validation Loss: 0.03899389\n",
      "Epoch: 0950 cost = 0.022731245\n",
      "Validation Loss: 0.04261566\n",
      "Epoch: 0951 cost = 0.022710548\n",
      "Validation Loss: 0.047977906\n",
      "Epoch: 0952 cost = 0.022689736\n",
      "Validation Loss: 0.056110725\n",
      "Epoch: 0953 cost = 0.022668693\n",
      "Validation Loss: 0.06308294\n",
      "Epoch: 0954 cost = 0.022647798\n",
      "Validation Loss: 0.05906348\n",
      "Epoch: 0955 cost = 0.022627191\n",
      "Validation Loss: 0.06636802\n",
      "Epoch: 0956 cost = 0.022606220\n",
      "Validation Loss: 0.055505704\n",
      "Epoch: 0957 cost = 0.022585396\n",
      "Validation Loss: 0.04843623\n",
      "Epoch: 0958 cost = 0.022564695\n",
      "Validation Loss: 0.044504963\n",
      "Epoch: 0959 cost = 0.022543910\n",
      "Validation Loss: 0.03180886\n",
      "Epoch: 0960 cost = 0.022523370\n",
      "Validation Loss: 0.032829296\n",
      "Epoch: 0961 cost = 0.022502468\n",
      "Validation Loss: 0.043169454\n",
      "Epoch: 0962 cost = 0.022481824\n",
      "Validation Loss: 0.03858495\n",
      "Epoch: 0963 cost = 0.022461419\n",
      "Validation Loss: 0.037683453\n",
      "Epoch: 0964 cost = 0.022440248\n",
      "Validation Loss: 0.049778063\n",
      "Epoch: 0965 cost = 0.022419726\n",
      "Validation Loss: 0.05095146\n",
      "Epoch: 0966 cost = 0.022399165\n",
      "Validation Loss: 0.04317464\n",
      "Epoch: 0967 cost = 0.022378499\n",
      "Validation Loss: 0.037069775\n",
      "Epoch: 0968 cost = 0.022357720\n",
      "Validation Loss: 0.03779645\n",
      "Epoch: 0969 cost = 0.022337026\n",
      "Validation Loss: 0.04135419\n",
      "Epoch: 0970 cost = 0.022316433\n",
      "Validation Loss: 0.047075562\n",
      "Epoch: 0971 cost = 0.022295424\n",
      "Validation Loss: 0.040442094\n",
      "Epoch: 0972 cost = 0.022274844\n",
      "Validation Loss: 0.032357857\n",
      "Epoch: 0973 cost = 0.022254220\n",
      "Validation Loss: 0.033113226\n",
      "Epoch: 0974 cost = 0.022233473\n",
      "Validation Loss: 0.03351348\n",
      "Epoch: 0975 cost = 0.022212461\n",
      "Validation Loss: 0.031120397\n",
      "Epoch: 0976 cost = 0.022191689\n",
      "Validation Loss: 0.03429005\n",
      "Epoch: 0977 cost = 0.022170801\n",
      "Validation Loss: 0.04091509\n",
      "Epoch: 0978 cost = 0.022149993\n",
      "Validation Loss: 0.039443765\n",
      "Epoch: 0979 cost = 0.022129064\n",
      "Validation Loss: 0.03736837\n",
      "Epoch: 0980 cost = 0.022108151\n",
      "Validation Loss: 0.044395037\n",
      "Epoch: 0981 cost = 0.022087012\n",
      "Validation Loss: 0.03801448\n",
      "Epoch: 0982 cost = 0.022065963\n",
      "Validation Loss: 0.035493318\n",
      "Epoch: 0983 cost = 0.022044662\n",
      "Validation Loss: 0.04020775\n",
      "Epoch: 0984 cost = 0.022023437\n",
      "Validation Loss: 0.052257735\n",
      "Epoch: 0985 cost = 0.022002447\n",
      "Validation Loss: 0.058496095\n",
      "Epoch: 0986 cost = 0.021981090\n",
      "Validation Loss: 0.047569767\n",
      "Epoch: 0987 cost = 0.021959493\n",
      "Validation Loss: 0.029778065\n",
      "Epoch: 0988 cost = 0.021938026\n",
      "Validation Loss: 0.030525113\n",
      "Epoch: 0989 cost = 0.021916907\n",
      "Validation Loss: 0.032742627\n",
      "Epoch: 0990 cost = 0.021894736\n",
      "Validation Loss: 0.022494202\n",
      "Epoch: 0991 cost = 0.021873073\n",
      "Validation Loss: 0.03287773\n",
      "Epoch: 0992 cost = 0.021851495\n",
      "Validation Loss: 0.02936388\n",
      "Epoch: 0993 cost = 0.021829113\n",
      "Validation Loss: 0.029689157\n",
      "Epoch: 0994 cost = 0.021806937\n",
      "Validation Loss: 0.041033633\n",
      "Epoch: 0995 cost = 0.021784630\n",
      "Validation Loss: 0.029522907\n",
      "Epoch: 0996 cost = 0.021762396\n",
      "Validation Loss: 0.029278396\n",
      "Epoch: 0997 cost = 0.021739574\n",
      "Validation Loss: 0.031681985\n",
      "Epoch: 0998 cost = 0.021716944\n",
      "Validation Loss: 0.030409884\n",
      "Epoch: 0999 cost = 0.021693937\n",
      "Validation Loss: 0.035200644\n",
      "Epoch: 1000 cost = 0.021670870\n",
      "Validation Loss: 0.045023438\n",
      "Epoch: 1001 cost = 0.021647804\n",
      "Validation Loss: 0.04679188\n",
      "Epoch: 1002 cost = 0.021624103\n",
      "Validation Loss: 0.03694731\n",
      "Epoch: 1003 cost = 0.021600522\n",
      "Validation Loss: 0.02909036\n",
      "Epoch: 1004 cost = 0.021576590\n",
      "Validation Loss: 0.04080739\n",
      "Epoch: 1005 cost = 0.021552311\n",
      "Validation Loss: 0.045206297\n",
      "Epoch: 1006 cost = 0.021527774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.036422968\n",
      "Epoch: 1007 cost = 0.021503322\n",
      "Validation Loss: 0.030314201\n",
      "Epoch: 1008 cost = 0.021478318\n",
      "Validation Loss: 0.024230003\n",
      "Epoch: 1009 cost = 0.021452820\n",
      "Validation Loss: 0.031090915\n",
      "Epoch: 1010 cost = 0.021427648\n",
      "Validation Loss: 0.033350468\n",
      "Epoch: 1011 cost = 0.021401523\n",
      "Validation Loss: 0.02988906\n",
      "Epoch: 1012 cost = 0.021375376\n",
      "Validation Loss: 0.035841465\n",
      "Epoch: 1013 cost = 0.021348911\n",
      "Validation Loss: 0.0529894\n",
      "Epoch: 1014 cost = 0.021321890\n",
      "Validation Loss: 0.03710325\n",
      "Epoch: 1015 cost = 0.021294460\n",
      "Validation Loss: 0.035525203\n",
      "Epoch: 1016 cost = 0.021267144\n",
      "Validation Loss: 0.03596714\n",
      "Epoch: 1017 cost = 0.021239229\n",
      "Validation Loss: 0.03245745\n",
      "Epoch: 1018 cost = 0.021210761\n",
      "Validation Loss: 0.02634119\n",
      "Epoch: 1019 cost = 0.021182033\n",
      "Validation Loss: 0.03373033\n",
      "Epoch: 1020 cost = 0.021152978\n",
      "Validation Loss: 0.034410387\n",
      "Epoch: 1021 cost = 0.021123635\n",
      "Validation Loss: 0.029050685\n",
      "Epoch: 1022 cost = 0.021093930\n",
      "Validation Loss: 0.032027237\n",
      "Epoch: 1023 cost = 0.021063725\n",
      "Validation Loss: 0.039614107\n",
      "Epoch: 1024 cost = 0.021033377\n",
      "Validation Loss: 0.03577298\n",
      "Epoch: 1025 cost = 0.021002666\n",
      "Validation Loss: 0.034308586\n",
      "Epoch: 1026 cost = 0.020971728\n",
      "Validation Loss: 0.03451001\n",
      "Epoch: 1027 cost = 0.020940537\n",
      "Validation Loss: 0.03418985\n",
      "Epoch: 1028 cost = 0.020909117\n",
      "Validation Loss: 0.04625451\n",
      "Epoch: 1029 cost = 0.020877916\n",
      "Validation Loss: 0.051450748\n",
      "Epoch: 1030 cost = 0.020846325\n",
      "Validation Loss: 0.048552334\n",
      "Epoch: 1031 cost = 0.020814992\n",
      "Validation Loss: 0.047389243\n",
      "Epoch: 1032 cost = 0.020783680\n",
      "Validation Loss: 0.041989997\n",
      "Epoch: 1033 cost = 0.020752470\n",
      "Validation Loss: 0.038510215\n",
      "Epoch: 1034 cost = 0.020721240\n",
      "Validation Loss: 0.035839237\n",
      "Epoch: 1035 cost = 0.020690471\n",
      "Validation Loss: 0.04368524\n",
      "Epoch: 1036 cost = 0.020659731\n",
      "Validation Loss: 0.05434936\n",
      "Epoch: 1037 cost = 0.020629479\n",
      "Validation Loss: 0.059482783\n",
      "Epoch: 1038 cost = 0.020599115\n",
      "Validation Loss: 0.054772615\n",
      "Epoch: 1039 cost = 0.020569384\n",
      "Validation Loss: 0.03751377\n",
      "Epoch: 1040 cost = 0.020539602\n",
      "Validation Loss: 0.025358044\n",
      "Epoch: 1041 cost = 0.020510229\n",
      "Validation Loss: 0.025185416\n",
      "Epoch: 1042 cost = 0.020481151\n",
      "Validation Loss: 0.036729656\n",
      "Epoch: 1043 cost = 0.020452473\n",
      "Validation Loss: 0.043258008\n",
      "Epoch: 1044 cost = 0.020423532\n",
      "Validation Loss: 0.046763774\n",
      "Epoch: 1045 cost = 0.020395065\n",
      "Validation Loss: 0.049059153\n",
      "Epoch: 1046 cost = 0.020366703\n",
      "Validation Loss: 0.05276458\n",
      "Epoch: 1047 cost = 0.020338823\n",
      "Validation Loss: 0.05172167\n",
      "Epoch: 1048 cost = 0.020310754\n",
      "Validation Loss: 0.042588834\n",
      "Epoch: 1049 cost = 0.020283183\n",
      "Validation Loss: 0.04285581\n",
      "Epoch: 1050 cost = 0.020255994\n",
      "Validation Loss: 0.035259284\n",
      "Epoch: 1051 cost = 0.020228723\n",
      "Validation Loss: 0.030090617\n",
      "Epoch: 1052 cost = 0.020201958\n",
      "Validation Loss: 0.027255487\n",
      "Epoch: 1053 cost = 0.020175291\n",
      "Validation Loss: 0.032690175\n",
      "Epoch: 1054 cost = 0.020148651\n",
      "Validation Loss: 0.034365464\n",
      "Epoch: 1055 cost = 0.020122420\n",
      "Validation Loss: 0.03275472\n",
      "Epoch: 1056 cost = 0.020096308\n",
      "Validation Loss: 0.034758102\n",
      "Epoch: 1057 cost = 0.020070449\n",
      "Validation Loss: 0.03548293\n",
      "Epoch: 1058 cost = 0.020044903\n",
      "Validation Loss: 0.034785036\n",
      "Epoch: 1059 cost = 0.020019672\n",
      "Validation Loss: 0.03512352\n",
      "Epoch: 1060 cost = 0.019994266\n",
      "Validation Loss: 0.0316999\n",
      "Epoch: 1061 cost = 0.019969615\n",
      "Validation Loss: 0.03540894\n",
      "Epoch: 1062 cost = 0.019944679\n",
      "Validation Loss: 0.034484316\n",
      "Epoch: 1063 cost = 0.019920427\n",
      "Validation Loss: 0.039970014\n",
      "Epoch: 1064 cost = 0.019895775\n",
      "Validation Loss: 0.030583642\n",
      "Epoch: 1065 cost = 0.019871739\n",
      "Validation Loss: 0.029468779\n",
      "Epoch: 1066 cost = 0.019848079\n",
      "Validation Loss: 0.029692855\n",
      "Epoch: 1067 cost = 0.019824869\n",
      "Validation Loss: 0.023489919\n",
      "Epoch: 1068 cost = 0.019801147\n",
      "Validation Loss: 0.03100546\n",
      "Epoch: 1069 cost = 0.019778023\n",
      "Validation Loss: 0.03225504\n",
      "Epoch: 1070 cost = 0.019754992\n",
      "Validation Loss: 0.029624559\n",
      "Epoch: 1071 cost = 0.019732201\n",
      "Validation Loss: 0.028409109\n",
      "Epoch: 1072 cost = 0.019709696\n",
      "Validation Loss: 0.026834875\n",
      "Epoch: 1073 cost = 0.019687358\n",
      "Validation Loss: 0.029723195\n",
      "Epoch: 1074 cost = 0.019665211\n",
      "Validation Loss: 0.034381468\n",
      "Epoch: 1075 cost = 0.019643314\n",
      "Validation Loss: 0.03712673\n",
      "Epoch: 1076 cost = 0.019621677\n",
      "Validation Loss: 0.03611709\n",
      "Epoch: 1077 cost = 0.019600320\n",
      "Validation Loss: 0.044348698\n",
      "Epoch: 1078 cost = 0.019579040\n",
      "Validation Loss: 0.039982047\n",
      "Epoch: 1079 cost = 0.019557949\n",
      "Validation Loss: 0.026410012\n",
      "Epoch: 1080 cost = 0.019537053\n",
      "Validation Loss: 0.036105875\n",
      "Epoch: 1081 cost = 0.019516495\n",
      "Validation Loss: 0.04326779\n",
      "Epoch: 1082 cost = 0.019495914\n",
      "Validation Loss: 0.054781422\n",
      "Epoch: 1083 cost = 0.019475624\n",
      "Validation Loss: 0.0382014\n",
      "Epoch: 1084 cost = 0.019455707\n",
      "Validation Loss: 0.04124365\n",
      "Epoch: 1085 cost = 0.019435860\n",
      "Validation Loss: 0.039603785\n",
      "Epoch: 1086 cost = 0.019416129\n",
      "Validation Loss: 0.039330646\n",
      "Epoch: 1087 cost = 0.019396598\n",
      "Validation Loss: 0.03538901\n",
      "Epoch: 1088 cost = 0.019377146\n",
      "Validation Loss: 0.032136414\n",
      "Epoch: 1089 cost = 0.019358055\n",
      "Validation Loss: 0.03174356\n",
      "Epoch: 1090 cost = 0.019339309\n",
      "Validation Loss: 0.03142964\n",
      "Epoch: 1091 cost = 0.019320527\n",
      "Validation Loss: 0.034547724\n",
      "Epoch: 1092 cost = 0.019301972\n",
      "Validation Loss: 0.037288498\n",
      "Epoch: 1093 cost = 0.019283694\n",
      "Validation Loss: 0.02900546\n",
      "Epoch: 1094 cost = 0.019265434\n",
      "Validation Loss: 0.02720766\n",
      "Epoch: 1095 cost = 0.019247280\n",
      "Validation Loss: 0.031698566\n",
      "Epoch: 1096 cost = 0.019229237\n",
      "Validation Loss: 0.031315695\n",
      "Epoch: 1097 cost = 0.019211695\n",
      "Validation Loss: 0.036594793\n",
      "Epoch: 1098 cost = 0.019194015\n",
      "Validation Loss: 0.045865774\n",
      "Epoch: 1099 cost = 0.019176423\n",
      "Validation Loss: 0.032737\n",
      "Epoch: 1100 cost = 0.019159179\n",
      "Validation Loss: 0.032362513\n",
      "Epoch: 1101 cost = 0.019142402\n",
      "Validation Loss: 0.03363099\n",
      "Epoch: 1102 cost = 0.019125309\n",
      "Validation Loss: 0.029774591\n",
      "Epoch: 1103 cost = 0.019108170\n",
      "Validation Loss: 0.027585143\n",
      "Epoch: 1104 cost = 0.019091797\n",
      "Validation Loss: 0.02519769\n",
      "Epoch: 1105 cost = 0.019075061\n",
      "Validation Loss: 0.03347988\n",
      "Epoch: 1106 cost = 0.019058516\n",
      "Validation Loss: 0.03681603\n",
      "Epoch: 1107 cost = 0.019042290\n",
      "Validation Loss: 0.061521057\n",
      "Epoch: 1108 cost = 0.019025992\n",
      "Validation Loss: 0.057967003\n",
      "Epoch: 1109 cost = 0.019009772\n",
      "Validation Loss: 0.05647923\n",
      "Epoch: 1110 cost = 0.018994372\n",
      "Validation Loss: 0.041264396\n",
      "Epoch: 1111 cost = 0.018978337\n",
      "Validation Loss: 0.03728438\n",
      "Epoch: 1112 cost = 0.018962604\n",
      "Validation Loss: 0.030962711\n",
      "Epoch: 1113 cost = 0.018947055\n",
      "Validation Loss: 0.028540898\n",
      "Epoch: 1114 cost = 0.018931623\n",
      "Validation Loss: 0.028731653\n",
      "Epoch: 1115 cost = 0.018916153\n",
      "Validation Loss: 0.038199194\n",
      "Epoch: 1116 cost = 0.018901032\n",
      "Validation Loss: 0.04389093\n",
      "Epoch: 1117 cost = 0.018885879\n",
      "Validation Loss: 0.043434836\n",
      "Epoch: 1118 cost = 0.018870866\n",
      "Validation Loss: 0.042349275\n",
      "Epoch: 1119 cost = 0.018855976\n",
      "Validation Loss: 0.02372024\n",
      "Epoch: 1120 cost = 0.018841040\n",
      "Validation Loss: 0.029871719\n",
      "Epoch: 1121 cost = 0.018826600\n",
      "Validation Loss: 0.040535692\n",
      "Epoch: 1122 cost = 0.018811710\n",
      "Validation Loss: 0.03397464\n",
      "Epoch: 1123 cost = 0.018797258\n",
      "Validation Loss: 0.027262308\n",
      "Epoch: 1124 cost = 0.018782500\n",
      "Validation Loss: 0.04258386\n",
      "Epoch: 1125 cost = 0.018768598\n",
      "Validation Loss: 0.046306375\n",
      "Epoch: 1126 cost = 0.018753939\n",
      "Validation Loss: 0.039817978\n",
      "Epoch: 1127 cost = 0.018739771\n",
      "Validation Loss: 0.0378264\n",
      "Epoch: 1128 cost = 0.018725451\n",
      "Validation Loss: 0.0522243\n",
      "Epoch: 1129 cost = 0.018711666\n",
      "Validation Loss: 0.049058452\n",
      "Epoch: 1130 cost = 0.018697706\n",
      "Validation Loss: 0.043058723\n",
      "Epoch: 1131 cost = 0.018683629\n",
      "Validation Loss: 0.03715094\n",
      "Epoch: 1132 cost = 0.018669982\n",
      "Validation Loss: 0.040859737\n",
      "Epoch: 1133 cost = 0.018656417\n",
      "Validation Loss: 0.040529955\n",
      "Epoch: 1134 cost = 0.018642712\n",
      "Validation Loss: 0.031009192\n",
      "Epoch: 1135 cost = 0.018628792\n",
      "Validation Loss: 0.03886687\n",
      "Epoch: 1136 cost = 0.018615433\n",
      "Validation Loss: 0.039356172\n",
      "Epoch: 1137 cost = 0.018602006\n",
      "Validation Loss: 0.039113797\n",
      "Epoch: 1138 cost = 0.018588536\n",
      "Validation Loss: 0.03547754\n",
      "Epoch: 1139 cost = 0.018575157\n",
      "Validation Loss: 0.04060983\n",
      "Epoch: 1140 cost = 0.018561869\n",
      "Validation Loss: 0.037291348\n",
      "Epoch: 1141 cost = 0.018548893\n",
      "Validation Loss: 0.026326999\n",
      "Epoch: 1142 cost = 0.018535707\n",
      "Validation Loss: 0.023156496\n",
      "Epoch: 1143 cost = 0.018522417\n",
      "Validation Loss: 0.02795409\n",
      "Epoch: 1144 cost = 0.018509668\n",
      "Validation Loss: 0.034714296\n",
      "Epoch: 1145 cost = 0.018496520\n",
      "Validation Loss: 0.03199557\n",
      "Epoch: 1146 cost = 0.018483663\n",
      "Validation Loss: 0.030295674\n",
      "Epoch: 1147 cost = 0.018470579\n",
      "Validation Loss: 0.028006703\n",
      "Epoch: 1148 cost = 0.018458020\n",
      "Validation Loss: 0.03924344\n",
      "Epoch: 1149 cost = 0.018445309\n",
      "Validation Loss: 0.05225328\n",
      "Epoch: 1150 cost = 0.018432479\n",
      "Validation Loss: 0.05156273\n",
      "Epoch: 1151 cost = 0.018419692\n",
      "Validation Loss: 0.050031934\n",
      "Epoch: 1152 cost = 0.018406982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.034083698\n",
      "Epoch: 1153 cost = 0.018394786\n",
      "Validation Loss: 0.03278184\n",
      "Epoch: 1154 cost = 0.018382436\n",
      "Validation Loss: 0.027298\n",
      "Epoch: 1155 cost = 0.018369731\n",
      "Validation Loss: 0.024538215\n",
      "Epoch: 1156 cost = 0.018357422\n",
      "Validation Loss: 0.045940418\n",
      "Epoch: 1157 cost = 0.018345260\n",
      "Validation Loss: 0.066364974\n",
      "Epoch: 1158 cost = 0.018332543\n",
      "Validation Loss: 0.0728273\n",
      "Epoch: 1159 cost = 0.018320675\n",
      "Validation Loss: 0.055272996\n",
      "Epoch: 1160 cost = 0.018308290\n",
      "Validation Loss: 0.046660803\n",
      "Epoch: 1161 cost = 0.018295840\n",
      "Validation Loss: 0.03767147\n",
      "Epoch: 1162 cost = 0.018283744\n",
      "Validation Loss: 0.031152671\n",
      "Epoch: 1163 cost = 0.018271547\n",
      "Validation Loss: 0.044454776\n",
      "Epoch: 1164 cost = 0.018259749\n",
      "Validation Loss: 0.0652416\n",
      "Epoch: 1165 cost = 0.018247643\n",
      "Validation Loss: 0.07692642\n",
      "Epoch: 1166 cost = 0.018235602\n",
      "Validation Loss: 0.06488415\n",
      "Epoch: 1167 cost = 0.018223533\n",
      "Validation Loss: 0.054793015\n",
      "Epoch: 1168 cost = 0.018211892\n",
      "Validation Loss: 0.05163925\n",
      "Epoch: 1169 cost = 0.018199923\n",
      "Validation Loss: 0.030182267\n",
      "Epoch: 1170 cost = 0.018188397\n",
      "Validation Loss: 0.034435842\n",
      "Epoch: 1171 cost = 0.018176581\n",
      "Validation Loss: 0.038477574\n",
      "Epoch: 1172 cost = 0.018164510\n",
      "Validation Loss: 0.03649451\n",
      "Epoch: 1173 cost = 0.018152944\n",
      "Validation Loss: 0.033599988\n",
      "Epoch: 1174 cost = 0.018141328\n",
      "Validation Loss: 0.026575692\n",
      "Epoch: 1175 cost = 0.018129631\n",
      "Validation Loss: 0.028552338\n",
      "Epoch: 1176 cost = 0.018118048\n",
      "Validation Loss: 0.027105184\n",
      "Epoch: 1177 cost = 0.018106480\n",
      "Validation Loss: 0.03226935\n",
      "Epoch: 1178 cost = 0.018094742\n",
      "Validation Loss: 0.029279022\n",
      "Epoch: 1179 cost = 0.018083556\n",
      "Validation Loss: 0.04121289\n",
      "Epoch: 1180 cost = 0.018071814\n",
      "Validation Loss: 0.037117317\n",
      "Epoch: 1181 cost = 0.018060397\n",
      "Validation Loss: 0.035280712\n",
      "Epoch: 1182 cost = 0.018048861\n",
      "Validation Loss: 0.034561824\n",
      "Epoch: 1183 cost = 0.018037690\n",
      "Validation Loss: 0.03290697\n",
      "Epoch: 1184 cost = 0.018025838\n",
      "Validation Loss: 0.024799302\n",
      "Epoch: 1185 cost = 0.018014903\n",
      "Validation Loss: 0.0426689\n",
      "Epoch: 1186 cost = 0.018003510\n",
      "Validation Loss: 0.03686382\n",
      "Epoch: 1187 cost = 0.017992163\n",
      "Validation Loss: 0.024078283\n",
      "Epoch: 1188 cost = 0.017980952\n",
      "Validation Loss: 0.031024748\n",
      "Epoch: 1189 cost = 0.017969928\n",
      "Validation Loss: 0.029410042\n",
      "Epoch: 1190 cost = 0.017958654\n",
      "Validation Loss: 0.052640673\n",
      "Epoch: 1191 cost = 0.017947623\n",
      "Validation Loss: 0.05414405\n",
      "Epoch: 1192 cost = 0.017936334\n",
      "Validation Loss: 0.06845641\n",
      "Epoch: 1193 cost = 0.017925010\n",
      "Validation Loss: 0.06663257\n",
      "Epoch: 1194 cost = 0.017914220\n",
      "Validation Loss: 0.07409036\n",
      "Epoch: 1195 cost = 0.017903175\n",
      "Validation Loss: 0.072656065\n",
      "Epoch: 1196 cost = 0.017892338\n",
      "Validation Loss: 0.055660807\n",
      "Epoch: 1197 cost = 0.017880966\n",
      "Validation Loss: 0.04002437\n",
      "Epoch: 1198 cost = 0.017870138\n",
      "Validation Loss: 0.034146626\n",
      "Epoch: 1199 cost = 0.017859294\n",
      "Validation Loss: 0.047539078\n",
      "Epoch: 1200 cost = 0.017848436\n",
      "Validation Loss: 0.034245525\n",
      "Epoch: 1201 cost = 0.017837281\n",
      "Validation Loss: 0.024292262\n",
      "Epoch: 1202 cost = 0.017826800\n",
      "Validation Loss: 0.033691995\n",
      "Epoch: 1203 cost = 0.017815633\n",
      "Validation Loss: 0.03715023\n",
      "Epoch: 1204 cost = 0.017804698\n",
      "Validation Loss: 0.05047087\n",
      "Epoch: 1205 cost = 0.017793925\n",
      "Validation Loss: 0.043862857\n",
      "Epoch: 1206 cost = 0.017783456\n",
      "Validation Loss: 0.048641015\n",
      "Epoch: 1207 cost = 0.017772817\n",
      "Validation Loss: 0.056560643\n",
      "Epoch: 1208 cost = 0.017761889\n",
      "Validation Loss: 0.033541497\n",
      "Epoch: 1209 cost = 0.017751295\n",
      "Validation Loss: 0.029535737\n",
      "Epoch: 1210 cost = 0.017740790\n",
      "Validation Loss: 0.04155537\n",
      "Epoch: 1211 cost = 0.017729840\n",
      "Validation Loss: 0.057359885\n",
      "Epoch: 1212 cost = 0.017719729\n",
      "Validation Loss: 0.039778717\n",
      "Epoch: 1213 cost = 0.017708853\n",
      "Validation Loss: 0.03277246\n",
      "Epoch: 1214 cost = 0.017698261\n",
      "Validation Loss: 0.035335395\n",
      "Epoch: 1215 cost = 0.017687717\n",
      "Validation Loss: 0.031992886\n",
      "Epoch: 1216 cost = 0.017677099\n",
      "Validation Loss: 0.037286732\n",
      "Epoch: 1217 cost = 0.017666790\n",
      "Validation Loss: 0.0439435\n",
      "Epoch: 1218 cost = 0.017656233\n",
      "Validation Loss: 0.03216943\n",
      "Epoch: 1219 cost = 0.017645714\n",
      "Validation Loss: 0.03329198\n",
      "Epoch: 1220 cost = 0.017635188\n",
      "Validation Loss: 0.045960445\n",
      "Epoch: 1221 cost = 0.017625050\n",
      "Validation Loss: 0.027530037\n",
      "Epoch: 1222 cost = 0.017614642\n",
      "Validation Loss: 0.046682496\n",
      "Epoch: 1223 cost = 0.017603802\n",
      "Validation Loss: 0.052809097\n",
      "Epoch: 1224 cost = 0.017593843\n",
      "Validation Loss: 0.047128648\n",
      "Epoch: 1225 cost = 0.017583300\n",
      "Validation Loss: 0.03300656\n",
      "Epoch: 1226 cost = 0.017573201\n",
      "Validation Loss: 0.031655204\n",
      "Epoch: 1227 cost = 0.017562902\n",
      "Validation Loss: 0.03601811\n",
      "Epoch: 1228 cost = 0.017552532\n",
      "Validation Loss: 0.026158826\n",
      "Epoch: 1229 cost = 0.017542317\n",
      "Validation Loss: 0.025903046\n",
      "Epoch: 1230 cost = 0.017532392\n",
      "Validation Loss: 0.0329323\n",
      "Epoch: 1231 cost = 0.017521934\n",
      "Validation Loss: 0.028505545\n",
      "Epoch: 1232 cost = 0.017511848\n",
      "Validation Loss: 0.031058308\n",
      "Epoch: 1233 cost = 0.017501637\n",
      "Validation Loss: 0.04885884\n",
      "Epoch: 1234 cost = 0.017491574\n",
      "Validation Loss: 0.03889369\n",
      "Epoch: 1235 cost = 0.017481528\n",
      "Validation Loss: 0.029250974\n",
      "Epoch: 1236 cost = 0.017471252\n",
      "Validation Loss: 0.028010776\n",
      "Epoch: 1237 cost = 0.017461372\n",
      "Validation Loss: 0.031795163\n",
      "Epoch: 1238 cost = 0.017451626\n",
      "Validation Loss: 0.025550138\n",
      "Epoch: 1239 cost = 0.017441063\n",
      "Validation Loss: 0.029263182\n",
      "Epoch: 1240 cost = 0.017431253\n",
      "Validation Loss: 0.03272702\n",
      "Epoch: 1241 cost = 0.017421109\n",
      "Validation Loss: 0.040974606\n",
      "Epoch: 1242 cost = 0.017411087\n",
      "Validation Loss: 0.0307637\n",
      "Epoch: 1243 cost = 0.017401374\n",
      "Validation Loss: 0.030485447\n",
      "Epoch: 1244 cost = 0.017391355\n",
      "Validation Loss: 0.034407306\n",
      "Epoch: 1245 cost = 0.017381583\n",
      "Validation Loss: 0.05050087\n",
      "Epoch: 1246 cost = 0.017371273\n",
      "Validation Loss: 0.057012692\n",
      "Epoch: 1247 cost = 0.017361595\n",
      "Validation Loss: 0.074459784\n",
      "Epoch: 1248 cost = 0.017351677\n",
      "Validation Loss: 0.08255778\n",
      "Epoch: 1249 cost = 0.017341825\n",
      "Validation Loss: 0.059681322\n",
      "Epoch: 1250 cost = 0.017331907\n",
      "Validation Loss: 0.054683264\n",
      "Epoch: 1251 cost = 0.017322590\n",
      "Validation Loss: 0.056130864\n",
      "Epoch: 1252 cost = 0.017312908\n",
      "Validation Loss: 0.045689154\n",
      "Epoch: 1253 cost = 0.017302756\n",
      "Validation Loss: 0.01968029\n",
      "Epoch: 1254 cost = 0.017293239\n",
      "Validation Loss: 0.033712905\n",
      "Epoch: 1255 cost = 0.017283108\n",
      "Validation Loss: 0.033019807\n",
      "Epoch: 1256 cost = 0.017273770\n",
      "Validation Loss: 0.026288612\n",
      "Epoch: 1257 cost = 0.017264146\n",
      "Validation Loss: 0.026342144\n",
      "Epoch: 1258 cost = 0.017254806\n",
      "Validation Loss: 0.029970912\n",
      "Epoch: 1259 cost = 0.017244716\n",
      "Validation Loss: 0.028094813\n",
      "Epoch: 1260 cost = 0.017235232\n",
      "Validation Loss: 0.030488854\n",
      "Epoch: 1261 cost = 0.017225400\n",
      "Validation Loss: 0.034930352\n",
      "Epoch: 1262 cost = 0.017216276\n",
      "Validation Loss: 0.035810165\n",
      "Epoch: 1263 cost = 0.017206301\n",
      "Validation Loss: 0.029146366\n",
      "Epoch: 1264 cost = 0.017196883\n",
      "Validation Loss: 0.02790346\n",
      "Epoch: 1265 cost = 0.017187378\n",
      "Validation Loss: 0.029755844\n",
      "Epoch: 1266 cost = 0.017177547\n",
      "Validation Loss: 0.03019068\n",
      "Epoch: 1267 cost = 0.017168127\n",
      "Validation Loss: 0.032315772\n",
      "Epoch: 1268 cost = 0.017158923\n",
      "Validation Loss: 0.038905434\n",
      "Epoch: 1269 cost = 0.017149090\n",
      "Validation Loss: 0.04123845\n",
      "Epoch: 1270 cost = 0.017139689\n",
      "Validation Loss: 0.04351434\n",
      "Epoch: 1271 cost = 0.017130391\n",
      "Validation Loss: 0.025738599\n",
      "Epoch: 1272 cost = 0.017120950\n",
      "Validation Loss: 0.025912166\n",
      "Epoch: 1273 cost = 0.017111503\n",
      "Validation Loss: 0.035267983\n",
      "Epoch: 1274 cost = 0.017102175\n",
      "Validation Loss: 0.027253764\n",
      "Epoch: 1275 cost = 0.017092813\n",
      "Validation Loss: 0.028538644\n",
      "Epoch: 1276 cost = 0.017083524\n",
      "Validation Loss: 0.028023113\n",
      "Epoch: 1277 cost = 0.017074456\n",
      "Validation Loss: 0.036967937\n",
      "Epoch: 1278 cost = 0.017064752\n",
      "Validation Loss: 0.050048076\n",
      "Epoch: 1279 cost = 0.017055586\n",
      "Validation Loss: 0.03396553\n",
      "Epoch: 1280 cost = 0.017045864\n",
      "Validation Loss: 0.019994779\n",
      "Epoch: 1281 cost = 0.017036806\n",
      "Validation Loss: 0.02580846\n",
      "Epoch: 1282 cost = 0.017027626\n",
      "Validation Loss: 0.028613469\n",
      "Epoch: 1283 cost = 0.017018283\n",
      "Validation Loss: 0.03657596\n",
      "Epoch: 1284 cost = 0.017009193\n",
      "Validation Loss: 0.035050675\n",
      "Epoch: 1285 cost = 0.017000026\n",
      "Validation Loss: 0.026103742\n",
      "Epoch: 1286 cost = 0.016990743\n",
      "Validation Loss: 0.021826083\n",
      "Epoch: 1287 cost = 0.016981592\n",
      "Validation Loss: 0.022624604\n",
      "Epoch: 1288 cost = 0.016972393\n",
      "Validation Loss: 0.030566014\n",
      "Epoch: 1289 cost = 0.016962968\n",
      "Validation Loss: 0.02339088\n",
      "Epoch: 1290 cost = 0.016954251\n",
      "Validation Loss: 0.026446568\n",
      "Epoch: 1291 cost = 0.016944846\n",
      "Validation Loss: 0.026023818\n",
      "Epoch: 1292 cost = 0.016935982\n",
      "Validation Loss: 0.028890232\n",
      "Epoch: 1293 cost = 0.016926692\n",
      "Validation Loss: 0.032095987\n",
      "Epoch: 1294 cost = 0.016917526\n",
      "Validation Loss: 0.023954665\n",
      "Epoch: 1295 cost = 0.016908517\n",
      "Validation Loss: 0.036875874\n",
      "Epoch: 1296 cost = 0.016899460\n",
      "Validation Loss: 0.033605754\n",
      "Epoch: 1297 cost = 0.016890126\n",
      "Validation Loss: 0.026861142\n",
      "Epoch: 1298 cost = 0.016881277\n",
      "Validation Loss: 0.027000409\n",
      "Epoch: 1299 cost = 0.016872185\n",
      "Validation Loss: 0.029959204\n",
      "Epoch: 1300 cost = 0.016863090\n",
      "Validation Loss: 0.025769405\n",
      "Epoch: 1301 cost = 0.016854250\n",
      "Validation Loss: 0.025588466\n",
      "Epoch: 1302 cost = 0.016845359\n",
      "Validation Loss: 0.02707883\n",
      "Epoch: 1303 cost = 0.016836383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.028437193\n",
      "Epoch: 1304 cost = 0.016827197\n",
      "Validation Loss: 0.02882946\n",
      "Epoch: 1305 cost = 0.016818181\n",
      "Validation Loss: 0.030063992\n",
      "Epoch: 1306 cost = 0.016809406\n",
      "Validation Loss: 0.03509594\n",
      "Epoch: 1307 cost = 0.016800439\n",
      "Validation Loss: 0.032028586\n",
      "Epoch: 1308 cost = 0.016791412\n",
      "Validation Loss: 0.030654851\n",
      "Epoch: 1309 cost = 0.016783034\n",
      "Validation Loss: 0.03655473\n",
      "Epoch: 1310 cost = 0.016773790\n",
      "Validation Loss: 0.03734985\n",
      "Epoch: 1311 cost = 0.016765155\n",
      "Validation Loss: 0.036230367\n",
      "Epoch: 1312 cost = 0.016756288\n",
      "Validation Loss: 0.050993532\n",
      "Epoch: 1313 cost = 0.016747622\n",
      "Validation Loss: 0.053751048\n",
      "Epoch: 1314 cost = 0.016738340\n",
      "Validation Loss: 0.059759814\n",
      "Epoch: 1315 cost = 0.016730034\n",
      "Validation Loss: 0.04320833\n",
      "Epoch: 1316 cost = 0.016720861\n",
      "Validation Loss: 0.02608915\n",
      "Epoch: 1317 cost = 0.016712215\n",
      "Validation Loss: 0.022050746\n",
      "Epoch: 1318 cost = 0.016703327\n",
      "Validation Loss: 0.018941449\n",
      "Epoch: 1319 cost = 0.016694654\n",
      "Validation Loss: 0.027638778\n",
      "Epoch: 1320 cost = 0.016686156\n",
      "Validation Loss: 0.02252275\n",
      "Epoch: 1321 cost = 0.016677406\n",
      "Validation Loss: 0.017312054\n",
      "Epoch: 1322 cost = 0.016668364\n",
      "Validation Loss: 0.026825929\n",
      "Epoch: 1323 cost = 0.016659763\n",
      "Validation Loss: 0.02211754\n",
      "Epoch: 1324 cost = 0.016651111\n",
      "Validation Loss: 0.022538932\n",
      "Epoch: 1325 cost = 0.016642330\n",
      "Validation Loss: 0.031214084\n",
      "Epoch: 1326 cost = 0.016634077\n",
      "Validation Loss: 0.029397197\n",
      "Epoch: 1327 cost = 0.016625248\n",
      "Validation Loss: 0.036022153\n",
      "Epoch: 1328 cost = 0.016616529\n",
      "Validation Loss: 0.03367268\n",
      "Epoch: 1329 cost = 0.016607903\n",
      "Validation Loss: 0.02917999\n",
      "Epoch: 1330 cost = 0.016599374\n",
      "Validation Loss: 0.04220806\n",
      "Epoch: 1331 cost = 0.016590983\n",
      "Validation Loss: 0.03843627\n",
      "Epoch: 1332 cost = 0.016582549\n",
      "Validation Loss: 0.03336\n",
      "Epoch: 1333 cost = 0.016573974\n",
      "Validation Loss: 0.0350745\n",
      "Epoch: 1334 cost = 0.016565493\n",
      "Validation Loss: 0.03140629\n",
      "Epoch: 1335 cost = 0.016556823\n",
      "Validation Loss: 0.033022746\n",
      "Epoch: 1336 cost = 0.016548047\n",
      "Validation Loss: 0.032807123\n",
      "Epoch: 1337 cost = 0.016539617\n",
      "Validation Loss: 0.023261053\n",
      "Epoch: 1338 cost = 0.016531350\n",
      "Validation Loss: 0.018313555\n",
      "Epoch: 1339 cost = 0.016522864\n",
      "Validation Loss: 0.02270331\n",
      "Epoch: 1340 cost = 0.016514466\n",
      "Validation Loss: 0.025077851\n",
      "Epoch: 1341 cost = 0.016505707\n",
      "Validation Loss: 0.02731195\n",
      "Epoch: 1342 cost = 0.016497571\n",
      "Validation Loss: 0.036741253\n",
      "Epoch: 1343 cost = 0.016489288\n",
      "Validation Loss: 0.026504917\n",
      "Epoch: 1344 cost = 0.016481036\n",
      "Validation Loss: 0.019919071\n",
      "Epoch: 1345 cost = 0.016472511\n",
      "Validation Loss: 0.021670438\n",
      "Epoch: 1346 cost = 0.016463977\n",
      "Validation Loss: 0.024310125\n",
      "Epoch: 1347 cost = 0.016455812\n",
      "Validation Loss: 0.027153147\n",
      "Epoch: 1348 cost = 0.016447478\n",
      "Validation Loss: 0.03240184\n",
      "Epoch: 1349 cost = 0.016439639\n",
      "Validation Loss: 0.033857543\n",
      "Epoch: 1350 cost = 0.016430961\n",
      "Validation Loss: 0.037926454\n",
      "Epoch: 1351 cost = 0.016423081\n",
      "Validation Loss: 0.050722938\n",
      "Epoch: 1352 cost = 0.016414818\n",
      "Validation Loss: 0.04213379\n",
      "Epoch: 1353 cost = 0.016406591\n",
      "Validation Loss: 0.035887863\n",
      "Epoch: 1354 cost = 0.016398208\n",
      "Validation Loss: 0.03144296\n",
      "Epoch: 1355 cost = 0.016390394\n",
      "Validation Loss: 0.031166563\n",
      "Epoch: 1356 cost = 0.016381977\n",
      "Validation Loss: 0.038450327\n",
      "Epoch: 1357 cost = 0.016373857\n",
      "Validation Loss: 0.039349012\n",
      "Epoch: 1358 cost = 0.016366065\n",
      "Validation Loss: 0.041120633\n",
      "Epoch: 1359 cost = 0.016357747\n",
      "Validation Loss: 0.04826346\n",
      "Epoch: 1360 cost = 0.016349554\n",
      "Validation Loss: 0.041234095\n",
      "Epoch: 1361 cost = 0.016342105\n",
      "Validation Loss: 0.043326814\n",
      "Epoch: 1362 cost = 0.016334024\n",
      "Validation Loss: 0.024609568\n",
      "Epoch: 1363 cost = 0.016325783\n",
      "Validation Loss: 0.019259969\n",
      "Epoch: 1364 cost = 0.016318110\n",
      "Validation Loss: 0.02199846\n",
      "Epoch: 1365 cost = 0.016310030\n",
      "Validation Loss: 0.024323344\n",
      "Epoch: 1366 cost = 0.016302180\n",
      "Validation Loss: 0.020401778\n",
      "Epoch: 1367 cost = 0.016294459\n",
      "Validation Loss: 0.034169484\n",
      "Epoch: 1368 cost = 0.016286296\n",
      "Validation Loss: 0.04572335\n",
      "Epoch: 1369 cost = 0.016278439\n",
      "Validation Loss: 0.056770403\n",
      "Epoch: 1370 cost = 0.016270816\n",
      "Validation Loss: 0.055755373\n",
      "Epoch: 1371 cost = 0.016262961\n",
      "Validation Loss: 0.059644323\n",
      "Epoch: 1372 cost = 0.016255263\n",
      "Validation Loss: 0.06555205\n",
      "Epoch: 1373 cost = 0.016247369\n",
      "Validation Loss: 0.053224456\n",
      "Epoch: 1374 cost = 0.016240071\n",
      "Validation Loss: 0.041854054\n",
      "Epoch: 1375 cost = 0.016232285\n",
      "Validation Loss: 0.019559147\n",
      "Epoch: 1376 cost = 0.016224469\n",
      "Validation Loss: 0.019294364\n",
      "Epoch: 1377 cost = 0.016217133\n",
      "Validation Loss: 0.024605688\n",
      "Epoch: 1378 cost = 0.016209180\n",
      "Validation Loss: 0.02550641\n",
      "Epoch: 1379 cost = 0.016201791\n",
      "Validation Loss: 0.028894568\n",
      "Epoch: 1380 cost = 0.016194310\n",
      "Validation Loss: 0.02576622\n",
      "Epoch: 1381 cost = 0.016186784\n",
      "Validation Loss: 0.020104485\n",
      "Epoch: 1382 cost = 0.016179211\n",
      "Validation Loss: 0.036854714\n",
      "Epoch: 1383 cost = 0.016171634\n",
      "Validation Loss: 0.06280046\n",
      "Epoch: 1384 cost = 0.016164359\n",
      "Validation Loss: 0.060737606\n",
      "Epoch: 1385 cost = 0.016156963\n",
      "Validation Loss: 0.05851815\n",
      "Epoch: 1386 cost = 0.016149597\n",
      "Validation Loss: 0.051762745\n",
      "Epoch: 1387 cost = 0.016142297\n",
      "Validation Loss: 0.03953268\n",
      "Epoch: 1388 cost = 0.016134964\n",
      "Validation Loss: 0.03511804\n",
      "Epoch: 1389 cost = 0.016127434\n",
      "Validation Loss: 0.03513766\n",
      "Epoch: 1390 cost = 0.016119764\n",
      "Validation Loss: 0.025427286\n",
      "Epoch: 1391 cost = 0.016112726\n",
      "Validation Loss: 0.018967258\n",
      "Epoch: 1392 cost = 0.016105516\n",
      "Validation Loss: 0.032458644\n",
      "Epoch: 1393 cost = 0.016098565\n",
      "Validation Loss: 0.034696117\n",
      "Epoch: 1394 cost = 0.016090814\n",
      "Validation Loss: 0.031840928\n",
      "Epoch: 1395 cost = 0.016084070\n",
      "Validation Loss: 0.039267827\n",
      "Epoch: 1396 cost = 0.016076964\n",
      "Validation Loss: 0.043614767\n",
      "Epoch: 1397 cost = 0.016069865\n",
      "Validation Loss: 0.027324362\n",
      "Epoch: 1398 cost = 0.016062535\n",
      "Validation Loss: 0.023296006\n",
      "Epoch: 1399 cost = 0.016055456\n",
      "Validation Loss: 0.02400252\n",
      "Epoch: 1400 cost = 0.016048333\n",
      "Validation Loss: 0.025282966\n",
      "Epoch: 1401 cost = 0.016041421\n",
      "Validation Loss: 0.030861337\n",
      "Epoch: 1402 cost = 0.016034165\n",
      "Validation Loss: 0.03885982\n",
      "Epoch: 1403 cost = 0.016027319\n",
      "Validation Loss: 0.03640132\n",
      "Epoch: 1404 cost = 0.016020578\n",
      "Validation Loss: 0.036041375\n",
      "Epoch: 1405 cost = 0.016013442\n",
      "Validation Loss: 0.025156498\n",
      "Epoch: 1406 cost = 0.016006227\n",
      "Validation Loss: 0.021498805\n",
      "Epoch: 1407 cost = 0.015999313\n",
      "Validation Loss: 0.026533913\n",
      "Epoch: 1408 cost = 0.015992643\n",
      "Validation Loss: 0.030020045\n",
      "Epoch: 1409 cost = 0.015985686\n",
      "Validation Loss: 0.03360552\n",
      "Epoch: 1410 cost = 0.015979003\n",
      "Validation Loss: 0.042233523\n",
      "Epoch: 1411 cost = 0.015972166\n",
      "Validation Loss: 0.036047537\n",
      "Epoch: 1412 cost = 0.015965406\n",
      "Validation Loss: 0.02751459\n",
      "Epoch: 1413 cost = 0.015958403\n",
      "Validation Loss: 0.020960232\n",
      "Epoch: 1414 cost = 0.015951668\n",
      "Validation Loss: 0.0350779\n",
      "Epoch: 1415 cost = 0.015945061\n",
      "Validation Loss: 0.052162543\n",
      "Epoch: 1416 cost = 0.015938289\n",
      "Validation Loss: 0.051374316\n",
      "Epoch: 1417 cost = 0.015931548\n",
      "Validation Loss: 0.03563959\n",
      "Epoch: 1418 cost = 0.015924990\n",
      "Validation Loss: 0.01917193\n",
      "Epoch: 1419 cost = 0.015918298\n",
      "Validation Loss: 0.030283967\n",
      "Epoch: 1420 cost = 0.015911929\n",
      "Validation Loss: 0.028594028\n",
      "Epoch: 1421 cost = 0.015905478\n",
      "Validation Loss: 0.022069618\n",
      "Epoch: 1422 cost = 0.015898883\n",
      "Validation Loss: 0.033622343\n",
      "Epoch: 1423 cost = 0.015891839\n",
      "Validation Loss: 0.034608953\n",
      "Epoch: 1424 cost = 0.015885182\n",
      "Validation Loss: 0.023953456\n",
      "Epoch: 1425 cost = 0.015878896\n",
      "Validation Loss: 0.022466572\n",
      "Epoch: 1426 cost = 0.015872286\n",
      "Validation Loss: 0.029186515\n",
      "Epoch: 1427 cost = 0.015865763\n",
      "Validation Loss: 0.038938485\n",
      "Epoch: 1428 cost = 0.015859242\n",
      "Validation Loss: 0.05040729\n",
      "Epoch: 1429 cost = 0.015852542\n",
      "Validation Loss: 0.042683467\n",
      "Epoch: 1430 cost = 0.015846323\n",
      "Validation Loss: 0.03914062\n",
      "Epoch: 1431 cost = 0.015839598\n",
      "Validation Loss: 0.03118097\n",
      "Epoch: 1432 cost = 0.015833654\n",
      "Validation Loss: 0.036560006\n",
      "Epoch: 1433 cost = 0.015827031\n",
      "Validation Loss: 0.04136329\n",
      "Epoch: 1434 cost = 0.015820542\n",
      "Validation Loss: 0.057756342\n",
      "Epoch: 1435 cost = 0.015814070\n",
      "Validation Loss: 0.048461545\n",
      "Epoch: 1436 cost = 0.015807932\n",
      "Validation Loss: 0.031919595\n",
      "Epoch: 1437 cost = 0.015801495\n",
      "Validation Loss: 0.028268356\n",
      "Epoch: 1438 cost = 0.015795832\n",
      "Validation Loss: 0.018954791\n",
      "Epoch: 1439 cost = 0.015788757\n",
      "Validation Loss: 0.020894008\n",
      "Epoch: 1440 cost = 0.015782633\n",
      "Validation Loss: 0.018346135\n",
      "Epoch: 1441 cost = 0.015776418\n",
      "Validation Loss: 0.023838092\n",
      "Epoch: 1442 cost = 0.015769889\n",
      "Validation Loss: 0.03820033\n",
      "Epoch: 1443 cost = 0.015763738\n",
      "Validation Loss: 0.04831068\n",
      "Epoch: 1444 cost = 0.015757716\n",
      "Validation Loss: 0.03945487\n",
      "Epoch: 1445 cost = 0.015751276\n",
      "Validation Loss: 0.018233825\n",
      "Epoch: 1446 cost = 0.015745205\n",
      "Validation Loss: 0.017297534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1447 cost = 0.015739011\n",
      "Validation Loss: 0.038810883\n",
      "Epoch: 1448 cost = 0.015732696\n",
      "Validation Loss: 0.03270605\n",
      "Epoch: 1449 cost = 0.015726410\n",
      "Validation Loss: 0.03677606\n",
      "Epoch: 1450 cost = 0.015720620\n",
      "Validation Loss: 0.03152517\n",
      "Epoch: 1451 cost = 0.015714245\n",
      "Validation Loss: 0.033525225\n",
      "Epoch: 1452 cost = 0.015708006\n",
      "Validation Loss: 0.039755628\n",
      "Epoch: 1453 cost = 0.015701948\n",
      "Validation Loss: 0.028573137\n",
      "Epoch: 1454 cost = 0.015695890\n",
      "Validation Loss: 0.025204653\n",
      "Epoch: 1455 cost = 0.015689795\n",
      "Validation Loss: 0.043469656\n",
      "Epoch: 1456 cost = 0.015684126\n",
      "Validation Loss: 0.05489269\n",
      "Epoch: 1457 cost = 0.015677802\n",
      "Validation Loss: 0.049266055\n",
      "Epoch: 1458 cost = 0.015671763\n",
      "Validation Loss: 0.0411977\n",
      "Epoch: 1459 cost = 0.015665439\n",
      "Validation Loss: 0.033427935\n",
      "Epoch: 1460 cost = 0.015659841\n",
      "Validation Loss: 0.034421634\n",
      "Epoch: 1461 cost = 0.015653708\n",
      "Validation Loss: 0.036362447\n",
      "Epoch: 1462 cost = 0.015647760\n",
      "Validation Loss: 0.03271949\n",
      "Epoch: 1463 cost = 0.015641624\n",
      "Validation Loss: 0.023463732\n",
      "Epoch: 1464 cost = 0.015635699\n",
      "Validation Loss: 0.026845278\n",
      "Epoch: 1465 cost = 0.015629569\n",
      "Validation Loss: 0.023374679\n",
      "Epoch: 1466 cost = 0.015623999\n",
      "Validation Loss: 0.020844258\n",
      "Epoch: 1467 cost = 0.015618002\n",
      "Validation Loss: 0.023739306\n",
      "Epoch: 1468 cost = 0.015612316\n",
      "Validation Loss: 0.019914899\n",
      "Epoch: 1469 cost = 0.015605945\n",
      "Validation Loss: 0.023217443\n",
      "Epoch: 1470 cost = 0.015600377\n",
      "Validation Loss: 0.026213428\n",
      "Epoch: 1471 cost = 0.015594547\n",
      "Validation Loss: 0.02420511\n",
      "Epoch: 1472 cost = 0.015588369\n",
      "Validation Loss: 0.029142873\n",
      "Epoch: 1473 cost = 0.015582660\n",
      "Validation Loss: 0.029736867\n",
      "Epoch: 1474 cost = 0.015576813\n",
      "Validation Loss: 0.036055144\n",
      "Epoch: 1475 cost = 0.015571259\n",
      "Validation Loss: 0.03903294\n",
      "Epoch: 1476 cost = 0.015565354\n",
      "Validation Loss: 0.035514675\n",
      "Epoch: 1477 cost = 0.015559531\n",
      "Validation Loss: 0.036737695\n",
      "Epoch: 1478 cost = 0.015553763\n",
      "Validation Loss: 0.042272393\n",
      "Epoch: 1479 cost = 0.015548015\n",
      "Validation Loss: 0.0403379\n",
      "Epoch: 1480 cost = 0.015542390\n",
      "Validation Loss: 0.029017117\n",
      "Epoch: 1481 cost = 0.015536634\n",
      "Validation Loss: 0.026252326\n",
      "Epoch: 1482 cost = 0.015530944\n",
      "Validation Loss: 0.02429844\n",
      "Epoch: 1483 cost = 0.015524959\n",
      "Validation Loss: 0.030378832\n",
      "Epoch: 1484 cost = 0.015519678\n",
      "Validation Loss: 0.03594849\n",
      "Epoch: 1485 cost = 0.015513424\n",
      "Validation Loss: 0.032762304\n",
      "Epoch: 1486 cost = 0.015507976\n",
      "Validation Loss: 0.027965866\n",
      "Epoch: 1487 cost = 0.015502026\n",
      "Validation Loss: 0.02653401\n",
      "Epoch: 1488 cost = 0.015496586\n",
      "Validation Loss: 0.023539847\n",
      "Epoch: 1489 cost = 0.015491043\n",
      "Validation Loss: 0.02375972\n",
      "Epoch: 1490 cost = 0.015485333\n",
      "Validation Loss: 0.029803481\n",
      "Epoch: 1491 cost = 0.015479970\n",
      "Validation Loss: 0.030162202\n",
      "Epoch: 1492 cost = 0.015474196\n",
      "Validation Loss: 0.029840074\n",
      "Epoch: 1493 cost = 0.015468584\n",
      "Validation Loss: 0.019594733\n",
      "Epoch: 1494 cost = 0.015463157\n",
      "Validation Loss: 0.024845663\n",
      "Epoch: 1495 cost = 0.015457384\n",
      "Validation Loss: 0.024623415\n",
      "Epoch: 1496 cost = 0.015451899\n",
      "Validation Loss: 0.021962266\n",
      "Epoch: 1497 cost = 0.015446493\n",
      "Validation Loss: 0.031041011\n",
      "Epoch: 1498 cost = 0.015440603\n",
      "Validation Loss: 0.025139049\n",
      "Epoch: 1499 cost = 0.015435520\n",
      "Validation Loss: 0.035247397\n",
      "Epoch: 1500 cost = 0.015430069\n",
      "Validation Loss: 0.046339784\n",
      "Epoch: 1501 cost = 0.015424151\n",
      "Validation Loss: 0.036513302\n",
      "Epoch: 1502 cost = 0.015418810\n",
      "Validation Loss: 0.03306955\n",
      "Epoch: 1503 cost = 0.015413543\n",
      "Validation Loss: 0.024442209\n",
      "Epoch: 1504 cost = 0.015408172\n",
      "Validation Loss: 0.031311322\n",
      "Epoch: 1505 cost = 0.015402622\n",
      "Validation Loss: 0.02666439\n",
      "Epoch: 1506 cost = 0.015397164\n",
      "Validation Loss: 0.03030813\n",
      "Epoch: 1507 cost = 0.015391823\n",
      "Validation Loss: 0.04109496\n",
      "Epoch: 1508 cost = 0.015386454\n",
      "Validation Loss: 0.04229664\n",
      "Epoch: 1509 cost = 0.015380726\n",
      "Validation Loss: 0.028495762\n",
      "Epoch: 1510 cost = 0.015375852\n",
      "Validation Loss: 0.025185725\n",
      "Epoch: 1511 cost = 0.015370250\n",
      "Validation Loss: 0.025639057\n",
      "Epoch: 1512 cost = 0.015364992\n",
      "Validation Loss: 0.034943324\n",
      "Epoch: 1513 cost = 0.015359668\n",
      "Validation Loss: 0.037071146\n",
      "Epoch: 1514 cost = 0.015354217\n",
      "Validation Loss: 0.028699296\n",
      "Epoch: 1515 cost = 0.015348820\n",
      "Validation Loss: 0.025363242\n",
      "Epoch: 1516 cost = 0.015344041\n",
      "Validation Loss: 0.031551957\n",
      "Epoch: 1517 cost = 0.015338306\n",
      "Validation Loss: 0.03537173\n",
      "Epoch: 1518 cost = 0.015333060\n",
      "Validation Loss: 0.028216684\n",
      "Epoch: 1519 cost = 0.015327881\n",
      "Validation Loss: 0.017701676\n",
      "Epoch: 1520 cost = 0.015322686\n",
      "Validation Loss: 0.020201042\n",
      "Epoch: 1521 cost = 0.015317530\n",
      "Validation Loss: 0.03170098\n",
      "Epoch: 1522 cost = 0.015312170\n",
      "Validation Loss: 0.027770692\n",
      "Epoch: 1523 cost = 0.015306966\n",
      "Validation Loss: 0.025350004\n",
      "Epoch: 1524 cost = 0.015301702\n",
      "Validation Loss: 0.02395595\n",
      "Epoch: 1525 cost = 0.015296839\n",
      "Validation Loss: 0.031039782\n",
      "Epoch: 1526 cost = 0.015291200\n",
      "Validation Loss: 0.031670082\n",
      "Epoch: 1527 cost = 0.015286353\n",
      "Validation Loss: 0.036380112\n",
      "Epoch: 1528 cost = 0.015281515\n",
      "Validation Loss: 0.04239885\n",
      "Epoch: 1529 cost = 0.015276246\n",
      "Validation Loss: 0.04034299\n",
      "Epoch: 1530 cost = 0.015271308\n",
      "Validation Loss: 0.03593645\n",
      "Epoch: 1531 cost = 0.015266228\n",
      "Validation Loss: 0.033284772\n",
      "Epoch: 1532 cost = 0.015260969\n",
      "Validation Loss: 0.027382141\n",
      "Epoch: 1533 cost = 0.015255833\n",
      "Validation Loss: 0.020395767\n",
      "Epoch: 1534 cost = 0.015250870\n",
      "Validation Loss: 0.026185539\n",
      "Epoch: 1535 cost = 0.015246048\n",
      "Validation Loss: 0.02399944\n",
      "Epoch: 1536 cost = 0.015240860\n",
      "Validation Loss: 0.030503577\n",
      "Epoch: 1537 cost = 0.015235924\n",
      "Validation Loss: 0.03955468\n",
      "Epoch: 1538 cost = 0.015231335\n",
      "Validation Loss: 0.042939764\n",
      "Epoch: 1539 cost = 0.015225989\n",
      "Validation Loss: 0.03637039\n",
      "Epoch: 1540 cost = 0.015221032\n",
      "Validation Loss: 0.027662838\n",
      "Epoch: 1541 cost = 0.015215943\n",
      "Validation Loss: 0.024887653\n",
      "Epoch: 1542 cost = 0.015210967\n",
      "Validation Loss: 0.026792688\n",
      "Epoch: 1543 cost = 0.015206453\n",
      "Validation Loss: 0.030575447\n",
      "Epoch: 1544 cost = 0.015201486\n",
      "Validation Loss: 0.039377883\n",
      "Epoch: 1545 cost = 0.015196597\n",
      "Validation Loss: 0.047482003\n",
      "Epoch: 1546 cost = 0.015191962\n",
      "Validation Loss: 0.047333077\n",
      "Epoch: 1547 cost = 0.015186665\n",
      "Validation Loss: 0.04175457\n",
      "Epoch: 1548 cost = 0.015181640\n",
      "Validation Loss: 0.030007206\n",
      "Epoch: 1549 cost = 0.015176593\n",
      "Validation Loss: 0.027704485\n",
      "Epoch: 1550 cost = 0.015171947\n",
      "Validation Loss: 0.027207471\n",
      "Epoch: 1551 cost = 0.015167327\n",
      "Validation Loss: 0.029481834\n",
      "Epoch: 1552 cost = 0.015162568\n",
      "Validation Loss: 0.033020824\n",
      "Epoch: 1553 cost = 0.015157751\n",
      "Validation Loss: 0.032692697\n",
      "Epoch: 1554 cost = 0.015152827\n",
      "Validation Loss: 0.01958253\n",
      "Epoch: 1555 cost = 0.015148222\n",
      "Validation Loss: 0.020075662\n",
      "Epoch: 1556 cost = 0.015143490\n",
      "Validation Loss: 0.023501648\n",
      "Epoch: 1557 cost = 0.015138736\n",
      "Validation Loss: 0.025508564\n",
      "Epoch: 1558 cost = 0.015134363\n",
      "Validation Loss: 0.03468948\n",
      "Epoch: 1559 cost = 0.015129028\n",
      "Validation Loss: 0.037488274\n",
      "Epoch: 1560 cost = 0.015124703\n",
      "Validation Loss: 0.03322763\n",
      "Epoch: 1561 cost = 0.015119884\n",
      "Validation Loss: 0.026049959\n",
      "Epoch: 1562 cost = 0.015115385\n",
      "Validation Loss: 0.018599456\n",
      "Epoch: 1563 cost = 0.015110589\n",
      "Validation Loss: 0.016282585\n",
      "Epoch: 1564 cost = 0.015106030\n",
      "Validation Loss: 0.026760107\n",
      "Epoch: 1565 cost = 0.015101482\n",
      "Validation Loss: 0.021307912\n",
      "Epoch: 1566 cost = 0.015097008\n",
      "Validation Loss: 0.030224986\n",
      "Epoch: 1567 cost = 0.015092293\n",
      "Validation Loss: 0.03353065\n",
      "Epoch: 1568 cost = 0.015087617\n",
      "Validation Loss: 0.03475615\n",
      "Epoch: 1569 cost = 0.015083293\n",
      "Validation Loss: 0.041799307\n",
      "Epoch: 1570 cost = 0.015078652\n",
      "Validation Loss: 0.04941138\n",
      "Epoch: 1571 cost = 0.015073966\n",
      "Validation Loss: 0.050270174\n",
      "Epoch: 1572 cost = 0.015069348\n",
      "Validation Loss: 0.03745863\n",
      "Epoch: 1573 cost = 0.015064817\n",
      "Validation Loss: 0.032091804\n",
      "Epoch: 1574 cost = 0.015060508\n",
      "Validation Loss: 0.022129422\n",
      "Epoch: 1575 cost = 0.015056102\n",
      "Validation Loss: 0.022031687\n",
      "Epoch: 1576 cost = 0.015051422\n",
      "Validation Loss: 0.0283962\n",
      "Epoch: 1577 cost = 0.015047247\n",
      "Validation Loss: 0.030541632\n",
      "Epoch: 1578 cost = 0.015042467\n",
      "Validation Loss: 0.039313857\n",
      "Epoch: 1579 cost = 0.015037914\n",
      "Validation Loss: 0.024917547\n",
      "Epoch: 1580 cost = 0.015033861\n",
      "Validation Loss: 0.023073226\n",
      "Epoch: 1581 cost = 0.015029333\n",
      "Validation Loss: 0.025468409\n",
      "Epoch: 1582 cost = 0.015024919\n",
      "Validation Loss: 0.025566338\n",
      "Epoch: 1583 cost = 0.015020473\n",
      "Validation Loss: 0.017793398\n",
      "Epoch: 1584 cost = 0.015015855\n",
      "Validation Loss: 0.021720665\n",
      "Epoch: 1585 cost = 0.015011602\n",
      "Validation Loss: 0.025057152\n",
      "Epoch: 1586 cost = 0.015007276\n",
      "Validation Loss: 0.037528995\n",
      "Epoch: 1587 cost = 0.015002965\n",
      "Validation Loss: 0.03423717\n",
      "Epoch: 1588 cost = 0.014998807\n",
      "Validation Loss: 0.035797298\n",
      "Epoch: 1589 cost = 0.014994617\n",
      "Validation Loss: 0.035338063\n",
      "Epoch: 1590 cost = 0.014990163\n",
      "Validation Loss: 0.029428624\n",
      "Epoch: 1591 cost = 0.014985918\n",
      "Validation Loss: 0.025432054\n",
      "Epoch: 1592 cost = 0.014981591\n",
      "Validation Loss: 0.024580022\n",
      "Epoch: 1593 cost = 0.014977236\n",
      "Validation Loss: 0.033047795\n",
      "Epoch: 1594 cost = 0.014972958\n",
      "Validation Loss: 0.036823012\n",
      "Epoch: 1595 cost = 0.014969071\n",
      "Validation Loss: 0.033102274\n",
      "Epoch: 1596 cost = 0.014964735\n",
      "Validation Loss: 0.029382532\n",
      "Epoch: 1597 cost = 0.014960542\n",
      "Validation Loss: 0.03069816\n",
      "Epoch: 1598 cost = 0.014956301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.040463224\n",
      "Epoch: 1599 cost = 0.014952342\n",
      "Validation Loss: 0.04933155\n",
      "Epoch: 1600 cost = 0.014947858\n",
      "Validation Loss: 0.046905316\n",
      "Epoch: 1601 cost = 0.014943936\n",
      "Validation Loss: 0.03618137\n",
      "Epoch: 1602 cost = 0.014939672\n",
      "Validation Loss: 0.027411385\n",
      "Epoch: 1603 cost = 0.014935494\n",
      "Validation Loss: 0.033354256\n",
      "Epoch: 1604 cost = 0.014931342\n",
      "Validation Loss: 0.03944077\n",
      "Epoch: 1605 cost = 0.014927370\n",
      "Validation Loss: 0.034702223\n",
      "Epoch: 1606 cost = 0.014923376\n",
      "Validation Loss: 0.020344969\n",
      "Epoch: 1607 cost = 0.014919055\n",
      "Validation Loss: 0.0218647\n",
      "Epoch: 1608 cost = 0.014915133\n",
      "Validation Loss: 0.02457411\n",
      "Epoch: 1609 cost = 0.014911088\n",
      "Validation Loss: 0.028503243\n",
      "Epoch: 1610 cost = 0.014907153\n",
      "Validation Loss: 0.026311267\n",
      "Epoch: 1611 cost = 0.014902206\n",
      "Validation Loss: 0.037190244\n",
      "Epoch: 1612 cost = 0.014899015\n",
      "Validation Loss: 0.038504265\n",
      "Epoch: 1613 cost = 0.014894934\n",
      "Validation Loss: 0.029833097\n",
      "Epoch: 1614 cost = 0.014891024\n",
      "Validation Loss: 0.018922344\n",
      "Epoch: 1615 cost = 0.014887060\n",
      "Validation Loss: 0.023642067\n",
      "Epoch: 1616 cost = 0.014882977\n",
      "Validation Loss: 0.036614284\n",
      "Epoch: 1617 cost = 0.014878677\n",
      "Validation Loss: 0.041584704\n",
      "Epoch: 1618 cost = 0.014875186\n",
      "Validation Loss: 0.04520517\n",
      "Epoch: 1619 cost = 0.014871162\n",
      "Validation Loss: 0.02865033\n",
      "Epoch: 1620 cost = 0.014867556\n",
      "Validation Loss: 0.027304927\n",
      "Epoch: 1621 cost = 0.014863527\n",
      "Validation Loss: 0.016890882\n",
      "Epoch: 1622 cost = 0.014859595\n",
      "Validation Loss: 0.023256784\n",
      "Epoch: 1623 cost = 0.014855670\n",
      "Validation Loss: 0.027495075\n",
      "Epoch: 1624 cost = 0.014852233\n",
      "Validation Loss: 0.02370683\n",
      "Epoch: 1625 cost = 0.014847669\n",
      "Validation Loss: 0.027121346\n",
      "Epoch: 1626 cost = 0.014843690\n",
      "Validation Loss: 0.0237915\n",
      "Epoch: 1627 cost = 0.014840613\n",
      "Validation Loss: 0.03135997\n",
      "Epoch: 1628 cost = 0.014836776\n",
      "Validation Loss: 0.03440663\n",
      "Epoch: 1629 cost = 0.014832570\n",
      "Validation Loss: 0.032893885\n",
      "Epoch: 1630 cost = 0.014829204\n",
      "Validation Loss: 0.032296147\n",
      "Epoch: 1631 cost = 0.014825612\n",
      "Validation Loss: 0.034042414\n",
      "Epoch: 1632 cost = 0.014821488\n",
      "Validation Loss: 0.031026322\n",
      "Epoch: 1633 cost = 0.014817407\n",
      "Validation Loss: 0.033530343\n",
      "Epoch: 1634 cost = 0.014813851\n",
      "Validation Loss: 0.030049713\n",
      "Epoch: 1635 cost = 0.014810206\n",
      "Validation Loss: 0.03147386\n",
      "Epoch: 1636 cost = 0.014806334\n",
      "Validation Loss: 0.026275687\n",
      "Epoch: 1637 cost = 0.014802450\n",
      "Validation Loss: 0.0225774\n",
      "Epoch: 1638 cost = 0.014798579\n",
      "Validation Loss: 0.024032027\n",
      "Epoch: 1639 cost = 0.014795301\n",
      "Validation Loss: 0.02525385\n",
      "Epoch: 1640 cost = 0.014791453\n",
      "Validation Loss: 0.026659057\n",
      "Epoch: 1641 cost = 0.014787536\n",
      "Validation Loss: 0.03384725\n",
      "Epoch: 1642 cost = 0.014784596\n",
      "Validation Loss: 0.030138286\n",
      "Epoch: 1643 cost = 0.014780541\n",
      "Validation Loss: 0.02968266\n",
      "Epoch: 1644 cost = 0.014777500\n",
      "Validation Loss: 0.03450472\n",
      "Epoch: 1645 cost = 0.014773444\n",
      "Validation Loss: 0.029345408\n",
      "Epoch: 1646 cost = 0.014769844\n",
      "Validation Loss: 0.021310125\n",
      "Epoch: 1647 cost = 0.014766195\n",
      "Validation Loss: 0.028487327\n",
      "Epoch: 1648 cost = 0.014762398\n",
      "Validation Loss: 0.03698525\n",
      "Epoch: 1649 cost = 0.014758940\n",
      "Validation Loss: 0.040435396\n",
      "Epoch: 1650 cost = 0.014755713\n",
      "Validation Loss: 0.038645465\n",
      "Epoch: 1651 cost = 0.014752016\n",
      "Validation Loss: 0.038239844\n",
      "Epoch: 1652 cost = 0.014748508\n",
      "Validation Loss: 0.03181598\n",
      "Epoch: 1653 cost = 0.014744805\n",
      "Validation Loss: 0.038657542\n",
      "Epoch: 1654 cost = 0.014741348\n",
      "Validation Loss: 0.033065557\n",
      "Epoch: 1655 cost = 0.014737982\n",
      "Validation Loss: 0.02277083\n",
      "Epoch: 1656 cost = 0.014734281\n",
      "Validation Loss: 0.02102859\n",
      "Epoch: 1657 cost = 0.014730886\n",
      "Validation Loss: 0.02881064\n",
      "Epoch: 1658 cost = 0.014727609\n",
      "Validation Loss: 0.02374643\n",
      "Epoch: 1659 cost = 0.014724333\n",
      "Validation Loss: 0.027378717\n",
      "Epoch: 1660 cost = 0.014720628\n",
      "Validation Loss: 0.040002614\n",
      "Epoch: 1661 cost = 0.014717112\n",
      "Validation Loss: 0.043538388\n",
      "Epoch: 1662 cost = 0.014713836\n",
      "Validation Loss: 0.037995193\n",
      "Epoch: 1663 cost = 0.014710178\n",
      "Validation Loss: 0.026713237\n",
      "Epoch: 1664 cost = 0.014707163\n",
      "Validation Loss: 0.028344195\n",
      "Epoch: 1665 cost = 0.014703517\n",
      "Validation Loss: 0.025462484\n",
      "Epoch: 1666 cost = 0.014700013\n",
      "Validation Loss: 0.029579395\n",
      "Epoch: 1667 cost = 0.014697198\n",
      "Validation Loss: 0.029130632\n",
      "Epoch: 1668 cost = 0.014693615\n",
      "Validation Loss: 0.030902574\n",
      "Epoch: 1669 cost = 0.014690143\n",
      "Validation Loss: 0.036801897\n",
      "Epoch: 1670 cost = 0.014686833\n",
      "Validation Loss: 0.040797092\n",
      "Epoch: 1671 cost = 0.014683283\n",
      "Validation Loss: 0.036873136\n",
      "Epoch: 1672 cost = 0.014679722\n",
      "Validation Loss: 0.030977294\n",
      "Epoch: 1673 cost = 0.014676392\n",
      "Validation Loss: 0.022747362\n",
      "Epoch: 1674 cost = 0.014673676\n",
      "Validation Loss: 0.02893693\n",
      "Epoch: 1675 cost = 0.014670428\n",
      "Validation Loss: 0.031837486\n",
      "Epoch: 1676 cost = 0.014666715\n",
      "Validation Loss: 0.033299718\n",
      "Epoch: 1677 cost = 0.014663601\n",
      "Validation Loss: 0.025248053\n",
      "Epoch: 1678 cost = 0.014660343\n",
      "Validation Loss: 0.018899908\n",
      "Epoch: 1679 cost = 0.014656731\n",
      "Validation Loss: 0.022062303\n",
      "Epoch: 1680 cost = 0.014653885\n",
      "Validation Loss: 0.021223651\n",
      "Epoch: 1681 cost = 0.014650470\n",
      "Validation Loss: 0.02339878\n",
      "Epoch: 1682 cost = 0.014647483\n",
      "Validation Loss: 0.019396115\n",
      "Epoch: 1683 cost = 0.014644104\n",
      "Validation Loss: 0.02269504\n",
      "Epoch: 1684 cost = 0.014641023\n",
      "Validation Loss: 0.030835107\n",
      "Epoch: 1685 cost = 0.014637623\n",
      "Validation Loss: 0.028829912\n",
      "Epoch: 1686 cost = 0.014634880\n",
      "Validation Loss: 0.029277075\n",
      "Epoch: 1687 cost = 0.014631718\n",
      "Validation Loss: 0.029908944\n",
      "Epoch: 1688 cost = 0.014628531\n",
      "Validation Loss: 0.025542652\n",
      "Epoch: 1689 cost = 0.014624945\n",
      "Validation Loss: 0.025704255\n",
      "Epoch: 1690 cost = 0.014622005\n",
      "Validation Loss: 0.03253967\n",
      "Epoch: 1691 cost = 0.014618874\n",
      "Validation Loss: 0.04733632\n",
      "Epoch: 1692 cost = 0.014615627\n",
      "Validation Loss: 0.03875164\n",
      "Epoch: 1693 cost = 0.014612519\n",
      "Validation Loss: 0.033736896\n",
      "Epoch: 1694 cost = 0.014609618\n",
      "Validation Loss: 0.030592656\n",
      "Epoch: 1695 cost = 0.014606708\n",
      "Validation Loss: 0.027519058\n",
      "Epoch: 1696 cost = 0.014603716\n",
      "Validation Loss: 0.02108173\n",
      "Epoch: 1697 cost = 0.014600393\n",
      "Validation Loss: 0.023597872\n",
      "Epoch: 1698 cost = 0.014597577\n",
      "Validation Loss: 0.028219528\n",
      "Epoch: 1699 cost = 0.014593928\n",
      "Validation Loss: 0.02861034\n",
      "Epoch: 1700 cost = 0.014591088\n",
      "Validation Loss: 0.025930418\n",
      "Epoch: 1701 cost = 0.014588787\n",
      "Validation Loss: 0.023952585\n",
      "Epoch: 1702 cost = 0.014585567\n",
      "Validation Loss: 0.024302073\n",
      "Epoch: 1703 cost = 0.014582350\n",
      "Validation Loss: 0.0213648\n",
      "Epoch: 1704 cost = 0.014579493\n",
      "Validation Loss: 0.026316326\n",
      "Epoch: 1705 cost = 0.014576133\n",
      "Validation Loss: 0.034637384\n",
      "Epoch: 1706 cost = 0.014573287\n",
      "Validation Loss: 0.035914544\n",
      "Epoch: 1707 cost = 0.014570485\n",
      "Validation Loss: 0.02335979\n",
      "Epoch: 1708 cost = 0.014567512\n",
      "Validation Loss: 0.022705313\n",
      "Epoch: 1709 cost = 0.014564089\n",
      "Validation Loss: 0.021010216\n",
      "Epoch: 1710 cost = 0.014561624\n",
      "Validation Loss: 0.027742766\n",
      "Epoch: 1711 cost = 0.014558541\n",
      "Validation Loss: 0.026826642\n",
      "Epoch: 1712 cost = 0.014555645\n",
      "Validation Loss: 0.027051285\n",
      "Epoch: 1713 cost = 0.014552921\n",
      "Validation Loss: 0.026540622\n",
      "Epoch: 1714 cost = 0.014549804\n",
      "Validation Loss: 0.028547565\n",
      "Epoch: 1715 cost = 0.014546775\n",
      "Validation Loss: 0.026522674\n",
      "Epoch: 1716 cost = 0.014543986\n",
      "Validation Loss: 0.021290682\n",
      "Epoch: 1717 cost = 0.014540910\n",
      "Validation Loss: 0.024248099\n",
      "Epoch: 1718 cost = 0.014537929\n",
      "Validation Loss: 0.02516491\n",
      "Epoch: 1719 cost = 0.014535398\n",
      "Validation Loss: 0.040075336\n",
      "Epoch: 1720 cost = 0.014532736\n",
      "Validation Loss: 0.03509321\n",
      "Epoch: 1721 cost = 0.014529879\n",
      "Validation Loss: 0.0407372\n",
      "Epoch: 1722 cost = 0.014526379\n",
      "Validation Loss: 0.04978478\n",
      "Epoch: 1723 cost = 0.014523907\n",
      "Validation Loss: 0.042403493\n",
      "Epoch: 1724 cost = 0.014521113\n",
      "Validation Loss: 0.037358027\n",
      "Epoch: 1725 cost = 0.014518205\n",
      "Validation Loss: 0.032842323\n",
      "Epoch: 1726 cost = 0.014515375\n",
      "Validation Loss: 0.03406941\n",
      "Epoch: 1727 cost = 0.014512673\n",
      "Validation Loss: 0.030801417\n",
      "Epoch: 1728 cost = 0.014510098\n",
      "Validation Loss: 0.030519517\n",
      "Epoch: 1729 cost = 0.014507565\n",
      "Validation Loss: 0.029113814\n",
      "Epoch: 1730 cost = 0.014504485\n",
      "Validation Loss: 0.02952869\n",
      "Epoch: 1731 cost = 0.014501776\n",
      "Validation Loss: 0.024821026\n",
      "Epoch: 1732 cost = 0.014499048\n",
      "Validation Loss: 0.028939625\n",
      "Epoch: 1733 cost = 0.014496151\n",
      "Validation Loss: 0.02423971\n",
      "Epoch: 1734 cost = 0.014493032\n",
      "Validation Loss: 0.020862272\n",
      "Epoch: 1735 cost = 0.014490709\n",
      "Validation Loss: 0.026951512\n",
      "Epoch: 1736 cost = 0.014488229\n",
      "Validation Loss: 0.028823424\n",
      "Epoch: 1737 cost = 0.014485676\n",
      "Validation Loss: 0.024968881\n",
      "Epoch: 1738 cost = 0.014482851\n",
      "Validation Loss: 0.022687016\n",
      "Epoch: 1739 cost = 0.014479866\n",
      "Validation Loss: 0.021695208\n",
      "Epoch: 1740 cost = 0.014477102\n",
      "Validation Loss: 0.030895872\n",
      "Epoch: 1741 cost = 0.014474411\n",
      "Validation Loss: 0.040157694\n",
      "Epoch: 1742 cost = 0.014471982\n",
      "Validation Loss: 0.037535395\n",
      "Epoch: 1743 cost = 0.014469122\n",
      "Validation Loss: 0.046383135\n",
      "Epoch: 1744 cost = 0.014466519\n",
      "Validation Loss: 0.04682146\n",
      "Epoch: 1745 cost = 0.014464211\n",
      "Validation Loss: 0.044681743\n",
      "Epoch: 1746 cost = 0.014461481\n",
      "Validation Loss: 0.039560746\n",
      "Epoch: 1747 cost = 0.014458538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03620301\n",
      "Epoch: 1748 cost = 0.014456088\n",
      "Validation Loss: 0.02843655\n",
      "Epoch: 1749 cost = 0.014453641\n",
      "Validation Loss: 0.032818645\n",
      "Epoch: 1750 cost = 0.014450947\n",
      "Validation Loss: 0.033606373\n",
      "Epoch: 1751 cost = 0.014447968\n",
      "Validation Loss: 0.02727961\n",
      "Epoch: 1752 cost = 0.014445703\n",
      "Validation Loss: 0.033806182\n",
      "Epoch: 1753 cost = 0.014443180\n",
      "Validation Loss: 0.028674088\n",
      "Epoch: 1754 cost = 0.014440969\n",
      "Validation Loss: 0.023559986\n",
      "Epoch: 1755 cost = 0.014438114\n",
      "Validation Loss: 0.022917043\n",
      "Epoch: 1756 cost = 0.014435263\n",
      "Validation Loss: 0.029034296\n",
      "Epoch: 1757 cost = 0.014433258\n",
      "Validation Loss: 0.025427232\n",
      "Epoch: 1758 cost = 0.014430439\n",
      "Validation Loss: 0.024621893\n",
      "Epoch: 1759 cost = 0.014428577\n",
      "Validation Loss: 0.05025413\n",
      "Epoch: 1760 cost = 0.014425305\n",
      "Validation Loss: 0.047078423\n",
      "Epoch: 1761 cost = 0.014422667\n",
      "Validation Loss: 0.03366313\n",
      "Epoch: 1762 cost = 0.014420399\n",
      "Validation Loss: 0.020434424\n",
      "Epoch: 1763 cost = 0.014417859\n",
      "Validation Loss: 0.03146662\n",
      "Epoch: 1764 cost = 0.014415401\n",
      "Validation Loss: 0.03478659\n",
      "Epoch: 1765 cost = 0.014413250\n",
      "Validation Loss: 0.027620666\n",
      "Epoch: 1766 cost = 0.014410563\n",
      "Validation Loss: 0.025436765\n",
      "Epoch: 1767 cost = 0.014407975\n",
      "Validation Loss: 0.02692932\n",
      "Epoch: 1768 cost = 0.014405209\n",
      "Validation Loss: 0.025938323\n",
      "Epoch: 1769 cost = 0.014403218\n",
      "Validation Loss: 0.025302174\n",
      "Epoch: 1770 cost = 0.014400581\n",
      "Validation Loss: 0.021705363\n",
      "Epoch: 1771 cost = 0.014398253\n",
      "Validation Loss: 0.037955668\n",
      "Epoch: 1772 cost = 0.014395577\n",
      "Validation Loss: 0.053392872\n",
      "Epoch: 1773 cost = 0.014393058\n",
      "Validation Loss: 0.04192545\n",
      "Epoch: 1774 cost = 0.014390713\n",
      "Validation Loss: 0.040742345\n",
      "Epoch: 1775 cost = 0.014388249\n",
      "Validation Loss: 0.04225624\n",
      "Epoch: 1776 cost = 0.014386148\n",
      "Validation Loss: 0.045831047\n",
      "Epoch: 1777 cost = 0.014383624\n",
      "Validation Loss: 0.038756605\n",
      "Epoch: 1778 cost = 0.014381105\n",
      "Validation Loss: 0.04450636\n",
      "Epoch: 1779 cost = 0.014378668\n",
      "Validation Loss: 0.041854475\n",
      "Epoch: 1780 cost = 0.014376616\n",
      "Validation Loss: 0.042076536\n",
      "Epoch: 1781 cost = 0.014373833\n",
      "Validation Loss: 0.039569866\n",
      "Epoch: 1782 cost = 0.014371891\n",
      "Validation Loss: 0.04224622\n",
      "Epoch: 1783 cost = 0.014369081\n",
      "Validation Loss: 0.033406865\n",
      "Epoch: 1784 cost = 0.014367139\n",
      "Validation Loss: 0.030973224\n",
      "Epoch: 1785 cost = 0.014364322\n",
      "Validation Loss: 0.029382067\n",
      "Epoch: 1786 cost = 0.014362507\n",
      "Validation Loss: 0.019628642\n",
      "Epoch: 1787 cost = 0.014359773\n",
      "Validation Loss: 0.023114784\n",
      "Epoch: 1788 cost = 0.014357937\n",
      "Validation Loss: 0.025272746\n",
      "Epoch: 1789 cost = 0.014355211\n",
      "Validation Loss: 0.02076279\n",
      "Epoch: 1790 cost = 0.014352775\n",
      "Validation Loss: 0.019878766\n",
      "Epoch: 1791 cost = 0.014350625\n",
      "Validation Loss: 0.022734888\n",
      "Epoch: 1792 cost = 0.014348281\n",
      "Validation Loss: 0.021207362\n",
      "Epoch: 1793 cost = 0.014346064\n",
      "Validation Loss: 0.033427328\n",
      "Epoch: 1794 cost = 0.014343290\n",
      "Validation Loss: 0.027894571\n",
      "Epoch: 1795 cost = 0.014341466\n",
      "Validation Loss: 0.02860163\n",
      "Epoch: 1796 cost = 0.014339200\n",
      "Validation Loss: 0.0297848\n",
      "Epoch: 1797 cost = 0.014337076\n",
      "Validation Loss: 0.031987015\n",
      "Epoch: 1798 cost = 0.014334270\n",
      "Validation Loss: 0.035572827\n",
      "Epoch: 1799 cost = 0.014332285\n",
      "Validation Loss: 0.040130697\n",
      "Epoch: 1800 cost = 0.014330044\n",
      "Validation Loss: 0.04841732\n",
      "Epoch: 1801 cost = 0.014327692\n",
      "Validation Loss: 0.036168847\n",
      "Epoch: 1802 cost = 0.014325502\n",
      "Validation Loss: 0.020470321\n",
      "Epoch: 1803 cost = 0.014323223\n",
      "Validation Loss: 0.025018908\n",
      "Epoch: 1804 cost = 0.014321183\n",
      "Validation Loss: 0.028418511\n",
      "Epoch: 1805 cost = 0.014318845\n",
      "Validation Loss: 0.027849497\n",
      "Epoch: 1806 cost = 0.014316485\n",
      "Validation Loss: 0.0370316\n",
      "Epoch: 1807 cost = 0.014314646\n",
      "Validation Loss: 0.029193252\n",
      "Epoch: 1808 cost = 0.014312144\n",
      "Validation Loss: 0.029776286\n",
      "Epoch: 1809 cost = 0.014309987\n",
      "Validation Loss: 0.025573121\n",
      "Epoch: 1810 cost = 0.014308009\n",
      "Validation Loss: 0.014526459\n",
      "Epoch: 1811 cost = 0.014305523\n",
      "Validation Loss: 0.044151064\n",
      "Epoch: 1812 cost = 0.014303554\n",
      "Validation Loss: 0.036846355\n",
      "Epoch: 1813 cost = 0.014301542\n",
      "Validation Loss: 0.022979734\n",
      "Epoch: 1814 cost = 0.014299384\n",
      "Validation Loss: 0.021079684\n",
      "Epoch: 1815 cost = 0.014297148\n",
      "Validation Loss: 0.018457718\n",
      "Epoch: 1816 cost = 0.014294682\n",
      "Validation Loss: 0.02767025\n",
      "Epoch: 1817 cost = 0.014292516\n",
      "Validation Loss: 0.029054511\n",
      "Epoch: 1818 cost = 0.014290442\n",
      "Validation Loss: 0.051706884\n",
      "Epoch: 1819 cost = 0.014288441\n",
      "Validation Loss: 0.057100214\n",
      "Epoch: 1820 cost = 0.014286165\n",
      "Validation Loss: 0.033637024\n",
      "Epoch: 1821 cost = 0.014284391\n",
      "Validation Loss: 0.03176495\n",
      "Epoch: 1822 cost = 0.014281705\n",
      "Validation Loss: 0.044680968\n",
      "Epoch: 1823 cost = 0.014280037\n",
      "Validation Loss: 0.053530496\n",
      "Epoch: 1824 cost = 0.014278032\n",
      "Validation Loss: 0.032642905\n",
      "Epoch: 1825 cost = 0.014275470\n",
      "Validation Loss: 0.02661116\n",
      "Epoch: 1826 cost = 0.014274011\n",
      "Validation Loss: 0.01802731\n",
      "Epoch: 1827 cost = 0.014271569\n",
      "Validation Loss: 0.01922619\n",
      "Epoch: 1828 cost = 0.014269471\n",
      "Validation Loss: 0.020453092\n",
      "Epoch: 1829 cost = 0.014267572\n",
      "Validation Loss: 0.03321091\n",
      "Epoch: 1830 cost = 0.014265400\n",
      "Validation Loss: 0.0326196\n",
      "Epoch: 1831 cost = 0.014263306\n",
      "Validation Loss: 0.035596985\n",
      "Epoch: 1832 cost = 0.014261385\n",
      "Validation Loss: 0.027128503\n",
      "Epoch: 1833 cost = 0.014259296\n",
      "Validation Loss: 0.023596762\n",
      "Epoch: 1834 cost = 0.014257398\n",
      "Validation Loss: 0.041302513\n",
      "Epoch: 1835 cost = 0.014255426\n",
      "Validation Loss: 0.05789147\n",
      "Epoch: 1836 cost = 0.014253175\n",
      "Validation Loss: 0.042738255\n",
      "Epoch: 1837 cost = 0.014251246\n",
      "Validation Loss: 0.03235717\n",
      "Epoch: 1838 cost = 0.014249170\n",
      "Validation Loss: 0.04025636\n",
      "Epoch: 1839 cost = 0.014247304\n",
      "Validation Loss: 0.036587924\n",
      "Epoch: 1840 cost = 0.014244716\n",
      "Validation Loss: 0.034791622\n",
      "Epoch: 1841 cost = 0.014242641\n",
      "Validation Loss: 0.037727214\n",
      "Epoch: 1842 cost = 0.014240995\n",
      "Validation Loss: 0.038773343\n",
      "Epoch: 1843 cost = 0.014238686\n",
      "Validation Loss: 0.028148435\n",
      "Epoch: 1844 cost = 0.014236553\n",
      "Validation Loss: 0.03239192\n",
      "Epoch: 1845 cost = 0.014234784\n",
      "Validation Loss: 0.03292608\n",
      "Epoch: 1846 cost = 0.014232984\n",
      "Validation Loss: 0.02855539\n",
      "Epoch: 1847 cost = 0.014231084\n",
      "Validation Loss: 0.023483656\n",
      "Epoch: 1848 cost = 0.014229232\n",
      "Validation Loss: 0.03373843\n",
      "Epoch: 1849 cost = 0.014227058\n",
      "Validation Loss: 0.03930667\n",
      "Epoch: 1850 cost = 0.014225270\n",
      "Validation Loss: 0.03232784\n",
      "Epoch: 1851 cost = 0.014223240\n",
      "Validation Loss: 0.023527306\n",
      "Epoch: 1852 cost = 0.014221224\n",
      "Validation Loss: 0.0323945\n",
      "Epoch: 1853 cost = 0.014219130\n",
      "Validation Loss: 0.026644632\n",
      "Epoch: 1854 cost = 0.014217166\n",
      "Validation Loss: 0.024836032\n",
      "Epoch: 1855 cost = 0.014215470\n",
      "Validation Loss: 0.025365608\n",
      "Epoch: 1856 cost = 0.014213546\n",
      "Validation Loss: 0.029200917\n",
      "Epoch: 1857 cost = 0.014211570\n",
      "Validation Loss: 0.030671014\n",
      "Epoch: 1858 cost = 0.014209447\n",
      "Validation Loss: 0.025337037\n",
      "Epoch: 1859 cost = 0.014207632\n",
      "Validation Loss: 0.02295261\n",
      "Epoch: 1860 cost = 0.014205736\n",
      "Validation Loss: 0.028668651\n",
      "Epoch: 1861 cost = 0.014203366\n",
      "Validation Loss: 0.03299099\n",
      "Epoch: 1862 cost = 0.014201943\n",
      "Validation Loss: 0.022900883\n",
      "Epoch: 1863 cost = 0.014200051\n",
      "Validation Loss: 0.024011053\n",
      "Epoch: 1864 cost = 0.014198145\n",
      "Validation Loss: 0.030659724\n",
      "Epoch: 1865 cost = 0.014196363\n",
      "Validation Loss: 0.034888256\n",
      "Epoch: 1866 cost = 0.014194172\n",
      "Validation Loss: 0.02894384\n",
      "Epoch: 1867 cost = 0.014192641\n",
      "Validation Loss: 0.02588937\n",
      "Epoch: 1868 cost = 0.014191095\n",
      "Validation Loss: 0.028808953\n",
      "Epoch: 1869 cost = 0.014188840\n",
      "Validation Loss: 0.036834948\n",
      "Epoch: 1870 cost = 0.014186699\n",
      "Validation Loss: 0.03361087\n",
      "Epoch: 1871 cost = 0.014185374\n",
      "Validation Loss: 0.03245108\n",
      "Epoch: 1872 cost = 0.014183208\n",
      "Validation Loss: 0.030405788\n",
      "Epoch: 1873 cost = 0.014181351\n",
      "Validation Loss: 0.022295952\n",
      "Epoch: 1874 cost = 0.014179801\n",
      "Validation Loss: 0.024102353\n",
      "Epoch: 1875 cost = 0.014177700\n",
      "Validation Loss: 0.02984724\n",
      "Epoch: 1876 cost = 0.014175722\n",
      "Validation Loss: 0.026687104\n",
      "Epoch: 1877 cost = 0.014173985\n",
      "Validation Loss: 0.01735133\n",
      "Epoch: 1878 cost = 0.014171779\n",
      "Validation Loss: 0.02110672\n",
      "Epoch: 1879 cost = 0.014170362\n",
      "Validation Loss: 0.025120897\n",
      "Epoch: 1880 cost = 0.014168409\n",
      "Validation Loss: 0.027304675\n",
      "Epoch: 1881 cost = 0.014166931\n",
      "Validation Loss: 0.03261376\n",
      "Epoch: 1882 cost = 0.014164533\n",
      "Validation Loss: 0.042732924\n",
      "Epoch: 1883 cost = 0.014162751\n",
      "Validation Loss: 0.03379652\n",
      "Epoch: 1884 cost = 0.014161039\n",
      "Validation Loss: 0.03439548\n",
      "Epoch: 1885 cost = 0.014159667\n",
      "Validation Loss: 0.017057082\n",
      "Epoch: 1886 cost = 0.014157877\n",
      "Validation Loss: 0.01630897\n",
      "Epoch: 1887 cost = 0.014155739\n",
      "Validation Loss: 0.02195481\n",
      "Epoch: 1888 cost = 0.014154139\n",
      "Validation Loss: 0.017046845\n",
      "Epoch: 1889 cost = 0.014152734\n",
      "Validation Loss: 0.022258796\n",
      "Epoch: 1890 cost = 0.014150021\n",
      "Validation Loss: 0.016270556\n",
      "Epoch: 1891 cost = 0.014149232\n",
      "Validation Loss: 0.019847604\n",
      "Epoch: 1892 cost = 0.014147044\n",
      "Validation Loss: 0.03566689\n",
      "Epoch: 1893 cost = 0.014145221\n",
      "Validation Loss: 0.029577244\n",
      "Epoch: 1894 cost = 0.014143744\n",
      "Validation Loss: 0.042126212\n",
      "Epoch: 1895 cost = 0.014141568\n",
      "Validation Loss: 0.041974183\n",
      "Epoch: 1896 cost = 0.014139751\n",
      "Validation Loss: 0.025830885\n",
      "Epoch: 1897 cost = 0.014137738\n",
      "Validation Loss: 0.016790459\n",
      "Epoch: 1898 cost = 0.014136101\n",
      "Validation Loss: 0.02015299\n",
      "Epoch: 1899 cost = 0.014134823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0298961\n",
      "Epoch: 1900 cost = 0.014133246\n",
      "Validation Loss: 0.032573227\n",
      "Epoch: 1901 cost = 0.014131052\n",
      "Validation Loss: 0.026221503\n",
      "Epoch: 1902 cost = 0.014129118\n",
      "Validation Loss: 0.034728415\n",
      "Epoch: 1903 cost = 0.014127818\n",
      "Validation Loss: 0.035680052\n",
      "Epoch: 1904 cost = 0.014126287\n",
      "Validation Loss: 0.03623222\n",
      "Epoch: 1905 cost = 0.014123981\n",
      "Validation Loss: 0.033080515\n",
      "Epoch: 1906 cost = 0.014122382\n",
      "Validation Loss: 0.028268224\n",
      "Epoch: 1907 cost = 0.014120563\n",
      "Validation Loss: 0.03005714\n",
      "Epoch: 1908 cost = 0.014118962\n",
      "Validation Loss: 0.030828735\n",
      "Epoch: 1909 cost = 0.014117219\n",
      "Validation Loss: 0.036965042\n",
      "Epoch: 1910 cost = 0.014115887\n",
      "Validation Loss: 0.03355606\n",
      "Epoch: 1911 cost = 0.014113962\n",
      "Validation Loss: 0.029092515\n",
      "Epoch: 1912 cost = 0.014112446\n",
      "Validation Loss: 0.03449639\n",
      "Epoch: 1913 cost = 0.014110691\n",
      "Validation Loss: 0.028613882\n",
      "Epoch: 1914 cost = 0.014109132\n",
      "Validation Loss: 0.037314422\n",
      "Epoch: 1915 cost = 0.014107306\n",
      "Validation Loss: 0.04596334\n",
      "Epoch: 1916 cost = 0.014105909\n",
      "Validation Loss: 0.035276722\n",
      "Epoch: 1917 cost = 0.014104043\n",
      "Validation Loss: 0.024821348\n",
      "Epoch: 1918 cost = 0.014102262\n",
      "Validation Loss: 0.02738464\n",
      "Epoch: 1919 cost = 0.014100377\n",
      "Validation Loss: 0.02216195\n",
      "Epoch: 1920 cost = 0.014098655\n",
      "Validation Loss: 0.032172356\n",
      "Epoch: 1921 cost = 0.014097288\n",
      "Validation Loss: 0.02403226\n",
      "Epoch: 1922 cost = 0.014095324\n",
      "Validation Loss: 0.02547413\n",
      "Epoch: 1923 cost = 0.014093941\n",
      "Validation Loss: 0.03398603\n",
      "Epoch: 1924 cost = 0.014092278\n",
      "Validation Loss: 0.034238853\n",
      "Epoch: 1925 cost = 0.014090886\n",
      "Validation Loss: 0.023465995\n",
      "Epoch: 1926 cost = 0.014089015\n",
      "Validation Loss: 0.027628211\n",
      "Epoch: 1927 cost = 0.014087330\n",
      "Validation Loss: 0.02851111\n",
      "Epoch: 1928 cost = 0.014085588\n",
      "Validation Loss: 0.029644884\n",
      "Epoch: 1929 cost = 0.014084356\n",
      "Validation Loss: 0.032206804\n",
      "Epoch: 1930 cost = 0.014082609\n",
      "Validation Loss: 0.033124365\n",
      "Epoch: 1931 cost = 0.014081166\n",
      "Validation Loss: 0.03229228\n",
      "Epoch: 1932 cost = 0.014079406\n",
      "Validation Loss: 0.032864545\n",
      "Epoch: 1933 cost = 0.014077829\n",
      "Validation Loss: 0.028662102\n",
      "Epoch: 1934 cost = 0.014076122\n",
      "Validation Loss: 0.022272864\n",
      "Epoch: 1935 cost = 0.014074901\n",
      "Validation Loss: 0.016820163\n",
      "Epoch: 1936 cost = 0.014072815\n",
      "Validation Loss: 0.0337514\n",
      "Epoch: 1937 cost = 0.014071549\n",
      "Validation Loss: 0.029167552\n",
      "Epoch: 1938 cost = 0.014070227\n",
      "Validation Loss: 0.020523924\n",
      "Epoch: 1939 cost = 0.014068108\n",
      "Validation Loss: 0.022160968\n",
      "Epoch: 1940 cost = 0.014066646\n",
      "Validation Loss: 0.02799776\n",
      "Epoch: 1941 cost = 0.014065174\n",
      "Validation Loss: 0.017710278\n",
      "Epoch: 1942 cost = 0.014063597\n",
      "Validation Loss: 0.019244501\n",
      "Epoch: 1943 cost = 0.014062115\n",
      "Validation Loss: 0.01928162\n",
      "Epoch: 1944 cost = 0.014060285\n",
      "Validation Loss: 0.022630462\n",
      "Epoch: 1945 cost = 0.014058589\n",
      "Validation Loss: 0.02152365\n",
      "Epoch: 1946 cost = 0.014057139\n",
      "Validation Loss: 0.022327725\n",
      "Epoch: 1947 cost = 0.014055697\n",
      "Validation Loss: 0.020534627\n",
      "Epoch: 1948 cost = 0.014054304\n",
      "Validation Loss: 0.027378883\n",
      "Epoch: 1949 cost = 0.014052496\n",
      "Validation Loss: 0.028862232\n",
      "Epoch: 1950 cost = 0.014051084\n",
      "Validation Loss: 0.028964939\n",
      "Epoch: 1951 cost = 0.014049414\n",
      "Validation Loss: 0.022110637\n",
      "Epoch: 1952 cost = 0.014047456\n",
      "Validation Loss: 0.023049546\n",
      "Epoch: 1953 cost = 0.014046175\n",
      "Validation Loss: 0.02525585\n",
      "Epoch: 1954 cost = 0.014044999\n",
      "Validation Loss: 0.01703683\n",
      "Epoch: 1955 cost = 0.014043165\n",
      "Validation Loss: 0.015779417\n",
      "Epoch: 1956 cost = 0.014041517\n",
      "Validation Loss: 0.021531982\n",
      "Epoch: 1957 cost = 0.014040169\n",
      "Validation Loss: 0.025206387\n",
      "Epoch: 1958 cost = 0.014039195\n",
      "Validation Loss: 0.024275346\n",
      "Epoch: 1959 cost = 0.014037564\n",
      "Validation Loss: 0.02731569\n",
      "Epoch: 1960 cost = 0.014035724\n",
      "Validation Loss: 0.03466717\n",
      "Epoch: 1961 cost = 0.014033989\n",
      "Validation Loss: 0.02506904\n",
      "Epoch: 1962 cost = 0.014032883\n",
      "Validation Loss: 0.028489877\n",
      "Epoch: 1963 cost = 0.014030936\n",
      "Validation Loss: 0.03098255\n",
      "Epoch: 1964 cost = 0.014029499\n",
      "Validation Loss: 0.035554748\n",
      "Epoch: 1965 cost = 0.014028244\n",
      "Validation Loss: 0.028414696\n",
      "Epoch: 1966 cost = 0.014026311\n",
      "Validation Loss: 0.020075882\n",
      "Epoch: 1967 cost = 0.014024993\n",
      "Validation Loss: 0.018485548\n",
      "Epoch: 1968 cost = 0.014023541\n",
      "Validation Loss: 0.02332877\n",
      "Epoch: 1969 cost = 0.014022058\n",
      "Validation Loss: 0.030490244\n",
      "Epoch: 1970 cost = 0.014020850\n",
      "Validation Loss: 0.031265788\n",
      "Epoch: 1971 cost = 0.014019304\n",
      "Validation Loss: 0.028639734\n",
      "Epoch: 1972 cost = 0.014017516\n",
      "Validation Loss: 0.02462986\n",
      "Epoch: 1973 cost = 0.014015867\n",
      "Validation Loss: 0.023809785\n",
      "Epoch: 1974 cost = 0.014014833\n",
      "Validation Loss: 0.029435283\n",
      "Epoch: 1975 cost = 0.014013154\n",
      "Validation Loss: 0.030879753\n",
      "Epoch: 1976 cost = 0.014011573\n",
      "Validation Loss: 0.034929466\n",
      "Epoch: 1977 cost = 0.014010074\n",
      "Validation Loss: 0.0315717\n",
      "Epoch: 1978 cost = 0.014008188\n",
      "Validation Loss: 0.026686843\n",
      "Epoch: 1979 cost = 0.014007572\n",
      "Validation Loss: 0.02202492\n",
      "Epoch: 1980 cost = 0.014005963\n",
      "Validation Loss: 0.019913007\n",
      "Epoch: 1981 cost = 0.014004477\n",
      "Validation Loss: 0.032208856\n",
      "Epoch: 1982 cost = 0.014002830\n",
      "Validation Loss: 0.04077419\n",
      "Epoch: 1983 cost = 0.014001648\n",
      "Validation Loss: 0.04924143\n",
      "Epoch: 1984 cost = 0.014000014\n",
      "Validation Loss: 0.068554096\n",
      "Epoch: 1985 cost = 0.013998795\n",
      "Validation Loss: 0.062719636\n",
      "Epoch: 1986 cost = 0.013996807\n",
      "Validation Loss: 0.038473845\n",
      "Epoch: 1987 cost = 0.013995759\n",
      "Validation Loss: 0.02806904\n",
      "Epoch: 1988 cost = 0.013994460\n",
      "Validation Loss: 0.027454285\n",
      "Epoch: 1989 cost = 0.013992673\n",
      "Validation Loss: 0.026457934\n",
      "Epoch: 1990 cost = 0.013991101\n",
      "Validation Loss: 0.032942012\n",
      "Epoch: 1991 cost = 0.013990210\n",
      "Validation Loss: 0.03227905\n",
      "Epoch: 1992 cost = 0.013988795\n",
      "Validation Loss: 0.0197721\n",
      "Epoch: 1993 cost = 0.013987204\n",
      "Validation Loss: 0.023688868\n",
      "Epoch: 1994 cost = 0.013985624\n",
      "Validation Loss: 0.022814263\n",
      "Epoch: 1995 cost = 0.013984094\n",
      "Validation Loss: 0.01806792\n",
      "Epoch: 1996 cost = 0.013982992\n",
      "Validation Loss: 0.024572793\n",
      "Epoch: 1997 cost = 0.013981666\n",
      "Validation Loss: 0.03611571\n",
      "Epoch: 1998 cost = 0.013979591\n",
      "Validation Loss: 0.02556027\n",
      "Epoch: 1999 cost = 0.013978759\n",
      "Validation Loss: 0.02288259\n",
      "Epoch: 2000 cost = 0.013977215\n",
      "Validation Loss: 0.017150963\n",
      "Epoch: 2001 cost = 0.013976370\n",
      "Validation Loss: 0.016668815\n",
      "Epoch: 2002 cost = 0.013974429\n",
      "Validation Loss: 0.026039861\n",
      "Epoch: 2003 cost = 0.013973635\n",
      "Validation Loss: 0.025889397\n",
      "Epoch: 2004 cost = 0.013971222\n",
      "Validation Loss: 0.025959436\n",
      "Epoch: 2005 cost = 0.013970234\n",
      "Validation Loss: 0.03142164\n",
      "Epoch: 2006 cost = 0.013968629\n",
      "Validation Loss: 0.036226097\n",
      "Epoch: 2007 cost = 0.013967498\n",
      "Validation Loss: 0.041767787\n",
      "Epoch: 2008 cost = 0.013966633\n",
      "Validation Loss: 0.031166768\n",
      "Epoch: 2009 cost = 0.013965290\n",
      "Validation Loss: 0.03249731\n",
      "Epoch: 2010 cost = 0.013963697\n",
      "Validation Loss: 0.036375556\n",
      "Epoch: 2011 cost = 0.013961967\n",
      "Validation Loss: 0.031134216\n",
      "Epoch: 2012 cost = 0.013960740\n",
      "Validation Loss: 0.027743151\n",
      "Epoch: 2013 cost = 0.013959407\n",
      "Validation Loss: 0.027301662\n",
      "Epoch: 2014 cost = 0.013957940\n",
      "Validation Loss: 0.025344614\n",
      "Epoch: 2015 cost = 0.013956879\n",
      "Validation Loss: 0.027010594\n",
      "Epoch: 2016 cost = 0.013954961\n",
      "Validation Loss: 0.02756567\n",
      "Epoch: 2017 cost = 0.013954026\n",
      "Validation Loss: 0.03160998\n",
      "Epoch: 2018 cost = 0.013952208\n",
      "Validation Loss: 0.030153107\n",
      "Epoch: 2019 cost = 0.013951319\n",
      "Validation Loss: 0.03161769\n",
      "Epoch: 2020 cost = 0.013949883\n",
      "Validation Loss: 0.021839932\n",
      "Epoch: 2021 cost = 0.013948855\n",
      "Validation Loss: 0.014861236\n",
      "Epoch: 2022 cost = 0.013947030\n",
      "Validation Loss: 0.01929727\n",
      "Epoch: 2023 cost = 0.013945785\n",
      "Validation Loss: 0.016525157\n",
      "Epoch: 2024 cost = 0.013944842\n",
      "Validation Loss: 0.018495185\n",
      "Epoch: 2025 cost = 0.013943363\n",
      "Validation Loss: 0.02517351\n",
      "Epoch: 2026 cost = 0.013941398\n",
      "Validation Loss: 0.022301137\n",
      "Epoch: 2027 cost = 0.013940852\n",
      "Validation Loss: 0.032297336\n",
      "Epoch: 2028 cost = 0.013938954\n",
      "Validation Loss: 0.03691095\n",
      "Epoch: 2029 cost = 0.013937610\n",
      "Validation Loss: 0.018537119\n",
      "Epoch: 2030 cost = 0.013936659\n",
      "Validation Loss: 0.023758674\n",
      "Epoch: 2031 cost = 0.013935217\n",
      "Validation Loss: 0.027141394\n",
      "Epoch: 2032 cost = 0.013933728\n",
      "Validation Loss: 0.031203449\n",
      "Epoch: 2033 cost = 0.013932931\n",
      "Validation Loss: 0.05409714\n",
      "Epoch: 2034 cost = 0.013931067\n",
      "Validation Loss: 0.059939712\n",
      "Epoch: 2035 cost = 0.013929584\n",
      "Validation Loss: 0.04234917\n",
      "Epoch: 2036 cost = 0.013928339\n",
      "Validation Loss: 0.028216388\n",
      "Epoch: 2037 cost = 0.013927273\n",
      "Validation Loss: 0.04892465\n",
      "Epoch: 2038 cost = 0.013925993\n",
      "Validation Loss: 0.04186839\n",
      "Epoch: 2039 cost = 0.013924551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03864994\n",
      "Epoch: 2040 cost = 0.013923768\n",
      "Validation Loss: 0.036922645\n",
      "Epoch: 2041 cost = 0.013921898\n",
      "Validation Loss: 0.029942727\n",
      "Epoch: 2042 cost = 0.013920555\n",
      "Validation Loss: 0.025385432\n",
      "Epoch: 2043 cost = 0.013919160\n",
      "Validation Loss: 0.031039894\n",
      "Epoch: 2044 cost = 0.013917888\n",
      "Validation Loss: 0.039597478\n",
      "Epoch: 2045 cost = 0.013916703\n",
      "Validation Loss: 0.031462125\n",
      "Epoch: 2046 cost = 0.013915894\n",
      "Validation Loss: 0.023222737\n",
      "Epoch: 2047 cost = 0.013914320\n",
      "Validation Loss: 0.026782732\n",
      "Epoch: 2048 cost = 0.013912533\n",
      "Validation Loss: 0.026353965\n",
      "Epoch: 2049 cost = 0.013911596\n",
      "Validation Loss: 0.028711366\n",
      "Epoch: 2050 cost = 0.013910405\n",
      "Validation Loss: 0.031245561\n",
      "Epoch: 2051 cost = 0.013908931\n",
      "Validation Loss: 0.030789815\n",
      "Epoch: 2052 cost = 0.013907758\n",
      "Validation Loss: 0.03874194\n",
      "Epoch: 2053 cost = 0.013906876\n",
      "Validation Loss: 0.032691307\n",
      "Epoch: 2054 cost = 0.013905424\n",
      "Validation Loss: 0.025619049\n",
      "Epoch: 2055 cost = 0.013903652\n",
      "Validation Loss: 0.025521986\n",
      "Epoch: 2056 cost = 0.013902710\n",
      "Validation Loss: 0.028825166\n",
      "Epoch: 2057 cost = 0.013901737\n",
      "Validation Loss: 0.03145827\n",
      "Epoch: 2058 cost = 0.013900594\n",
      "Validation Loss: 0.03340121\n",
      "Epoch: 2059 cost = 0.013899119\n",
      "Validation Loss: 0.024599474\n",
      "Epoch: 2060 cost = 0.013897731\n",
      "Validation Loss: 0.02518222\n",
      "Epoch: 2061 cost = 0.013896510\n",
      "Validation Loss: 0.02787865\n",
      "Epoch: 2062 cost = 0.013895118\n",
      "Validation Loss: 0.02784848\n",
      "Epoch: 2063 cost = 0.013894124\n",
      "Validation Loss: 0.0298368\n",
      "Epoch: 2064 cost = 0.013892328\n",
      "Validation Loss: 0.02751848\n",
      "Epoch: 2065 cost = 0.013891235\n",
      "Validation Loss: 0.0306239\n",
      "Epoch: 2066 cost = 0.013890134\n",
      "Validation Loss: 0.028631343\n",
      "Epoch: 2067 cost = 0.013889044\n",
      "Validation Loss: 0.023891663\n",
      "Epoch: 2068 cost = 0.013887793\n",
      "Validation Loss: 0.024529792\n",
      "Epoch: 2069 cost = 0.013886739\n",
      "Validation Loss: 0.021881022\n",
      "Epoch: 2070 cost = 0.013885258\n",
      "Validation Loss: 0.023057189\n",
      "Epoch: 2071 cost = 0.013884218\n",
      "Validation Loss: 0.024653193\n",
      "Epoch: 2072 cost = 0.013883183\n",
      "Validation Loss: 0.026226075\n",
      "Epoch: 2073 cost = 0.013881581\n",
      "Validation Loss: 0.027399097\n",
      "Epoch: 2074 cost = 0.013880385\n",
      "Validation Loss: 0.03550751\n",
      "Epoch: 2075 cost = 0.013879176\n",
      "Validation Loss: 0.029807642\n",
      "Epoch: 2076 cost = 0.013877844\n",
      "Validation Loss: 0.022898296\n",
      "Epoch: 2077 cost = 0.013876687\n",
      "Validation Loss: 0.018992376\n",
      "Epoch: 2078 cost = 0.013875814\n",
      "Validation Loss: 0.019138588\n",
      "Epoch: 2079 cost = 0.013874412\n",
      "Validation Loss: 0.024253596\n",
      "Epoch: 2080 cost = 0.013873549\n",
      "Validation Loss: 0.036206994\n",
      "Epoch: 2081 cost = 0.013872065\n",
      "Validation Loss: 0.039315067\n",
      "Epoch: 2082 cost = 0.013870910\n",
      "Validation Loss: 0.035283852\n",
      "Epoch: 2083 cost = 0.013869238\n",
      "Validation Loss: 0.028024808\n",
      "Epoch: 2084 cost = 0.013867863\n",
      "Validation Loss: 0.025139084\n",
      "Epoch: 2085 cost = 0.013867109\n",
      "Validation Loss: 0.03233169\n",
      "Epoch: 2086 cost = 0.013865622\n",
      "Validation Loss: 0.03666325\n",
      "Epoch: 2087 cost = 0.013864728\n",
      "Validation Loss: 0.02606118\n",
      "Epoch: 2088 cost = 0.013863715\n",
      "Validation Loss: 0.023836853\n",
      "Epoch: 2089 cost = 0.013862208\n",
      "Validation Loss: 0.021724738\n",
      "Epoch: 2090 cost = 0.013860963\n",
      "Validation Loss: 0.029583985\n",
      "Epoch: 2091 cost = 0.013859872\n",
      "Validation Loss: 0.023611188\n",
      "Epoch: 2092 cost = 0.013859106\n",
      "Validation Loss: 0.01871683\n",
      "Epoch: 2093 cost = 0.013857473\n",
      "Validation Loss: 0.02079695\n",
      "Epoch: 2094 cost = 0.013856540\n",
      "Validation Loss: 0.033343237\n",
      "Epoch: 2095 cost = 0.013855377\n",
      "Validation Loss: 0.04344056\n",
      "Epoch: 2096 cost = 0.013854525\n",
      "Validation Loss: 0.04848464\n",
      "Epoch: 2097 cost = 0.013852771\n",
      "Validation Loss: 0.040531363\n",
      "Epoch: 2098 cost = 0.013851873\n",
      "Validation Loss: 0.03632931\n",
      "Epoch: 2099 cost = 0.013850423\n",
      "Validation Loss: 0.03797144\n",
      "Epoch: 2100 cost = 0.013849628\n",
      "Validation Loss: 0.03947668\n",
      "Epoch: 2101 cost = 0.013847996\n",
      "Validation Loss: 0.017555876\n",
      "Epoch: 2102 cost = 0.013847229\n",
      "Validation Loss: 0.030352347\n",
      "Epoch: 2103 cost = 0.013845796\n",
      "Validation Loss: 0.032935023\n",
      "Epoch: 2104 cost = 0.013844464\n",
      "Validation Loss: 0.029915953\n",
      "Epoch: 2105 cost = 0.013843568\n",
      "Validation Loss: 0.025574682\n",
      "Epoch: 2106 cost = 0.013842885\n",
      "Validation Loss: 0.02641864\n",
      "Epoch: 2107 cost = 0.013841523\n",
      "Validation Loss: 0.03087875\n",
      "Epoch: 2108 cost = 0.013840034\n",
      "Validation Loss: 0.038332704\n",
      "Epoch: 2109 cost = 0.013838575\n",
      "Validation Loss: 0.029145231\n",
      "Epoch: 2110 cost = 0.013837392\n",
      "Validation Loss: 0.021168983\n",
      "Epoch: 2111 cost = 0.013836770\n",
      "Validation Loss: 0.02362302\n",
      "Epoch: 2112 cost = 0.013835513\n",
      "Validation Loss: 0.020342896\n",
      "Epoch: 2113 cost = 0.013834427\n",
      "Validation Loss: 0.023025256\n",
      "Epoch: 2114 cost = 0.013832647\n",
      "Validation Loss: 0.02834518\n",
      "Epoch: 2115 cost = 0.013832038\n",
      "Validation Loss: 0.029112631\n",
      "Epoch: 2116 cost = 0.013830957\n",
      "Validation Loss: 0.02298534\n",
      "Epoch: 2117 cost = 0.013829631\n",
      "Validation Loss: 0.020308191\n",
      "Epoch: 2118 cost = 0.013828689\n",
      "Validation Loss: 0.033867717\n",
      "Epoch: 2119 cost = 0.013827076\n",
      "Validation Loss: 0.042724464\n",
      "Epoch: 2120 cost = 0.013826135\n",
      "Validation Loss: 0.038854796\n",
      "Epoch: 2121 cost = 0.013825422\n",
      "Validation Loss: 0.03182145\n",
      "Epoch: 2122 cost = 0.013824292\n",
      "Validation Loss: 0.030034488\n",
      "Epoch: 2123 cost = 0.013822949\n",
      "Validation Loss: 0.026454765\n",
      "Epoch: 2124 cost = 0.013822045\n",
      "Validation Loss: 0.02641911\n",
      "Epoch: 2125 cost = 0.013820418\n",
      "Validation Loss: 0.031459793\n",
      "Epoch: 2126 cost = 0.013819162\n",
      "Validation Loss: 0.027430804\n",
      "Epoch: 2127 cost = 0.013818354\n",
      "Validation Loss: 0.044635393\n",
      "Epoch: 2128 cost = 0.013816721\n",
      "Validation Loss: 0.040261153\n",
      "Epoch: 2129 cost = 0.013816141\n",
      "Validation Loss: 0.02281201\n",
      "Epoch: 2130 cost = 0.013814638\n",
      "Validation Loss: 0.023810942\n",
      "Epoch: 2131 cost = 0.013814391\n",
      "Validation Loss: 0.017169358\n",
      "Epoch: 2132 cost = 0.013812455\n",
      "Validation Loss: 0.017254125\n",
      "Epoch: 2133 cost = 0.013811782\n",
      "Validation Loss: 0.023399077\n",
      "Epoch: 2134 cost = 0.013810368\n",
      "Validation Loss: 0.023482112\n",
      "Epoch: 2135 cost = 0.013809367\n",
      "Validation Loss: 0.028779099\n",
      "Epoch: 2136 cost = 0.013808197\n",
      "Validation Loss: 0.025246669\n",
      "Epoch: 2137 cost = 0.013806712\n",
      "Validation Loss: 0.03329349\n",
      "Epoch: 2138 cost = 0.013806299\n",
      "Validation Loss: 0.027578354\n",
      "Epoch: 2139 cost = 0.013804572\n",
      "Validation Loss: 0.015764259\n",
      "Epoch: 2140 cost = 0.013804086\n",
      "Validation Loss: 0.012218144\n",
      "Epoch: 2141 cost = 0.013802554\n",
      "Validation Loss: 0.04448749\n",
      "Epoch: 2142 cost = 0.013801416\n",
      "Validation Loss: 0.039350793\n",
      "Epoch: 2143 cost = 0.013800841\n",
      "Validation Loss: 0.027057704\n",
      "Epoch: 2144 cost = 0.013799299\n",
      "Validation Loss: 0.023053609\n",
      "Epoch: 2145 cost = 0.013798705\n",
      "Validation Loss: 0.029480966\n",
      "Epoch: 2146 cost = 0.013797331\n",
      "Validation Loss: 0.027504498\n",
      "Epoch: 2147 cost = 0.013796198\n",
      "Validation Loss: 0.027893096\n",
      "Epoch: 2148 cost = 0.013795232\n",
      "Validation Loss: 0.024826555\n",
      "Epoch: 2149 cost = 0.013794024\n",
      "Validation Loss: 0.023759741\n",
      "Epoch: 2150 cost = 0.013792609\n",
      "Validation Loss: 0.02444161\n",
      "Epoch: 2151 cost = 0.013791531\n",
      "Validation Loss: 0.022342652\n",
      "Epoch: 2152 cost = 0.013790606\n",
      "Validation Loss: 0.024333278\n",
      "Epoch: 2153 cost = 0.013789713\n",
      "Validation Loss: 0.027702734\n",
      "Epoch: 2154 cost = 0.013788756\n",
      "Validation Loss: 0.026589163\n",
      "Epoch: 2155 cost = 0.013787467\n",
      "Validation Loss: 0.039936293\n",
      "Epoch: 2156 cost = 0.013786000\n",
      "Validation Loss: 0.036160536\n",
      "Epoch: 2157 cost = 0.013785661\n",
      "Validation Loss: 0.030316332\n",
      "Epoch: 2158 cost = 0.013784397\n",
      "Validation Loss: 0.028696107\n",
      "Epoch: 2159 cost = 0.013783038\n",
      "Validation Loss: 0.025658535\n",
      "Epoch: 2160 cost = 0.013782226\n",
      "Validation Loss: 0.023739265\n",
      "Epoch: 2161 cost = 0.013781243\n",
      "Validation Loss: 0.028795116\n",
      "Epoch: 2162 cost = 0.013780114\n",
      "Validation Loss: 0.031836845\n",
      "Epoch: 2163 cost = 0.013778840\n",
      "Validation Loss: 0.029137712\n",
      "Epoch: 2164 cost = 0.013777981\n",
      "Validation Loss: 0.024641516\n",
      "Epoch: 2165 cost = 0.013776917\n",
      "Validation Loss: 0.021124238\n",
      "Epoch: 2166 cost = 0.013775561\n",
      "Validation Loss: 0.028817138\n",
      "Epoch: 2167 cost = 0.013774768\n",
      "Validation Loss: 0.02282147\n",
      "Epoch: 2168 cost = 0.013773609\n",
      "Validation Loss: 0.021686073\n",
      "Epoch: 2169 cost = 0.013772982\n",
      "Validation Loss: 0.023443028\n",
      "Epoch: 2170 cost = 0.013771297\n",
      "Validation Loss: 0.023273675\n",
      "Epoch: 2171 cost = 0.013770399\n",
      "Validation Loss: 0.027307145\n",
      "Epoch: 2172 cost = 0.013769370\n",
      "Validation Loss: 0.021498496\n",
      "Epoch: 2173 cost = 0.013768408\n",
      "Validation Loss: 0.025770882\n",
      "Epoch: 2174 cost = 0.013767353\n",
      "Validation Loss: 0.028652161\n",
      "Epoch: 2175 cost = 0.013766080\n",
      "Validation Loss: 0.024350306\n",
      "Epoch: 2176 cost = 0.013765267\n",
      "Validation Loss: 0.027914345\n",
      "Epoch: 2177 cost = 0.013764051\n",
      "Validation Loss: 0.021101668\n",
      "Epoch: 2178 cost = 0.013762756\n",
      "Validation Loss: 0.0257985\n",
      "Epoch: 2179 cost = 0.013762279\n",
      "Validation Loss: 0.029380029\n",
      "Epoch: 2180 cost = 0.013760913\n",
      "Validation Loss: 0.027074547\n",
      "Epoch: 2181 cost = 0.013759906\n",
      "Validation Loss: 0.029162057\n",
      "Epoch: 2182 cost = 0.013758938\n",
      "Validation Loss: 0.02658744\n",
      "Epoch: 2183 cost = 0.013757817\n",
      "Validation Loss: 0.024911666\n",
      "Epoch: 2184 cost = 0.013756643\n",
      "Validation Loss: 0.025784226\n",
      "Epoch: 2185 cost = 0.013755840\n",
      "Validation Loss: 0.025833188\n",
      "Epoch: 2186 cost = 0.013754600\n",
      "Validation Loss: 0.024129597\n",
      "Epoch: 2187 cost = 0.013753851\n",
      "Validation Loss: 0.024811698\n",
      "Epoch: 2188 cost = 0.013752430\n",
      "Validation Loss: 0.023415487\n",
      "Epoch: 2189 cost = 0.013751803\n",
      "Validation Loss: 0.026249854\n",
      "Epoch: 2190 cost = 0.013750705\n",
      "Validation Loss: 0.028585156\n",
      "Epoch: 2191 cost = 0.013749642\n",
      "Validation Loss: 0.024584455\n",
      "Epoch: 2192 cost = 0.013748451\n",
      "Validation Loss: 0.026102418\n",
      "Epoch: 2193 cost = 0.013747455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.024271434\n",
      "Epoch: 2194 cost = 0.013746316\n",
      "Validation Loss: 0.037022702\n",
      "Epoch: 2195 cost = 0.013745526\n",
      "Validation Loss: 0.037286248\n",
      "Epoch: 2196 cost = 0.013744643\n",
      "Validation Loss: 0.031769313\n",
      "Epoch: 2197 cost = 0.013743661\n",
      "Validation Loss: 0.033094633\n",
      "Epoch: 2198 cost = 0.013742539\n",
      "Validation Loss: 0.031139934\n",
      "Epoch: 2199 cost = 0.013741548\n",
      "Validation Loss: 0.029138034\n",
      "Epoch: 2200 cost = 0.013740286\n",
      "Validation Loss: 0.042776957\n",
      "Epoch: 2201 cost = 0.013739655\n",
      "Validation Loss: 0.04298147\n",
      "Epoch: 2202 cost = 0.013738035\n",
      "Validation Loss: 0.047762275\n",
      "Epoch: 2203 cost = 0.013737479\n",
      "Validation Loss: 0.040115356\n",
      "Epoch: 2204 cost = 0.013736342\n",
      "Validation Loss: 0.024772901\n",
      "Epoch: 2205 cost = 0.013735364\n",
      "Validation Loss: 0.019963933\n",
      "Epoch: 2206 cost = 0.013734458\n",
      "Validation Loss: 0.018333293\n",
      "Epoch: 2207 cost = 0.013733667\n",
      "Validation Loss: 0.017661192\n",
      "Epoch: 2208 cost = 0.013732713\n",
      "Validation Loss: 0.02259954\n",
      "Epoch: 2209 cost = 0.013731660\n",
      "Validation Loss: 0.02658023\n",
      "Epoch: 2210 cost = 0.013729990\n",
      "Validation Loss: 0.02283931\n",
      "Epoch: 2211 cost = 0.013729408\n",
      "Validation Loss: 0.020297786\n",
      "Epoch: 2212 cost = 0.013728488\n",
      "Validation Loss: 0.028505588\n",
      "Epoch: 2213 cost = 0.013727740\n",
      "Validation Loss: 0.03101503\n",
      "Epoch: 2214 cost = 0.013726321\n",
      "Validation Loss: 0.022504132\n",
      "Epoch: 2215 cost = 0.013725655\n",
      "Validation Loss: 0.02525192\n",
      "Epoch: 2216 cost = 0.013724739\n",
      "Validation Loss: 0.022330387\n",
      "Epoch: 2217 cost = 0.013724167\n",
      "Validation Loss: 0.028118627\n",
      "Epoch: 2218 cost = 0.013722787\n",
      "Validation Loss: 0.03253169\n",
      "Epoch: 2219 cost = 0.013721650\n",
      "Validation Loss: 0.031798128\n",
      "Epoch: 2220 cost = 0.013720520\n",
      "Validation Loss: 0.028669065\n",
      "Epoch: 2221 cost = 0.013719768\n",
      "Validation Loss: 0.030871198\n",
      "Epoch: 2222 cost = 0.013718496\n",
      "Validation Loss: 0.028346695\n",
      "Epoch: 2223 cost = 0.013717710\n",
      "Validation Loss: 0.031273756\n",
      "Epoch: 2224 cost = 0.013716374\n",
      "Validation Loss: 0.027801065\n",
      "Epoch: 2225 cost = 0.013715387\n",
      "Validation Loss: 0.03396307\n",
      "Epoch: 2226 cost = 0.013714706\n",
      "Validation Loss: 0.031218844\n",
      "Epoch: 2227 cost = 0.013713883\n",
      "Validation Loss: 0.024236953\n",
      "Epoch: 2228 cost = 0.013712644\n",
      "Validation Loss: 0.024579233\n",
      "Epoch: 2229 cost = 0.013711768\n",
      "Validation Loss: 0.0203516\n",
      "Epoch: 2230 cost = 0.013710649\n",
      "Validation Loss: 0.021648947\n",
      "Epoch: 2231 cost = 0.013709931\n",
      "Validation Loss: 0.024089275\n",
      "Epoch: 2232 cost = 0.013708946\n",
      "Validation Loss: 0.022747874\n",
      "Epoch: 2233 cost = 0.013707947\n",
      "Validation Loss: 0.025189605\n",
      "Epoch: 2234 cost = 0.013707128\n",
      "Validation Loss: 0.02557177\n",
      "Epoch: 2235 cost = 0.013706705\n",
      "Validation Loss: 0.030392615\n",
      "Epoch: 2236 cost = 0.013704810\n",
      "Validation Loss: 0.028676668\n",
      "Epoch: 2237 cost = 0.013704014\n",
      "Validation Loss: 0.031486146\n",
      "Epoch: 2238 cost = 0.013702980\n",
      "Validation Loss: 0.028748682\n",
      "Epoch: 2239 cost = 0.013702174\n",
      "Validation Loss: 0.02383997\n",
      "Epoch: 2240 cost = 0.013700785\n",
      "Validation Loss: 0.026010692\n",
      "Epoch: 2241 cost = 0.013699983\n",
      "Validation Loss: 0.036285535\n",
      "Epoch: 2242 cost = 0.013699395\n",
      "Validation Loss: 0.024677452\n",
      "Epoch: 2243 cost = 0.013698226\n",
      "Validation Loss: 0.025930779\n",
      "Epoch: 2244 cost = 0.013697756\n",
      "Validation Loss: 0.027954407\n",
      "Epoch: 2245 cost = 0.013696894\n",
      "Validation Loss: 0.028226051\n",
      "Epoch: 2246 cost = 0.013695428\n",
      "Validation Loss: 0.030273726\n",
      "Epoch: 2247 cost = 0.013694546\n",
      "Validation Loss: 0.03844921\n",
      "Epoch: 2248 cost = 0.013694022\n",
      "Validation Loss: 0.042192537\n",
      "Epoch: 2249 cost = 0.013692350\n",
      "Validation Loss: 0.03254294\n",
      "Epoch: 2250 cost = 0.013691402\n",
      "Validation Loss: 0.025395352\n",
      "Epoch: 2251 cost = 0.013690872\n",
      "Validation Loss: 0.022459194\n",
      "Epoch: 2252 cost = 0.013689969\n",
      "Validation Loss: 0.022860384\n",
      "Epoch: 2253 cost = 0.013688686\n",
      "Validation Loss: 0.033054672\n",
      "Epoch: 2254 cost = 0.013687797\n",
      "Validation Loss: 0.03667462\n",
      "Epoch: 2255 cost = 0.013687198\n",
      "Validation Loss: 0.035686355\n",
      "Epoch: 2256 cost = 0.013686825\n",
      "Validation Loss: 0.036166694\n",
      "Epoch: 2257 cost = 0.013685564\n",
      "Validation Loss: 0.022083316\n",
      "Epoch: 2258 cost = 0.013684312\n",
      "Validation Loss: 0.022186553\n",
      "Epoch: 2259 cost = 0.013683061\n",
      "Validation Loss: 0.02952115\n",
      "Epoch: 2260 cost = 0.013682399\n",
      "Validation Loss: 0.038083628\n",
      "Epoch: 2261 cost = 0.013681123\n",
      "Validation Loss: 0.030479683\n",
      "Epoch: 2262 cost = 0.013680540\n",
      "Validation Loss: 0.027626064\n",
      "Epoch: 2263 cost = 0.013679110\n",
      "Validation Loss: 0.022135314\n",
      "Epoch: 2264 cost = 0.013678883\n",
      "Validation Loss: 0.021071909\n",
      "Epoch: 2265 cost = 0.013677551\n",
      "Validation Loss: 0.022561895\n",
      "Epoch: 2266 cost = 0.013676827\n",
      "Validation Loss: 0.026339166\n",
      "Epoch: 2267 cost = 0.013675954\n",
      "Validation Loss: 0.025086\n",
      "Epoch: 2268 cost = 0.013674979\n",
      "Validation Loss: 0.029636363\n",
      "Epoch: 2269 cost = 0.013674026\n",
      "Validation Loss: 0.028883755\n",
      "Epoch: 2270 cost = 0.013673190\n",
      "Validation Loss: 0.025945965\n",
      "Epoch: 2271 cost = 0.013672015\n",
      "Validation Loss: 0.034540266\n",
      "Epoch: 2272 cost = 0.013671460\n",
      "Validation Loss: 0.036999904\n",
      "Epoch: 2273 cost = 0.013670145\n",
      "Validation Loss: 0.037251472\n",
      "Epoch: 2274 cost = 0.013669463\n",
      "Validation Loss: 0.02629619\n",
      "Epoch: 2275 cost = 0.013668989\n",
      "Validation Loss: 0.051778495\n",
      "Epoch: 2276 cost = 0.013667504\n",
      "Validation Loss: 0.049847804\n",
      "Epoch: 2277 cost = 0.013666944\n",
      "Validation Loss: 0.031811096\n",
      "Epoch: 2278 cost = 0.013665622\n",
      "Validation Loss: 0.040293407\n",
      "Epoch: 2279 cost = 0.013664758\n",
      "Validation Loss: 0.028852403\n",
      "Epoch: 2280 cost = 0.013664365\n",
      "Validation Loss: 0.03373186\n",
      "Epoch: 2281 cost = 0.013663684\n",
      "Validation Loss: 0.041308295\n",
      "Epoch: 2282 cost = 0.013662084\n",
      "Validation Loss: 0.028854823\n",
      "Epoch: 2283 cost = 0.013661325\n",
      "Validation Loss: 0.024979357\n",
      "Epoch: 2284 cost = 0.013660355\n",
      "Validation Loss: 0.03209382\n",
      "Epoch: 2285 cost = 0.013659779\n",
      "Validation Loss: 0.031918306\n",
      "Epoch: 2286 cost = 0.013659017\n",
      "Validation Loss: 0.032196466\n",
      "Epoch: 2287 cost = 0.013657795\n",
      "Validation Loss: 0.029468808\n",
      "Epoch: 2288 cost = 0.013656690\n",
      "Validation Loss: 0.024053922\n",
      "Epoch: 2289 cost = 0.013655614\n",
      "Validation Loss: 0.021557806\n",
      "Epoch: 2290 cost = 0.013655124\n",
      "Validation Loss: 0.030344628\n",
      "Epoch: 2291 cost = 0.013654265\n",
      "Validation Loss: 0.040835664\n",
      "Epoch: 2292 cost = 0.013653238\n",
      "Validation Loss: 0.031966317\n",
      "Epoch: 2293 cost = 0.013652156\n",
      "Validation Loss: 0.031678747\n",
      "Epoch: 2294 cost = 0.013651215\n",
      "Validation Loss: 0.036248986\n",
      "Epoch: 2295 cost = 0.013650256\n",
      "Validation Loss: 0.047929164\n",
      "Epoch: 2296 cost = 0.013649416\n",
      "Validation Loss: 0.055981677\n",
      "Epoch: 2297 cost = 0.013648568\n",
      "Validation Loss: 0.064239725\n",
      "Epoch: 2298 cost = 0.013648101\n",
      "Validation Loss: 0.048926394\n",
      "Epoch: 2299 cost = 0.013647016\n",
      "Validation Loss: 0.029947285\n",
      "Epoch: 2300 cost = 0.013646237\n",
      "Validation Loss: 0.03331084\n",
      "Epoch: 2301 cost = 0.013645070\n",
      "Validation Loss: 0.042773183\n",
      "Epoch: 2302 cost = 0.013644519\n",
      "Validation Loss: 0.027618282\n",
      "Epoch: 2303 cost = 0.013643004\n",
      "Validation Loss: 0.029615328\n",
      "Epoch: 2304 cost = 0.013642912\n",
      "Validation Loss: 0.03307824\n",
      "Epoch: 2305 cost = 0.013641959\n",
      "Validation Loss: 0.031760912\n",
      "Epoch: 2306 cost = 0.013640900\n",
      "Validation Loss: 0.0316754\n",
      "Epoch: 2307 cost = 0.013640500\n",
      "Validation Loss: 0.025308875\n",
      "Epoch: 2308 cost = 0.013639296\n",
      "Validation Loss: 0.049562316\n",
      "Epoch: 2309 cost = 0.013638496\n",
      "Validation Loss: 0.0495943\n",
      "Epoch: 2310 cost = 0.013637742\n",
      "Validation Loss: 0.056296732\n",
      "Epoch: 2311 cost = 0.013636511\n",
      "Validation Loss: 0.04653642\n",
      "Epoch: 2312 cost = 0.013635239\n",
      "Validation Loss: 0.030723756\n",
      "Epoch: 2313 cost = 0.013634858\n",
      "Validation Loss: 0.02479833\n",
      "Epoch: 2314 cost = 0.013633841\n",
      "Validation Loss: 0.027157627\n",
      "Epoch: 2315 cost = 0.013633058\n",
      "Validation Loss: 0.01881187\n",
      "Epoch: 2316 cost = 0.013632190\n",
      "Validation Loss: 0.018965174\n",
      "Epoch: 2317 cost = 0.013631357\n",
      "Validation Loss: 0.022093946\n",
      "Epoch: 2318 cost = 0.013630420\n",
      "Validation Loss: 0.026476156\n",
      "Epoch: 2319 cost = 0.013629655\n",
      "Validation Loss: 0.02065334\n",
      "Epoch: 2320 cost = 0.013628751\n",
      "Validation Loss: 0.021804972\n",
      "Epoch: 2321 cost = 0.013627908\n",
      "Validation Loss: 0.02388158\n",
      "Epoch: 2322 cost = 0.013626670\n",
      "Validation Loss: 0.023774186\n",
      "Epoch: 2323 cost = 0.013626229\n",
      "Validation Loss: 0.022145832\n",
      "Epoch: 2324 cost = 0.013625410\n",
      "Validation Loss: 0.020614777\n",
      "Epoch: 2325 cost = 0.013624725\n",
      "Validation Loss: 0.026229661\n",
      "Epoch: 2326 cost = 0.013623009\n",
      "Validation Loss: 0.028597804\n",
      "Epoch: 2327 cost = 0.013622868\n",
      "Validation Loss: 0.035154354\n",
      "Epoch: 2328 cost = 0.013621577\n",
      "Validation Loss: 0.03786882\n",
      "Epoch: 2329 cost = 0.013621377\n",
      "Validation Loss: 0.026321322\n",
      "Epoch: 2330 cost = 0.013619653\n",
      "Validation Loss: 0.02656532\n",
      "Epoch: 2331 cost = 0.013619180\n",
      "Validation Loss: 0.033086475\n",
      "Epoch: 2332 cost = 0.013618175\n",
      "Validation Loss: 0.027220706\n",
      "Epoch: 2333 cost = 0.013616983\n",
      "Validation Loss: 0.03295464\n",
      "Epoch: 2334 cost = 0.013617081\n",
      "Validation Loss: 0.03883084\n",
      "Epoch: 2335 cost = 0.013616164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.035758514\n",
      "Epoch: 2336 cost = 0.013615423\n",
      "Validation Loss: 0.040377434\n",
      "Epoch: 2337 cost = 0.013613858\n",
      "Validation Loss: 0.043873683\n",
      "Epoch: 2338 cost = 0.013613174\n",
      "Validation Loss: 0.052529365\n",
      "Epoch: 2339 cost = 0.013612622\n",
      "Validation Loss: 0.03024922\n",
      "Epoch: 2340 cost = 0.013611411\n",
      "Validation Loss: 0.047285683\n",
      "Epoch: 2341 cost = 0.013610963\n",
      "Validation Loss: 0.03845003\n",
      "Epoch: 2342 cost = 0.013610240\n",
      "Validation Loss: 0.020763626\n",
      "Epoch: 2343 cost = 0.013609086\n",
      "Validation Loss: 0.021631224\n",
      "Epoch: 2344 cost = 0.013608831\n",
      "Validation Loss: 0.02669251\n",
      "Epoch: 2345 cost = 0.013607707\n",
      "Validation Loss: 0.024888117\n",
      "Epoch: 2346 cost = 0.013606984\n",
      "Validation Loss: 0.03695918\n",
      "Epoch: 2347 cost = 0.013605876\n",
      "Validation Loss: 0.03914007\n",
      "Epoch: 2348 cost = 0.013604534\n",
      "Validation Loss: 0.03605621\n",
      "Epoch: 2349 cost = 0.013604281\n",
      "Validation Loss: 0.02736824\n",
      "Epoch: 2350 cost = 0.013603008\n",
      "Validation Loss: 0.021791419\n",
      "Epoch: 2351 cost = 0.013602231\n",
      "Validation Loss: 0.02397838\n",
      "Epoch: 2352 cost = 0.013601952\n",
      "Validation Loss: 0.028297357\n",
      "Epoch: 2353 cost = 0.013600221\n",
      "Validation Loss: 0.025661774\n",
      "Epoch: 2354 cost = 0.013600217\n",
      "Validation Loss: 0.027829092\n",
      "Epoch: 2355 cost = 0.013599164\n",
      "Validation Loss: 0.03008315\n",
      "Epoch: 2356 cost = 0.013598558\n",
      "Validation Loss: 0.028277779\n",
      "Epoch: 2357 cost = 0.013597436\n",
      "Validation Loss: 0.036751747\n",
      "Epoch: 2358 cost = 0.013596598\n",
      "Validation Loss: 0.036590256\n",
      "Epoch: 2359 cost = 0.013596055\n",
      "Validation Loss: 0.032627363\n",
      "Epoch: 2360 cost = 0.013594762\n",
      "Validation Loss: 0.037125252\n",
      "Epoch: 2361 cost = 0.013594362\n",
      "Validation Loss: 0.027328068\n",
      "Epoch: 2362 cost = 0.013593115\n",
      "Validation Loss: 0.03368026\n",
      "Epoch: 2363 cost = 0.013592493\n",
      "Validation Loss: 0.038604856\n",
      "Epoch: 2364 cost = 0.013591667\n",
      "Validation Loss: 0.0406902\n",
      "Epoch: 2365 cost = 0.013590901\n",
      "Validation Loss: 0.036349952\n",
      "Epoch: 2366 cost = 0.013589815\n",
      "Validation Loss: 0.026503941\n",
      "Epoch: 2367 cost = 0.013589112\n",
      "Validation Loss: 0.02609348\n",
      "Epoch: 2368 cost = 0.013588217\n",
      "Validation Loss: 0.02825148\n",
      "Epoch: 2369 cost = 0.013587886\n",
      "Validation Loss: 0.030798335\n",
      "Epoch: 2370 cost = 0.013587169\n",
      "Validation Loss: 0.027237328\n",
      "Epoch: 2371 cost = 0.013585930\n",
      "Validation Loss: 0.025250172\n",
      "Epoch: 2372 cost = 0.013585120\n",
      "Validation Loss: 0.023470966\n",
      "Epoch: 2373 cost = 0.013584889\n",
      "Validation Loss: 0.021088183\n",
      "Epoch: 2374 cost = 0.013583321\n",
      "Validation Loss: 0.02751516\n",
      "Epoch: 2375 cost = 0.013582751\n",
      "Validation Loss: 0.027288683\n",
      "Epoch: 2376 cost = 0.013582030\n",
      "Validation Loss: 0.02341153\n",
      "Epoch: 2377 cost = 0.013580667\n",
      "Validation Loss: 0.023670748\n",
      "Epoch: 2378 cost = 0.013580804\n",
      "Validation Loss: 0.026180876\n",
      "Epoch: 2379 cost = 0.013579755\n",
      "Validation Loss: 0.031115752\n",
      "Epoch: 2380 cost = 0.013579241\n",
      "Validation Loss: 0.0314993\n",
      "Epoch: 2381 cost = 0.013578272\n",
      "Validation Loss: 0.03547749\n",
      "Epoch: 2382 cost = 0.013577186\n",
      "Validation Loss: 0.03688148\n",
      "Epoch: 2383 cost = 0.013576258\n",
      "Validation Loss: 0.031784683\n",
      "Epoch: 2384 cost = 0.013575587\n",
      "Validation Loss: 0.02263166\n",
      "Epoch: 2385 cost = 0.013574681\n",
      "Validation Loss: 0.0369664\n",
      "Epoch: 2386 cost = 0.013574089\n",
      "Validation Loss: 0.03000096\n",
      "Epoch: 2387 cost = 0.013573298\n",
      "Validation Loss: 0.019448396\n",
      "Epoch: 2388 cost = 0.013572330\n",
      "Validation Loss: 0.017559087\n",
      "Epoch: 2389 cost = 0.013571879\n",
      "Validation Loss: 0.031545375\n",
      "Epoch: 2390 cost = 0.013571166\n",
      "Validation Loss: 0.027763626\n",
      "Epoch: 2391 cost = 0.013569929\n",
      "Validation Loss: 0.033337682\n",
      "Epoch: 2392 cost = 0.013568800\n",
      "Validation Loss: 0.028190961\n",
      "Epoch: 2393 cost = 0.013568099\n",
      "Validation Loss: 0.027779603\n",
      "Epoch: 2394 cost = 0.013568309\n",
      "Validation Loss: 0.03196494\n",
      "Epoch: 2395 cost = 0.013566288\n",
      "Validation Loss: 0.031351592\n",
      "Epoch: 2396 cost = 0.013566060\n",
      "Validation Loss: 0.03186008\n",
      "Epoch: 2397 cost = 0.013565544\n",
      "Validation Loss: 0.030634986\n",
      "Epoch: 2398 cost = 0.013564663\n",
      "Validation Loss: 0.026116272\n",
      "Epoch: 2399 cost = 0.013563665\n",
      "Validation Loss: 0.022130987\n",
      "Epoch: 2400 cost = 0.013562934\n",
      "Validation Loss: 0.02486029\n",
      "Epoch: 2401 cost = 0.013562388\n",
      "Validation Loss: 0.022507355\n",
      "Epoch: 2402 cost = 0.013561577\n",
      "Validation Loss: 0.029905219\n",
      "Epoch: 2403 cost = 0.013560419\n",
      "Validation Loss: 0.033552837\n",
      "Epoch: 2404 cost = 0.013559825\n",
      "Validation Loss: 0.03527225\n",
      "Epoch: 2405 cost = 0.013558930\n",
      "Validation Loss: 0.03451682\n",
      "Epoch: 2406 cost = 0.013558187\n",
      "Validation Loss: 0.031375244\n",
      "Epoch: 2407 cost = 0.013557479\n",
      "Validation Loss: 0.022698889\n",
      "Epoch: 2408 cost = 0.013557028\n",
      "Validation Loss: 0.02861474\n",
      "Epoch: 2409 cost = 0.013555647\n",
      "Validation Loss: 0.025173457\n",
      "Epoch: 2410 cost = 0.013554982\n",
      "Validation Loss: 0.038252264\n",
      "Epoch: 2411 cost = 0.013554238\n",
      "Validation Loss: 0.035762735\n",
      "Epoch: 2412 cost = 0.013553451\n",
      "Validation Loss: 0.024715116\n",
      "Epoch: 2413 cost = 0.013552606\n",
      "Validation Loss: 0.021772094\n",
      "Epoch: 2414 cost = 0.013551986\n",
      "Validation Loss: 0.02177941\n",
      "Epoch: 2415 cost = 0.013551193\n",
      "Validation Loss: 0.02511944\n",
      "Epoch: 2416 cost = 0.013550195\n",
      "Validation Loss: 0.03346089\n",
      "Epoch: 2417 cost = 0.013549370\n",
      "Validation Loss: 0.03519443\n",
      "Epoch: 2418 cost = 0.013549003\n",
      "Validation Loss: 0.028229503\n",
      "Epoch: 2419 cost = 0.013547935\n",
      "Validation Loss: 0.024928918\n",
      "Epoch: 2420 cost = 0.013547114\n",
      "Validation Loss: 0.026358921\n",
      "Epoch: 2421 cost = 0.013546583\n",
      "Validation Loss: 0.028333947\n",
      "Epoch: 2422 cost = 0.013545460\n",
      "Validation Loss: 0.02681888\n",
      "Epoch: 2423 cost = 0.013545169\n",
      "Validation Loss: 0.026967935\n",
      "Epoch: 2424 cost = 0.013544153\n",
      "Validation Loss: 0.028587732\n",
      "Epoch: 2425 cost = 0.013543477\n",
      "Validation Loss: 0.025426317\n",
      "Epoch: 2426 cost = 0.013542717\n",
      "Validation Loss: 0.028448002\n",
      "Epoch: 2427 cost = 0.013542337\n",
      "Validation Loss: 0.034908496\n",
      "Epoch: 2428 cost = 0.013541015\n",
      "Validation Loss: 0.023855487\n",
      "Epoch: 2429 cost = 0.013540143\n",
      "Validation Loss: 0.029922992\n",
      "Epoch: 2430 cost = 0.013539656\n",
      "Validation Loss: 0.023569524\n",
      "Epoch: 2431 cost = 0.013538718\n",
      "Validation Loss: 0.028619522\n",
      "Epoch: 2432 cost = 0.013538316\n",
      "Validation Loss: 0.037073746\n",
      "Epoch: 2433 cost = 0.013537897\n",
      "Validation Loss: 0.027058203\n",
      "Epoch: 2434 cost = 0.013536781\n",
      "Validation Loss: 0.02708423\n",
      "Epoch: 2435 cost = 0.013536398\n",
      "Validation Loss: 0.02700786\n",
      "Epoch: 2436 cost = 0.013535120\n",
      "Validation Loss: 0.026355874\n",
      "Epoch: 2437 cost = 0.013533869\n",
      "Validation Loss: 0.023260333\n",
      "Epoch: 2438 cost = 0.013533888\n",
      "Validation Loss: 0.024049038\n",
      "Epoch: 2439 cost = 0.013532699\n",
      "Validation Loss: 0.033668928\n",
      "Epoch: 2440 cost = 0.013532441\n",
      "Validation Loss: 0.032030914\n",
      "Epoch: 2441 cost = 0.013531046\n",
      "Validation Loss: 0.030758245\n",
      "Epoch: 2442 cost = 0.013530685\n",
      "Validation Loss: 0.03361381\n",
      "Epoch: 2443 cost = 0.013529898\n",
      "Validation Loss: 0.027655954\n",
      "Epoch: 2444 cost = 0.013529012\n",
      "Validation Loss: 0.021262674\n",
      "Epoch: 2445 cost = 0.013528566\n",
      "Validation Loss: 0.022384768\n",
      "Epoch: 2446 cost = 0.013527564\n",
      "Validation Loss: 0.021199802\n",
      "Epoch: 2447 cost = 0.013526662\n",
      "Validation Loss: 0.025734177\n",
      "Epoch: 2448 cost = 0.013525951\n",
      "Validation Loss: 0.030078439\n",
      "Epoch: 2449 cost = 0.013525259\n",
      "Validation Loss: 0.029417044\n",
      "Epoch: 2450 cost = 0.013524825\n",
      "Validation Loss: 0.023170488\n",
      "Epoch: 2451 cost = 0.013524219\n",
      "Validation Loss: 0.022386972\n",
      "Epoch: 2452 cost = 0.013523070\n",
      "Validation Loss: 0.025721213\n",
      "Epoch: 2453 cost = 0.013521920\n",
      "Validation Loss: 0.026638828\n",
      "Epoch: 2454 cost = 0.013521514\n",
      "Validation Loss: 0.03346486\n",
      "Epoch: 2455 cost = 0.013521200\n",
      "Validation Loss: 0.035214186\n",
      "Epoch: 2456 cost = 0.013519956\n",
      "Validation Loss: 0.03308028\n",
      "Epoch: 2457 cost = 0.013519599\n",
      "Validation Loss: 0.03375349\n",
      "Epoch: 2458 cost = 0.013519008\n",
      "Validation Loss: 0.028545197\n",
      "Epoch: 2459 cost = 0.013517605\n",
      "Validation Loss: 0.024871178\n",
      "Epoch: 2460 cost = 0.013517193\n",
      "Validation Loss: 0.022833137\n",
      "Epoch: 2461 cost = 0.013516569\n",
      "Validation Loss: 0.026152417\n",
      "Epoch: 2462 cost = 0.013515687\n",
      "Validation Loss: 0.023154393\n",
      "Epoch: 2463 cost = 0.013515165\n",
      "Validation Loss: 0.021495067\n",
      "Epoch: 2464 cost = 0.013514600\n",
      "Validation Loss: 0.030683823\n",
      "Epoch: 2465 cost = 0.013513348\n",
      "Validation Loss: 0.030857764\n",
      "Epoch: 2466 cost = 0.013512897\n",
      "Validation Loss: 0.03241563\n",
      "Epoch: 2467 cost = 0.013512174\n",
      "Validation Loss: 0.03230688\n",
      "Epoch: 2468 cost = 0.013511143\n",
      "Validation Loss: 0.027070135\n",
      "Epoch: 2469 cost = 0.013510142\n",
      "Validation Loss: 0.03128752\n",
      "Epoch: 2470 cost = 0.013509891\n",
      "Validation Loss: 0.040047262\n",
      "Epoch: 2471 cost = 0.013509216\n",
      "Validation Loss: 0.039145067\n",
      "Epoch: 2472 cost = 0.013508523\n",
      "Validation Loss: 0.045681078\n",
      "Epoch: 2473 cost = 0.013507894\n",
      "Validation Loss: 0.043848753\n",
      "Epoch: 2474 cost = 0.013506889\n",
      "Validation Loss: 0.028661197\n",
      "Epoch: 2475 cost = 0.013506987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.021052428\n",
      "Epoch: 2476 cost = 0.013505435\n",
      "Validation Loss: 0.03117418\n",
      "Epoch: 2477 cost = 0.013504783\n",
      "Validation Loss: 0.032402266\n",
      "Epoch: 2478 cost = 0.013504577\n",
      "Validation Loss: 0.036705866\n",
      "Epoch: 2479 cost = 0.013503653\n",
      "Validation Loss: 0.032379124\n",
      "Epoch: 2480 cost = 0.013503186\n",
      "Validation Loss: 0.03412478\n",
      "Epoch: 2481 cost = 0.013502036\n",
      "Validation Loss: 0.029033646\n",
      "Epoch: 2482 cost = 0.013501250\n",
      "Validation Loss: 0.022461694\n",
      "Epoch: 2483 cost = 0.013500430\n",
      "Validation Loss: 0.016102888\n",
      "Epoch: 2484 cost = 0.013499930\n",
      "Validation Loss: 0.025147237\n",
      "Epoch: 2485 cost = 0.013499021\n",
      "Validation Loss: 0.021586182\n",
      "Epoch: 2486 cost = 0.013498874\n",
      "Validation Loss: 0.031300124\n",
      "Epoch: 2487 cost = 0.013497643\n",
      "Validation Loss: 0.032022696\n",
      "Epoch: 2488 cost = 0.013497323\n",
      "Validation Loss: 0.03371305\n",
      "Epoch: 2489 cost = 0.013496048\n",
      "Validation Loss: 0.023200119\n",
      "Epoch: 2490 cost = 0.013495559\n",
      "Validation Loss: 0.03083023\n",
      "Epoch: 2491 cost = 0.013494526\n",
      "Validation Loss: 0.03054989\n",
      "Epoch: 2492 cost = 0.013493958\n",
      "Validation Loss: 0.025697306\n",
      "Epoch: 2493 cost = 0.013493370\n",
      "Validation Loss: 0.02034918\n",
      "Epoch: 2494 cost = 0.013492770\n",
      "Validation Loss: 0.020796677\n",
      "Epoch: 2495 cost = 0.013491874\n",
      "Validation Loss: 0.022066284\n",
      "Epoch: 2496 cost = 0.013491500\n",
      "Validation Loss: 0.026578646\n",
      "Epoch: 2497 cost = 0.013489986\n",
      "Validation Loss: 0.025001742\n",
      "Epoch: 2498 cost = 0.013489517\n",
      "Validation Loss: 0.023229929\n",
      "Epoch: 2499 cost = 0.013488936\n",
      "Validation Loss: 0.025251932\n",
      "Epoch: 2500 cost = 0.013488350\n",
      "Validation Loss: 0.021705767\n",
      "Epoch: 2501 cost = 0.013488169\n",
      "Validation Loss: 0.02498492\n",
      "Epoch: 2502 cost = 0.013486790\n",
      "Validation Loss: 0.03246975\n",
      "Epoch: 2503 cost = 0.013485866\n",
      "Validation Loss: 0.030430522\n",
      "Epoch: 2504 cost = 0.013485739\n",
      "Validation Loss: 0.027938899\n",
      "Epoch: 2505 cost = 0.013484996\n",
      "Validation Loss: 0.032953657\n",
      "Epoch: 2506 cost = 0.013483699\n",
      "Validation Loss: 0.033269953\n",
      "Epoch: 2507 cost = 0.013483893\n",
      "Validation Loss: 0.024084134\n",
      "Epoch: 2508 cost = 0.013482433\n",
      "Validation Loss: 0.020016886\n",
      "Epoch: 2509 cost = 0.013482361\n",
      "Validation Loss: 0.013057476\n",
      "Epoch: 2510 cost = 0.013481282\n",
      "Validation Loss: 0.01980608\n",
      "Epoch: 2511 cost = 0.013480900\n",
      "Validation Loss: 0.027144998\n",
      "Epoch: 2512 cost = 0.013480104\n",
      "Validation Loss: 0.021794086\n",
      "Epoch: 2513 cost = 0.013479290\n",
      "Validation Loss: 0.016443186\n",
      "Epoch: 2514 cost = 0.013478464\n",
      "Validation Loss: 0.010266256\n",
      "Epoch: 2515 cost = 0.013477527\n",
      "Validation Loss: 0.035558436\n",
      "Epoch: 2516 cost = 0.013477751\n",
      "Validation Loss: 0.03381781\n",
      "Epoch: 2517 cost = 0.013476589\n",
      "Validation Loss: 0.03193889\n",
      "Epoch: 2518 cost = 0.013475848\n",
      "Validation Loss: 0.01652532\n",
      "Epoch: 2519 cost = 0.013474418\n",
      "Validation Loss: 0.02702925\n",
      "Epoch: 2520 cost = 0.013474564\n",
      "Validation Loss: 0.047903128\n",
      "Epoch: 2521 cost = 0.013473874\n",
      "Validation Loss: 0.059458118\n",
      "Epoch: 2522 cost = 0.013473026\n",
      "Validation Loss: 0.02865259\n",
      "Epoch: 2523 cost = 0.013472403\n",
      "Validation Loss: 0.023383927\n",
      "Epoch: 2524 cost = 0.013471789\n",
      "Validation Loss: 0.027403254\n",
      "Epoch: 2525 cost = 0.013470821\n",
      "Validation Loss: 0.019053949\n",
      "Epoch: 2526 cost = 0.013470307\n",
      "Validation Loss: 0.025469586\n",
      "Epoch: 2527 cost = 0.013469688\n",
      "Validation Loss: 0.031212812\n",
      "Epoch: 2528 cost = 0.013469004\n",
      "Validation Loss: 0.03514598\n",
      "Epoch: 2529 cost = 0.013468497\n",
      "Validation Loss: 0.04325093\n",
      "Epoch: 2530 cost = 0.013467494\n",
      "Validation Loss: 0.047266997\n",
      "Epoch: 2531 cost = 0.013466492\n",
      "Validation Loss: 0.03845841\n",
      "Epoch: 2532 cost = 0.013466206\n",
      "Validation Loss: 0.03333215\n",
      "Epoch: 2533 cost = 0.013465438\n",
      "Validation Loss: 0.02023846\n",
      "Epoch: 2534 cost = 0.013464792\n",
      "Validation Loss: 0.028718444\n",
      "Epoch: 2535 cost = 0.013464052\n",
      "Validation Loss: 0.037033435\n",
      "Epoch: 2536 cost = 0.013463451\n",
      "Validation Loss: 0.034050517\n",
      "Epoch: 2537 cost = 0.013463376\n",
      "Validation Loss: 0.0319107\n",
      "Epoch: 2538 cost = 0.013461924\n",
      "Validation Loss: 0.025773626\n",
      "Epoch: 2539 cost = 0.013461381\n",
      "Validation Loss: 0.033873152\n",
      "Epoch: 2540 cost = 0.013460377\n",
      "Validation Loss: 0.020788569\n",
      "Epoch: 2541 cost = 0.013460178\n",
      "Validation Loss: 0.02908091\n",
      "Epoch: 2542 cost = 0.013459656\n",
      "Validation Loss: 0.0365576\n",
      "Epoch: 2543 cost = 0.013458450\n",
      "Validation Loss: 0.04210369\n",
      "Epoch: 2544 cost = 0.013458013\n",
      "Validation Loss: 0.044490676\n",
      "Epoch: 2545 cost = 0.013457242\n",
      "Validation Loss: 0.038604002\n",
      "Epoch: 2546 cost = 0.013456717\n",
      "Validation Loss: 0.027400421\n",
      "Epoch: 2547 cost = 0.013455752\n",
      "Validation Loss: 0.03306851\n",
      "Epoch: 2548 cost = 0.013455611\n",
      "Validation Loss: 0.025153706\n",
      "Epoch: 2549 cost = 0.013454662\n",
      "Validation Loss: 0.03149163\n",
      "Epoch: 2550 cost = 0.013453639\n",
      "Validation Loss: 0.037093487\n",
      "Epoch: 2551 cost = 0.013453519\n",
      "Validation Loss: 0.026128264\n",
      "Epoch: 2552 cost = 0.013452837\n",
      "Validation Loss: 0.027895521\n",
      "Epoch: 2553 cost = 0.013452200\n",
      "Validation Loss: 0.043281063\n",
      "Epoch: 2554 cost = 0.013451483\n",
      "Validation Loss: 0.04047914\n",
      "Epoch: 2555 cost = 0.013450417\n",
      "Validation Loss: 0.032731686\n",
      "Epoch: 2556 cost = 0.013449966\n",
      "Validation Loss: 0.030074038\n",
      "Epoch: 2557 cost = 0.013449394\n",
      "Validation Loss: 0.03229797\n",
      "Epoch: 2558 cost = 0.013448388\n",
      "Validation Loss: 0.04885791\n",
      "Epoch: 2559 cost = 0.013447861\n",
      "Validation Loss: 0.05064971\n",
      "Epoch: 2560 cost = 0.013446977\n",
      "Validation Loss: 0.037723947\n",
      "Epoch: 2561 cost = 0.013446681\n",
      "Validation Loss: 0.029072905\n",
      "Epoch: 2562 cost = 0.013446065\n",
      "Validation Loss: 0.030233996\n",
      "Epoch: 2563 cost = 0.013445249\n",
      "Validation Loss: 0.03042028\n",
      "Epoch: 2564 cost = 0.013444976\n",
      "Validation Loss: 0.0313549\n",
      "Epoch: 2565 cost = 0.013444525\n",
      "Validation Loss: 0.031373695\n",
      "Epoch: 2566 cost = 0.013443396\n",
      "Validation Loss: 0.03409326\n",
      "Epoch: 2567 cost = 0.013442398\n",
      "Validation Loss: 0.036363676\n",
      "Epoch: 2568 cost = 0.013441789\n",
      "Validation Loss: 0.03531169\n",
      "Epoch: 2569 cost = 0.013441452\n",
      "Validation Loss: 0.030535607\n",
      "Epoch: 2570 cost = 0.013440763\n",
      "Validation Loss: 0.019104496\n",
      "Epoch: 2571 cost = 0.013439844\n",
      "Validation Loss: 0.020873649\n",
      "Epoch: 2572 cost = 0.013439116\n",
      "Validation Loss: 0.028090661\n",
      "Epoch: 2573 cost = 0.013439257\n",
      "Validation Loss: 0.02332072\n",
      "Epoch: 2574 cost = 0.013437972\n",
      "Validation Loss: 0.02797462\n",
      "Epoch: 2575 cost = 0.013437179\n",
      "Validation Loss: 0.030095069\n",
      "Epoch: 2576 cost = 0.013436832\n",
      "Validation Loss: 0.03993034\n",
      "Epoch: 2577 cost = 0.013435981\n",
      "Validation Loss: 0.03236142\n",
      "Epoch: 2578 cost = 0.013435167\n",
      "Validation Loss: 0.023902869\n",
      "Epoch: 2579 cost = 0.013434704\n",
      "Validation Loss: 0.022127034\n",
      "Epoch: 2580 cost = 0.013434207\n",
      "Validation Loss: 0.028955907\n",
      "Epoch: 2581 cost = 0.013434078\n",
      "Validation Loss: 0.02747985\n",
      "Epoch: 2582 cost = 0.013432652\n",
      "Validation Loss: 0.020518297\n",
      "Epoch: 2583 cost = 0.013432206\n",
      "Validation Loss: 0.018622553\n",
      "Epoch: 2584 cost = 0.013431484\n",
      "Validation Loss: 0.024073862\n",
      "Epoch: 2585 cost = 0.013430399\n",
      "Validation Loss: 0.03436927\n",
      "Epoch: 2586 cost = 0.013430076\n",
      "Validation Loss: 0.046189684\n",
      "Epoch: 2587 cost = 0.013429674\n",
      "Validation Loss: 0.03339151\n",
      "Epoch: 2588 cost = 0.013429065\n",
      "Validation Loss: 0.027921971\n",
      "Epoch: 2589 cost = 0.013428357\n",
      "Validation Loss: 0.029246407\n",
      "Epoch: 2590 cost = 0.013428229\n",
      "Validation Loss: 0.026253292\n",
      "Epoch: 2591 cost = 0.013426637\n",
      "Validation Loss: 0.028544538\n",
      "Epoch: 2592 cost = 0.013426313\n",
      "Validation Loss: 0.027309481\n",
      "Epoch: 2593 cost = 0.013425949\n",
      "Validation Loss: 0.035925154\n",
      "Epoch: 2594 cost = 0.013425041\n",
      "Validation Loss: 0.03557221\n",
      "Epoch: 2595 cost = 0.013424387\n",
      "Validation Loss: 0.032820288\n",
      "Epoch: 2596 cost = 0.013423876\n",
      "Validation Loss: 0.03424697\n",
      "Epoch: 2597 cost = 0.013423040\n",
      "Validation Loss: 0.030441223\n",
      "Epoch: 2598 cost = 0.013422620\n",
      "Validation Loss: 0.033309612\n",
      "Epoch: 2599 cost = 0.013421305\n",
      "Validation Loss: 0.028319493\n",
      "Epoch: 2600 cost = 0.013420971\n",
      "Validation Loss: 0.030099975\n",
      "Epoch: 2601 cost = 0.013420467\n",
      "Validation Loss: 0.033973288\n",
      "Epoch: 2602 cost = 0.013419921\n",
      "Validation Loss: 0.043129455\n",
      "Epoch: 2603 cost = 0.013419306\n",
      "Validation Loss: 0.043223456\n",
      "Epoch: 2604 cost = 0.013418434\n",
      "Validation Loss: 0.038844347\n",
      "Epoch: 2605 cost = 0.013418073\n",
      "Validation Loss: 0.024873499\n",
      "Epoch: 2606 cost = 0.013417832\n",
      "Validation Loss: 0.02545121\n",
      "Epoch: 2607 cost = 0.013417489\n",
      "Validation Loss: 0.023378557\n",
      "Epoch: 2608 cost = 0.013416220\n",
      "Validation Loss: 0.018111214\n",
      "Epoch: 2609 cost = 0.013416013\n",
      "Validation Loss: 0.024598796\n",
      "Epoch: 2610 cost = 0.013414903\n",
      "Validation Loss: 0.028907288\n",
      "Epoch: 2611 cost = 0.013414275\n",
      "Validation Loss: 0.024737412\n",
      "Epoch: 2612 cost = 0.013413279\n",
      "Validation Loss: 0.023524467\n",
      "Epoch: 2613 cost = 0.013412943\n",
      "Validation Loss: 0.02515129\n",
      "Epoch: 2614 cost = 0.013412664\n",
      "Validation Loss: 0.02508808\n",
      "Epoch: 2615 cost = 0.013411604\n",
      "Validation Loss: 0.027693141\n",
      "Epoch: 2616 cost = 0.013411200\n",
      "Validation Loss: 0.029988991\n",
      "Epoch: 2617 cost = 0.013410922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.034689218\n",
      "Epoch: 2618 cost = 0.013410258\n",
      "Validation Loss: 0.032752544\n",
      "Epoch: 2619 cost = 0.013408724\n",
      "Validation Loss: 0.025840364\n",
      "Epoch: 2620 cost = 0.013409002\n",
      "Validation Loss: 0.025923666\n",
      "Epoch: 2621 cost = 0.013407616\n",
      "Validation Loss: 0.024908215\n",
      "Epoch: 2622 cost = 0.013407301\n",
      "Validation Loss: 0.034739997\n",
      "Epoch: 2623 cost = 0.013406795\n",
      "Validation Loss: 0.03308585\n",
      "Epoch: 2624 cost = 0.013405638\n",
      "Validation Loss: 0.025435962\n",
      "Epoch: 2625 cost = 0.013405694\n",
      "Validation Loss: 0.019369446\n",
      "Epoch: 2626 cost = 0.013404881\n",
      "Validation Loss: 0.021826372\n",
      "Epoch: 2627 cost = 0.013404190\n",
      "Validation Loss: 0.027469633\n",
      "Epoch: 2628 cost = 0.013403501\n",
      "Validation Loss: 0.033626825\n",
      "Epoch: 2629 cost = 0.013402918\n",
      "Validation Loss: 0.03895973\n",
      "Epoch: 2630 cost = 0.013402664\n",
      "Validation Loss: 0.045038283\n",
      "Epoch: 2631 cost = 0.013401491\n",
      "Validation Loss: 0.041637775\n",
      "Epoch: 2632 cost = 0.013401344\n",
      "Validation Loss: 0.029183747\n",
      "Epoch: 2633 cost = 0.013400504\n",
      "Validation Loss: 0.025104893\n",
      "Epoch: 2634 cost = 0.013400097\n",
      "Validation Loss: 0.025563084\n",
      "Epoch: 2635 cost = 0.013398888\n",
      "Validation Loss: 0.028174339\n",
      "Epoch: 2636 cost = 0.013398430\n",
      "Validation Loss: 0.033414528\n",
      "Epoch: 2637 cost = 0.013397763\n",
      "Validation Loss: 0.03701543\n",
      "Epoch: 2638 cost = 0.013397680\n",
      "Validation Loss: 0.029192545\n",
      "Epoch: 2639 cost = 0.013396291\n",
      "Validation Loss: 0.019374346\n",
      "Epoch: 2640 cost = 0.013396254\n",
      "Validation Loss: 0.023213297\n",
      "Epoch: 2641 cost = 0.013395318\n",
      "Validation Loss: 0.0174094\n",
      "Epoch: 2642 cost = 0.013395087\n",
      "Validation Loss: 0.0142205795\n",
      "Epoch: 2643 cost = 0.013394013\n",
      "Validation Loss: 0.024142137\n",
      "Epoch: 2644 cost = 0.013393576\n",
      "Validation Loss: 0.030853096\n",
      "Epoch: 2645 cost = 0.013392928\n",
      "Validation Loss: 0.027218487\n",
      "Epoch: 2646 cost = 0.013392427\n",
      "Validation Loss: 0.025652967\n",
      "Epoch: 2647 cost = 0.013392171\n",
      "Validation Loss: 0.021469176\n",
      "Epoch: 2648 cost = 0.013391056\n",
      "Validation Loss: 0.026145605\n",
      "Epoch: 2649 cost = 0.013390975\n",
      "Validation Loss: 0.033130534\n",
      "Epoch: 2650 cost = 0.013390130\n",
      "Validation Loss: 0.024630256\n",
      "Epoch: 2651 cost = 0.013389039\n",
      "Validation Loss: 0.031104028\n",
      "Epoch: 2652 cost = 0.013388682\n",
      "Validation Loss: 0.056864034\n",
      "Epoch: 2653 cost = 0.013388177\n",
      "Validation Loss: 0.047066323\n",
      "Epoch: 2654 cost = 0.013387429\n",
      "Validation Loss: 0.027222877\n",
      "Epoch: 2655 cost = 0.013386820\n",
      "Validation Loss: 0.03561171\n",
      "Epoch: 2656 cost = 0.013385963\n",
      "Validation Loss: 0.044381183\n",
      "Epoch: 2657 cost = 0.013385742\n",
      "Validation Loss: 0.03366\n",
      "Epoch: 2658 cost = 0.013384969\n",
      "Validation Loss: 0.030486736\n",
      "Epoch: 2659 cost = 0.013384556\n",
      "Validation Loss: 0.030250628\n",
      "Epoch: 2660 cost = 0.013383829\n",
      "Validation Loss: 0.031352855\n",
      "Epoch: 2661 cost = 0.013383343\n",
      "Validation Loss: 0.02214682\n",
      "Epoch: 2662 cost = 0.013382695\n",
      "Validation Loss: 0.022510726\n",
      "Epoch: 2663 cost = 0.013382583\n",
      "Validation Loss: 0.025677448\n",
      "Epoch: 2664 cost = 0.013381127\n",
      "Validation Loss: 0.03165017\n",
      "Epoch: 2665 cost = 0.013380490\n",
      "Validation Loss: 0.025171665\n",
      "Epoch: 2666 cost = 0.013380426\n",
      "Validation Loss: 0.02746952\n",
      "Epoch: 2667 cost = 0.013379823\n",
      "Validation Loss: 0.021144222\n",
      "Epoch: 2668 cost = 0.013378923\n",
      "Validation Loss: 0.017526863\n",
      "Epoch: 2669 cost = 0.013377967\n",
      "Validation Loss: 0.016968397\n",
      "Epoch: 2670 cost = 0.013377825\n",
      "Validation Loss: 0.025786925\n",
      "Epoch: 2671 cost = 0.013377178\n",
      "Validation Loss: 0.028911702\n",
      "Epoch: 2672 cost = 0.013376528\n",
      "Validation Loss: 0.033705376\n",
      "Epoch: 2673 cost = 0.013376077\n",
      "Validation Loss: 0.025571227\n",
      "Epoch: 2674 cost = 0.013375413\n",
      "Validation Loss: 0.024498465\n",
      "Epoch: 2675 cost = 0.013374844\n",
      "Validation Loss: 0.018552057\n",
      "Epoch: 2676 cost = 0.013374524\n",
      "Validation Loss: 0.022542382\n",
      "Epoch: 2677 cost = 0.013373713\n",
      "Validation Loss: 0.029480519\n",
      "Epoch: 2678 cost = 0.013372883\n",
      "Validation Loss: 0.03725471\n",
      "Epoch: 2679 cost = 0.013372573\n",
      "Validation Loss: 0.03210671\n",
      "Epoch: 2680 cost = 0.013371870\n",
      "Validation Loss: 0.030201811\n",
      "Epoch: 2681 cost = 0.013371566\n",
      "Validation Loss: 0.02977115\n",
      "Epoch: 2682 cost = 0.013370456\n",
      "Validation Loss: 0.021803077\n",
      "Epoch: 2683 cost = 0.013370093\n",
      "Validation Loss: 0.022060584\n",
      "Epoch: 2684 cost = 0.013369769\n",
      "Validation Loss: 0.018705009\n",
      "Epoch: 2685 cost = 0.013368918\n",
      "Validation Loss: 0.024198273\n",
      "Epoch: 2686 cost = 0.013368255\n",
      "Validation Loss: 0.031084549\n",
      "Epoch: 2687 cost = 0.013367704\n",
      "Validation Loss: 0.028351417\n",
      "Epoch: 2688 cost = 0.013367282\n",
      "Validation Loss: 0.024785273\n",
      "Epoch: 2689 cost = 0.013366692\n",
      "Validation Loss: 0.022620652\n",
      "Epoch: 2690 cost = 0.013366163\n",
      "Validation Loss: 0.024419686\n",
      "Epoch: 2691 cost = 0.013365119\n",
      "Validation Loss: 0.02427348\n",
      "Epoch: 2692 cost = 0.013364561\n",
      "Validation Loss: 0.027054109\n",
      "Epoch: 2693 cost = 0.013364416\n",
      "Validation Loss: 0.02081091\n",
      "Epoch: 2694 cost = 0.013363890\n",
      "Validation Loss: 0.023771392\n",
      "Epoch: 2695 cost = 0.013363563\n",
      "Validation Loss: 0.035935834\n",
      "Epoch: 2696 cost = 0.013362716\n",
      "Validation Loss: 0.044771127\n",
      "Epoch: 2697 cost = 0.013361429\n",
      "Validation Loss: 0.032917786\n",
      "Epoch: 2698 cost = 0.013361640\n",
      "Validation Loss: 0.028423017\n",
      "Epoch: 2699 cost = 0.013360854\n",
      "Validation Loss: 0.024505746\n",
      "Epoch: 2700 cost = 0.013360012\n",
      "Validation Loss: 0.024006005\n",
      "Epoch: 2701 cost = 0.013359238\n",
      "Validation Loss: 0.023635473\n",
      "Epoch: 2702 cost = 0.013359204\n",
      "Validation Loss: 0.01763892\n",
      "Epoch: 2703 cost = 0.013358411\n",
      "Validation Loss: 0.024158463\n",
      "Epoch: 2704 cost = 0.013357610\n",
      "Validation Loss: 0.024382506\n",
      "Epoch: 2705 cost = 0.013356940\n",
      "Validation Loss: 0.022023056\n",
      "Epoch: 2706 cost = 0.013356688\n",
      "Validation Loss: 0.02446646\n",
      "Epoch: 2707 cost = 0.013356137\n",
      "Validation Loss: 0.028112106\n",
      "Epoch: 2708 cost = 0.013355577\n",
      "Validation Loss: 0.026859876\n",
      "Epoch: 2709 cost = 0.013354541\n",
      "Validation Loss: 0.026254633\n",
      "Epoch: 2710 cost = 0.013354477\n",
      "Validation Loss: 0.023573197\n",
      "Epoch: 2711 cost = 0.013353920\n",
      "Validation Loss: 0.03486074\n",
      "Epoch: 2712 cost = 0.013353136\n",
      "Validation Loss: 0.0400618\n",
      "Epoch: 2713 cost = 0.013352387\n",
      "Validation Loss: 0.024857467\n",
      "Epoch: 2714 cost = 0.013352014\n",
      "Validation Loss: 0.030074295\n",
      "Epoch: 2715 cost = 0.013351514\n",
      "Validation Loss: 0.02273276\n",
      "Epoch: 2716 cost = 0.013350849\n",
      "Validation Loss: 0.017850902\n",
      "Epoch: 2717 cost = 0.013350209\n",
      "Validation Loss: 0.018227836\n",
      "Epoch: 2718 cost = 0.013349823\n",
      "Validation Loss: 0.016695645\n",
      "Epoch: 2719 cost = 0.013348733\n",
      "Validation Loss: 0.019877328\n",
      "Epoch: 2720 cost = 0.013348577\n",
      "Validation Loss: 0.025117777\n",
      "Epoch: 2721 cost = 0.013347795\n",
      "Validation Loss: 0.03423657\n",
      "Epoch: 2722 cost = 0.013347637\n",
      "Validation Loss: 0.030863738\n",
      "Epoch: 2723 cost = 0.013347360\n",
      "Validation Loss: 0.03175355\n",
      "Epoch: 2724 cost = 0.013346169\n",
      "Validation Loss: 0.020673208\n",
      "Epoch: 2725 cost = 0.013345766\n",
      "Validation Loss: 0.020103136\n",
      "Epoch: 2726 cost = 0.013345139\n",
      "Validation Loss: 0.027121931\n",
      "Epoch: 2727 cost = 0.013344495\n",
      "Validation Loss: 0.02902133\n",
      "Epoch: 2728 cost = 0.013343512\n",
      "Validation Loss: 0.025218587\n",
      "Epoch: 2729 cost = 0.013343652\n",
      "Validation Loss: 0.025763454\n",
      "Epoch: 2730 cost = 0.013342832\n",
      "Validation Loss: 0.021400928\n",
      "Epoch: 2731 cost = 0.013341933\n",
      "Validation Loss: 0.021074785\n",
      "Epoch: 2732 cost = 0.013341657\n",
      "Validation Loss: 0.025971526\n",
      "Epoch: 2733 cost = 0.013341361\n",
      "Validation Loss: 0.029013935\n",
      "Epoch: 2734 cost = 0.013340678\n",
      "Validation Loss: 0.032575082\n",
      "Epoch: 2735 cost = 0.013339537\n",
      "Validation Loss: 0.031284314\n",
      "Epoch: 2736 cost = 0.013339266\n",
      "Validation Loss: 0.04575766\n",
      "Epoch: 2737 cost = 0.013339125\n",
      "Validation Loss: 0.047743563\n",
      "Epoch: 2738 cost = 0.013338563\n",
      "Validation Loss: 0.039588377\n",
      "Epoch: 2739 cost = 0.013338210\n",
      "Validation Loss: 0.032405175\n",
      "Epoch: 2740 cost = 0.013337107\n",
      "Validation Loss: 0.024329908\n",
      "Epoch: 2741 cost = 0.013336916\n",
      "Validation Loss: 0.026363136\n",
      "Epoch: 2742 cost = 0.013336563\n",
      "Validation Loss: 0.041845348\n",
      "Epoch: 2743 cost = 0.013335609\n",
      "Validation Loss: 0.04013025\n",
      "Epoch: 2744 cost = 0.013334853\n",
      "Validation Loss: 0.020389378\n",
      "Epoch: 2745 cost = 0.013334485\n",
      "Validation Loss: 0.018481826\n",
      "Epoch: 2746 cost = 0.013333813\n",
      "Validation Loss: 0.02985972\n",
      "Epoch: 2747 cost = 0.013333487\n",
      "Validation Loss: 0.03154165\n",
      "Epoch: 2748 cost = 0.013332626\n",
      "Validation Loss: 0.034887124\n",
      "Epoch: 2749 cost = 0.013332147\n",
      "Validation Loss: 0.036495216\n",
      "Epoch: 2750 cost = 0.013331838\n",
      "Validation Loss: 0.042522293\n",
      "Epoch: 2751 cost = 0.013330465\n",
      "Validation Loss: 0.041500863\n",
      "Epoch: 2752 cost = 0.013330597\n",
      "Validation Loss: 0.02629414\n",
      "Epoch: 2753 cost = 0.013330260\n",
      "Validation Loss: 0.017519169\n",
      "Epoch: 2754 cost = 0.013328964\n",
      "Validation Loss: 0.018562736\n",
      "Epoch: 2755 cost = 0.013328568\n",
      "Validation Loss: 0.024055673\n",
      "Epoch: 2756 cost = 0.013328522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.027531864\n",
      "Epoch: 2757 cost = 0.013328066\n",
      "Validation Loss: 0.03111032\n",
      "Epoch: 2758 cost = 0.013327116\n",
      "Validation Loss: 0.020316852\n",
      "Epoch: 2759 cost = 0.013326725\n",
      "Validation Loss: 0.027056305\n",
      "Epoch: 2760 cost = 0.013325626\n",
      "Validation Loss: 0.03930647\n",
      "Epoch: 2761 cost = 0.013325979\n",
      "Validation Loss: 0.024797054\n",
      "Epoch: 2762 cost = 0.013325382\n",
      "Validation Loss: 0.021578792\n",
      "Epoch: 2763 cost = 0.013324467\n",
      "Validation Loss: 0.025066935\n",
      "Epoch: 2764 cost = 0.013323725\n",
      "Validation Loss: 0.0353125\n",
      "Epoch: 2765 cost = 0.013323100\n",
      "Validation Loss: 0.025905123\n",
      "Epoch: 2766 cost = 0.013322652\n",
      "Validation Loss: 0.028504414\n",
      "Epoch: 2767 cost = 0.013322770\n",
      "Validation Loss: 0.023784552\n",
      "Epoch: 2768 cost = 0.013321750\n",
      "Validation Loss: 0.02485556\n",
      "Epoch: 2769 cost = 0.013321232\n",
      "Validation Loss: 0.03252943\n",
      "Epoch: 2770 cost = 0.013320644\n",
      "Validation Loss: 0.040780425\n",
      "Epoch: 2771 cost = 0.013319599\n",
      "Validation Loss: 0.034924433\n",
      "Epoch: 2772 cost = 0.013319444\n",
      "Validation Loss: 0.026037116\n",
      "Epoch: 2773 cost = 0.013318849\n",
      "Validation Loss: 0.02054909\n",
      "Epoch: 2774 cost = 0.013318546\n",
      "Validation Loss: 0.029276762\n",
      "Epoch: 2775 cost = 0.013318342\n",
      "Validation Loss: 0.032277096\n",
      "Epoch: 2776 cost = 0.013317077\n",
      "Validation Loss: 0.028552283\n",
      "Epoch: 2777 cost = 0.013317017\n",
      "Validation Loss: 0.024841247\n",
      "Epoch: 2778 cost = 0.013316234\n",
      "Validation Loss: 0.043953277\n",
      "Epoch: 2779 cost = 0.013315698\n",
      "Validation Loss: 0.040107448\n",
      "Epoch: 2780 cost = 0.013315412\n",
      "Validation Loss: 0.031858303\n",
      "Epoch: 2781 cost = 0.013314262\n",
      "Validation Loss: 0.014505218\n",
      "Epoch: 2782 cost = 0.013314209\n",
      "Validation Loss: 0.015362186\n",
      "Epoch: 2783 cost = 0.013313478\n",
      "Validation Loss: 0.01652528\n",
      "Epoch: 2784 cost = 0.013313323\n",
      "Validation Loss: 0.028765982\n",
      "Epoch: 2785 cost = 0.013312225\n",
      "Validation Loss: 0.033072535\n",
      "Epoch: 2786 cost = 0.013312135\n",
      "Validation Loss: 0.02737499\n",
      "Epoch: 2787 cost = 0.013310971\n",
      "Validation Loss: 0.028407872\n",
      "Epoch: 2788 cost = 0.013310814\n",
      "Validation Loss: 0.020866398\n",
      "Epoch: 2789 cost = 0.013309798\n",
      "Validation Loss: 0.023816403\n",
      "Epoch: 2790 cost = 0.013309915\n",
      "Validation Loss: 0.028598646\n",
      "Epoch: 2791 cost = 0.013309473\n",
      "Validation Loss: 0.034338597\n",
      "Epoch: 2792 cost = 0.013308862\n",
      "Validation Loss: 0.030507334\n",
      "Epoch: 2793 cost = 0.013307917\n",
      "Validation Loss: 0.034894258\n",
      "Epoch: 2794 cost = 0.013308065\n",
      "Validation Loss: 0.03535824\n",
      "Epoch: 2795 cost = 0.013307149\n",
      "Validation Loss: 0.031460535\n",
      "Epoch: 2796 cost = 0.013306570\n",
      "Validation Loss: 0.032210287\n",
      "Epoch: 2797 cost = 0.013306078\n",
      "Validation Loss: 0.02788551\n",
      "Epoch: 2798 cost = 0.013305527\n",
      "Validation Loss: 0.02132653\n",
      "Epoch: 2799 cost = 0.013304676\n",
      "Validation Loss: 0.014304014\n",
      "Epoch: 2800 cost = 0.013304035\n",
      "Validation Loss: 0.023940636\n",
      "Epoch: 2801 cost = 0.013303684\n",
      "Validation Loss: 0.0363569\n",
      "Epoch: 2802 cost = 0.013303198\n",
      "Validation Loss: 0.04106522\n",
      "Epoch: 2803 cost = 0.013302845\n",
      "Validation Loss: 0.038755294\n",
      "Epoch: 2804 cost = 0.013302256\n",
      "Validation Loss: 0.037828643\n",
      "Epoch: 2805 cost = 0.013301604\n",
      "Validation Loss: 0.035527773\n",
      "Epoch: 2806 cost = 0.013301080\n",
      "Validation Loss: 0.037094917\n",
      "Epoch: 2807 cost = 0.013300587\n",
      "Validation Loss: 0.037247404\n",
      "Epoch: 2808 cost = 0.013300100\n",
      "Validation Loss: 0.03620039\n",
      "Epoch: 2809 cost = 0.013299439\n",
      "Validation Loss: 0.03366919\n",
      "Epoch: 2810 cost = 0.013298929\n",
      "Validation Loss: 0.028430862\n",
      "Epoch: 2811 cost = 0.013298778\n",
      "Validation Loss: 0.021909324\n",
      "Epoch: 2812 cost = 0.013297959\n",
      "Validation Loss: 0.023727475\n",
      "Epoch: 2813 cost = 0.013297288\n",
      "Validation Loss: 0.024308989\n",
      "Epoch: 2814 cost = 0.013296841\n",
      "Validation Loss: 0.019500222\n",
      "Epoch: 2815 cost = 0.013296709\n",
      "Validation Loss: 0.021157002\n",
      "Epoch: 2816 cost = 0.013295708\n",
      "Validation Loss: 0.020249525\n",
      "Epoch: 2817 cost = 0.013295344\n",
      "Validation Loss: 0.023920773\n",
      "Epoch: 2818 cost = 0.013294640\n",
      "Validation Loss: 0.026998017\n",
      "Epoch: 2819 cost = 0.013294252\n",
      "Validation Loss: 0.026626851\n",
      "Epoch: 2820 cost = 0.013293644\n",
      "Validation Loss: 0.030053815\n",
      "Epoch: 2821 cost = 0.013293479\n",
      "Validation Loss: 0.029418873\n",
      "Epoch: 2822 cost = 0.013292624\n",
      "Validation Loss: 0.02950696\n",
      "Epoch: 2823 cost = 0.013292606\n",
      "Validation Loss: 0.032378174\n",
      "Epoch: 2824 cost = 0.013291383\n",
      "Validation Loss: 0.025778279\n",
      "Epoch: 2825 cost = 0.013291005\n",
      "Validation Loss: 0.02930964\n",
      "Epoch: 2826 cost = 0.013290993\n",
      "Validation Loss: 0.03202089\n",
      "Epoch: 2827 cost = 0.013290058\n",
      "Validation Loss: 0.025990922\n",
      "Epoch: 2828 cost = 0.013289094\n",
      "Validation Loss: 0.026901625\n",
      "Epoch: 2829 cost = 0.013289159\n",
      "Validation Loss: 0.030790104\n",
      "Epoch: 2830 cost = 0.013288620\n",
      "Validation Loss: 0.04105435\n",
      "Epoch: 2831 cost = 0.013287863\n",
      "Validation Loss: 0.035339538\n",
      "Epoch: 2832 cost = 0.013287581\n",
      "Validation Loss: 0.023671951\n",
      "Epoch: 2833 cost = 0.013287104\n",
      "Validation Loss: 0.02813006\n",
      "Epoch: 2834 cost = 0.013286506\n",
      "Validation Loss: 0.030231884\n",
      "Epoch: 2835 cost = 0.013286337\n",
      "Validation Loss: 0.023458911\n",
      "Epoch: 2836 cost = 0.013285226\n",
      "Validation Loss: 0.023077566\n",
      "Epoch: 2837 cost = 0.013285240\n",
      "Validation Loss: 0.03647181\n",
      "Epoch: 2838 cost = 0.013284317\n",
      "Validation Loss: 0.028198106\n",
      "Epoch: 2839 cost = 0.013283591\n",
      "Validation Loss: 0.022950444\n",
      "Epoch: 2840 cost = 0.013283523\n",
      "Validation Loss: 0.016004978\n",
      "Epoch: 2841 cost = 0.013282887\n",
      "Validation Loss: 0.017132666\n",
      "Epoch: 2842 cost = 0.013282095\n",
      "Validation Loss: 0.024434464\n",
      "Epoch: 2843 cost = 0.013281968\n",
      "Validation Loss: 0.023172932\n",
      "Epoch: 2844 cost = 0.013281674\n",
      "Validation Loss: 0.02989295\n",
      "Epoch: 2845 cost = 0.013281188\n",
      "Validation Loss: 0.031742454\n",
      "Epoch: 2846 cost = 0.013280179\n",
      "Validation Loss: 0.022845002\n",
      "Epoch: 2847 cost = 0.013279363\n",
      "Validation Loss: 0.03018599\n",
      "Epoch: 2848 cost = 0.013279536\n",
      "Validation Loss: 0.039467957\n",
      "Epoch: 2849 cost = 0.013278976\n",
      "Validation Loss: 0.051592644\n",
      "Epoch: 2850 cost = 0.013278053\n",
      "Validation Loss: 0.045709573\n",
      "Epoch: 2851 cost = 0.013277696\n",
      "Validation Loss: 0.041106004\n",
      "Epoch: 2852 cost = 0.013277694\n",
      "Validation Loss: 0.043523476\n",
      "Epoch: 2853 cost = 0.013276749\n",
      "Validation Loss: 0.04003018\n",
      "Epoch: 2854 cost = 0.013275475\n",
      "Validation Loss: 0.035513535\n",
      "Epoch: 2855 cost = 0.013275633\n",
      "Validation Loss: 0.027637597\n",
      "Epoch: 2856 cost = 0.013275155\n",
      "Validation Loss: 0.03208073\n",
      "Epoch: 2857 cost = 0.013274695\n",
      "Validation Loss: 0.03882567\n",
      "Epoch: 2858 cost = 0.013274391\n",
      "Validation Loss: 0.04735823\n",
      "Epoch: 2859 cost = 0.013273841\n",
      "Validation Loss: 0.03663546\n",
      "Epoch: 2860 cost = 0.013273140\n",
      "Validation Loss: 0.020951428\n",
      "Epoch: 2861 cost = 0.013272382\n",
      "Validation Loss: 0.025412211\n",
      "Epoch: 2862 cost = 0.013272109\n",
      "Validation Loss: 0.016665751\n",
      "Epoch: 2863 cost = 0.013271468\n",
      "Validation Loss: 0.013541566\n",
      "Epoch: 2864 cost = 0.013271209\n",
      "Validation Loss: 0.01937807\n",
      "Epoch: 2865 cost = 0.013270810\n",
      "Validation Loss: 0.02754565\n",
      "Epoch: 2866 cost = 0.013270015\n",
      "Validation Loss: 0.038386118\n",
      "Epoch: 2867 cost = 0.013269443\n",
      "Validation Loss: 0.025187217\n",
      "Epoch: 2868 cost = 0.013269114\n",
      "Validation Loss: 0.022497552\n",
      "Epoch: 2869 cost = 0.013268692\n",
      "Validation Loss: 0.021633383\n",
      "Epoch: 2870 cost = 0.013268394\n",
      "Validation Loss: 0.034783\n",
      "Epoch: 2871 cost = 0.013267605\n",
      "Validation Loss: 0.037626706\n",
      "Epoch: 2872 cost = 0.013267249\n",
      "Validation Loss: 0.036452904\n",
      "Epoch: 2873 cost = 0.013266577\n",
      "Validation Loss: 0.040246453\n",
      "Epoch: 2874 cost = 0.013266094\n",
      "Validation Loss: 0.033274353\n",
      "Epoch: 2875 cost = 0.013265059\n",
      "Validation Loss: 0.030088559\n",
      "Epoch: 2876 cost = 0.013265086\n",
      "Validation Loss: 0.0252307\n",
      "Epoch: 2877 cost = 0.013265304\n",
      "Validation Loss: 0.018407462\n",
      "Epoch: 2878 cost = 0.013263848\n",
      "Validation Loss: 0.01717543\n",
      "Epoch: 2879 cost = 0.013263547\n",
      "Validation Loss: 0.022092482\n",
      "Epoch: 2880 cost = 0.013263022\n",
      "Validation Loss: 0.023583394\n",
      "Epoch: 2881 cost = 0.013262518\n",
      "Validation Loss: 0.028565757\n",
      "Epoch: 2882 cost = 0.013262241\n",
      "Validation Loss: 0.025808541\n",
      "Epoch: 2883 cost = 0.013261655\n",
      "Validation Loss: 0.029094657\n",
      "Epoch: 2884 cost = 0.013260738\n",
      "Validation Loss: 0.033558846\n",
      "Epoch: 2885 cost = 0.013261056\n",
      "Validation Loss: 0.030743763\n",
      "Epoch: 2886 cost = 0.013260578\n",
      "Validation Loss: 0.028142203\n",
      "Epoch: 2887 cost = 0.013260193\n",
      "Validation Loss: 0.029254135\n",
      "Epoch: 2888 cost = 0.013259042\n",
      "Validation Loss: 0.039034218\n",
      "Epoch: 2889 cost = 0.013258772\n",
      "Validation Loss: 0.04401785\n",
      "Epoch: 2890 cost = 0.013258169\n",
      "Validation Loss: 0.031206092\n",
      "Epoch: 2891 cost = 0.013257660\n",
      "Validation Loss: 0.02897538\n",
      "Epoch: 2892 cost = 0.013257128\n",
      "Validation Loss: 0.031387355\n",
      "Epoch: 2893 cost = 0.013256708\n",
      "Validation Loss: 0.046638574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2894 cost = 0.013256172\n",
      "Validation Loss: 0.0349264\n",
      "Epoch: 2895 cost = 0.013255800\n",
      "Validation Loss: 0.028886735\n",
      "Epoch: 2896 cost = 0.013255318\n",
      "Validation Loss: 0.023889296\n",
      "Epoch: 2897 cost = 0.013254486\n",
      "Validation Loss: 0.024616767\n",
      "Epoch: 2898 cost = 0.013253941\n",
      "Validation Loss: 0.023451613\n",
      "Epoch: 2899 cost = 0.013254064\n",
      "Validation Loss: 0.028225873\n",
      "Epoch: 2900 cost = 0.013253069\n",
      "Validation Loss: 0.023083994\n",
      "Epoch: 2901 cost = 0.013253251\n",
      "Validation Loss: 0.02186369\n",
      "Epoch: 2902 cost = 0.013252399\n",
      "Validation Loss: 0.026155781\n",
      "Epoch: 2903 cost = 0.013252096\n",
      "Validation Loss: 0.022147618\n",
      "Epoch: 2904 cost = 0.013251721\n",
      "Validation Loss: 0.021837866\n",
      "Epoch: 2905 cost = 0.013250620\n",
      "Validation Loss: 0.024826087\n",
      "Epoch: 2906 cost = 0.013250514\n",
      "Validation Loss: 0.03516432\n",
      "Epoch: 2907 cost = 0.013249842\n",
      "Validation Loss: 0.03245289\n",
      "Epoch: 2908 cost = 0.013249713\n",
      "Validation Loss: 0.028012086\n",
      "Epoch: 2909 cost = 0.013248953\n",
      "Validation Loss: 0.023065364\n",
      "Epoch: 2910 cost = 0.013248040\n",
      "Validation Loss: 0.021679072\n",
      "Epoch: 2911 cost = 0.013247866\n",
      "Validation Loss: 0.026368642\n",
      "Epoch: 2912 cost = 0.013247512\n",
      "Validation Loss: 0.03143274\n",
      "Epoch: 2913 cost = 0.013246778\n",
      "Validation Loss: 0.024116045\n",
      "Epoch: 2914 cost = 0.013246234\n",
      "Validation Loss: 0.021487266\n",
      "Epoch: 2915 cost = 0.013246505\n",
      "Validation Loss: 0.018821763\n",
      "Epoch: 2916 cost = 0.013245646\n",
      "Validation Loss: 0.05037094\n",
      "Epoch: 2917 cost = 0.013245189\n",
      "Validation Loss: 0.046661213\n",
      "Epoch: 2918 cost = 0.013244884\n",
      "Validation Loss: 0.034781676\n",
      "Epoch: 2919 cost = 0.013243930\n",
      "Validation Loss: 0.038051333\n",
      "Epoch: 2920 cost = 0.013243595\n",
      "Validation Loss: 0.036567856\n",
      "Epoch: 2921 cost = 0.013242755\n",
      "Validation Loss: 0.029589787\n",
      "Epoch: 2922 cost = 0.013242326\n",
      "Validation Loss: 0.042129286\n",
      "Epoch: 2923 cost = 0.013242203\n",
      "Validation Loss: 0.04135089\n",
      "Epoch: 2924 cost = 0.013241388\n",
      "Validation Loss: 0.033113874\n",
      "Epoch: 2925 cost = 0.013241609\n",
      "Validation Loss: 0.032096617\n",
      "Epoch: 2926 cost = 0.013240576\n",
      "Validation Loss: 0.028693989\n",
      "Epoch: 2927 cost = 0.013240399\n",
      "Validation Loss: 0.033027064\n",
      "Epoch: 2928 cost = 0.013239512\n",
      "Validation Loss: 0.032305583\n",
      "Epoch: 2929 cost = 0.013239181\n",
      "Validation Loss: 0.020882947\n",
      "Epoch: 2930 cost = 0.013239017\n",
      "Validation Loss: 0.024834862\n",
      "Epoch: 2931 cost = 0.013238033\n",
      "Validation Loss: 0.022092974\n",
      "Epoch: 2932 cost = 0.013237703\n",
      "Validation Loss: 0.016588323\n",
      "Epoch: 2933 cost = 0.013237378\n",
      "Validation Loss: 0.015553421\n",
      "Epoch: 2934 cost = 0.013237560\n",
      "Validation Loss: 0.02597328\n",
      "Epoch: 2935 cost = 0.013236538\n",
      "Validation Loss: 0.028841369\n",
      "Epoch: 2936 cost = 0.013235634\n",
      "Validation Loss: 0.025971513\n",
      "Epoch: 2937 cost = 0.013235282\n",
      "Validation Loss: 0.017927824\n",
      "Epoch: 2938 cost = 0.013234678\n",
      "Validation Loss: 0.015107254\n",
      "Epoch: 2939 cost = 0.013234700\n",
      "Validation Loss: 0.022933055\n",
      "Epoch: 2940 cost = 0.013234095\n",
      "Validation Loss: 0.028905993\n",
      "Epoch: 2941 cost = 0.013233797\n",
      "Validation Loss: 0.024933094\n",
      "Epoch: 2942 cost = 0.013232869\n",
      "Validation Loss: 0.026317764\n",
      "Epoch: 2943 cost = 0.013232607\n",
      "Validation Loss: 0.024924714\n",
      "Epoch: 2944 cost = 0.013232281\n",
      "Validation Loss: 0.025696995\n",
      "Epoch: 2945 cost = 0.013231348\n",
      "Validation Loss: 0.021431519\n",
      "Epoch: 2946 cost = 0.013231236\n",
      "Validation Loss: 0.020173034\n",
      "Epoch: 2947 cost = 0.013230707\n",
      "Validation Loss: 0.028846856\n",
      "Epoch: 2948 cost = 0.013229933\n",
      "Validation Loss: 0.037475217\n",
      "Epoch: 2949 cost = 0.013229829\n",
      "Validation Loss: 0.02693108\n",
      "Epoch: 2950 cost = 0.013229533\n",
      "Validation Loss: 0.019433394\n",
      "Epoch: 2951 cost = 0.013229220\n",
      "Validation Loss: 0.022106098\n",
      "Epoch: 2952 cost = 0.013228499\n",
      "Validation Loss: 0.026007771\n",
      "Epoch: 2953 cost = 0.013227903\n",
      "Validation Loss: 0.017319027\n",
      "Epoch: 2954 cost = 0.013227445\n",
      "Validation Loss: 0.01166223\n",
      "Epoch: 2955 cost = 0.013227016\n",
      "Validation Loss: 0.020524533\n",
      "Epoch: 2956 cost = 0.013226763\n",
      "Validation Loss: 0.026289916\n",
      "Epoch: 2957 cost = 0.013225951\n",
      "Validation Loss: 0.02744569\n",
      "Epoch: 2958 cost = 0.013225203\n",
      "Validation Loss: 0.019900275\n",
      "Epoch: 2959 cost = 0.013224845\n",
      "Validation Loss: 0.018577386\n",
      "Epoch: 2960 cost = 0.013225022\n",
      "Validation Loss: 0.021103546\n",
      "Epoch: 2961 cost = 0.013224011\n",
      "Validation Loss: 0.02609105\n",
      "Epoch: 2962 cost = 0.013223981\n",
      "Validation Loss: 0.017043704\n",
      "Epoch: 2963 cost = 0.013222984\n",
      "Validation Loss: 0.013320645\n",
      "Epoch: 2964 cost = 0.013222883\n",
      "Validation Loss: 0.021016438\n",
      "Epoch: 2965 cost = 0.013222828\n",
      "Validation Loss: 0.024457956\n",
      "Epoch: 2966 cost = 0.013222065\n",
      "Validation Loss: 0.029982664\n",
      "Epoch: 2967 cost = 0.013221451\n",
      "Validation Loss: 0.041100234\n",
      "Epoch: 2968 cost = 0.013220865\n",
      "Validation Loss: 0.03233687\n",
      "Epoch: 2969 cost = 0.013220299\n",
      "Validation Loss: 0.031358782\n",
      "Epoch: 2970 cost = 0.013220088\n",
      "Validation Loss: 0.03119155\n",
      "Epoch: 2971 cost = 0.013220033\n",
      "Validation Loss: 0.039594304\n",
      "Epoch: 2972 cost = 0.013219355\n",
      "Validation Loss: 0.03405394\n",
      "Epoch: 2973 cost = 0.013218363\n",
      "Validation Loss: 0.02084059\n",
      "Epoch: 2974 cost = 0.013218601\n",
      "Validation Loss: 0.019669658\n",
      "Epoch: 2975 cost = 0.013217851\n",
      "Validation Loss: 0.01937526\n",
      "Epoch: 2976 cost = 0.013217566\n",
      "Validation Loss: 0.026803188\n",
      "Epoch: 2977 cost = 0.013216930\n",
      "Validation Loss: 0.024061166\n",
      "Epoch: 2978 cost = 0.013216331\n",
      "Validation Loss: 0.030605868\n",
      "Epoch: 2979 cost = 0.013215822\n",
      "Validation Loss: 0.026283374\n",
      "Epoch: 2980 cost = 0.013215690\n",
      "Validation Loss: 0.034284584\n",
      "Epoch: 2981 cost = 0.013214817\n",
      "Validation Loss: 0.04344273\n",
      "Epoch: 2982 cost = 0.013214899\n",
      "Validation Loss: 0.04666458\n",
      "Epoch: 2983 cost = 0.013213914\n",
      "Validation Loss: 0.063443236\n",
      "Epoch: 2984 cost = 0.013213642\n",
      "Validation Loss: 0.068908274\n",
      "Epoch: 2985 cost = 0.013213260\n",
      "Validation Loss: 0.065919966\n",
      "Epoch: 2986 cost = 0.013212703\n",
      "Validation Loss: 0.054089144\n",
      "Epoch: 2987 cost = 0.013212354\n",
      "Validation Loss: 0.040877033\n",
      "Epoch: 2988 cost = 0.013211468\n",
      "Validation Loss: 0.04829965\n",
      "Epoch: 2989 cost = 0.013211656\n",
      "Validation Loss: 0.039801747\n",
      "Epoch: 2990 cost = 0.013211188\n",
      "Validation Loss: 0.031124229\n",
      "Epoch: 2991 cost = 0.013210541\n",
      "Validation Loss: 0.034216378\n",
      "Epoch: 2992 cost = 0.013209986\n",
      "Validation Loss: 0.021390779\n",
      "Epoch: 2993 cost = 0.013209398\n",
      "Validation Loss: 0.035076324\n",
      "Epoch: 2994 cost = 0.013209006\n",
      "Validation Loss: 0.023460327\n",
      "Epoch: 2995 cost = 0.013209148\n",
      "Validation Loss: 0.015835984\n",
      "Epoch: 2996 cost = 0.013207989\n",
      "Validation Loss: 0.020742396\n",
      "Epoch: 2997 cost = 0.013207688\n",
      "Validation Loss: 0.013368887\n",
      "Epoch: 2998 cost = 0.013206790\n",
      "Validation Loss: 0.019804604\n",
      "Epoch: 2999 cost = 0.013206573\n",
      "Validation Loss: 0.027150868\n",
      "Epoch: 3000 cost = 0.013206379\n",
      "Validation Loss: 0.021186333\n",
      "Epoch: 3001 cost = 0.013205581\n",
      "Validation Loss: 0.021972422\n",
      "Epoch: 3002 cost = 0.013205503\n",
      "Validation Loss: 0.02734115\n",
      "Epoch: 3003 cost = 0.013204757\n",
      "Validation Loss: 0.019351624\n",
      "Epoch: 3004 cost = 0.013204246\n",
      "Validation Loss: 0.025054457\n",
      "Epoch: 3005 cost = 0.013203980\n",
      "Validation Loss: 0.030652009\n",
      "Epoch: 3006 cost = 0.013203355\n",
      "Validation Loss: 0.04167308\n",
      "Epoch: 3007 cost = 0.013203438\n",
      "Validation Loss: 0.041752808\n",
      "Epoch: 3008 cost = 0.013202502\n",
      "Validation Loss: 0.026709395\n",
      "Epoch: 3009 cost = 0.013202396\n",
      "Validation Loss: 0.025862172\n",
      "Epoch: 3010 cost = 0.013201922\n",
      "Validation Loss: 0.023444531\n",
      "Epoch: 3011 cost = 0.013201109\n",
      "Validation Loss: 0.022525905\n",
      "Epoch: 3012 cost = 0.013201287\n",
      "Validation Loss: 0.022745047\n",
      "Epoch: 3013 cost = 0.013200859\n",
      "Validation Loss: 0.026449567\n",
      "Epoch: 3014 cost = 0.013200550\n",
      "Validation Loss: 0.03476907\n",
      "Epoch: 3015 cost = 0.013200008\n",
      "Validation Loss: 0.03586261\n",
      "Epoch: 3016 cost = 0.013199015\n",
      "Validation Loss: 0.025143838\n",
      "Epoch: 3017 cost = 0.013198963\n",
      "Validation Loss: 0.019575808\n",
      "Epoch: 3018 cost = 0.013197849\n",
      "Validation Loss: 0.032497708\n",
      "Epoch: 3019 cost = 0.013197857\n",
      "Validation Loss: 0.036440674\n",
      "Epoch: 3020 cost = 0.013197571\n",
      "Validation Loss: 0.027742805\n",
      "Epoch: 3021 cost = 0.013197047\n",
      "Validation Loss: 0.025531035\n",
      "Epoch: 3022 cost = 0.013196335\n",
      "Validation Loss: 0.035405137\n",
      "Epoch: 3023 cost = 0.013196499\n",
      "Validation Loss: 0.036556225\n",
      "Epoch: 3024 cost = 0.013195909\n",
      "Validation Loss: 0.029410273\n",
      "Epoch: 3025 cost = 0.013195161\n",
      "Validation Loss: 0.015610616\n",
      "Epoch: 3026 cost = 0.013195021\n",
      "Validation Loss: 0.016534036\n",
      "Epoch: 3027 cost = 0.013194140\n",
      "Validation Loss: 0.020820979\n",
      "Epoch: 3028 cost = 0.013194481\n",
      "Validation Loss: 0.015030817\n",
      "Epoch: 3029 cost = 0.013193173\n",
      "Validation Loss: 0.023433857\n",
      "Epoch: 3030 cost = 0.013193604\n",
      "Validation Loss: 0.03188116\n",
      "Epoch: 3031 cost = 0.013192473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.038630158\n",
      "Epoch: 3032 cost = 0.013192167\n",
      "Validation Loss: 0.036672466\n",
      "Epoch: 3033 cost = 0.013191967\n",
      "Validation Loss: 0.03713558\n",
      "Epoch: 3034 cost = 0.013191423\n",
      "Validation Loss: 0.031121636\n",
      "Epoch: 3035 cost = 0.013190240\n",
      "Validation Loss: 0.03256455\n",
      "Epoch: 3036 cost = 0.013190612\n",
      "Validation Loss: 0.03248413\n",
      "Epoch: 3037 cost = 0.013190178\n",
      "Validation Loss: 0.025543679\n",
      "Epoch: 3038 cost = 0.013189595\n",
      "Validation Loss: 0.02239924\n",
      "Epoch: 3039 cost = 0.013189333\n",
      "Validation Loss: 0.02419279\n",
      "Epoch: 3040 cost = 0.013188831\n",
      "Validation Loss: 0.034241512\n",
      "Epoch: 3041 cost = 0.013188417\n",
      "Validation Loss: 0.040531162\n",
      "Epoch: 3042 cost = 0.013188050\n",
      "Validation Loss: 0.02897825\n",
      "Epoch: 3043 cost = 0.013187633\n",
      "Validation Loss: 0.028402453\n",
      "Epoch: 3044 cost = 0.013186969\n",
      "Validation Loss: 0.03298691\n",
      "Epoch: 3045 cost = 0.013186630\n",
      "Validation Loss: 0.026002305\n",
      "Epoch: 3046 cost = 0.013185957\n",
      "Validation Loss: 0.028723963\n",
      "Epoch: 3047 cost = 0.013185941\n",
      "Validation Loss: 0.031529613\n",
      "Epoch: 3048 cost = 0.013185243\n",
      "Validation Loss: 0.03751134\n",
      "Epoch: 3049 cost = 0.013184659\n",
      "Validation Loss: 0.031060806\n",
      "Epoch: 3050 cost = 0.013184591\n",
      "Validation Loss: 0.02310207\n",
      "Epoch: 3051 cost = 0.013183851\n",
      "Validation Loss: 0.020213783\n",
      "Epoch: 3052 cost = 0.013182832\n",
      "Validation Loss: 0.02853669\n",
      "Epoch: 3053 cost = 0.013183340\n",
      "Validation Loss: 0.029467143\n",
      "Epoch: 3054 cost = 0.013182506\n",
      "Validation Loss: 0.017935578\n",
      "Epoch: 3055 cost = 0.013182328\n",
      "Validation Loss: 0.020834198\n",
      "Epoch: 3056 cost = 0.013181169\n",
      "Validation Loss: 0.021340033\n",
      "Epoch: 3057 cost = 0.013181923\n",
      "Validation Loss: 0.022860741\n",
      "Epoch: 3058 cost = 0.013181367\n",
      "Validation Loss: 0.024577143\n",
      "Epoch: 3059 cost = 0.013180630\n",
      "Validation Loss: 0.037166126\n",
      "Epoch: 3060 cost = 0.013180382\n",
      "Validation Loss: 0.044244394\n",
      "Epoch: 3061 cost = 0.013180175\n",
      "Validation Loss: 0.0414785\n",
      "Epoch: 3062 cost = 0.013179134\n",
      "Validation Loss: 0.039084557\n",
      "Epoch: 3063 cost = 0.013179032\n",
      "Validation Loss: 0.029918136\n",
      "Epoch: 3064 cost = 0.013178411\n",
      "Validation Loss: 0.021389123\n",
      "Epoch: 3065 cost = 0.013178186\n",
      "Validation Loss: 0.019419366\n",
      "Epoch: 3066 cost = 0.013177611\n",
      "Validation Loss: 0.024609132\n",
      "Epoch: 3067 cost = 0.013177330\n",
      "Validation Loss: 0.02961855\n",
      "Epoch: 3068 cost = 0.013176556\n",
      "Validation Loss: 0.03198913\n",
      "Epoch: 3069 cost = 0.013176358\n",
      "Validation Loss: 0.045277093\n",
      "Epoch: 3070 cost = 0.013175950\n",
      "Validation Loss: 0.034347743\n",
      "Epoch: 3071 cost = 0.013175769\n",
      "Validation Loss: 0.022630258\n",
      "Epoch: 3072 cost = 0.013175094\n",
      "Validation Loss: 0.030798204\n",
      "Epoch: 3073 cost = 0.013174675\n",
      "Validation Loss: 0.039856616\n",
      "Epoch: 3074 cost = 0.013173964\n",
      "Validation Loss: 0.04189544\n",
      "Epoch: 3075 cost = 0.013174045\n",
      "Validation Loss: 0.04234816\n",
      "Epoch: 3076 cost = 0.013173293\n",
      "Validation Loss: 0.041986637\n",
      "Epoch: 3077 cost = 0.013172918\n",
      "Validation Loss: 0.037052706\n",
      "Epoch: 3078 cost = 0.013172541\n",
      "Validation Loss: 0.033890735\n",
      "Epoch: 3079 cost = 0.013171974\n",
      "Validation Loss: 0.025706738\n",
      "Epoch: 3080 cost = 0.013171420\n",
      "Validation Loss: 0.04020517\n",
      "Epoch: 3081 cost = 0.013171488\n",
      "Validation Loss: 0.038048513\n",
      "Epoch: 3082 cost = 0.013171045\n",
      "Validation Loss: 0.031467237\n",
      "Epoch: 3083 cost = 0.013170679\n",
      "Validation Loss: 0.0330661\n",
      "Epoch: 3084 cost = 0.013169843\n",
      "Validation Loss: 0.032304063\n",
      "Epoch: 3085 cost = 0.013169495\n",
      "Validation Loss: 0.029584136\n",
      "Epoch: 3086 cost = 0.013169386\n",
      "Validation Loss: 0.02215384\n",
      "Epoch: 3087 cost = 0.013168927\n",
      "Validation Loss: 0.022074977\n",
      "Epoch: 3088 cost = 0.013168260\n",
      "Validation Loss: 0.016902583\n",
      "Epoch: 3089 cost = 0.013167765\n",
      "Validation Loss: 0.016056135\n",
      "Epoch: 3090 cost = 0.013167171\n",
      "Validation Loss: 0.01742743\n",
      "Epoch: 3091 cost = 0.013167218\n",
      "Validation Loss: 0.024299584\n",
      "Epoch: 3092 cost = 0.013167112\n",
      "Validation Loss: 0.02385627\n",
      "Epoch: 3093 cost = 0.013166200\n",
      "Validation Loss: 0.025161844\n",
      "Epoch: 3094 cost = 0.013165695\n",
      "Validation Loss: 0.01969774\n",
      "Epoch: 3095 cost = 0.013165597\n",
      "Validation Loss: 0.016446548\n",
      "Epoch: 3096 cost = 0.013165111\n",
      "Validation Loss: 0.020637928\n",
      "Epoch: 3097 cost = 0.013164402\n",
      "Validation Loss: 0.019026762\n",
      "Epoch: 3098 cost = 0.013164466\n",
      "Validation Loss: 0.017358357\n",
      "Epoch: 3099 cost = 0.013163842\n",
      "Validation Loss: 0.019506456\n",
      "Epoch: 3100 cost = 0.013163351\n",
      "Validation Loss: 0.019795833\n",
      "Epoch: 3101 cost = 0.013162826\n",
      "Validation Loss: 0.017604226\n",
      "Epoch: 3102 cost = 0.013162380\n",
      "Validation Loss: 0.01993304\n",
      "Epoch: 3103 cost = 0.013162016\n",
      "Validation Loss: 0.025100362\n",
      "Epoch: 3104 cost = 0.013161395\n",
      "Validation Loss: 0.019686377\n",
      "Epoch: 3105 cost = 0.013161212\n",
      "Validation Loss: 0.01535404\n",
      "Epoch: 3106 cost = 0.013161007\n",
      "Validation Loss: 0.020430135\n",
      "Epoch: 3107 cost = 0.013160146\n",
      "Validation Loss: 0.03476713\n",
      "Epoch: 3108 cost = 0.013159975\n",
      "Validation Loss: 0.03722085\n",
      "Epoch: 3109 cost = 0.013159446\n",
      "Validation Loss: 0.04006257\n",
      "Epoch: 3110 cost = 0.013158978\n",
      "Validation Loss: 0.0397366\n",
      "Epoch: 3111 cost = 0.013158750\n",
      "Validation Loss: 0.0278519\n",
      "Epoch: 3112 cost = 0.013158501\n",
      "Validation Loss: 0.028450498\n",
      "Epoch: 3113 cost = 0.013157699\n",
      "Validation Loss: 0.02688137\n",
      "Epoch: 3114 cost = 0.013157775\n",
      "Validation Loss: 0.019232262\n",
      "Epoch: 3115 cost = 0.013157365\n",
      "Validation Loss: 0.028823454\n",
      "Epoch: 3116 cost = 0.013157004\n",
      "Validation Loss: 0.029707374\n",
      "Epoch: 3117 cost = 0.013156813\n",
      "Validation Loss: 0.035407696\n",
      "Epoch: 3118 cost = 0.013156305\n",
      "Validation Loss: 0.04261169\n",
      "Epoch: 3119 cost = 0.013155194\n",
      "Validation Loss: 0.03654488\n",
      "Epoch: 3120 cost = 0.013154904\n",
      "Validation Loss: 0.024161082\n",
      "Epoch: 3121 cost = 0.013154956\n",
      "Validation Loss: 0.016053211\n",
      "Epoch: 3122 cost = 0.013154150\n",
      "Validation Loss: 0.026364325\n",
      "Epoch: 3123 cost = 0.013154029\n",
      "Validation Loss: 0.021908013\n",
      "Epoch: 3124 cost = 0.013153269\n",
      "Validation Loss: 0.027708355\n",
      "Epoch: 3125 cost = 0.013153171\n",
      "Validation Loss: 0.02748521\n",
      "Epoch: 3126 cost = 0.013152439\n",
      "Validation Loss: 0.016594535\n",
      "Epoch: 3127 cost = 0.013152313\n",
      "Validation Loss: 0.018953985\n",
      "Epoch: 3128 cost = 0.013152068\n",
      "Validation Loss: 0.03210155\n",
      "Epoch: 3129 cost = 0.013151307\n",
      "Validation Loss: 0.040471096\n",
      "Epoch: 3130 cost = 0.013151377\n",
      "Validation Loss: 0.04290308\n",
      "Epoch: 3131 cost = 0.013150506\n",
      "Validation Loss: 0.03850295\n",
      "Epoch: 3132 cost = 0.013150204\n",
      "Validation Loss: 0.0312798\n",
      "Epoch: 3133 cost = 0.013150169\n",
      "Validation Loss: 0.028456556\n",
      "Epoch: 3134 cost = 0.013149439\n",
      "Validation Loss: 0.026827551\n",
      "Epoch: 3135 cost = 0.013148732\n",
      "Validation Loss: 0.030655267\n",
      "Epoch: 3136 cost = 0.013148672\n",
      "Validation Loss: 0.02924251\n",
      "Epoch: 3137 cost = 0.013148534\n",
      "Validation Loss: 0.026685728\n",
      "Epoch: 3138 cost = 0.013147301\n",
      "Validation Loss: 0.021562623\n",
      "Epoch: 3139 cost = 0.013147331\n",
      "Validation Loss: 0.019689122\n",
      "Epoch: 3140 cost = 0.013146912\n",
      "Validation Loss: 0.020472746\n",
      "Epoch: 3141 cost = 0.013146853\n",
      "Validation Loss: 0.01910559\n",
      "Epoch: 3142 cost = 0.013146005\n",
      "Validation Loss: 0.028672935\n",
      "Epoch: 3143 cost = 0.013146076\n",
      "Validation Loss: 0.022719178\n",
      "Epoch: 3144 cost = 0.013144902\n",
      "Validation Loss: 0.027097574\n",
      "Epoch: 3145 cost = 0.013145175\n",
      "Validation Loss: 0.032037094\n",
      "Epoch: 3146 cost = 0.013144715\n",
      "Validation Loss: 0.031834688\n",
      "Epoch: 3147 cost = 0.013144282\n",
      "Validation Loss: 0.03542862\n",
      "Epoch: 3148 cost = 0.013144018\n",
      "Validation Loss: 0.023008624\n",
      "Epoch: 3149 cost = 0.013143964\n",
      "Validation Loss: 0.037756372\n",
      "Epoch: 3150 cost = 0.013143043\n",
      "Validation Loss: 0.0397029\n",
      "Epoch: 3151 cost = 0.013142654\n",
      "Validation Loss: 0.034388244\n",
      "Epoch: 3152 cost = 0.013142461\n",
      "Validation Loss: 0.034581043\n",
      "Epoch: 3153 cost = 0.013141808\n",
      "Validation Loss: 0.041282345\n",
      "Epoch: 3154 cost = 0.013141242\n",
      "Validation Loss: 0.043380246\n",
      "Epoch: 3155 cost = 0.013141053\n",
      "Validation Loss: 0.042755686\n",
      "Epoch: 3156 cost = 0.013140469\n",
      "Validation Loss: 0.045420583\n",
      "Epoch: 3157 cost = 0.013140113\n",
      "Validation Loss: 0.041144\n",
      "Epoch: 3158 cost = 0.013140084\n",
      "Validation Loss: 0.03550815\n",
      "Epoch: 3159 cost = 0.013139258\n",
      "Validation Loss: 0.03307628\n",
      "Epoch: 3160 cost = 0.013138491\n",
      "Validation Loss: 0.029325241\n",
      "Epoch: 3161 cost = 0.013138805\n",
      "Validation Loss: 0.036932103\n",
      "Epoch: 3162 cost = 0.013138353\n",
      "Validation Loss: 0.03812639\n",
      "Epoch: 3163 cost = 0.013137793\n",
      "Validation Loss: 0.040252183\n",
      "Epoch: 3164 cost = 0.013137410\n",
      "Validation Loss: 0.039316706\n",
      "Epoch: 3165 cost = 0.013137051\n",
      "Validation Loss: 0.041282155\n",
      "Epoch: 3166 cost = 0.013136617\n",
      "Validation Loss: 0.03249005\n",
      "Epoch: 3167 cost = 0.013135765\n",
      "Validation Loss: 0.033396527\n",
      "Epoch: 3168 cost = 0.013136114\n",
      "Validation Loss: 0.030309593\n",
      "Epoch: 3169 cost = 0.013135454\n",
      "Validation Loss: 0.023751322\n",
      "Epoch: 3170 cost = 0.013135446\n",
      "Validation Loss: 0.031958707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3171 cost = 0.013134623\n",
      "Validation Loss: 0.042727794\n",
      "Epoch: 3172 cost = 0.013134176\n",
      "Validation Loss: 0.04223503\n",
      "Epoch: 3173 cost = 0.013133746\n",
      "Validation Loss: 0.044046745\n",
      "Epoch: 3174 cost = 0.013133600\n",
      "Validation Loss: 0.03948517\n",
      "Epoch: 3175 cost = 0.013133124\n",
      "Validation Loss: 0.028428486\n",
      "Epoch: 3176 cost = 0.013132639\n",
      "Validation Loss: 0.033196777\n",
      "Epoch: 3177 cost = 0.013132136\n",
      "Validation Loss: 0.03222845\n",
      "Epoch: 3178 cost = 0.013131902\n",
      "Validation Loss: 0.027300395\n",
      "Epoch: 3179 cost = 0.013131498\n",
      "Validation Loss: 0.036635075\n",
      "Epoch: 3180 cost = 0.013130806\n",
      "Validation Loss: 0.03816696\n",
      "Epoch: 3181 cost = 0.013130502\n",
      "Validation Loss: 0.036796074\n",
      "Epoch: 3182 cost = 0.013130548\n",
      "Validation Loss: 0.02880943\n",
      "Epoch: 3183 cost = 0.013130120\n",
      "Validation Loss: 0.02426201\n",
      "Epoch: 3184 cost = 0.013129387\n",
      "Validation Loss: 0.02863676\n",
      "Epoch: 3185 cost = 0.013128581\n",
      "Validation Loss: 0.03468818\n",
      "Epoch: 3186 cost = 0.013129358\n",
      "Validation Loss: 0.03165052\n",
      "Epoch: 3187 cost = 0.013128223\n",
      "Validation Loss: 0.029215952\n",
      "Epoch: 3188 cost = 0.013128228\n",
      "Validation Loss: 0.02268846\n",
      "Epoch: 3189 cost = 0.013128075\n",
      "Validation Loss: 0.022406312\n",
      "Epoch: 3190 cost = 0.013127314\n",
      "Validation Loss: 0.03072383\n",
      "Epoch: 3191 cost = 0.013126600\n",
      "Validation Loss: 0.031419963\n",
      "Epoch: 3192 cost = 0.013126891\n",
      "Validation Loss: 0.030171018\n",
      "Epoch: 3193 cost = 0.013126120\n",
      "Validation Loss: 0.019417565\n",
      "Epoch: 3194 cost = 0.013126047\n",
      "Validation Loss: 0.024807543\n",
      "Epoch: 3195 cost = 0.013125867\n",
      "Validation Loss: 0.02368962\n",
      "Epoch: 3196 cost = 0.013125314\n",
      "Validation Loss: 0.025943438\n",
      "Epoch: 3197 cost = 0.013125019\n",
      "Validation Loss: 0.023430532\n",
      "Epoch: 3198 cost = 0.013124604\n",
      "Validation Loss: 0.023572752\n",
      "Epoch: 3199 cost = 0.013124399\n",
      "Validation Loss: 0.03138028\n",
      "Epoch: 3200 cost = 0.013123395\n",
      "Validation Loss: 0.046200875\n",
      "Epoch: 3201 cost = 0.013123190\n",
      "Validation Loss: 0.052793145\n",
      "Epoch: 3202 cost = 0.013122971\n",
      "Validation Loss: 0.035550416\n",
      "Epoch: 3203 cost = 0.013122737\n",
      "Validation Loss: 0.024103153\n",
      "Epoch: 3204 cost = 0.013122114\n",
      "Validation Loss: 0.014330698\n",
      "Epoch: 3205 cost = 0.013121454\n",
      "Validation Loss: 0.017758284\n",
      "Epoch: 3206 cost = 0.013121525\n",
      "Validation Loss: 0.02318251\n",
      "Epoch: 3207 cost = 0.013121268\n",
      "Validation Loss: 0.033122227\n",
      "Epoch: 3208 cost = 0.013120170\n",
      "Validation Loss: 0.028069375\n",
      "Epoch: 3209 cost = 0.013120328\n",
      "Validation Loss: 0.033452846\n",
      "Epoch: 3210 cost = 0.013119647\n",
      "Validation Loss: 0.03682491\n",
      "Epoch: 3211 cost = 0.013119200\n",
      "Validation Loss: 0.032761987\n",
      "Epoch: 3212 cost = 0.013118853\n",
      "Validation Loss: 0.040165864\n",
      "Epoch: 3213 cost = 0.013119084\n",
      "Validation Loss: 0.031724077\n",
      "Epoch: 3214 cost = 0.013118252\n",
      "Validation Loss: 0.02320597\n",
      "Epoch: 3215 cost = 0.013118067\n",
      "Validation Loss: 0.023166928\n",
      "Epoch: 3216 cost = 0.013117546\n",
      "Validation Loss: 0.041279137\n",
      "Epoch: 3217 cost = 0.013117041\n",
      "Validation Loss: 0.065490834\n",
      "Epoch: 3218 cost = 0.013116562\n",
      "Validation Loss: 0.057972375\n",
      "Epoch: 3219 cost = 0.013116461\n",
      "Validation Loss: 0.054014824\n",
      "Epoch: 3220 cost = 0.013115970\n",
      "Validation Loss: 0.0391426\n",
      "Epoch: 3221 cost = 0.013115562\n",
      "Validation Loss: 0.034226026\n",
      "Epoch: 3222 cost = 0.013114716\n",
      "Validation Loss: 0.0340184\n",
      "Epoch: 3223 cost = 0.013115209\n",
      "Validation Loss: 0.03481566\n",
      "Epoch: 3224 cost = 0.013114197\n",
      "Validation Loss: 0.030257631\n",
      "Epoch: 3225 cost = 0.013113936\n",
      "Validation Loss: 0.024645\n",
      "Epoch: 3226 cost = 0.013113170\n",
      "Validation Loss: 0.03518823\n",
      "Epoch: 3227 cost = 0.013113495\n",
      "Validation Loss: 0.03030175\n",
      "Epoch: 3228 cost = 0.013112903\n",
      "Validation Loss: 0.03010125\n",
      "Epoch: 3229 cost = 0.013112623\n",
      "Validation Loss: 0.02881653\n",
      "Epoch: 3230 cost = 0.013112160\n",
      "Validation Loss: 0.025989905\n",
      "Epoch: 3231 cost = 0.013111875\n",
      "Validation Loss: 0.021234294\n",
      "Epoch: 3232 cost = 0.013112053\n",
      "Validation Loss: 0.028391689\n",
      "Epoch: 3233 cost = 0.013110805\n",
      "Validation Loss: 0.025796585\n",
      "Epoch: 3234 cost = 0.013110432\n",
      "Validation Loss: 0.02228922\n",
      "Epoch: 3235 cost = 0.013110356\n",
      "Validation Loss: 0.023681175\n",
      "Epoch: 3236 cost = 0.013109855\n",
      "Validation Loss: 0.026494524\n",
      "Epoch: 3237 cost = 0.013109948\n",
      "Validation Loss: 0.02914996\n",
      "Epoch: 3238 cost = 0.013108983\n",
      "Validation Loss: 0.034568254\n",
      "Epoch: 3239 cost = 0.013108918\n",
      "Validation Loss: 0.032021828\n",
      "Epoch: 3240 cost = 0.013108310\n",
      "Validation Loss: 0.022647435\n",
      "Epoch: 3241 cost = 0.013108667\n",
      "Validation Loss: 0.032900397\n",
      "Epoch: 3242 cost = 0.013108269\n",
      "Validation Loss: 0.042034075\n",
      "Epoch: 3243 cost = 0.013106917\n",
      "Validation Loss: 0.050109394\n",
      "Epoch: 3244 cost = 0.013106957\n",
      "Validation Loss: 0.042211097\n",
      "Epoch: 3245 cost = 0.013106956\n",
      "Validation Loss: 0.029921988\n",
      "Epoch: 3246 cost = 0.013106196\n",
      "Validation Loss: 0.024980994\n",
      "Epoch: 3247 cost = 0.013105632\n",
      "Validation Loss: 0.027282307\n",
      "Epoch: 3248 cost = 0.013105800\n",
      "Validation Loss: 0.017304204\n",
      "Epoch: 3249 cost = 0.013104422\n",
      "Validation Loss: 0.026971396\n",
      "Epoch: 3250 cost = 0.013104416\n",
      "Validation Loss: 0.021146689\n",
      "Epoch: 3251 cost = 0.013104360\n",
      "Validation Loss: 0.020195168\n",
      "Epoch: 3252 cost = 0.013103826\n",
      "Validation Loss: 0.021301998\n",
      "Epoch: 3253 cost = 0.013103567\n",
      "Validation Loss: 0.029019699\n",
      "Epoch: 3254 cost = 0.013103514\n",
      "Validation Loss: 0.02368605\n",
      "Epoch: 3255 cost = 0.013103033\n",
      "Validation Loss: 0.03435612\n",
      "Epoch: 3256 cost = 0.013102695\n",
      "Validation Loss: 0.032002047\n",
      "Epoch: 3257 cost = 0.013102192\n",
      "Validation Loss: 0.027030505\n",
      "Epoch: 3258 cost = 0.013101851\n",
      "Validation Loss: 0.037412323\n",
      "Epoch: 3259 cost = 0.013102128\n",
      "Validation Loss: 0.032898843\n",
      "Epoch: 3260 cost = 0.013101034\n",
      "Validation Loss: 0.04235762\n",
      "Epoch: 3261 cost = 0.013100468\n",
      "Validation Loss: 0.030067397\n",
      "Epoch: 3262 cost = 0.013100247\n",
      "Validation Loss: 0.022090754\n",
      "Epoch: 3263 cost = 0.013099899\n",
      "Validation Loss: 0.027533598\n",
      "Epoch: 3264 cost = 0.013099636\n",
      "Validation Loss: 0.03191518\n",
      "Epoch: 3265 cost = 0.013098976\n",
      "Validation Loss: 0.024081957\n",
      "Epoch: 3266 cost = 0.013098997\n",
      "Validation Loss: 0.02530873\n",
      "Epoch: 3267 cost = 0.013098792\n",
      "Validation Loss: 0.035101425\n",
      "Epoch: 3268 cost = 0.013098337\n",
      "Validation Loss: 0.028339194\n",
      "Epoch: 3269 cost = 0.013098048\n",
      "Validation Loss: 0.027784482\n",
      "Epoch: 3270 cost = 0.013097585\n",
      "Validation Loss: 0.025002565\n",
      "Epoch: 3271 cost = 0.013097052\n",
      "Validation Loss: 0.03700175\n",
      "Epoch: 3272 cost = 0.013096968\n",
      "Validation Loss: 0.041945204\n",
      "Epoch: 3273 cost = 0.013096202\n",
      "Validation Loss: 0.026472013\n",
      "Epoch: 3274 cost = 0.013096356\n",
      "Validation Loss: 0.029800823\n",
      "Epoch: 3275 cost = 0.013095425\n",
      "Validation Loss: 0.033873256\n",
      "Epoch: 3276 cost = 0.013095595\n",
      "Validation Loss: 0.037489142\n",
      "Epoch: 3277 cost = 0.013095406\n",
      "Validation Loss: 0.042909622\n",
      "Epoch: 3278 cost = 0.013094285\n",
      "Validation Loss: 0.029255144\n",
      "Epoch: 3279 cost = 0.013093938\n",
      "Validation Loss: 0.035135206\n",
      "Epoch: 3280 cost = 0.013093594\n",
      "Validation Loss: 0.032960203\n",
      "Epoch: 3281 cost = 0.013093188\n",
      "Validation Loss: 0.032164\n",
      "Epoch: 3282 cost = 0.013092955\n",
      "Validation Loss: 0.029601516\n",
      "Epoch: 3283 cost = 0.013092341\n",
      "Validation Loss: 0.03967079\n",
      "Epoch: 3284 cost = 0.013091611\n",
      "Validation Loss: 0.03441775\n",
      "Epoch: 3285 cost = 0.013092153\n",
      "Validation Loss: 0.023834318\n",
      "Epoch: 3286 cost = 0.013091061\n",
      "Validation Loss: 0.03561881\n",
      "Epoch: 3287 cost = 0.013091294\n",
      "Validation Loss: 0.025240108\n",
      "Epoch: 3288 cost = 0.013091094\n",
      "Validation Loss: 0.018630883\n",
      "Epoch: 3289 cost = 0.013090164\n",
      "Validation Loss: 0.017605925\n",
      "Epoch: 3290 cost = 0.013090349\n",
      "Validation Loss: 0.016730145\n",
      "Epoch: 3291 cost = 0.013089515\n",
      "Validation Loss: 0.017011968\n",
      "Epoch: 3292 cost = 0.013089507\n",
      "Validation Loss: 0.024899552\n",
      "Epoch: 3293 cost = 0.013089243\n",
      "Validation Loss: 0.019033363\n",
      "Epoch: 3294 cost = 0.013089566\n",
      "Validation Loss: 0.030755812\n",
      "Epoch: 3295 cost = 0.013088127\n",
      "Validation Loss: 0.031732477\n",
      "Epoch: 3296 cost = 0.013087957\n",
      "Validation Loss: 0.020201048\n",
      "Epoch: 3297 cost = 0.013087675\n",
      "Validation Loss: 0.016902218\n",
      "Epoch: 3298 cost = 0.013087352\n",
      "Validation Loss: 0.024759138\n",
      "Epoch: 3299 cost = 0.013087289\n",
      "Validation Loss: 0.02416294\n",
      "Epoch: 3300 cost = 0.013085678\n",
      "Validation Loss: 0.025536982\n",
      "Epoch: 3301 cost = 0.013086161\n",
      "Validation Loss: 0.024423515\n",
      "Epoch: 3302 cost = 0.013085450\n",
      "Validation Loss: 0.029036464\n",
      "Epoch: 3303 cost = 0.013085513\n",
      "Validation Loss: 0.034063924\n",
      "Epoch: 3304 cost = 0.013085475\n",
      "Validation Loss: 0.035027575\n",
      "Epoch: 3305 cost = 0.013084450\n",
      "Validation Loss: 0.03396433\n",
      "Epoch: 3306 cost = 0.013084491\n",
      "Validation Loss: 0.024780162\n",
      "Epoch: 3307 cost = 0.013084253\n",
      "Validation Loss: 0.014067274\n",
      "Epoch: 3308 cost = 0.013083768\n",
      "Validation Loss: 0.016098162\n",
      "Epoch: 3309 cost = 0.013083035\n",
      "Validation Loss: 0.020929176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3310 cost = 0.013083214\n",
      "Validation Loss: 0.024928046\n",
      "Epoch: 3311 cost = 0.013082571\n",
      "Validation Loss: 0.022475686\n",
      "Epoch: 3312 cost = 0.013082410\n",
      "Validation Loss: 0.01880939\n",
      "Epoch: 3313 cost = 0.013082049\n",
      "Validation Loss: 0.019756297\n",
      "Epoch: 3314 cost = 0.013081571\n",
      "Validation Loss: 0.019116867\n",
      "Epoch: 3315 cost = 0.013081085\n",
      "Validation Loss: 0.01305727\n",
      "Epoch: 3316 cost = 0.013080713\n",
      "Validation Loss: 0.016337382\n",
      "Epoch: 3317 cost = 0.013080775\n",
      "Validation Loss: 0.0173843\n",
      "Epoch: 3318 cost = 0.013080393\n",
      "Validation Loss: 0.018189246\n",
      "Epoch: 3319 cost = 0.013079698\n",
      "Validation Loss: 0.026610946\n",
      "Epoch: 3320 cost = 0.013079924\n",
      "Validation Loss: 0.021714628\n",
      "Epoch: 3321 cost = 0.013078801\n",
      "Validation Loss: 0.020356046\n",
      "Epoch: 3322 cost = 0.013078737\n",
      "Validation Loss: 0.018330786\n",
      "Epoch: 3323 cost = 0.013078329\n",
      "Validation Loss: 0.02457789\n",
      "Epoch: 3324 cost = 0.013078565\n",
      "Validation Loss: 0.030455505\n",
      "Epoch: 3325 cost = 0.013077728\n",
      "Validation Loss: 0.03572229\n",
      "Epoch: 3326 cost = 0.013076893\n",
      "Validation Loss: 0.021131571\n",
      "Epoch: 3327 cost = 0.013076531\n",
      "Validation Loss: 0.017771719\n",
      "Epoch: 3328 cost = 0.013076723\n",
      "Validation Loss: 0.019659529\n",
      "Epoch: 3329 cost = 0.013076177\n",
      "Validation Loss: 0.02635131\n",
      "Epoch: 3330 cost = 0.013075940\n",
      "Validation Loss: 0.02646409\n",
      "Epoch: 3331 cost = 0.013075219\n",
      "Validation Loss: 0.02359213\n",
      "Epoch: 3332 cost = 0.013075234\n",
      "Validation Loss: 0.019760998\n",
      "Epoch: 3333 cost = 0.013075194\n",
      "Validation Loss: 0.021904636\n",
      "Epoch: 3334 cost = 0.013074683\n",
      "Validation Loss: 0.019050011\n",
      "Epoch: 3335 cost = 0.013073922\n",
      "Validation Loss: 0.021748213\n",
      "Epoch: 3336 cost = 0.013073939\n",
      "Validation Loss: 0.024089323\n",
      "Epoch: 3337 cost = 0.013073338\n",
      "Validation Loss: 0.02206596\n",
      "Epoch: 3338 cost = 0.013073118\n",
      "Validation Loss: 0.02472984\n",
      "Epoch: 3339 cost = 0.013072704\n",
      "Validation Loss: 0.020488266\n",
      "Epoch: 3340 cost = 0.013072446\n",
      "Validation Loss: 0.021544807\n",
      "Epoch: 3341 cost = 0.013071507\n",
      "Validation Loss: 0.02293267\n",
      "Epoch: 3342 cost = 0.013072034\n",
      "Validation Loss: 0.024972633\n",
      "Epoch: 3343 cost = 0.013071654\n",
      "Validation Loss: 0.028730717\n",
      "Epoch: 3344 cost = 0.013071152\n",
      "Validation Loss: 0.03338609\n",
      "Epoch: 3345 cost = 0.013070709\n",
      "Validation Loss: 0.032994978\n",
      "Epoch: 3346 cost = 0.013070185\n",
      "Validation Loss: 0.019387372\n",
      "Epoch: 3347 cost = 0.013070265\n",
      "Validation Loss: 0.024878347\n",
      "Epoch: 3348 cost = 0.013069522\n",
      "Validation Loss: 0.028301585\n",
      "Epoch: 3349 cost = 0.013069263\n",
      "Validation Loss: 0.028696936\n",
      "Epoch: 3350 cost = 0.013069118\n",
      "Validation Loss: 0.04247965\n",
      "Epoch: 3351 cost = 0.013068572\n",
      "Validation Loss: 0.044775885\n",
      "Epoch: 3352 cost = 0.013068230\n",
      "Validation Loss: 0.033230755\n",
      "Epoch: 3353 cost = 0.013067871\n",
      "Validation Loss: 0.01928446\n",
      "Epoch: 3354 cost = 0.013067595\n",
      "Validation Loss: 0.026771579\n",
      "Epoch: 3355 cost = 0.013067397\n",
      "Validation Loss: 0.034309696\n",
      "Epoch: 3356 cost = 0.013066737\n",
      "Validation Loss: 0.027226806\n",
      "Epoch: 3357 cost = 0.013066551\n",
      "Validation Loss: 0.03016174\n",
      "Epoch: 3358 cost = 0.013066222\n",
      "Validation Loss: 0.030841934\n",
      "Epoch: 3359 cost = 0.013066026\n",
      "Validation Loss: 0.027994664\n",
      "Epoch: 3360 cost = 0.013065368\n",
      "Validation Loss: 0.024483344\n",
      "Epoch: 3361 cost = 0.013064976\n",
      "Validation Loss: 0.022769261\n",
      "Epoch: 3362 cost = 0.013064737\n",
      "Validation Loss: 0.016186882\n",
      "Epoch: 3363 cost = 0.013064490\n",
      "Validation Loss: 0.02146474\n",
      "Epoch: 3364 cost = 0.013064132\n",
      "Validation Loss: 0.021583684\n",
      "Epoch: 3365 cost = 0.013063366\n",
      "Validation Loss: 0.020593734\n",
      "Epoch: 3366 cost = 0.013063481\n",
      "Validation Loss: 0.017401734\n",
      "Epoch: 3367 cost = 0.013062937\n",
      "Validation Loss: 0.027315103\n",
      "Epoch: 3368 cost = 0.013063505\n",
      "Validation Loss: 0.039399818\n",
      "Epoch: 3369 cost = 0.013062040\n",
      "Validation Loss: 0.036348566\n",
      "Epoch: 3370 cost = 0.013061819\n",
      "Validation Loss: 0.03604958\n",
      "Epoch: 3371 cost = 0.013061794\n",
      "Validation Loss: 0.02490438\n",
      "Epoch: 3372 cost = 0.013061119\n",
      "Validation Loss: 0.017622352\n",
      "Epoch: 3373 cost = 0.013060582\n",
      "Validation Loss: 0.017956335\n",
      "Epoch: 3374 cost = 0.013060882\n",
      "Validation Loss: 0.016169606\n",
      "Epoch: 3375 cost = 0.013059988\n",
      "Validation Loss: 0.027007727\n",
      "Epoch: 3376 cost = 0.013059903\n",
      "Validation Loss: 0.021946616\n",
      "Epoch: 3377 cost = 0.013059749\n",
      "Validation Loss: 0.029298987\n",
      "Epoch: 3378 cost = 0.013059157\n",
      "Validation Loss: 0.031361513\n",
      "Epoch: 3379 cost = 0.013058960\n",
      "Validation Loss: 0.040922605\n",
      "Epoch: 3380 cost = 0.013058976\n",
      "Validation Loss: 0.051360995\n",
      "Epoch: 3381 cost = 0.013058284\n",
      "Validation Loss: 0.03824549\n",
      "Epoch: 3382 cost = 0.013057924\n",
      "Validation Loss: 0.019167837\n",
      "Epoch: 3383 cost = 0.013057606\n",
      "Validation Loss: 0.016405497\n",
      "Epoch: 3384 cost = 0.013057386\n",
      "Validation Loss: 0.02153459\n",
      "Epoch: 3385 cost = 0.013057151\n",
      "Validation Loss: 0.030450232\n",
      "Epoch: 3386 cost = 0.013056741\n",
      "Validation Loss: 0.03365623\n",
      "Epoch: 3387 cost = 0.013055985\n",
      "Validation Loss: 0.045299407\n",
      "Epoch: 3388 cost = 0.013055568\n",
      "Validation Loss: 0.04328382\n",
      "Epoch: 3389 cost = 0.013055593\n",
      "Validation Loss: 0.044699546\n",
      "Epoch: 3390 cost = 0.013055299\n",
      "Validation Loss: 0.03381109\n",
      "Epoch: 3391 cost = 0.013054829\n",
      "Validation Loss: 0.020717084\n",
      "Epoch: 3392 cost = 0.013054715\n",
      "Validation Loss: 0.025619773\n",
      "Epoch: 3393 cost = 0.013054187\n",
      "Validation Loss: 0.032573357\n",
      "Epoch: 3394 cost = 0.013053601\n",
      "Validation Loss: 0.027413296\n",
      "Epoch: 3395 cost = 0.013053086\n",
      "Validation Loss: 0.020490456\n",
      "Epoch: 3396 cost = 0.013053278\n",
      "Validation Loss: 0.022975558\n",
      "Epoch: 3397 cost = 0.013052536\n",
      "Validation Loss: 0.02704592\n",
      "Epoch: 3398 cost = 0.013052577\n",
      "Validation Loss: 0.036713112\n",
      "Epoch: 3399 cost = 0.013051785\n",
      "Validation Loss: 0.033821773\n",
      "Epoch: 3400 cost = 0.013051922\n",
      "Validation Loss: 0.02407898\n",
      "Epoch: 3401 cost = 0.013050945\n",
      "Validation Loss: 0.024426442\n",
      "Epoch: 3402 cost = 0.013051081\n",
      "Validation Loss: 0.030543799\n",
      "Epoch: 3403 cost = 0.013051059\n",
      "Validation Loss: 0.026892224\n",
      "Epoch: 3404 cost = 0.013049960\n",
      "Validation Loss: 0.021883907\n",
      "Epoch: 3405 cost = 0.013050363\n",
      "Validation Loss: 0.025454957\n",
      "Epoch: 3406 cost = 0.013049724\n",
      "Validation Loss: 0.046461586\n",
      "Epoch: 3407 cost = 0.013049668\n",
      "Validation Loss: 0.046542436\n",
      "Epoch: 3408 cost = 0.013049441\n",
      "Validation Loss: 0.03790678\n",
      "Epoch: 3409 cost = 0.013048206\n",
      "Validation Loss: 0.033347975\n",
      "Epoch: 3410 cost = 0.013048562\n",
      "Validation Loss: 0.037595335\n",
      "Epoch: 3411 cost = 0.013048271\n",
      "Validation Loss: 0.035922427\n",
      "Epoch: 3412 cost = 0.013047480\n",
      "Validation Loss: 0.029218022\n",
      "Epoch: 3413 cost = 0.013047255\n",
      "Validation Loss: 0.03273391\n",
      "Epoch: 3414 cost = 0.013046697\n",
      "Validation Loss: 0.027593011\n",
      "Epoch: 3415 cost = 0.013047258\n",
      "Validation Loss: 0.027924621\n",
      "Epoch: 3416 cost = 0.013046549\n",
      "Validation Loss: 0.02439847\n",
      "Epoch: 3417 cost = 0.013046306\n",
      "Validation Loss: 0.03240593\n",
      "Epoch: 3418 cost = 0.013045876\n",
      "Validation Loss: 0.030634651\n",
      "Epoch: 3419 cost = 0.013045306\n",
      "Validation Loss: 0.029841075\n",
      "Epoch: 3420 cost = 0.013044678\n",
      "Validation Loss: 0.043700144\n",
      "Epoch: 3421 cost = 0.013044590\n",
      "Validation Loss: 0.05763216\n",
      "Epoch: 3422 cost = 0.013044324\n",
      "Validation Loss: 0.057534367\n",
      "Epoch: 3423 cost = 0.013043558\n",
      "Validation Loss: 0.047530293\n",
      "Epoch: 3424 cost = 0.013043793\n",
      "Validation Loss: 0.037713457\n",
      "Epoch: 3425 cost = 0.013043241\n",
      "Validation Loss: 0.031025544\n",
      "Epoch: 3426 cost = 0.013043045\n",
      "Validation Loss: 0.02401174\n",
      "Epoch: 3427 cost = 0.013042147\n",
      "Validation Loss: 0.029104402\n",
      "Epoch: 3428 cost = 0.013042776\n",
      "Validation Loss: 0.024913091\n",
      "Epoch: 3429 cost = 0.013041720\n",
      "Validation Loss: 0.03795148\n",
      "Epoch: 3430 cost = 0.013041882\n",
      "Validation Loss: 0.037355907\n",
      "Epoch: 3431 cost = 0.013041274\n",
      "Validation Loss: 0.04300568\n",
      "Epoch: 3432 cost = 0.013041058\n",
      "Validation Loss: 0.047052644\n",
      "Epoch: 3433 cost = 0.013040142\n",
      "Validation Loss: 0.042819206\n",
      "Epoch: 3434 cost = 0.013040288\n",
      "Validation Loss: 0.035337064\n",
      "Epoch: 3435 cost = 0.013039949\n",
      "Validation Loss: 0.024008663\n",
      "Epoch: 3436 cost = 0.013039818\n",
      "Validation Loss: 0.02925494\n",
      "Epoch: 3437 cost = 0.013039168\n",
      "Validation Loss: 0.030612648\n",
      "Epoch: 3438 cost = 0.013038914\n",
      "Validation Loss: 0.036305048\n",
      "Epoch: 3439 cost = 0.013038853\n",
      "Validation Loss: 0.03787524\n",
      "Epoch: 3440 cost = 0.013037876\n",
      "Validation Loss: 0.033853736\n",
      "Epoch: 3441 cost = 0.013038057\n",
      "Validation Loss: 0.026420357\n",
      "Epoch: 3442 cost = 0.013037525\n",
      "Validation Loss: 0.022469386\n",
      "Epoch: 3443 cost = 0.013038152\n",
      "Validation Loss: 0.024693733\n",
      "Epoch: 3444 cost = 0.013036980\n",
      "Validation Loss: 0.031170247\n",
      "Epoch: 3445 cost = 0.013036490\n",
      "Validation Loss: 0.03020764\n",
      "Epoch: 3446 cost = 0.013035599\n",
      "Validation Loss: 0.027778285\n",
      "Epoch: 3447 cost = 0.013036460\n",
      "Validation Loss: 0.023576992\n",
      "Epoch: 3448 cost = 0.013035806\n",
      "Validation Loss: 0.016496196\n",
      "Epoch: 3449 cost = 0.013035304\n",
      "Validation Loss: 0.024211163\n",
      "Epoch: 3450 cost = 0.013035639\n",
      "Validation Loss: 0.03508645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3451 cost = 0.013034694\n",
      "Validation Loss: 0.033355657\n",
      "Epoch: 3452 cost = 0.013034704\n",
      "Validation Loss: 0.032223854\n",
      "Epoch: 3453 cost = 0.013033712\n",
      "Validation Loss: 0.029138556\n",
      "Epoch: 3454 cost = 0.013033694\n",
      "Validation Loss: 0.024369957\n",
      "Epoch: 3455 cost = 0.013032966\n",
      "Validation Loss: 0.023728874\n",
      "Epoch: 3456 cost = 0.013033361\n",
      "Validation Loss: 0.026529007\n",
      "Epoch: 3457 cost = 0.013032597\n",
      "Validation Loss: 0.034179382\n",
      "Epoch: 3458 cost = 0.013032352\n",
      "Validation Loss: 0.027355816\n",
      "Epoch: 3459 cost = 0.013031966\n",
      "Validation Loss: 0.03897973\n",
      "Epoch: 3460 cost = 0.013031886\n",
      "Validation Loss: 0.030493448\n",
      "Epoch: 3461 cost = 0.013031867\n",
      "Validation Loss: 0.031177761\n",
      "Epoch: 3462 cost = 0.013031341\n",
      "Validation Loss: 0.03316919\n",
      "Epoch: 3463 cost = 0.013030522\n",
      "Validation Loss: 0.027647426\n",
      "Epoch: 3464 cost = 0.013030601\n",
      "Validation Loss: 0.026797276\n",
      "Epoch: 3465 cost = 0.013029691\n",
      "Validation Loss: 0.029499229\n",
      "Epoch: 3466 cost = 0.013029492\n",
      "Validation Loss: 0.032743566\n",
      "Epoch: 3467 cost = 0.013029807\n",
      "Validation Loss: 0.040575605\n",
      "Epoch: 3468 cost = 0.013029423\n",
      "Validation Loss: 0.04153016\n",
      "Epoch: 3469 cost = 0.013028890\n",
      "Validation Loss: 0.035680868\n",
      "Epoch: 3470 cost = 0.013029442\n",
      "Validation Loss: 0.04601256\n",
      "Epoch: 3471 cost = 0.013027814\n",
      "Validation Loss: 0.034170445\n",
      "Epoch: 3472 cost = 0.013028474\n",
      "Validation Loss: 0.032214038\n",
      "Epoch: 3473 cost = 0.013027391\n",
      "Validation Loss: 0.027577844\n",
      "Epoch: 3474 cost = 0.013027669\n",
      "Validation Loss: 0.026255686\n",
      "Epoch: 3475 cost = 0.013027270\n",
      "Validation Loss: 0.028999742\n",
      "Epoch: 3476 cost = 0.013026854\n",
      "Validation Loss: 0.037530173\n",
      "Epoch: 3477 cost = 0.013026301\n",
      "Validation Loss: 0.031310484\n",
      "Epoch: 3478 cost = 0.013025611\n",
      "Validation Loss: 0.029753856\n",
      "Epoch: 3479 cost = 0.013025848\n",
      "Validation Loss: 0.033659894\n",
      "Epoch: 3480 cost = 0.013025539\n",
      "Validation Loss: 0.03035374\n",
      "Epoch: 3481 cost = 0.013024358\n",
      "Validation Loss: 0.025221165\n",
      "Epoch: 3482 cost = 0.013024786\n",
      "Validation Loss: 0.035697497\n",
      "Epoch: 3483 cost = 0.013024132\n",
      "Validation Loss: 0.031569917\n",
      "Epoch: 3484 cost = 0.013024118\n",
      "Validation Loss: 0.040874377\n",
      "Epoch: 3485 cost = 0.013023342\n",
      "Validation Loss: 0.043108482\n",
      "Epoch: 3486 cost = 0.013023477\n",
      "Validation Loss: 0.04464949\n",
      "Epoch: 3487 cost = 0.013022830\n",
      "Validation Loss: 0.032023136\n",
      "Epoch: 3488 cost = 0.013022623\n",
      "Validation Loss: 0.022760486\n",
      "Epoch: 3489 cost = 0.013022312\n",
      "Validation Loss: 0.026115205\n",
      "Epoch: 3490 cost = 0.013022326\n",
      "Validation Loss: 0.0193676\n",
      "Epoch: 3491 cost = 0.013021957\n",
      "Validation Loss: 0.017648352\n",
      "Epoch: 3492 cost = 0.013021507\n",
      "Validation Loss: 0.024173662\n",
      "Epoch: 3493 cost = 0.013021269\n",
      "Validation Loss: 0.02438431\n",
      "Epoch: 3494 cost = 0.013020304\n",
      "Validation Loss: 0.021685518\n",
      "Epoch: 3495 cost = 0.013020678\n",
      "Validation Loss: 0.015454747\n",
      "Epoch: 3496 cost = 0.013020800\n",
      "Validation Loss: 0.016918626\n",
      "Epoch: 3497 cost = 0.013019365\n",
      "Validation Loss: 0.024665084\n",
      "Epoch: 3498 cost = 0.013019461\n",
      "Validation Loss: 0.029152032\n",
      "Epoch: 3499 cost = 0.013019066\n",
      "Validation Loss: 0.02046008\n",
      "Epoch: 3500 cost = 0.013018754\n",
      "Validation Loss: 0.02915551\n",
      "Epoch: 3501 cost = 0.013018469\n",
      "Validation Loss: 0.023663113\n",
      "Epoch: 3502 cost = 0.013018227\n",
      "Validation Loss: 0.026503203\n",
      "Epoch: 3503 cost = 0.013016962\n",
      "Validation Loss: 0.034342963\n",
      "Epoch: 3504 cost = 0.013018035\n",
      "Validation Loss: 0.025887752\n",
      "Epoch: 3505 cost = 0.013016994\n",
      "Validation Loss: 0.022573853\n",
      "Epoch: 3506 cost = 0.013016789\n",
      "Validation Loss: 0.029457696\n",
      "Epoch: 3507 cost = 0.013016484\n",
      "Validation Loss: 0.028138319\n",
      "Epoch: 3508 cost = 0.013016244\n",
      "Validation Loss: 0.023306357\n",
      "Epoch: 3509 cost = 0.013015679\n",
      "Validation Loss: 0.028115284\n",
      "Epoch: 3510 cost = 0.013015391\n",
      "Validation Loss: 0.028276533\n",
      "Epoch: 3511 cost = 0.013015169\n",
      "Validation Loss: 0.034844227\n",
      "Epoch: 3512 cost = 0.013014876\n",
      "Validation Loss: 0.02937647\n",
      "Epoch: 3513 cost = 0.013013991\n",
      "Validation Loss: 0.027693728\n",
      "Epoch: 3514 cost = 0.013014694\n",
      "Validation Loss: 0.03270095\n",
      "Epoch: 3515 cost = 0.013014501\n",
      "Validation Loss: 0.031811904\n",
      "Epoch: 3516 cost = 0.013013967\n",
      "Validation Loss: 0.025485413\n",
      "Epoch: 3517 cost = 0.013013698\n",
      "Validation Loss: 0.0299058\n",
      "Epoch: 3518 cost = 0.013012609\n",
      "Validation Loss: 0.032340717\n",
      "Epoch: 3519 cost = 0.013013118\n",
      "Validation Loss: 0.025001088\n",
      "Epoch: 3520 cost = 0.013012358\n",
      "Validation Loss: 0.028473696\n",
      "Epoch: 3521 cost = 0.013012600\n",
      "Validation Loss: 0.045592483\n",
      "Epoch: 3522 cost = 0.013011673\n",
      "Validation Loss: 0.0396456\n",
      "Epoch: 3523 cost = 0.013011045\n",
      "Validation Loss: 0.025108784\n",
      "Epoch: 3524 cost = 0.013011004\n",
      "Validation Loss: 0.02161702\n",
      "Epoch: 3525 cost = 0.013011305\n",
      "Validation Loss: 0.015546719\n",
      "Epoch: 3526 cost = 0.013010583\n",
      "Validation Loss: 0.019899685\n",
      "Epoch: 3527 cost = 0.013010559\n",
      "Validation Loss: 0.02572285\n",
      "Epoch: 3528 cost = 0.013009598\n",
      "Validation Loss: 0.02478582\n",
      "Epoch: 3529 cost = 0.013008673\n",
      "Validation Loss: 0.02117266\n",
      "Epoch: 3530 cost = 0.013009434\n",
      "Validation Loss: 0.02935126\n",
      "Epoch: 3531 cost = 0.013009162\n",
      "Validation Loss: 0.020307483\n",
      "Epoch: 3532 cost = 0.013008172\n",
      "Validation Loss: 0.017532935\n",
      "Epoch: 3533 cost = 0.013008270\n",
      "Validation Loss: 0.025944432\n",
      "Epoch: 3534 cost = 0.013007866\n",
      "Validation Loss: 0.023051128\n",
      "Epoch: 3535 cost = 0.013007934\n",
      "Validation Loss: 0.02762722\n",
      "Epoch: 3536 cost = 0.013007663\n",
      "Validation Loss: 0.038167953\n",
      "Epoch: 3537 cost = 0.013007182\n",
      "Validation Loss: 0.04807782\n",
      "Epoch: 3538 cost = 0.013006793\n",
      "Validation Loss: 0.050235085\n",
      "Epoch: 3539 cost = 0.013006501\n",
      "Validation Loss: 0.049245983\n",
      "Epoch: 3540 cost = 0.013005391\n",
      "Validation Loss: 0.041242994\n",
      "Epoch: 3541 cost = 0.013005783\n",
      "Validation Loss: 0.03803966\n",
      "Epoch: 3542 cost = 0.013005422\n",
      "Validation Loss: 0.03671648\n",
      "Epoch: 3543 cost = 0.013004863\n",
      "Validation Loss: 0.030110838\n",
      "Epoch: 3544 cost = 0.013004349\n",
      "Validation Loss: 0.027127037\n",
      "Epoch: 3545 cost = 0.013004754\n",
      "Validation Loss: 0.042435993\n",
      "Epoch: 3546 cost = 0.013004132\n",
      "Validation Loss: 0.051845964\n",
      "Epoch: 3547 cost = 0.013004096\n",
      "Validation Loss: 0.059809137\n",
      "Epoch: 3548 cost = 0.013003055\n",
      "Validation Loss: 0.063532375\n",
      "Epoch: 3549 cost = 0.013003341\n",
      "Validation Loss: 0.0351121\n",
      "Epoch: 3550 cost = 0.013002359\n",
      "Validation Loss: 0.02260536\n",
      "Epoch: 3551 cost = 0.013002827\n",
      "Validation Loss: 0.027050208\n",
      "Epoch: 3552 cost = 0.013001751\n",
      "Validation Loss: 0.027174808\n",
      "Epoch: 3553 cost = 0.013002442\n",
      "Validation Loss: 0.04032988\n",
      "Epoch: 3554 cost = 0.013001626\n",
      "Validation Loss: 0.0332796\n",
      "Epoch: 3555 cost = 0.013001182\n",
      "Validation Loss: 0.029333018\n",
      "Epoch: 3556 cost = 0.013001246\n",
      "Validation Loss: 0.023285825\n",
      "Epoch: 3557 cost = 0.013000387\n",
      "Validation Loss: 0.024785178\n",
      "Epoch: 3558 cost = 0.013000345\n",
      "Validation Loss: 0.021981986\n",
      "Epoch: 3559 cost = 0.012999883\n",
      "Validation Loss: 0.03244842\n",
      "Epoch: 3560 cost = 0.012999364\n",
      "Validation Loss: 0.050176945\n",
      "Epoch: 3561 cost = 0.012999463\n",
      "Validation Loss: 0.05023032\n",
      "Epoch: 3562 cost = 0.012999036\n",
      "Validation Loss: 0.05493503\n",
      "Epoch: 3563 cost = 0.012998960\n",
      "Validation Loss: 0.031061357\n",
      "Epoch: 3564 cost = 0.012998401\n",
      "Validation Loss: 0.030000206\n",
      "Epoch: 3565 cost = 0.012998117\n",
      "Validation Loss: 0.024595547\n",
      "Epoch: 3566 cost = 0.012998050\n",
      "Validation Loss: 0.019048695\n",
      "Epoch: 3567 cost = 0.012997701\n",
      "Validation Loss: 0.018016033\n",
      "Epoch: 3568 cost = 0.012997090\n",
      "Validation Loss: 0.032188375\n",
      "Epoch: 3569 cost = 0.012996864\n",
      "Validation Loss: 0.03249532\n",
      "Epoch: 3570 cost = 0.012996604\n",
      "Validation Loss: 0.027864395\n",
      "Epoch: 3571 cost = 0.012996504\n",
      "Validation Loss: 0.030762192\n",
      "Epoch: 3572 cost = 0.012996229\n",
      "Validation Loss: 0.046872117\n",
      "Epoch: 3573 cost = 0.012995896\n",
      "Validation Loss: 0.039804447\n",
      "Epoch: 3574 cost = 0.012995155\n",
      "Validation Loss: 0.020989096\n",
      "Epoch: 3575 cost = 0.012994941\n",
      "Validation Loss: 0.018420074\n",
      "Epoch: 3576 cost = 0.012994501\n",
      "Validation Loss: 0.024886005\n",
      "Epoch: 3577 cost = 0.012994888\n",
      "Validation Loss: 0.030793339\n",
      "Epoch: 3578 cost = 0.012994415\n",
      "Validation Loss: 0.027537435\n",
      "Epoch: 3579 cost = 0.012994306\n",
      "Validation Loss: 0.023380077\n",
      "Epoch: 3580 cost = 0.012993427\n",
      "Validation Loss: 0.033187177\n",
      "Epoch: 3581 cost = 0.012993456\n",
      "Validation Loss: 0.027078262\n",
      "Epoch: 3582 cost = 0.012992941\n",
      "Validation Loss: 0.023847215\n",
      "Epoch: 3583 cost = 0.012992660\n",
      "Validation Loss: 0.02208582\n",
      "Epoch: 3584 cost = 0.012991764\n",
      "Validation Loss: 0.014347702\n",
      "Epoch: 3585 cost = 0.012992158\n",
      "Validation Loss: 0.016358374\n",
      "Epoch: 3586 cost = 0.012991400\n",
      "Validation Loss: 0.021383693\n",
      "Epoch: 3587 cost = 0.012991525\n",
      "Validation Loss: 0.03242493\n",
      "Epoch: 3588 cost = 0.012991389\n",
      "Validation Loss: 0.04751183\n",
      "Epoch: 3589 cost = 0.012990724\n",
      "Validation Loss: 0.03428714\n",
      "Epoch: 3590 cost = 0.012990295\n",
      "Validation Loss: 0.02077681\n",
      "Epoch: 3591 cost = 0.012989604\n",
      "Validation Loss: 0.022957943\n",
      "Epoch: 3592 cost = 0.012989590\n",
      "Validation Loss: 0.027923308\n",
      "Epoch: 3593 cost = 0.012990225\n",
      "Validation Loss: 0.05255583\n",
      "Epoch: 3594 cost = 0.012989323\n",
      "Validation Loss: 0.067215085\n",
      "Epoch: 3595 cost = 0.012989164\n",
      "Validation Loss: 0.059896912\n",
      "Epoch: 3596 cost = 0.012988152\n",
      "Validation Loss: 0.04304591\n",
      "Epoch: 3597 cost = 0.012988552\n",
      "Validation Loss: 0.03169398\n",
      "Epoch: 3598 cost = 0.012987588\n",
      "Validation Loss: 0.040707022\n",
      "Epoch: 3599 cost = 0.012987413\n",
      "Validation Loss: 0.031523146\n",
      "Epoch: 3600 cost = 0.012987092\n",
      "Validation Loss: 0.03548236\n",
      "Epoch: 3601 cost = 0.012986542\n",
      "Validation Loss: 0.026625276\n",
      "Epoch: 3602 cost = 0.012986836\n",
      "Validation Loss: 0.023048528\n",
      "Epoch: 3603 cost = 0.012986068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.023316734\n",
      "Epoch: 3604 cost = 0.012985937\n",
      "Validation Loss: 0.023906663\n",
      "Epoch: 3605 cost = 0.012985964\n",
      "Validation Loss: 0.029342828\n",
      "Epoch: 3606 cost = 0.012985531\n",
      "Validation Loss: 0.035448406\n",
      "Epoch: 3607 cost = 0.012984854\n",
      "Validation Loss: 0.035504434\n",
      "Epoch: 3608 cost = 0.012984761\n",
      "Validation Loss: 0.030775731\n",
      "Epoch: 3609 cost = 0.012984579\n",
      "Validation Loss: 0.024180919\n",
      "Epoch: 3610 cost = 0.012984539\n",
      "Validation Loss: 0.036596708\n",
      "Epoch: 3611 cost = 0.012984021\n",
      "Validation Loss: 0.0391423\n",
      "Epoch: 3612 cost = 0.012983045\n",
      "Validation Loss: 0.032646485\n",
      "Epoch: 3613 cost = 0.012983243\n",
      "Validation Loss: 0.025747428\n",
      "Epoch: 3614 cost = 0.012982871\n",
      "Validation Loss: 0.027902802\n",
      "Epoch: 3615 cost = 0.012982656\n",
      "Validation Loss: 0.041990116\n",
      "Epoch: 3616 cost = 0.012982494\n",
      "Validation Loss: 0.031510696\n",
      "Epoch: 3617 cost = 0.012981853\n",
      "Validation Loss: 0.033298906\n",
      "Epoch: 3618 cost = 0.012981389\n",
      "Validation Loss: 0.03202342\n",
      "Epoch: 3619 cost = 0.012980991\n",
      "Validation Loss: 0.021806015\n",
      "Epoch: 3620 cost = 0.012980821\n",
      "Validation Loss: 0.017119773\n",
      "Epoch: 3621 cost = 0.012980791\n",
      "Validation Loss: 0.023082675\n",
      "Epoch: 3622 cost = 0.012980266\n",
      "Validation Loss: 0.027006019\n",
      "Epoch: 3623 cost = 0.012980460\n",
      "Validation Loss: 0.030568277\n",
      "Epoch: 3624 cost = 0.012979991\n",
      "Validation Loss: 0.03483\n",
      "Epoch: 3625 cost = 0.012979645\n",
      "Validation Loss: 0.028422989\n",
      "Epoch: 3626 cost = 0.012979269\n",
      "Validation Loss: 0.027992018\n",
      "Epoch: 3627 cost = 0.012978593\n",
      "Validation Loss: 0.01912835\n",
      "Epoch: 3628 cost = 0.012978706\n",
      "Validation Loss: 0.015380708\n",
      "Epoch: 3629 cost = 0.012978415\n",
      "Validation Loss: 0.020015571\n",
      "Epoch: 3630 cost = 0.012978253\n",
      "Validation Loss: 0.030891398\n",
      "Epoch: 3631 cost = 0.012977596\n",
      "Validation Loss: 0.028359113\n",
      "Epoch: 3632 cost = 0.012977623\n",
      "Validation Loss: 0.032001816\n",
      "Epoch: 3633 cost = 0.012976777\n",
      "Validation Loss: 0.030542737\n",
      "Epoch: 3634 cost = 0.012976894\n",
      "Validation Loss: 0.03639355\n",
      "Epoch: 3635 cost = 0.012976249\n",
      "Validation Loss: 0.028800145\n",
      "Epoch: 3636 cost = 0.012976208\n",
      "Validation Loss: 0.026594007\n",
      "Epoch: 3637 cost = 0.012975531\n",
      "Validation Loss: 0.026813734\n",
      "Epoch: 3638 cost = 0.012975669\n",
      "Validation Loss: 0.026372332\n",
      "Epoch: 3639 cost = 0.012975024\n",
      "Validation Loss: 0.023251167\n",
      "Epoch: 3640 cost = 0.012974302\n",
      "Validation Loss: 0.028825473\n",
      "Epoch: 3641 cost = 0.012974759\n",
      "Validation Loss: 0.035143062\n",
      "Epoch: 3642 cost = 0.012974329\n",
      "Validation Loss: 0.033878896\n",
      "Epoch: 3643 cost = 0.012973940\n",
      "Validation Loss: 0.035381325\n",
      "Epoch: 3644 cost = 0.012973612\n",
      "Validation Loss: 0.032047197\n",
      "Epoch: 3645 cost = 0.012973237\n",
      "Validation Loss: 0.027393674\n",
      "Epoch: 3646 cost = 0.012973249\n",
      "Validation Loss: 0.018646214\n",
      "Epoch: 3647 cost = 0.012972469\n",
      "Validation Loss: 0.025961297\n",
      "Epoch: 3648 cost = 0.012972676\n",
      "Validation Loss: 0.040800992\n",
      "Epoch: 3649 cost = 0.012972043\n",
      "Validation Loss: 0.03524715\n",
      "Epoch: 3650 cost = 0.012971727\n",
      "Validation Loss: 0.026153143\n",
      "Epoch: 3651 cost = 0.012971235\n",
      "Validation Loss: 0.022304755\n",
      "Epoch: 3652 cost = 0.012971408\n",
      "Validation Loss: 0.022448746\n",
      "Epoch: 3653 cost = 0.012970660\n",
      "Validation Loss: 0.03259177\n",
      "Epoch: 3654 cost = 0.012970613\n",
      "Validation Loss: 0.025968945\n",
      "Epoch: 3655 cost = 0.012970429\n",
      "Validation Loss: 0.030443706\n",
      "Epoch: 3656 cost = 0.012970045\n",
      "Validation Loss: 0.026086586\n",
      "Epoch: 3657 cost = 0.012969416\n",
      "Validation Loss: 0.030718453\n",
      "Epoch: 3658 cost = 0.012969063\n",
      "Validation Loss: 0.03289036\n",
      "Epoch: 3659 cost = 0.012969169\n",
      "Validation Loss: 0.028459048\n",
      "Epoch: 3660 cost = 0.012968515\n",
      "Validation Loss: 0.032607578\n",
      "Epoch: 3661 cost = 0.012968551\n",
      "Validation Loss: 0.03231149\n",
      "Epoch: 3662 cost = 0.012967819\n",
      "Validation Loss: 0.026772536\n",
      "Epoch: 3663 cost = 0.012967530\n",
      "Validation Loss: 0.02882689\n",
      "Epoch: 3664 cost = 0.012967432\n",
      "Validation Loss: 0.023745188\n",
      "Epoch: 3665 cost = 0.012967064\n",
      "Validation Loss: 0.02526881\n",
      "Epoch: 3666 cost = 0.012967297\n",
      "Validation Loss: 0.030593928\n",
      "Epoch: 3667 cost = 0.012966499\n",
      "Validation Loss: 0.03554791\n",
      "Epoch: 3668 cost = 0.012966202\n",
      "Validation Loss: 0.017815733\n",
      "Epoch: 3669 cost = 0.012966085\n",
      "Validation Loss: 0.022426434\n",
      "Epoch: 3670 cost = 0.012965355\n",
      "Validation Loss: 0.02738153\n",
      "Epoch: 3671 cost = 0.012965307\n",
      "Validation Loss: 0.03485808\n",
      "Epoch: 3672 cost = 0.012964936\n",
      "Validation Loss: 0.048617654\n",
      "Epoch: 3673 cost = 0.012964779\n",
      "Validation Loss: 0.040945735\n",
      "Epoch: 3674 cost = 0.012964116\n",
      "Validation Loss: 0.04174811\n",
      "Epoch: 3675 cost = 0.012964222\n",
      "Validation Loss: 0.057036806\n",
      "Epoch: 3676 cost = 0.012963968\n",
      "Validation Loss: 0.055128302\n",
      "Epoch: 3677 cost = 0.012963612\n",
      "Validation Loss: 0.04019966\n",
      "Epoch: 3678 cost = 0.012963104\n",
      "Validation Loss: 0.02262166\n",
      "Epoch: 3679 cost = 0.012962794\n",
      "Validation Loss: 0.022502374\n",
      "Epoch: 3680 cost = 0.012963292\n",
      "Validation Loss: 0.01789854\n",
      "Epoch: 3681 cost = 0.012962861\n",
      "Validation Loss: 0.01933364\n",
      "Epoch: 3682 cost = 0.012961753\n",
      "Validation Loss: 0.018747011\n",
      "Epoch: 3683 cost = 0.012961809\n",
      "Validation Loss: 0.015276206\n",
      "Epoch: 3684 cost = 0.012961719\n",
      "Validation Loss: 0.030361008\n",
      "Epoch: 3685 cost = 0.012961527\n",
      "Validation Loss: 0.03842993\n",
      "Epoch: 3686 cost = 0.012961397\n",
      "Validation Loss: 0.031052276\n",
      "Epoch: 3687 cost = 0.012960282\n",
      "Validation Loss: 0.025501814\n",
      "Epoch: 3688 cost = 0.012960539\n",
      "Validation Loss: 0.032147978\n",
      "Epoch: 3689 cost = 0.012959533\n",
      "Validation Loss: 0.018663565\n",
      "Epoch: 3690 cost = 0.012959472\n",
      "Validation Loss: 0.021838708\n",
      "Epoch: 3691 cost = 0.012959050\n",
      "Validation Loss: 0.037135117\n",
      "Epoch: 3692 cost = 0.012959347\n",
      "Validation Loss: 0.039726228\n",
      "Epoch: 3693 cost = 0.012958580\n",
      "Validation Loss: 0.031349476\n",
      "Epoch: 3694 cost = 0.012958768\n",
      "Validation Loss: 0.02942477\n",
      "Epoch: 3695 cost = 0.012957803\n",
      "Validation Loss: 0.030982854\n",
      "Epoch: 3696 cost = 0.012957997\n",
      "Validation Loss: 0.034753717\n",
      "Epoch: 3697 cost = 0.012957562\n",
      "Validation Loss: 0.03535891\n",
      "Epoch: 3698 cost = 0.012957108\n",
      "Validation Loss: 0.026196035\n",
      "Epoch: 3699 cost = 0.012957101\n",
      "Validation Loss: 0.021500755\n",
      "Epoch: 3700 cost = 0.012956434\n",
      "Validation Loss: 0.01944616\n",
      "Epoch: 3701 cost = 0.012956048\n",
      "Validation Loss: 0.021404868\n",
      "Epoch: 3702 cost = 0.012955962\n",
      "Validation Loss: 0.021902923\n",
      "Epoch: 3703 cost = 0.012955987\n",
      "Validation Loss: 0.02612663\n",
      "Epoch: 3704 cost = 0.012955167\n",
      "Validation Loss: 0.028911676\n",
      "Epoch: 3705 cost = 0.012955411\n",
      "Validation Loss: 0.024772277\n",
      "Epoch: 3706 cost = 0.012954901\n",
      "Validation Loss: 0.030246304\n",
      "Epoch: 3707 cost = 0.012954713\n",
      "Validation Loss: 0.02684417\n",
      "Epoch: 3708 cost = 0.012953966\n",
      "Validation Loss: 0.026066473\n",
      "Epoch: 3709 cost = 0.012953953\n",
      "Validation Loss: 0.016888695\n",
      "Epoch: 3710 cost = 0.012953368\n",
      "Validation Loss: 0.019732151\n",
      "Epoch: 3711 cost = 0.012953304\n",
      "Validation Loss: 0.013559348\n",
      "Epoch: 3712 cost = 0.012953042\n",
      "Validation Loss: 0.017882204\n",
      "Epoch: 3713 cost = 0.012952811\n",
      "Validation Loss: 0.020168062\n",
      "Epoch: 3714 cost = 0.012952734\n",
      "Validation Loss: 0.020157857\n",
      "Epoch: 3715 cost = 0.012952434\n",
      "Validation Loss: 0.02567643\n",
      "Epoch: 3716 cost = 0.012952152\n",
      "Validation Loss: 0.029617498\n",
      "Epoch: 3717 cost = 0.012951682\n",
      "Validation Loss: 0.024871225\n",
      "Epoch: 3718 cost = 0.012950866\n",
      "Validation Loss: 0.02552937\n",
      "Epoch: 3719 cost = 0.012951037\n",
      "Validation Loss: 0.03790318\n",
      "Epoch: 3720 cost = 0.012950419\n",
      "Validation Loss: 0.03069276\n",
      "Epoch: 3721 cost = 0.012950330\n",
      "Validation Loss: 0.03167264\n",
      "Epoch: 3722 cost = 0.012950079\n",
      "Validation Loss: 0.021577073\n",
      "Epoch: 3723 cost = 0.012949493\n",
      "Validation Loss: 0.018258372\n",
      "Epoch: 3724 cost = 0.012950203\n",
      "Validation Loss: 0.023533795\n",
      "Epoch: 3725 cost = 0.012949153\n",
      "Validation Loss: 0.025874613\n",
      "Epoch: 3726 cost = 0.012948866\n",
      "Validation Loss: 0.033640627\n",
      "Epoch: 3727 cost = 0.012948308\n",
      "Validation Loss: 0.03531158\n",
      "Epoch: 3728 cost = 0.012947902\n",
      "Validation Loss: 0.02974307\n",
      "Epoch: 3729 cost = 0.012947986\n",
      "Validation Loss: 0.031689733\n",
      "Epoch: 3730 cost = 0.012948195\n",
      "Validation Loss: 0.03004503\n",
      "Epoch: 3731 cost = 0.012947973\n",
      "Validation Loss: 0.03280994\n",
      "Epoch: 3732 cost = 0.012947373\n",
      "Validation Loss: 0.027204596\n",
      "Epoch: 3733 cost = 0.012946079\n",
      "Validation Loss: 0.033487298\n",
      "Epoch: 3734 cost = 0.012946388\n",
      "Validation Loss: 0.039284267\n",
      "Epoch: 3735 cost = 0.012945980\n",
      "Validation Loss: 0.0383604\n",
      "Epoch: 3736 cost = 0.012946035\n",
      "Validation Loss: 0.04695996\n",
      "Epoch: 3737 cost = 0.012945421\n",
      "Validation Loss: 0.04445664\n",
      "Epoch: 3738 cost = 0.012945239\n",
      "Validation Loss: 0.029764835\n",
      "Epoch: 3739 cost = 0.012944603\n",
      "Validation Loss: 0.029900892\n",
      "Epoch: 3740 cost = 0.012944762\n",
      "Validation Loss: 0.035307467\n",
      "Epoch: 3741 cost = 0.012944139\n",
      "Validation Loss: 0.023250947\n",
      "Epoch: 3742 cost = 0.012943844\n",
      "Validation Loss: 0.026081752\n",
      "Epoch: 3743 cost = 0.012943931\n",
      "Validation Loss: 0.016205255\n",
      "Epoch: 3744 cost = 0.012943111\n",
      "Validation Loss: 0.022414304\n",
      "Epoch: 3745 cost = 0.012943237\n",
      "Validation Loss: 0.029938525\n",
      "Epoch: 3746 cost = 0.012943227\n",
      "Validation Loss: 0.024812406\n",
      "Epoch: 3747 cost = 0.012942469\n",
      "Validation Loss: 0.028878398\n",
      "Epoch: 3748 cost = 0.012942021\n",
      "Validation Loss: 0.031005379\n",
      "Epoch: 3749 cost = 0.012941973\n",
      "Validation Loss: 0.028711561\n",
      "Epoch: 3750 cost = 0.012941915\n",
      "Validation Loss: 0.023630153\n",
      "Epoch: 3751 cost = 0.012941131\n",
      "Validation Loss: 0.0392243\n",
      "Epoch: 3752 cost = 0.012941395\n",
      "Validation Loss: 0.050274264\n",
      "Epoch: 3753 cost = 0.012940682\n",
      "Validation Loss: 0.052304257\n",
      "Epoch: 3754 cost = 0.012940668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04590306\n",
      "Epoch: 3755 cost = 0.012940369\n",
      "Validation Loss: 0.039056268\n",
      "Epoch: 3756 cost = 0.012939783\n",
      "Validation Loss: 0.043552026\n",
      "Epoch: 3757 cost = 0.012939752\n",
      "Validation Loss: 0.030564245\n",
      "Epoch: 3758 cost = 0.012939201\n",
      "Validation Loss: 0.023842026\n",
      "Epoch: 3759 cost = 0.012939019\n",
      "Validation Loss: 0.021740817\n",
      "Epoch: 3760 cost = 0.012938664\n",
      "Validation Loss: 0.028049666\n",
      "Epoch: 3761 cost = 0.012938521\n",
      "Validation Loss: 0.025713906\n",
      "Epoch: 3762 cost = 0.012938187\n",
      "Validation Loss: 0.02619324\n",
      "Epoch: 3763 cost = 0.012938179\n",
      "Validation Loss: 0.030964246\n",
      "Epoch: 3764 cost = 0.012937700\n",
      "Validation Loss: 0.03116869\n",
      "Epoch: 3765 cost = 0.012937184\n",
      "Validation Loss: 0.027403295\n",
      "Epoch: 3766 cost = 0.012936958\n",
      "Validation Loss: 0.029741231\n",
      "Epoch: 3767 cost = 0.012936733\n",
      "Validation Loss: 0.029586786\n",
      "Epoch: 3768 cost = 0.012936593\n",
      "Validation Loss: 0.033963095\n",
      "Epoch: 3769 cost = 0.012936048\n",
      "Validation Loss: 0.03316711\n",
      "Epoch: 3770 cost = 0.012935740\n",
      "Validation Loss: 0.027049096\n",
      "Epoch: 3771 cost = 0.012935383\n",
      "Validation Loss: 0.02466923\n",
      "Epoch: 3772 cost = 0.012934685\n",
      "Validation Loss: 0.029487582\n",
      "Epoch: 3773 cost = 0.012934709\n",
      "Validation Loss: 0.022004781\n",
      "Epoch: 3774 cost = 0.012934335\n",
      "Validation Loss: 0.022641486\n",
      "Epoch: 3775 cost = 0.012934466\n",
      "Validation Loss: 0.028109567\n",
      "Epoch: 3776 cost = 0.012933255\n",
      "Validation Loss: 0.022660559\n",
      "Epoch: 3777 cost = 0.012933715\n",
      "Validation Loss: 0.02146513\n",
      "Epoch: 3778 cost = 0.012932972\n",
      "Validation Loss: 0.024716003\n",
      "Epoch: 3779 cost = 0.012933058\n",
      "Validation Loss: 0.044186037\n",
      "Epoch: 3780 cost = 0.012932302\n",
      "Validation Loss: 0.045209877\n",
      "Epoch: 3781 cost = 0.012932656\n",
      "Validation Loss: 0.038487636\n",
      "Epoch: 3782 cost = 0.012932007\n",
      "Validation Loss: 0.038752317\n",
      "Epoch: 3783 cost = 0.012932427\n",
      "Validation Loss: 0.040696193\n",
      "Epoch: 3784 cost = 0.012931709\n",
      "Validation Loss: 0.05344908\n",
      "Epoch: 3785 cost = 0.012931247\n",
      "Validation Loss: 0.052252065\n",
      "Epoch: 3786 cost = 0.012930701\n",
      "Validation Loss: 0.050343834\n",
      "Epoch: 3787 cost = 0.012930988\n",
      "Validation Loss: 0.038924042\n",
      "Epoch: 3788 cost = 0.012929973\n",
      "Validation Loss: 0.030881064\n",
      "Epoch: 3789 cost = 0.012929705\n",
      "Validation Loss: 0.027612973\n",
      "Epoch: 3790 cost = 0.012929676\n",
      "Validation Loss: 0.029179443\n",
      "Epoch: 3791 cost = 0.012929340\n",
      "Validation Loss: 0.037891243\n",
      "Epoch: 3792 cost = 0.012928918\n",
      "Validation Loss: 0.030383807\n",
      "Epoch: 3793 cost = 0.012929413\n",
      "Validation Loss: 0.02899613\n",
      "Epoch: 3794 cost = 0.012928545\n",
      "Validation Loss: 0.03085804\n",
      "Epoch: 3795 cost = 0.012928777\n",
      "Validation Loss: 0.03444166\n",
      "Epoch: 3796 cost = 0.012927990\n",
      "Validation Loss: 0.024223125\n",
      "Epoch: 3797 cost = 0.012927842\n",
      "Validation Loss: 0.034800142\n",
      "Epoch: 3798 cost = 0.012927457\n",
      "Validation Loss: 0.02494929\n",
      "Epoch: 3799 cost = 0.012927375\n",
      "Validation Loss: 0.027288174\n",
      "Epoch: 3800 cost = 0.012926627\n",
      "Validation Loss: 0.03971952\n",
      "Epoch: 3801 cost = 0.012926410\n",
      "Validation Loss: 0.03534493\n",
      "Epoch: 3802 cost = 0.012925878\n",
      "Validation Loss: 0.035872687\n",
      "Epoch: 3803 cost = 0.012926146\n",
      "Validation Loss: 0.035994407\n",
      "Epoch: 3804 cost = 0.012925767\n",
      "Validation Loss: 0.02443224\n",
      "Epoch: 3805 cost = 0.012925257\n",
      "Validation Loss: 0.020794403\n",
      "Epoch: 3806 cost = 0.012924722\n",
      "Validation Loss: 0.024312181\n",
      "Epoch: 3807 cost = 0.012924973\n",
      "Validation Loss: 0.022686569\n",
      "Epoch: 3808 cost = 0.012924822\n",
      "Validation Loss: 0.015550278\n",
      "Epoch: 3809 cost = 0.012924082\n",
      "Validation Loss: 0.024909485\n",
      "Epoch: 3810 cost = 0.012923758\n",
      "Validation Loss: 0.023091225\n",
      "Epoch: 3811 cost = 0.012923298\n",
      "Validation Loss: 0.02299736\n",
      "Epoch: 3812 cost = 0.012923245\n",
      "Validation Loss: 0.01918017\n",
      "Epoch: 3813 cost = 0.012922644\n",
      "Validation Loss: 0.021978874\n",
      "Epoch: 3814 cost = 0.012922080\n",
      "Validation Loss: 0.030861767\n",
      "Epoch: 3815 cost = 0.012922403\n",
      "Validation Loss: 0.028464101\n",
      "Epoch: 3816 cost = 0.012922469\n",
      "Validation Loss: 0.024231706\n",
      "Epoch: 3817 cost = 0.012921637\n",
      "Validation Loss: 0.030295657\n",
      "Epoch: 3818 cost = 0.012921431\n",
      "Validation Loss: 0.024981543\n",
      "Epoch: 3819 cost = 0.012921435\n",
      "Validation Loss: 0.027777443\n",
      "Epoch: 3820 cost = 0.012920831\n",
      "Validation Loss: 0.01868151\n",
      "Epoch: 3821 cost = 0.012920344\n",
      "Validation Loss: 0.022491314\n",
      "Epoch: 3822 cost = 0.012919890\n",
      "Validation Loss: 0.022138897\n",
      "Epoch: 3823 cost = 0.012920420\n",
      "Validation Loss: 0.02677546\n",
      "Epoch: 3824 cost = 0.012920486\n",
      "Validation Loss: 0.036395293\n",
      "Epoch: 3825 cost = 0.012919651\n",
      "Validation Loss: 0.033889968\n",
      "Epoch: 3826 cost = 0.012919158\n",
      "Validation Loss: 0.025509238\n",
      "Epoch: 3827 cost = 0.012919377\n",
      "Validation Loss: 0.026087888\n",
      "Epoch: 3828 cost = 0.012918695\n",
      "Validation Loss: 0.026523292\n",
      "Epoch: 3829 cost = 0.012918310\n",
      "Validation Loss: 0.032019738\n",
      "Epoch: 3830 cost = 0.012917678\n",
      "Validation Loss: 0.029858848\n",
      "Epoch: 3831 cost = 0.012917842\n",
      "Validation Loss: 0.015277005\n",
      "Epoch: 3832 cost = 0.012917519\n",
      "Validation Loss: 0.021034548\n",
      "Epoch: 3833 cost = 0.012916759\n",
      "Validation Loss: 0.02675358\n",
      "Epoch: 3834 cost = 0.012916900\n",
      "Validation Loss: 0.020751184\n",
      "Epoch: 3835 cost = 0.012916420\n",
      "Validation Loss: 0.020525197\n",
      "Epoch: 3836 cost = 0.012916058\n",
      "Validation Loss: 0.023781002\n",
      "Epoch: 3837 cost = 0.012916023\n",
      "Validation Loss: 0.021475876\n",
      "Epoch: 3838 cost = 0.012915841\n",
      "Validation Loss: 0.020910548\n",
      "Epoch: 3839 cost = 0.012915354\n",
      "Validation Loss: 0.025696756\n",
      "Epoch: 3840 cost = 0.012915069\n",
      "Validation Loss: 0.027049748\n",
      "Epoch: 3841 cost = 0.012914799\n",
      "Validation Loss: 0.026916547\n",
      "Epoch: 3842 cost = 0.012914578\n",
      "Validation Loss: 0.022188893\n",
      "Epoch: 3843 cost = 0.012914388\n",
      "Validation Loss: 0.03219523\n",
      "Epoch: 3844 cost = 0.012913638\n",
      "Validation Loss: 0.031393714\n",
      "Epoch: 3845 cost = 0.012913588\n",
      "Validation Loss: 0.039550185\n",
      "Epoch: 3846 cost = 0.012913496\n",
      "Validation Loss: 0.03922143\n",
      "Epoch: 3847 cost = 0.012913019\n",
      "Validation Loss: 0.028508103\n",
      "Epoch: 3848 cost = 0.012912580\n",
      "Validation Loss: 0.027721465\n",
      "Epoch: 3849 cost = 0.012912317\n",
      "Validation Loss: 0.034959543\n",
      "Epoch: 3850 cost = 0.012912066\n",
      "Validation Loss: 0.03368262\n",
      "Epoch: 3851 cost = 0.012911434\n",
      "Validation Loss: 0.037200246\n",
      "Epoch: 3852 cost = 0.012911822\n",
      "Validation Loss: 0.034573052\n",
      "Epoch: 3853 cost = 0.012911281\n",
      "Validation Loss: 0.027481113\n",
      "Epoch: 3854 cost = 0.012910957\n",
      "Validation Loss: 0.017769538\n",
      "Epoch: 3855 cost = 0.012910477\n",
      "Validation Loss: 0.027707707\n",
      "Epoch: 3856 cost = 0.012910784\n",
      "Validation Loss: 0.037812013\n",
      "Epoch: 3857 cost = 0.012909850\n",
      "Validation Loss: 0.044728283\n",
      "Epoch: 3858 cost = 0.012909471\n",
      "Validation Loss: 0.044014413\n",
      "Epoch: 3859 cost = 0.012909939\n",
      "Validation Loss: 0.03430661\n",
      "Epoch: 3860 cost = 0.012909146\n",
      "Validation Loss: 0.02974205\n",
      "Epoch: 3861 cost = 0.012908894\n",
      "Validation Loss: 0.026464578\n",
      "Epoch: 3862 cost = 0.012909037\n",
      "Validation Loss: 0.020409467\n",
      "Epoch: 3863 cost = 0.012908233\n",
      "Validation Loss: 0.013932245\n",
      "Epoch: 3864 cost = 0.012908279\n",
      "Validation Loss: 0.020056803\n",
      "Epoch: 3865 cost = 0.012908067\n",
      "Validation Loss: 0.028232811\n",
      "Epoch: 3866 cost = 0.012907720\n",
      "Validation Loss: 0.03601509\n",
      "Epoch: 3867 cost = 0.012906738\n",
      "Validation Loss: 0.03556129\n",
      "Epoch: 3868 cost = 0.012906949\n",
      "Validation Loss: 0.040749025\n",
      "Epoch: 3869 cost = 0.012906432\n",
      "Validation Loss: 0.038070038\n",
      "Epoch: 3870 cost = 0.012906531\n",
      "Validation Loss: 0.036047406\n",
      "Epoch: 3871 cost = 0.012906435\n",
      "Validation Loss: 0.049655873\n",
      "Epoch: 3872 cost = 0.012905652\n",
      "Validation Loss: 0.04604062\n",
      "Epoch: 3873 cost = 0.012905183\n",
      "Validation Loss: 0.03457145\n",
      "Epoch: 3874 cost = 0.012905440\n",
      "Validation Loss: 0.03694155\n",
      "Epoch: 3875 cost = 0.012904576\n",
      "Validation Loss: 0.030789189\n",
      "Epoch: 3876 cost = 0.012904557\n",
      "Validation Loss: 0.01959281\n",
      "Epoch: 3877 cost = 0.012904239\n",
      "Validation Loss: 0.023048693\n",
      "Epoch: 3878 cost = 0.012903590\n",
      "Validation Loss: 0.019919926\n",
      "Epoch: 3879 cost = 0.012903438\n",
      "Validation Loss: 0.028050493\n",
      "Epoch: 3880 cost = 0.012903509\n",
      "Validation Loss: 0.03256182\n",
      "Epoch: 3881 cost = 0.012902967\n",
      "Validation Loss: 0.023655664\n",
      "Epoch: 3882 cost = 0.012902887\n",
      "Validation Loss: 0.01847797\n",
      "Epoch: 3883 cost = 0.012902579\n",
      "Validation Loss: 0.02372139\n",
      "Epoch: 3884 cost = 0.012902184\n",
      "Validation Loss: 0.035703737\n",
      "Epoch: 3885 cost = 0.012901600\n",
      "Validation Loss: 0.03267292\n",
      "Epoch: 3886 cost = 0.012901623\n",
      "Validation Loss: 0.020842291\n",
      "Epoch: 3887 cost = 0.012901429\n",
      "Validation Loss: 0.02761643\n",
      "Epoch: 3888 cost = 0.012900957\n",
      "Validation Loss: 0.02237423\n",
      "Epoch: 3889 cost = 0.012901334\n",
      "Validation Loss: 0.021208111\n",
      "Epoch: 3890 cost = 0.012900401\n",
      "Validation Loss: 0.021139987\n",
      "Epoch: 3891 cost = 0.012900061\n",
      "Validation Loss: 0.034916945\n",
      "Epoch: 3892 cost = 0.012899183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.023015842\n",
      "Epoch: 3893 cost = 0.012899865\n",
      "Validation Loss: 0.022849556\n",
      "Epoch: 3894 cost = 0.012899460\n",
      "Validation Loss: 0.025144855\n",
      "Epoch: 3895 cost = 0.012899067\n",
      "Validation Loss: 0.029493596\n",
      "Epoch: 3896 cost = 0.012898387\n",
      "Validation Loss: 0.031207219\n",
      "Epoch: 3897 cost = 0.012898484\n",
      "Validation Loss: 0.036171798\n",
      "Epoch: 3898 cost = 0.012897964\n",
      "Validation Loss: 0.038019184\n",
      "Epoch: 3899 cost = 0.012897703\n",
      "Validation Loss: 0.03324689\n",
      "Epoch: 3900 cost = 0.012897310\n",
      "Validation Loss: 0.02427269\n",
      "Epoch: 3901 cost = 0.012897240\n",
      "Validation Loss: 0.01888992\n",
      "Epoch: 3902 cost = 0.012897026\n",
      "Validation Loss: 0.018495975\n",
      "Epoch: 3903 cost = 0.012897136\n",
      "Validation Loss: 0.028689526\n",
      "Epoch: 3904 cost = 0.012895785\n",
      "Validation Loss: 0.033446748\n",
      "Epoch: 3905 cost = 0.012895627\n",
      "Validation Loss: 0.027742332\n",
      "Epoch: 3906 cost = 0.012895387\n",
      "Validation Loss: 0.019922059\n",
      "Epoch: 3907 cost = 0.012895280\n",
      "Validation Loss: 0.0238005\n",
      "Epoch: 3908 cost = 0.012895331\n",
      "Validation Loss: 0.024406139\n",
      "Epoch: 3909 cost = 0.012894590\n",
      "Validation Loss: 0.034000877\n",
      "Epoch: 3910 cost = 0.012894636\n",
      "Validation Loss: 0.040192325\n",
      "Epoch: 3911 cost = 0.012894449\n",
      "Validation Loss: 0.04621736\n",
      "Epoch: 3912 cost = 0.012893730\n",
      "Validation Loss: 0.034035515\n",
      "Epoch: 3913 cost = 0.012893364\n",
      "Validation Loss: 0.024294829\n",
      "Epoch: 3914 cost = 0.012893746\n",
      "Validation Loss: 0.016902667\n",
      "Epoch: 3915 cost = 0.012892915\n",
      "Validation Loss: 0.018004775\n",
      "Epoch: 3916 cost = 0.012893045\n",
      "Validation Loss: 0.02156311\n",
      "Epoch: 3917 cost = 0.012892198\n",
      "Validation Loss: 0.024244959\n",
      "Epoch: 3918 cost = 0.012891985\n",
      "Validation Loss: 0.031226328\n",
      "Epoch: 3919 cost = 0.012892112\n",
      "Validation Loss: 0.030574247\n",
      "Epoch: 3920 cost = 0.012892019\n",
      "Validation Loss: 0.024621129\n",
      "Epoch: 3921 cost = 0.012891065\n",
      "Validation Loss: 0.029011657\n",
      "Epoch: 3922 cost = 0.012891117\n",
      "Validation Loss: 0.024505982\n",
      "Epoch: 3923 cost = 0.012890957\n",
      "Validation Loss: 0.025931846\n",
      "Epoch: 3924 cost = 0.012890573\n",
      "Validation Loss: 0.028441766\n",
      "Epoch: 3925 cost = 0.012890039\n",
      "Validation Loss: 0.023782698\n",
      "Epoch: 3926 cost = 0.012890047\n",
      "Validation Loss: 0.025965795\n",
      "Epoch: 3927 cost = 0.012889756\n",
      "Validation Loss: 0.029280983\n",
      "Epoch: 3928 cost = 0.012889300\n",
      "Validation Loss: 0.030113136\n",
      "Epoch: 3929 cost = 0.012889296\n",
      "Validation Loss: 0.03646195\n",
      "Epoch: 3930 cost = 0.012888867\n",
      "Validation Loss: 0.04707268\n",
      "Epoch: 3931 cost = 0.012888129\n",
      "Validation Loss: 0.0382822\n",
      "Epoch: 3932 cost = 0.012888307\n",
      "Validation Loss: 0.036476996\n",
      "Epoch: 3933 cost = 0.012887763\n",
      "Validation Loss: 0.020780042\n",
      "Epoch: 3934 cost = 0.012887182\n",
      "Validation Loss: 0.017373353\n",
      "Epoch: 3935 cost = 0.012887402\n",
      "Validation Loss: 0.02090784\n",
      "Epoch: 3936 cost = 0.012887025\n",
      "Validation Loss: 0.023977201\n",
      "Epoch: 3937 cost = 0.012886190\n",
      "Validation Loss: 0.025964323\n",
      "Epoch: 3938 cost = 0.012886318\n",
      "Validation Loss: 0.02998814\n",
      "Epoch: 3939 cost = 0.012885763\n",
      "Validation Loss: 0.03178785\n",
      "Epoch: 3940 cost = 0.012885243\n",
      "Validation Loss: 0.03468298\n",
      "Epoch: 3941 cost = 0.012885357\n",
      "Validation Loss: 0.03691921\n",
      "Epoch: 3942 cost = 0.012884616\n",
      "Validation Loss: 0.036006115\n",
      "Epoch: 3943 cost = 0.012884699\n",
      "Validation Loss: 0.043597396\n",
      "Epoch: 3944 cost = 0.012885135\n",
      "Validation Loss: 0.030941302\n",
      "Epoch: 3945 cost = 0.012884777\n",
      "Validation Loss: 0.026978621\n",
      "Epoch: 3946 cost = 0.012884359\n",
      "Validation Loss: 0.03307741\n",
      "Epoch: 3947 cost = 0.012883558\n",
      "Validation Loss: 0.030995741\n",
      "Epoch: 3948 cost = 0.012882492\n",
      "Validation Loss: 0.029881021\n",
      "Epoch: 3949 cost = 0.012883513\n",
      "Validation Loss: 0.029888412\n",
      "Epoch: 3950 cost = 0.012882435\n",
      "Validation Loss: 0.027045\n",
      "Epoch: 3951 cost = 0.012882927\n",
      "Validation Loss: 0.031911165\n",
      "Epoch: 3952 cost = 0.012882040\n",
      "Validation Loss: 0.037533004\n",
      "Epoch: 3953 cost = 0.012882102\n",
      "Validation Loss: 0.024800664\n",
      "Epoch: 3954 cost = 0.012882027\n",
      "Validation Loss: 0.02581796\n",
      "Epoch: 3955 cost = 0.012881650\n",
      "Validation Loss: 0.019196117\n",
      "Epoch: 3956 cost = 0.012880545\n",
      "Validation Loss: 0.019722797\n",
      "Epoch: 3957 cost = 0.012881131\n",
      "Validation Loss: 0.02502086\n",
      "Epoch: 3958 cost = 0.012880738\n",
      "Validation Loss: 0.026586635\n",
      "Epoch: 3959 cost = 0.012880276\n",
      "Validation Loss: 0.027107973\n",
      "Epoch: 3960 cost = 0.012880195\n",
      "Validation Loss: 0.041928366\n",
      "Epoch: 3961 cost = 0.012879753\n",
      "Validation Loss: 0.046978205\n",
      "Epoch: 3962 cost = 0.012879338\n",
      "Validation Loss: 0.0380948\n",
      "Epoch: 3963 cost = 0.012879493\n",
      "Validation Loss: 0.028355923\n",
      "Epoch: 3964 cost = 0.012879037\n",
      "Validation Loss: 0.033616807\n",
      "Epoch: 3965 cost = 0.012878138\n",
      "Validation Loss: 0.030816209\n",
      "Epoch: 3966 cost = 0.012878347\n",
      "Validation Loss: 0.032144807\n",
      "Epoch: 3967 cost = 0.012878131\n",
      "Validation Loss: 0.026834358\n",
      "Epoch: 3968 cost = 0.012877174\n",
      "Validation Loss: 0.029703435\n",
      "Epoch: 3969 cost = 0.012877534\n",
      "Validation Loss: 0.0217199\n",
      "Epoch: 3970 cost = 0.012877404\n",
      "Validation Loss: 0.024842542\n",
      "Epoch: 3971 cost = 0.012876525\n",
      "Validation Loss: 0.020438006\n",
      "Epoch: 3972 cost = 0.012876774\n",
      "Validation Loss: 0.021117626\n",
      "Epoch: 3973 cost = 0.012876236\n",
      "Validation Loss: 0.022681082\n",
      "Epoch: 3974 cost = 0.012876193\n",
      "Validation Loss: 0.028877094\n",
      "Epoch: 3975 cost = 0.012875518\n",
      "Validation Loss: 0.039958905\n",
      "Epoch: 3976 cost = 0.012875311\n",
      "Validation Loss: 0.035349183\n",
      "Epoch: 3977 cost = 0.012875354\n",
      "Validation Loss: 0.018829588\n",
      "Epoch: 3978 cost = 0.012874865\n",
      "Validation Loss: 0.01749831\n",
      "Epoch: 3979 cost = 0.012874532\n",
      "Validation Loss: 0.022218976\n",
      "Epoch: 3980 cost = 0.012874195\n",
      "Validation Loss: 0.01937465\n",
      "Epoch: 3981 cost = 0.012874043\n",
      "Validation Loss: 0.018368986\n",
      "Epoch: 3982 cost = 0.012873380\n",
      "Validation Loss: 0.024149558\n",
      "Epoch: 3983 cost = 0.012873041\n",
      "Validation Loss: 0.02122407\n",
      "Epoch: 3984 cost = 0.012873022\n",
      "Validation Loss: 0.023982188\n",
      "Epoch: 3985 cost = 0.012872577\n",
      "Validation Loss: 0.028041184\n",
      "Epoch: 3986 cost = 0.012872294\n",
      "Validation Loss: 0.021831458\n",
      "Epoch: 3987 cost = 0.012872154\n",
      "Validation Loss: 0.021953093\n",
      "Epoch: 3988 cost = 0.012871805\n",
      "Validation Loss: 0.02212942\n",
      "Epoch: 3989 cost = 0.012871292\n",
      "Validation Loss: 0.029307336\n",
      "Epoch: 3990 cost = 0.012870884\n",
      "Validation Loss: 0.022826599\n",
      "Epoch: 3991 cost = 0.012870672\n",
      "Validation Loss: 0.028123572\n",
      "Epoch: 3992 cost = 0.012869991\n",
      "Validation Loss: 0.03214856\n",
      "Epoch: 3993 cost = 0.012869909\n",
      "Validation Loss: 0.028508853\n",
      "Epoch: 3994 cost = 0.012870572\n",
      "Validation Loss: 0.027952379\n",
      "Epoch: 3995 cost = 0.012869865\n",
      "Validation Loss: 0.031196266\n",
      "Epoch: 3996 cost = 0.012869791\n",
      "Validation Loss: 0.04121118\n",
      "Epoch: 3997 cost = 0.012869284\n",
      "Validation Loss: 0.0402021\n",
      "Epoch: 3998 cost = 0.012869014\n",
      "Validation Loss: 0.032399915\n",
      "Epoch: 3999 cost = 0.012869158\n",
      "Validation Loss: 0.042466834\n",
      "Epoch: 4000 cost = 0.012868290\n",
      "Validation Loss: 0.03332913\n",
      "Epoch: 4001 cost = 0.012868462\n",
      "Validation Loss: 0.033697035\n",
      "Epoch: 4002 cost = 0.012867844\n",
      "Validation Loss: 0.036516372\n",
      "Epoch: 4003 cost = 0.012867620\n",
      "Validation Loss: 0.04409525\n",
      "Epoch: 4004 cost = 0.012866962\n",
      "Validation Loss: 0.040079337\n",
      "Epoch: 4005 cost = 0.012866500\n",
      "Validation Loss: 0.033987388\n",
      "Epoch: 4006 cost = 0.012866358\n",
      "Validation Loss: 0.032362264\n",
      "Epoch: 4007 cost = 0.012866394\n",
      "Validation Loss: 0.017663954\n",
      "Epoch: 4008 cost = 0.012865725\n",
      "Validation Loss: 0.020539995\n",
      "Epoch: 4009 cost = 0.012866041\n",
      "Validation Loss: 0.030776773\n",
      "Epoch: 4010 cost = 0.012865232\n",
      "Validation Loss: 0.038353633\n",
      "Epoch: 4011 cost = 0.012865006\n",
      "Validation Loss: 0.043730833\n",
      "Epoch: 4012 cost = 0.012864712\n",
      "Validation Loss: 0.026984297\n",
      "Epoch: 4013 cost = 0.012864276\n",
      "Validation Loss: 0.032932848\n",
      "Epoch: 4014 cost = 0.012864125\n",
      "Validation Loss: 0.030763915\n",
      "Epoch: 4015 cost = 0.012864014\n",
      "Validation Loss: 0.022610582\n",
      "Epoch: 4016 cost = 0.012863823\n",
      "Validation Loss: 0.01775512\n",
      "Epoch: 4017 cost = 0.012863689\n",
      "Validation Loss: 0.019089349\n",
      "Epoch: 4018 cost = 0.012863215\n",
      "Validation Loss: 0.030621294\n",
      "Epoch: 4019 cost = 0.012862826\n",
      "Validation Loss: 0.03486932\n",
      "Epoch: 4020 cost = 0.012861914\n",
      "Validation Loss: 0.023880588\n",
      "Epoch: 4021 cost = 0.012861836\n",
      "Validation Loss: 0.024247257\n",
      "Epoch: 4022 cost = 0.012862278\n",
      "Validation Loss: 0.02314914\n",
      "Epoch: 4023 cost = 0.012861900\n",
      "Validation Loss: 0.019449407\n",
      "Epoch: 4024 cost = 0.012860904\n",
      "Validation Loss: 0.029088685\n",
      "Epoch: 4025 cost = 0.012861221\n",
      "Validation Loss: 0.021262476\n",
      "Epoch: 4026 cost = 0.012860887\n",
      "Validation Loss: 0.016567146\n",
      "Epoch: 4027 cost = 0.012860698\n",
      "Validation Loss: 0.020360548\n",
      "Epoch: 4028 cost = 0.012860295\n",
      "Validation Loss: 0.02803467\n",
      "Epoch: 4029 cost = 0.012859467\n",
      "Validation Loss: 0.0284783\n",
      "Epoch: 4030 cost = 0.012859751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.025722014\n",
      "Epoch: 4031 cost = 0.012859145\n",
      "Validation Loss: 0.02078153\n",
      "Epoch: 4032 cost = 0.012859386\n",
      "Validation Loss: 0.020686137\n",
      "Epoch: 4033 cost = 0.012859105\n",
      "Validation Loss: 0.037166808\n",
      "Epoch: 4034 cost = 0.012858521\n",
      "Validation Loss: 0.036223903\n",
      "Epoch: 4035 cost = 0.012857664\n",
      "Validation Loss: 0.023736566\n",
      "Epoch: 4036 cost = 0.012858060\n",
      "Validation Loss: 0.03210063\n",
      "Epoch: 4037 cost = 0.012857267\n",
      "Validation Loss: 0.025879314\n",
      "Epoch: 4038 cost = 0.012856847\n",
      "Validation Loss: 0.031167554\n",
      "Epoch: 4039 cost = 0.012856992\n",
      "Validation Loss: 0.04747844\n",
      "Epoch: 4040 cost = 0.012857352\n",
      "Validation Loss: 0.04058775\n",
      "Epoch: 4041 cost = 0.012856043\n",
      "Validation Loss: 0.026322883\n",
      "Epoch: 4042 cost = 0.012855725\n",
      "Validation Loss: 0.027573684\n",
      "Epoch: 4043 cost = 0.012855484\n",
      "Validation Loss: 0.032592986\n",
      "Epoch: 4044 cost = 0.012855458\n",
      "Validation Loss: 0.033111602\n",
      "Epoch: 4045 cost = 0.012854695\n",
      "Validation Loss: 0.03723159\n",
      "Epoch: 4046 cost = 0.012855349\n",
      "Validation Loss: 0.023702096\n",
      "Epoch: 4047 cost = 0.012854663\n",
      "Validation Loss: 0.031495515\n",
      "Epoch: 4048 cost = 0.012854606\n",
      "Validation Loss: 0.028282646\n",
      "Epoch: 4049 cost = 0.012853881\n",
      "Validation Loss: 0.019560432\n",
      "Epoch: 4050 cost = 0.012853876\n",
      "Validation Loss: 0.02003936\n",
      "Epoch: 4051 cost = 0.012853254\n",
      "Validation Loss: 0.021565886\n",
      "Epoch: 4052 cost = 0.012853146\n",
      "Validation Loss: 0.025649568\n",
      "Epoch: 4053 cost = 0.012852639\n",
      "Validation Loss: 0.030100958\n",
      "Epoch: 4054 cost = 0.012852758\n",
      "Validation Loss: 0.029216146\n",
      "Epoch: 4055 cost = 0.012852602\n",
      "Validation Loss: 0.022095064\n",
      "Epoch: 4056 cost = 0.012852114\n",
      "Validation Loss: 0.020183317\n",
      "Epoch: 4057 cost = 0.012851485\n",
      "Validation Loss: 0.024938384\n",
      "Epoch: 4058 cost = 0.012851092\n",
      "Validation Loss: 0.03327808\n",
      "Epoch: 4059 cost = 0.012851027\n",
      "Validation Loss: 0.035740133\n",
      "Epoch: 4060 cost = 0.012850581\n",
      "Validation Loss: 0.029868042\n",
      "Epoch: 4061 cost = 0.012850368\n",
      "Validation Loss: 0.036809426\n",
      "Epoch: 4062 cost = 0.012850194\n",
      "Validation Loss: 0.028178414\n",
      "Epoch: 4063 cost = 0.012849346\n",
      "Validation Loss: 0.020154076\n",
      "Epoch: 4064 cost = 0.012849298\n",
      "Validation Loss: 0.027700618\n",
      "Epoch: 4065 cost = 0.012849396\n",
      "Validation Loss: 0.02885366\n",
      "Epoch: 4066 cost = 0.012848871\n",
      "Validation Loss: 0.032277163\n",
      "Epoch: 4067 cost = 0.012848608\n",
      "Validation Loss: 0.038508505\n",
      "Epoch: 4068 cost = 0.012848152\n",
      "Validation Loss: 0.052190486\n",
      "Epoch: 4069 cost = 0.012848226\n",
      "Validation Loss: 0.04930562\n",
      "Epoch: 4070 cost = 0.012847855\n",
      "Validation Loss: 0.027737215\n",
      "Epoch: 4071 cost = 0.012847346\n",
      "Validation Loss: 0.018870814\n",
      "Epoch: 4072 cost = 0.012846909\n",
      "Validation Loss: 0.019254824\n",
      "Epoch: 4073 cost = 0.012846828\n",
      "Validation Loss: 0.04037672\n",
      "Epoch: 4074 cost = 0.012846810\n",
      "Validation Loss: 0.03789448\n",
      "Epoch: 4075 cost = 0.012846784\n",
      "Validation Loss: 0.026224269\n",
      "Epoch: 4076 cost = 0.012845894\n",
      "Validation Loss: 0.027105605\n",
      "Epoch: 4077 cost = 0.012846158\n",
      "Validation Loss: 0.03781412\n",
      "Epoch: 4078 cost = 0.012845205\n",
      "Validation Loss: 0.041413695\n",
      "Epoch: 4079 cost = 0.012845567\n",
      "Validation Loss: 0.03887281\n",
      "Epoch: 4080 cost = 0.012844536\n",
      "Validation Loss: 0.03213167\n",
      "Epoch: 4081 cost = 0.012844767\n",
      "Validation Loss: 0.030218119\n",
      "Epoch: 4082 cost = 0.012844001\n",
      "Validation Loss: 0.031870868\n",
      "Epoch: 4083 cost = 0.012843995\n",
      "Validation Loss: 0.030719673\n",
      "Epoch: 4084 cost = 0.012843264\n",
      "Validation Loss: 0.028313527\n",
      "Epoch: 4085 cost = 0.012843153\n",
      "Validation Loss: 0.033385742\n",
      "Epoch: 4086 cost = 0.012843430\n",
      "Validation Loss: 0.032423515\n",
      "Epoch: 4087 cost = 0.012842691\n",
      "Validation Loss: 0.032231398\n",
      "Epoch: 4088 cost = 0.012842779\n",
      "Validation Loss: 0.02745952\n",
      "Epoch: 4089 cost = 0.012841807\n",
      "Validation Loss: 0.025517622\n",
      "Epoch: 4090 cost = 0.012841479\n",
      "Validation Loss: 0.015678592\n",
      "Epoch: 4091 cost = 0.012841716\n",
      "Validation Loss: 0.02222907\n",
      "Epoch: 4092 cost = 0.012841342\n",
      "Validation Loss: 0.028014617\n",
      "Epoch: 4093 cost = 0.012841308\n",
      "Validation Loss: 0.028687574\n",
      "Epoch: 4094 cost = 0.012840674\n",
      "Validation Loss: 0.027937587\n",
      "Epoch: 4095 cost = 0.012841080\n",
      "Validation Loss: 0.01970366\n",
      "Epoch: 4096 cost = 0.012840065\n",
      "Validation Loss: 0.02282553\n",
      "Epoch: 4097 cost = 0.012839607\n",
      "Validation Loss: 0.021328928\n",
      "Epoch: 4098 cost = 0.012840160\n",
      "Validation Loss: 0.022239394\n",
      "Epoch: 4099 cost = 0.012838667\n",
      "Validation Loss: 0.022184085\n",
      "Epoch: 4100 cost = 0.012838881\n",
      "Validation Loss: 0.027582316\n",
      "Epoch: 4101 cost = 0.012838229\n",
      "Validation Loss: 0.039822407\n",
      "Epoch: 4102 cost = 0.012838376\n",
      "Validation Loss: 0.03134871\n",
      "Epoch: 4103 cost = 0.012838231\n",
      "Validation Loss: 0.01752964\n",
      "Epoch: 4104 cost = 0.012837426\n",
      "Validation Loss: 0.020463\n",
      "Epoch: 4105 cost = 0.012837234\n",
      "Validation Loss: 0.033554018\n",
      "Epoch: 4106 cost = 0.012837077\n",
      "Validation Loss: 0.032102536\n",
      "Epoch: 4107 cost = 0.012837421\n",
      "Validation Loss: 0.029520327\n",
      "Epoch: 4108 cost = 0.012836239\n",
      "Validation Loss: 0.03135999\n",
      "Epoch: 4109 cost = 0.012836173\n",
      "Validation Loss: 0.031621013\n",
      "Epoch: 4110 cost = 0.012835896\n",
      "Validation Loss: 0.030613018\n",
      "Epoch: 4111 cost = 0.012835439\n",
      "Validation Loss: 0.025661629\n",
      "Epoch: 4112 cost = 0.012834850\n",
      "Validation Loss: 0.033552904\n",
      "Epoch: 4113 cost = 0.012834677\n",
      "Validation Loss: 0.022930415\n",
      "Epoch: 4114 cost = 0.012834921\n",
      "Validation Loss: 0.01902403\n",
      "Epoch: 4115 cost = 0.012834215\n",
      "Validation Loss: 0.026748922\n",
      "Epoch: 4116 cost = 0.012834210\n",
      "Validation Loss: 0.024526076\n",
      "Epoch: 4117 cost = 0.012833855\n",
      "Validation Loss: 0.024554992\n",
      "Epoch: 4118 cost = 0.012833978\n",
      "Validation Loss: 0.022836916\n",
      "Epoch: 4119 cost = 0.012833162\n",
      "Validation Loss: 0.02148031\n",
      "Epoch: 4120 cost = 0.012833258\n",
      "Validation Loss: 0.024447525\n",
      "Epoch: 4121 cost = 0.012832647\n",
      "Validation Loss: 0.027920498\n",
      "Epoch: 4122 cost = 0.012832466\n",
      "Validation Loss: 0.02157739\n",
      "Epoch: 4123 cost = 0.012831932\n",
      "Validation Loss: 0.029186202\n",
      "Epoch: 4124 cost = 0.012832142\n",
      "Validation Loss: 0.038077738\n",
      "Epoch: 4125 cost = 0.012831682\n",
      "Validation Loss: 0.030906074\n",
      "Epoch: 4126 cost = 0.012830954\n",
      "Validation Loss: 0.032331035\n",
      "Epoch: 4127 cost = 0.012830985\n",
      "Validation Loss: 0.031403273\n",
      "Epoch: 4128 cost = 0.012830849\n",
      "Validation Loss: 0.020814847\n",
      "Epoch: 4129 cost = 0.012830292\n",
      "Validation Loss: 0.018244978\n",
      "Epoch: 4130 cost = 0.012830354\n",
      "Validation Loss: 0.023552472\n",
      "Epoch: 4131 cost = 0.012829645\n",
      "Validation Loss: 0.027887182\n",
      "Epoch: 4132 cost = 0.012829407\n",
      "Validation Loss: 0.029888425\n",
      "Epoch: 4133 cost = 0.012829163\n",
      "Validation Loss: 0.032067332\n",
      "Epoch: 4134 cost = 0.012828539\n",
      "Validation Loss: 0.0262901\n",
      "Epoch: 4135 cost = 0.012828326\n",
      "Validation Loss: 0.02457361\n",
      "Epoch: 4136 cost = 0.012828035\n",
      "Validation Loss: 0.03732901\n",
      "Epoch: 4137 cost = 0.012828012\n",
      "Validation Loss: 0.032658536\n",
      "Epoch: 4138 cost = 0.012827490\n",
      "Validation Loss: 0.025314692\n",
      "Epoch: 4139 cost = 0.012827128\n",
      "Validation Loss: 0.024460718\n",
      "Epoch: 4140 cost = 0.012826887\n",
      "Validation Loss: 0.02931215\n",
      "Epoch: 4141 cost = 0.012826414\n",
      "Validation Loss: 0.04290338\n",
      "Epoch: 4142 cost = 0.012826810\n",
      "Validation Loss: 0.04519934\n",
      "Epoch: 4143 cost = 0.012826088\n",
      "Validation Loss: 0.04238186\n",
      "Epoch: 4144 cost = 0.012826233\n",
      "Validation Loss: 0.032063134\n",
      "Epoch: 4145 cost = 0.012825594\n",
      "Validation Loss: 0.029827163\n",
      "Epoch: 4146 cost = 0.012825386\n",
      "Validation Loss: 0.024043007\n",
      "Epoch: 4147 cost = 0.012824798\n",
      "Validation Loss: 0.020545889\n",
      "Epoch: 4148 cost = 0.012824466\n",
      "Validation Loss: 0.024322264\n",
      "Epoch: 4149 cost = 0.012824593\n",
      "Validation Loss: 0.026081918\n",
      "Epoch: 4150 cost = 0.012823967\n",
      "Validation Loss: 0.032120492\n",
      "Epoch: 4151 cost = 0.012823880\n",
      "Validation Loss: 0.033093464\n",
      "Epoch: 4152 cost = 0.012824068\n",
      "Validation Loss: 0.03206991\n",
      "Epoch: 4153 cost = 0.012822729\n",
      "Validation Loss: 0.03330059\n",
      "Epoch: 4154 cost = 0.012822942\n",
      "Validation Loss: 0.039091185\n",
      "Epoch: 4155 cost = 0.012823086\n",
      "Validation Loss: 0.03672603\n",
      "Epoch: 4156 cost = 0.012822266\n",
      "Validation Loss: 0.028268978\n",
      "Epoch: 4157 cost = 0.012821937\n",
      "Validation Loss: 0.027183065\n",
      "Epoch: 4158 cost = 0.012821250\n",
      "Validation Loss: 0.03468748\n",
      "Epoch: 4159 cost = 0.012821365\n",
      "Validation Loss: 0.03360281\n",
      "Epoch: 4160 cost = 0.012820961\n",
      "Validation Loss: 0.038893458\n",
      "Epoch: 4161 cost = 0.012820763\n",
      "Validation Loss: 0.047920246\n",
      "Epoch: 4162 cost = 0.012820591\n",
      "Validation Loss: 0.053996745\n",
      "Epoch: 4163 cost = 0.012820435\n",
      "Validation Loss: 0.036805354\n",
      "Epoch: 4164 cost = 0.012819293\n",
      "Validation Loss: 0.022920735\n",
      "Epoch: 4165 cost = 0.012819635\n",
      "Validation Loss: 0.0203722\n",
      "Epoch: 4166 cost = 0.012818942\n",
      "Validation Loss: 0.020896664\n",
      "Epoch: 4167 cost = 0.012819118\n",
      "Validation Loss: 0.033122476\n",
      "Epoch: 4168 cost = 0.012818596\n",
      "Validation Loss: 0.019433782\n",
      "Epoch: 4169 cost = 0.012818959\n",
      "Validation Loss: 0.025197394\n",
      "Epoch: 4170 cost = 0.012818151\n",
      "Validation Loss: 0.032745842\n",
      "Epoch: 4171 cost = 0.012818076\n",
      "Validation Loss: 0.04785856\n",
      "Epoch: 4172 cost = 0.012817167\n",
      "Validation Loss: 0.02874425\n",
      "Epoch: 4173 cost = 0.012817217\n",
      "Validation Loss: 0.027189946\n",
      "Epoch: 4174 cost = 0.012816628\n",
      "Validation Loss: 0.033163335\n",
      "Epoch: 4175 cost = 0.012816776\n",
      "Validation Loss: 0.03636626\n",
      "Epoch: 4176 cost = 0.012816180\n",
      "Validation Loss: 0.024415111\n",
      "Epoch: 4177 cost = 0.012816354\n",
      "Validation Loss: 0.024749003\n",
      "Epoch: 4178 cost = 0.012815527\n",
      "Validation Loss: 0.03124142\n",
      "Epoch: 4179 cost = 0.012815512\n",
      "Validation Loss: 0.038908735\n",
      "Epoch: 4180 cost = 0.012814558\n",
      "Validation Loss: 0.033282768\n",
      "Epoch: 4181 cost = 0.012814629\n",
      "Validation Loss: 0.028357733\n",
      "Epoch: 4182 cost = 0.012814281\n",
      "Validation Loss: 0.03361786\n",
      "Epoch: 4183 cost = 0.012814304\n",
      "Validation Loss: 0.043187045\n",
      "Epoch: 4184 cost = 0.012813833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04287101\n",
      "Epoch: 4185 cost = 0.012813453\n",
      "Validation Loss: 0.030501729\n",
      "Epoch: 4186 cost = 0.012813553\n",
      "Validation Loss: 0.03037648\n",
      "Epoch: 4187 cost = 0.012812950\n",
      "Validation Loss: 0.036820892\n",
      "Epoch: 4188 cost = 0.012812248\n",
      "Validation Loss: 0.034892436\n",
      "Epoch: 4189 cost = 0.012812377\n",
      "Validation Loss: 0.028595438\n",
      "Epoch: 4190 cost = 0.012812195\n",
      "Validation Loss: 0.028159518\n",
      "Epoch: 4191 cost = 0.012811701\n",
      "Validation Loss: 0.026991365\n",
      "Epoch: 4192 cost = 0.012811800\n",
      "Validation Loss: 0.027350672\n",
      "Epoch: 4193 cost = 0.012811460\n",
      "Validation Loss: 0.024467152\n",
      "Epoch: 4194 cost = 0.012810701\n",
      "Validation Loss: 0.022650689\n",
      "Epoch: 4195 cost = 0.012810260\n",
      "Validation Loss: 0.022819925\n",
      "Epoch: 4196 cost = 0.012810091\n",
      "Validation Loss: 0.017713966\n",
      "Epoch: 4197 cost = 0.012809816\n",
      "Validation Loss: 0.016380811\n",
      "Epoch: 4198 cost = 0.012809644\n",
      "Validation Loss: 0.016225912\n",
      "Epoch: 4199 cost = 0.012809165\n",
      "Validation Loss: 0.01959344\n",
      "Epoch: 4200 cost = 0.012808965\n",
      "Validation Loss: 0.026039269\n",
      "Epoch: 4201 cost = 0.012808201\n",
      "Validation Loss: 0.023688812\n",
      "Epoch: 4202 cost = 0.012809013\n",
      "Validation Loss: 0.025383716\n",
      "Epoch: 4203 cost = 0.012807966\n",
      "Validation Loss: 0.03150838\n",
      "Epoch: 4204 cost = 0.012807612\n",
      "Validation Loss: 0.027467843\n",
      "Epoch: 4205 cost = 0.012807221\n",
      "Validation Loss: 0.022060094\n",
      "Epoch: 4206 cost = 0.012806831\n",
      "Validation Loss: 0.026801178\n",
      "Epoch: 4207 cost = 0.012807115\n",
      "Validation Loss: 0.026839802\n",
      "Epoch: 4208 cost = 0.012806398\n",
      "Validation Loss: 0.029018223\n",
      "Epoch: 4209 cost = 0.012806388\n",
      "Validation Loss: 0.031382218\n",
      "Epoch: 4210 cost = 0.012805722\n",
      "Validation Loss: 0.033533305\n",
      "Epoch: 4211 cost = 0.012805502\n",
      "Validation Loss: 0.031959996\n",
      "Epoch: 4212 cost = 0.012805336\n",
      "Validation Loss: 0.03281048\n",
      "Epoch: 4213 cost = 0.012805427\n",
      "Validation Loss: 0.018234007\n",
      "Epoch: 4214 cost = 0.012804805\n",
      "Validation Loss: 0.024445461\n",
      "Epoch: 4215 cost = 0.012805079\n",
      "Validation Loss: 0.035803746\n",
      "Epoch: 4216 cost = 0.012803734\n",
      "Validation Loss: 0.029098526\n",
      "Epoch: 4217 cost = 0.012803485\n",
      "Validation Loss: 0.032924328\n",
      "Epoch: 4218 cost = 0.012803668\n",
      "Validation Loss: 0.039297678\n",
      "Epoch: 4219 cost = 0.012803201\n",
      "Validation Loss: 0.028570656\n",
      "Epoch: 4220 cost = 0.012803875\n",
      "Validation Loss: 0.026588\n",
      "Epoch: 4221 cost = 0.012803014\n",
      "Validation Loss: 0.0350344\n",
      "Epoch: 4222 cost = 0.012802245\n",
      "Validation Loss: 0.029849924\n",
      "Epoch: 4223 cost = 0.012801960\n",
      "Validation Loss: 0.02885226\n",
      "Epoch: 4224 cost = 0.012801344\n",
      "Validation Loss: 0.030956388\n",
      "Epoch: 4225 cost = 0.012801340\n",
      "Validation Loss: 0.018772077\n",
      "Epoch: 4226 cost = 0.012800961\n",
      "Validation Loss: 0.0248986\n",
      "Epoch: 4227 cost = 0.012800576\n",
      "Validation Loss: 0.039565317\n",
      "Epoch: 4228 cost = 0.012800209\n",
      "Validation Loss: 0.04063679\n",
      "Epoch: 4229 cost = 0.012799848\n",
      "Validation Loss: 0.04029295\n",
      "Epoch: 4230 cost = 0.012799647\n",
      "Validation Loss: 0.044215124\n",
      "Epoch: 4231 cost = 0.012799800\n",
      "Validation Loss: 0.024850428\n",
      "Epoch: 4232 cost = 0.012799179\n",
      "Validation Loss: 0.028553113\n",
      "Epoch: 4233 cost = 0.012799241\n",
      "Validation Loss: 0.040622115\n",
      "Epoch: 4234 cost = 0.012799330\n",
      "Validation Loss: 0.025700368\n",
      "Epoch: 4235 cost = 0.012797977\n",
      "Validation Loss: 0.034830634\n",
      "Epoch: 4236 cost = 0.012797734\n",
      "Validation Loss: 0.043961264\n",
      "Epoch: 4237 cost = 0.012798179\n",
      "Validation Loss: 0.040414385\n",
      "Epoch: 4238 cost = 0.012797337\n",
      "Validation Loss: 0.040527903\n",
      "Epoch: 4239 cost = 0.012796873\n",
      "Validation Loss: 0.033250142\n",
      "Epoch: 4240 cost = 0.012797043\n",
      "Validation Loss: 0.025037808\n",
      "Epoch: 4241 cost = 0.012796748\n",
      "Validation Loss: 0.035409525\n",
      "Epoch: 4242 cost = 0.012796325\n",
      "Validation Loss: 0.018419268\n",
      "Epoch: 4243 cost = 0.012795978\n",
      "Validation Loss: 0.023557601\n",
      "Epoch: 4244 cost = 0.012795886\n",
      "Validation Loss: 0.03710717\n",
      "Epoch: 4245 cost = 0.012795314\n",
      "Validation Loss: 0.031336043\n",
      "Epoch: 4246 cost = 0.012795019\n",
      "Validation Loss: 0.04304458\n",
      "Epoch: 4247 cost = 0.012794193\n",
      "Validation Loss: 0.030846152\n",
      "Epoch: 4248 cost = 0.012794410\n",
      "Validation Loss: 0.017377466\n",
      "Epoch: 4249 cost = 0.012793664\n",
      "Validation Loss: 0.024815204\n",
      "Epoch: 4250 cost = 0.012793707\n",
      "Validation Loss: 0.023423094\n",
      "Epoch: 4251 cost = 0.012793211\n",
      "Validation Loss: 0.032879204\n",
      "Epoch: 4252 cost = 0.012792957\n",
      "Validation Loss: 0.031937893\n",
      "Epoch: 4253 cost = 0.012792870\n",
      "Validation Loss: 0.031091982\n",
      "Epoch: 4254 cost = 0.012792623\n",
      "Validation Loss: 0.037711944\n",
      "Epoch: 4255 cost = 0.012792089\n",
      "Validation Loss: 0.042008698\n",
      "Epoch: 4256 cost = 0.012791588\n",
      "Validation Loss: 0.03110753\n",
      "Epoch: 4257 cost = 0.012792096\n",
      "Validation Loss: 0.030801201\n",
      "Epoch: 4258 cost = 0.012791115\n",
      "Validation Loss: 0.033169646\n",
      "Epoch: 4259 cost = 0.012791302\n",
      "Validation Loss: 0.025749143\n",
      "Epoch: 4260 cost = 0.012790537\n",
      "Validation Loss: 0.021072373\n",
      "Epoch: 4261 cost = 0.012790272\n",
      "Validation Loss: 0.022759201\n",
      "Epoch: 4262 cost = 0.012790270\n",
      "Validation Loss: 0.016877864\n",
      "Epoch: 4263 cost = 0.012789580\n",
      "Validation Loss: 0.023187889\n",
      "Epoch: 4264 cost = 0.012789388\n",
      "Validation Loss: 0.026933165\n",
      "Epoch: 4265 cost = 0.012788930\n",
      "Validation Loss: 0.03147629\n",
      "Epoch: 4266 cost = 0.012788464\n",
      "Validation Loss: 0.0404419\n",
      "Epoch: 4267 cost = 0.012788976\n",
      "Validation Loss: 0.040927693\n",
      "Epoch: 4268 cost = 0.012788440\n",
      "Validation Loss: 0.033879288\n",
      "Epoch: 4269 cost = 0.012787770\n",
      "Validation Loss: 0.035688933\n",
      "Epoch: 4270 cost = 0.012787375\n",
      "Validation Loss: 0.025798857\n",
      "Epoch: 4271 cost = 0.012787326\n",
      "Validation Loss: 0.035965305\n",
      "Epoch: 4272 cost = 0.012786704\n",
      "Validation Loss: 0.029406592\n",
      "Epoch: 4273 cost = 0.012786417\n",
      "Validation Loss: 0.03453885\n",
      "Epoch: 4274 cost = 0.012786516\n",
      "Validation Loss: 0.02691149\n",
      "Epoch: 4275 cost = 0.012786016\n",
      "Validation Loss: 0.023683207\n",
      "Epoch: 4276 cost = 0.012785813\n",
      "Validation Loss: 0.02670327\n",
      "Epoch: 4277 cost = 0.012785596\n",
      "Validation Loss: 0.021338493\n",
      "Epoch: 4278 cost = 0.012785220\n",
      "Validation Loss: 0.03251315\n",
      "Epoch: 4279 cost = 0.012784953\n",
      "Validation Loss: 0.039858665\n",
      "Epoch: 4280 cost = 0.012784566\n",
      "Validation Loss: 0.037905205\n",
      "Epoch: 4281 cost = 0.012784055\n",
      "Validation Loss: 0.027740728\n",
      "Epoch: 4282 cost = 0.012783366\n",
      "Validation Loss: 0.030294433\n",
      "Epoch: 4283 cost = 0.012783370\n",
      "Validation Loss: 0.016265953\n",
      "Epoch: 4284 cost = 0.012782633\n",
      "Validation Loss: 0.022933789\n",
      "Epoch: 4285 cost = 0.012783175\n",
      "Validation Loss: 0.027630486\n",
      "Epoch: 4286 cost = 0.012782738\n",
      "Validation Loss: 0.034530282\n",
      "Epoch: 4287 cost = 0.012782103\n",
      "Validation Loss: 0.043748632\n",
      "Epoch: 4288 cost = 0.012782585\n",
      "Validation Loss: 0.02410978\n",
      "Epoch: 4289 cost = 0.012781783\n",
      "Validation Loss: 0.020699987\n",
      "Epoch: 4290 cost = 0.012781316\n",
      "Validation Loss: 0.031801224\n",
      "Epoch: 4291 cost = 0.012780943\n",
      "Validation Loss: 0.029220276\n",
      "Epoch: 4292 cost = 0.012781148\n",
      "Validation Loss: 0.026520211\n",
      "Epoch: 4293 cost = 0.012780355\n",
      "Validation Loss: 0.023682026\n",
      "Epoch: 4294 cost = 0.012780429\n",
      "Validation Loss: 0.0281718\n",
      "Epoch: 4295 cost = 0.012780388\n",
      "Validation Loss: 0.04193578\n",
      "Epoch: 4296 cost = 0.012779228\n",
      "Validation Loss: 0.04074545\n",
      "Epoch: 4297 cost = 0.012778948\n",
      "Validation Loss: 0.03821115\n",
      "Epoch: 4298 cost = 0.012778707\n",
      "Validation Loss: 0.03064437\n",
      "Epoch: 4299 cost = 0.012778703\n",
      "Validation Loss: 0.03865909\n",
      "Epoch: 4300 cost = 0.012778499\n",
      "Validation Loss: 0.027727447\n",
      "Epoch: 4301 cost = 0.012777980\n",
      "Validation Loss: 0.027631436\n",
      "Epoch: 4302 cost = 0.012777514\n",
      "Validation Loss: 0.0279444\n",
      "Epoch: 4303 cost = 0.012777575\n",
      "Validation Loss: 0.028204473\n",
      "Epoch: 4304 cost = 0.012776703\n",
      "Validation Loss: 0.035733145\n",
      "Epoch: 4305 cost = 0.012776645\n",
      "Validation Loss: 0.02663349\n",
      "Epoch: 4306 cost = 0.012776133\n",
      "Validation Loss: 0.026489582\n",
      "Epoch: 4307 cost = 0.012775508\n",
      "Validation Loss: 0.034326352\n",
      "Epoch: 4308 cost = 0.012775742\n",
      "Validation Loss: 0.033693325\n",
      "Epoch: 4309 cost = 0.012776019\n",
      "Validation Loss: 0.020185811\n",
      "Epoch: 4310 cost = 0.012775561\n",
      "Validation Loss: 0.02398477\n",
      "Epoch: 4311 cost = 0.012774276\n",
      "Validation Loss: 0.032198075\n",
      "Epoch: 4312 cost = 0.012774617\n",
      "Validation Loss: 0.03251635\n",
      "Epoch: 4313 cost = 0.012774373\n",
      "Validation Loss: 0.018719902\n",
      "Epoch: 4314 cost = 0.012773709\n",
      "Validation Loss: 0.017778846\n",
      "Epoch: 4315 cost = 0.012773773\n",
      "Validation Loss: 0.02350025\n",
      "Epoch: 4316 cost = 0.012773164\n",
      "Validation Loss: 0.024919568\n",
      "Epoch: 4317 cost = 0.012773145\n",
      "Validation Loss: 0.02462785\n",
      "Epoch: 4318 cost = 0.012772389\n",
      "Validation Loss: 0.036141533\n",
      "Epoch: 4319 cost = 0.012772563\n",
      "Validation Loss: 0.03354398\n",
      "Epoch: 4320 cost = 0.012772294\n",
      "Validation Loss: 0.028159766\n",
      "Epoch: 4321 cost = 0.012771892\n",
      "Validation Loss: 0.033625256\n",
      "Epoch: 4322 cost = 0.012771236\n",
      "Validation Loss: 0.03410421\n",
      "Epoch: 4323 cost = 0.012771389\n",
      "Validation Loss: 0.030077\n",
      "Epoch: 4324 cost = 0.012770797\n",
      "Validation Loss: 0.025157122\n",
      "Epoch: 4325 cost = 0.012770283\n",
      "Validation Loss: 0.019788122\n",
      "Epoch: 4326 cost = 0.012770185\n",
      "Validation Loss: 0.019221\n",
      "Epoch: 4327 cost = 0.012769999\n",
      "Validation Loss: 0.020988017\n",
      "Epoch: 4328 cost = 0.012768976\n",
      "Validation Loss: 0.021000864\n",
      "Epoch: 4329 cost = 0.012769247\n",
      "Validation Loss: 0.025236502\n",
      "Epoch: 4330 cost = 0.012768561\n",
      "Validation Loss: 0.028828394\n",
      "Epoch: 4331 cost = 0.012768394\n",
      "Validation Loss: 0.03093675\n",
      "Epoch: 4332 cost = 0.012768064\n",
      "Validation Loss: 0.030560035\n",
      "Epoch: 4333 cost = 0.012767709\n",
      "Validation Loss: 0.037029266\n",
      "Epoch: 4334 cost = 0.012767737\n",
      "Validation Loss: 0.031229226\n",
      "Epoch: 4335 cost = 0.012767455\n",
      "Validation Loss: 0.031725727\n",
      "Epoch: 4336 cost = 0.012766751\n",
      "Validation Loss: 0.03742978\n",
      "Epoch: 4337 cost = 0.012766254\n",
      "Validation Loss: 0.0322458\n",
      "Epoch: 4338 cost = 0.012766102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.025562499\n",
      "Epoch: 4339 cost = 0.012765934\n",
      "Validation Loss: 0.022352984\n",
      "Epoch: 4340 cost = 0.012765854\n",
      "Validation Loss: 0.016394503\n",
      "Epoch: 4341 cost = 0.012765426\n",
      "Validation Loss: 0.023712933\n",
      "Epoch: 4342 cost = 0.012764846\n",
      "Validation Loss: 0.025857318\n",
      "Epoch: 4343 cost = 0.012764199\n",
      "Validation Loss: 0.030206356\n",
      "Epoch: 4344 cost = 0.012764614\n",
      "Validation Loss: 0.034535903\n",
      "Epoch: 4345 cost = 0.012764227\n",
      "Validation Loss: 0.026760295\n",
      "Epoch: 4346 cost = 0.012763290\n",
      "Validation Loss: 0.023544239\n",
      "Epoch: 4347 cost = 0.012763431\n",
      "Validation Loss: 0.030191185\n",
      "Epoch: 4348 cost = 0.012763697\n",
      "Validation Loss: 0.024567604\n",
      "Epoch: 4349 cost = 0.012762222\n",
      "Validation Loss: 0.02042953\n",
      "Epoch: 4350 cost = 0.012762207\n",
      "Validation Loss: 0.023639392\n",
      "Epoch: 4351 cost = 0.012762053\n",
      "Validation Loss: 0.01873486\n",
      "Epoch: 4352 cost = 0.012762027\n",
      "Validation Loss: 0.023469353\n",
      "Epoch: 4353 cost = 0.012761488\n",
      "Validation Loss: 0.027068613\n",
      "Epoch: 4354 cost = 0.012760586\n",
      "Validation Loss: 0.020280754\n",
      "Epoch: 4355 cost = 0.012760816\n",
      "Validation Loss: 0.018681178\n",
      "Epoch: 4356 cost = 0.012760521\n",
      "Validation Loss: 0.015535794\n",
      "Epoch: 4357 cost = 0.012760150\n",
      "Validation Loss: 0.016933661\n",
      "Epoch: 4358 cost = 0.012759623\n",
      "Validation Loss: 0.017157214\n",
      "Epoch: 4359 cost = 0.012759806\n",
      "Validation Loss: 0.023631498\n",
      "Epoch: 4360 cost = 0.012759212\n",
      "Validation Loss: 0.02400495\n",
      "Epoch: 4361 cost = 0.012758463\n",
      "Validation Loss: 0.03016004\n",
      "Epoch: 4362 cost = 0.012758354\n",
      "Validation Loss: 0.03995355\n",
      "Epoch: 4363 cost = 0.012758376\n",
      "Validation Loss: 0.03877758\n",
      "Epoch: 4364 cost = 0.012757958\n",
      "Validation Loss: 0.023024809\n",
      "Epoch: 4365 cost = 0.012757932\n",
      "Validation Loss: 0.032451946\n",
      "Epoch: 4366 cost = 0.012757288\n",
      "Validation Loss: 0.029502092\n",
      "Epoch: 4367 cost = 0.012757154\n",
      "Validation Loss: 0.020452384\n",
      "Epoch: 4368 cost = 0.012756744\n",
      "Validation Loss: 0.019996287\n",
      "Epoch: 4369 cost = 0.012756716\n",
      "Validation Loss: 0.031225305\n",
      "Epoch: 4370 cost = 0.012755782\n",
      "Validation Loss: 0.03191841\n",
      "Epoch: 4371 cost = 0.012755226\n",
      "Validation Loss: 0.03932155\n",
      "Epoch: 4372 cost = 0.012754979\n",
      "Validation Loss: 0.029906608\n",
      "Epoch: 4373 cost = 0.012755507\n",
      "Validation Loss: 0.021189444\n",
      "Epoch: 4374 cost = 0.012754658\n",
      "Validation Loss: 0.022647906\n",
      "Epoch: 4375 cost = 0.012754302\n",
      "Validation Loss: 0.025524367\n",
      "Epoch: 4376 cost = 0.012753751\n",
      "Validation Loss: 0.029149642\n",
      "Epoch: 4377 cost = 0.012753348\n",
      "Validation Loss: 0.038097307\n",
      "Epoch: 4378 cost = 0.012753407\n",
      "Validation Loss: 0.025207244\n",
      "Epoch: 4379 cost = 0.012753052\n",
      "Validation Loss: 0.025657687\n",
      "Epoch: 4380 cost = 0.012752448\n",
      "Validation Loss: 0.040402032\n",
      "Epoch: 4381 cost = 0.012752493\n",
      "Validation Loss: 0.030811856\n",
      "Epoch: 4382 cost = 0.012751733\n",
      "Validation Loss: 0.031332865\n",
      "Epoch: 4383 cost = 0.012752199\n",
      "Validation Loss: 0.024293363\n",
      "Epoch: 4384 cost = 0.012751443\n",
      "Validation Loss: 0.022764862\n",
      "Epoch: 4385 cost = 0.012751026\n",
      "Validation Loss: 0.024791872\n",
      "Epoch: 4386 cost = 0.012751029\n",
      "Validation Loss: 0.032409806\n",
      "Epoch: 4387 cost = 0.012750372\n",
      "Validation Loss: 0.028442074\n",
      "Epoch: 4388 cost = 0.012750192\n",
      "Validation Loss: 0.0258162\n",
      "Epoch: 4389 cost = 0.012749941\n",
      "Validation Loss: 0.025685493\n",
      "Epoch: 4390 cost = 0.012749468\n",
      "Validation Loss: 0.03312321\n",
      "Epoch: 4391 cost = 0.012749193\n",
      "Validation Loss: 0.034535326\n",
      "Epoch: 4392 cost = 0.012748843\n",
      "Validation Loss: 0.042566683\n",
      "Epoch: 4393 cost = 0.012748486\n",
      "Validation Loss: 0.04250741\n",
      "Epoch: 4394 cost = 0.012748435\n",
      "Validation Loss: 0.0440106\n",
      "Epoch: 4395 cost = 0.012748092\n",
      "Validation Loss: 0.03729063\n",
      "Epoch: 4396 cost = 0.012747811\n",
      "Validation Loss: 0.01905878\n",
      "Epoch: 4397 cost = 0.012747373\n",
      "Validation Loss: 0.027545124\n",
      "Epoch: 4398 cost = 0.012747086\n",
      "Validation Loss: 0.03216941\n",
      "Epoch: 4399 cost = 0.012746588\n",
      "Validation Loss: 0.029572057\n",
      "Epoch: 4400 cost = 0.012746847\n",
      "Validation Loss: 0.036153786\n",
      "Epoch: 4401 cost = 0.012746205\n",
      "Validation Loss: 0.027065793\n",
      "Epoch: 4402 cost = 0.012745802\n",
      "Validation Loss: 0.025385382\n",
      "Epoch: 4403 cost = 0.012745406\n",
      "Validation Loss: 0.02359092\n",
      "Epoch: 4404 cost = 0.012744967\n",
      "Validation Loss: 0.018600373\n",
      "Epoch: 4405 cost = 0.012744334\n",
      "Validation Loss: 0.02002301\n",
      "Epoch: 4406 cost = 0.012744271\n",
      "Validation Loss: 0.02702619\n",
      "Epoch: 4407 cost = 0.012744272\n",
      "Validation Loss: 0.027668301\n",
      "Epoch: 4408 cost = 0.012743581\n",
      "Validation Loss: 0.03843943\n",
      "Epoch: 4409 cost = 0.012743548\n",
      "Validation Loss: 0.031244399\n",
      "Epoch: 4410 cost = 0.012743509\n",
      "Validation Loss: 0.024314528\n",
      "Epoch: 4411 cost = 0.012742591\n",
      "Validation Loss: 0.02566532\n",
      "Epoch: 4412 cost = 0.012742436\n",
      "Validation Loss: 0.022197958\n",
      "Epoch: 4413 cost = 0.012742281\n",
      "Validation Loss: 0.025524\n",
      "Epoch: 4414 cost = 0.012741834\n",
      "Validation Loss: 0.033684693\n",
      "Epoch: 4415 cost = 0.012741715\n",
      "Validation Loss: 0.033695977\n",
      "Epoch: 4416 cost = 0.012740986\n",
      "Validation Loss: 0.02776269\n",
      "Epoch: 4417 cost = 0.012741786\n",
      "Validation Loss: 0.028124234\n",
      "Epoch: 4418 cost = 0.012741158\n",
      "Validation Loss: 0.035074435\n",
      "Epoch: 4419 cost = 0.012740363\n",
      "Validation Loss: 0.03557342\n",
      "Epoch: 4420 cost = 0.012739902\n",
      "Validation Loss: 0.032721993\n",
      "Epoch: 4421 cost = 0.012739743\n",
      "Validation Loss: 0.02634576\n",
      "Epoch: 4422 cost = 0.012739381\n",
      "Validation Loss: 0.021148939\n",
      "Epoch: 4423 cost = 0.012738395\n",
      "Validation Loss: 0.021022102\n",
      "Epoch: 4424 cost = 0.012738580\n",
      "Validation Loss: 0.037308693\n",
      "Epoch: 4425 cost = 0.012738492\n",
      "Validation Loss: 0.03683175\n",
      "Epoch: 4426 cost = 0.012738195\n",
      "Validation Loss: 0.033885755\n",
      "Epoch: 4427 cost = 0.012737434\n",
      "Validation Loss: 0.04415858\n",
      "Epoch: 4428 cost = 0.012737267\n",
      "Validation Loss: 0.034253284\n",
      "Epoch: 4429 cost = 0.012736833\n",
      "Validation Loss: 0.023782922\n",
      "Epoch: 4430 cost = 0.012736307\n",
      "Validation Loss: 0.02408592\n",
      "Epoch: 4431 cost = 0.012735995\n",
      "Validation Loss: 0.018178053\n",
      "Epoch: 4432 cost = 0.012735797\n",
      "Validation Loss: 0.015092499\n",
      "Epoch: 4433 cost = 0.012735871\n",
      "Validation Loss: 0.019262208\n",
      "Epoch: 4434 cost = 0.012734953\n",
      "Validation Loss: 0.030542275\n",
      "Epoch: 4435 cost = 0.012735271\n",
      "Validation Loss: 0.042973142\n",
      "Epoch: 4436 cost = 0.012734396\n",
      "Validation Loss: 0.039432023\n",
      "Epoch: 4437 cost = 0.012734321\n",
      "Validation Loss: 0.028927404\n",
      "Epoch: 4438 cost = 0.012733832\n",
      "Validation Loss: 0.02443394\n",
      "Epoch: 4439 cost = 0.012733543\n",
      "Validation Loss: 0.027284259\n",
      "Epoch: 4440 cost = 0.012732889\n",
      "Validation Loss: 0.023271015\n",
      "Epoch: 4441 cost = 0.012733277\n",
      "Validation Loss: 0.026632061\n",
      "Epoch: 4442 cost = 0.012732328\n",
      "Validation Loss: 0.035031132\n",
      "Epoch: 4443 cost = 0.012732148\n",
      "Validation Loss: 0.026272532\n",
      "Epoch: 4444 cost = 0.012731610\n",
      "Validation Loss: 0.019572549\n",
      "Epoch: 4445 cost = 0.012731574\n",
      "Validation Loss: 0.017071249\n",
      "Epoch: 4446 cost = 0.012730926\n",
      "Validation Loss: 0.014753006\n",
      "Epoch: 4447 cost = 0.012730831\n",
      "Validation Loss: 0.018449616\n",
      "Epoch: 4448 cost = 0.012730241\n",
      "Validation Loss: 0.019443648\n",
      "Epoch: 4449 cost = 0.012729893\n",
      "Validation Loss: 0.026209632\n",
      "Epoch: 4450 cost = 0.012729922\n",
      "Validation Loss: 0.029302727\n",
      "Epoch: 4451 cost = 0.012729770\n",
      "Validation Loss: 0.02626955\n",
      "Epoch: 4452 cost = 0.012729309\n",
      "Validation Loss: 0.027187243\n",
      "Epoch: 4453 cost = 0.012728682\n",
      "Validation Loss: 0.024859577\n",
      "Epoch: 4454 cost = 0.012728337\n",
      "Validation Loss: 0.019894373\n",
      "Epoch: 4455 cost = 0.012728202\n",
      "Validation Loss: 0.020598797\n",
      "Epoch: 4456 cost = 0.012727907\n",
      "Validation Loss: 0.024861278\n",
      "Epoch: 4457 cost = 0.012727314\n",
      "Validation Loss: 0.021295317\n",
      "Epoch: 4458 cost = 0.012727290\n",
      "Validation Loss: 0.019222196\n",
      "Epoch: 4459 cost = 0.012727116\n",
      "Validation Loss: 0.016291924\n",
      "Epoch: 4460 cost = 0.012726524\n",
      "Validation Loss: 0.026225364\n",
      "Epoch: 4461 cost = 0.012725991\n",
      "Validation Loss: 0.029693693\n",
      "Epoch: 4462 cost = 0.012725887\n",
      "Validation Loss: 0.031568594\n",
      "Epoch: 4463 cost = 0.012725581\n",
      "Validation Loss: 0.021497326\n",
      "Epoch: 4464 cost = 0.012725075\n",
      "Validation Loss: 0.027526218\n",
      "Epoch: 4465 cost = 0.012724783\n",
      "Validation Loss: 0.02729546\n",
      "Epoch: 4466 cost = 0.012724651\n",
      "Validation Loss: 0.03556251\n",
      "Epoch: 4467 cost = 0.012724255\n",
      "Validation Loss: 0.026384857\n",
      "Epoch: 4468 cost = 0.012724033\n",
      "Validation Loss: 0.0209642\n",
      "Epoch: 4469 cost = 0.012723245\n",
      "Validation Loss: 0.021291858\n",
      "Epoch: 4470 cost = 0.012723191\n",
      "Validation Loss: 0.033866957\n",
      "Epoch: 4471 cost = 0.012722609\n",
      "Validation Loss: 0.045972183\n",
      "Epoch: 4472 cost = 0.012722122\n",
      "Validation Loss: 0.033478055\n",
      "Epoch: 4473 cost = 0.012722172\n",
      "Validation Loss: 0.02959305\n",
      "Epoch: 4474 cost = 0.012721948\n",
      "Validation Loss: 0.028612994\n",
      "Epoch: 4475 cost = 0.012721670\n",
      "Validation Loss: 0.022352176\n",
      "Epoch: 4476 cost = 0.012721243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.015836367\n",
      "Epoch: 4477 cost = 0.012720719\n",
      "Validation Loss: 0.02491212\n",
      "Epoch: 4478 cost = 0.012720729\n",
      "Validation Loss: 0.029922502\n",
      "Epoch: 4479 cost = 0.012720162\n",
      "Validation Loss: 0.031019831\n",
      "Epoch: 4480 cost = 0.012719658\n",
      "Validation Loss: 0.026403919\n",
      "Epoch: 4481 cost = 0.012719422\n",
      "Validation Loss: 0.021727327\n",
      "Epoch: 4482 cost = 0.012719132\n",
      "Validation Loss: 0.017109016\n",
      "Epoch: 4483 cost = 0.012718555\n",
      "Validation Loss: 0.020447597\n",
      "Epoch: 4484 cost = 0.012718153\n",
      "Validation Loss: 0.015410351\n",
      "Epoch: 4485 cost = 0.012718419\n",
      "Validation Loss: 0.018354286\n",
      "Epoch: 4486 cost = 0.012717820\n",
      "Validation Loss: 0.01924567\n",
      "Epoch: 4487 cost = 0.012717121\n",
      "Validation Loss: 0.026098976\n",
      "Epoch: 4488 cost = 0.012716578\n",
      "Validation Loss: 0.026611902\n",
      "Epoch: 4489 cost = 0.012716882\n",
      "Validation Loss: 0.02946282\n",
      "Epoch: 4490 cost = 0.012716047\n",
      "Validation Loss: 0.020211283\n",
      "Epoch: 4491 cost = 0.012716098\n",
      "Validation Loss: 0.021142986\n",
      "Epoch: 4492 cost = 0.012716136\n",
      "Validation Loss: 0.031274404\n",
      "Epoch: 4493 cost = 0.012715251\n",
      "Validation Loss: 0.027006695\n",
      "Epoch: 4494 cost = 0.012715436\n",
      "Validation Loss: 0.02042432\n",
      "Epoch: 4495 cost = 0.012714811\n",
      "Validation Loss: 0.022437645\n",
      "Epoch: 4496 cost = 0.012714341\n",
      "Validation Loss: 0.01639467\n",
      "Epoch: 4497 cost = 0.012713915\n",
      "Validation Loss: 0.031196844\n",
      "Epoch: 4498 cost = 0.012713986\n",
      "Validation Loss: 0.03487988\n",
      "Epoch: 4499 cost = 0.012713230\n",
      "Validation Loss: 0.026447337\n",
      "Epoch: 4500 cost = 0.012713139\n",
      "Validation Loss: 0.027995875\n",
      "Epoch: 4501 cost = 0.012712251\n",
      "Validation Loss: 0.034589253\n",
      "Epoch: 4502 cost = 0.012712344\n",
      "Validation Loss: 0.035271\n",
      "Epoch: 4503 cost = 0.012712308\n",
      "Validation Loss: 0.038179744\n",
      "Epoch: 4504 cost = 0.012711834\n",
      "Validation Loss: 0.033682853\n",
      "Epoch: 4505 cost = 0.012711126\n",
      "Validation Loss: 0.030515753\n",
      "Epoch: 4506 cost = 0.012710727\n",
      "Validation Loss: 0.032191172\n",
      "Epoch: 4507 cost = 0.012710349\n",
      "Validation Loss: 0.03874261\n",
      "Epoch: 4508 cost = 0.012710877\n",
      "Validation Loss: 0.038152397\n",
      "Epoch: 4509 cost = 0.012710120\n",
      "Validation Loss: 0.036397286\n",
      "Epoch: 4510 cost = 0.012709636\n",
      "Validation Loss: 0.032860473\n",
      "Epoch: 4511 cost = 0.012709206\n",
      "Validation Loss: 0.020784399\n",
      "Epoch: 4512 cost = 0.012708807\n",
      "Validation Loss: 0.022087013\n",
      "Epoch: 4513 cost = 0.012708370\n",
      "Validation Loss: 0.0273489\n",
      "Epoch: 4514 cost = 0.012708684\n",
      "Validation Loss: 0.032679718\n",
      "Epoch: 4515 cost = 0.012708118\n",
      "Validation Loss: 0.05356162\n",
      "Epoch: 4516 cost = 0.012707829\n",
      "Validation Loss: 0.054246906\n",
      "Epoch: 4517 cost = 0.012707011\n",
      "Validation Loss: 0.04068091\n",
      "Epoch: 4518 cost = 0.012707081\n",
      "Validation Loss: 0.038389083\n",
      "Epoch: 4519 cost = 0.012706530\n",
      "Validation Loss: 0.034652382\n",
      "Epoch: 4520 cost = 0.012706206\n",
      "Validation Loss: 0.03271375\n",
      "Epoch: 4521 cost = 0.012705672\n",
      "Validation Loss: 0.032075536\n",
      "Epoch: 4522 cost = 0.012705420\n",
      "Validation Loss: 0.02697997\n",
      "Epoch: 4523 cost = 0.012704932\n",
      "Validation Loss: 0.020233558\n",
      "Epoch: 4524 cost = 0.012705040\n",
      "Validation Loss: 0.019763716\n",
      "Epoch: 4525 cost = 0.012704364\n",
      "Validation Loss: 0.017910268\n",
      "Epoch: 4526 cost = 0.012704045\n",
      "Validation Loss: 0.01355754\n",
      "Epoch: 4527 cost = 0.012703738\n",
      "Validation Loss: 0.022691851\n",
      "Epoch: 4528 cost = 0.012703650\n",
      "Validation Loss: 0.02099344\n",
      "Epoch: 4529 cost = 0.012703319\n",
      "Validation Loss: 0.024444288\n",
      "Epoch: 4530 cost = 0.012702395\n",
      "Validation Loss: 0.022740517\n",
      "Epoch: 4531 cost = 0.012702272\n",
      "Validation Loss: 0.022650693\n",
      "Epoch: 4532 cost = 0.012702209\n",
      "Validation Loss: 0.019130187\n",
      "Epoch: 4533 cost = 0.012701420\n",
      "Validation Loss: 0.0151601285\n",
      "Epoch: 4534 cost = 0.012701523\n",
      "Validation Loss: 0.017777503\n",
      "Epoch: 4535 cost = 0.012700909\n",
      "Validation Loss: 0.024935497\n",
      "Epoch: 4536 cost = 0.012700820\n",
      "Validation Loss: 0.02572166\n",
      "Epoch: 4537 cost = 0.012700485\n",
      "Validation Loss: 0.02503054\n",
      "Epoch: 4538 cost = 0.012699707\n",
      "Validation Loss: 0.026122887\n",
      "Epoch: 4539 cost = 0.012699724\n",
      "Validation Loss: 0.025886912\n",
      "Epoch: 4540 cost = 0.012699345\n",
      "Validation Loss: 0.026559165\n",
      "Epoch: 4541 cost = 0.012698916\n",
      "Validation Loss: 0.02967516\n",
      "Epoch: 4542 cost = 0.012698764\n",
      "Validation Loss: 0.030506581\n",
      "Epoch: 4543 cost = 0.012698183\n",
      "Validation Loss: 0.034326933\n",
      "Epoch: 4544 cost = 0.012697978\n",
      "Validation Loss: 0.028453635\n",
      "Epoch: 4545 cost = 0.012698002\n",
      "Validation Loss: 0.021472659\n",
      "Epoch: 4546 cost = 0.012697235\n",
      "Validation Loss: 0.026291225\n",
      "Epoch: 4547 cost = 0.012697413\n",
      "Validation Loss: 0.027393842\n",
      "Epoch: 4548 cost = 0.012696585\n",
      "Validation Loss: 0.023085589\n",
      "Epoch: 4549 cost = 0.012696385\n",
      "Validation Loss: 0.027729934\n",
      "Epoch: 4550 cost = 0.012695889\n",
      "Validation Loss: 0.023584351\n",
      "Epoch: 4551 cost = 0.012695824\n",
      "Validation Loss: 0.029936282\n",
      "Epoch: 4552 cost = 0.012695468\n",
      "Validation Loss: 0.03038869\n",
      "Epoch: 4553 cost = 0.012694413\n",
      "Validation Loss: 0.028744819\n",
      "Epoch: 4554 cost = 0.012694537\n",
      "Validation Loss: 0.0247255\n",
      "Epoch: 4555 cost = 0.012694479\n",
      "Validation Loss: 0.030320805\n",
      "Epoch: 4556 cost = 0.012693523\n",
      "Validation Loss: 0.03117849\n",
      "Epoch: 4557 cost = 0.012693686\n",
      "Validation Loss: 0.03288219\n",
      "Epoch: 4558 cost = 0.012693293\n",
      "Validation Loss: 0.034745444\n",
      "Epoch: 4559 cost = 0.012692857\n",
      "Validation Loss: 0.041732557\n",
      "Epoch: 4560 cost = 0.012692304\n",
      "Validation Loss: 0.0430102\n",
      "Epoch: 4561 cost = 0.012692044\n",
      "Validation Loss: 0.035460055\n",
      "Epoch: 4562 cost = 0.012691974\n",
      "Validation Loss: 0.03328291\n",
      "Epoch: 4563 cost = 0.012691384\n",
      "Validation Loss: 0.0377383\n",
      "Epoch: 4564 cost = 0.012691041\n",
      "Validation Loss: 0.038945284\n",
      "Epoch: 4565 cost = 0.012690796\n",
      "Validation Loss: 0.024999086\n",
      "Epoch: 4566 cost = 0.012690422\n",
      "Validation Loss: 0.01920936\n",
      "Epoch: 4567 cost = 0.012690298\n",
      "Validation Loss: 0.018516833\n",
      "Epoch: 4568 cost = 0.012690083\n",
      "Validation Loss: 0.015256643\n",
      "Epoch: 4569 cost = 0.012688959\n",
      "Validation Loss: 0.030600293\n",
      "Epoch: 4570 cost = 0.012689540\n",
      "Validation Loss: 0.028063923\n",
      "Epoch: 4571 cost = 0.012688667\n",
      "Validation Loss: 0.031326886\n",
      "Epoch: 4572 cost = 0.012688481\n",
      "Validation Loss: 0.036136243\n",
      "Epoch: 4573 cost = 0.012687862\n",
      "Validation Loss: 0.03350308\n",
      "Epoch: 4574 cost = 0.012687714\n",
      "Validation Loss: 0.034604922\n",
      "Epoch: 4575 cost = 0.012687331\n",
      "Validation Loss: 0.032759357\n",
      "Epoch: 4576 cost = 0.012687042\n",
      "Validation Loss: 0.033920106\n",
      "Epoch: 4577 cost = 0.012686636\n",
      "Validation Loss: 0.03894337\n",
      "Epoch: 4578 cost = 0.012686896\n",
      "Validation Loss: 0.05093031\n",
      "Epoch: 4579 cost = 0.012685588\n",
      "Validation Loss: 0.044789005\n",
      "Epoch: 4580 cost = 0.012685414\n",
      "Validation Loss: 0.027460102\n",
      "Epoch: 4581 cost = 0.012685528\n",
      "Validation Loss: 0.021168318\n",
      "Epoch: 4582 cost = 0.012684822\n",
      "Validation Loss: 0.025771324\n",
      "Epoch: 4583 cost = 0.012684867\n",
      "Validation Loss: 0.021881506\n",
      "Epoch: 4584 cost = 0.012684252\n",
      "Validation Loss: 0.023612175\n",
      "Epoch: 4585 cost = 0.012684130\n",
      "Validation Loss: 0.03171705\n",
      "Epoch: 4586 cost = 0.012683649\n",
      "Validation Loss: 0.042419758\n",
      "Epoch: 4587 cost = 0.012683407\n",
      "Validation Loss: 0.033595238\n",
      "Epoch: 4588 cost = 0.012682851\n",
      "Validation Loss: 0.032958817\n",
      "Epoch: 4589 cost = 0.012682689\n",
      "Validation Loss: 0.0417947\n",
      "Epoch: 4590 cost = 0.012682299\n",
      "Validation Loss: 0.037841532\n",
      "Epoch: 4591 cost = 0.012681891\n",
      "Validation Loss: 0.035671357\n",
      "Epoch: 4592 cost = 0.012681506\n",
      "Validation Loss: 0.03466675\n",
      "Epoch: 4593 cost = 0.012681500\n",
      "Validation Loss: 0.023619084\n",
      "Epoch: 4594 cost = 0.012680967\n",
      "Validation Loss: 0.021850906\n",
      "Epoch: 4595 cost = 0.012680146\n",
      "Validation Loss: 0.024118783\n",
      "Epoch: 4596 cost = 0.012679891\n",
      "Validation Loss: 0.025964977\n",
      "Epoch: 4597 cost = 0.012679662\n",
      "Validation Loss: 0.025702553\n",
      "Epoch: 4598 cost = 0.012679158\n",
      "Validation Loss: 0.029645685\n",
      "Epoch: 4599 cost = 0.012678905\n",
      "Validation Loss: 0.03184499\n",
      "Epoch: 4600 cost = 0.012678525\n",
      "Validation Loss: 0.030365337\n",
      "Epoch: 4601 cost = 0.012678095\n",
      "Validation Loss: 0.02947859\n",
      "Epoch: 4602 cost = 0.012677873\n",
      "Validation Loss: 0.034509487\n",
      "Epoch: 4603 cost = 0.012677330\n",
      "Validation Loss: 0.026180627\n",
      "Epoch: 4604 cost = 0.012677761\n",
      "Validation Loss: 0.025941478\n",
      "Epoch: 4605 cost = 0.012676725\n",
      "Validation Loss: 0.020552106\n",
      "Epoch: 4606 cost = 0.012676312\n",
      "Validation Loss: 0.024780964\n",
      "Epoch: 4607 cost = 0.012675908\n",
      "Validation Loss: 0.019003546\n",
      "Epoch: 4608 cost = 0.012675907\n",
      "Validation Loss: 0.019711442\n",
      "Epoch: 4609 cost = 0.012675665\n",
      "Validation Loss: 0.029478477\n",
      "Epoch: 4610 cost = 0.012675324\n",
      "Validation Loss: 0.049826622\n",
      "Epoch: 4611 cost = 0.012675062\n",
      "Validation Loss: 0.040403593\n",
      "Epoch: 4612 cost = 0.012674325\n",
      "Validation Loss: 0.035978172\n",
      "Epoch: 4613 cost = 0.012674339\n",
      "Validation Loss: 0.033767216\n",
      "Epoch: 4614 cost = 0.012673555\n",
      "Validation Loss: 0.043837346\n",
      "Epoch: 4615 cost = 0.012673133\n",
      "Validation Loss: 0.05684791\n",
      "Epoch: 4616 cost = 0.012673274\n",
      "Validation Loss: 0.045452572\n",
      "Epoch: 4617 cost = 0.012672609\n",
      "Validation Loss: 0.04461318\n",
      "Epoch: 4618 cost = 0.012672243\n",
      "Validation Loss: 0.0501509\n",
      "Epoch: 4619 cost = 0.012671509\n",
      "Validation Loss: 0.041201472\n",
      "Epoch: 4620 cost = 0.012671697\n",
      "Validation Loss: 0.01788453\n",
      "Epoch: 4621 cost = 0.012670977\n",
      "Validation Loss: 0.017935889\n",
      "Epoch: 4622 cost = 0.012670893\n",
      "Validation Loss: 0.015156882\n",
      "Epoch: 4623 cost = 0.012670362\n",
      "Validation Loss: 0.023148507\n",
      "Epoch: 4624 cost = 0.012670229\n",
      "Validation Loss: 0.029746775\n",
      "Epoch: 4625 cost = 0.012670075\n",
      "Validation Loss: 0.027622439\n",
      "Epoch: 4626 cost = 0.012669240\n",
      "Validation Loss: 0.02625419\n",
      "Epoch: 4627 cost = 0.012669172\n",
      "Validation Loss: 0.021929685\n",
      "Epoch: 4628 cost = 0.012669095\n",
      "Validation Loss: 0.023414278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4629 cost = 0.012668537\n",
      "Validation Loss: 0.02461512\n",
      "Epoch: 4630 cost = 0.012668478\n",
      "Validation Loss: 0.0219525\n",
      "Epoch: 4631 cost = 0.012667321\n",
      "Validation Loss: 0.022533517\n",
      "Epoch: 4632 cost = 0.012666825\n",
      "Validation Loss: 0.02357976\n",
      "Epoch: 4633 cost = 0.012666770\n",
      "Validation Loss: 0.027446799\n",
      "Epoch: 4634 cost = 0.012666282\n",
      "Validation Loss: 0.022721753\n",
      "Epoch: 4635 cost = 0.012666488\n",
      "Validation Loss: 0.03150489\n",
      "Epoch: 4636 cost = 0.012665859\n",
      "Validation Loss: 0.046802007\n",
      "Epoch: 4637 cost = 0.012666041\n",
      "Validation Loss: 0.027516063\n",
      "Epoch: 4638 cost = 0.012665248\n",
      "Validation Loss: 0.030482521\n",
      "Epoch: 4639 cost = 0.012664935\n",
      "Validation Loss: 0.026893238\n",
      "Epoch: 4640 cost = 0.012664567\n",
      "Validation Loss: 0.032622263\n",
      "Epoch: 4641 cost = 0.012664439\n",
      "Validation Loss: 0.026720246\n",
      "Epoch: 4642 cost = 0.012663182\n",
      "Validation Loss: 0.025349319\n",
      "Epoch: 4643 cost = 0.012664276\n",
      "Validation Loss: 0.02566419\n",
      "Epoch: 4644 cost = 0.012663145\n",
      "Validation Loss: 0.027289446\n",
      "Epoch: 4645 cost = 0.012663012\n",
      "Validation Loss: 0.03862837\n",
      "Epoch: 4646 cost = 0.012662769\n",
      "Validation Loss: 0.04445373\n",
      "Epoch: 4647 cost = 0.012662102\n",
      "Validation Loss: 0.0416702\n",
      "Epoch: 4648 cost = 0.012661688\n",
      "Validation Loss: 0.022057448\n",
      "Epoch: 4649 cost = 0.012661544\n",
      "Validation Loss: 0.022029722\n",
      "Epoch: 4650 cost = 0.012661443\n",
      "Validation Loss: 0.028455434\n",
      "Epoch: 4651 cost = 0.012660755\n",
      "Validation Loss: 0.033627883\n",
      "Epoch: 4652 cost = 0.012660246\n",
      "Validation Loss: 0.033739224\n",
      "Epoch: 4653 cost = 0.012660090\n",
      "Validation Loss: 0.037213437\n",
      "Epoch: 4654 cost = 0.012659368\n",
      "Validation Loss: 0.029513812\n",
      "Epoch: 4655 cost = 0.012658897\n",
      "Validation Loss: 0.032180216\n",
      "Epoch: 4656 cost = 0.012658808\n",
      "Validation Loss: 0.04273087\n",
      "Epoch: 4657 cost = 0.012658407\n",
      "Validation Loss: 0.042924788\n",
      "Epoch: 4658 cost = 0.012657774\n",
      "Validation Loss: 0.052966356\n",
      "Epoch: 4659 cost = 0.012657871\n",
      "Validation Loss: 0.051166944\n",
      "Epoch: 4660 cost = 0.012657910\n",
      "Validation Loss: 0.031118147\n",
      "Epoch: 4661 cost = 0.012656819\n",
      "Validation Loss: 0.028451532\n",
      "Epoch: 4662 cost = 0.012656579\n",
      "Validation Loss: 0.03477286\n",
      "Epoch: 4663 cost = 0.012656527\n",
      "Validation Loss: 0.034486447\n",
      "Epoch: 4664 cost = 0.012655761\n",
      "Validation Loss: 0.03724078\n",
      "Epoch: 4665 cost = 0.012655733\n",
      "Validation Loss: 0.03408858\n",
      "Epoch: 4666 cost = 0.012655716\n",
      "Validation Loss: 0.027629921\n",
      "Epoch: 4667 cost = 0.012654963\n",
      "Validation Loss: 0.026001105\n",
      "Epoch: 4668 cost = 0.012654559\n",
      "Validation Loss: 0.027088469\n",
      "Epoch: 4669 cost = 0.012654558\n",
      "Validation Loss: 0.030897997\n",
      "Epoch: 4670 cost = 0.012654161\n",
      "Validation Loss: 0.022949966\n",
      "Epoch: 4671 cost = 0.012653039\n",
      "Validation Loss: 0.02246296\n",
      "Epoch: 4672 cost = 0.012653256\n",
      "Validation Loss: 0.026351485\n",
      "Epoch: 4673 cost = 0.012653415\n",
      "Validation Loss: 0.022449499\n",
      "Epoch: 4674 cost = 0.012652856\n",
      "Validation Loss: 0.01765347\n",
      "Epoch: 4675 cost = 0.012652076\n",
      "Validation Loss: 0.020286208\n",
      "Epoch: 4676 cost = 0.012651938\n",
      "Validation Loss: 0.02516998\n",
      "Epoch: 4677 cost = 0.012651698\n",
      "Validation Loss: 0.019220183\n",
      "Epoch: 4678 cost = 0.012651086\n",
      "Validation Loss: 0.01721788\n",
      "Epoch: 4679 cost = 0.012650371\n",
      "Validation Loss: 0.028281664\n",
      "Epoch: 4680 cost = 0.012650657\n",
      "Validation Loss: 0.032835215\n",
      "Epoch: 4681 cost = 0.012649994\n",
      "Validation Loss: 0.032277588\n",
      "Epoch: 4682 cost = 0.012650176\n",
      "Validation Loss: 0.033108287\n",
      "Epoch: 4683 cost = 0.012649582\n",
      "Validation Loss: 0.03653057\n",
      "Epoch: 4684 cost = 0.012648846\n",
      "Validation Loss: 0.02630426\n",
      "Epoch: 4685 cost = 0.012648426\n",
      "Validation Loss: 0.017778791\n",
      "Epoch: 4686 cost = 0.012648471\n",
      "Validation Loss: 0.017283829\n",
      "Epoch: 4687 cost = 0.012647651\n",
      "Validation Loss: 0.019858344\n",
      "Epoch: 4688 cost = 0.012647857\n",
      "Validation Loss: 0.025324227\n",
      "Epoch: 4689 cost = 0.012647028\n",
      "Validation Loss: 0.026795546\n",
      "Epoch: 4690 cost = 0.012647041\n",
      "Validation Loss: 0.022994572\n",
      "Epoch: 4691 cost = 0.012646417\n",
      "Validation Loss: 0.0221843\n",
      "Epoch: 4692 cost = 0.012646617\n",
      "Validation Loss: 0.028376328\n",
      "Epoch: 4693 cost = 0.012645860\n",
      "Validation Loss: 0.024000874\n",
      "Epoch: 4694 cost = 0.012645195\n",
      "Validation Loss: 0.023446966\n",
      "Epoch: 4695 cost = 0.012645045\n",
      "Validation Loss: 0.02995466\n",
      "Epoch: 4696 cost = 0.012644551\n",
      "Validation Loss: 0.039945193\n",
      "Epoch: 4697 cost = 0.012644725\n",
      "Validation Loss: 0.033506874\n",
      "Epoch: 4698 cost = 0.012644303\n",
      "Validation Loss: 0.025357163\n",
      "Epoch: 4699 cost = 0.012644025\n",
      "Validation Loss: 0.032487478\n",
      "Epoch: 4700 cost = 0.012643406\n",
      "Validation Loss: 0.030431863\n",
      "Epoch: 4701 cost = 0.012643086\n",
      "Validation Loss: 0.033557307\n",
      "Epoch: 4702 cost = 0.012642311\n",
      "Validation Loss: 0.030270921\n",
      "Epoch: 4703 cost = 0.012642179\n",
      "Validation Loss: 0.04120831\n",
      "Epoch: 4704 cost = 0.012642474\n",
      "Validation Loss: 0.031193923\n",
      "Epoch: 4705 cost = 0.012641566\n",
      "Validation Loss: 0.026468908\n",
      "Epoch: 4706 cost = 0.012641184\n",
      "Validation Loss: 0.030768465\n",
      "Epoch: 4707 cost = 0.012640762\n",
      "Validation Loss: 0.036557026\n",
      "Epoch: 4708 cost = 0.012640319\n",
      "Validation Loss: 0.03456619\n",
      "Epoch: 4709 cost = 0.012640692\n",
      "Validation Loss: 0.024391985\n",
      "Epoch: 4710 cost = 0.012639685\n",
      "Validation Loss: 0.019999031\n",
      "Epoch: 4711 cost = 0.012639737\n",
      "Validation Loss: 0.02532102\n",
      "Epoch: 4712 cost = 0.012638968\n",
      "Validation Loss: 0.037817158\n",
      "Epoch: 4713 cost = 0.012638830\n",
      "Validation Loss: 0.03675875\n",
      "Epoch: 4714 cost = 0.012638761\n",
      "Validation Loss: 0.01865109\n",
      "Epoch: 4715 cost = 0.012638462\n",
      "Validation Loss: 0.020332139\n",
      "Epoch: 4716 cost = 0.012638010\n",
      "Validation Loss: 0.024493648\n",
      "Epoch: 4717 cost = 0.012637435\n",
      "Validation Loss: 0.031324565\n",
      "Epoch: 4718 cost = 0.012637086\n",
      "Validation Loss: 0.028040364\n",
      "Epoch: 4719 cost = 0.012636989\n",
      "Validation Loss: 0.023451678\n",
      "Epoch: 4720 cost = 0.012636027\n",
      "Validation Loss: 0.023259576\n",
      "Epoch: 4721 cost = 0.012636151\n",
      "Validation Loss: 0.030592317\n",
      "Epoch: 4722 cost = 0.012635631\n",
      "Validation Loss: 0.022183124\n",
      "Epoch: 4723 cost = 0.012635273\n",
      "Validation Loss: 0.023211481\n",
      "Epoch: 4724 cost = 0.012634904\n",
      "Validation Loss: 0.022147119\n",
      "Epoch: 4725 cost = 0.012634437\n",
      "Validation Loss: 0.023248108\n",
      "Epoch: 4726 cost = 0.012634091\n",
      "Validation Loss: 0.017535813\n",
      "Epoch: 4727 cost = 0.012633770\n",
      "Validation Loss: 0.022456354\n",
      "Epoch: 4728 cost = 0.012633797\n",
      "Validation Loss: 0.029769719\n",
      "Epoch: 4729 cost = 0.012633474\n",
      "Validation Loss: 0.02709408\n",
      "Epoch: 4730 cost = 0.012632582\n",
      "Validation Loss: 0.024802824\n",
      "Epoch: 4731 cost = 0.012632871\n",
      "Validation Loss: 0.032528084\n",
      "Epoch: 4732 cost = 0.012632413\n",
      "Validation Loss: 0.027145153\n",
      "Epoch: 4733 cost = 0.012631640\n",
      "Validation Loss: 0.03182796\n",
      "Epoch: 4734 cost = 0.012631616\n",
      "Validation Loss: 0.029927084\n",
      "Epoch: 4735 cost = 0.012630989\n",
      "Validation Loss: 0.021298539\n",
      "Epoch: 4736 cost = 0.012630694\n",
      "Validation Loss: 0.019003652\n",
      "Epoch: 4737 cost = 0.012630616\n",
      "Validation Loss: 0.026413757\n",
      "Epoch: 4738 cost = 0.012630176\n",
      "Validation Loss: 0.027088545\n",
      "Epoch: 4739 cost = 0.012629837\n",
      "Validation Loss: 0.017876714\n",
      "Epoch: 4740 cost = 0.012629171\n",
      "Validation Loss: 0.02026559\n",
      "Epoch: 4741 cost = 0.012629061\n",
      "Validation Loss: 0.018650295\n",
      "Epoch: 4742 cost = 0.012628399\n",
      "Validation Loss: 0.022608917\n",
      "Epoch: 4743 cost = 0.012628233\n",
      "Validation Loss: 0.03151114\n",
      "Epoch: 4744 cost = 0.012628337\n",
      "Validation Loss: 0.024467325\n",
      "Epoch: 4745 cost = 0.012627877\n",
      "Validation Loss: 0.032051444\n",
      "Epoch: 4746 cost = 0.012627737\n",
      "Validation Loss: 0.0411729\n",
      "Epoch: 4747 cost = 0.012626525\n",
      "Validation Loss: 0.040500704\n",
      "Epoch: 4748 cost = 0.012626411\n",
      "Validation Loss: 0.031462673\n",
      "Epoch: 4749 cost = 0.012626378\n",
      "Validation Loss: 0.040974155\n",
      "Epoch: 4750 cost = 0.012625844\n",
      "Validation Loss: 0.039462164\n",
      "Epoch: 4751 cost = 0.012625855\n",
      "Validation Loss: 0.017366115\n",
      "Epoch: 4752 cost = 0.012625065\n",
      "Validation Loss: 0.01921164\n",
      "Epoch: 4753 cost = 0.012624799\n",
      "Validation Loss: 0.017870814\n",
      "Epoch: 4754 cost = 0.012624290\n",
      "Validation Loss: 0.027852165\n",
      "Epoch: 4755 cost = 0.012624251\n",
      "Validation Loss: 0.025797097\n",
      "Epoch: 4756 cost = 0.012623996\n",
      "Validation Loss: 0.02528483\n",
      "Epoch: 4757 cost = 0.012623373\n",
      "Validation Loss: 0.024770692\n",
      "Epoch: 4758 cost = 0.012623124\n",
      "Validation Loss: 0.029131679\n",
      "Epoch: 4759 cost = 0.012622532\n",
      "Validation Loss: 0.021005532\n",
      "Epoch: 4760 cost = 0.012622228\n",
      "Validation Loss: 0.022753106\n",
      "Epoch: 4761 cost = 0.012622010\n",
      "Validation Loss: 0.0151667725\n",
      "Epoch: 4762 cost = 0.012621481\n",
      "Validation Loss: 0.023545904\n",
      "Epoch: 4763 cost = 0.012621354\n",
      "Validation Loss: 0.025128469\n",
      "Epoch: 4764 cost = 0.012621066\n",
      "Validation Loss: 0.028854473\n",
      "Epoch: 4765 cost = 0.012620848\n",
      "Validation Loss: 0.023174344\n",
      "Epoch: 4766 cost = 0.012620157\n",
      "Validation Loss: 0.024784021\n",
      "Epoch: 4767 cost = 0.012620011\n",
      "Validation Loss: 0.023284199\n",
      "Epoch: 4768 cost = 0.012619498\n",
      "Validation Loss: 0.026685625\n",
      "Epoch: 4769 cost = 0.012619423\n",
      "Validation Loss: 0.025109667\n",
      "Epoch: 4770 cost = 0.012619166\n",
      "Validation Loss: 0.024823686\n",
      "Epoch: 4771 cost = 0.012618827\n",
      "Validation Loss: 0.026497234\n",
      "Epoch: 4772 cost = 0.012618341\n",
      "Validation Loss: 0.0298509\n",
      "Epoch: 4773 cost = 0.012617853\n",
      "Validation Loss: 0.01946199\n",
      "Epoch: 4774 cost = 0.012617836\n",
      "Validation Loss: 0.018594906\n",
      "Epoch: 4775 cost = 0.012617219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.024675554\n",
      "Epoch: 4776 cost = 0.012616748\n",
      "Validation Loss: 0.01951176\n",
      "Epoch: 4777 cost = 0.012616694\n",
      "Validation Loss: 0.017296875\n",
      "Epoch: 4778 cost = 0.012616218\n",
      "Validation Loss: 0.032971825\n",
      "Epoch: 4779 cost = 0.012615832\n",
      "Validation Loss: 0.041701626\n",
      "Epoch: 4780 cost = 0.012615461\n",
      "Validation Loss: 0.02741125\n",
      "Epoch: 4781 cost = 0.012614933\n",
      "Validation Loss: 0.019141994\n",
      "Epoch: 4782 cost = 0.012614615\n",
      "Validation Loss: 0.021843031\n",
      "Epoch: 4783 cost = 0.012614417\n",
      "Validation Loss: 0.023860384\n",
      "Epoch: 4784 cost = 0.012613660\n",
      "Validation Loss: 0.023776403\n",
      "Epoch: 4785 cost = 0.012613653\n",
      "Validation Loss: 0.029543499\n",
      "Epoch: 4786 cost = 0.012613652\n",
      "Validation Loss: 0.024430681\n",
      "Epoch: 4787 cost = 0.012613251\n",
      "Validation Loss: 0.03211078\n",
      "Epoch: 4788 cost = 0.012612774\n",
      "Validation Loss: 0.032458093\n",
      "Epoch: 4789 cost = 0.012612835\n",
      "Validation Loss: 0.031525612\n",
      "Epoch: 4790 cost = 0.012611803\n",
      "Validation Loss: 0.024512097\n",
      "Epoch: 4791 cost = 0.012611274\n",
      "Validation Loss: 0.019670723\n",
      "Epoch: 4792 cost = 0.012611448\n",
      "Validation Loss: 0.018167779\n",
      "Epoch: 4793 cost = 0.012610548\n",
      "Validation Loss: 0.020034583\n",
      "Epoch: 4794 cost = 0.012610519\n",
      "Validation Loss: 0.02127528\n",
      "Epoch: 4795 cost = 0.012609953\n",
      "Validation Loss: 0.02767757\n",
      "Epoch: 4796 cost = 0.012610212\n",
      "Validation Loss: 0.03093773\n",
      "Epoch: 4797 cost = 0.012609553\n",
      "Validation Loss: 0.028779412\n",
      "Epoch: 4798 cost = 0.012609200\n",
      "Validation Loss: 0.0366501\n",
      "Epoch: 4799 cost = 0.012609290\n",
      "Validation Loss: 0.052650977\n",
      "Epoch: 4800 cost = 0.012608343\n",
      "Validation Loss: 0.04254682\n",
      "Epoch: 4801 cost = 0.012608391\n",
      "Validation Loss: 0.044690624\n",
      "Epoch: 4802 cost = 0.012607730\n",
      "Validation Loss: 0.042281024\n",
      "Epoch: 4803 cost = 0.012607522\n",
      "Validation Loss: 0.029781394\n",
      "Epoch: 4804 cost = 0.012607001\n",
      "Validation Loss: 0.024964461\n",
      "Epoch: 4805 cost = 0.012606998\n",
      "Validation Loss: 0.037224565\n",
      "Epoch: 4806 cost = 0.012606274\n",
      "Validation Loss: 0.03237596\n",
      "Epoch: 4807 cost = 0.012606174\n",
      "Validation Loss: 0.03269919\n",
      "Epoch: 4808 cost = 0.012605721\n",
      "Validation Loss: 0.0228478\n",
      "Epoch: 4809 cost = 0.012605339\n",
      "Validation Loss: 0.017503072\n",
      "Epoch: 4810 cost = 0.012604729\n",
      "Validation Loss: 0.019824393\n",
      "Epoch: 4811 cost = 0.012605090\n",
      "Validation Loss: 0.028344331\n",
      "Epoch: 4812 cost = 0.012604418\n",
      "Validation Loss: 0.025932968\n",
      "Epoch: 4813 cost = 0.012603690\n",
      "Validation Loss: 0.018707162\n",
      "Epoch: 4814 cost = 0.012603554\n",
      "Validation Loss: 0.026153494\n",
      "Epoch: 4815 cost = 0.012603597\n",
      "Validation Loss: 0.025951525\n",
      "Epoch: 4816 cost = 0.012602994\n",
      "Validation Loss: 0.026025502\n",
      "Epoch: 4817 cost = 0.012602182\n",
      "Validation Loss: 0.029786263\n",
      "Epoch: 4818 cost = 0.012602008\n",
      "Validation Loss: 0.027911993\n",
      "Epoch: 4819 cost = 0.012601637\n",
      "Validation Loss: 0.031116428\n",
      "Epoch: 4820 cost = 0.012601611\n",
      "Validation Loss: 0.025810363\n",
      "Epoch: 4821 cost = 0.012601017\n",
      "Validation Loss: 0.02118064\n",
      "Epoch: 4822 cost = 0.012600868\n",
      "Validation Loss: 0.02968882\n",
      "Epoch: 4823 cost = 0.012600594\n",
      "Validation Loss: 0.03720711\n",
      "Epoch: 4824 cost = 0.012600194\n",
      "Validation Loss: 0.031296205\n",
      "Epoch: 4825 cost = 0.012599892\n",
      "Validation Loss: 0.024685247\n",
      "Epoch: 4826 cost = 0.012599567\n",
      "Validation Loss: 0.02358635\n",
      "Epoch: 4827 cost = 0.012599533\n",
      "Validation Loss: 0.021728579\n",
      "Epoch: 4828 cost = 0.012598924\n",
      "Validation Loss: 0.021274006\n",
      "Epoch: 4829 cost = 0.012598325\n",
      "Validation Loss: 0.02572485\n",
      "Epoch: 4830 cost = 0.012598489\n",
      "Validation Loss: 0.025520021\n",
      "Epoch: 4831 cost = 0.012597319\n",
      "Validation Loss: 0.02059202\n",
      "Epoch: 4832 cost = 0.012597341\n",
      "Validation Loss: 0.018384038\n",
      "Epoch: 4833 cost = 0.012597337\n",
      "Validation Loss: 0.024031494\n",
      "Epoch: 4834 cost = 0.012597049\n",
      "Validation Loss: 0.027502384\n",
      "Epoch: 4835 cost = 0.012596232\n",
      "Validation Loss: 0.025818607\n",
      "Epoch: 4836 cost = 0.012595777\n",
      "Validation Loss: 0.030574646\n",
      "Epoch: 4837 cost = 0.012595564\n",
      "Validation Loss: 0.03074136\n",
      "Epoch: 4838 cost = 0.012595736\n",
      "Validation Loss: 0.029602977\n",
      "Epoch: 4839 cost = 0.012595083\n",
      "Validation Loss: 0.026720034\n",
      "Epoch: 4840 cost = 0.012595063\n",
      "Validation Loss: 0.038681943\n",
      "Epoch: 4841 cost = 0.012594940\n",
      "Validation Loss: 0.05716591\n",
      "Epoch: 4842 cost = 0.012593801\n",
      "Validation Loss: 0.04362453\n",
      "Epoch: 4843 cost = 0.012593558\n",
      "Validation Loss: 0.037496828\n",
      "Epoch: 4844 cost = 0.012593068\n",
      "Validation Loss: 0.033003688\n",
      "Epoch: 4845 cost = 0.012592969\n",
      "Validation Loss: 0.041080844\n",
      "Epoch: 4846 cost = 0.012592936\n",
      "Validation Loss: 0.037824403\n",
      "Epoch: 4847 cost = 0.012592676\n",
      "Validation Loss: 0.034689147\n",
      "Epoch: 4848 cost = 0.012591931\n",
      "Validation Loss: 0.039591018\n",
      "Epoch: 4849 cost = 0.012591704\n",
      "Validation Loss: 0.05048427\n",
      "Epoch: 4850 cost = 0.012591561\n",
      "Validation Loss: 0.051629648\n",
      "Epoch: 4851 cost = 0.012590952\n",
      "Validation Loss: 0.032600872\n",
      "Epoch: 4852 cost = 0.012590292\n",
      "Validation Loss: 0.026385091\n",
      "Epoch: 4853 cost = 0.012590319\n",
      "Validation Loss: 0.033467814\n",
      "Epoch: 4854 cost = 0.012589970\n",
      "Validation Loss: 0.02268215\n",
      "Epoch: 4855 cost = 0.012589621\n",
      "Validation Loss: 0.023986526\n",
      "Epoch: 4856 cost = 0.012589148\n",
      "Validation Loss: 0.020494964\n",
      "Epoch: 4857 cost = 0.012588728\n",
      "Validation Loss: 0.028335009\n",
      "Epoch: 4858 cost = 0.012588870\n",
      "Validation Loss: 0.022153512\n",
      "Epoch: 4859 cost = 0.012588546\n",
      "Validation Loss: 0.023245936\n",
      "Epoch: 4860 cost = 0.012587773\n",
      "Validation Loss: 0.0278924\n",
      "Epoch: 4861 cost = 0.012587435\n",
      "Validation Loss: 0.029831592\n",
      "Epoch: 4862 cost = 0.012587321\n",
      "Validation Loss: 0.022641968\n",
      "Epoch: 4863 cost = 0.012587012\n",
      "Validation Loss: 0.030911136\n",
      "Epoch: 4864 cost = 0.012586837\n",
      "Validation Loss: 0.0365187\n",
      "Epoch: 4865 cost = 0.012586257\n",
      "Validation Loss: 0.032847032\n",
      "Epoch: 4866 cost = 0.012586049\n",
      "Validation Loss: 0.027294599\n",
      "Epoch: 4867 cost = 0.012585361\n",
      "Validation Loss: 0.031834915\n",
      "Epoch: 4868 cost = 0.012585449\n",
      "Validation Loss: 0.03836534\n",
      "Epoch: 4869 cost = 0.012584746\n",
      "Validation Loss: 0.027174395\n",
      "Epoch: 4870 cost = 0.012584419\n",
      "Validation Loss: 0.018903699\n",
      "Epoch: 4871 cost = 0.012585166\n",
      "Validation Loss: 0.02163797\n",
      "Epoch: 4872 cost = 0.012584013\n",
      "Validation Loss: 0.024457928\n",
      "Epoch: 4873 cost = 0.012583364\n",
      "Validation Loss: 0.031739637\n",
      "Epoch: 4874 cost = 0.012583752\n",
      "Validation Loss: 0.031947955\n",
      "Epoch: 4875 cost = 0.012582870\n",
      "Validation Loss: 0.025667353\n",
      "Epoch: 4876 cost = 0.012582763\n",
      "Validation Loss: 0.02047511\n",
      "Epoch: 4877 cost = 0.012581979\n",
      "Validation Loss: 0.017872045\n",
      "Epoch: 4878 cost = 0.012581899\n",
      "Validation Loss: 0.02024649\n",
      "Epoch: 4879 cost = 0.012581485\n",
      "Validation Loss: 0.026392037\n",
      "Epoch: 4880 cost = 0.012581213\n",
      "Validation Loss: 0.028755493\n",
      "Epoch: 4881 cost = 0.012580600\n",
      "Validation Loss: 0.024973243\n",
      "Epoch: 4882 cost = 0.012580427\n",
      "Validation Loss: 0.022777757\n",
      "Epoch: 4883 cost = 0.012580072\n",
      "Validation Loss: 0.029437667\n",
      "Epoch: 4884 cost = 0.012579826\n",
      "Validation Loss: 0.027487326\n",
      "Epoch: 4885 cost = 0.012579622\n",
      "Validation Loss: 0.024993727\n",
      "Epoch: 4886 cost = 0.012579323\n",
      "Validation Loss: 0.033067793\n",
      "Epoch: 4887 cost = 0.012578752\n",
      "Validation Loss: 0.031220281\n",
      "Epoch: 4888 cost = 0.012578425\n",
      "Validation Loss: 0.036601454\n",
      "Epoch: 4889 cost = 0.012578368\n",
      "Validation Loss: 0.038298722\n",
      "Epoch: 4890 cost = 0.012577893\n",
      "Validation Loss: 0.037641514\n",
      "Epoch: 4891 cost = 0.012577521\n",
      "Validation Loss: 0.04322249\n",
      "Epoch: 4892 cost = 0.012576921\n",
      "Validation Loss: 0.04840709\n",
      "Epoch: 4893 cost = 0.012576587\n",
      "Validation Loss: 0.03612901\n",
      "Epoch: 4894 cost = 0.012576789\n",
      "Validation Loss: 0.03123164\n",
      "Epoch: 4895 cost = 0.012576633\n",
      "Validation Loss: 0.03083446\n",
      "Epoch: 4896 cost = 0.012575774\n",
      "Validation Loss: 0.02204142\n",
      "Epoch: 4897 cost = 0.012575405\n",
      "Validation Loss: 0.027390879\n",
      "Epoch: 4898 cost = 0.012575336\n",
      "Validation Loss: 0.030050406\n",
      "Epoch: 4899 cost = 0.012574884\n",
      "Validation Loss: 0.03457839\n",
      "Epoch: 4900 cost = 0.012574214\n",
      "Validation Loss: 0.040193014\n",
      "Epoch: 4901 cost = 0.012573703\n",
      "Validation Loss: 0.045685947\n",
      "Epoch: 4902 cost = 0.012573807\n",
      "Validation Loss: 0.05104658\n",
      "Epoch: 4903 cost = 0.012573532\n",
      "Validation Loss: 0.039915767\n",
      "Epoch: 4904 cost = 0.012573359\n",
      "Validation Loss: 0.0349858\n",
      "Epoch: 4905 cost = 0.012572910\n",
      "Validation Loss: 0.03290356\n",
      "Epoch: 4906 cost = 0.012572730\n",
      "Validation Loss: 0.03146541\n",
      "Epoch: 4907 cost = 0.012571820\n",
      "Validation Loss: 0.026506172\n",
      "Epoch: 4908 cost = 0.012571959\n",
      "Validation Loss: 0.031626225\n",
      "Epoch: 4909 cost = 0.012571169\n",
      "Validation Loss: 0.038888466\n",
      "Epoch: 4910 cost = 0.012571389\n",
      "Validation Loss: 0.038890008\n",
      "Epoch: 4911 cost = 0.012571084\n",
      "Validation Loss: 0.031317532\n",
      "Epoch: 4912 cost = 0.012570456\n",
      "Validation Loss: 0.025662221\n",
      "Epoch: 4913 cost = 0.012570315\n",
      "Validation Loss: 0.026332589\n",
      "Epoch: 4914 cost = 0.012570014\n",
      "Validation Loss: 0.0305008\n",
      "Epoch: 4915 cost = 0.012569893\n",
      "Validation Loss: 0.024709407\n",
      "Epoch: 4916 cost = 0.012569350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.045671377\n",
      "Epoch: 4917 cost = 0.012569194\n",
      "Validation Loss: 0.045698278\n",
      "Epoch: 4918 cost = 0.012568767\n",
      "Validation Loss: 0.03610134\n",
      "Epoch: 4919 cost = 0.012568378\n",
      "Validation Loss: 0.031908605\n",
      "Epoch: 4920 cost = 0.012568311\n",
      "Validation Loss: 0.028622642\n",
      "Epoch: 4921 cost = 0.012567682\n",
      "Validation Loss: 0.033938188\n",
      "Epoch: 4922 cost = 0.012567111\n",
      "Validation Loss: 0.024154074\n",
      "Epoch: 4923 cost = 0.012566952\n",
      "Validation Loss: 0.03139339\n",
      "Epoch: 4924 cost = 0.012566856\n",
      "Validation Loss: 0.040120814\n",
      "Epoch: 4925 cost = 0.012566593\n",
      "Validation Loss: 0.039700355\n",
      "Epoch: 4926 cost = 0.012565651\n",
      "Validation Loss: 0.030699886\n",
      "Epoch: 4927 cost = 0.012565563\n",
      "Validation Loss: 0.019118099\n",
      "Epoch: 4928 cost = 0.012565629\n",
      "Validation Loss: 0.02678111\n",
      "Epoch: 4929 cost = 0.012565058\n",
      "Validation Loss: 0.032560274\n",
      "Epoch: 4930 cost = 0.012564464\n",
      "Validation Loss: 0.035471704\n",
      "Epoch: 4931 cost = 0.012564338\n",
      "Validation Loss: 0.02270541\n",
      "Epoch: 4932 cost = 0.012564108\n",
      "Validation Loss: 0.016725585\n",
      "Epoch: 4933 cost = 0.012563803\n",
      "Validation Loss: 0.023680067\n",
      "Epoch: 4934 cost = 0.012563578\n",
      "Validation Loss: 0.019324457\n",
      "Epoch: 4935 cost = 0.012562873\n",
      "Validation Loss: 0.016754905\n",
      "Epoch: 4936 cost = 0.012563073\n",
      "Validation Loss: 0.016078193\n",
      "Epoch: 4937 cost = 0.012562414\n",
      "Validation Loss: 0.017778546\n",
      "Epoch: 4938 cost = 0.012562197\n",
      "Validation Loss: 0.0287522\n",
      "Epoch: 4939 cost = 0.012561569\n",
      "Validation Loss: 0.032520555\n",
      "Epoch: 4940 cost = 0.012561442\n",
      "Validation Loss: 0.03685559\n",
      "Epoch: 4941 cost = 0.012561460\n",
      "Validation Loss: 0.040846877\n",
      "Epoch: 4942 cost = 0.012560771\n",
      "Validation Loss: 0.04943112\n",
      "Epoch: 4943 cost = 0.012560675\n",
      "Validation Loss: 0.04266742\n",
      "Epoch: 4944 cost = 0.012559851\n",
      "Validation Loss: 0.033450715\n",
      "Epoch: 4945 cost = 0.012560395\n",
      "Validation Loss: 0.032450996\n",
      "Epoch: 4946 cost = 0.012559359\n",
      "Validation Loss: 0.03170337\n",
      "Epoch: 4947 cost = 0.012559238\n",
      "Validation Loss: 0.03033613\n",
      "Epoch: 4948 cost = 0.012558650\n",
      "Validation Loss: 0.0347548\n",
      "Epoch: 4949 cost = 0.012558403\n",
      "Validation Loss: 0.03666302\n",
      "Epoch: 4950 cost = 0.012558111\n",
      "Validation Loss: 0.028332895\n",
      "Epoch: 4951 cost = 0.012558068\n",
      "Validation Loss: 0.021468656\n",
      "Epoch: 4952 cost = 0.012557796\n",
      "Validation Loss: 0.016478634\n",
      "Epoch: 4953 cost = 0.012557278\n",
      "Validation Loss: 0.022318175\n",
      "Epoch: 4954 cost = 0.012557120\n",
      "Validation Loss: 0.033234894\n",
      "Epoch: 4955 cost = 0.012556438\n",
      "Validation Loss: 0.044625636\n",
      "Epoch: 4956 cost = 0.012556284\n",
      "Validation Loss: 0.04680266\n",
      "Epoch: 4957 cost = 0.012556031\n",
      "Validation Loss: 0.035967086\n",
      "Epoch: 4958 cost = 0.012555614\n",
      "Validation Loss: 0.033689246\n",
      "Epoch: 4959 cost = 0.012555271\n",
      "Validation Loss: 0.022685971\n",
      "Epoch: 4960 cost = 0.012555301\n",
      "Validation Loss: 0.02501993\n",
      "Epoch: 4961 cost = 0.012554842\n",
      "Validation Loss: 0.024978999\n",
      "Epoch: 4962 cost = 0.012554793\n",
      "Validation Loss: 0.024558485\n",
      "Epoch: 4963 cost = 0.012554109\n",
      "Validation Loss: 0.026155854\n",
      "Epoch: 4964 cost = 0.012554098\n",
      "Validation Loss: 0.025269391\n",
      "Epoch: 4965 cost = 0.012553434\n",
      "Validation Loss: 0.027872017\n",
      "Epoch: 4966 cost = 0.012552974\n",
      "Validation Loss: 0.027334537\n",
      "Epoch: 4967 cost = 0.012552640\n",
      "Validation Loss: 0.021427013\n",
      "Epoch: 4968 cost = 0.012552498\n",
      "Validation Loss: 0.028700853\n",
      "Epoch: 4969 cost = 0.012552175\n",
      "Validation Loss: 0.025498115\n",
      "Epoch: 4970 cost = 0.012551744\n",
      "Validation Loss: 0.027419727\n",
      "Epoch: 4971 cost = 0.012551309\n",
      "Validation Loss: 0.023504116\n",
      "Epoch: 4972 cost = 0.012551181\n",
      "Validation Loss: 0.027073368\n",
      "Epoch: 4973 cost = 0.012550715\n",
      "Validation Loss: 0.023639413\n",
      "Epoch: 4974 cost = 0.012550680\n",
      "Validation Loss: 0.024965122\n",
      "Epoch: 4975 cost = 0.012550322\n",
      "Validation Loss: 0.032937344\n",
      "Epoch: 4976 cost = 0.012549913\n",
      "Validation Loss: 0.029726373\n",
      "Epoch: 4977 cost = 0.012549457\n",
      "Validation Loss: 0.029835952\n",
      "Epoch: 4978 cost = 0.012549330\n",
      "Validation Loss: 0.032096505\n",
      "Epoch: 4979 cost = 0.012549022\n",
      "Validation Loss: 0.020808818\n",
      "Epoch: 4980 cost = 0.012548755\n",
      "Validation Loss: 0.02682874\n",
      "Epoch: 4981 cost = 0.012548385\n",
      "Validation Loss: 0.03356955\n",
      "Epoch: 4982 cost = 0.012548284\n",
      "Validation Loss: 0.04370308\n",
      "Epoch: 4983 cost = 0.012547750\n",
      "Validation Loss: 0.04213777\n",
      "Epoch: 4984 cost = 0.012547115\n",
      "Validation Loss: 0.032915536\n",
      "Epoch: 4985 cost = 0.012547110\n",
      "Validation Loss: 0.028585704\n",
      "Epoch: 4986 cost = 0.012546661\n",
      "Validation Loss: 0.020945994\n",
      "Epoch: 4987 cost = 0.012546442\n",
      "Validation Loss: 0.029248593\n",
      "Epoch: 4988 cost = 0.012546073\n",
      "Validation Loss: 0.023990665\n",
      "Epoch: 4989 cost = 0.012545736\n",
      "Validation Loss: 0.023411173\n",
      "Epoch: 4990 cost = 0.012545499\n",
      "Validation Loss: 0.023126576\n",
      "Epoch: 4991 cost = 0.012545179\n",
      "Validation Loss: 0.023382701\n",
      "Epoch: 4992 cost = 0.012544722\n",
      "Validation Loss: 0.024489485\n",
      "Epoch: 4993 cost = 0.012544337\n",
      "Validation Loss: 0.029231323\n",
      "Epoch: 4994 cost = 0.012544392\n",
      "Validation Loss: 0.021549638\n",
      "Epoch: 4995 cost = 0.012543799\n",
      "Validation Loss: 0.025206719\n",
      "Epoch: 4996 cost = 0.012543510\n",
      "Validation Loss: 0.038656563\n",
      "Epoch: 4997 cost = 0.012543353\n",
      "Validation Loss: 0.03576363\n",
      "Epoch: 4998 cost = 0.012542611\n",
      "Validation Loss: 0.037508875\n",
      "Epoch: 4999 cost = 0.012542640\n",
      "Validation Loss: 0.033235792\n",
      "Epoch: 5000 cost = 0.012542294\n",
      "Validation Loss: 0.033220135\n",
      "Optimization Finished!\n",
      "Test Loss: 0.029859781\n"
     ]
    }
   ],
   "source": [
    "#we store the variables here\n",
    "log_files_path = 'C:/Users/yy2895/Desktop/st14-10-14/tmp/model.ckpt'\n",
    "def layer_batch_normalization(x, n_out, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - n_out: integer, depth of input maps - number of sample in the batch \n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - batch-normalized maps   \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    beta_init = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    beta = tf.get_variable(\"beta\", [n_out], initializer=beta_init)\n",
    "    \n",
    "    gamma_init = tf.constant_initializer(value=1.0, dtype=tf.float32)\n",
    "    gamma = tf.get_variable(\"gamma\", [n_out], initializer=gamma_init)\n",
    "\n",
    "    #tf.nn.moment: https://www.tensorflow.org/api_docs/python/tf/nn/moments\n",
    "    #calculate mean and variance of x\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "    \n",
    "    #tf.train.ExponentialMovingAverage:\n",
    "    #https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
    "    #Maintains moving averages of variables by employing an exponential decay.\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    \n",
    "    def mean_var_with_update():\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "        \n",
    "    #tf.cond: https://www.tensorflow.org/api_docs/python/tf/cond\n",
    "    #Return true_fn() if the predicate pred is true else false_fn()\n",
    "    mean, var = tf.cond(phase_train, mean_var_with_update, lambda: (ema_mean, ema_var))\n",
    "    \n",
    "    \n",
    "    #Here, we changesd the shape of x into [[[x1]],[[x2] ],....]\n",
    "\n",
    "    reshaped_x = tf.reshape(x, [-1, 1, 1, n_out])\n",
    "    normed = tf.nn.batch_norm_with_global_normalization(reshaped_x, mean, var, beta, gamma, 1e-3, True)\n",
    "    \n",
    "    return tf.reshape(normed, [-1, n_out])\n",
    "\n",
    "def layer(x, weight_shape, bias_shape, phase_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the network layers\n",
    "    input:\n",
    "        - x: input vector of the layer\n",
    "        - weight_shape: shape the the weight maxtrix\n",
    "        - bias_shape: shape of the bias vector\n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector of the layer after the matrix multiplication and non linear transformation\n",
    "    \"\"\"\n",
    "    \n",
    "    #initialize weights\n",
    "    weight_init = tf.random_normal_initializer(stddev=(1.0/weight_shape[0])**0.5)\n",
    "    W = tf.get_variable(\"W\", weight_shape, initializer=weight_init)\n",
    "    \n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    b = tf.get_variable(\"b\", bias_shape, initializer=bias_init)\n",
    "\n",
    "    logits = tf.matmul(x, W) + b\n",
    "    \n",
    "    #apply the non-linear function after the batch normalization\n",
    "    return tf.nn.sigmoid(layer_batch_normalization(logits, weight_shape[1], phase_train))\n",
    "def encoder(x, n_code, phase_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Defines the network encoder part\n",
    "    input:\n",
    "        - x: input vector of the encoder\n",
    "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder)\n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector: reduced dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope(\"code\"):\n",
    "            output = layer(x, [14, n_code], [n_code], phase_train)\n",
    "\n",
    "\n",
    "    return output\n",
    "\n",
    "def decoder(x, n_code, phase_train):\n",
    "    \"\"\"\n",
    "    Defines the network encoder part\n",
    "    input:\n",
    "        - x: input vector of the decoder - reduced dimension vector\n",
    "        - n_code: number of neurons in the code layer (output of the encoder - input of the decoder) \n",
    "        - phase_train: boolean tf.Varialbe, true indicates training phase\n",
    "    output:\n",
    "        - output vector: reconstructed dimension of the initial vector\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        \n",
    "   \n",
    "        with tf.variable_scope(\"output\"):\n",
    "            output = layer(x, [ n_code, 14], [14], phase_train)\n",
    "\n",
    "    return output\n",
    "def loss(output, x):\n",
    "    \"\"\"\n",
    "    Compute the loss of the auto-encoder\n",
    "    \n",
    "    intput:\n",
    "        - output: the output of the decoder\n",
    "        - x: true value of the sample batch - this is the input of the encoder\n",
    "        \n",
    "        the two have the same shape (batch_size * num_of_classes)\n",
    "    output:\n",
    "        - loss: loss of the corresponding batch (scalar tensor)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"training\"):\n",
    "        \n",
    "        l2 = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x)), 1))\n",
    "        train_loss = tf.reduce_mean(l2)\n",
    "        train_summary_op = tf.summary.scalar(\"train_cost\", train_loss)\n",
    "        return train_loss, train_summary_op\n",
    "def training(cost, global_step):\n",
    "    \"\"\"\n",
    "    defines the necessary elements to train the network\n",
    "    \n",
    "    intput:\n",
    "        - cost: the cost is the loss of the corresponding batch\n",
    "        - global_step: number of batch seen so far, it is incremented by one \n",
    "        each time the .minimize() function is called\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False, name='Adam')\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.005)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op\n",
    "def evaluate(output, x):\n",
    "    \"\"\"\n",
    "    evaluates the accuracy on the validation set \n",
    "    input:\n",
    "        -output: prediction vector of the network for the validation set\n",
    "        -x: true value for the validation set\n",
    "    output:\n",
    "        - val_loss: loss of the autoencoder\n",
    "        - in_image_op: input image \n",
    "        - out_image_op:reconstructed image \n",
    "        - val_summary_op: summary of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope(\"validation\"):\n",
    "        \n",
    "        #in_image_op = image_summary(\"input_image\", x)\n",
    "        \n",
    "        #out_image_op = image_summary(\"output_image\", output)\n",
    "        \n",
    "        l2_norm = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(output, x, name=\"val_diff\")), 1))\n",
    "        \n",
    "        val_loss = tf.reduce_mean(l2_norm)\n",
    "        \n",
    "        val_summary_op = tf.summary.scalar(\"val_cost\", val_loss)\n",
    "        \n",
    "        #return val_loss, in_image_op, out_image_op, val_summary_op\n",
    "        return val_loss,  val_summary_op\n",
    "\"\"\"\n",
    "def image_summary(label, tensor):\n",
    "    #tf.summary.image: https://www.tensorflow.org/api_docs/python/tf/summary/image\n",
    "    #Outputs a Summary protocol buffer with images.\n",
    "\n",
    "    tensor_reshaped = tf.reshape(tensor, [-1, 19, 1, 1])\n",
    "    return tf.summary.image(label, tensor_reshaped)\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    print('we begin')\n",
    "\n",
    "    #if a python file, please use the 4 lines bellow and comment the \"n_code = '2'\"\n",
    "    #parser = argparse.ArgumentParser(description='Autoencoder')\n",
    "    #parser.add_argument('n_code', nargs=1, type=str)\n",
    "    #args = parser.parse_args(['--help'])\n",
    "    #n_code = args.n_code[0]\n",
    "    \n",
    "    #if a jupyter file, please comment the 4 above and use the one bellow\n",
    "    n_code = '10'\n",
    "    \n",
    "    #feel free to change with your own \n",
    "    #log_files_path = r'C:\\Users\\yy2895\\Desktop\\pys'\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.variable_scope(\"autoencoder_model\"):\n",
    "\n",
    "            #the input variables are first define as placeholder \n",
    "            # a placeholder is a variable/data which will be assigned later \n",
    "            # image vector & label, phase_train is a boolean \n",
    "            x = tf.placeholder(\"float\", [None, 14]) # MNIST data image of shape 28*28=784\n",
    "            \n",
    "            phase_train = tf.placeholder(tf.bool)\n",
    "            \n",
    "            #define the encoder \n",
    "            code = encoder(x, int(n_code), phase_train)\n",
    "            \n",
    "            #define the decoder\n",
    "            output = decoder(code, int(n_code), phase_train)\n",
    "            \n",
    "            #compute the loss \n",
    "            cost, train_summary_op = loss(output, x)\n",
    "\n",
    "            #initialize the value of the global_step variable \n",
    "            # recall: it is incremented by one each time the .minimise() is called\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "            train_op = training(cost, global_step)\n",
    "\n",
    "            #evaluate the accuracy of the network (done on a validation set)\n",
    "            #eval_op, in_image_op, out_image_op, val_summary_op = evaluate(output, x)\n",
    "            eval_op, val_summary_op = evaluate(output, x)\n",
    "\n",
    "            summary_op = tf.summary.merge_all()\n",
    "\n",
    "            #save and restore variables to and from checkpoints.\n",
    "            #saver = tf.train.Saver(max_to_keep=200)\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            #defines a session\n",
    "            sess = tf.Session()\n",
    "\n",
    "            # summary writer\n",
    "            #https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter\n",
    "            #train_writer = tf.summary.FileWriter(log_files_path+'mnist_autoencoder_hidden_' + n_code + '_logs/', graph=sess.graph)\n",
    "\n",
    "            #val_writer   = tf.summary.FileWriter(log_files_path+'mnist_autoencoder_hidden_' + n_code + '_logs/', graph=sess.graph)\n",
    "\n",
    "            #initialization of the variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "\n",
    "            sess.run(init_op)\n",
    "            currentmin=10000000000\n",
    "            currentmin_index=-1\n",
    "            error_path=[]\n",
    "            togive10=[]\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                #total_batch = int(numberofsamples/batch_size)\n",
    "                \n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "                    \n",
    "                    minibatch_x= trainset[i]\n",
    "                    \n",
    "                    # Fit training using batch data\n",
    "                    #the training is done using the training dataset\n",
    "                    _, new_cost, train_summary = sess.run([train_op, cost, train_summary_op], feed_dict={x: minibatch_x, phase_train: True})\n",
    "                    \n",
    "                    #train_writer.add_summary(train_summary, sess.run(global_step))\n",
    "                    \n",
    "                    # Compute average loss\n",
    "                    avg_cost += new_cost/total_batch\n",
    "                    \n",
    "                \n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print(\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:0.9f}\".format(avg_cost))\n",
    "\n",
    "                    #the accuracy is evaluated using the validation dataset\n",
    "                    #train_writer.add_summary(train_summary, sess.run(global_step))\n",
    "\n",
    "                    #validation_loss, in_image, out_image, val_summary = sess.run([eval_op, in_image_op, out_image_op, val_summary_op], feed_dict={x: validationset, phase_train: False})\n",
    "                    validation_loss,  val_summary = sess.run([eval_op, val_summary_op], feed_dict={x: validationset, phase_train: False})\n",
    "                    #val_writer.add_summary(in_image, sess.run(global_step))\n",
    "                    #val_writer.add_summary(out_image, sess.run(global_step))\n",
    "                    #val_writer.add_summary(val_summary, sess.run(global_step))\n",
    "                    print(\"Validation Loss:\", validation_loss)\n",
    "                    error_path.append(validation_loss)\n",
    "                    \n",
    "                    if validation_loss<currentmin:\n",
    "                        currentmin=validation_loss\n",
    "                        currentmin_index=epoch\n",
    "                        saver.save(sess, 'C:/Users/yy2895/Desktop/st14-10-14/tmp/model.ckpt')\n",
    "                        togive3=[]\n",
    "                        for i in range(len(d)):\n",
    "                            any_image = d[i].reshape(-1,14)\n",
    "                            output_any_image = sess.run(code,feed_dict={x:any_image,phase_train: False})\n",
    "                            togive3.append(output_any_image)\n",
    "                            \n",
    "                        togive10=togive3\n",
    "                    #save to use later\n",
    "                    #https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "                    #saver.save(sess, log_files_path+'model-checkpoint', global_step=global_step)\n",
    "                    #saver.save(sess, 'C:/Users/yy2895/Desktop/st19-14-19/tmp/model.ckpt')\n",
    "                    \n",
    "\n",
    "            print(\"Optimization Finished!\")\n",
    "\n",
    "            test_loss = sess.run(eval_op, feed_dict={x: testset, phase_train: False})\n",
    "            #nps_loss = sess.run(eval_op, feed_dict={x: mnist.validation.images, phase_train: False})\n",
    "            print(\"Test Loss:\", test_loss)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010266256"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('C:/Users/yy2895/Desktop/update_stresult14-10-14.csv', 'w',newline='') as myfile:\n",
    "     wr = csv.writer(myfile)\n",
    "     for i in range(len(togive3)):\n",
    "        wr.writerow(list(togive3[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.18888506, 0.19898792, 0.329743  , 0.72397375, 0.139016  ,\n",
       "         0.77916986, 0.74029064, 0.347895  , 0.37947345, 0.86553514]],\n",
       "       dtype=float32),\n",
       " array([[0.18292631, 0.17480557, 0.34514594, 0.7184445 , 0.1296512 ,\n",
       "         0.7831607 , 0.741733  , 0.35088143, 0.37724173, 0.86885804]],\n",
       "       dtype=float32),\n",
       " array([[0.17416574, 0.17346913, 0.30567208, 0.7179786 , 0.12849899,\n",
       "         0.78538924, 0.7478609 , 0.33251756, 0.38244033, 0.8679365 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1734374 , 0.19809288, 0.3035711 , 0.70983046, 0.12791628,\n",
       "         0.7880835 , 0.7417218 , 0.31291392, 0.3987469 , 0.86572725]],\n",
       "       dtype=float32),\n",
       " array([[0.167542  , 0.23115537, 0.26456735, 0.70091295, 0.13516732,\n",
       "         0.78852284, 0.7425108 , 0.2774203 , 0.41774914, 0.8648367 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17022698, 0.21831554, 0.2936367 , 0.69640285, 0.1271238 ,\n",
       "         0.78976476, 0.74427676, 0.30264708, 0.4115637 , 0.86856896]],\n",
       "       dtype=float32),\n",
       " array([[0.16287716, 0.21963935, 0.2517285 , 0.69995296, 0.12908617,\n",
       "         0.7850726 , 0.74404025, 0.27545   , 0.41596666, 0.8650445 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16955693, 0.24391733, 0.2998718 , 0.68695647, 0.13066384,\n",
       "         0.7751419 , 0.7419336 , 0.29513764, 0.4270334 , 0.8654127 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1603826 , 0.22514717, 0.2666971 , 0.68900806, 0.12498295,\n",
       "         0.78648853, 0.74648297, 0.28095013, 0.4228976 , 0.8676156 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16912203, 0.23502547, 0.30549815, 0.678538  , 0.1258399 ,\n",
       "         0.78645444, 0.74292576, 0.29710844, 0.4252002 , 0.8691701 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16720738, 0.28657275, 0.27254936, 0.67303187, 0.1393742 ,\n",
       "         0.7752335 , 0.7457291 , 0.26990947, 0.4499767 , 0.8661126 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15694578, 0.32900923, 0.1704074 , 0.68699527, 0.12591143,\n",
       "         0.78222317, 0.74274707, 0.20430177, 0.4629591 , 0.86174595]],\n",
       "       dtype=float32),\n",
       " array([[0.14916004, 0.29577422, 0.14817546, 0.6897493 , 0.12091761,\n",
       "         0.7862835 , 0.74820185, 0.19828998, 0.45633146, 0.86380523]],\n",
       "       dtype=float32),\n",
       " array([[0.14614384, 0.3170191 , 0.11615468, 0.6852792 , 0.10142923,\n",
       "         0.7951213 , 0.7491504 , 0.17424226, 0.47319192, 0.862307  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15527904, 0.33560485, 0.1485554 , 0.6797341 , 0.12058297,\n",
       "         0.7795387 , 0.7434284 , 0.17962034, 0.48003644, 0.85991883]],\n",
       "       dtype=float32),\n",
       " array([[0.15380692, 0.38018396, 0.10088784, 0.6794645 , 0.11487198,\n",
       "         0.76987296, 0.73886096, 0.14925693, 0.49995673, 0.8580186 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16315654, 0.26352876, 0.28086522, 0.68459463, 0.13471027,\n",
       "         0.77556926, 0.7457096 , 0.29480746, 0.42879966, 0.8675554 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15891348, 0.30118725, 0.21562918, 0.6765122 , 0.1222944 ,\n",
       "         0.7792472 , 0.7514169 , 0.26219255, 0.4485683 , 0.8659722 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16357268, 0.25695843, 0.31892198, 0.67314005, 0.1248035 ,\n",
       "         0.77461123, 0.7508376 , 0.32263157, 0.43146193, 0.8675369 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16082102, 0.2946374 , 0.24709202, 0.6693065 , 0.12259968,\n",
       "         0.7838927 , 0.74742705, 0.26440042, 0.45285735, 0.86687547]],\n",
       "       dtype=float32),\n",
       " array([[0.16005854, 0.33387253, 0.18105498, 0.6657519 , 0.1214419 ,\n",
       "         0.7771643 , 0.74591726, 0.21464112, 0.47377473, 0.8679304 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16134979, 0.3074541 , 0.21974084, 0.6689958 , 0.12137145,\n",
       "         0.7824197 , 0.747594  , 0.2522706 , 0.45467335, 0.8698071 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14928089, 0.282272  , 0.21081209, 0.6818765 , 0.10248968,\n",
       "         0.7958098 , 0.748269  , 0.26219526, 0.44282445, 0.8640975 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14771749, 0.2458675 , 0.2687582 , 0.6797488 , 0.09360366,\n",
       "         0.79887855, 0.7481251 , 0.30427322, 0.42642036, 0.8660979 ]],\n",
       "       dtype=float32),\n",
       " array([[0.13928723, 0.2878782 , 0.12126153, 0.6879004 , 0.08488438,\n",
       "         0.8104586 , 0.7537801 , 0.18800992, 0.47582832, 0.8561612 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15740108, 0.28853405, 0.20523982, 0.69003004, 0.12696905,\n",
       "         0.77673244, 0.7435645 , 0.24183916, 0.4423796 , 0.8649337 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16692285, 0.24348563, 0.34909004, 0.6813595 , 0.12955518,\n",
       "         0.76849747, 0.7431033 , 0.32853648, 0.41945297, 0.8693382 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16393425, 0.26226258, 0.27781138, 0.6898163 , 0.13881992,\n",
       "         0.7704666 , 0.74312806, 0.2804316 , 0.4329353 , 0.86361194]],\n",
       "       dtype=float32),\n",
       " array([[0.15454732, 0.2863564 , 0.17451765, 0.6830114 , 0.11828838,\n",
       "         0.78240085, 0.7427513 , 0.21364595, 0.45504504, 0.8653989 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14811735, 0.27073374, 0.19759718, 0.68354243, 0.10262903,\n",
       "         0.7977515 , 0.74471945, 0.24429874, 0.44262657, 0.86555666]],\n",
       "       dtype=float32),\n",
       " array([[0.16192536, 0.24322848, 0.29767194, 0.67147636, 0.12467223,\n",
       "         0.78438985, 0.7474204 , 0.30253333, 0.42740366, 0.8720464 ]],\n",
       "       dtype=float32),\n",
       " array([[0.164008  , 0.24712346, 0.29021257, 0.6854098 , 0.12682684,\n",
       "         0.7774528 , 0.7471156 , 0.30427408, 0.42422825, 0.8675405 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15377331, 0.25923514, 0.21649337, 0.700374  , 0.1140615 ,\n",
       "         0.7807    , 0.7459954 , 0.26736462, 0.42815903, 0.86140424]],\n",
       "       dtype=float32),\n",
       " array([[0.16174282, 0.23614769, 0.3505618 , 0.6724511 , 0.11071815,\n",
       "         0.7868687 , 0.7468211 , 0.3287516 , 0.42502448, 0.8700927 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16110566, 0.20654733, 0.3728543 , 0.66735625, 0.10165609,\n",
       "         0.79097533, 0.74816644, 0.34430346, 0.41219148, 0.87357193]],\n",
       "       dtype=float32),\n",
       " array([[0.16070904, 0.20153217, 0.34018672, 0.6745811 , 0.11486763,\n",
       "         0.7866527 , 0.7465946 , 0.32073286, 0.41600406, 0.8706929 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15495466, 0.20592886, 0.30605993, 0.68762624, 0.10213055,\n",
       "         0.79076546, 0.7450186 , 0.30921742, 0.41558772, 0.86746186]],\n",
       "       dtype=float32),\n",
       " array([[0.15524188, 0.22941533, 0.2604061 , 0.69416064, 0.11237581,\n",
       "         0.7899145 , 0.7450743 , 0.2843367 , 0.42265025, 0.8668812 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16390613, 0.18631506, 0.36202073, 0.67787355, 0.11154924,\n",
       "         0.78917927, 0.74718904, 0.3276581 , 0.41176656, 0.8712915 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15157016, 0.19503868, 0.3013462 , 0.68894565, 0.09787306,\n",
       "         0.7858142 , 0.7447877 , 0.30122685, 0.41805625, 0.8650479 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1511173 , 0.24008991, 0.24449922, 0.69797295, 0.10510938,\n",
       "         0.7878594 , 0.74390113, 0.27300605, 0.43112227, 0.86089844]],\n",
       "       dtype=float32),\n",
       " array([[0.15582608, 0.2597173 , 0.20715763, 0.69713587, 0.12527691,\n",
       "         0.7874202 , 0.74291867, 0.23958117, 0.43848017, 0.8647414 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15980436, 0.2462695 , 0.26101905, 0.69214934, 0.12595794,\n",
       "         0.78016984, 0.7449482 , 0.2757778 , 0.43162653, 0.86566687]],\n",
       "       dtype=float32),\n",
       " array([[0.16829804, 0.21729262, 0.3286745 , 0.6899603 , 0.13478032,\n",
       "         0.7694316 , 0.74023145, 0.29881537, 0.42176622, 0.866825  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16034056, 0.19444618, 0.31023473, 0.68581927, 0.12066939,\n",
       "         0.7803855 , 0.74274725, 0.29701346, 0.41446355, 0.8689163 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17402269, 0.17749913, 0.44218692, 0.6609273 , 0.10618459,\n",
       "         0.78603315, 0.7452661 , 0.34801933, 0.41342482, 0.87234634]],\n",
       "       dtype=float32),\n",
       " array([[0.1707041 , 0.21369092, 0.3991489 , 0.6597487 , 0.10335406,\n",
       "         0.788651  , 0.74689996, 0.3361448 , 0.42335457, 0.87173045]],\n",
       "       dtype=float32),\n",
       " array([[0.17482744, 0.2684964 , 0.33915886, 0.6776291 , 0.14749935,\n",
       "         0.764472  , 0.73894155, 0.29254243, 0.44076234, 0.86717224]],\n",
       "       dtype=float32),\n",
       " array([[0.18027648, 0.20803556, 0.41159528, 0.6752409 , 0.12106162,\n",
       "         0.76838905, 0.7403129 , 0.33057776, 0.42029393, 0.870642  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16325873, 0.21415746, 0.30334613, 0.6902843 , 0.12120871,\n",
       "         0.7813576 , 0.7431677 , 0.29474533, 0.41833436, 0.8691687 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16562736, 0.2564096 , 0.3014028 , 0.6790388 , 0.12546284,\n",
       "         0.78797615, 0.7419843 , 0.28189585, 0.43982652, 0.8675341 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15137377, 0.25815597, 0.19129373, 0.7033353 , 0.11677287,\n",
       "         0.7923658 , 0.7421575 , 0.23747541, 0.43625447, 0.86200213]],\n",
       "       dtype=float32),\n",
       " array([[0.18658909, 0.20626636, 0.3796528 , 0.6996547 , 0.13312066,\n",
       "         0.769711  , 0.7367894 , 0.3313899 , 0.4048281 , 0.8686762 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16701286, 0.2391407 , 0.34577265, 0.6773023 , 0.11526413,\n",
       "         0.7691395 , 0.7377312 , 0.29315707, 0.43899554, 0.8649365 ]],\n",
       "       dtype=float32),\n",
       " array([[0.20037113, 0.21420872, 0.42096034, 0.69522744, 0.14420228,\n",
       "         0.74728334, 0.74076825, 0.35435256, 0.4035952 , 0.8714078 ]],\n",
       "       dtype=float32),\n",
       " array([[0.171598  , 0.21684857, 0.34849474, 0.6811821 , 0.14004657,\n",
       "         0.77341276, 0.7397635 , 0.29042813, 0.43460372, 0.8653612 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14377649, 0.25847685, 0.2162353 , 0.67855465, 0.13155843,\n",
       "         0.79288584, 0.74149245, 0.21862623, 0.4594079 , 0.86675346]],\n",
       "       dtype=float32),\n",
       " array([[0.15334442, 0.24102195, 0.25020215, 0.68176   , 0.12010662,\n",
       "         0.78283393, 0.75121284, 0.26309034, 0.44614092, 0.8668948 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14581087, 0.22992022, 0.23919556, 0.677089  , 0.10516439,\n",
       "         0.7936837 , 0.7528094 , 0.26146343, 0.44103038, 0.8697276 ]],\n",
       "       dtype=float32),\n",
       " array([[0.12466045, 0.21434282, 0.17646886, 0.6869405 , 0.07833123,\n",
       "         0.81061554, 0.75108635, 0.22857355, 0.44428438, 0.865362  ]],\n",
       "       dtype=float32),\n",
       " array([[0.12733118, 0.27198854, 0.13021763, 0.6906949 , 0.08523192,\n",
       "         0.81958026, 0.74631715, 0.1920603 , 0.46694547, 0.8568938 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14467812, 0.22885343, 0.20297894, 0.6835932 , 0.12703037,\n",
       "         0.78647757, 0.74947804, 0.23555581, 0.4437164 , 0.8665451 ]],\n",
       "       dtype=float32),\n",
       " array([[0.18846603, 0.15319183, 0.47185233, 0.67386496, 0.11481982,\n",
       "         0.78013265, 0.7458837 , 0.3600989 , 0.39933574, 0.8748703 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17530473, 0.21956037, 0.28415477, 0.70393115, 0.15646417,\n",
       "         0.7608484 , 0.7494991 , 0.3004437 , 0.4147411 , 0.86326104]],\n",
       "       dtype=float32),\n",
       " array([[0.1497605 , 0.2371994 , 0.23833935, 0.67781186, 0.10642652,\n",
       "         0.7950939 , 0.74825346, 0.2650289 , 0.43620306, 0.86996716]],\n",
       "       dtype=float32),\n",
       " array([[0.14707138, 0.1633327 , 0.32370716, 0.662654  , 0.07561462,\n",
       "         0.8119974 , 0.7465208 , 0.2846591 , 0.41997895, 0.8790367 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17506918, 0.21500511, 0.35636944, 0.6739872 , 0.11315887,\n",
       "         0.78644156, 0.7460171 , 0.3173495 , 0.41979706, 0.87426597]],\n",
       "       dtype=float32),\n",
       " array([[0.2134651 , 0.19710772, 0.45763326, 0.69289404, 0.14600949,\n",
       "         0.7528528 , 0.7453686 , 0.3825137 , 0.38844407, 0.8767043 ]],\n",
       "       dtype=float32),\n",
       " array([[0.21433507, 0.22062239, 0.40485737, 0.732532  , 0.12902167,\n",
       "         0.7367309 , 0.7369308 , 0.3783643 , 0.37879953, 0.8702876 ]],\n",
       "       dtype=float32),\n",
       " array([[0.18660788, 0.26375207, 0.3584758 , 0.70436084, 0.09912328,\n",
       "         0.76673704, 0.73807347, 0.33406124, 0.41288444, 0.869783  ]],\n",
       "       dtype=float32),\n",
       " array([[0.17344429, 0.13197827, 0.4294944 , 0.6901681 , 0.07706253,\n",
       "         0.805437  , 0.7486098 , 0.348595  , 0.3834232 , 0.88266426]],\n",
       "       dtype=float32),\n",
       " array([[0.17510957, 0.09960172, 0.4316891 , 0.68126124, 0.11660054,\n",
       "         0.79578114, 0.752196  , 0.3400174 , 0.3771921 , 0.8825724 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16209973, 0.18172264, 0.339985  , 0.67536443, 0.13494387,\n",
       "         0.78180367, 0.7467102 , 0.27423477, 0.4404917 , 0.86766773]],\n",
       "       dtype=float32),\n",
       " array([[0.12630315, 0.26411524, 0.14938621, 0.7210453 , 0.09597753,\n",
       "         0.80044514, 0.7348165 , 0.20081683, 0.45657462, 0.8476112 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14051889, 0.22270079, 0.22411734, 0.7038622 , 0.08391696,\n",
       "         0.80916715, 0.7378963 , 0.24242772, 0.44974133, 0.8532173 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1261796 , 0.21753602, 0.16788125, 0.7042213 , 0.09859511,\n",
       "         0.8029132 , 0.7381516 , 0.20661609, 0.45042378, 0.85323167]],\n",
       "       dtype=float32),\n",
       " array([[0.10700893, 0.2721429 , 0.083245  , 0.72519135, 0.08220629,\n",
       "         0.8168144 , 0.743742  , 0.16265911, 0.4657236 , 0.841605  ]],\n",
       "       dtype=float32),\n",
       " array([[0.11987725, 0.33862635, 0.04872878, 0.7249579 , 0.09858228,\n",
       "         0.8071268 , 0.7538417 , 0.12879747, 0.4796335 , 0.8375465 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15772669, 0.33216515, 0.18234886, 0.6956833 , 0.14935695,\n",
       "         0.75601435, 0.74981594, 0.2566945 , 0.44867375, 0.85841376]],\n",
       "       dtype=float32),\n",
       " array([[0.18314399, 0.21006171, 0.33894292, 0.67336416, 0.20424928,\n",
       "         0.7448236 , 0.7500864 , 0.30873942, 0.42062962, 0.8715523 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1563259 , 0.21061914, 0.18437825, 0.6799381 , 0.17252669,\n",
       "         0.78547186, 0.7478307 , 0.22224076, 0.431866  , 0.86854273]],\n",
       "       dtype=float32),\n",
       " array([[0.15009041, 0.2530534 , 0.20347989, 0.662528  , 0.11894651,\n",
       "         0.8207336 , 0.7498465 , 0.25387555, 0.4355264 , 0.8761358 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14930825, 0.26634568, 0.17998478, 0.6500069 , 0.11442941,\n",
       "         0.8269255 , 0.7542114 , 0.24198544, 0.44564354, 0.8808404 ]],\n",
       "       dtype=float32),\n",
       " array([[0.18233663, 0.28764278, 0.27086857, 0.6490923 , 0.2149406 ,\n",
       "         0.7406334 , 0.74889845, 0.24197084, 0.47630796, 0.87039226]],\n",
       "       dtype=float32),\n",
       " array([[0.14712991, 0.27767533, 0.17035753, 0.685954  , 0.14509647,\n",
       "         0.77976686, 0.7444702 , 0.2218137 , 0.4413314 , 0.8680185 ]],\n",
       "       dtype=float32),\n",
       " array([[0.12993018, 0.33192304, 0.06913172, 0.6880181 , 0.11112479,\n",
       "         0.7875225 , 0.7437362 , 0.14076026, 0.4861472 , 0.8553949 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1507332 , 0.53310317, 0.04452248, 0.59593284, 0.16789682,\n",
       "         0.67627394, 0.7278027 , 0.15462269, 0.6018018 , 0.8663058 ]],\n",
       "       dtype=float32),\n",
       " array([[0.13418394, 0.42882088, 0.03272622, 0.66402805, 0.12920874,\n",
       "         0.73650914, 0.7403136 , 0.14640886, 0.5367229 , 0.8556729 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15638308, 0.46102977, 0.04414897, 0.642901  , 0.20194624,\n",
       "         0.6626406 , 0.7294911 , 0.1690271 , 0.55898243, 0.85599554]],\n",
       "       dtype=float32),\n",
       " array([[0.16990498, 0.29780853, 0.3269032 , 0.6925919 , 0.1422112 ,\n",
       "         0.77913815, 0.75079894, 0.30015436, 0.41266996, 0.86530983]],\n",
       "       dtype=float32),\n",
       " array([[0.17813319, 0.267935  , 0.415731  , 0.6834218 , 0.13608697,\n",
       "         0.7706063 , 0.7494948 , 0.34947193, 0.4016666 , 0.86887026]],\n",
       "       dtype=float32),\n",
       " array([[0.17348014, 0.31301522, 0.28858605, 0.6731559 , 0.14628725,\n",
       "         0.7728074 , 0.756034  , 0.28297114, 0.43197095, 0.8691926 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16511291, 0.31713152, 0.2936893 , 0.6683975 , 0.11116598,\n",
       "         0.810972  , 0.7543388 , 0.30005774, 0.42535448, 0.8753834 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16483949, 0.29377627, 0.315135  , 0.6648738 , 0.10933534,\n",
       "         0.8132649 , 0.75436777, 0.31404772, 0.41760305, 0.87754977]],\n",
       "       dtype=float32),\n",
       " array([[0.18074147, 0.27222687, 0.45467785, 0.65415406, 0.10319027,\n",
       "         0.8230665 , 0.75561744, 0.38306084, 0.39415213, 0.8872043 ]],\n",
       "       dtype=float32),\n",
       " array([[0.18053976, 0.2896028 , 0.44458497, 0.6723984 , 0.11460919,\n",
       "         0.7948247 , 0.73928255, 0.33753562, 0.4296516 , 0.8642163 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14789833, 0.25954   , 0.25990415, 0.70173764, 0.0771177 ,\n",
       "         0.8170618 , 0.7433927 , 0.29157832, 0.41304082, 0.86271054]],\n",
       "       dtype=float32),\n",
       " array([[0.14858966, 0.25264975, 0.2738064 , 0.70807403, 0.06233503,\n",
       "         0.81514484, 0.7453845 , 0.31986955, 0.39725438, 0.86755896]],\n",
       "       dtype=float32),\n",
       " array([[0.16429952, 0.2758077 , 0.32382533, 0.70487463, 0.09250662,\n",
       "         0.7758966 , 0.7391215 , 0.31682545, 0.41634965, 0.85894704]],\n",
       "       dtype=float32),\n",
       " array([[0.17987241, 0.23082149, 0.42010853, 0.70542794, 0.09572633,\n",
       "         0.751634  , 0.7373347 , 0.34630063, 0.40801844, 0.8611229 ]],\n",
       "       dtype=float32),\n",
       " array([[0.18298784, 0.23092845, 0.45706952, 0.7114068 , 0.06620568,\n",
       "         0.7514535 , 0.72509813, 0.3548681 , 0.40624318, 0.8600669 ]],\n",
       "       dtype=float32),\n",
       " array([[0.18760225, 0.22094676, 0.4253801 , 0.69289577, 0.1302519 ,\n",
       "         0.7682908 , 0.7392613 , 0.34282508, 0.40470982, 0.8691038 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1672627 , 0.2623483 , 0.23551463, 0.6943901 , 0.16282466,\n",
       "         0.78651756, 0.74556357, 0.23889516, 0.43949658, 0.8622178 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15484358, 0.2843739 , 0.14539236, 0.7174726 , 0.14592518,\n",
       "         0.7760332 , 0.74820805, 0.20171526, 0.4402731 , 0.8527428 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15001597, 0.3318503 , 0.09708837, 0.6891996 , 0.12611033,\n",
       "         0.78492063, 0.74686176, 0.16066818, 0.4891578 , 0.85384387]],\n",
       "       dtype=float32),\n",
       " array([[0.12150486, 0.46504906, 0.0034235 , 0.6630488 , 0.16641001,\n",
       "         0.6615687 , 0.7420123 , 0.10544777, 0.5915346 , 0.8579525 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17866667, 0.26912364, 0.3917306 , 0.6935623 , 0.1322418 ,\n",
       "         0.7952497 , 0.74413836, 0.3129744 , 0.42199978, 0.8601883 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15731198, 0.23697789, 0.27396622, 0.69579273, 0.14036189,\n",
       "         0.79174364, 0.7499552 , 0.2656307 , 0.41304675, 0.8673776 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17153239, 0.25415975, 0.30533803, 0.6821086 , 0.17425416,\n",
       "         0.7674757 , 0.7502025 , 0.25310248, 0.43687508, 0.86517733]],\n",
       "       dtype=float32),\n",
       " array([[0.18735176, 0.21459903, 0.45006585, 0.6871413 , 0.19670032,\n",
       "         0.7454918 , 0.75174326, 0.34276065, 0.40632004, 0.8690285 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16783689, 0.21150896, 0.3458468 , 0.6730317 , 0.172663  ,\n",
       "         0.7772649 , 0.75026923, 0.2709578 , 0.4286383 , 0.87303233]],\n",
       "       dtype=float32),\n",
       " array([[0.17203844, 0.33738998, 0.1600753 , 0.62093073, 0.22080696,\n",
       "         0.6724072 , 0.72969705, 0.24387501, 0.5252079 , 0.877111  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15581071, 0.37854666, 0.07657054, 0.63161576, 0.11855422,\n",
       "         0.735058  , 0.73564625, 0.16544819, 0.54138535, 0.86592895]],\n",
       "       dtype=float32),\n",
       " array([[0.14572585, 0.33200297, 0.11198304, 0.67449874, 0.07762928,\n",
       "         0.81131697, 0.747405  , 0.16625133, 0.47317237, 0.8637334 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14842907, 0.24592061, 0.27011722, 0.6970988 , 0.0902999 ,\n",
       "         0.82922405, 0.7502921 , 0.28677997, 0.40103146, 0.8698225 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16122067, 0.22201754, 0.32775024, 0.7114485 , 0.11846174,\n",
       "         0.7873817 , 0.74763066, 0.3136967 , 0.39335558, 0.8593102 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15778218, 0.21386473, 0.33959687, 0.70985496, 0.1042012 ,\n",
       "         0.79654217, 0.7494976 , 0.3332791 , 0.38608614, 0.86535645]],\n",
       "       dtype=float32),\n",
       " array([[0.16787694, 0.24434738, 0.34151313, 0.6970442 , 0.13337815,\n",
       "         0.79142994, 0.74684745, 0.30181047, 0.40810618, 0.86752146]],\n",
       "       dtype=float32),\n",
       " array([[0.15977278, 0.3023836 , 0.19584043, 0.66453886, 0.11910285,\n",
       "         0.78288007, 0.74826145, 0.20845078, 0.4667316 , 0.868477  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15913281, 0.22736897, 0.318178  , 0.68721205, 0.11191589,\n",
       "         0.80757254, 0.7487106 , 0.30505863, 0.40650985, 0.87223643]],\n",
       "       dtype=float32),\n",
       " array([[0.14656253, 0.24777064, 0.24946153, 0.69638985, 0.08719887,\n",
       "         0.82244223, 0.74429137, 0.27828404, 0.4099757 , 0.8679111 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15274718, 0.23022667, 0.3100355 , 0.6832213 , 0.09154486,\n",
       "         0.82086915, 0.7512222 , 0.31116283, 0.4123244 , 0.8684699 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14564985, 0.21817419, 0.2820444 , 0.7035874 , 0.07613492,\n",
       "         0.8196436 , 0.75045186, 0.3169466 , 0.40138432, 0.8635997 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15537147, 0.22133535, 0.3025722 , 0.7173136 , 0.08845548,\n",
       "         0.78829306, 0.7553873 , 0.34538475, 0.3944344 , 0.86039835]],\n",
       "       dtype=float32),\n",
       " array([[0.14890257, 0.24582785, 0.24003977, 0.7117314 , 0.08841648,\n",
       "         0.8065001 , 0.75400805, 0.3020729 , 0.4134167 , 0.85776746]],\n",
       "       dtype=float32),\n",
       " array([[0.15968315, 0.21616043, 0.3318263 , 0.6945792 , 0.11255918,\n",
       "         0.78967667, 0.747673  , 0.31065843, 0.41299453, 0.8646831 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15210651, 0.2378216 , 0.2245219 , 0.69352823, 0.10427775,\n",
       "         0.81226844, 0.7454257 , 0.24598287, 0.43098804, 0.86612743]],\n",
       "       dtype=float32),\n",
       " array([[0.15621826, 0.24726945, 0.19567674, 0.6982065 , 0.12337071,\n",
       "         0.79595476, 0.74225014, 0.21667501, 0.43755808, 0.86563224]],\n",
       "       dtype=float32),\n",
       " array([[0.16467983, 0.24928382, 0.20684826, 0.6904677 , 0.14556804,\n",
       "         0.7776591 , 0.7409776 , 0.20774367, 0.45203212, 0.8636349 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1616429 , 0.23121338, 0.23276024, 0.71508294, 0.14017037,\n",
       "         0.7781295 , 0.7387612 , 0.24913652, 0.4109951 , 0.8638139 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1642819 , 0.25444093, 0.23144972, 0.70313376, 0.1422534 ,\n",
       "         0.7731661 , 0.7408522 , 0.24185179, 0.4277833 , 0.86224025]],\n",
       "       dtype=float32),\n",
       " array([[0.17162241, 0.20799892, 0.350509  , 0.6894222 , 0.14117102,\n",
       "         0.7747692 , 0.7439293 , 0.3132978 , 0.41170472, 0.8683597 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16308996, 0.20680226, 0.30447397, 0.69226825, 0.12792738,\n",
       "         0.780696  , 0.7441678 , 0.299067  , 0.4099753 , 0.8680244 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17319536, 0.19989663, 0.39398873, 0.6797423 , 0.12941128,\n",
       "         0.782238  , 0.74581075, 0.33960623, 0.4066959 , 0.8732062 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1774097 , 0.17045294, 0.4477321 , 0.6757827 , 0.12138696,\n",
       "         0.7849967 , 0.746973  , 0.365319  , 0.39439714, 0.8766687 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17441966, 0.16703628, 0.42829385, 0.6773126 , 0.11444967,\n",
       "         0.79160774, 0.7474687 , 0.36157015, 0.38928485, 0.87932986]],\n",
       "       dtype=float32),\n",
       " array([[0.18184578, 0.16471271, 0.48526403, 0.67198426, 0.10153873,\n",
       "         0.79651994, 0.7464112 , 0.3823714 , 0.38747618, 0.8808062 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17508076, 0.18943205, 0.44889113, 0.66934496, 0.09501649,\n",
       "         0.8058659 , 0.73981094, 0.3545433 , 0.40355968, 0.8767564 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16752444, 0.21064033, 0.38398975, 0.6798423 , 0.10477001,\n",
       "         0.7965763 , 0.74208254, 0.32497612, 0.41619474, 0.8718213 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17015351, 0.19263859, 0.41768843, 0.6933962 , 0.07564507,\n",
       "         0.79338694, 0.73648137, 0.34255895, 0.4092737 , 0.86785674]],\n",
       "       dtype=float32),\n",
       " array([[0.1686136 , 0.2345219 , 0.35275605, 0.7022121 , 0.10772276,\n",
       "         0.76623267, 0.7375867 , 0.30981135, 0.42946088, 0.8579331 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15650105, 0.20582199, 0.2942577 , 0.7148933 , 0.09466611,\n",
       "         0.78129166, 0.73836946, 0.29393044, 0.41807568, 0.8578964 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15753274, 0.21119632, 0.28109846, 0.7032155 , 0.1212438 ,\n",
       "         0.7796109 , 0.742734  , 0.27983552, 0.42372793, 0.86176   ]],\n",
       "       dtype=float32),\n",
       " array([[0.16204703, 0.24267773, 0.26399028, 0.7017575 , 0.13526951,\n",
       "         0.77222425, 0.7434324 , 0.27429968, 0.43074673, 0.86122316]],\n",
       "       dtype=float32),\n",
       " array([[0.1549437 , 0.2538884 , 0.21360072, 0.7064223 , 0.13358276,\n",
       "         0.7788086 , 0.74623704, 0.25451055, 0.43324444, 0.86012346]],\n",
       "       dtype=float32),\n",
       " array([[0.16826265, 0.28950018, 0.21993685, 0.69641197, 0.17325777,\n",
       "         0.7637138 , 0.745325  , 0.23562214, 0.44913664, 0.8596761 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1688056 , 0.27319986, 0.24787039, 0.695414  , 0.14760968,\n",
       "         0.77073073, 0.74645555, 0.27040997, 0.43792865, 0.8625502 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16926248, 0.25199372, 0.29280937, 0.68869007, 0.12986057,\n",
       "         0.77391165, 0.7452788 , 0.29559103, 0.43125898, 0.86462873]],\n",
       "       dtype=float32),\n",
       " array([[0.17770877, 0.256662  , 0.31102988, 0.6853361 , 0.14907198,\n",
       "         0.7516019 , 0.74652755, 0.3060605 , 0.43182704, 0.8633706 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16565195, 0.2745008 , 0.24538033, 0.6830002 , 0.14152102,\n",
       "         0.7799104 , 0.7465501 , 0.26482335, 0.44116655, 0.8667182 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1544626 , 0.24604523, 0.20030496, 0.69322   , 0.13495211,\n",
       "         0.78913873, 0.7442744 , 0.23253861, 0.4366256 , 0.8652441 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16989528, 0.26420096, 0.2548655 , 0.6759481 , 0.15059257,\n",
       "         0.7794586 , 0.74588645, 0.2574718 , 0.44428477, 0.8690412 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15457681, 0.266059  , 0.15475321, 0.6864739 , 0.15076523,\n",
       "         0.7812081 , 0.74375165, 0.19270147, 0.45480224, 0.86780435]],\n",
       "       dtype=float32),\n",
       " array([[0.15182449, 0.29894614, 0.11892249, 0.67969424, 0.1312599 ,\n",
       "         0.7788184 , 0.7452891 , 0.17585152, 0.47301853, 0.8664812 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16027658, 0.22132736, 0.31533948, 0.6711229 , 0.11049494,\n",
       "         0.8093801 , 0.7443808 , 0.29765764, 0.42455718, 0.87282693]],\n",
       "       dtype=float32),\n",
       " array([[0.1553109 , 0.24928565, 0.26138744, 0.67574936, 0.11230639,\n",
       "         0.79332507, 0.74921227, 0.28535196, 0.4322059 , 0.8678524 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1557712 , 0.21918143, 0.28308782, 0.66937786, 0.1300885 ,\n",
       "         0.7901628 , 0.74926364, 0.27604613, 0.43310767, 0.8696077 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15686773, 0.23482715, 0.27262917, 0.6883939 , 0.11915329,\n",
       "         0.77894425, 0.7491561 , 0.29221147, 0.42414948, 0.86661625]],\n",
       "       dtype=float32),\n",
       " array([[0.17401455, 0.22116679, 0.41099128, 0.6626305 , 0.10033812,\n",
       "         0.7895156 , 0.7491541 , 0.35152835, 0.41748017, 0.8735873 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15589608, 0.22967227, 0.30466673, 0.674785  , 0.09175146,\n",
       "         0.80068576, 0.748121  , 0.30851692, 0.42613557, 0.8672622 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16143093, 0.24984553, 0.3175372 , 0.6780593 , 0.09227264,\n",
       "         0.79707015, 0.74583215, 0.31153792, 0.42941657, 0.8681155 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16420643, 0.2447234 , 0.3460571 , 0.67117375, 0.0938612 ,\n",
       "         0.7987561 , 0.7406908 , 0.30960256, 0.4284405 , 0.8720298 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16676606, 0.21558434, 0.35614902, 0.6854955 , 0.08543855,\n",
       "         0.79858226, 0.7416925 , 0.32158655, 0.41649446, 0.8721337 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17416872, 0.27992663, 0.32274035, 0.69142824, 0.12840891,\n",
       "         0.75864625, 0.7403569 , 0.2986757 , 0.44121572, 0.8612581 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15808924, 0.24183577, 0.2636142 , 0.70721143, 0.11264659,\n",
       "         0.7738294 , 0.73821455, 0.27464887, 0.4288695 , 0.8602054 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15383798, 0.22397502, 0.25724512, 0.6992823 , 0.11794663,\n",
       "         0.787405  , 0.74146247, 0.26745543, 0.42490044, 0.86593443]],\n",
       "       dtype=float32),\n",
       " array([[0.16153188, 0.21399623, 0.28540364, 0.69414365, 0.11281287,\n",
       "         0.78569   , 0.73937774, 0.2862319 , 0.41743058, 0.86844146]],\n",
       "       dtype=float32),\n",
       " array([[0.17044853, 0.1665977 , 0.35079193, 0.6983694 , 0.10908126,\n",
       "         0.77194405, 0.7413431 , 0.3154269 , 0.40388772, 0.8681114 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15454863, 0.15547895, 0.2810568 , 0.70833945, 0.10121648,\n",
       "         0.7864093 , 0.7423137 , 0.28917336, 0.40007898, 0.86679804]],\n",
       "       dtype=float32),\n",
       " array([[0.16658306, 0.16544142, 0.30072293, 0.7000646 , 0.13647139,\n",
       "         0.7761314 , 0.7450228 , 0.29449758, 0.40262917, 0.87013954]],\n",
       "       dtype=float32),\n",
       " array([[0.1686389 , 0.16716446, 0.32332173, 0.6895427 , 0.13028729,\n",
       "         0.7886114 , 0.74678934, 0.30301628, 0.40469146, 0.8733935 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16812484, 0.20192859, 0.29594338, 0.69183016, 0.14278494,\n",
       "         0.77363074, 0.7467822 , 0.28888977, 0.41984537, 0.8679191 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1546844 , 0.22028394, 0.23819433, 0.6931239 , 0.11766921,\n",
       "         0.79877156, 0.7461065 , 0.2663261 , 0.424123  , 0.86864626]],\n",
       "       dtype=float32),\n",
       " array([[0.15207057, 0.25149778, 0.17815427, 0.68918765, 0.1493871 ,\n",
       "         0.79437333, 0.7437878 , 0.20767386, 0.44852298, 0.86397445]],\n",
       "       dtype=float32),\n",
       " array([[0.14712714, 0.29617065, 0.11659068, 0.68344736, 0.13397938,\n",
       "         0.7861755 , 0.7467433 , 0.17340186, 0.4730568 , 0.8622549 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15886836, 0.28279865, 0.1680227 , 0.69108784, 0.16222107,\n",
       "         0.77114475, 0.7468369 , 0.20307584, 0.45679584, 0.86068004]],\n",
       "       dtype=float32),\n",
       " array([[0.15372542, 0.27850837, 0.12859292, 0.6982057 , 0.16293588,\n",
       "         0.76346815, 0.7455703 , 0.18754533, 0.46046895, 0.85625005]],\n",
       "       dtype=float32),\n",
       " array([[0.15902573, 0.27530736, 0.1521571 , 0.69434905, 0.17234284,\n",
       "         0.760442  , 0.7435032 , 0.19871965, 0.4530966 , 0.8602795 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16433576, 0.38136366, 0.10362433, 0.65686095, 0.20951043,\n",
       "         0.7027217 , 0.73614955, 0.2104631 , 0.5243786 , 0.85686   ]],\n",
       "       dtype=float32),\n",
       " array([[0.17812148, 0.326223  , 0.2511179 , 0.6584716 , 0.21954198,\n",
       "         0.71837354, 0.73870355, 0.2656327 , 0.4824697 , 0.86437196]],\n",
       "       dtype=float32),\n",
       " array([[0.17180552, 0.31949025, 0.20972674, 0.65778023, 0.19128227,\n",
       "         0.7274545 , 0.74087685, 0.23906815, 0.47989264, 0.8667378 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16662756, 0.2601489 , 0.2503611 , 0.6790649 , 0.14068997,\n",
       "         0.7729992 , 0.75253755, 0.25971675, 0.43082434, 0.8704085 ]],\n",
       "       dtype=float32),\n",
       " array([[0.18114209, 0.38137144, 0.20908517, 0.6212533 , 0.21035689,\n",
       "         0.68156755, 0.7353611 , 0.2695046 , 0.530179  , 0.86811477]],\n",
       "       dtype=float32),\n",
       " array([[0.1611246 , 0.37128064, 0.12380543, 0.63987774, 0.13485311,\n",
       "         0.7351226 , 0.7441406 , 0.20493102, 0.509852  , 0.86922723]],\n",
       "       dtype=float32),\n",
       " array([[0.1625808 , 0.35894603, 0.17599155, 0.6384951 , 0.12479458,\n",
       "         0.7612814 , 0.74600154, 0.22284448, 0.4937225 , 0.8730093 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15526813, 0.36572242, 0.14676276, 0.66638017, 0.09979471,\n",
       "         0.7872287 , 0.7508158 , 0.20178181, 0.47289512, 0.8662287 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14912811, 0.32849872, 0.15684697, 0.68217933, 0.08695854,\n",
       "         0.80985475, 0.75539553, 0.22161621, 0.44704157, 0.8654277 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15013677, 0.24698202, 0.2908241 , 0.7004389 , 0.0770717 ,\n",
       "         0.82786345, 0.7506433 , 0.324462  , 0.3941804 , 0.8673131 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15884736, 0.25626963, 0.32038417, 0.6947057 , 0.0893327 ,\n",
       "         0.8159361 , 0.7516519 , 0.341168  , 0.391457  , 0.87320346]],\n",
       "       dtype=float32),\n",
       " array([[0.15715694, 0.27022934, 0.28640127, 0.691882  , 0.09761474,\n",
       "         0.8104973 , 0.7506564 , 0.30492595, 0.41338855, 0.8666763 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16727526, 0.29685387, 0.29064828, 0.70094556, 0.12405029,\n",
       "         0.7856849 , 0.7447622 , 0.29030696, 0.42067474, 0.86251456]],\n",
       "       dtype=float32),\n",
       " array([[0.14932567, 0.3188208 , 0.18082952, 0.7052323 , 0.08723628,\n",
       "         0.8147885 , 0.74932325, 0.25659457, 0.42669582, 0.8631112 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15874073, 0.30041018, 0.24784382, 0.69929427, 0.09925039,\n",
       "         0.8018745 , 0.7475384 , 0.29142535, 0.4213786 , 0.8633246 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1519818 , 0.27043524, 0.25467572, 0.69550747, 0.08366137,\n",
       "         0.81587356, 0.75000155, 0.30134267, 0.4173818 , 0.8646491 ]],\n",
       "       dtype=float32),\n",
       " array([[0.13297409, 0.27749988, 0.16908938, 0.6992695 , 0.07379477,\n",
       "         0.8262532 , 0.74777246, 0.23485208, 0.4352116 , 0.8595229 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16317241, 0.2925156 , 0.24460907, 0.7027888 , 0.11378179,\n",
       "         0.78885823, 0.7397533 , 0.25906172, 0.43390682, 0.8585569 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1669456 , 0.2717755 , 0.27054748, 0.70097625, 0.13290809,\n",
       "         0.77263874, 0.7457307 , 0.2820502 , 0.42508316, 0.862206  ]],\n",
       "       dtype=float32),\n",
       " array([[0.17259586, 0.23377669, 0.36859497, 0.69804317, 0.12323091,\n",
       "         0.76309717, 0.74161536, 0.33449513, 0.40708578, 0.86597735]],\n",
       "       dtype=float32),\n",
       " array([[0.15449728, 0.24531783, 0.24806096, 0.6965892 , 0.105313  ,\n",
       "         0.7943006 , 0.7466484 , 0.27507663, 0.42448404, 0.86252326]],\n",
       "       dtype=float32),\n",
       " array([[0.15480426, 0.249303  , 0.22386938, 0.67660326, 0.11046406,\n",
       "         0.80111206, 0.7466819 , 0.23965745, 0.44285887, 0.8690958 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16162206, 0.23514163, 0.28517696, 0.6825879 , 0.12221171,\n",
       "         0.79183215, 0.74577117, 0.28324628, 0.42270428, 0.8716869 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17415588, 0.20539619, 0.42791235, 0.6782397 , 0.10754026,\n",
       "         0.78642845, 0.7444976 , 0.35424584, 0.4069299 , 0.8723899 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17189933, 0.20931278, 0.38819504, 0.6881036 , 0.11829117,\n",
       "         0.7660495 , 0.74351525, 0.33774105, 0.4105887 , 0.86627424]],\n",
       "       dtype=float32),\n",
       " array([[0.16406445, 0.19806084, 0.34653503, 0.69816536, 0.10754212,\n",
       "         0.7767897 , 0.7421033 , 0.32142454, 0.4065668 , 0.8658849 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15314303, 0.22237067, 0.2788339 , 0.68537396, 0.10149307,\n",
       "         0.8041853 , 0.7474096 , 0.28785402, 0.4226062 , 0.8684165 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16293707, 0.2717784 , 0.26146233, 0.68650496, 0.1215817 ,\n",
       "         0.79337335, 0.7451056 , 0.27167067, 0.43629918, 0.8680168 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16567507, 0.233852  , 0.293819  , 0.70054305, 0.11520198,\n",
       "         0.7801172 , 0.7470633 , 0.3078184 , 0.4171789 , 0.8650799 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15172231, 0.24174322, 0.25653708, 0.69981354, 0.0960513 ,\n",
       "         0.79339004, 0.74401706, 0.27937818, 0.42967665, 0.8591801 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15750077, 0.24771099, 0.24213667, 0.70009947, 0.11814732,\n",
       "         0.79207915, 0.744395  , 0.2617237 , 0.43139994, 0.86371255]],\n",
       "       dtype=float32),\n",
       " array([[0.15510447, 0.2244312 , 0.2273073 , 0.69651234, 0.12048914,\n",
       "         0.7964966 , 0.74361396, 0.24989505, 0.4251121 , 0.8682457 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15538684, 0.23219721, 0.21755537, 0.69837594, 0.12546861,\n",
       "         0.78292197, 0.7492463 , 0.25057158, 0.43209404, 0.86216956]],\n",
       "       dtype=float32),\n",
       " array([[0.16267736, 0.27215278, 0.21823628, 0.6909335 , 0.14280267,\n",
       "         0.77724236, 0.7428486 , 0.2264123 , 0.4485854 , 0.8628095 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16166404, 0.25360185, 0.23257007, 0.6963707 , 0.13661742,\n",
       "         0.77264684, 0.7447716 , 0.25678426, 0.43071172, 0.8644894 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16690706, 0.28287545, 0.23409803, 0.67961013, 0.13344309,\n",
       "         0.7747607 , 0.7411133 , 0.23967218, 0.45036685, 0.8642898 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16051391, 0.2251483 , 0.2846423 , 0.67291033, 0.13307595,\n",
       "         0.7878226 , 0.74206376, 0.26425442, 0.43324417, 0.8708356 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16331083, 0.2505709 , 0.25738186, 0.67230403, 0.13269319,\n",
       "         0.7783117 , 0.74554265, 0.25437355, 0.44573367, 0.86714417]],\n",
       "       dtype=float32),\n",
       " array([[0.15727596, 0.2152276 , 0.26692525, 0.68076783, 0.11756731,\n",
       "         0.78925383, 0.7501898 , 0.28118935, 0.42768505, 0.86799425]],\n",
       "       dtype=float32),\n",
       " array([[0.16472834, 0.22591612, 0.33146986, 0.67343307, 0.11832621,\n",
       "         0.7842851 , 0.74859124, 0.3149757 , 0.42336446, 0.87123686]],\n",
       "       dtype=float32),\n",
       " array([[0.17111847, 0.19693686, 0.39308298, 0.67495847, 0.1049948 ,\n",
       "         0.7832418 , 0.74628556, 0.3459927 , 0.40969226, 0.8723983 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16429576, 0.18007414, 0.34893972, 0.67976373, 0.10926905,\n",
       "         0.79114527, 0.7499826 , 0.32994285, 0.404801  , 0.87401545]],\n",
       "       dtype=float32),\n",
       " array([[0.1535652 , 0.17212988, 0.3116243 , 0.6847108 , 0.0910132 ,\n",
       "         0.8092141 , 0.7494554 , 0.3127274 , 0.40444374, 0.87325364]],\n",
       "       dtype=float32),\n",
       " array([[0.16517395, 0.22906804, 0.31566218, 0.68106425, 0.1172797 ,\n",
       "         0.7878557 , 0.7475949 , 0.3028035 , 0.42812055, 0.86862826]],\n",
       "       dtype=float32),\n",
       " array([[0.15363489, 0.22279179, 0.253667  , 0.69073355, 0.10660252,\n",
       "         0.7985911 , 0.74471986, 0.2760837 , 0.4232092 , 0.86910224]],\n",
       "       dtype=float32),\n",
       " array([[0.16751125, 0.21347226, 0.33352792, 0.69337034, 0.11533672,\n",
       "         0.77089655, 0.73821944, 0.30481303, 0.4180943 , 0.86670035]],\n",
       "       dtype=float32),\n",
       " array([[0.1489266 , 0.18275292, 0.29633942, 0.6891754 , 0.07617107,\n",
       "         0.8069711 , 0.744745  , 0.30115077, 0.41625983, 0.86383337]],\n",
       "       dtype=float32),\n",
       " array([[0.15286046, 0.22199461, 0.2774473 , 0.69760823, 0.08559813,\n",
       "         0.7848928 , 0.74637926, 0.29831988, 0.42592096, 0.8592537 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16726002, 0.22515468, 0.30082896, 0.69302917, 0.12396271,\n",
       "         0.77509105, 0.7444039 , 0.29379544, 0.42729238, 0.86397624]],\n",
       "       dtype=float32),\n",
       " array([[0.16539414, 0.19991164, 0.30604902, 0.6986125 , 0.12918484,\n",
       "         0.76510024, 0.74481297, 0.29588455, 0.41663322, 0.86573094]],\n",
       "       dtype=float32),\n",
       " array([[0.16350055, 0.21773076, 0.27398333, 0.69424546, 0.13407332,\n",
       "         0.77676237, 0.7455429 , 0.28009894, 0.42394927, 0.86626446]],\n",
       "       dtype=float32),\n",
       " array([[0.1631483 , 0.23112912, 0.225813  , 0.7047901 , 0.1548788 ,\n",
       "         0.77259344, 0.74446213, 0.25394976, 0.42227408, 0.8671964 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16323254, 0.29678473, 0.15872996, 0.69709575, 0.14934888,\n",
       "         0.7805009 , 0.74164325, 0.19527847, 0.45443884, 0.8659574 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14930381, 0.29672828, 0.11683597, 0.6899188 , 0.1280165 ,\n",
       "         0.78461605, 0.7437224 , 0.17262109, 0.46792418, 0.8635812 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15456434, 0.24457085, 0.19435966, 0.6891612 , 0.12265441,\n",
       "         0.7933889 , 0.74725974, 0.23525573, 0.43965253, 0.865557  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15206197, 0.25382537, 0.18582086, 0.6899443 , 0.12723008,\n",
       "         0.78515846, 0.74732965, 0.22749172, 0.4434539 , 0.86371994]],\n",
       "       dtype=float32),\n",
       " array([[0.1648671 , 0.23993073, 0.26490363, 0.69221604, 0.13864121,\n",
       "         0.7735252 , 0.74674815, 0.28350434, 0.425434  , 0.86596   ]],\n",
       "       dtype=float32),\n",
       " array([[0.15391383, 0.21862508, 0.22933301, 0.69157803, 0.11302399,\n",
       "         0.79697996, 0.74805033, 0.26724336, 0.42540452, 0.8659214 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16904598, 0.22964036, 0.29757807, 0.6818601 , 0.13884328,\n",
       "         0.7742114 , 0.74959683, 0.30412275, 0.42149854, 0.8709565 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16929348, 0.19204044, 0.3354996 , 0.67753226, 0.13754234,\n",
       "         0.78396595, 0.74722636, 0.31201276, 0.41082424, 0.87508875]],\n",
       "       dtype=float32),\n",
       " array([[0.15848197, 0.22384669, 0.27075216, 0.68100435, 0.1256357 ,\n",
       "         0.7899383 , 0.74575835, 0.27745605, 0.42554203, 0.8711604 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15430574, 0.2076852 , 0.24962725, 0.6806054 , 0.11123518,\n",
       "         0.8044256 , 0.74861544, 0.2777313 , 0.41937092, 0.8737185 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16574675, 0.2218324 , 0.34500667, 0.6769919 , 0.10065481,\n",
       "         0.7949932 , 0.7454916 , 0.32346526, 0.42010045, 0.86983114]],\n",
       "       dtype=float32),\n",
       " array([[0.16056515, 0.20252258, 0.33652568, 0.67590785, 0.09825194,\n",
       "         0.79313666, 0.74663377, 0.3169574 , 0.41676253, 0.8697384 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16543627, 0.25273547, 0.35741726, 0.67571247, 0.08375598,\n",
       "         0.7774856 , 0.74248844, 0.3286414 , 0.43107003, 0.86267585]],\n",
       "       dtype=float32),\n",
       " array([[0.16233118, 0.24529654, 0.3174354 , 0.685826  , 0.09548733,\n",
       "         0.7796873 , 0.7442745 , 0.3106735 , 0.43097812, 0.8617478 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16682675, 0.2721141 , 0.30593115, 0.6824822 , 0.11613946,\n",
       "         0.7764486 , 0.74283886, 0.2971977 , 0.43746087, 0.8647293 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17014402, 0.2065124 , 0.37327847, 0.68176466, 0.09705094,\n",
       "         0.7812957 , 0.7436187 , 0.3271882 , 0.41836712, 0.86790407]],\n",
       "       dtype=float32),\n",
       " array([[0.15799841, 0.23159274, 0.29306898, 0.6894806 , 0.09648679,\n",
       "         0.78554153, 0.7433095 , 0.29483357, 0.4283206 , 0.86353993]],\n",
       "       dtype=float32),\n",
       " array([[0.15569949, 0.24598756, 0.25980955, 0.6944248 , 0.10655259,\n",
       "         0.79052395, 0.74350786, 0.27498695, 0.4353012 , 0.86250746]],\n",
       "       dtype=float32),\n",
       " array([[0.1583296 , 0.28038424, 0.23936659, 0.69165105, 0.12569636,\n",
       "         0.786064  , 0.7428606 , 0.2555515 , 0.44848242, 0.8611881 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16313462, 0.28599945, 0.23990647, 0.6939215 , 0.14354505,\n",
       "         0.76859057, 0.7415607 , 0.25872162, 0.44142157, 0.8636394 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16035832, 0.26409537, 0.21343264, 0.7026739 , 0.14672643,\n",
       "         0.77089494, 0.7461524 , 0.25139716, 0.43558508, 0.86293495]],\n",
       "       dtype=float32),\n",
       " array([[0.15782234, 0.2742752 , 0.20566887, 0.70289   , 0.13462105,\n",
       "         0.7770232 , 0.74377173, 0.24488491, 0.4397623 , 0.86045766]],\n",
       "       dtype=float32),\n",
       " array([[0.15326625, 0.26745585, 0.16750862, 0.6982355 , 0.13173297,\n",
       "         0.78968686, 0.7467065 , 0.21969244, 0.44298255, 0.864657  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16158158, 0.20770733, 0.29613292, 0.6789002 , 0.11926354,\n",
       "         0.79423076, 0.7468161 , 0.28938696, 0.4253836 , 0.8696284 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1689408 , 0.20510834, 0.32206136, 0.6782123 , 0.13192308,\n",
       "         0.77248144, 0.74659747, 0.3045814 , 0.41992864, 0.8694428 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17236012, 0.18475224, 0.3557156 , 0.6800441 , 0.12391862,\n",
       "         0.7737255 , 0.7458996 , 0.31956816, 0.4100303 , 0.87206304]],\n",
       "       dtype=float32),\n",
       " array([[0.16509315, 0.20256494, 0.32254407, 0.6754284 , 0.1250097 ,\n",
       "         0.7840005 , 0.74509996, 0.29608718, 0.42087594, 0.8719186 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15941897, 0.20502494, 0.27355346, 0.6814666 , 0.11904808,\n",
       "         0.79868114, 0.7477109 , 0.28417215, 0.41838512, 0.8737641 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15360335, 0.22436506, 0.24012905, 0.6874388 , 0.10979259,\n",
       "         0.80100155, 0.7466998 , 0.2680334 , 0.4286017 , 0.8680045 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16002434, 0.25991222, 0.23515998, 0.6882735 , 0.12814867,\n",
       "         0.7899459 , 0.74326444, 0.25360167, 0.44129595, 0.8657446 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15438297, 0.2659773 , 0.19293186, 0.6984549 , 0.12924226,\n",
       "         0.78461415, 0.744695  , 0.23880121, 0.43701383, 0.8650898 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15752038, 0.3145307 , 0.15926918, 0.6962996 , 0.14190872,\n",
       "         0.7805025 , 0.74005985, 0.1962063 , 0.45916873, 0.8615958 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1557554 , 0.3110731 , 0.14051218, 0.6999597 , 0.14689559,\n",
       "         0.77190846, 0.7422244 , 0.18757395, 0.45811445, 0.86000276]],\n",
       "       dtype=float32),\n",
       " array([[0.15610217, 0.3115299 , 0.14759754, 0.69630384, 0.13719715,\n",
       "         0.77248317, 0.74289113, 0.1998557 , 0.4542695 , 0.86159456]],\n",
       "       dtype=float32),\n",
       " array([[0.15719818, 0.32584214, 0.1472993 , 0.6853289 , 0.14831676,\n",
       "         0.76417214, 0.7431081 , 0.1932223 , 0.47143072, 0.85981643]],\n",
       "       dtype=float32),\n",
       " array([[0.1671575 , 0.3440977 , 0.1897284 , 0.6723256 , 0.14724015,\n",
       "         0.75994575, 0.7446502 , 0.21676287, 0.47303256, 0.863115  ]],\n",
       "       dtype=float32),\n",
       " array([[0.1644395 , 0.3289003 , 0.19317368, 0.6748515 , 0.13661067,\n",
       "         0.76726997, 0.746743  , 0.22813731, 0.46496034, 0.86385953]],\n",
       "       dtype=float32),\n",
       " array([[0.17572623, 0.327262  , 0.25016472, 0.6610895 , 0.15909421,\n",
       "         0.7534653 , 0.74510527, 0.24456786, 0.4708789 , 0.8668421 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16556658, 0.33672047, 0.18537754, 0.659424  , 0.13077052,\n",
       "         0.76529664, 0.7475262 , 0.22248462, 0.4780573 , 0.86727434]],\n",
       "       dtype=float32),\n",
       " array([[0.16320144, 0.34523112, 0.1802684 , 0.6624379 , 0.12291455,\n",
       "         0.7708932 , 0.74690175, 0.22338288, 0.47628057, 0.865778  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16267036, 0.3159042 , 0.22462718, 0.6630466 , 0.12074985,\n",
       "         0.7843848 , 0.74578476, 0.25477934, 0.455958  , 0.8707341 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16130914, 0.27938685, 0.25835624, 0.67915606, 0.11628531,\n",
       "         0.7905591 , 0.7459742 , 0.29104596, 0.42978653, 0.8700091 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16543886, 0.2681114 , 0.28196257, 0.6808748 , 0.12713167,\n",
       "         0.7838463 , 0.7432376 , 0.28977582, 0.42960635, 0.8692505 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16357034, 0.25861347, 0.28443474, 0.6911548 , 0.11845171,\n",
       "         0.78264993, 0.7451238 , 0.31165543, 0.41676137, 0.8687115 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16449304, 0.2617296 , 0.27846387, 0.6904807 , 0.12435137,\n",
       "         0.7800442 , 0.74362373, 0.29688263, 0.42301473, 0.86739576]],\n",
       "       dtype=float32),\n",
       " array([[0.1627061 , 0.2710284 , 0.26057765, 0.68997055, 0.12232714,\n",
       "         0.7804007 , 0.7439852 , 0.28755707, 0.4271643 , 0.866682  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16330694, 0.26006982, 0.29430437, 0.68776095, 0.11601235,\n",
       "         0.7840729 , 0.7398125 , 0.30293798, 0.42076954, 0.86828786]],\n",
       "       dtype=float32),\n",
       " array([[0.16184297, 0.25458726, 0.2978284 , 0.68785954, 0.10920394,\n",
       "         0.78709495, 0.74139154, 0.30610108, 0.42246553, 0.8667947 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16481496, 0.25372154, 0.29688117, 0.6865933 , 0.12082492,\n",
       "         0.78412324, 0.7424733 , 0.29819816, 0.42580754, 0.8674744 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15816022, 0.25497818, 0.2647511 , 0.6974663 , 0.10567265,\n",
       "         0.7838146 , 0.7454967 , 0.29933733, 0.42359287, 0.8628623 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16743712, 0.23767139, 0.34391114, 0.68661237, 0.10762174,\n",
       "         0.77355206, 0.74479944, 0.3304417 , 0.4199748 , 0.8658616 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16457017, 0.24106602, 0.31662753, 0.6875646 , 0.1120432 ,\n",
       "         0.78114206, 0.7454025 , 0.31228116, 0.42505425, 0.8657478 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15897636, 0.24711482, 0.26651537, 0.69145364, 0.11302213,\n",
       "         0.7863598 , 0.7464804 , 0.2886001 , 0.42846826, 0.86493707]],\n",
       "       dtype=float32),\n",
       " array([[0.15674312, 0.22163476, 0.28488797, 0.68676364, 0.10287257,\n",
       "         0.7973068 , 0.7469198 , 0.29595998, 0.42384344, 0.86693215]],\n",
       "       dtype=float32),\n",
       " array([[0.16145372, 0.1838097 , 0.37060806, 0.678181  , 0.08431164,\n",
       "         0.7967482 , 0.74892354, 0.34028524, 0.41000643, 0.8686965 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1554335 , 0.18483673, 0.3190534 , 0.68425155, 0.08995906,\n",
       "         0.7967443 , 0.74896586, 0.31780934, 0.41197926, 0.86695313]],\n",
       "       dtype=float32),\n",
       " array([[0.15699899, 0.18869212, 0.30529362, 0.69335437, 0.10124367,\n",
       "         0.7879095 , 0.7459832 , 0.30278635, 0.41654965, 0.8638332 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15905389, 0.22188252, 0.26214674, 0.7007701 , 0.12045895,\n",
       "         0.78413486, 0.74379176, 0.2802913 , 0.41985983, 0.8666594 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16475756, 0.23349951, 0.24165401, 0.7060261 , 0.15396966,\n",
       "         0.77734935, 0.7409841 , 0.25808236, 0.4192279 , 0.86934704]],\n",
       "       dtype=float32),\n",
       " array([[0.16232161, 0.23303905, 0.22790307, 0.7051808 , 0.1509064 ,\n",
       "         0.7766439 , 0.74126244, 0.25166643, 0.41992003, 0.8685862 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15147746, 0.23903328, 0.19041516, 0.70657307, 0.12232345,\n",
       "         0.78913426, 0.74213606, 0.23438753, 0.42856517, 0.86359805]],\n",
       "       dtype=float32),\n",
       " array([[0.15205936, 0.21733838, 0.2151328 , 0.6977942 , 0.11621623,\n",
       "         0.7928517 , 0.7454566 , 0.25390103, 0.4248011 , 0.8657317 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15961395, 0.21293698, 0.26088354, 0.68526727, 0.12836422,\n",
       "         0.78626585, 0.7450351 , 0.26879615, 0.4266587 , 0.868176  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16699372, 0.20312938, 0.29971254, 0.6899552 , 0.13980965,\n",
       "         0.76946753, 0.74509084, 0.29246348, 0.4177352 , 0.8679374 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16756159, 0.20018148, 0.32294315, 0.684978  , 0.1245264 ,\n",
       "         0.77264583, 0.74723804, 0.310229  , 0.4162329 , 0.8689057 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17700069, 0.19235063, 0.40270737, 0.6706257 , 0.11894798,\n",
       "         0.77599305, 0.74411315, 0.33332524, 0.41578776, 0.8719976 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16164635, 0.18585217, 0.3296321 , 0.6712481 , 0.10484685,\n",
       "         0.7989097 , 0.749022  , 0.31349474, 0.41246292, 0.8740011 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15673773, 0.20819843, 0.2853374 , 0.67878574, 0.10290665,\n",
       "         0.8019018 , 0.749358  , 0.29309568, 0.4232365 , 0.87022835]],\n",
       "       dtype=float32),\n",
       " array([[0.15688926, 0.2059306 , 0.26533696, 0.6861925 , 0.11308435,\n",
       "         0.79783624, 0.74931985, 0.28158498, 0.42376703, 0.8690097 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15811335, 0.24863796, 0.2394819 , 0.6939087 , 0.11695781,\n",
       "         0.7858562 , 0.7440639 , 0.26651594, 0.43316984, 0.86472344]],\n",
       "       dtype=float32),\n",
       " array([[0.15046868, 0.2692161 , 0.18973757, 0.70018476, 0.11495967,\n",
       "         0.78987926, 0.74331903, 0.23383893, 0.44298133, 0.8607449 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15195984, 0.30323678, 0.16991125, 0.6970929 , 0.11764418,\n",
       "         0.7888676 , 0.7432891 , 0.21627535, 0.45578876, 0.8592393 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15313557, 0.27644968, 0.18539435, 0.6981911 , 0.12072652,\n",
       "         0.78578085, 0.7446265 , 0.233278  , 0.44280973, 0.8624593 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16115801, 0.28118795, 0.2248277 , 0.68979627, 0.13040702,\n",
       "         0.77669615, 0.7450356 , 0.2532668 , 0.4441849 , 0.8633317 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16667603, 0.29800802, 0.24128412, 0.6881677 , 0.1456103 ,\n",
       "         0.76347756, 0.74284154, 0.25691837, 0.44596842, 0.8627633 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16823591, 0.30117872, 0.23888923, 0.6827089 , 0.15275447,\n",
       "         0.76333475, 0.74283665, 0.24699755, 0.4507884 , 0.8640434 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16454576, 0.2766381 , 0.2454271 , 0.6770383 , 0.14242087,\n",
       "         0.7728265 , 0.74493545, 0.25506672, 0.44569707, 0.86763144]],\n",
       "       dtype=float32),\n",
       " array([[0.16229925, 0.29689172, 0.21890078, 0.6709101 , 0.12626046,\n",
       "         0.78010297, 0.7478556 , 0.2468851 , 0.45620802, 0.86712277]],\n",
       "       dtype=float32),\n",
       " array([[0.16043928, 0.30042157, 0.22180152, 0.67059445, 0.11475516,\n",
       "         0.788494  , 0.7497802 , 0.25660712, 0.4568694 , 0.8654524 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16206478, 0.2929527 , 0.23622714, 0.67511815, 0.11779246,\n",
       "         0.78501195, 0.7471153 , 0.26431954, 0.44948098, 0.8659858 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16507676, 0.25384662, 0.29937342, 0.676105  , 0.11840595,\n",
       "         0.7859185 , 0.7454415 , 0.29550356, 0.43370295, 0.86880654]],\n",
       "       dtype=float32),\n",
       " array([[0.16931628, 0.21866179, 0.35372362, 0.6754701 , 0.11433685,\n",
       "         0.78084683, 0.7459638 , 0.32432634, 0.4197301 , 0.87083465]],\n",
       "       dtype=float32),\n",
       " array([[0.16015114, 0.18772513, 0.32668233, 0.6828344 , 0.09825782,\n",
       "         0.7911406 , 0.74791026, 0.320792  , 0.40929   , 0.8704482 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16032456, 0.20813756, 0.29387036, 0.6891177 , 0.11088483,\n",
       "         0.7878101 , 0.7479202 , 0.29999292, 0.42039457, 0.8670089 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15783186, 0.21906494, 0.27545175, 0.68921715, 0.10915256,\n",
       "         0.79097843, 0.7445906 , 0.28836742, 0.4207936 , 0.8688372 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16392897, 0.21219425, 0.33016253, 0.67873096, 0.1092227 ,\n",
       "         0.7831572 , 0.742982  , 0.305681  , 0.42198825, 0.8689833 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16595088, 0.17276342, 0.38756114, 0.6719768 , 0.09053786,\n",
       "         0.7918768 , 0.74491864, 0.33438382, 0.40825427, 0.8708742 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15848184, 0.18313155, 0.33471292, 0.6790271 , 0.08868498,\n",
       "         0.7892456 , 0.7459126 , 0.31549546, 0.41168976, 0.8685505 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15800178, 0.21294805, 0.29383534, 0.68714607, 0.10453917,\n",
       "         0.79051787, 0.7470312 , 0.29428893, 0.4250818 , 0.8660679 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16280438, 0.25976205, 0.263237  , 0.69226056, 0.13284113,\n",
       "         0.77620924, 0.7441602 , 0.2716691 , 0.4376586 , 0.8645217 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15850818, 0.27478123, 0.21777351, 0.6987882 , 0.13193761,\n",
       "         0.7768058 , 0.74649364, 0.2574728 , 0.43895632, 0.86299944]],\n",
       "       dtype=float32),\n",
       " array([[0.16182072, 0.26890212, 0.22065508, 0.70153147, 0.14827012,\n",
       "         0.7713426 , 0.7436727 , 0.25120828, 0.4347639 , 0.86483926]],\n",
       "       dtype=float32),\n",
       " array([[0.15206173, 0.27849868, 0.16180684, 0.7033973 , 0.12458371,\n",
       "         0.7894534 , 0.74651337, 0.22267583, 0.4430094 , 0.86301327]],\n",
       "       dtype=float32),\n",
       " array([[0.15341674, 0.2803692 , 0.15257196, 0.70677114, 0.12268059,\n",
       "         0.7883979 , 0.7453265 , 0.21611695, 0.44277734, 0.8620195 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15602845, 0.2582949 , 0.18848084, 0.69946474, 0.12454317,\n",
       "         0.786431  , 0.7438028 , 0.2363362 , 0.43628043, 0.8639239 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16780035, 0.24675332, 0.24207628, 0.6983044 , 0.1600358 ,\n",
       "         0.76575226, 0.7417619 , 0.25478587, 0.4282637 , 0.86605513]],\n",
       "       dtype=float32),\n",
       " array([[0.16316003, 0.2725487 , 0.21037138, 0.69417936, 0.14651385,\n",
       "         0.76856893, 0.74306077, 0.2395877 , 0.43946582, 0.86400026]],\n",
       "       dtype=float32),\n",
       " array([[0.16170377, 0.24433856, 0.24333256, 0.68997425, 0.1299015 ,\n",
       "         0.77845913, 0.7439592 , 0.26655626, 0.43099234, 0.86580247]],\n",
       "       dtype=float32),\n",
       " array([[0.16263261, 0.2646712 , 0.22424495, 0.6794466 , 0.12678921,\n",
       "         0.7836106 , 0.74594676, 0.25218216, 0.44349623, 0.8675409 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16401313, 0.21900195, 0.26902843, 0.67987216, 0.12995358,\n",
       "         0.78565574, 0.74485797, 0.27896407, 0.42320207, 0.8719806 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16270533, 0.20811702, 0.29489905, 0.6799176 , 0.1239564 ,\n",
       "         0.78878033, 0.744316  , 0.28993937, 0.41973457, 0.87186   ]],\n",
       "       dtype=float32),\n",
       " array([[0.16451576, 0.2182137 , 0.2989738 , 0.68081284, 0.12389969,\n",
       "         0.78372484, 0.7452616 , 0.2948023 , 0.42249638, 0.8702313 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16423656, 0.20252691, 0.31768095, 0.680865  , 0.11576676,\n",
       "         0.78713036, 0.7462878 , 0.3081616 , 0.41533273, 0.8717024 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16674112, 0.17750789, 0.36158642, 0.6768362 , 0.11177026,\n",
       "         0.7865444 , 0.7434587 , 0.3205071 , 0.4083594 , 0.87239414]],\n",
       "       dtype=float32),\n",
       " array([[0.15895587, 0.19982514, 0.32781127, 0.67503184, 0.09109262,\n",
       "         0.79455394, 0.7464908 , 0.3163827 , 0.41571516, 0.8700653 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16381522, 0.19391726, 0.3746221 , 0.6681703 , 0.08463892,\n",
       "         0.79365915, 0.7439463 , 0.32968143, 0.41535458, 0.8702103 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1602797 , 0.23755756, 0.306576  , 0.6773217 , 0.10567364,\n",
       "         0.78889346, 0.7448553 , 0.29315388, 0.43721193, 0.8640387 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1695163 , 0.19634514, 0.3734831 , 0.6800245 , 0.09746896,\n",
       "         0.78228474, 0.7423907 , 0.3235954 , 0.41621047, 0.8693377 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16213651, 0.22712979, 0.31241646, 0.68744713, 0.10224073,\n",
       "         0.7793441 , 0.7423736 , 0.29762223, 0.4288309 , 0.86433893]],\n",
       "       dtype=float32),\n",
       " array([[0.15537919, 0.25339243, 0.25197378, 0.69433254, 0.10788837,\n",
       "         0.7829107 , 0.74452555, 0.27465612, 0.43634772, 0.8617011 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15652294, 0.28896105, 0.23863482, 0.69641256, 0.11152857,\n",
       "         0.7817039 , 0.74293524, 0.26559502, 0.44486013, 0.86053926]],\n",
       "       dtype=float32),\n",
       " array([[0.15034601, 0.31598037, 0.17275213, 0.69975406, 0.11917183,\n",
       "         0.78929335, 0.74581075, 0.22524095, 0.4592599 , 0.8561131 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15623306, 0.2970099 , 0.18435599, 0.69844794, 0.13508457,\n",
       "         0.7801156 , 0.74812907, 0.23720124, 0.44802678, 0.8616775 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15128419, 0.31147522, 0.1308027 , 0.7056018 , 0.13282454,\n",
       "         0.7849775 , 0.74504805, 0.18576322, 0.46123108, 0.8571597 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15366514, 0.3051863 , 0.12937276, 0.70328784, 0.1378681 ,\n",
       "         0.7767993 , 0.74626994, 0.18939145, 0.45603368, 0.8600459 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15366246, 0.30677944, 0.1275693 , 0.6919654 , 0.13030939,\n",
       "         0.78146297, 0.7453799 , 0.18566355, 0.46406296, 0.86308056]],\n",
       "       dtype=float32),\n",
       " array([[0.16038576, 0.25028792, 0.20432025, 0.69372666, 0.14416067,\n",
       "         0.7768524 , 0.74696434, 0.24282558, 0.43445876, 0.86628145]],\n",
       "       dtype=float32),\n",
       " array([[0.16202204, 0.25730154, 0.20655139, 0.68094313, 0.14125188,\n",
       "         0.7773614 , 0.7489184 , 0.24313352, 0.44224456, 0.8693024 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16486035, 0.2757116 , 0.22788338, 0.68374294, 0.14493285,\n",
       "         0.77230763, 0.74560535, 0.25020623, 0.44362003, 0.86642534]],\n",
       "       dtype=float32),\n",
       " array([[0.16450842, 0.2614704 , 0.21905853, 0.6748983 , 0.14117484,\n",
       "         0.7741825 , 0.749197  , 0.25127614, 0.44284958, 0.8711688 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16151588, 0.2464031 , 0.23694587, 0.67741066, 0.1320314 ,\n",
       "         0.78351605, 0.7473298 , 0.26594695, 0.4322597 , 0.8721579 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16774692, 0.23272108, 0.31610465, 0.675286  , 0.13111314,\n",
       "         0.78381526, 0.74703455, 0.30937004, 0.4226868 , 0.87250304]],\n",
       "       dtype=float32),\n",
       " array([[0.15551224, 0.22335309, 0.258221  , 0.6814357 , 0.10897662,\n",
       "         0.79960257, 0.74749935, 0.28861004, 0.42034793, 0.8715899 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16192941, 0.2506068 , 0.27259067, 0.68514013, 0.12136555,\n",
       "         0.786701  , 0.7450412 , 0.28677332, 0.42959407, 0.8679187 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16163148, 0.26326564, 0.2666064 , 0.68447506, 0.11870566,\n",
       "         0.78494227, 0.7462219 , 0.2906285 , 0.42963302, 0.8685945 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16012916, 0.25329652, 0.25351802, 0.6972233 , 0.12031646,\n",
       "         0.77691185, 0.7461131 , 0.28840047, 0.4240566 , 0.8655369 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16206856, 0.24911788, 0.3257283 , 0.6796646 , 0.0979034 ,\n",
       "         0.78569084, 0.74664015, 0.3175696 , 0.43404374, 0.86183137]],\n",
       "       dtype=float32),\n",
       " array([[0.15580884, 0.27597988, 0.28347316, 0.67627764, 0.09613469,\n",
       "         0.7909343 , 0.7442192 , 0.2937969 , 0.44112596, 0.8625412 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16609202, 0.30226278, 0.26862645, 0.6842941 , 0.124684  ,\n",
       "         0.77913016, 0.74213284, 0.2790126 , 0.4432801 , 0.86533564]],\n",
       "       dtype=float32),\n",
       " array([[0.16401662, 0.31431687, 0.24418996, 0.69150454, 0.12035377,\n",
       "         0.7779878 , 0.7425118 , 0.2736401 , 0.4435304 , 0.8630427 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17139786, 0.26491734, 0.32731178, 0.6846398 , 0.12737791,\n",
       "         0.76408005, 0.74096626, 0.30535227, 0.4320904 , 0.8654579 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1736234 , 0.28647572, 0.32460946, 0.68170327, 0.13586958,\n",
       "         0.76218474, 0.73963845, 0.29794896, 0.43955415, 0.8646392 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15334588, 0.26636398, 0.23373356, 0.6885784 , 0.10867764,\n",
       "         0.7896211 , 0.7449788 , 0.26502797, 0.43908513, 0.8630436 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1604749 , 0.23839839, 0.31136173, 0.6722558 , 0.10392572,\n",
       "         0.78932095, 0.7448353 , 0.29915914, 0.4338961 , 0.8656477 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16229117, 0.24959235, 0.30026326, 0.6759691 , 0.10546455,\n",
       "         0.7871323 , 0.74631983, 0.3001969 , 0.43427607, 0.8654626 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16340631, 0.23359428, 0.27227244, 0.69289404, 0.12878592,\n",
       "         0.77441007, 0.74520725, 0.28369135, 0.42524597, 0.8664905 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15872505, 0.23920295, 0.23543462, 0.6982718 , 0.12475143,\n",
       "         0.7808477 , 0.7450951 , 0.26699606, 0.4266959 , 0.8653672 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16018033, 0.240436  , 0.22807643, 0.70062566, 0.13467081,\n",
       "         0.7813377 , 0.74257034, 0.25775376, 0.42328286, 0.86840004]],\n",
       "       dtype=float32),\n",
       " array([[0.1614336 , 0.2271121 , 0.25319728, 0.6891287 , 0.13049455,\n",
       "         0.7856676 , 0.7432908 , 0.26796794, 0.4236643 , 0.8702856 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15914582, 0.2281808 , 0.23345517, 0.69513786, 0.12954429,\n",
       "         0.7843526 , 0.7433948 , 0.25875717, 0.42432463, 0.8679508 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16882984, 0.21399538, 0.347841  , 0.67437655, 0.11760607,\n",
       "         0.7761835 , 0.73911095, 0.3065855 , 0.42244437, 0.86861944]],\n",
       "       dtype=float32),\n",
       " array([[0.16434857, 0.23176885, 0.31023058, 0.676846  , 0.1163803 ,\n",
       "         0.7787337 , 0.7432357 , 0.29465267, 0.4305048 , 0.86638236]],\n",
       "       dtype=float32),\n",
       " array([[0.16181226, 0.22617637, 0.23309712, 0.6984812 , 0.13836151,\n",
       "         0.78153497, 0.74734646, 0.2613813 , 0.4246595 , 0.8678482 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1593504 , 0.24246141, 0.20565934, 0.70327556, 0.13587454,\n",
       "         0.78152275, 0.7475196 , 0.25169495, 0.42556354, 0.8675971 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15491295, 0.2502272 , 0.19006303, 0.6980456 , 0.12318509,\n",
       "         0.788517  , 0.7485063 , 0.24172553, 0.4341383 , 0.8660796 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15059727, 0.27525964, 0.14612183, 0.6923498 , 0.11078584,\n",
       "         0.7954855 , 0.75310004, 0.21424715, 0.4535017 , 0.8637669 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15528026, 0.27930242, 0.19216962, 0.68859416, 0.11503367,\n",
       "         0.79056686, 0.74721146, 0.23814894, 0.44738266, 0.86412084]],\n",
       "       dtype=float32),\n",
       " array([[0.15849806, 0.25268772, 0.2289546 , 0.68987113, 0.12063793,\n",
       "         0.78507733, 0.74745554, 0.26434162, 0.43377212, 0.86609286]],\n",
       "       dtype=float32),\n",
       " array([[0.15898538, 0.2513025 , 0.24532582, 0.68727726, 0.11656856,\n",
       "         0.78459257, 0.7479196 , 0.27564427, 0.4335992 , 0.8653086 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16273184, 0.21520647, 0.3120467 , 0.68135345, 0.11767282,\n",
       "         0.77951   , 0.7475464 , 0.30259007, 0.42491582, 0.8671264 ]],\n",
       "       dtype=float32),\n",
       " array([[0.170523  , 0.25695154, 0.3063773 , 0.6782546 , 0.13778189,\n",
       "         0.77209085, 0.7428605 , 0.28712732, 0.4360453 , 0.86742043]],\n",
       "       dtype=float32),\n",
       " array([[0.15783367, 0.25944996, 0.22054219, 0.6853675 , 0.12285329,\n",
       "         0.78639024, 0.74684715, 0.2525998 , 0.43915772, 0.8671936 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16614668, 0.26339403, 0.27107352, 0.6795737 , 0.13185592,\n",
       "         0.7783256 , 0.74107295, 0.27262193, 0.4343037 , 0.869443  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16704938, 0.2687657 , 0.28296626, 0.6789402 , 0.12952963,\n",
       "         0.7771109 , 0.7404768 , 0.27724153, 0.437328  , 0.8674643 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16140126, 0.27647012, 0.2450944 , 0.6844315 , 0.12152862,\n",
       "         0.78185934, 0.7429041 , 0.26354554, 0.44070032, 0.8655092 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15729497, 0.26917285, 0.22550172, 0.6882749 , 0.11650236,\n",
       "         0.78550947, 0.743027  , 0.2537626 , 0.43995765, 0.8644577 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16676757, 0.2495952 , 0.31738976, 0.6762612 , 0.11730379,\n",
       "         0.7776362 , 0.7432864 , 0.300608  , 0.43320474, 0.866549  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16431342, 0.26778343, 0.28282496, 0.6797604 , 0.1204446 ,\n",
       "         0.7785065 , 0.7445702 , 0.28393802, 0.43996045, 0.86498064]],\n",
       "       dtype=float32),\n",
       " array([[0.16189158, 0.2639254 , 0.25289693, 0.68763375, 0.12370313,\n",
       "         0.7760837 , 0.745353  , 0.27330163, 0.43608102, 0.8647941 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16665012, 0.23101756, 0.3305381 , 0.67442334, 0.11394019,\n",
       "         0.78162   , 0.7440288 , 0.30629188, 0.42822388, 0.8682362 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16345742, 0.24417067, 0.28025183, 0.6802119 , 0.12481184,\n",
       "         0.78308785, 0.74465126, 0.28024784, 0.4324516 , 0.8684877 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16612887, 0.22272842, 0.3224892 , 0.6770933 , 0.11155847,\n",
       "         0.78565496, 0.7439252 , 0.30387974, 0.42660972, 0.86734974]],\n",
       "       dtype=float32),\n",
       " array([[0.17174022, 0.20691685, 0.4073915 , 0.6598965 , 0.09680077,\n",
       "         0.78364646, 0.74246204, 0.33566597, 0.42263034, 0.86897755]],\n",
       "       dtype=float32),\n",
       " array([[0.16513821, 0.1685248 , 0.41437373, 0.65834403, 0.07704997,\n",
       "         0.7962154 , 0.7465596 , 0.34971708, 0.40611148, 0.8712214 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15640861, 0.2269454 , 0.31785342, 0.6760465 , 0.08290086,\n",
       "         0.7922045 , 0.74713236, 0.30903274, 0.4304464 , 0.8641078 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16182843, 0.1994457 , 0.32371256, 0.6879151 , 0.10008737,\n",
       "         0.7824985 , 0.7451546 , 0.30629882, 0.4192249 , 0.8667633 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16620098, 0.20530485, 0.32604113, 0.6875958 , 0.11331608,\n",
       "         0.780118  , 0.7442502 , 0.3032674 , 0.41934854, 0.86908287]],\n",
       "       dtype=float32),\n",
       " array([[0.16380669, 0.18407023, 0.32090178, 0.69177765, 0.11347972,\n",
       "         0.7861071 , 0.7435843 , 0.298776  , 0.41230437, 0.8705677 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16371451, 0.17895715, 0.31179178, 0.69786936, 0.11375255,\n",
       "         0.784614  , 0.7422906 , 0.2958825 , 0.4107028 , 0.86853284]],\n",
       "       dtype=float32),\n",
       " array([[0.1461653 , 0.20716089, 0.20909101, 0.70935446, 0.10449517,\n",
       "         0.80128634, 0.74509037, 0.25420442, 0.42309594, 0.8623856 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15117554, 0.23342778, 0.20172065, 0.70475036, 0.12768584,\n",
       "         0.790689  , 0.7442709 , 0.24199027, 0.43057883, 0.8637009 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1531564 , 0.24178699, 0.19753571, 0.70546436, 0.12964043,\n",
       "         0.7842235 , 0.7458708 , 0.24571587, 0.43060234, 0.86307657]],\n",
       "       dtype=float32),\n",
       " array([[0.17548123, 0.20292646, 0.34438202, 0.6920159 , 0.1350568 ,\n",
       "         0.7577278 , 0.74118507, 0.3051359 , 0.41915694, 0.8665343 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16540658, 0.2338434 , 0.3021124 , 0.68338007, 0.12282228,\n",
       "         0.7721733 , 0.742     , 0.28657442, 0.43332326, 0.8641701 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15539227, 0.20438729, 0.24506086, 0.69554543, 0.11729801,\n",
       "         0.7907121 , 0.7476935 , 0.27301565, 0.42082873, 0.8665504 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1625526 , 0.21622463, 0.25456896, 0.6861131 , 0.14172803,\n",
       "         0.7897755 , 0.7469335 , 0.2667484 , 0.42559338, 0.8710484 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1631495 , 0.2156043 , 0.25260523, 0.690563  , 0.14117613,\n",
       "         0.78229135, 0.7488181 , 0.27433762, 0.42122024, 0.870629  ]],\n",
       "       dtype=float32),\n",
       " array([[0.1633186 , 0.22852226, 0.2343091 , 0.69222236, 0.15046091,\n",
       "         0.7792807 , 0.7476611 , 0.2596392 , 0.42699474, 0.8691905 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15000959, 0.23712163, 0.17805254, 0.69879615, 0.12314798,\n",
       "         0.7958098 , 0.74642104, 0.23128971, 0.43244857, 0.86558676]],\n",
       "       dtype=float32),\n",
       " array([[0.15176696, 0.29272255, 0.1329439 , 0.6958551 , 0.12590547,\n",
       "         0.79282546, 0.74493694, 0.19047374, 0.4560239 , 0.8644878 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15249904, 0.34219435, 0.11135867, 0.69397384, 0.12306543,\n",
       "         0.78380406, 0.7444588 , 0.17615971, 0.46953663, 0.8625496 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15673162, 0.30519685, 0.14898124, 0.69713885, 0.13617589,\n",
       "         0.7761445 , 0.7457841 , 0.20314296, 0.45406494, 0.8619091 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15496354, 0.29807416, 0.15648094, 0.6971506 , 0.13493347,\n",
       "         0.77774245, 0.74562436, 0.21092129, 0.4493086 , 0.86232024]],\n",
       "       dtype=float32),\n",
       " array([[0.15605788, 0.3083773 , 0.1670299 , 0.68951017, 0.13286051,\n",
       "         0.7752322 , 0.7468105 , 0.21925652, 0.45379812, 0.862756  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16070111, 0.27494168, 0.22447713, 0.67886007, 0.12816565,\n",
       "         0.7836961 , 0.7450857 , 0.25312534, 0.44337806, 0.8674721 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16291517, 0.300291  , 0.22757412, 0.6796517 , 0.12804958,\n",
       "         0.77805775, 0.74611455, 0.25993297, 0.44770813, 0.86556363]],\n",
       "       dtype=float32),\n",
       " array([[0.16691798, 0.32453167, 0.25135913, 0.6737721 , 0.12239943,\n",
       "         0.7796402 , 0.74464846, 0.2723492 , 0.45438448, 0.86392534]],\n",
       "       dtype=float32),\n",
       " array([[0.1626771 , 0.32920727, 0.22407284, 0.67897195, 0.12117226,\n",
       "         0.7788384 , 0.7467942 , 0.26332685, 0.45348945, 0.8637672 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15659443, 0.32633758, 0.1844351 , 0.67238855, 0.11639272,\n",
       "         0.7859219 , 0.7465209 , 0.22717491, 0.46590385, 0.86552125]],\n",
       "       dtype=float32),\n",
       " array([[0.16293554, 0.31565893, 0.22286285, 0.67584467, 0.13108264,\n",
       "         0.7783224 , 0.7465023 , 0.25610262, 0.4499279 , 0.86958075]],\n",
       "       dtype=float32),\n",
       " array([[0.15755881, 0.30297428, 0.19974168, 0.67580014, 0.12055122,\n",
       "         0.78502464, 0.7461297 , 0.23981829, 0.45328003, 0.8685386 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15952916, 0.29249698, 0.23332472, 0.68240935, 0.12240515,\n",
       "         0.783165  , 0.7460194 , 0.2665008 , 0.44123858, 0.8672412 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1614464 , 0.3208787 , 0.20058112, 0.68137145, 0.12876341,\n",
       "         0.7772379 , 0.74380004, 0.23348115, 0.45846853, 0.86460876]],\n",
       "       dtype=float32),\n",
       " array([[0.15815261, 0.28887206, 0.2066533 , 0.689564  , 0.12433376,\n",
       "         0.77746224, 0.74586934, 0.2493915 , 0.44192845, 0.86448836]],\n",
       "       dtype=float32),\n",
       " array([[0.16427204, 0.26570198, 0.28210622, 0.6813175 , 0.1327682 ,\n",
       "         0.7755301 , 0.7432108 , 0.2861391 , 0.43097883, 0.8684464 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16779874, 0.27688813, 0.29456043, 0.68427044, 0.12711242,\n",
       "         0.77188843, 0.74232966, 0.29936683, 0.43121862, 0.8655051 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16534607, 0.30034375, 0.25738782, 0.67668325, 0.12004334,\n",
       "         0.77892077, 0.7452146 , 0.27586523, 0.44760746, 0.86380833]],\n",
       "       dtype=float32),\n",
       " array([[0.1634293 , 0.28336638, 0.26493764, 0.68144953, 0.11611227,\n",
       "         0.78093904, 0.7444036 , 0.28676304, 0.43712223, 0.8649674 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16612026, 0.27821   , 0.28563184, 0.67811906, 0.1171682 ,\n",
       "         0.78149736, 0.74704427, 0.3007619 , 0.4361392 , 0.8658602 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16472535, 0.27684426, 0.2666543 , 0.68020463, 0.11946703,\n",
       "         0.780661  , 0.74601877, 0.28404823, 0.43902132, 0.8654559 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16486418, 0.27636427, 0.2683068 , 0.6842521 , 0.12226255,\n",
       "         0.77831966, 0.74371666, 0.28215158, 0.4366806 , 0.8652124 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16010806, 0.26137897, 0.25547665, 0.6861022 , 0.11283733,\n",
       "         0.78635544, 0.7458285 , 0.28330866, 0.43182507, 0.8662914 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1670784 , 0.24014515, 0.32597202, 0.68079305, 0.1199588 ,\n",
       "         0.77993035, 0.7434468 , 0.31199276, 0.42374715, 0.8686534 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1622324 , 0.22897947, 0.2981244 , 0.6845639 , 0.11531973,\n",
       "         0.78485745, 0.7457714 , 0.30043036, 0.42419136, 0.86729085]],\n",
       "       dtype=float32),\n",
       " array([[0.1597687 , 0.23268797, 0.27171853, 0.69268066, 0.11588088,\n",
       "         0.78292316, 0.74438006, 0.28820905, 0.4230431 , 0.86605036]],\n",
       "       dtype=float32),\n",
       " array([[0.16239914, 0.2119683 , 0.3056837 , 0.69005287, 0.11581349,\n",
       "         0.7815405 , 0.74426425, 0.30666682, 0.41374627, 0.8690414 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16910164, 0.20350929, 0.34843254, 0.68625814, 0.12393276,\n",
       "         0.7755432 , 0.7423533 , 0.31838602, 0.4114073 , 0.8707408 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1632203 , 0.20681882, 0.31925914, 0.6873136 , 0.11418613,\n",
       "         0.7809847 , 0.74497736, 0.30936328, 0.416128  , 0.8682238 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15736258, 0.23308845, 0.26681626, 0.6909385 , 0.11086243,\n",
       "         0.78703046, 0.74534583, 0.28404623, 0.426941  , 0.86548984]],\n",
       "       dtype=float32),\n",
       " array([[0.15776396, 0.22061796, 0.27046838, 0.6915227 , 0.11154981,\n",
       "         0.788924  , 0.74599475, 0.28681475, 0.42216575, 0.86731684]],\n",
       "       dtype=float32),\n",
       " array([[0.16034983, 0.21289052, 0.30726475, 0.68325883, 0.1107224 ,\n",
       "         0.78551763, 0.7455891 , 0.29963887, 0.42198417, 0.86871964]],\n",
       "       dtype=float32),\n",
       " array([[0.16022652, 0.22435561, 0.26460597, 0.6962702 , 0.12119052,\n",
       "         0.7824421 , 0.7451612 , 0.2799961 , 0.4234037 , 0.86608213]],\n",
       "       dtype=float32),\n",
       " array([[0.15792711, 0.22920565, 0.22498114, 0.70478565, 0.1257573 ,\n",
       "         0.7848493 , 0.7444204 , 0.25925323, 0.42200136, 0.8662198 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1575292 , 0.23567943, 0.22372483, 0.70132565, 0.12280772,\n",
       "         0.7867726 , 0.74407953, 0.25770384, 0.42495844, 0.86645544]],\n",
       "       dtype=float32),\n",
       " array([[0.1646986 , 0.22464627, 0.30157372, 0.68427587, 0.12305354,\n",
       "         0.7801169 , 0.74345   , 0.29198545, 0.42506284, 0.8678991 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16277578, 0.2211048 , 0.2943214 , 0.684974  , 0.11993998,\n",
       "         0.78112036, 0.7445801 , 0.2896079 , 0.42623794, 0.8665128 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15844916, 0.22789302, 0.24903859, 0.6938008 , 0.12075766,\n",
       "         0.7828068 , 0.7445364 , 0.26958212, 0.42633012, 0.8657072 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15920563, 0.23550743, 0.24981162, 0.68910235, 0.12132595,\n",
       "         0.7843951 , 0.7451699 , 0.26930776, 0.42928657, 0.86711395]],\n",
       "       dtype=float32),\n",
       " array([[0.16273138, 0.23291534, 0.2814664 , 0.68170357, 0.12286878,\n",
       "         0.7824476 , 0.7438639 , 0.2797548 , 0.43062046, 0.8674195 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16629048, 0.24304762, 0.27431962, 0.6841698 , 0.13651603,\n",
       "         0.77633995, 0.74339676, 0.27201036, 0.4324658 , 0.86804634]],\n",
       "       dtype=float32),\n",
       " array([[0.16056432, 0.24335468, 0.2466549 , 0.68817127, 0.12509307,\n",
       "         0.78173614, 0.7428924 , 0.26363942, 0.43078485, 0.8670126 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17291953, 0.2177092 , 0.3725391 , 0.66952   , 0.12086613,\n",
       "         0.77873385, 0.7403015 , 0.3146816 , 0.4250157 , 0.86998844]],\n",
       "       dtype=float32),\n",
       " array([[0.16395773, 0.22226386, 0.32111302, 0.67182714, 0.11211194,\n",
       "         0.78682804, 0.7452205 , 0.30049682, 0.42881423, 0.86855793]],\n",
       "       dtype=float32),\n",
       " array([[0.16030711, 0.22562118, 0.26566505, 0.6881968 , 0.11980499,\n",
       "         0.78370893, 0.7468226 , 0.27979198, 0.42722133, 0.8669325 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16031615, 0.21330847, 0.27706063, 0.68856394, 0.11964785,\n",
       "         0.7837515 , 0.7456625 , 0.2835746 , 0.42243102, 0.86796093]],\n",
       "       dtype=float32),\n",
       " array([[0.16580549, 0.22865582, 0.30635   , 0.68153286, 0.12007308,\n",
       "         0.7803978 , 0.74529636, 0.29472047, 0.4286095 , 0.8675304 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16095284, 0.26787603, 0.2423052 , 0.6863659 , 0.12244561,\n",
       "         0.7837664 , 0.7467782 , 0.26611072, 0.44010314, 0.8659284 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15553853, 0.24703111, 0.23024455, 0.69147176, 0.1136267 ,\n",
       "         0.78855664, 0.7451643 , 0.26111373, 0.43377194, 0.8650437 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1680527 , 0.19666938, 0.3821291 , 0.6673964 , 0.09731495,\n",
       "         0.7888036 , 0.74290484, 0.32324484, 0.4217171 , 0.86863124]],\n",
       "       dtype=float32),\n",
       " array([[0.15985876, 0.2289864 , 0.32118297, 0.670451  , 0.09360243,\n",
       "         0.79045105, 0.7466217 , 0.30544513, 0.43242005, 0.86544555]],\n",
       "       dtype=float32),\n",
       " array([[0.16330832, 0.25760505, 0.27831113, 0.6843938 , 0.12191766,\n",
       "         0.77718335, 0.74561757, 0.28025073, 0.44019538, 0.86366636]],\n",
       "       dtype=float32),\n",
       " array([[0.16457523, 0.22930282, 0.31805387, 0.680922  , 0.10660399,\n",
       "         0.7781062 , 0.7454187 , 0.30064306, 0.43111518, 0.86493033]],\n",
       "       dtype=float32),\n",
       " array([[0.15759565, 0.23302564, 0.26308715, 0.6898484 , 0.10998678,\n",
       "         0.78730416, 0.74768066, 0.27995405, 0.43231958, 0.86404353]],\n",
       "       dtype=float32),\n",
       " array([[0.17244206, 0.21131055, 0.37742236, 0.66871685, 0.10322359,\n",
       "         0.78464746, 0.7456505 , 0.3244464 , 0.42487252, 0.8683727 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16189148, 0.21437003, 0.33200493, 0.6704525 , 0.09647912,\n",
       "         0.7915067 , 0.7467055 , 0.30718663, 0.42625123, 0.86818373]],\n",
       "       dtype=float32),\n",
       " array([[0.18674867, 0.15509015, 0.5000941 , 0.66066647, 0.10375703,\n",
       "         0.7977008 , 0.74087423, 0.3577171 , 0.4102071 , 0.8706319 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17040555, 0.17721263, 0.370972  , 0.6849107 , 0.09787365,\n",
       "         0.78342634, 0.7411481 , 0.31818864, 0.4077442 , 0.8724098 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16957651, 0.19563735, 0.3060979 , 0.69886476, 0.14515604,\n",
       "         0.77060556, 0.74526745, 0.28786373, 0.41920337, 0.86793953]],\n",
       "       dtype=float32),\n",
       " array([[0.15054227, 0.23049083, 0.20364033, 0.71333987, 0.12263574,\n",
       "         0.7832198 , 0.7466518 , 0.25344157, 0.42473114, 0.8639111 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14242104, 0.26427293, 0.14716744, 0.7158466 , 0.11390597,\n",
       "         0.79717445, 0.7481971 , 0.22377336, 0.43663117, 0.86050314]],\n",
       "       dtype=float32),\n",
       " array([[0.14900987, 0.23893411, 0.17332664, 0.712104  , 0.11982676,\n",
       "         0.7926688 , 0.7483257 , 0.2422788 , 0.42702252, 0.8634426 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14523497, 0.2037481 , 0.20770109, 0.70220613, 0.10766013,\n",
       "         0.80501133, 0.74368644, 0.24719064, 0.42315096, 0.86534494]],\n",
       "       dtype=float32),\n",
       " array([[0.1441147 , 0.20784386, 0.19388211, 0.70888716, 0.11173407,\n",
       "         0.79439634, 0.7441345 , 0.2418746 , 0.4239756 , 0.86150086]],\n",
       "       dtype=float32),\n",
       " array([[0.16942586, 0.186383  , 0.30317217, 0.6979012 , 0.1320266 ,\n",
       "         0.771717  , 0.74431866, 0.29852018, 0.40716678, 0.8708586 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16631365, 0.18516722, 0.29368368, 0.6960784 , 0.13802229,\n",
       "         0.7647601 , 0.7447986 , 0.29013434, 0.40969917, 0.869639  ]],\n",
       "       dtype=float32),\n",
       " array([[0.18594146, 0.17859234, 0.39644516, 0.68019176, 0.13999586,\n",
       "         0.7582374 , 0.7450131 , 0.33001083, 0.40627214, 0.874524  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16124803, 0.21063085, 0.28977537, 0.68333596, 0.1142146 ,\n",
       "         0.79371953, 0.7486542 , 0.2892021 , 0.4238445 , 0.8706205 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15233725, 0.19546974, 0.23443386, 0.6910124 , 0.11351427,\n",
       "         0.80771625, 0.7497107 , 0.27053753, 0.4148158 , 0.8730356 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16160542, 0.23528625, 0.27463895, 0.673734  , 0.12534004,\n",
       "         0.8014256 , 0.7454987 , 0.27303636, 0.43274197, 0.8727157 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1513193 , 0.20514219, 0.22398798, 0.7070732 , 0.11008693,\n",
       "         0.7951799 , 0.74720585, 0.26613426, 0.4171817 , 0.8666536 ]],\n",
       "       dtype=float32),\n",
       " array([[0.156204  , 0.23303372, 0.20976391, 0.69958395, 0.13847442,\n",
       "         0.7853381 , 0.744835  , 0.24450831, 0.4303222 , 0.86512417]],\n",
       "       dtype=float32),\n",
       " array([[0.13822386, 0.24817847, 0.13565546, 0.7187088 , 0.10745348,\n",
       "         0.79853284, 0.74560964, 0.21307898, 0.43239048, 0.85816014]],\n",
       "       dtype=float32),\n",
       " array([[0.14939716, 0.25665995, 0.1915991 , 0.6992949 , 0.12122981,\n",
       "         0.78826714, 0.7450263 , 0.23970169, 0.4367648 , 0.8628032 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15205017, 0.29447392, 0.15811345, 0.6915159 , 0.12828961,\n",
       "         0.78722394, 0.7464606 , 0.21067643, 0.45591182, 0.86104935]],\n",
       "       dtype=float32),\n",
       " array([[0.15188514, 0.27719292, 0.14133854, 0.6999928 , 0.14108536,\n",
       "         0.7763894 , 0.7469815 , 0.20074902, 0.44620702, 0.8617092 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17816007, 0.26379028, 0.3339102 , 0.67228436, 0.14974654,\n",
       "         0.76270336, 0.7444653 , 0.30388337, 0.4353848 , 0.8697948 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16177554, 0.21429227, 0.28115088, 0.67691326, 0.13122116,\n",
       "         0.7817177 , 0.74812627, 0.2880918 , 0.42172128, 0.8717818 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16871388, 0.3056936 , 0.27173468, 0.6647941 , 0.13295034,\n",
       "         0.775491  , 0.7465967 , 0.2788996 , 0.45210874, 0.8669348 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1621229 , 0.28535974, 0.24496005, 0.6759743 , 0.13211524,\n",
       "         0.7790956 , 0.74554974, 0.26232135, 0.4470264 , 0.866475  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16320403, 0.35650426, 0.18563499, 0.6692555 , 0.13297185,\n",
       "         0.7802012 , 0.7467612 , 0.22153133, 0.47487018, 0.86643696]],\n",
       "       dtype=float32),\n",
       " array([[0.15818506, 0.38920847, 0.12927124, 0.6751135 , 0.1254418 ,\n",
       "         0.77371866, 0.7488942 , 0.19216163, 0.48557076, 0.86369354]],\n",
       "       dtype=float32),\n",
       " array([[0.16247904, 0.327749  , 0.16853079, 0.6838965 , 0.1389276 ,\n",
       "         0.77031237, 0.7470593 , 0.21914537, 0.45882177, 0.866385  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15652151, 0.3426537 , 0.14126952, 0.681597  , 0.13338904,\n",
       "         0.7728626 , 0.74355096, 0.19335185, 0.47284463, 0.86399066]],\n",
       "       dtype=float32),\n",
       " array([[0.1545178 , 0.33295467, 0.1332786 , 0.6824476 , 0.12357969,\n",
       "         0.7750999 , 0.74348176, 0.19482116, 0.46555808, 0.8658126 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1557673 , 0.35014427, 0.13599452, 0.6885963 , 0.1099725 ,\n",
       "         0.77614224, 0.744607  , 0.19592138, 0.47127637, 0.8563981 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1503668 , 0.33596686, 0.12994307, 0.6926054 , 0.11162664,\n",
       "         0.7758292 , 0.7441549 , 0.1927758 , 0.46909934, 0.8546772 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15578456, 0.3049673 , 0.19629893, 0.6879909 , 0.11928675,\n",
       "         0.78027415, 0.74464625, 0.23779391, 0.45037112, 0.8603649 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1607209 , 0.29943487, 0.24240147, 0.6754765 , 0.11660718,\n",
       "         0.78283876, 0.74589473, 0.26839077, 0.44895753, 0.86321557]],\n",
       "       dtype=float32),\n",
       " array([[0.16586739, 0.29690295, 0.2920967 , 0.673291  , 0.11028906,\n",
       "         0.7871659 , 0.7462938 , 0.3164739 , 0.43381807, 0.8677893 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16983745, 0.28707513, 0.36049378, 0.6692685 , 0.10571964,\n",
       "         0.78438586, 0.7447674 , 0.34582222, 0.42946035, 0.8683612 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16860922, 0.25094825, 0.35798436, 0.66570085, 0.11896175,\n",
       "         0.7850666 , 0.7473536 , 0.33319494, 0.42394525, 0.8731678 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1559883 , 0.24230364, 0.31113982, 0.670541  , 0.10392395,\n",
       "         0.7999649 , 0.7500561 , 0.3161142 , 0.42346776, 0.8730735 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17301062, 0.20668316, 0.45784187, 0.6584233 , 0.09877867,\n",
       "         0.7910078 , 0.74440783, 0.36432877, 0.41315097, 0.874779  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15766643, 0.211308  , 0.3699864 , 0.6700086 , 0.08732473,\n",
       "         0.79825085, 0.74579215, 0.3322929 , 0.41758785, 0.87169576]],\n",
       "       dtype=float32),\n",
       " array([[0.16483213, 0.20146385, 0.3833473 , 0.68260235, 0.09526049,\n",
       "         0.78167313, 0.7402837 , 0.33323342, 0.41171035, 0.86969805]],\n",
       "       dtype=float32),\n",
       " array([[0.15426649, 0.21635687, 0.3007912 , 0.6995435 , 0.09171724,\n",
       "         0.7887104 , 0.7445159 , 0.30787957, 0.41824722, 0.8640939 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16607311, 0.24550031, 0.32316458, 0.698517  , 0.11119723,\n",
       "         0.7683982 , 0.74111134, 0.3090894 , 0.42801887, 0.86158997]],\n",
       "       dtype=float32),\n",
       " array([[0.15490103, 0.24580362, 0.23159814, 0.7055291 , 0.12459837,\n",
       "         0.7844751 , 0.74108833, 0.25582758, 0.43470976, 0.85835594]],\n",
       "       dtype=float32),\n",
       " array([[0.14733508, 0.26010993, 0.15861364, 0.70906526, 0.12232599,\n",
       "         0.7873612 , 0.7444477 , 0.21552095, 0.43986577, 0.858448  ]],\n",
       "       dtype=float32),\n",
       " array([[0.14608154, 0.3178394 , 0.11047068, 0.7027596 , 0.11069454,\n",
       "         0.79022634, 0.7473474 , 0.17888427, 0.46866927, 0.8543416 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14759922, 0.32578805, 0.11351532, 0.6949907 , 0.11476652,\n",
       "         0.787004  , 0.7465243 , 0.17870986, 0.47415859, 0.8561263 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16363493, 0.3201914 , 0.16295451, 0.6879929 , 0.14641066,\n",
       "         0.76538193, 0.7419018 , 0.19626318, 0.47072333, 0.8581963 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1621406 , 0.31103712, 0.16592105, 0.69030493, 0.14295669,\n",
       "         0.7655638 , 0.74370325, 0.20669343, 0.46053573, 0.8601046 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16881403, 0.26580328, 0.24251498, 0.6798754 , 0.16321748,\n",
       "         0.7619539 , 0.7457935 , 0.2525672 , 0.44186458, 0.86881423]],\n",
       "       dtype=float32),\n",
       " array([[0.18047816, 0.21880256, 0.38349158, 0.67585474, 0.1660809 ,\n",
       "         0.7646335 , 0.7455838 , 0.3352657 , 0.4134815 , 0.8748427 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17087753, 0.24131699, 0.30023035, 0.6752537 , 0.1472562 ,\n",
       "         0.77279717, 0.74902886, 0.3044514 , 0.4243965 , 0.8733661 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16843927, 0.24183477, 0.2949636 , 0.66981226, 0.13870889,\n",
       "         0.78352034, 0.7465139 , 0.28906405, 0.43172437, 0.87406784]],\n",
       "       dtype=float32),\n",
       " array([[0.16995893, 0.22526023, 0.32676962, 0.6754978 , 0.13434486,\n",
       "         0.78606194, 0.746692  , 0.31599084, 0.4162025 , 0.87606406]],\n",
       "       dtype=float32),\n",
       " array([[0.16659015, 0.25200272, 0.27362582, 0.67637074, 0.13377944,\n",
       "         0.78310025, 0.74534625, 0.2787286 , 0.43372476, 0.87208146]],\n",
       "       dtype=float32),\n",
       " array([[0.1616514 , 0.26183698, 0.23104922, 0.6927652 , 0.1292689 ,\n",
       "         0.7803217 , 0.7443285 , 0.267812  , 0.42780536, 0.868641  ]],\n",
       "       dtype=float32),\n",
       " array([[0.14861006, 0.30334088, 0.13399191, 0.69586194, 0.10220497,\n",
       "         0.79143035, 0.74337584, 0.19928733, 0.4571769 , 0.8607879 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15309301, 0.2894808 , 0.17834732, 0.6972493 , 0.11090531,\n",
       "         0.78756535, 0.7422023 , 0.2343062 , 0.44017923, 0.8631706 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15625574, 0.26492137, 0.2318346 , 0.69258595, 0.11134128,\n",
       "         0.7878613 , 0.7454127 , 0.27799523, 0.42834148, 0.8653623 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16392872, 0.2576774 , 0.30067992, 0.6920669 , 0.12178341,\n",
       "         0.7706341 , 0.74244696, 0.30595794, 0.42708495, 0.86149085]],\n",
       "       dtype=float32),\n",
       " array([[0.16542304, 0.24676682, 0.32181305, 0.68584335, 0.11978548,\n",
       "         0.77305436, 0.7453519 , 0.3199689 , 0.42408147, 0.86492455]],\n",
       "       dtype=float32),\n",
       " array([[0.16541412, 0.26773357, 0.27008626, 0.6876935 , 0.1301562 ,\n",
       "         0.7765263 , 0.7446362 , 0.2813142 , 0.43474847, 0.8653656 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16530526, 0.2796312 , 0.2532614 , 0.6783303 , 0.13077664,\n",
       "         0.7753546 , 0.74755424, 0.2755631 , 0.4402378 , 0.867976  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16036098, 0.29208162, 0.22670542, 0.6779691 , 0.11723005,\n",
       "         0.7854819 , 0.7467279 , 0.2613041 , 0.44647586, 0.86667323]],\n",
       "       dtype=float32),\n",
       " array([[0.15573561, 0.28132743, 0.22257349, 0.68384826, 0.10723373,\n",
       "         0.7916876 , 0.74674875, 0.26537   , 0.44158295, 0.86456794]],\n",
       "       dtype=float32),\n",
       " array([[0.15738507, 0.27478787, 0.2565799 , 0.67216   , 0.10519209,\n",
       "         0.79808354, 0.7462701 , 0.27488294, 0.44570068, 0.8661153 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15418388, 0.2649793 , 0.22873355, 0.69084597, 0.10539578,\n",
       "         0.79243475, 0.74639225, 0.27003455, 0.43569311, 0.8634894 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16800185, 0.23814873, 0.34250978, 0.6832476 , 0.12006693,\n",
       "         0.77481675, 0.74420875, 0.32341227, 0.4215014 , 0.86767787]],\n",
       "       dtype=float32),\n",
       " array([[0.17423911, 0.20058508, 0.45088166, 0.6698546 , 0.09831566,\n",
       "         0.77210593, 0.74297   , 0.36440033, 0.41434866, 0.86771554]],\n",
       "       dtype=float32),\n",
       " array([[0.16632737, 0.1979605 , 0.40973693, 0.6706222 , 0.08928211,\n",
       "         0.7786718 , 0.7453178 , 0.35549685, 0.41106886, 0.86805606]],\n",
       "       dtype=float32),\n",
       " array([[0.15883663, 0.19687153, 0.34990183, 0.6815056 , 0.08847174,\n",
       "         0.7951919 , 0.74758834, 0.33404064, 0.4095749 , 0.8699461 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16113049, 0.19035047, 0.34232807, 0.6854093 , 0.10346584,\n",
       "         0.79273427, 0.74669063, 0.32116145, 0.41206774, 0.8693511 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16650106, 0.20837526, 0.33850864, 0.68588084, 0.12207322,\n",
       "         0.7870064 , 0.74411744, 0.30879903, 0.41920874, 0.86996955]],\n",
       "       dtype=float32),\n",
       " array([[0.16138496, 0.21611807, 0.30048507, 0.6972014 , 0.11649193,\n",
       "         0.78089017, 0.74297947, 0.29646415, 0.4200062 , 0.8660534 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1603619 , 0.22814213, 0.31181434, 0.6906473 , 0.10706764,\n",
       "         0.7850299 , 0.74073166, 0.2937565 , 0.43029618, 0.8629723 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15329601, 0.21942787, 0.27343342, 0.6982013 , 0.09864119,\n",
       "         0.79033786, 0.7426569 , 0.28564766, 0.42474213, 0.8624765 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15467772, 0.1993195 , 0.27387294, 0.7019879 , 0.10617185,\n",
       "         0.78980184, 0.74383366, 0.2853098 , 0.4178158 , 0.8643613 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16770236, 0.20438623, 0.34267712, 0.6892798 , 0.11891088,\n",
       "         0.7699292 , 0.74168223, 0.30527082, 0.42214394, 0.8650658 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16921465, 0.2020348 , 0.3313926 , 0.6911869 , 0.12998447,\n",
       "         0.76775575, 0.7430631 , 0.30236158, 0.41875893, 0.86701375]],\n",
       "       dtype=float32),\n",
       " array([[0.1672362 , 0.17963123, 0.3227047 , 0.6962008 , 0.12796208,\n",
       "         0.77291876, 0.7449157 , 0.30339307, 0.40873104, 0.8693072 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16283338, 0.1869083 , 0.27901828, 0.69081146, 0.14364998,\n",
       "         0.7889822 , 0.74513686, 0.27428925, 0.41740564, 0.8699215 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15609047, 0.20075767, 0.24357331, 0.69406176, 0.12490656,\n",
       "         0.79804236, 0.74734277, 0.26855695, 0.41865355, 0.869897  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15813   , 0.22631036, 0.24972403, 0.6875743 , 0.125942  ,\n",
       "         0.7946518 , 0.74509466, 0.26613945, 0.42805934, 0.86890835]],\n",
       "       dtype=float32),\n",
       " array([[0.16028845, 0.26314935, 0.20116536, 0.6920652 , 0.15055574,\n",
       "         0.7840612 , 0.7429167 , 0.2218907 , 0.4465307 , 0.86496013]],\n",
       "       dtype=float32),\n",
       " array([[0.1528546 , 0.2914634 , 0.13442475, 0.7052754 , 0.13909145,\n",
       "         0.78249156, 0.74436224, 0.19139968, 0.44933674, 0.86250013]],\n",
       "       dtype=float32),\n",
       " array([[0.15328047, 0.2955682 , 0.123601  , 0.702977  , 0.13850372,\n",
       "         0.7804121 , 0.7433227 , 0.17793822, 0.45769608, 0.8607891 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15666084, 0.28088596, 0.1543759 , 0.69449216, 0.1384706 ,\n",
       "         0.77889925, 0.7462785 , 0.20497566, 0.45058435, 0.863982  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15622029, 0.28366315, 0.15454195, 0.68953335, 0.13444372,\n",
       "         0.77879745, 0.7456684 , 0.20433395, 0.45402452, 0.86457336]],\n",
       "       dtype=float32),\n",
       " array([[0.16429462, 0.27274594, 0.20909248, 0.6822193 , 0.15115   ,\n",
       "         0.77036566, 0.74699384, 0.2391755 , 0.44418836, 0.869073  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16343811, 0.29674733, 0.19761865, 0.6746384 , 0.13501172,\n",
       "         0.7750904 , 0.7479799 , 0.23743336, 0.45394918, 0.8688312 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17105319, 0.2847911 , 0.25860864, 0.67223096, 0.15551889,\n",
       "         0.76443106, 0.74533814, 0.2608948 , 0.4468085 , 0.86978596]],\n",
       "       dtype=float32),\n",
       " array([[0.17018867, 0.28407565, 0.26692846, 0.6759545 , 0.14264086,\n",
       "         0.7696363 , 0.7452033 , 0.27638844, 0.4407124 , 0.86847544]],\n",
       "       dtype=float32),\n",
       " array([[0.15636416, 0.31082296, 0.18243101, 0.67145395, 0.11579064,\n",
       "         0.78521377, 0.7466711 , 0.22701034, 0.46337974, 0.86561227]],\n",
       "       dtype=float32),\n",
       " array([[0.15761343, 0.29728964, 0.20311156, 0.6729978 , 0.11313176,\n",
       "         0.7891587 , 0.7470773 , 0.24682377, 0.452366  , 0.8675471 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16283104, 0.29307973, 0.24109313, 0.67870957, 0.11482631,\n",
       "         0.78810567, 0.74436617, 0.2735236 , 0.44074416, 0.8675089 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16284907, 0.28450552, 0.24050218, 0.685371  , 0.12372812,\n",
       "         0.7809316 , 0.7452401 , 0.2669207 , 0.4415595 , 0.8643555 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16508655, 0.2638699 , 0.2790346 , 0.6892622 , 0.12694517,\n",
       "         0.7768028 , 0.743177  , 0.29630512, 0.42452282, 0.8674314 ]],\n",
       "       dtype=float32),\n",
       " array([[0.161807  , 0.24443822, 0.28984234, 0.6893618 , 0.11946663,\n",
       "         0.780512  , 0.7440511 , 0.30423394, 0.41969934, 0.86763847]],\n",
       "       dtype=float32),\n",
       " array([[0.16333438, 0.24967255, 0.31302434, 0.6815438 , 0.11118481,\n",
       "         0.7846322 , 0.74477345, 0.3161304 , 0.4238694 , 0.86753196]],\n",
       "       dtype=float32),\n",
       " array([[0.16192073, 0.26610535, 0.2704524 , 0.68357563, 0.12008534,\n",
       "         0.78651273, 0.7435752 , 0.2793774 , 0.43649727, 0.86599416]],\n",
       "       dtype=float32),\n",
       " array([[0.15501893, 0.2601066 , 0.2351872 , 0.6901816 , 0.11090133,\n",
       "         0.78956866, 0.7454773 , 0.27290317, 0.4309883 , 0.8658996 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15841174, 0.25824293, 0.2695625 , 0.6806869 , 0.11653917,\n",
       "         0.7882544 , 0.74496543, 0.27925652, 0.43648547, 0.86630446]],\n",
       "       dtype=float32),\n",
       " array([[0.15521581, 0.24852113, 0.2566314 , 0.68739545, 0.11245153,\n",
       "         0.78719604, 0.74496347, 0.27993152, 0.42921105, 0.8661288 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16207732, 0.24532188, 0.3083261 , 0.6818913 , 0.11687997,\n",
       "         0.7830222 , 0.7436252 , 0.29827678, 0.43045354, 0.86650264]],\n",
       "       dtype=float32),\n",
       " array([[0.15688492, 0.24141563, 0.2655939 , 0.68620735, 0.11104616,\n",
       "         0.78999054, 0.74448496, 0.28180727, 0.42867127, 0.8667815 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15854569, 0.23489758, 0.29724628, 0.6817679 , 0.10566743,\n",
       "         0.79091704, 0.74622375, 0.29945314, 0.42896786, 0.86579984]],\n",
       "       dtype=float32),\n",
       " array([[0.1617845 , 0.2542693 , 0.24922985, 0.6902716 , 0.12876853,\n",
       "         0.7828767 , 0.74369854, 0.26085928, 0.43635315, 0.865815  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15524441, 0.23348433, 0.21708864, 0.70285064, 0.12840739,\n",
       "         0.7813091 , 0.7439775 , 0.25317362, 0.42241162, 0.86670303]],\n",
       "       dtype=float32),\n",
       " array([[0.15506817, 0.22125992, 0.24053936, 0.6943761 , 0.11726916,\n",
       "         0.79039377, 0.7445736 , 0.26664138, 0.4223251 , 0.86825156]],\n",
       "       dtype=float32),\n",
       " array([[0.16146252, 0.21777342, 0.26784536, 0.69155395, 0.12640019,\n",
       "         0.7827403 , 0.74542   , 0.28164455, 0.4197652 , 0.86937475]],\n",
       "       dtype=float32),\n",
       " array([[0.1571001 , 0.23993087, 0.23158127, 0.6919951 , 0.11026243,\n",
       "         0.7900294 , 0.74875224, 0.27301568, 0.42965987, 0.8656267 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16343524, 0.22468512, 0.29844528, 0.68599415, 0.12293961,\n",
       "         0.77959794, 0.74421066, 0.2927395 , 0.42502028, 0.866847  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16661753, 0.24224491, 0.2843844 , 0.68771493, 0.13297604,\n",
       "         0.7742958 , 0.74253356, 0.28274375, 0.4276792 , 0.8674691 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16335481, 0.22518636, 0.29383922, 0.6849944 , 0.12232911,\n",
       "         0.77909434, 0.7432097 , 0.29072466, 0.42391527, 0.86752343]],\n",
       "       dtype=float32),\n",
       " array([[0.16587557, 0.21671714, 0.30574283, 0.68546575, 0.1274187 ,\n",
       "         0.7762608 , 0.7424887 , 0.29415187, 0.42116916, 0.86769795]],\n",
       "       dtype=float32),\n",
       " array([[0.16577177, 0.23747548, 0.28501934, 0.6855258 , 0.12073658,\n",
       "         0.78109753, 0.7453789 , 0.29311547, 0.42597565, 0.8680701 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17317818, 0.20694347, 0.37681523, 0.67462355, 0.11639892,\n",
       "         0.77829033, 0.74358314, 0.32807565, 0.41822508, 0.869993  ]],\n",
       "       dtype=float32),\n",
       " array([[0.1685352 , 0.23027088, 0.31530768, 0.6808926 , 0.1218987 ,\n",
       "         0.77935654, 0.7451561 , 0.30336672, 0.42590043, 0.8683577 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16602775, 0.22786053, 0.303988  , 0.6866827 , 0.12166204,\n",
       "         0.7784781 , 0.7454456 , 0.29885247, 0.42398462, 0.86802363]],\n",
       "       dtype=float32),\n",
       " array([[0.15496987, 0.22366081, 0.23593454, 0.69522625, 0.11129651,\n",
       "         0.7892562 , 0.7492318 , 0.2760583 , 0.42317653, 0.8664314 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1614775 , 0.23535654, 0.26115066, 0.69057125, 0.12357312,\n",
       "         0.7838867 , 0.7456116 , 0.27683425, 0.4270556 , 0.86796343]],\n",
       "       dtype=float32),\n",
       " array([[0.16302364, 0.24895209, 0.2807697 , 0.6863503 , 0.11258713,\n",
       "         0.78136486, 0.7455137 , 0.29192922, 0.4305785 , 0.86572933]],\n",
       "       dtype=float32),\n",
       " array([[0.16003402, 0.24968494, 0.27914122, 0.6833063 , 0.10632478,\n",
       "         0.7852827 , 0.74486685, 0.28660122, 0.43671086, 0.8626484 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16236645, 0.2341564 , 0.27973363, 0.68832576, 0.11553782,\n",
       "         0.78154045, 0.74488056, 0.28722015, 0.4277778 , 0.8660832 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15762939, 0.2436205 , 0.25648233, 0.6913347 , 0.10607392,\n",
       "         0.7860399 , 0.7466634 , 0.28288227, 0.43008322, 0.8643465 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16757199, 0.234074  , 0.2954454 , 0.689406  , 0.12825888,\n",
       "         0.77395535, 0.744556  , 0.28992578, 0.4279423 , 0.8662898 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16169277, 0.25493687, 0.24103881, 0.69469565, 0.1273975 ,\n",
       "         0.7810342 , 0.7449549 , 0.26560926, 0.4324541 , 0.86608124]],\n",
       "       dtype=float32),\n",
       " array([[0.16388227, 0.2640398 , 0.25712886, 0.69099915, 0.12832001,\n",
       "         0.77716315, 0.7428753 , 0.26940656, 0.43589205, 0.8652158 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16413735, 0.28576246, 0.21145439, 0.6899551 , 0.14175484,\n",
       "         0.7796537 , 0.74091405, 0.22940175, 0.44690952, 0.8665053 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15823835, 0.29784408, 0.19071499, 0.69008535, 0.12606543,\n",
       "         0.7817388 , 0.74247855, 0.22824495, 0.44924933, 0.863934  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15369412, 0.2705446 , 0.19691415, 0.6874275 , 0.11235981,\n",
       "         0.7893155 , 0.7476642 , 0.24250397, 0.44616538, 0.8625092 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1619589 , 0.24762927, 0.28207508, 0.6789936 , 0.11724409,\n",
       "         0.78199387, 0.74503124, 0.2843668 , 0.4366597 , 0.8646316 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16106969, 0.25166637, 0.27657494, 0.6775947 , 0.11519104,\n",
       "         0.7829039 , 0.74653983, 0.28442335, 0.4382032 , 0.8645125 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16108993, 0.23940755, 0.28545573, 0.6784845 , 0.11217625,\n",
       "         0.78402764, 0.7479814 , 0.29268086, 0.43357766, 0.865173  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16979462, 0.22399746, 0.3466381 , 0.6725529 , 0.11585866,\n",
       "         0.7787744 , 0.7477698 , 0.3186973 , 0.425362  , 0.86933726]],\n",
       "       dtype=float32),\n",
       " array([[0.16439159, 0.2189316 , 0.31361482, 0.67903256, 0.11034327,\n",
       "         0.7851917 , 0.74900454, 0.31013092, 0.42160812, 0.86950296]],\n",
       "       dtype=float32),\n",
       " array([[0.17133166, 0.18679713, 0.39525715, 0.66733754, 0.10238858,\n",
       "         0.787783  , 0.7464419 , 0.33614665, 0.41293594, 0.8721247 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15576434, 0.2056984 , 0.30891803, 0.6759586 , 0.08814755,\n",
       "         0.80212694, 0.7483804 , 0.30723926, 0.42039657, 0.8692055 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16328448, 0.22961031, 0.31303024, 0.6780326 , 0.11043901,\n",
       "         0.79071677, 0.74471754, 0.29451442, 0.43193755, 0.8675518 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15535884, 0.2287451 , 0.25537744, 0.68964165, 0.10731445,\n",
       "         0.7931384 , 0.7467762 , 0.2772221 , 0.42957383, 0.8655131 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15535372, 0.2427298 , 0.25806636, 0.6935516 , 0.10493537,\n",
       "         0.78328836, 0.74450326, 0.2753812 , 0.4362399 , 0.8604578 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16014439, 0.21888284, 0.2976607 , 0.6892008 , 0.10385691,\n",
       "         0.78177935, 0.74319273, 0.29120317, 0.42726517, 0.8639506 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15128615, 0.23556036, 0.2221543 , 0.7005718 , 0.10918058,\n",
       "         0.7905214 , 0.74481153, 0.25717583, 0.43422052, 0.86023116]],\n",
       "       dtype=float32),\n",
       " array([[0.15477328, 0.21955343, 0.23164427, 0.70200294, 0.1132073 ,\n",
       "         0.7869504 , 0.74983555, 0.27394816, 0.42412907, 0.8634063 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16343114, 0.22390191, 0.28759953, 0.6877522 , 0.12321543,\n",
       "         0.7765606 , 0.7444501 , 0.2848833 , 0.42746472, 0.86601996]],\n",
       "       dtype=float32),\n",
       " array([[0.16582376, 0.22063641, 0.296422  , 0.68578225, 0.13094471,\n",
       "         0.7714178 , 0.74412704, 0.2867073 , 0.42569414, 0.86722654]],\n",
       "       dtype=float32),\n",
       " array([[0.16441584, 0.2565336 , 0.22242421, 0.69779927, 0.15557706,\n",
       "         0.77690923, 0.7417627 , 0.24094649, 0.43515936, 0.86651397]],\n",
       "       dtype=float32),\n",
       " array([[0.16034512, 0.28613913, 0.16979243, 0.6994959 , 0.15738985,\n",
       "         0.7796088 , 0.7413496 , 0.2103235 , 0.44096836, 0.8693043 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15707958, 0.31650147, 0.13335702, 0.69200265, 0.13576573,\n",
       "         0.7813972 , 0.7444619 , 0.18855116, 0.46144533, 0.86662036]],\n",
       "       dtype=float32),\n",
       " array([[0.15531376, 0.3064965 , 0.14795564, 0.69366145, 0.12363912,\n",
       "         0.78575176, 0.7456002 , 0.20728213, 0.45443827, 0.8641966 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16622224, 0.2649011 , 0.25225165, 0.6908831 , 0.15208295,\n",
       "         0.76959455, 0.73817766, 0.2608699 , 0.4293617 , 0.8680541 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15303761, 0.26404113, 0.19169886, 0.689779  , 0.11972802,\n",
       "         0.788745  , 0.7446101 , 0.23543166, 0.4413832 , 0.86449444]],\n",
       "       dtype=float32),\n",
       " array([[0.15909833, 0.23675293, 0.23152699, 0.68546945, 0.13447666,\n",
       "         0.78160685, 0.7465076 , 0.2591065 , 0.42993343, 0.8693368 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16642646, 0.2507693 , 0.2551438 , 0.6822172 , 0.13714951,\n",
       "         0.7755407 , 0.7465685 , 0.2747205 , 0.43185914, 0.8691519 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1641688 , 0.23711438, 0.25803512, 0.68673223, 0.1362168 ,\n",
       "         0.7743862 , 0.7467288 , 0.27855736, 0.42574617, 0.86883456]],\n",
       "       dtype=float32),\n",
       " array([[0.16018467, 0.2542882 , 0.23692879, 0.6804291 , 0.12232744,\n",
       "         0.786736  , 0.7471843 , 0.2659357 , 0.43575755, 0.86876523]],\n",
       "       dtype=float32),\n",
       " array([[0.16048248, 0.23432934, 0.2633262 , 0.67979455, 0.11767174,\n",
       "         0.79186434, 0.74632317, 0.28196976, 0.42675635, 0.8706328 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16145729, 0.24927066, 0.26018122, 0.6767596 , 0.12039324,\n",
       "         0.78954643, 0.7459193 , 0.27505443, 0.4343879 , 0.86967695]],\n",
       "       dtype=float32),\n",
       " array([[0.16141284, 0.25711894, 0.25874612, 0.68575126, 0.11946929,\n",
       "         0.7823557 , 0.74501246, 0.28041437, 0.43116444, 0.86713135]],\n",
       "       dtype=float32),\n",
       " array([[0.1612522 , 0.25577715, 0.25560024, 0.6917123 , 0.11822842,\n",
       "         0.7806538 , 0.7466392 , 0.28402656, 0.42961344, 0.8654972 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15989257, 0.2803373 , 0.2296881 , 0.6924806 , 0.11913045,\n",
       "         0.78199726, 0.7461312 , 0.2666764 , 0.43848756, 0.864042  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15182075, 0.28432384, 0.17313775, 0.6970716 , 0.10671391,\n",
       "         0.79333085, 0.75178474, 0.24211016, 0.44533378, 0.86195076]],\n",
       "       dtype=float32),\n",
       " array([[0.1542983 , 0.26576623, 0.21370354, 0.6910062 , 0.10877006,\n",
       "         0.7910893 , 0.74717695, 0.25898492, 0.43818426, 0.86413014]],\n",
       "       dtype=float32),\n",
       " array([[0.15741016, 0.25355512, 0.24230663, 0.6895401 , 0.1104996 ,\n",
       "         0.7878776 , 0.7478258 , 0.2764477 , 0.43361735, 0.86458683]],\n",
       "       dtype=float32),\n",
       " array([[0.15941039, 0.25207806, 0.25759977, 0.6889766 , 0.11331704,\n",
       "         0.78317577, 0.74586   , 0.28222236, 0.43110445, 0.8652456 ]],\n",
       "       dtype=float32),\n",
       " array([[0.161363  , 0.2572015 , 0.26705325, 0.68738097, 0.11767531,\n",
       "         0.77864754, 0.74633086, 0.28480488, 0.433468  , 0.8649774 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16125506, 0.23950073, 0.27922162, 0.6850803 , 0.11446571,\n",
       "         0.7825352 , 0.74656636, 0.29032937, 0.42909753, 0.8664544 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15841119, 0.23853901, 0.28027248, 0.68056846, 0.11052319,\n",
       "         0.7861296 , 0.7470311 , 0.2869724 , 0.43333912, 0.8661399 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17061152, 0.26483315, 0.3007902 , 0.6797313 , 0.13818382,\n",
       "         0.77435446, 0.7399499 , 0.27861977, 0.43795475, 0.86779106]],\n",
       "       dtype=float32),\n",
       " array([[0.1672798 , 0.26369134, 0.29176486, 0.6816583 , 0.1300186 ,\n",
       "         0.775943  , 0.73948544, 0.27975923, 0.43500957, 0.867577  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16547859, 0.25583223, 0.27271795, 0.6861509 , 0.13163292,\n",
       "         0.7783956 , 0.7401391 , 0.27166596, 0.43219978, 0.86795807]],\n",
       "       dtype=float32),\n",
       " array([[0.16392872, 0.23181757, 0.28060755, 0.6878278 , 0.12747899,\n",
       "         0.7785926 , 0.7411007 , 0.28053087, 0.4238097 , 0.8687223 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16548939, 0.22022909, 0.31110147, 0.6822916 , 0.12116183,\n",
       "         0.7786243 , 0.7420988 , 0.29419866, 0.42421496, 0.86783683]],\n",
       "       dtype=float32),\n",
       " array([[0.15997934, 0.21880896, 0.29034165, 0.68388855, 0.11034697,\n",
       "         0.7837342 , 0.74455285, 0.29075485, 0.42552182, 0.8660299 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15973027, 0.2377291 , 0.26264533, 0.6874318 , 0.11728605,\n",
       "         0.7836972 , 0.7445315 , 0.27602807, 0.43032935, 0.8660131 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16393024, 0.2464571 , 0.26151893, 0.68858045, 0.13145441,\n",
       "         0.77832085, 0.74402297, 0.27038905, 0.43187225, 0.86733156]],\n",
       "       dtype=float32),\n",
       " array([[0.16320905, 0.2378377 , 0.26564643, 0.68799025, 0.12813532,\n",
       "         0.77803236, 0.7445821 , 0.27643922, 0.42762393, 0.868321  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16170175, 0.24455328, 0.25298196, 0.6865954 , 0.12661465,\n",
       "         0.78342104, 0.74350023, 0.26504952, 0.43242246, 0.8679459 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16089699, 0.26042116, 0.24055815, 0.6861416 , 0.1242449 ,\n",
       "         0.782347  , 0.7430066 , 0.2599579 , 0.43646052, 0.8666139 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1636785 , 0.23506741, 0.2998505 , 0.67634565, 0.11454237,\n",
       "         0.7858687 , 0.7449785 , 0.29065433, 0.43238232, 0.86758465]],\n",
       "       dtype=float32),\n",
       " array([[0.16521887, 0.24128419, 0.32031894, 0.6729425 , 0.1096786 ,\n",
       "         0.77961123, 0.74539036, 0.30263457, 0.43391496, 0.86609983]],\n",
       "       dtype=float32),\n",
       " array([[0.16449134, 0.23701443, 0.2954061 , 0.68232197, 0.11713233,\n",
       "         0.7782916 , 0.7445931 , 0.29135662, 0.430242  , 0.86662495]],\n",
       "       dtype=float32),\n",
       " array([[0.16173111, 0.2419605 , 0.26793718, 0.68611044, 0.119485  ,\n",
       "         0.78030443, 0.74733007, 0.28149527, 0.43232173, 0.865925  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16245422, 0.2474184 , 0.27464542, 0.6818542 , 0.11931513,\n",
       "         0.7814229 , 0.7457555 , 0.28064236, 0.43483803, 0.86639464]],\n",
       "       dtype=float32),\n",
       " array([[0.16103546, 0.25366256, 0.24694793, 0.687383  , 0.12395775,\n",
       "         0.7842458 , 0.7449173 , 0.26641646, 0.43405983, 0.86774176]],\n",
       "       dtype=float32),\n",
       " array([[0.15618888, 0.2501018 , 0.21824837, 0.6918155 , 0.11728387,\n",
       "         0.7888642 , 0.7454673 , 0.25318402, 0.43537587, 0.86551756]],\n",
       "       dtype=float32),\n",
       " array([[0.1667176 , 0.22429366, 0.33823815, 0.67347413, 0.10766985,\n",
       "         0.7854189 , 0.7430574 , 0.30432934, 0.43087435, 0.866602  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15453431, 0.2330882 , 0.2741143 , 0.6782253 , 0.09693676,\n",
       "         0.79365313, 0.74749553, 0.28506047, 0.4355831 , 0.8634812 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16644894, 0.26457584, 0.24675733, 0.6951923 , 0.14115272,\n",
       "         0.77467936, 0.74245435, 0.25987458, 0.43543932, 0.86596006]],\n",
       "       dtype=float32),\n",
       " array([[0.15638849, 0.2536903 , 0.2060131 , 0.7013015 , 0.12468269,\n",
       "         0.78119254, 0.74602103, 0.2517758 , 0.43061683, 0.8650179 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15943159, 0.25497937, 0.23865786, 0.69069964, 0.12297424,\n",
       "         0.7812879 , 0.74544847, 0.26331547, 0.43625692, 0.8645252 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15716876, 0.26607156, 0.21253641, 0.69014776, 0.11748535,\n",
       "         0.7873568 , 0.7467696 , 0.2525148 , 0.44044945, 0.86445516]],\n",
       "       dtype=float32),\n",
       " array([[0.15785833, 0.2630446 , 0.20430271, 0.69157934, 0.12187569,\n",
       "         0.7866679 , 0.7461876 , 0.24391064, 0.4403959 , 0.86507267]],\n",
       "       dtype=float32),\n",
       " array([[0.15548462, 0.27402854, 0.19462302, 0.68878543, 0.11657821,\n",
       "         0.7885213 , 0.7464083 , 0.2384378 , 0.44553274, 0.86411196]],\n",
       "       dtype=float32),\n",
       " array([[0.15554754, 0.25023973, 0.22410163, 0.68713766, 0.11506721,\n",
       "         0.7887397 , 0.74620587, 0.2571954 , 0.4366675 , 0.86545545]],\n",
       "       dtype=float32),\n",
       " array([[0.1621678 , 0.25289634, 0.26018468, 0.68392855, 0.12457711,\n",
       "         0.7773683 , 0.74584866, 0.27470767, 0.43603814, 0.86501914]],\n",
       "       dtype=float32),\n",
       " array([[0.1604093 , 0.26209575, 0.24518062, 0.6818684 , 0.12567297,\n",
       "         0.7814114 , 0.7458968 , 0.26160726, 0.44165525, 0.8654735 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1467937 , 0.27882922, 0.16576143, 0.687506  , 0.10191415,\n",
       "         0.79832506, 0.74696237, 0.21987341, 0.45336255, 0.8616677 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15722731, 0.2664969 , 0.22657692, 0.6796859 , 0.11081119,\n",
       "         0.7915597 , 0.7464429 , 0.2577207 , 0.44396943, 0.8650696 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15724374, 0.25284016, 0.22122636, 0.68559337, 0.11287173,\n",
       "         0.79128915, 0.7508806 , 0.26330245, 0.4385993 , 0.8657639 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15907285, 0.252105  , 0.24135084, 0.68652534, 0.11928142,\n",
       "         0.7853979 , 0.749555  , 0.27209193, 0.43494388, 0.8666348 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15809326, 0.25193867, 0.22860375, 0.68889767, 0.11716326,\n",
       "         0.7869847 , 0.7485575 , 0.26668075, 0.43311697, 0.86718327]],\n",
       "       dtype=float32),\n",
       " array([[0.1666432 , 0.193498  , 0.36828765, 0.67161703, 0.11088166,\n",
       "         0.7908534 , 0.7498566 , 0.3268516 , 0.417551  , 0.8716888 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16107899, 0.20252499, 0.35514846, 0.66907763, 0.09496506,\n",
       "         0.79258025, 0.7500163 , 0.32680747, 0.42108762, 0.86832345]],\n",
       "       dtype=float32),\n",
       " array([[0.16343676, 0.20813842, 0.35925364, 0.67228746, 0.09465944,\n",
       "         0.7859191 , 0.74886507, 0.32905114, 0.42139104, 0.86708164]],\n",
       "       dtype=float32),\n",
       " array([[0.17134398, 0.24830173, 0.34960812, 0.67525715, 0.117796  ,\n",
       "         0.77075064, 0.7414515 , 0.311013  , 0.43155876, 0.86729676]],\n",
       "       dtype=float32),\n",
       " array([[0.1620344 , 0.24572231, 0.26266757, 0.6934709 , 0.11950658,\n",
       "         0.78145134, 0.7468003 , 0.28502417, 0.4282655 , 0.8664127 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16945848, 0.21273051, 0.34503174, 0.6837255 , 0.11290115,\n",
       "         0.7778924 , 0.74572664, 0.31535214, 0.42156017, 0.86787874]],\n",
       "       dtype=float32),\n",
       " array([[0.15339346, 0.21670295, 0.2664637 , 0.691894  , 0.09708998,\n",
       "         0.792257  , 0.7458813 , 0.28592956, 0.42551735, 0.86326   ]],\n",
       "       dtype=float32),\n",
       " array([[0.16310075, 0.24729247, 0.2686234 , 0.69054633, 0.13308589,\n",
       "         0.779376  , 0.7366011 , 0.26278508, 0.43302116, 0.86606914]],\n",
       "       dtype=float32),\n",
       " array([[0.16284153, 0.26020426, 0.2665765 , 0.6884967 , 0.12410993,\n",
       "         0.7792084 , 0.73859584, 0.26960352, 0.43543825, 0.86535305]],\n",
       "       dtype=float32),\n",
       " array([[0.17057785, 0.22079049, 0.32705235, 0.6859451 , 0.12902696,\n",
       "         0.76583475, 0.74063104, 0.2980485 , 0.42397738, 0.86714464]],\n",
       "       dtype=float32),\n",
       " array([[0.17029575, 0.2224713 , 0.30372703, 0.69097507, 0.14141087,\n",
       "         0.76299417, 0.7405228 , 0.28889787, 0.42106143, 0.8680485 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15864773, 0.23364909, 0.24114953, 0.69903505, 0.12740867,\n",
       "         0.7747138 , 0.742147  , 0.26539895, 0.42534646, 0.8647924 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16675796, 0.2049372 , 0.33488163, 0.6735948 , 0.11570011,\n",
       "         0.7864645 , 0.74301505, 0.30101728, 0.422943  , 0.86978513]],\n",
       "       dtype=float32),\n",
       " array([[0.16395414, 0.21626794, 0.2996086 , 0.6760306 , 0.11957287,\n",
       "         0.7895318 , 0.7468452 , 0.2921963 , 0.42428735, 0.8712476 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16518867, 0.2051929 , 0.30690852, 0.6794386 , 0.12252718,\n",
       "         0.7835647 , 0.74579763, 0.29402763, 0.4213179 , 0.86985683]],\n",
       "       dtype=float32),\n",
       " array([[0.16881269, 0.19598018, 0.34512654, 0.67663544, 0.11595182,\n",
       "         0.781864  , 0.7430895 , 0.30450436, 0.4207952 , 0.86866146]],\n",
       "       dtype=float32),\n",
       " array([[0.17163399, 0.1883145 , 0.36646518, 0.6778457 , 0.10711548,\n",
       "         0.7835181 , 0.7427292 , 0.31698215, 0.41170096, 0.8728305 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16292325, 0.20797858, 0.28204492, 0.6898258 , 0.12385473,\n",
       "         0.78744626, 0.7458682 , 0.2846939 , 0.41890782, 0.87100035]],\n",
       "       dtype=float32),\n",
       " array([[0.1566259 , 0.22200687, 0.22863679, 0.70120865, 0.12915464,\n",
       "         0.7861222 , 0.7431609 , 0.25834817, 0.42190754, 0.86788875]],\n",
       "       dtype=float32),\n",
       " array([[0.15634488, 0.23566331, 0.2112001 , 0.70627046, 0.13405666,\n",
       "         0.7841144 , 0.7432054 , 0.24927327, 0.4249693 , 0.8664328 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14949666, 0.24752347, 0.17128013, 0.70865965, 0.12342746,\n",
       "         0.79054564, 0.7456653 , 0.23438707, 0.42758834, 0.8656941 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15376194, 0.24010296, 0.1854737 , 0.70345396, 0.13328902,\n",
       "         0.7862122 , 0.7449002 , 0.23405552, 0.4301583 , 0.8650831 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14715353, 0.260631  , 0.14241928, 0.70968   , 0.12266684,\n",
       "         0.79205006, 0.7425847 , 0.20248748, 0.43749353, 0.862333  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15222712, 0.25941393, 0.15237929, 0.7099164 , 0.1355327 ,\n",
       "         0.78442055, 0.74322844, 0.2126784 , 0.43091294, 0.86522675]],\n",
       "       dtype=float32),\n",
       " array([[0.15605529, 0.2796242 , 0.15805605, 0.6968969 , 0.13399783,\n",
       "         0.78166455, 0.7470799 , 0.215334  , 0.44494137, 0.865342  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16577427, 0.28736162, 0.209955  , 0.69287634, 0.15183924,\n",
       "         0.7669356 , 0.7466861 , 0.24584106, 0.44192466, 0.8652071 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1617386 , 0.30895162, 0.18304837, 0.6878155 , 0.13787873,\n",
       "         0.7746105 , 0.7453059 , 0.22584048, 0.45285577, 0.86504245]],\n",
       "       dtype=float32),\n",
       " array([[0.15866695, 0.29017717, 0.17962568, 0.68267477, 0.12958166,\n",
       "         0.7791607 , 0.74686617, 0.22763722, 0.45043114, 0.8673266 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16360268, 0.28932357, 0.20584102, 0.66919833, 0.13192731,\n",
       "         0.7796441 , 0.7458503 , 0.2349271 , 0.45557725, 0.87074476]],\n",
       "       dtype=float32),\n",
       " array([[0.1600195 , 0.2890559 , 0.2122367 , 0.6733059 , 0.12844001,\n",
       "         0.78100574, 0.7462172 , 0.24408653, 0.4508107 , 0.86881924]],\n",
       "       dtype=float32),\n",
       " array([[0.15830183, 0.27594206, 0.21768291, 0.6766563 , 0.12388699,\n",
       "         0.7844837 , 0.74687403, 0.25147778, 0.445145  , 0.86839384]],\n",
       "       dtype=float32),\n",
       " array([[0.15831248, 0.2521409 , 0.24066451, 0.6838811 , 0.12316877,\n",
       "         0.78544766, 0.7452409 , 0.26917866, 0.43067223, 0.8689023 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15940805, 0.26105523, 0.2529044 , 0.6807379 , 0.11732408,\n",
       "         0.7871443 , 0.74561006, 0.27622503, 0.43536973, 0.8671326 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16480856, 0.2578246 , 0.2959804 , 0.68063134, 0.11749557,\n",
       "         0.78093857, 0.74609023, 0.30236906, 0.43161523, 0.8664443 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16238554, 0.23579967, 0.3041887 , 0.6810354 , 0.11309789,\n",
       "         0.7839041 , 0.74680287, 0.3082322 , 0.42393926, 0.868298  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16292974, 0.22500455, 0.34558555, 0.67089665, 0.10120097,\n",
       "         0.7871686 , 0.74563146, 0.3227196 , 0.42420346, 0.8680588 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16456677, 0.24934843, 0.3342045 , 0.67234063, 0.10209782,\n",
       "         0.78320444, 0.7464666 , 0.320083  , 0.43137527, 0.86586416]],\n",
       "       dtype=float32),\n",
       " array([[0.16389191, 0.23906341, 0.33523735, 0.6735201 , 0.1017151 ,\n",
       "         0.7843746 , 0.7462188 , 0.31781572, 0.42967013, 0.8659375 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16227643, 0.2604801 , 0.29201797, 0.6828963 , 0.11249831,\n",
       "         0.7804427 , 0.74466527, 0.2959644 , 0.43362808, 0.8651238 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16633652, 0.24559222, 0.34291232, 0.672689  , 0.10373087,\n",
       "         0.78217864, 0.74474025, 0.31314692, 0.43541455, 0.8642157 ]],\n",
       "       dtype=float32),\n",
       " array([[0.159609  , 0.278285  , 0.2677017 , 0.68637186, 0.10711015,\n",
       "         0.7818284 , 0.7447651 , 0.2856084 , 0.4404765 , 0.86198246]],\n",
       "       dtype=float32),\n",
       " array([[0.16019154, 0.27970886, 0.23080933, 0.69572234, 0.12686574,\n",
       "         0.78170854, 0.7425145 , 0.25629362, 0.4410914 , 0.86301386]],\n",
       "       dtype=float32),\n",
       " array([[0.15571573, 0.2891857 , 0.18201771, 0.7043782 , 0.1251626 ,\n",
       "         0.7829354 , 0.74428976, 0.23570865, 0.44080618, 0.86226547]],\n",
       "       dtype=float32),\n",
       " array([[0.15336931, 0.26374412, 0.17984198, 0.70684916, 0.12020058,\n",
       "         0.78617895, 0.74812967, 0.24263027, 0.43400368, 0.8627373 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15809101, 0.28827962, 0.18455678, 0.7004716 , 0.13281842,\n",
       "         0.77972823, 0.7422869 , 0.22494139, 0.4447141 , 0.86231667]],\n",
       "       dtype=float32),\n",
       " array([[0.16009828, 0.29165235, 0.18496688, 0.69596094, 0.13486025,\n",
       "         0.7779408 , 0.7425491 , 0.22332807, 0.44703323, 0.86373   ]],\n",
       "       dtype=float32),\n",
       " array([[0.1622491 , 0.28767338, 0.2002636 , 0.68970114, 0.1374597 ,\n",
       "         0.77507716, 0.74418133, 0.23579049, 0.4450074 , 0.866235  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16202083, 0.29538688, 0.200304  , 0.68353856, 0.12810983,\n",
       "         0.7781256 , 0.74635655, 0.24021251, 0.45031804, 0.86579233]],\n",
       "       dtype=float32),\n",
       " array([[0.16644986, 0.27855432, 0.25016978, 0.68144757, 0.134851  ,\n",
       "         0.77344453, 0.74551713, 0.2669723 , 0.44272438, 0.86601424]],\n",
       "       dtype=float32),\n",
       " array([[0.16563463, 0.25848335, 0.27810344, 0.6787877 , 0.12878932,\n",
       "         0.7770909 , 0.7450064 , 0.28466967, 0.43515363, 0.8673026 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1638059 , 0.23377343, 0.30280313, 0.67916244, 0.11847997,\n",
       "         0.78400856, 0.74477977, 0.299721  , 0.426692  , 0.8684497 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16736299, 0.22440325, 0.3424212 , 0.67074305, 0.11500848,\n",
       "         0.78810394, 0.7471047 , 0.31916305, 0.42422765, 0.87101865]],\n",
       "       dtype=float32),\n",
       " array([[0.16974217, 0.22204302, 0.34292436, 0.6764742 , 0.12298193,\n",
       "         0.78095144, 0.7457462 , 0.31677642, 0.42194018, 0.8707468 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16459636, 0.2350945 , 0.3104897 , 0.68115157, 0.11542071,\n",
       "         0.78161514, 0.7451734 , 0.30545145, 0.4250194 , 0.8685403 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16318539, 0.24598292, 0.2797724 , 0.6872062 , 0.12132985,\n",
       "         0.7818802 , 0.74441916, 0.28805697, 0.42865798, 0.86751264]],\n",
       "       dtype=float32),\n",
       " array([[0.16315654, 0.22767058, 0.31914973, 0.6787367 , 0.10696087,\n",
       "         0.7878887 , 0.74562436, 0.30654517, 0.42752612, 0.8669753 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15670383, 0.23508996, 0.28174144, 0.6816873 , 0.10455194,\n",
       "         0.7915657 , 0.74561006, 0.28716296, 0.4333728 , 0.8643811 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15438066, 0.2297972 , 0.27967313, 0.68590194, 0.09653534,\n",
       "         0.79073197, 0.74554366, 0.28990114, 0.4315073 , 0.8622188 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15932359, 0.22933988, 0.31030616, 0.6817751 , 0.09756892,\n",
       "         0.78293353, 0.74474704, 0.3023614 , 0.43024328, 0.8630292 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16146259, 0.24130586, 0.3120949 , 0.6798522 , 0.10189652,\n",
       "         0.77702296, 0.744877  , 0.30198503, 0.4339583 , 0.8626285 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16734977, 0.25407943, 0.29393536, 0.68820775, 0.12667021,\n",
       "         0.76877123, 0.7446358 , 0.29162633, 0.4338324 , 0.8641854 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15886606, 0.25513417, 0.23377809, 0.69722444, 0.12502928,\n",
       "         0.7805774 , 0.7448535 , 0.2641595 , 0.4331515 , 0.86420506]],\n",
       "       dtype=float32),\n",
       " array([[0.1631628 , 0.23083453, 0.281679  , 0.6865895 , 0.12176773,\n",
       "         0.7822995 , 0.7448801 , 0.28567046, 0.42682484, 0.8677575 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15938804, 0.21703878, 0.30372283, 0.67556006, 0.10218565,\n",
       "         0.79760426, 0.7476582 , 0.2964416 , 0.4292885 , 0.8669487 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15826876, 0.21829806, 0.2755217 , 0.68556637, 0.11076405,\n",
       "         0.78807694, 0.7455133 , 0.28389707, 0.42610633, 0.8663386 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15955961, 0.21255092, 0.274285  , 0.69035554, 0.1172119 ,\n",
       "         0.78669786, 0.74392164, 0.27976096, 0.42310464, 0.86736023]],\n",
       "       dtype=float32),\n",
       " array([[0.16153052, 0.20698619, 0.26453504, 0.6987266 , 0.1276406 ,\n",
       "         0.7793723 , 0.7453814 , 0.2792697 , 0.41757587, 0.8677989 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16124237, 0.23392013, 0.2298833 , 0.69858617, 0.1375297 ,\n",
       "         0.7800246 , 0.74603826, 0.26143983, 0.42479673, 0.86830294]],\n",
       "       dtype=float32),\n",
       " array([[0.15715632, 0.25027528, 0.18669637, 0.7054511 , 0.14458847,\n",
       "         0.7828289 , 0.740792  , 0.22436538, 0.42993033, 0.8668518 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16412547, 0.20907368, 0.29098716, 0.6870946 , 0.12708035,\n",
       "         0.78729504, 0.7431439 , 0.281803  , 0.4226912 , 0.8694211 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15669091, 0.20634487, 0.26621857, 0.6835441 , 0.10976058,\n",
       "         0.79475254, 0.7465062 , 0.28108072, 0.42228487, 0.86876553]],\n",
       "       dtype=float32),\n",
       " array([[0.16218477, 0.19149403, 0.2981897 , 0.68523633, 0.11205427,\n",
       "         0.7872799 , 0.7465384 , 0.29811233, 0.4144746 , 0.8696546 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1638109 , 0.18207975, 0.31822273, 0.6857807 , 0.11089925,\n",
       "         0.78110504, 0.7462885 , 0.30459264, 0.4118262 , 0.8694122 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16521771, 0.20496   , 0.30267787, 0.68865544, 0.12010264,\n",
       "         0.7756693 , 0.74527514, 0.29616553, 0.4174485 , 0.869419  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16532569, 0.21090925, 0.3004942 , 0.6871545 , 0.12064935,\n",
       "         0.7793795 , 0.7454227 , 0.29431367, 0.41916427, 0.8703012 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16752031, 0.23705462, 0.28290433, 0.6852053 , 0.13438404,\n",
       "         0.7816239 , 0.7471628 , 0.28471774, 0.42795956, 0.87082314]],\n",
       "       dtype=float32),\n",
       " array([[0.16271679, 0.233245  , 0.27551466, 0.6868164 , 0.1217705 ,\n",
       "         0.78792816, 0.7443513 , 0.2785018 , 0.42905995, 0.868611  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15842098, 0.23404163, 0.2547132 , 0.6901918 , 0.11592301,\n",
       "         0.7918838 , 0.74377894, 0.2715644 , 0.42710853, 0.8688169 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15824118, 0.23498413, 0.2247443 , 0.6996448 , 0.13218325,\n",
       "         0.78495944, 0.7442212 , 0.25362337, 0.42948815, 0.865254  ]],\n",
       "       dtype=float32),\n",
       " array([[0.1612919 , 0.23656644, 0.2610339 , 0.6950667 , 0.12334258,\n",
       "         0.78063285, 0.7422271 , 0.27120414, 0.42947817, 0.86490357]],\n",
       "       dtype=float32),\n",
       " array([[0.15544258, 0.23159082, 0.23303382, 0.7009289 , 0.12128567,\n",
       "         0.77979434, 0.74327695, 0.26153517, 0.42698017, 0.8634929 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16691665, 0.28138682, 0.25059283, 0.6917443 , 0.13525373,\n",
       "         0.76774305, 0.7418197 , 0.2688148 , 0.4384985 , 0.86388147]],\n",
       "       dtype=float32),\n",
       " array([[0.15350473, 0.28235257, 0.18302834, 0.69407475, 0.12432504,\n",
       "         0.7866812 , 0.74630505, 0.2314708 , 0.44722518, 0.86189204]],\n",
       "       dtype=float32),\n",
       " array([[0.15881439, 0.30638814, 0.16594769, 0.6939597 , 0.13808961,\n",
       "         0.7812743 , 0.7438718 , 0.20951591, 0.45454746, 0.8630287 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16032286, 0.28156546, 0.18202658, 0.6929314 , 0.13838826,\n",
       "         0.78251576, 0.7454698 , 0.22994669, 0.44084936, 0.86819   ]],\n",
       "       dtype=float32),\n",
       " array([[0.16170658, 0.26513207, 0.23654477, 0.68029183, 0.13466567,\n",
       "         0.7813244 , 0.74378866, 0.25291297, 0.44245878, 0.8662635 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15824479, 0.24957848, 0.23437478, 0.6820447 , 0.12218846,\n",
       "         0.7872174 , 0.74727905, 0.26384822, 0.4361147 , 0.8669421 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15649703, 0.2799295 , 0.2049586 , 0.68507826, 0.12051902,\n",
       "         0.78825885, 0.7466323 , 0.24606913, 0.4451012 , 0.8654898 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16165625, 0.3106746 , 0.16828279, 0.686698  , 0.13823906,\n",
       "         0.77529097, 0.74521405, 0.21132004, 0.45772776, 0.86573726]],\n",
       "       dtype=float32),\n",
       " array([[0.16473086, 0.31788045, 0.17266107, 0.6883707 , 0.14624411,\n",
       "         0.76964915, 0.7433554 , 0.21382692, 0.45392084, 0.86752415]],\n",
       "       dtype=float32),\n",
       " array([[0.15986711, 0.3154639 , 0.16597569, 0.6900504 , 0.13230956,\n",
       "         0.77569896, 0.74343014, 0.21187352, 0.45523232, 0.86429125]],\n",
       "       dtype=float32),\n",
       " array([[0.16240989, 0.35059512, 0.13531062, 0.6707639 , 0.13100553,\n",
       "         0.76223737, 0.7411671 , 0.18402563, 0.49227852, 0.86159927]],\n",
       "       dtype=float32),\n",
       " array([[0.15279333, 0.32366604, 0.12107775, 0.676061  , 0.10864852,\n",
       "         0.77845794, 0.744011  , 0.18447669, 0.47642553, 0.86326957]],\n",
       "       dtype=float32),\n",
       " array([[0.15765266, 0.30842048, 0.18015742, 0.6757175 , 0.11401402,\n",
       "         0.7818544 , 0.7473243 , 0.22939071, 0.4578359 , 0.8645462 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16361897, 0.3055966 , 0.22024623, 0.6764342 , 0.12292346,\n",
       "         0.77668184, 0.7457815 , 0.25025824, 0.45199203, 0.86420137]],\n",
       "       dtype=float32),\n",
       " array([[0.16542087, 0.27315244, 0.28220412, 0.6789861 , 0.1313018 ,\n",
       "         0.77387124, 0.7478969 , 0.29555434, 0.4333092 , 0.8662253 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17349564, 0.25671756, 0.367483  , 0.6722918 , 0.12922873,\n",
       "         0.77293193, 0.7474362 , 0.34016272, 0.42333618, 0.8701915 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16607998, 0.25162753, 0.34353092, 0.6702456 , 0.11727864,\n",
       "         0.78413785, 0.7479617 , 0.33283642, 0.42110547, 0.8719598 ]],\n",
       "       dtype=float32),\n",
       " array([[0.166253  , 0.2645207 , 0.32797688, 0.670798  , 0.11361736,\n",
       "         0.78851676, 0.7472923 , 0.32238808, 0.4289051 , 0.8699273 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16671771, 0.24502164, 0.3541659 , 0.673228  , 0.10653572,\n",
       "         0.78856087, 0.7457001 , 0.33369824, 0.4220865 , 0.8699417 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16179293, 0.26296076, 0.31951284, 0.6754786 , 0.10077003,\n",
       "         0.7909088 , 0.7463739 , 0.3213147 , 0.4270576 , 0.8683813 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16255884, 0.24298793, 0.3432467 , 0.67693233, 0.09777278,\n",
       "         0.78799504, 0.745331  , 0.3251243 , 0.426788  , 0.86583465]],\n",
       "       dtype=float32),\n",
       " array([[0.15565   , 0.25276762, 0.2744883 , 0.69008017, 0.10176793,\n",
       "         0.79034203, 0.74266607, 0.28776816, 0.43386716, 0.8608297 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14481917, 0.25644815, 0.20760494, 0.70232666, 0.0937464 ,\n",
       "         0.79751873, 0.74451095, 0.2623615 , 0.43113476, 0.86018556]],\n",
       "       dtype=float32),\n",
       " array([[0.15571252, 0.26599306, 0.22890449, 0.69678414, 0.11947087,\n",
       "         0.7862421 , 0.74119073, 0.2548359 , 0.43653274, 0.8625073 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14934137, 0.25846425, 0.17940617, 0.7065172 , 0.11377618,\n",
       "         0.78704625, 0.7456494 , 0.2363405 , 0.43485764, 0.85993487]],\n",
       "       dtype=float32),\n",
       " array([[0.15642957, 0.23547879, 0.24545428, 0.70251864, 0.1195612 ,\n",
       "         0.77679396, 0.74472874, 0.27650052, 0.4237835 , 0.86225563]],\n",
       "       dtype=float32),\n",
       " array([[0.15493451, 0.22297314, 0.24868141, 0.69679224, 0.11511749,\n",
       "         0.7834628 , 0.7443037 , 0.27557924, 0.42202935, 0.8646275 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17008801, 0.19946784, 0.3761012 , 0.6738327 , 0.11636741,\n",
       "         0.7798957 , 0.747411  , 0.32968822, 0.41875187, 0.8695296 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1680819 , 0.21121614, 0.36489734, 0.67002046, 0.1125302 ,\n",
       "         0.7827433 , 0.7453982 , 0.32293892, 0.42146847, 0.8701046 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17521441, 0.21887745, 0.3977035 , 0.6669838 , 0.11658464,\n",
       "         0.7739357 , 0.74631983, 0.3357792 , 0.4234532 , 0.8699447 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17589287, 0.20829016, 0.39394635, 0.6710889 , 0.11956479,\n",
       "         0.7838147 , 0.74617594, 0.33228907, 0.4193315 , 0.87209016]],\n",
       "       dtype=float32),\n",
       " array([[0.17399383, 0.17610864, 0.41099697, 0.67547125, 0.10414521,\n",
       "         0.78568435, 0.74574757, 0.3422781 , 0.406015  , 0.87351286]],\n",
       "       dtype=float32),\n",
       " array([[0.16826048, 0.18767937, 0.37213817, 0.6747791 , 0.10857671,\n",
       "         0.79334444, 0.7437175 , 0.31925622, 0.41338295, 0.8734772 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17067097, 0.12631339, 0.42719057, 0.69226956, 0.09026643,\n",
       "         0.79516935, 0.7444424 , 0.34370628, 0.38898927, 0.8745661 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16843921, 0.14010638, 0.39321125, 0.69363695, 0.10004404,\n",
       "         0.78969175, 0.7425968 , 0.32552624, 0.39664012, 0.87294185]],\n",
       "       dtype=float32),\n",
       " array([[0.1750857 , 0.09815603, 0.4531136 , 0.71106654, 0.08431053,\n",
       "         0.78754723, 0.7462413 , 0.35981703, 0.36912173, 0.8769799 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16707903, 0.14293209, 0.36331445, 0.7072738 , 0.11441772,\n",
       "         0.77899987, 0.7450998 , 0.31057268, 0.40478206, 0.8668629 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1661358 , 0.13932027, 0.3572083 , 0.71191245, 0.10396436,\n",
       "         0.7774959 , 0.7394662 , 0.3081004 , 0.39554566, 0.8701562 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16190483, 0.17901918, 0.2933189 , 0.70654255, 0.1356871 ,\n",
       "         0.78269315, 0.7431349 , 0.28020474, 0.41633335, 0.86551875]],\n",
       "       dtype=float32),\n",
       " array([[0.13684869, 0.2657584 , 0.14528644, 0.7165857 , 0.11931103,\n",
       "         0.8002932 , 0.7403673 , 0.21216416, 0.43663028, 0.8589121 ]],\n",
       "       dtype=float32),\n",
       " array([[0.13969995, 0.30054682, 0.11949354, 0.7103773 , 0.12996754,\n",
       "         0.7956766 , 0.74584174, 0.18955243, 0.45457196, 0.8555328 ]],\n",
       "       dtype=float32),\n",
       " array([[0.12491024, 0.31122717, 0.07431024, 0.71783495, 0.09841932,\n",
       "         0.8146947 , 0.74133736, 0.14560741, 0.46871886, 0.8476165 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15063937, 0.2949188 , 0.15390608, 0.70336163, 0.14739095,\n",
       "         0.7768907 , 0.746457  , 0.21592319, 0.4464797 , 0.8586051 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15448876, 0.22450756, 0.23637009, 0.692181  , 0.12948358,\n",
       "         0.7942067 , 0.7459726 , 0.26016557, 0.43503097, 0.8619238 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1784473 , 0.23474313, 0.33111197, 0.68593484, 0.16682243,\n",
       "         0.73597366, 0.7450693 , 0.31192818, 0.4239201 , 0.86656004]],\n",
       "       dtype=float32),\n",
       " array([[0.16806301, 0.24124593, 0.28550798, 0.6722272 , 0.14959843,\n",
       "         0.7806685 , 0.7475974 , 0.29049498, 0.42750552, 0.87368864]],\n",
       "       dtype=float32),\n",
       " array([[0.1783682 , 0.26766506, 0.2913956 , 0.6733397 , 0.18792093,\n",
       "         0.75595224, 0.7493474 , 0.2824753 , 0.44047007, 0.86947125]],\n",
       "       dtype=float32),\n",
       " array([[0.16560379, 0.3640853 , 0.13462056, 0.64269686, 0.14876644,\n",
       "         0.75773567, 0.7454127 , 0.1799365 , 0.50544506, 0.8716062 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16572097, 0.2826166 , 0.23435628, 0.6773591 , 0.15221854,\n",
       "         0.7830108 , 0.74579364, 0.25856075, 0.4382379 , 0.8722085 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15539628, 0.3712031 , 0.12028312, 0.64178395, 0.12302344,\n",
       "         0.7749364 , 0.74074465, 0.1749831 , 0.5194886 , 0.8642492 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15150987, 0.3832448 , 0.08448759, 0.6735968 , 0.14201577,\n",
       "         0.7533542 , 0.7365537 , 0.1786624 , 0.51087004, 0.8554011 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14872482, 0.40443602, 0.07762773, 0.6781156 , 0.12915422,\n",
       "         0.7604503 , 0.7377362 , 0.16801704, 0.5076638 , 0.854299  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15860406, 0.34306827, 0.15820831, 0.6950949 , 0.13284986,\n",
       "         0.7721892 , 0.74592245, 0.20521313, 0.45203906, 0.8592766 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16517523, 0.3098744 , 0.23119397, 0.68972176, 0.14153059,\n",
       "         0.77014625, 0.74914867, 0.2620905 , 0.43352947, 0.86440367]],\n",
       "       dtype=float32),\n",
       " array([[0.16424492, 0.27533603, 0.2933029 , 0.6884171 , 0.12878515,\n",
       "         0.77576786, 0.7486183 , 0.30903572, 0.4201038 , 0.86517954]],\n",
       "       dtype=float32),\n",
       " array([[0.17177664, 0.28172773, 0.35729033, 0.6578744 , 0.13082494,\n",
       "         0.7897889 , 0.7522642 , 0.33277163, 0.42541045, 0.8764821 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1664519 , 0.3225092 , 0.23803204, 0.65843976, 0.12469301,\n",
       "         0.7851792 , 0.75091463, 0.25910062, 0.4568051 , 0.87256354]],\n",
       "       dtype=float32),\n",
       " array([[0.17082764, 0.31433657, 0.27640915, 0.67706585, 0.12826309,\n",
       "         0.78098965, 0.7497446 , 0.30247664, 0.43226478, 0.87032616]],\n",
       "       dtype=float32),\n",
       " array([[0.16886327, 0.26615   , 0.36376566, 0.67724115, 0.10740255,\n",
       "         0.78783613, 0.746938  , 0.34436795, 0.4171466 , 0.86966735]],\n",
       "       dtype=float32),\n",
       " array([[0.15784653, 0.2930695 , 0.30772385, 0.67390543, 0.09338008,\n",
       "         0.8018233 , 0.7463408 , 0.31839743, 0.42871273, 0.8673092 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14535408, 0.28693804, 0.19995804, 0.683133  , 0.0904457 ,\n",
       "         0.8123464 , 0.74736017, 0.25565264, 0.43979114, 0.8646014 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15344846, 0.3069386 , 0.22047001, 0.6845817 , 0.10364658,\n",
       "         0.8020796 , 0.74381256, 0.25066584, 0.44986376, 0.8617787 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14561577, 0.2910029 , 0.15389876, 0.7078858 , 0.10192998,\n",
       "         0.79415596, 0.74461186, 0.21915115, 0.44108075, 0.8575171 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15968065, 0.27880123, 0.21496803, 0.7032926 , 0.13145497,\n",
       "         0.7720644 , 0.7438367 , 0.25767782, 0.42753875, 0.86288756]],\n",
       "       dtype=float32),\n",
       " array([[0.15965861, 0.25012344, 0.25182366, 0.7031459 , 0.12617701,\n",
       "         0.77280414, 0.7452625 , 0.28316224, 0.4206291 , 0.86198467]],\n",
       "       dtype=float32),\n",
       " array([[0.14499606, 0.27373385, 0.15793677, 0.70238763, 0.09787894,\n",
       "         0.7985454 , 0.7449856 , 0.22353095, 0.43843085, 0.8603584 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16652195, 0.22777008, 0.35268095, 0.6771235 , 0.11728776,\n",
       "         0.7866105 , 0.74525076, 0.32309017, 0.42019388, 0.8698167 ]],\n",
       "       dtype=float32),\n",
       " array([[0.18638468, 0.21930657, 0.49572712, 0.6578673 , 0.1162499 ,\n",
       "         0.7676773 , 0.7441054 , 0.37918192, 0.41621622, 0.8718677 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16965751, 0.23223148, 0.38926885, 0.67299294, 0.11242842,\n",
       "         0.7701241 , 0.74717855, 0.3420047 , 0.4180065 , 0.8711714 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17303407, 0.25038782, 0.3587951 , 0.6808868 , 0.12553944,\n",
       "         0.7722016 , 0.7464844 , 0.32665026, 0.42698747, 0.8677517 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16853562, 0.25699383, 0.2941758 , 0.684334  , 0.13224535,\n",
       "         0.7845372 , 0.74435854, 0.29015097, 0.43098623, 0.8694882 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16028444, 0.21697007, 0.30371833, 0.68189985, 0.11517199,\n",
       "         0.7998248 , 0.7471462 , 0.2987531 , 0.41904116, 0.8732779 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15144984, 0.23930246, 0.24729079, 0.68728805, 0.10361452,\n",
       "         0.80437976, 0.74373657, 0.26631233, 0.43367532, 0.8655302 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14289546, 0.20853554, 0.2382935 , 0.7024242 , 0.08470403,\n",
       "         0.8050795 , 0.744057  , 0.27454388, 0.4214715 , 0.86098295]],\n",
       "       dtype=float32),\n",
       " array([[0.15599264, 0.17554513, 0.34376177, 0.6945197 , 0.08749324,\n",
       "         0.78849036, 0.73998755, 0.3109558 , 0.4089787 , 0.8663688 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1562566 , 0.18094844, 0.30292436, 0.6992547 , 0.1123591 ,\n",
       "         0.78404063, 0.74562293, 0.2929427 , 0.4168232 , 0.86267936]],\n",
       "       dtype=float32),\n",
       " array([[0.15148483, 0.2003438 , 0.21135269, 0.7144142 , 0.12681645,\n",
       "         0.7808278 , 0.75016886, 0.25975913, 0.4180827 , 0.86008364]],\n",
       "       dtype=float32),\n",
       " array([[0.15735362, 0.24539424, 0.20767619, 0.70355237, 0.1428416 ,\n",
       "         0.77493775, 0.74325657, 0.2385082 , 0.43157598, 0.862354  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15868188, 0.27465954, 0.19995272, 0.69511855, 0.12731723,\n",
       "         0.7836404 , 0.7425416 , 0.24021655, 0.4379669 , 0.8652933 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1660557 , 0.3457568 , 0.13690053, 0.6799676 , 0.12045862,\n",
       "         0.77818155, 0.7431809 , 0.17688322, 0.48688343, 0.8604876 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16481723, 0.30665982, 0.14785016, 0.69467574, 0.13360594,\n",
       "         0.7697961 , 0.74592185, 0.20636465, 0.45155463, 0.86521524]],\n",
       "       dtype=float32),\n",
       " array([[0.16657831, 0.29123682, 0.1965243 , 0.68894255, 0.14777663,\n",
       "         0.7689902 , 0.7433456 , 0.2293655 , 0.44445896, 0.8675835 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15656526, 0.28788346, 0.16491844, 0.69342947, 0.12927808,\n",
       "         0.7738177 , 0.7464288 , 0.21752831, 0.44823572, 0.86153996]],\n",
       "       dtype=float32),\n",
       " array([[0.16430266, 0.30335462, 0.16771464, 0.67375106, 0.14207645,\n",
       "         0.75686586, 0.74646735, 0.20254956, 0.47485015, 0.8612755 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1520042 , 0.2544607 , 0.18074958, 0.6774158 , 0.1276388 ,\n",
       "         0.7818796 , 0.7456253 , 0.21927717, 0.45251945, 0.86592215]],\n",
       "       dtype=float32),\n",
       " array([[0.17223498, 0.2596507 , 0.29007867, 0.6623787 , 0.1479556 ,\n",
       "         0.77128357, 0.74734575, 0.27444208, 0.4456599 , 0.87282723]],\n",
       "       dtype=float32),\n",
       " array([[0.16947979, 0.2544763 , 0.27980542, 0.670324  , 0.12822238,\n",
       "         0.7846285 , 0.74742246, 0.2965945 , 0.42733622, 0.8749676 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16904885, 0.22841085, 0.31242585, 0.67893314, 0.13416421,\n",
       "         0.7796623 , 0.74716187, 0.31713605, 0.4138383 , 0.8736625 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1566454 , 0.26263338, 0.21569577, 0.67286426, 0.11729477,\n",
       "         0.789307  , 0.7456274 , 0.24717942, 0.44395205, 0.87094975]],\n",
       "       dtype=float32),\n",
       " array([[0.1562866 , 0.27165586, 0.19355588, 0.67954534, 0.12087934,\n",
       "         0.78330356, 0.7467628 , 0.23833753, 0.44439876, 0.86999804]],\n",
       "       dtype=float32),\n",
       " array([[0.15296623, 0.25460482, 0.22870755, 0.6756978 , 0.11244742,\n",
       "         0.7979649 , 0.74638456, 0.2589309 , 0.4375356 , 0.8711089 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16251802, 0.2603503 , 0.29524514, 0.68971837, 0.12121321,\n",
       "         0.78198624, 0.7442378 , 0.30866838, 0.42113513, 0.8669031 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16309474, 0.28689164, 0.23805673, 0.684603  , 0.12931944,\n",
       "         0.7823543 , 0.7375424 , 0.23944563, 0.4505043 , 0.86371183]],\n",
       "       dtype=float32),\n",
       " array([[0.14904931, 0.27731267, 0.1490653 , 0.6993303 , 0.10634492,\n",
       "         0.7835513 , 0.7454928 , 0.21548657, 0.4435295 , 0.86066425]],\n",
       "       dtype=float32),\n",
       " array([[0.16393894, 0.22177693, 0.332871  , 0.68833196, 0.11737397,\n",
       "         0.78660977, 0.7464213 , 0.33301568, 0.4084314 , 0.87030286]],\n",
       "       dtype=float32),\n",
       " array([[0.17857167, 0.20661898, 0.46515134, 0.67697895, 0.10936794,\n",
       "         0.7646383 , 0.74389195, 0.38728455, 0.40154025, 0.87149245]],\n",
       "       dtype=float32),\n",
       " array([[0.15775678, 0.21492796, 0.3235227 , 0.6855468 , 0.10550684,\n",
       "         0.79305017, 0.74796456, 0.32540804, 0.41528076, 0.8667301 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16018228, 0.2487273 , 0.30041915, 0.6888216 , 0.11302894,\n",
       "         0.788334  , 0.7446435 , 0.30576342, 0.4258755 , 0.86501753]],\n",
       "       dtype=float32),\n",
       " array([[0.16583078, 0.24908532, 0.33131257, 0.6796242 , 0.1151471 ,\n",
       "         0.7898378 , 0.7495008 , 0.3285012 , 0.42133737, 0.8713142 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16590253, 0.23620963, 0.31797156, 0.6865273 , 0.12446632,\n",
       "         0.7799396 , 0.7492833 , 0.31833896, 0.4210478 , 0.86835337]],\n",
       "       dtype=float32),\n",
       " array([[0.15547419, 0.23803726, 0.24764617, 0.69919914, 0.11544987,\n",
       "         0.78826046, 0.7449118 , 0.27546942, 0.426526  , 0.86326176]],\n",
       "       dtype=float32),\n",
       " array([[0.15785351, 0.21130808, 0.34972835, 0.68653977, 0.08710117,\n",
       "         0.7972242 , 0.7401021 , 0.31604636, 0.42282042, 0.8637711 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14956823, 0.22569066, 0.280827  , 0.6838961 , 0.08688857,\n",
       "         0.80766815, 0.74689364, 0.30006364, 0.4243963 , 0.8656682 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16150883, 0.21967785, 0.28884685, 0.6945085 , 0.12377682,\n",
       "         0.78276545, 0.746858  , 0.2942157 , 0.42230412, 0.8658058 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1620212 , 0.21102159, 0.2997367 , 0.7095763 , 0.11903159,\n",
       "         0.7576872 , 0.7444446 , 0.3067605 , 0.41408372, 0.8606881 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16309194, 0.21361698, 0.30366337, 0.70204496, 0.12038167,\n",
       "         0.7680123 , 0.74385995, 0.30314898, 0.4162557 , 0.86374086]],\n",
       "       dtype=float32),\n",
       " array([[0.16838337, 0.20573299, 0.35734096, 0.6805847 , 0.11408944,\n",
       "         0.7833669 , 0.7454361 , 0.32132462, 0.41566786, 0.8712568 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15946218, 0.1862287 , 0.34340322, 0.67280006, 0.10205711,\n",
       "         0.8027307 , 0.7452741 , 0.3083925 , 0.41947222, 0.8691661 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15498868, 0.20329021, 0.30587286, 0.6829487 , 0.09468075,\n",
       "         0.7981131 , 0.74666923, 0.30184   , 0.42068624, 0.8672208 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16919927, 0.1754537 , 0.40480667, 0.6777973 , 0.0937664 ,\n",
       "         0.7880909 , 0.7454222 , 0.33660042, 0.40887225, 0.8717451 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16704108, 0.19449286, 0.35349736, 0.68843955, 0.10972005,\n",
       "         0.77242565, 0.74537814, 0.31597376, 0.41665006, 0.8673006 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17294313, 0.17704667, 0.38907263, 0.6905747 , 0.10733525,\n",
       "         0.77318305, 0.7447163 , 0.32839456, 0.40802908, 0.8707927 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14413017, 0.14882709, 0.26474   , 0.71122164, 0.09103817,\n",
       "         0.80715036, 0.74817854, 0.28256205, 0.4014453 , 0.8680865 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16469029, 0.19576575, 0.29426983, 0.69342834, 0.13833398,\n",
       "         0.7929142 , 0.7423907 , 0.27808726, 0.42179474, 0.867992  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15080522, 0.24273767, 0.20024191, 0.7091426 , 0.11903571,\n",
       "         0.7957364 , 0.7414495 , 0.24404171, 0.43083853, 0.86205155]],\n",
       "       dtype=float32),\n",
       " array([[0.16053995, 0.24510415, 0.20836802, 0.7021332 , 0.167568  ,\n",
       "         0.7842018 , 0.73751956, 0.21759158, 0.43775755, 0.8630807 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14147371, 0.26605788, 0.09479786, 0.7178641 , 0.12343802,\n",
       "         0.79335546, 0.7434297 , 0.16092587, 0.4503944 , 0.85588443]],\n",
       "       dtype=float32),\n",
       " array([[0.14687814, 0.25256157, 0.13205911, 0.7075457 , 0.13313252,\n",
       "         0.7895758 , 0.74273777, 0.18944079, 0.44149393, 0.86129904]],\n",
       "       dtype=float32),\n",
       " array([[0.15443951, 0.298254  , 0.13312827, 0.69141364, 0.14811307,\n",
       "         0.7747978 , 0.74185055, 0.18252037, 0.46871012, 0.85867953]],\n",
       "       dtype=float32),\n",
       " array([[0.16281345, 0.3297245 , 0.1531211 , 0.68040013, 0.14341252,\n",
       "         0.7673961 , 0.7463325 , 0.19973598, 0.4708101 , 0.8627456 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16736855, 0.28868884, 0.2095081 , 0.6778852 , 0.16003846,\n",
       "         0.7637625 , 0.74606174, 0.23020585, 0.4551191 , 0.8657664 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1859962 , 0.2360972 , 0.37918276, 0.67301095, 0.17931448,\n",
       "         0.7548922 , 0.7487169 , 0.33584034, 0.41906464, 0.87495416]],\n",
       "       dtype=float32),\n",
       " array([[0.16955906, 0.2684764 , 0.26495543, 0.6658316 , 0.15061077,\n",
       "         0.77472687, 0.74931455, 0.2724731 , 0.44342875, 0.87351996]],\n",
       "       dtype=float32),\n",
       " array([[0.17297812, 0.2519519 , 0.31068626, 0.6674625 , 0.14360127,\n",
       "         0.7805963 , 0.7495059 , 0.30475116, 0.4311477 , 0.8745514 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17047222, 0.23655908, 0.33681488, 0.6644883 , 0.12616698,\n",
       "         0.7979352 , 0.74853516, 0.3217032 , 0.42066616, 0.878663  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16764127, 0.24260254, 0.34182948, 0.6726467 , 0.11021919,\n",
       "         0.7897392 , 0.74681   , 0.33266744, 0.4169497 , 0.8742791 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16430333, 0.23597002, 0.32278198, 0.67625076, 0.10927808,\n",
       "         0.79049575, 0.7476804 , 0.32271516, 0.4188616 , 0.8721017 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15976058, 0.2443726 , 0.3100671 , 0.6881842 , 0.09843934,\n",
       "         0.7803982 , 0.73969126, 0.3076858 , 0.4246699 , 0.8643763 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16350093, 0.22915749, 0.34346968, 0.68128324, 0.09407138,\n",
       "         0.78332496, 0.74555933, 0.32644734, 0.42214555, 0.86653686]],\n",
       "       dtype=float32),\n",
       " array([[0.16013657, 0.24842156, 0.2778209 , 0.6881688 , 0.11757396,\n",
       "         0.7880379 , 0.74302006, 0.28184175, 0.43573767, 0.86296886]],\n",
       "       dtype=float32),\n",
       " array([[0.1506901 , 0.2711031 , 0.19190706, 0.70767057, 0.11474728,\n",
       "         0.7833652 , 0.745864  , 0.25193426, 0.43564475, 0.8582626 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14680074, 0.30015746, 0.15104556, 0.70626724, 0.10847582,\n",
       "         0.7922652 , 0.7440214 , 0.21853428, 0.4467631 , 0.8582337 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14725985, 0.30811223, 0.12506571, 0.71009743, 0.11234252,\n",
       "         0.7889496 , 0.74739265, 0.19941898, 0.4528546 , 0.8563232 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15094669, 0.32036468, 0.12645328, 0.6993277 , 0.10950146,\n",
       "         0.7862724 , 0.7471498 , 0.19504979, 0.46285203, 0.8570962 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16533679, 0.26847437, 0.26781037, 0.6899372 , 0.14215006,\n",
       "         0.7685385 , 0.7466852 , 0.28651395, 0.4321642 , 0.865751  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16309997, 0.29470852, 0.22637245, 0.6819014 , 0.1351903 ,\n",
       "         0.77543676, 0.7475601 , 0.25805426, 0.4480017 , 0.8650391 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1628958 , 0.28103617, 0.24097097, 0.67870593, 0.13379121,\n",
       "         0.777492  , 0.7479463 , 0.2695315 , 0.44149485, 0.86844236]],\n",
       "       dtype=float32),\n",
       " array([[0.17346308, 0.27533898, 0.2914554 , 0.67342496, 0.15160674,\n",
       "         0.7679971 , 0.74324745, 0.2741496 , 0.4444262 , 0.86825514]],\n",
       "       dtype=float32),\n",
       " array([[0.1648454 , 0.2806669 , 0.2451755 , 0.6744948 , 0.13101766,\n",
       "         0.78024286, 0.74462265, 0.26459727, 0.4425303 , 0.86987424]],\n",
       "       dtype=float32),\n",
       " array([[0.16716608, 0.25305966, 0.2814743 , 0.67683697, 0.13561438,\n",
       "         0.7792888 , 0.7427588 , 0.28065217, 0.43196684, 0.87062925]],\n",
       "       dtype=float32),\n",
       " array([[0.1609432 , 0.25657895, 0.24014346, 0.67627615, 0.12281131,\n",
       "         0.7876488 , 0.74527496, 0.26553202, 0.43562394, 0.87104946]],\n",
       "       dtype=float32),\n",
       " array([[0.15372553, 0.2552393 , 0.21920976, 0.6911924 , 0.1090555 ,\n",
       "         0.79165524, 0.74382126, 0.26178202, 0.431269  , 0.865438  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16257371, 0.2544109 , 0.25754085, 0.68805933, 0.12681173,\n",
       "         0.78179514, 0.7415995 , 0.27192074, 0.42988005, 0.8676339 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15967384, 0.24915111, 0.24583016, 0.69386464, 0.12324606,\n",
       "         0.7785607 , 0.7427201 , 0.27227148, 0.42691848, 0.8650973 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16390443, 0.24595754, 0.28026015, 0.689722  , 0.12507595,\n",
       "         0.7762979 , 0.743124  , 0.2906828 , 0.4246484 , 0.8670731 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16784559, 0.24474181, 0.3186853 , 0.68360686, 0.1236503 ,\n",
       "         0.7735827 , 0.7441993 , 0.30861983, 0.42680752, 0.8664683 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16327779, 0.24634908, 0.27762213, 0.6829604 , 0.12189481,\n",
       "         0.78509706, 0.7441743 , 0.28541556, 0.4289021 , 0.8690673 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16521738, 0.26079166, 0.2773383 , 0.6830476 , 0.12650307,\n",
       "         0.7795221 , 0.74390984, 0.2819358 , 0.43472084, 0.8670916 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16165385, 0.28016862, 0.23331553, 0.68403554, 0.12338749,\n",
       "         0.78158313, 0.7436439 , 0.25866535, 0.4412366 , 0.8666176 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16040985, 0.27252898, 0.24395272, 0.6886096 , 0.11877873,\n",
       "         0.7799456 , 0.7447849 , 0.2715892 , 0.43694767, 0.864335  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16142024, 0.26290962, 0.25902152, 0.68595   , 0.11888023,\n",
       "         0.78133297, 0.7449612 , 0.27631244, 0.43661967, 0.8648455 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15827705, 0.25137344, 0.26464254, 0.682938  , 0.11030768,\n",
       "         0.78688234, 0.74563855, 0.28182325, 0.43452677, 0.8651371 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16302457, 0.26272884, 0.2769186 , 0.67840266, 0.11989847,\n",
       "         0.7834797 , 0.74357176, 0.27548084, 0.4420078 , 0.8649697 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16285789, 0.23915146, 0.29502627, 0.68069136, 0.11827897,\n",
       "         0.78362244, 0.74360687, 0.2881273 , 0.43173492, 0.8668826 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15691772, 0.2286131 , 0.2731692 , 0.68456155, 0.11039311,\n",
       "         0.7849274 , 0.7458687 , 0.28550538, 0.42804313, 0.86569446]],\n",
       "       dtype=float32),\n",
       " array([[0.15718214, 0.21278302, 0.2935533 , 0.68222183, 0.10547496,\n",
       "         0.78946525, 0.74624527, 0.2934794 , 0.42651945, 0.865298  ]],\n",
       "       dtype=float32),\n",
       " array([[0.15756327, 0.21118198, 0.28947777, 0.6843219 , 0.10829379,\n",
       "         0.79128605, 0.74466085, 0.2892548 , 0.42333564, 0.86740315]],\n",
       "       dtype=float32),\n",
       " array([[0.16067727, 0.23022063, 0.2710954 , 0.68607825, 0.11885086,\n",
       "         0.7887705 , 0.74372566, 0.27536526, 0.42926437, 0.86774516]],\n",
       "       dtype=float32),\n",
       " array([[0.1612241 , 0.24277653, 0.25800306, 0.6908519 , 0.1198198 ,\n",
       "         0.7836313 , 0.7450345 , 0.277824  , 0.4276357 , 0.86767715]],\n",
       "       dtype=float32),\n",
       " array([[0.1644181 , 0.24451502, 0.24837069, 0.6959672 , 0.13907355,\n",
       "         0.77863973, 0.74272007, 0.26086858, 0.42813778, 0.8683139 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15672687, 0.24946631, 0.21149279, 0.6979877 , 0.12245241,\n",
       "         0.78387845, 0.74667907, 0.25299928, 0.43134296, 0.8658198 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15752697, 0.23884672, 0.23794739, 0.6893943 , 0.11976324,\n",
       "         0.7872272 , 0.7457388 , 0.26169032, 0.43225676, 0.86676437]],\n",
       "       dtype=float32),\n",
       " array([[0.15760517, 0.2441656 , 0.23823735, 0.68730366, 0.11957264,\n",
       "         0.7843359 , 0.745427  , 0.26171812, 0.4342727 , 0.8658758 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1624971 , 0.24200146, 0.27029485, 0.68317944, 0.12317999,\n",
       "         0.779642  , 0.74567133, 0.27939075, 0.43214363, 0.8667881 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1653194 , 0.23111771, 0.31092462, 0.6822801 , 0.11740221,\n",
       "         0.77595276, 0.74585295, 0.30230212, 0.4281879 , 0.86566144]],\n",
       "       dtype=float32),\n",
       " array([[0.16837198, 0.24006471, 0.30508155, 0.68213195, 0.12394673,\n",
       "         0.77359134, 0.7470046 , 0.30195954, 0.42888823, 0.86690843]],\n",
       "       dtype=float32),\n",
       " array([[0.16657281, 0.23236828, 0.30641943, 0.6805043 , 0.11864546,\n",
       "         0.779531  , 0.74620026, 0.30120003, 0.4272072 , 0.86773044]],\n",
       "       dtype=float32),\n",
       " array([[0.16902441, 0.22477779, 0.32774013, 0.67885125, 0.11957661,\n",
       "         0.7791963 , 0.7457067 , 0.30819112, 0.42484212, 0.8689662 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16499445, 0.23817568, 0.29210353, 0.6791203 , 0.11995623,\n",
       "         0.786725  , 0.7454481 , 0.28751808, 0.432215  , 0.86848354]],\n",
       "       dtype=float32),\n",
       " array([[0.16014117, 0.2536319 , 0.24571598, 0.6898738 , 0.1189715 ,\n",
       "         0.7839899 , 0.7455491 , 0.27125308, 0.43260473, 0.8667344 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16318186, 0.25526813, 0.2562185 , 0.69264954, 0.1199741 ,\n",
       "         0.7807715 , 0.74415064, 0.27707562, 0.43118832, 0.86598414]],\n",
       "       dtype=float32),\n",
       " array([[0.15835112, 0.22589278, 0.2661786 , 0.69250077, 0.1121584 ,\n",
       "         0.78317195, 0.7448644 , 0.28255078, 0.4241926 , 0.8663517 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15774368, 0.2239091 , 0.26132452, 0.6909886 , 0.11331365,\n",
       "         0.78626776, 0.744241  , 0.27538344, 0.427045  , 0.8656356 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16082992, 0.22908883, 0.25768954, 0.6945462 , 0.12266516,\n",
       "         0.77885634, 0.7453351 , 0.27755734, 0.42399532, 0.8668698 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16385818, 0.22931388, 0.28736207, 0.6857367 , 0.12135257,\n",
       "         0.78105575, 0.7449526 , 0.2856163 , 0.42872176, 0.8668079 ]],\n",
       "       dtype=float32),\n",
       " array([[0.158978  , 0.2415508 , 0.24636742, 0.68965214, 0.12167093,\n",
       "         0.78327096, 0.7456375 , 0.267783  , 0.43129835, 0.8665117 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16766436, 0.2300892 , 0.30265963, 0.68375254, 0.12643743,\n",
       "         0.7758962 , 0.74343973, 0.29096186, 0.42724165, 0.8677045 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15892202, 0.24713896, 0.24928607, 0.68713474, 0.11745584,\n",
       "         0.7862317 , 0.7448453 , 0.2675668 , 0.43481323, 0.8654887 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15799132, 0.23933312, 0.2538252 , 0.6852569 , 0.11365205,\n",
       "         0.78911835, 0.7470338 , 0.27385587, 0.43263903, 0.8663594 ]],\n",
       "       dtype=float32),\n",
       " array([[0.162241  , 0.23878519, 0.29140693, 0.67827046, 0.10826126,\n",
       "         0.7870225 , 0.7465483 , 0.29223162, 0.4334523 , 0.8656962 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16766134, 0.20850772, 0.38323703, 0.66258657, 0.09581028,\n",
       "         0.7848259 , 0.7459674 , 0.32483256, 0.4288612 , 0.8660012 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16033371, 0.21787442, 0.3232121 , 0.67139685, 0.09737751,\n",
       "         0.7888416 , 0.7475028 , 0.30480182, 0.4304092 , 0.86533934]],\n",
       "       dtype=float32),\n",
       " array([[0.16043828, 0.23786063, 0.27039862, 0.68604374, 0.11803168,\n",
       "         0.7854322 , 0.7452789 , 0.27585483, 0.43458697, 0.865292  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16116689, 0.2408347 , 0.23787606, 0.6961918 , 0.13206427,\n",
       "         0.7826603 , 0.7446966 , 0.26337272, 0.42733178, 0.8682689 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15676676, 0.2423432 , 0.22232501, 0.69715875, 0.1220511 ,\n",
       "         0.787121  , 0.7458382 , 0.25888056, 0.4294679 , 0.86645013]],\n",
       "       dtype=float32),\n",
       " array([[0.16328798, 0.26163134, 0.20603134, 0.70293695, 0.15055893,\n",
       "         0.77989185, 0.74049234, 0.23172306, 0.43367967, 0.8668921 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15225591, 0.26840347, 0.15569736, 0.70723426, 0.12730221,\n",
       "         0.78897977, 0.7405135 , 0.20805307, 0.4368715 , 0.8645168 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15512504, 0.2738364 , 0.1760432 , 0.6986862 , 0.12631416,\n",
       "         0.7846722 , 0.7427857 , 0.22252512, 0.44154558, 0.8636789 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16096376, 0.28737852, 0.21280876, 0.6867825 , 0.1309525 ,\n",
       "         0.77708477, 0.7427678 , 0.24460343, 0.44410393, 0.8651301 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16222626, 0.26532042, 0.23470068, 0.68688715, 0.13074191,\n",
       "         0.7748452 , 0.74615943, 0.2603651 , 0.44051138, 0.86391443]],\n",
       "       dtype=float32),\n",
       " array([[0.16091257, 0.2596955 , 0.24432069, 0.68205535, 0.12267746,\n",
       "         0.7801577 , 0.74701774, 0.26785034, 0.44047812, 0.8644009 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16448912, 0.2570393 , 0.2723372 , 0.67692685, 0.1235174 ,\n",
       "         0.7799263 , 0.7482123 , 0.2872181 , 0.4351805 , 0.86823994]],\n",
       "       dtype=float32),\n",
       " array([[0.16607335, 0.2326795 , 0.30640048, 0.669905  , 0.12146027,\n",
       "         0.78680295, 0.748298  , 0.2985116 , 0.43072346, 0.87092614]],\n",
       "       dtype=float32),\n",
       " array([[0.16514347, 0.2274597 , 0.30175123, 0.6746495 , 0.12088145,\n",
       "         0.7845157 , 0.7483044 , 0.29829445, 0.42794305, 0.8701324 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1622312 , 0.24699861, 0.2634836 , 0.6803435 , 0.12151171,\n",
       "         0.7872744 , 0.746026  , 0.2736765 , 0.43607894, 0.8681675 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1606048 , 0.2511632 , 0.24691348, 0.686981  , 0.12115335,\n",
       "         0.78402054, 0.74609375, 0.27309895, 0.43100238, 0.8685518 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16205198, 0.23584774, 0.28472126, 0.68069535, 0.11594467,\n",
       "         0.78626496, 0.7450955 , 0.2868997 , 0.42991218, 0.8682496 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15968545, 0.22548114, 0.29586992, 0.6830728 , 0.10524452,\n",
       "         0.7838285 , 0.744483  , 0.29522976, 0.42685243, 0.8658787 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15410009, 0.23991597, 0.2456369 , 0.6899931 , 0.10705464,\n",
       "         0.78903157, 0.74433184, 0.27037007, 0.43167514, 0.86497074]],\n",
       "       dtype=float32),\n",
       " array([[0.15796699, 0.24125797, 0.22975579, 0.69844645, 0.12441184,\n",
       "         0.7844395 , 0.74352354, 0.25789925, 0.42891097, 0.8657251 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15887539, 0.24297328, 0.2507    , 0.6919985 , 0.11903906,\n",
       "         0.78252625, 0.743879  , 0.27025333, 0.43060997, 0.8652683 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16183633, 0.21045552, 0.32009384, 0.67935836, 0.1073014 ,\n",
       "         0.7807169 , 0.74489284, 0.301648  , 0.42606837, 0.86513627]],\n",
       "       dtype=float32),\n",
       " array([[0.15813884, 0.22289526, 0.2957899 , 0.67977566, 0.09912068,\n",
       "         0.78533727, 0.7471262 , 0.29885015, 0.42880565, 0.8639777 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16562529, 0.21472475, 0.36070147, 0.6673561 , 0.09307232,\n",
       "         0.7883448 , 0.74736243, 0.32398203, 0.425751  , 0.86740196]],\n",
       "       dtype=float32),\n",
       " array([[0.17018756, 0.2133655 , 0.39532453, 0.66106445, 0.09202738,\n",
       "         0.78715533, 0.7456581 , 0.33261952, 0.4256694 , 0.86854804]],\n",
       "       dtype=float32),\n",
       " array([[0.16426574, 0.21958515, 0.32694426, 0.6785032 , 0.10537908,\n",
       "         0.7839999 , 0.74617493, 0.30484816, 0.4279397 , 0.8668124 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16222608, 0.22082555, 0.28359902, 0.6900856 , 0.12771115,\n",
       "         0.78010195, 0.74536663, 0.2803518 , 0.42773885, 0.8673966 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16122115, 0.21032156, 0.2854873 , 0.6927624 , 0.118743  ,\n",
       "         0.7831832 , 0.7445669 , 0.2845542 , 0.42187703, 0.86811495]],\n",
       "       dtype=float32),\n",
       " array([[0.1612912 , 0.22806467, 0.27421412, 0.6928567 , 0.1144028 ,\n",
       "         0.78431904, 0.74424046, 0.2829141 , 0.42599532, 0.867081  ]],\n",
       "       dtype=float32),\n",
       " array([[0.1576341 , 0.23166455, 0.2262359 , 0.69972503, 0.12803349,\n",
       "         0.78920346, 0.7436788 , 0.25425017, 0.42984936, 0.8653051 ]],\n",
       "       dtype=float32),\n",
       " array([[0.14789298, 0.23468561, 0.17679863, 0.7089784 , 0.1196286 ,\n",
       "         0.7917919 , 0.74391824, 0.23251115, 0.4282641 , 0.8632606 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15829629, 0.20850699, 0.25428465, 0.69770885, 0.1286492 ,\n",
       "         0.7822445 , 0.7422522 , 0.26712596, 0.42034146, 0.8673394 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16247544, 0.21486731, 0.25632364, 0.6977442 , 0.13618648,\n",
       "         0.77372587, 0.7444038 , 0.2746275 , 0.4181882 , 0.8686829 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16424006, 0.20177558, 0.28280607, 0.69044435, 0.13111596,\n",
       "         0.77575684, 0.7451933 , 0.28401244, 0.42025897, 0.8671683 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15898408, 0.23539966, 0.23674083, 0.69325   , 0.12716936,\n",
       "         0.7806511 , 0.7454608 , 0.26534668, 0.42843568, 0.86618793]],\n",
       "       dtype=float32),\n",
       " array([[0.16556528, 0.26823857, 0.22705662, 0.6900367 , 0.14645137,\n",
       "         0.7801179 , 0.74442524, 0.251354  , 0.4366721 , 0.86940885]],\n",
       "       dtype=float32),\n",
       " array([[0.16430865, 0.3097494 , 0.1658892 , 0.6916525 , 0.15283985,\n",
       "         0.7756921 , 0.74363905, 0.20764045, 0.45331228, 0.86837965]],\n",
       "       dtype=float32),\n",
       " array([[0.15815252, 0.30749637, 0.14679289, 0.69625705, 0.13873959,\n",
       "         0.78003544, 0.7441543 , 0.2003391 , 0.45264474, 0.86608124]],\n",
       "       dtype=float32),\n",
       " array([[0.15428802, 0.26702493, 0.17729512, 0.6956606 , 0.12819235,\n",
       "         0.7886924 , 0.74500686, 0.2296802 , 0.43634066, 0.8677228 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16122636, 0.2890582 , 0.19479017, 0.68748736, 0.13314955,\n",
       "         0.7829696 , 0.7441665 , 0.23142423, 0.4476995 , 0.8665666 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16178897, 0.28792858, 0.22197379, 0.6853844 , 0.12565616,\n",
       "         0.78034604, 0.7452089 , 0.25781065, 0.44326296, 0.8648831 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15682401, 0.2561675 , 0.2444032 , 0.6842782 , 0.11895172,\n",
       "         0.7850166 , 0.7449698 , 0.26886353, 0.43550193, 0.8653704 ]],\n",
       "       dtype=float32),\n",
       " array([[0.165133  , 0.22546317, 0.3343827 , 0.67267436, 0.11308507,\n",
       "         0.7808643 , 0.746165  , 0.31301558, 0.42798904, 0.8668104 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1658335 , 0.22936687, 0.32923552, 0.6738717 , 0.10716466,\n",
       "         0.78004974, 0.74782056, 0.32058218, 0.42452258, 0.86748064]],\n",
       "       dtype=float32),\n",
       " array([[0.17044994, 0.22885863, 0.36530754, 0.6666693 , 0.10889606,\n",
       "         0.7832332 , 0.746538  , 0.32669735, 0.42649972, 0.869657  ]],\n",
       "       dtype=float32),\n",
       " array([[0.16979131, 0.23745857, 0.3557937 , 0.66657394, 0.10831285,\n",
       "         0.7869853 , 0.7468954 , 0.3221668 , 0.42845723, 0.8706336 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16338493, 0.24938473, 0.29511052, 0.679098  , 0.1119065 ,\n",
       "         0.7862553 , 0.74684334, 0.2976471 , 0.43096066, 0.86870015]],\n",
       "       dtype=float32),\n",
       " array([[0.16082351, 0.24306521, 0.2949915 , 0.6808123 , 0.11295488,\n",
       "         0.78508765, 0.74587494, 0.291001  , 0.43306202, 0.8671248 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15521917, 0.24475716, 0.27994275, 0.68454754, 0.09986592,\n",
       "         0.79018563, 0.74493295, 0.28470248, 0.43570766, 0.8640897 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16045122, 0.23717482, 0.29764768, 0.6879329 , 0.10397118,\n",
       "         0.78132546, 0.7431887 , 0.2926513 , 0.43035248, 0.86477894]],\n",
       "       dtype=float32),\n",
       " array([[0.16308382, 0.22737935, 0.29981354, 0.69147784, 0.10982687,\n",
       "         0.77747834, 0.7425552 , 0.293727  , 0.42609665, 0.8651416 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16648337, 0.22713256, 0.31907314, 0.68909377, 0.11159858,\n",
       "         0.7691615 , 0.74213696, 0.2978958 , 0.4282754 , 0.86435986]],\n",
       "       dtype=float32),\n",
       " array([[0.16649711, 0.2210114 , 0.31804705, 0.68863475, 0.11189321,\n",
       "         0.7725116 , 0.743342  , 0.29876667, 0.42556193, 0.86602795]],\n",
       "       dtype=float32),\n",
       " array([[0.16184266, 0.2262525 , 0.27043322, 0.6942918 , 0.12582801,\n",
       "         0.7805176 , 0.74506485, 0.27898425, 0.42780837, 0.8651427 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1595528 , 0.25047213, 0.23465315, 0.6938954 , 0.13286318,\n",
       "         0.7851523 , 0.7448024 , 0.26012662, 0.4345309 , 0.86511445]],\n",
       "       dtype=float32),\n",
       " array([[0.15842843, 0.2605801 , 0.23109938, 0.69051635, 0.12882875,\n",
       "         0.787641  , 0.74459684, 0.2560359 , 0.44031003, 0.8638807 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15397365, 0.26876056, 0.19299471, 0.69567984, 0.12679647,\n",
       "         0.78963447, 0.74544346, 0.24047518, 0.4396911 , 0.86394596]],\n",
       "       dtype=float32),\n",
       " array([[0.14811966, 0.27629113, 0.15494174, 0.6995259 , 0.11757524,\n",
       "         0.7950199 , 0.7481358 , 0.2202944 , 0.4458218 , 0.86110044]],\n",
       "       dtype=float32),\n",
       " array([[0.15619357, 0.2785859 , 0.1759244 , 0.6959407 , 0.13581106,\n",
       "         0.78438747, 0.7458777 , 0.22483143, 0.44442824, 0.8635787 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16079625, 0.23928517, 0.23536721, 0.69107157, 0.13741803,\n",
       "         0.7822427 , 0.7457596 , 0.26239115, 0.42880416, 0.8675325 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16685796, 0.23661587, 0.27263638, 0.6830598 , 0.14295855,\n",
       "         0.774232  , 0.7447384 , 0.27839407, 0.42815518, 0.8685003 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17372133, 0.20380689, 0.35879004, 0.6713083 , 0.1275848 ,\n",
       "         0.77456564, 0.7458272 , 0.31774464, 0.42021117, 0.8703247 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1599493 , 0.22359158, 0.2900459 , 0.67170733, 0.11170407,\n",
       "         0.79226714, 0.7482466 , 0.2932661 , 0.42752874, 0.8696752 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15919101, 0.24265908, 0.24348891, 0.6798916 , 0.12200221,\n",
       "         0.79249036, 0.7486901 , 0.2713957 , 0.43230942, 0.8697647 ]],\n",
       "       dtype=float32),\n",
       " array([[0.17009664, 0.28736493, 0.23717828, 0.68292344, 0.14767872,\n",
       "         0.7765811 , 0.7444252 , 0.2538686 , 0.44527534, 0.86875474]],\n",
       "       dtype=float32),\n",
       " array([[0.15749268, 0.3000618 , 0.1652328 , 0.69736266, 0.13467763,\n",
       "         0.7823793 , 0.74294096, 0.21706063, 0.44517353, 0.8663712 ]],\n",
       "       dtype=float32),\n",
       " array([[0.15538315, 0.32100534, 0.14618711, 0.6927275 , 0.12451613,\n",
       "         0.78313774, 0.74495095, 0.20343693, 0.45940828, 0.8627236 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1515054 , 0.29496357, 0.16887824, 0.69412094, 0.11234894,\n",
       "         0.7941388 , 0.74355614, 0.22193104, 0.44961995, 0.8623825 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1492271 , 0.31478813, 0.13630249, 0.6927047 , 0.11129189,\n",
       "         0.78792596, 0.74465775, 0.19710208, 0.46209344, 0.85937107]],\n",
       "       dtype=float32),\n",
       " array([[0.1552971 , 0.2927853 , 0.18902902, 0.6909172 , 0.11890242,\n",
       "         0.7837292 , 0.7450607 , 0.23985544, 0.44478416, 0.8633949 ]],\n",
       "       dtype=float32),\n",
       " array([[0.1665507 , 0.28298026, 0.23592524, 0.69327956, 0.145854  ,\n",
       "         0.76373744, 0.74499065, 0.26554373, 0.43486866, 0.8649049 ]],\n",
       "       dtype=float32),\n",
       " array([[0.16530947, 0.32235038, 0.18882693, 0.6854834 , 0.14034869,\n",
       "         0.7657063 , 0.7435332 , 0.22580546, 0.45514646, 0.86431664]],\n",
       "       dtype=float32),\n",
       " array([[0.16323821, 0.3231521 , 0.18090175, 0.6830571 , 0.13082553,\n",
       "         0.7708417 , 0.7466209 , 0.22799616, 0.45762977, 0.86468405]],\n",
       "       dtype=float32),\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "togive3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
